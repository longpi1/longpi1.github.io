

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/%E5%AD%A6%E6%A0%A1.png">
  <link rel="icon" href="/img/%E5%AD%A6%E6%A0%A1.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="lp">
  <meta name="keywords" content="">
  
    <meta name="description" content="极客时间Linux 性能优化实战笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="8.如何排查网络请求延迟变大">
<meta property="og:url" content="https://blog.longpi1.com/2022/11/12/8-%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/index.html">
<meta property="og:site_name" content="lp&#39;s blog">
<meta property="og:description" content="极客时间Linux 性能优化实战笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/55/63/55347dc1ec78688da5673f29b60aa863.png?wh=816*516">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/45/98/4590d2477d54bf9aa3d2881ff3296498.png?wh=453*372">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/f9/6e/f9fa457f95276ae4904a91619501376e.png?wh=761*295">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/ff/cc/ff498170eb58abcdd841709fb4c036cc.png?wh=722*471">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/72/8a/72eb14e8996147a458aa6523110c938a.png?wh=750*268">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/c5/c6/c51439692921cbf67b746a45fded2ec6.png?wh=672*934">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/b5/ba/b5f1643cdca33f29408881542fca4eba.png?wh=1599*621">
<meta property="article:published_time" content="2022-11-12T04:29:03.000Z">
<meta property="article:modified_time" content="2022-11-12T05:32:59.182Z">
<meta property="article:author" content="lp">
<meta property="article:tag" content="原创">
<meta property="article:tag" content="笔记">
<meta property="article:tag" content="linux">
<meta property="article:tag" content="网络">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://static001.geekbang.org/resource/image/55/63/55347dc1ec78688da5673f29b60aa863.png?wh=816*516">
  
  
  
  <title>8.如何排查网络请求延迟变大 - lp&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.longpi1.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":30,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"UvaCwj6C0pVj9XCWuMtLaBWJ-gzGzoHsz","app_key":"w2xUk9wycItSqrREmRMDYJHY","server_url":"https://uvacwj6c.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>lp&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                文章分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于我
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="8.如何排查网络请求延迟变大"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-11-12 12:29" pubdate>
          2022年11月12日 中午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          8.7k 字
        
      </span>
    

  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>


    <a target="_blank" rel="noopener" href="https://github.com/longpi1"><img loading="lazy" width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_left_darkblue_121621.png?resize=149%2C149" srcset="/img/loading.gif" lazyload class="attachment-full size-full" alt="follow me on GitHub" data-recalc-dims="1"></a>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <aside class="sidebar" style="padding-left: 2rem; margin-right: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">8.如何排查网络请求延迟变大</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="8-如何排查网络请求延迟变大"><a href="#8-如何排查网络请求延迟变大" class="headerlink" title="8.如何排查网络请求延迟变大"></a>8.如何排查网络请求延迟变大</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure>

<h2 id="网络延迟"><a href="#网络延迟" class="headerlink" title="网络延迟"></a>网络延迟</h2><p>提到 <strong>网络延迟</strong> 时，你可能轻松想起它的含义——网络数据传输所用的时间。不过要注意，这个时间可能是单向的，指从源地址发送到目的地址的单程时间；也可能是双向的，即从源地址发送到目的地址，然后又从目的地址发回响应，这个往返全程所用的时间。</p>
<p>通常，我们更常用的是双向的往返通信延迟，比如 ping 测试的结果，就是往返延时 RTT（Round-Trip Time）。</p>
<p>除了网络延迟外，另一个常用的指标是 <strong>应用程序延迟</strong>，它是指，从应用程序接收到请求，再到发回响应，全程所用的时间。通常，应用程序延迟也指的是往返延迟，是网络数据传输时间加上数据处理时间的和。</p>
<p>ping 基于 ICMP 协议，它通过计算 ICMP 回显响应报文与 ICMP 回显请求报文的时间差，来获得往返延时。这个过程并不需要特殊认证，常被很多网络攻击利用，比如端口扫描工具 nmap、组包工具 hping3 等等。</p>
<p>所以，为了避免这些问题，很多网络服务会把 ICMP 禁止掉，这也就导致我们无法用 ping ，来测试网络服务的可用性和往返延时。这时，可以用 traceroute 或 hping3 的 TCP 和 UDP 模式，来获取网络延迟。</p>
<p>比如，以 baidu.com 为例，可以执行下面的 hping3 命令，测试机器到百度搜索服务器的网络延迟：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80</span><br>$ hping3 -c 3 -S -p 80 baidu.com<br>HPING baidu.com (eth0 123.125.115.110): S set, 40 headers + 0 data bytes<br><span class="hljs-attribute">len</span>=46 <span class="hljs-attribute">ip</span>=123.125.115.110 <span class="hljs-attribute">ttl</span>=51 <span class="hljs-attribute">id</span>=47908 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=0 <span class="hljs-attribute">win</span>=8192 <span class="hljs-attribute">rtt</span>=20.9 ms<br><span class="hljs-attribute">len</span>=46 <span class="hljs-attribute">ip</span>=123.125.115.110 <span class="hljs-attribute">ttl</span>=51 <span class="hljs-attribute">id</span>=6788  <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=1 <span class="hljs-attribute">win</span>=8192 <span class="hljs-attribute">rtt</span>=20.9 ms<br><span class="hljs-attribute">len</span>=46 <span class="hljs-attribute">ip</span>=123.125.115.110 <span class="hljs-attribute">ttl</span>=51 <span class="hljs-attribute">id</span>=37699 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=2 <span class="hljs-attribute">win</span>=8192 <span class="hljs-attribute">rtt</span>=20.9 ms<br><br>--- baidu.com hping statistic ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max = 20.9/20.9/20.9 ms<br><br></code></pre></td></tr></table></figure>

<p>从 hping3 的结果中，可以看到，往返延迟 RTT 为 20.9ms。</p>
<p>用 traceroute ，也可以得到类似结果：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析</span><br>$ traceroute --tcp -p 80 -n baidu.com<br>traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets<br> 1  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 2  *</span> <span class="hljs-emphasis">* *</span><br> 3  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 4  *</span> <span class="hljs-emphasis">* *</span><br> 5  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 6  *</span> <span class="hljs-emphasis">* *</span><br> 7  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 8  *</span> <span class="hljs-emphasis">* *</span><br> 9  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis">10  *</span> <span class="hljs-emphasis">* *</span><br>11  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis">12  *</span> <span class="hljs-emphasis">* *</span><br>13  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis">14  123.125.115.110  20.684 ms *</span>  20.798 ms<br><br></code></pre></td></tr></table></figure>

<p>traceroute 会在路由的每一跳发送三个包，并在收到响应后，输出往返延时。如果无响应或者响应超时（默认5s），就会输出一个星号。</p>
<p>知道了基于 TCP 测试网络服务延迟的方法后，接下来，我们就通过一个案例，来学习网络延迟升高时的分析思路。</p>
<h2 id="案例准备"><a href="#案例准备" class="headerlink" title="案例准备"></a>案例准备</h2><p>下面的案例仍然基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。环境如下：</p>
<ul>
<li><p>机器配置：2 CPU，8GB 内存。</p>
</li>
<li><p>预先安装 docker、hping3、tcpdump、curl、wrk、Wireshark 等工具，比如 apt-get install docker.io hping3 tcpdump curl。</p>
</li>
</ul>
<p>由于Wireshark 需要图形界面，如果你的虚拟机没有图形界面，就可以把 Wireshark 安装到其他的机器中（比如 Windows 笔记本）。</p>
<p>本次案例用到两台虚拟机，关系如下：</p>
<p><img src="https://static001.geekbang.org/resource/image/55/63/55347dc1ec78688da5673f29b60aa863.png?wh=816*516" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>接下来，打开两个终端，分别 SSH 登录到两台机器上（以下步骤，假设终端编号与图示VM 编号一致），并安装上面提到的这些工具。</p>
<h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p>为了对比得出延迟增大的影响，首先在终端一中，执行下面的命令，运行官方 Nginx，它会在 80 端口监听：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> <span class="hljs-attribute">--network</span>=host <span class="hljs-attribute">--name</span>=good -itd nginx<br>fb4ed7cb9177d10e270f8320a7fb64717eac3451114c9fab3c50e02be2e88ba2<br><br></code></pre></td></tr></table></figure>

<p>继续在终端一中，执行下面的命令，运行案例应用，它会监听 8080 端口：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> --name nginx <span class="hljs-attribute">--network</span>=host -itd feisky/nginx:latency<br>b99bd136dcfd907747d9c803fdc0255e578bad6d66f4e9c32b826d75b6812724<br><br></code></pre></td></tr></table></figure>

<p>然后，在终端二中执行 curl 命令，验证两个容器已经正常启动。输出如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs xml"># 80端口正常<br>$ curl http://192.168.0.30<br><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span><br>...<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">em</span>&gt;</span>Thank you for using nginx.<span class="hljs-tag">&lt;/<span class="hljs-name">em</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br># 8080端口正常<br>$ curl http://192.168.0.30:8080<br>...<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">em</span>&gt;</span>Thank you for using nginx.<span class="hljs-tag">&lt;/<span class="hljs-name">em</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br></code></pre></td></tr></table></figure>

<p>接着，我们再用 hping3来测试它们的延迟，看看有什么区别。还是在终端二，执行下面的命令，分别测试案例机器 80 端口和 8080 端口的延迟：</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 测试80端口延迟</span><br>$ hping3 -c 3 -S -p 80 192.168.0.30<br>HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=0 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.8 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=1 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.7 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=2 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.6 ms<br><br>--- 192.168.0.30 hping statistic ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max = 7.6/7.7/7.8 ms<br><br></code></pre></td></tr></table></figure>

<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 测试8080端口延迟</span><br>$ hping3 -c 3 -S -p 8080 192.168.0.30<br>HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=0 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.7 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=1 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.6 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=2 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.3 ms<br><br>--- 192.168.0.30 hping statistic ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max = 7.3/7.6/7.7 ms<br><br></code></pre></td></tr></table></figure>

<p>从这个输出你可以看到，两个端口的延迟差不多，都是 7ms。不过，这只是单个请求的情况。换成并发请求的话，又会怎么样呢？</p>
<p>接下来，我们就用 wrk 试试。这次在终端二中，执行下面的新命令，分别测试案例机器并发 100 时， 80 端口和 8080 端口的性能：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试80端口性能</span><br>$ <span class="hljs-comment"># wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30/</span><br>Running 10s <span class="hljs-built_in">test</span> @ http://192.168.0.30/<br>  2 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency     9.19ms   12.32ms 319.61ms   97.80%<br>    Req/Sec     6.20k   426.80     8.25k    85.50%<br>  Latency Distribution<br>     50%    7.78ms<br>     75%    8.22ms<br>     90%    9.14ms<br>     99%   50.53ms<br>  123558 requests <span class="hljs-keyword">in</span> 10.01s, 100.15MB <span class="hljs-built_in">read</span><br>Requests/sec:  12340.91<br>Transfer/sec:     10.00MB<br><br></code></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试8080端口性能</span><br>$ wrk --latency -c 100 -t 2 --<span class="hljs-built_in">timeout</span> 2 http://192.168.0.30:8080/<br>Running 10s <span class="hljs-built_in">test</span> @ http://192.168.0.30:8080/<br>  2 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency    43.60ms    6.41ms  56.58ms   97.06%<br>    Req/Sec     1.15k   120.29     1.92k    88.50%<br>  Latency Distribution<br>     50%   44.02ms<br>     75%   44.33ms<br>     90%   47.62ms<br>     99%   48.88ms<br>  22853 requests <span class="hljs-keyword">in</span> 10.01s, 18.55MB <span class="hljs-built_in">read</span><br>Requests/sec:   2283.31<br>Transfer/sec:      1.85MB<br><br></code></pre></td></tr></table></figure>

<p>从上面两个输出可以看到，官方Nginx（监听在80端口）的平均延迟是 9.19ms，而案例 Nginx 的平均延迟（监听在 8080 端口）则是 43.6ms。从延迟的分布上来看，官方 Nginx 90% 的请求，都可以在 9ms以内完成；而案例 Nginx 50% 的请求，就已经达到了 44 ms。</p>
<p>再结合上面 hping3 的输出，我们很容易发现，案例 Nginx 在并发请求下的延迟增大了很多，这是怎么回事呢？</p>
<p>接下来，我们在终端一中，执行下面的 <strong>tcpdump</strong> 命令，抓取 8080 端口上收发的网络包，并保存到 nginx.pcap 文件：</p>
<figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>tcpdump -nn tcp port <span class="hljs-number">8080</span> -w nginx.pcap<br><br></code></pre></td></tr></table></figure>

<p>然后切换到终端二中，重新执行 wrk 命令：</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-comment"># 测试8080端口性能</span><br>$ wrk <span class="hljs-params">--latency</span> -c 100 -t 2 <span class="hljs-params">--timeout</span> 2 http:<span class="hljs-string">//192.168.0.30</span><span class="hljs-function">:8080</span>/<br><br></code></pre></td></tr></table></figure>

<p>当 wrk 命令结束后，再次切换回终端一，并按下 Ctrl+C 结束 tcpdump 命令。然后，再把抓取到的 nginx.pcap ，复制到装有 Wireshark 的机器中（如果 VM1 已经带有图形界面，那么可以跳过复制步骤），并用 Wireshark 打开它。</p>
<p>由于网络包的数量比较多，可以先过滤一下。比如，在选择一个包后，可以单击右键并选择 “Follow” -&gt; “TCP Stream”，如下图所示：</p>
<p><img src="https://static001.geekbang.org/resource/image/45/98/4590d2477d54bf9aa3d2881ff3296498.png?wh=453*372" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>然后，关闭弹出来的对话框，回到 Wireshark 主窗口。会发现 Wireshark 已经自动帮你设置了一个过滤表达式 tcp.stream eq 24。如下图所示（图中省去了源和目的IP地址）：</p>
<p><img src="https://static001.geekbang.org/resource/image/f9/6e/f9fa457f95276ae4904a91619501376e.png?wh=761*295" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>从这里，可以看到这个 TCP 连接从三次握手开始的每个请求和响应情况。如果觉得不够直观，可以继续点击菜单栏里的 Statics -&gt; Flow Graph，选中 “Limit to display filter” 并设置 Flow type 为 “TCP Flows”：</p>
<p><img src="https://static001.geekbang.org/resource/image/ff/cc/ff498170eb58abcdd841709fb4c036cc.png?wh=722*471" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>注意，这个图的左边是客户端，而右边是 Nginx 服务器。通过这个图就可以看出，前面三次握手，以及第一次 HTTP 请求和响应还是挺快的，但第二次 HTTP 请求就比较慢了，特别是客户端在收到服务器第一个分组后，40ms 后才发出了 ACK 响应（图中蓝色行）。</p>
<p>40ms 这个值，这是 TCP 延迟确认（Delayed ACK）的最小超时时间。</p>
<p>关于延迟确认。这是针对 TCP ACK 的一种优化机制，也就是说，不用每次请求都发送一个 ACK，而是先等一会儿（比如 40ms），看看有没有“顺风车”。如果这段时间内，正好有其他包需要发送，那就捎带着 ACK 一起发送过去。当然，如果一直等不到其他包，那就超时后单独发送 ACK。</p>
<p>因为案例中 40ms 发生在客户端上，我们有理由怀疑，是客户端开启了延迟确认机制。而这儿的客户端，实际上就是前面运行的 wrk。</p>
<p>查询 TCP 文档（执行 man tcp），只有 TCP 套接字专门设置了 TCP_QUICKACK ，才会开启快速确认模式；否则，默认情况下，采用的就是延迟确认机制：</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vim">TCP_QUICKACK (since Linux <span class="hljs-number">2.4</span>.<span class="hljs-number">4</span>)<br>              Enable  quickack <span class="hljs-keyword">mode</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">set</span> <span class="hljs-built_in">or</span> disable quickack <span class="hljs-keyword">mode</span> <span class="hljs-keyword">if</span> cleared.  In quickack <span class="hljs-keyword">mode</span>, acks are sent imme‐<br>              diately, rather than delayed <span class="hljs-keyword">if</span> needed in accordance <span class="hljs-keyword">to</span> <span class="hljs-keyword">normal</span> TCP operation.  This flag <span class="hljs-keyword">is</span>  not  perma‐<br>              nent,  it <span class="hljs-keyword">only</span> enables <span class="hljs-keyword">a</span> switch <span class="hljs-keyword">to</span> <span class="hljs-built_in">or</span> from quickack <span class="hljs-keyword">mode</span>.  Subsequent operation of the TCP protocol will<br>              once again enter/leave quickack <span class="hljs-keyword">mode</span> depending <span class="hljs-keyword">on</span> internal  protocol  processing  <span class="hljs-built_in">and</span>  factors  such  <span class="hljs-keyword">as</span><br>              delayed ack timeouts occurring <span class="hljs-built_in">and</span> data transfer.  This option should not <span class="hljs-keyword">be</span> used in code intended <span class="hljs-keyword">to</span> <span class="hljs-keyword">be</span><br>              portable.<br><br></code></pre></td></tr></table></figure>

<p>为了验证我们的猜想，确认 wrk 的行为，我们可以用 strace ，来观察 wrk 为套接字设置了哪些 TCP 选项。</p>
<p>切换到终端二中，执行下面的命令：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ strace -f wrk <span class="hljs-attr">--latency</span> -c <span class="hljs-number">100</span> -t <span class="hljs-number">2</span> <span class="hljs-attr">--timeout</span> <span class="hljs-number">2</span> http:<span class="hljs-comment">//192.168.0.30:8080/</span><br>...<br><span class="hljs-function"><span class="hljs-title">setsockopt</span><span class="hljs-params">(<span class="hljs-number">52</span>, SOL_TCP, TCP_NODELAY, [<span class="hljs-number">1</span>], <span class="hljs-number">4</span>)</span></span> = <span class="hljs-number">0</span><br>...<br><br></code></pre></td></tr></table></figure>

<p>可以看到，wrk 只设置了 TCP_NODELAY 选项，而没有设置 TCP_QUICKACK。这说明 wrk 采用的正是延迟确认，也就解释了上面这个40ms 的问题。</p>
<p>不过，别忘了，这只是客户端的行为，按理来说，Nginx 服务器不应该受到这个行为的影响。那是不是我们分析网络包时，漏掉了什么线索呢？让我们回到 Wireshark 重新观察一下。</p>
<p><img src="https://static001.geekbang.org/resource/image/72/8a/72eb14e8996147a458aa6523110c938a.png?wh=750*268" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>仔细观察 Wireshark 的界面，其中， 1173 号包，就是刚才说到的延迟 ACK 包；下一行的 1175 ，则是 Nginx 发送的第二个分组包，它跟 697 号包组合起来，构成一个完整的 HTTP 响应（ACK 号都是 85）。</p>
<p>第二个分组没跟前一个分组（697 号）一起发送，而是等到客户端对第一个分组的 ACK 后（1173 号）才发送，这看起来跟延迟确认有点像，只不过，这儿不再是 ACK，而是发送数据。</p>
<p>基于这个机制，我们可以怀疑这里用到了Nagle 算法，关于Nagle 算法是 TCP 协议中用于减少小包发送数量的一种优化算法，目的是为了提高实际带宽的利用率。</p>
<p>举个例子，当有效负载只有 1 字节时，再加上 TCP 头部和 IP 头部分别占用的 20 字节，整个网络包就是 41 字节，这样实际带宽的利用率只有 2.4%（1&#x2F;41）。往大了说，如果整个网络带宽都被这种小包占满，那整个网络的有效利用率就太低了。</p>
<p>Nagle 算法正是为了解决这个问题。它通过合并 TCP 小包，提高网络带宽的利用率。Nagle 算法规定，一个 TCP 连接上，最多只能有一个未被确认的未完成分组；在收到这个分组的 ACK 前，不发送其他分组。这些小分组会被组合起来，并在收到 ACK 后，用同一个分组发送出去。</p>
<p>显然，Nagle 算法本身的想法还是挺好的，但是知道 Linux 默认的延迟确认机制后，你应该就不这么想了。因为它们一起使用时，网络延迟会明显。如下图所示：</p>
<p><img src="https://static001.geekbang.org/resource/image/c5/c6/c51439692921cbf67b746a45fded2ec6.png?wh=672*934" srcset="/img/loading.gif" lazyload alt="img"></p>
<ul>
<li><p>当 Sever 发送了第一个分组后，由于 Client 开启了延迟确认，就需要等待 40ms 后才会回复 ACK。</p>
</li>
<li><p>同时，由于 Server 端开启了 Nagle，而这时还没收到第一个分组的 ACK，Server 也会在这里一直等着。</p>
</li>
<li><p>直到 40ms 超时后，Client 才会回复ACK，然后，Server 才会继续发送第二个分组。</p>
</li>
</ul>
<p>既然可能是 Nagle 的问题，那该怎么知道，案例 Nginx 有没有开启 Nagle 呢？</p>
<p>查询 tcp 的文档，只有设置了 TCP_NODELAY 后，Nagle 算法才会禁用。所以，我们只需要查看 Nginx 的 tcp_nodelay 选项就可以了。</p>
<figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">TCP_NODELAY<br>              <span class="hljs-keyword">If</span> <span class="hljs-keyword">set</span>, <span class="hljs-keyword">disable</span> the Nagle algorithm.  This means that segments are <span class="hljs-keyword">always</span> sent <span class="hljs-keyword">as</span> soon <span class="hljs-keyword">as</span> possible, even<br>              <span class="hljs-keyword">if</span> there <span class="hljs-keyword">is</span> <span class="hljs-keyword">only</span> a small amount <span class="hljs-keyword">of</span> data.  <span class="hljs-keyword">When</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">set</span>, data <span class="hljs-keyword">is</span> buffered <span class="hljs-keyword">until</span>  there  <span class="hljs-keyword">is</span>  a  sufficient<br>              amount  <span class="hljs-keyword">to</span>  send <span class="hljs-keyword">out</span>, thereby avoiding the frequent sending <span class="hljs-keyword">of</span> small packets, which results <span class="hljs-keyword">in</span> poor uti‐<br>              lization <span class="hljs-keyword">of</span> the network.  This <span class="hljs-keyword">option</span> <span class="hljs-keyword">is</span> overridden <span class="hljs-keyword">by</span> TCP_CORK; however, setting this <span class="hljs-keyword">option</span> forces  an<br>              explicit flush <span class="hljs-keyword">of</span> pending output, even <span class="hljs-keyword">if</span> TCP_CORK <span class="hljs-keyword">is</span> currently <span class="hljs-keyword">set</span>.<br><br></code></pre></td></tr></table></figure>

<p>我们回到终端一中，执行下面的命令，查看案例 Nginx 的配置:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">docker <span class="hljs-built_in">exec</span> nginx <span class="hljs-built_in">cat</span> /etc/nginx/nginx.conf | grep tcp_nodelay</span><br>    tcp_nodelay    off;<br><br></code></pre></td></tr></table></figure>

<p>果然，可以看到，案例 Nginx 的 tcp_nodelay 是关闭的，将其设置为 on 后再重新进行测试。</p>
<p>接着，切换到终端二，重新执行 wrk 测试延迟：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ wrk --latency -c 100 -t 2 --<span class="hljs-built_in">timeout</span> 2 http://192.168.0.30:8080/<br>Running 10s <span class="hljs-built_in">test</span> @ http://192.168.0.30:8080/<br>  2 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency     9.58ms   14.98ms 350.08ms   97.91%<br>    Req/Sec     6.22k   282.13     6.93k    68.50%<br>  Latency Distribution<br>     50%    7.78ms<br>     75%    8.20ms<br>     90%    9.02ms<br>     99%   73.14ms<br>  123990 requests <span class="hljs-keyword">in</span> 10.01s, 100.50MB <span class="hljs-built_in">read</span><br>Requests/sec:  12384.04<br>Transfer/sec:     10.04MB<br><br></code></pre></td></tr></table></figure>

<p>果然，现在延迟已经缩短成了 9ms，跟我们测试的官方 Nginx 镜像是一样的（Nginx 默认就是开启 tcp_nodelay 的） 。</p>
<p>作为对比，我们用 tcpdump ，抓取优化后的网络包（这儿实际上抓取的是官方 Nginx 监听的 80 端口）。结果如下：</p>
<p><img src="https://static001.geekbang.org/resource/image/b5/ba/b5f1643cdca33f29408881542fca4eba.png?wh=1599*621" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>从图中可以发现，由于 Nginx 不用再等 ACK，536 和 540 两个分组是连续发送的；而客户端呢，虽然仍开启了延迟确认，但这时收到了两个需要回复 ACK 的包，所以也不用等 40ms，可以直接合并回复 ACK。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章讲解了网络延迟增大后的分析方法。网络延迟，是最核心的网络性能指标。由于网络传输、网络包处理等各种因素的影响，网络延迟不可避免。但过大的网络延迟，会直接影响用户的体验。</p>
<p>所以，在发现网络延迟增大后，可以用 traceroute、hping3、tcpdump、Wireshark、strace 等多种工具，来定位网络中的潜在问题。比如，</p>
<ul>
<li><p>使用 hping3 以及 wrk 等工具，确认单次请求和并发请求情况的网络延迟是否正常。</p>
</li>
<li><p>使用 traceroute，确认路由是否正确，并查看路由中每一跳网关的延迟。</p>
</li>
<li><p>使用 tcpdump 和 Wireshark，确认网络包的收发是否正常。</p>
</li>
<li><p>使用 strace 等，观察应用程序对网络套接字的调用情况是否正常。</p>
</li>
</ul>
<p>这样，就可以依次从路由、网络包的收发、再到应用程序等，逐层排查，直到定位问题根源。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/linux/" class="category-chain-item">linux</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%8E%9F%E5%88%9B/">#原创</a>
      
        <a href="/tags/%E7%AC%94%E8%AE%B0/">#笔记</a>
      
        <a href="/tags/linux/">#linux</a>
      
        <a href="/tags/%E7%BD%91%E7%BB%9C/">#网络</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>8.如何排查网络请求延迟变大</div>
      <div>https://blog.longpi1.com/2022/11/12/8-网络请求延迟变大了该怎么办？/</div>
    </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/11/14/9-%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96NAT%E6%80%A7%E8%83%BD%EF%BC%9F%EF%BC%88%E4%B8%8A%EF%BC%89/" title="9.如何优化 NAT 性能？（上）">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">9.如何优化 NAT 性能？（上）</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/11/09/7-%E6%80%8E%E4%B9%88%E7%BC%93%E8%A7%A3DDoS%E6%94%BB%E5%87%BB%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98%EF%BC%9F/" title="7.怎么缓解DDoS攻击带来的性能下降问题？">
                        <span class="hidden-mobile">7.怎么缓解DDoS攻击带来的性能下降问题？</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.4.17/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"UvaCwj6C0pVj9XCWuMtLaBWJ-gzGzoHsz","appKey":"w2xUk9wycItSqrREmRMDYJHY","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <div>lp的个人博客 | 记录成长的过程</div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    

    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
