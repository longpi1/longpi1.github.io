

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/%E5%AD%A6%E6%A0%A1.png">
  <link rel="icon" href="/img/%E5%AD%A6%E6%A0%A1.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="lp">
  <meta name="keywords" content="">
  
    <meta name="description" content="极客时间RPC实战课程笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="RPC实战笔记">
<meta property="og:url" content="https://blog.longpi1.com/2022/08/28/RPC%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="lp&#39;s blog">
<meta property="og:description" content="极客时间RPC实战课程笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/ac/fa/acf53138659f4982bbef02acdd30f1fa.jpg?wh=3846*1377">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/30/fb/30f52b433aa5f103114a8420c6f829fb.jpg?wh=2951*2181">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/a3/a6/a3688580dccd3053fac8c0178cef4ba6.jpg?wh=3084*2183">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/50/be/506e902e06e91663334672c29bfbc2be.jpg?wh=3205*1778">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/c19JKY4lWEjf3y7.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/d2/04/d215d279ef8bfbe84286e81174b4e704.jpg">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/82/59/826a6da653c4093f3dc3f0a833915259.jpg">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/7e/9f/7e2616937e3bc5323faf3ba4c09d739f.jpg">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/b4/a5/b42e44968c3fdcdfe2acf96377f5b2a5.jpg">
<meta property="og:image" content="c:/Users/longp/AppData/Roaming/Typora/typora-user-images/image-20220717151659788.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/51/5d/514dc04df2b8b2f3130b7d44776a825d.jpg?wh=2746*1445">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/3b/18/3b6a23f392b9b8d6fcf31803a5b4ef18.jpg?wh=5273*1884">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/50/75/503fabeeae226a722f83e9fb6c0d4075.jpg?wh=4214*1803">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/9rWbXJjnkFMGdgL.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/73/ff/73b59c7949ebed2903ede474856062ff.jpg?wh=4256*2276">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/OfNVTmrCbYEkohq.png">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/g4dzHEyWfrpRhDK.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/b7/68/b78964a2db3adc8080364e9cfc79ca68.jpg?wh=3900*879">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/23/f7/23f24c545d33ec4d6d72fc10e94a0ff7.jpg?wh=2513*1991">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/78/39/7868289c87ca9de144fe32fac98f8339.jpg?wh=2506*1964">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/vAXShkqrxu8e2pK.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/f4/b8/f48704443b33df17fc490778c00c71b8.jpg?wh=3345*1443">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/5e/1c/5e294378a3d86e7d279507f62fe5ee1c.jpg?wh=4175*1969">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/00/af/00065674063f30c98caaa58bb4cd7baf.jpg?wh=4085*2365">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/32/81/32441dc643e64a022acfcbe0b4c77e81.jpg?wh=5154*1923">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/5e/81/5e5706e6fc02ef0caaee565ea358f281.jpg?wh=5129*2058">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/9b/17/9bae10ba8a5b96b03102fb9ef4f30e17.jpg?wh=2560*1315">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/f8/ad/f8e8a4dd16f2fd2af366f810404057ad.jpg?wh=2563*1313">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/dc/31/dc2a18f1e2c495380cc4053b92ed3131.jpg?wh=2171*1472">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/90/64/903fa4374beb753c1db8f1f8b82ff464.jpg?wh=2642*1990">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/59/87/59b7479220a415ef034fb6edb589ec87.jpg?wh=3788*1350">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/KPjgxwin6sIVuby.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/c8/67/c899c36097fd5e3f70bf031f4b2c2167.jpg?wh=3596*1810">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/a1/50/a15be58b32195422bd5a18dba0e68050.jpg?wh=3195*1277">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/77/cc/7752081ec658f1d56ac4219f1c07fbcc.jpg?wh=3131*2891">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/qUCtZw2Ps7EdYDu.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/e7/d4/e796da8cf26f056479a59fd97b43d0d4.jpg?wh=2558*2523">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/3c/bd/3c84f9cf6745f2d50e34bd8431c84abd.jpg?wh=3374*893">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/HhWuQ9j2KxJ3Ayt.png">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/FZ1Tlig6GQbLCvE.png">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/tT46nkNsdzK9Vmw.png">
<meta property="og:image" content="https://static001.geekbang.org/resource/image/b8/1b/b8fee37688d39ae7913429f6cbc06f1b.jpg?wh=4498*1228">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/ldO1BCDz3xqs7ay.png">
<meta property="og:image" content="https://s2.loli.net/2022/08/28/Cq24cT78wnWaYRz.png">
<meta property="article:published_time" content="2022-08-28T13:02:06.000Z">
<meta property="article:modified_time" content="2022-08-28T13:34:56.710Z">
<meta property="article:author" content="lp">
<meta property="article:tag" content="原创">
<meta property="article:tag" content="RPC">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://static001.geekbang.org/resource/image/ac/fa/acf53138659f4982bbef02acdd30f1fa.jpg?wh=3846*1377">
  
  
  
  <title>RPC实战笔记 - lp&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"blog.longpi1.com","root":"/","version":"1.9.2","typing":{"enable":true,"typeSpeed":30,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"UvaCwj6C0pVj9XCWuMtLaBWJ-gzGzoHsz","app_key":"w2xUk9wycItSqrREmRMDYJHY","server_url":"https://uvacwj6c.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  

  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 6.2.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>lp&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                文章分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于我
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/bg.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="RPC实战笔记"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2022-08-28 21:02" pubdate>
          2022年8月28日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          13k 字
        
      </span>
    

  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>


    <a target="_blank" rel="noopener" href="https://github.com/longpi1"><img loading="lazy" width="149" height="149" src="https://github.blog/wp-content/uploads/2008/12/forkme_left_darkblue_121621.png?resize=149%2C149" srcset="/img/loading.gif" lazyload class="attachment-full size-full" alt="follow me on GitHub" data-recalc-dims="1"></a>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">RPC实战笔记</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="RPC总结"><a href="#RPC总结" class="headerlink" title="RPC总结"></a>RPC总结</h1><h2 id="RPC-的作用"><a href="#RPC-的作用" class="headerlink" title="RPC 的作用"></a>RPC 的作用</h2><ol>
<li><p>屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；</p>
</li>
<li><p>隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。</p>
</li>
</ol>
<h2 id="一个完整的-RPC-会涉及到哪些步骤？"><a href="#一个完整的-RPC-会涉及到哪些步骤？" class="headerlink" title="一个完整的 RPC 会涉及到哪些步骤？"></a>一个完整的 RPC 会涉及到哪些步骤？</h2><p><img src="https://static001.geekbang.org/resource/image/ac/fa/acf53138659f4982bbef02acdd30f1fa.jpg?wh=3846*1377" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="RPC架构"><a href="#RPC架构" class="headerlink" title="RPC架构"></a>RPC架构</h2><p><img src="https://static001.geekbang.org/resource/image/30/fb/30f52b433aa5f103114a8420c6f829fb.jpg?wh=2951*2181" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                      <strong>核心功能体系</strong> </p>
<p><img src="https://static001.geekbang.org/resource/image/a3/a6/a3688580dccd3053fac8c0178cef4ba6.jpg?wh=3084*2183" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                  <strong>插件化体系架构</strong> </p>
<p><strong>插件化体系</strong>整个架构就变成了一个微内核架构，我们将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离并提供接口的默认实现。这样的架构相比之前的架构，有很多优势。首先它的可扩展性很好，实现了开闭原则，用户可以非常方便地通过插件扩展实现自己的功能，而且不需要修改核心功能的本身；其次就是保持了核心包的精简，依赖外部包少，这样可以有效减少开发人员引入 RPC 导致的包版本冲突问题。</p>
<h2 id="RPC应用场景"><a href="#RPC应用场景" class="headerlink" title="RPC应用场景"></a>RPC应用场景</h2><p><img src="https://static001.geekbang.org/resource/image/50/be/506e902e06e91663334672c29bfbc2be.jpg?wh=3205*1778" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="RPC注意点"><a href="#RPC注意点" class="headerlink" title="RPC注意点"></a>RPC注意点</h2><p><img src="https://s2.loli.net/2022/08/28/c19JKY4lWEjf3y7.png" srcset="/img/loading.gif" lazyload alt="image-20220716134042279.png"></p>
<h2 id="RPC协议与HTTP的设计区别"><a href="#RPC协议与HTTP的设计区别" class="headerlink" title="RPC协议与HTTP的设计区别"></a>RPC协议与HTTP的设计区别</h2><p>相对于 HTTP 的用处，RPC 更多的是负责应用间的通信，所以性能要求相对更高。但 HTTP 协议的数据包大小相对请求数据本身要大很多，又需要加入很多无用的内容，比如换行符号、回车符等；还有一个更重要的原因是，HTTP 协议属于无状态协议，客户端无法对请求和响应进行关联，每次请求都需要重新建立连接，响应完成后再关闭连接。因此，对于要求高性能的 RPC 来说，HTTP 协议基本很难满足需求，所以 RPC 会选择设计更紧凑的私有协议。</p>
<h2 id="对象如何在网络中传输"><a href="#对象如何在网络中传输" class="headerlink" title="对象如何在网络中传输"></a>对象如何在网络中传输</h2><h3 id="序列化与反序列化"><a href="#序列化与反序列化" class="headerlink" title="序列化与反序列化"></a>序列化与反序列化</h3><p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是不能直接在网络中传输的，所以我们需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程叫做“序列化”。这时，服务提供方就可以正确地从二进制数据中分割出不同的请求，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象，这个过程称之为“反序列化”。</p>
<p><img src="https://static001.geekbang.org/resource/image/d2/04/d215d279ef8bfbe84286e81174b4e704.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<h3 id="RPC通信流程"><a href="#RPC通信流程" class="headerlink" title="RPC通信流程"></a>RPC通信流程</h3><p><img src="https://static001.geekbang.org/resource/image/82/59/826a6da653c4093f3dc3f0a833915259.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<h3 id="常见的序列化方式"><a href="#常见的序列化方式" class="headerlink" title="常见的序列化方式"></a>常见的序列化方式</h3><p><strong>JDK 原生序列化</strong></p>
<p>JDK序列化过程就是在读取对象数据的时候，不断加入一些特殊分隔符，这些特殊分隔符用于在反序列化过程中截断用。</p>
<p><img src="https://static001.geekbang.org/resource/image/7e/9f/7e2616937e3bc5323faf3ba4c09d739f.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<ul>
<li>头部数据用来声明序列化协议、序列化版本，用于高低版本向后兼容</li>
<li>对象数据主要包括类名、签名、属性名、属性类型及属性值，当然还有开头结尾等数据，除了属性值属于真正的对象值，其他都是为了反序列化用的元数据</li>
<li>存在对象引用、继承的情况下，就是递归遍历“写对象”逻辑</li>
</ul>
<p><strong>JSON序列化</strong></p>
<p><strong>缺点：</strong></p>
<p>JSON 进行序列化的额外空间开销比较大，对于大数据量服务这意味着需要巨大的内存和磁盘开销；JSON 没有类型，但像 Java 这种强类型语言，需要通过反射统一解决，所以性能不会太好。</p>
<p>JSON 没有类型，但像 Java 这种强类型语言，需要通过反射统一解决，所以性能不会太好。</p>
<p>所以如果 RPC 框架选用 JSON 序列化，服务提供者与服务调用者之间传输的数据量要相对较小，否则将严重影响性能。</p>
<p><strong>Hessian序列化</strong></p>
<p>Hessian 是动态类型、二进制、紧凑的，并且可跨语言移植的一种序列化框架。Hessian 协议要比 JDK、JSON 更加紧凑，性能上要比 JDK、JSON 序列化高效很多，而且生成的字节数也更小。</p>
<p><strong>Protobuf序列化</strong></p>
<p>Protobuf 是 Google 公司内部的混合语言数据标准，是一种轻便、高效的结构化数据存储格式，可以用于结构化数据序列化，支持 Java、Python、C++、Go 等语言。Protobuf 使用的时候需要定义 IDL（Interface description language），然后使用不同语言的 IDL 编译器，生成序列化工具类；</p>
<p><strong>优点：</strong></p>
<ul>
<li>序列化后体积相比 JSON、Hessian 小很多；</li>
<li>IDL 能清晰地描述语义，所以足以帮助并保证应用程序之间的类型不会丢失，无需类似 XML 解析器；</li>
<li>序列化反序列化速度很快，不需要通过反射获取类型；</li>
<li>消息格式升级和兼容性不错，可以做到向后兼容。</li>
</ul>
<p><strong>缺点：</strong>对于具有反射和动态能力的语言来说，用起来很费劲</p>
<h4 id="如何选择哪种框架"><a href="#如何选择哪种框架" class="headerlink" title="如何选择哪种框架"></a>如何选择哪种框架</h4><p><img src="https://static001.geekbang.org/resource/image/b4/a5/b42e44968c3fdcdfe2acf96377f5b2a5.jpg" srcset="/img/loading.gif" lazyload alt="img"></p>
<h2 id="RPC-框架在使用时要注意哪些问题？"><a href="#RPC-框架在使用时要注意哪些问题？" class="headerlink" title="RPC 框架在使用时要注意哪些问题？"></a>RPC 框架在使用时要注意哪些问题？</h2><p><strong>对象构造得过于复杂：</strong>属性很多，并且存在多层的嵌套，比如 A 对象关联 B 对象，B 对象又聚合 C 对象，C 对象又关联聚合很多其他对象，对象依赖关系过于复杂。序列化框架在序列化与反序列化对象时，对象越复杂就越浪费性能，消耗 CPU，这会严重影响 RPC 框架整体的性能；另外，对象越复杂，在序列化与反序列化的过程中，出现问题的概率就越高。</p>
<p><strong>对象过于庞大：</strong>我经常遇到业务过来咨询，为啥他们的 RPC 请求经常超时，排查后发现他们的入参对象非常得大，比如为一个大 List 或者大 Map，序列化之后字节长度达到了上兆字节。这种情况同样会严重地浪费了性能、CPU，并且序列化一个如此大的对象是很耗费时间的，这肯定会直接影响到请求的耗时。</p>
<p><strong>使用序列化框架不支持的类作为入参类：</strong>比如 Hessian 框架，不支持 LinkedHashMap、LinkedHashSet 等，而且大多数情况下最好不要使用第三方集合类，如 Guava 中的集合类，很多开源的序列化框架都是优先支持编程语言原生的对象。因此如果入参是集合类，应尽量选用原生的、最为常用的集合类，如 HashMap、ArrayList。</p>
<p><strong>对象有复杂的继承关系：</strong>大多数序列化框架在序列化对象时都会将对象的属性一一进行序列化，当有继承关系时，会不停地寻找父类，遍历属性。就像问题 1 一样，对象关系越复杂，就越浪费性能，同时又很容易出现序列化上的问题。</p>
<p><img src="C:\Users\longp\AppData\Roaming\Typora\typora-user-images\image-20220717151659788.png" srcset="/img/loading.gif" lazyload alt="image-20220717151659788"></p>
<h2 id="RPC主要实现功能"><a href="#RPC主要实现功能" class="headerlink" title="RPC主要实现功能"></a>RPC主要实现功能</h2><h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p><strong>一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）要AP还是CP</strong></p>
<p><img src="https://static001.geekbang.org/resource/image/51/5d/514dc04df2b8b2f3130b7d44776a825d.jpg?wh=2746*1445" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                                          <strong>服务发现原理</strong></p>
<p><strong>服务注册：</strong>在服务提供方启动的时候，将对外暴露的接口注册到注册中心之中，注册中心将这个服务节点的 IP 和接口保存下来。</p>
<p><strong>服务订阅：</strong>在服务调用方启动的时候，去注册中心查找并订阅服务提供方的 IP，然后缓存到本地，并用于后续的远程调用。</p>
<h4 id="为什么不使用-DNS？"><a href="#为什么不使用-DNS？" class="headerlink" title="为什么不使用 DNS？"></a>为什么不使用 DNS？</h4><p><img src="https://static001.geekbang.org/resource/image/3b/18/3b6a23f392b9b8d6fcf31803a5b4ef18.jpg?wh=5273*1884" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                             <strong>DNS查询流程</strong></p>
<p><strong>使用DNS存在的问题：</strong></p>
<ul>
<li>如果这个 IP 端口下线了，服务调用者不能及时摘除服务节点；</li>
<li>如果在之前已经上线了一部分服务节点，这时我突然对这个服务进行扩容，那么新上线的服务节点不能及时接收到流量；</li>
</ul>
<h4 id="基于-ZooKeeper-的服务发现"><a href="#基于-ZooKeeper-的服务发现" class="headerlink" title="基于 ZooKeeper 的服务发现"></a>基于 ZooKeeper 的服务发现</h4><p><img src="https://static001.geekbang.org/resource/image/50/75/503fabeeae226a722f83e9fb6c0d4075.jpg?wh=4214*1803" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><img src="https://s2.loli.net/2022/08/28/9rWbXJjnkFMGdgL.png" srcset="/img/loading.gif" lazyload alt="实践.png"></p>
<h4 id="基于消息总线的最终一致性的注册中心"><a href="#基于消息总线的最终一致性的注册中心" class="headerlink" title="基于消息总线的最终一致性的注册中心"></a>基于消息总线的最终一致性的注册中心</h4><p>ZooKeeper 的一大特点就是强一致性，ZooKeeper 集群的每个节点的数据每次发生更新操作，都会通知其它 ZooKeeper 节点同时执行更新。它要求保证每个节点的数据能够实时的完全一致，这也就直接导致了 ZooKeeper 集群性能上的下降。这就好比几个人在玩传递东西的游戏，必须这一轮每个人都拿到东西之后，所有的人才能开始下一轮，而不是说我只要获得到东西之后，就可以直接进行下一轮了。</p>
<p>而 RPC 框架的服务发现，在服务节点刚上线时，服务调用方是可以容忍在一段时间之后（比如几秒钟之后）发现这个新上线的节点的。毕竟服务节点刚上线之后的几秒内，甚至更长的一段时间内没有接收到请求流量，对整个服务集群是没有什么影响的，<strong>所以我们可以牺牲掉 CP（强制一致性），而选择 AP（最终一致），来换取整个注册中心集群的性能和稳定性。</strong></p>
<p>是否有一种简单、高效，并且最终一致的更新机制，能代替 ZooKeeper 那种数据强一致的数据更新机制呢？</p>
<p>因为要求最终一致性，我们可以考虑采用消息总线机制。注册数据可以全量缓存在每个注册中心内存中，通过消息总线来同步数据。当有一个注册中心节点接收到服务节点注册时，会产生一个消息推送给消息总线，再通过消息总线通知给其它注册中心节点更新数据并进行服务下发，从而达到注册中心间数据最终一致性，具体流程如下图所示：</p>
<p><img src="https://static001.geekbang.org/resource/image/73/ff/73b59c7949ebed2903ede474856062ff.jpg?wh=4256*2276" srcset="/img/loading.gif" lazyload alt="img"></p>
<ul>
<li>当有服务上线，注册中心节点收到注册请求，服务列表数据发生变化，会生成一个消息，推送给消息总线，每个消息都有整体递增的版本。</li>
<li>消息总线会主动推送消息到各个注册中心，同时注册中心也会定时拉取消息。对于获取到消息的在消息回放模块里面回放，只接受大于本地版本号的消息，小于本地版本号的消息直接丢弃，从而实现最终一致性。</li>
<li>消费者订阅可以从注册中心内存拿到指定接口的全部服务实例，并缓存到消费者的内存里面。</li>
<li>采用推拉模式，消费者可以及时地拿到服务实例增量变化情况，并和内存中的缓存数据进行合并。</li>
</ul>
<p>为了性能，采用两级缓存，注册中心和消费者的内存缓存，通过异步推拉模式来确保最终一致性。</p>
<p><img src="https://s2.loli.net/2022/08/28/OfNVTmrCbYEkohq.png" srcset="/img/loading.gif" lazyload alt="image-20220720220716266.png"><br><img src="https://s2.loli.net/2022/08/28/g4dzHEyWfrpRhDK.png" srcset="/img/loading.gif" lazyload alt="image-20220720220817173.png"></p>
<h3 id="健康检测"><a href="#健康检测" class="headerlink" title="健康检测"></a>健康检测</h3><p><strong>Script Check、HTTP Check、TCP Check、TTL Check等</strong></p>
<h4 id="consul做法"><a href="#consul做法" class="headerlink" title="consul做法"></a>consul做法</h4><p><strong>TTL&#x2F;TCP？</strong></p>
<h4 id="etcd做法？"><a href="#etcd做法？" class="headerlink" title="etcd做法？"></a>etcd做法？</h4><p><strong>基于lease租约机制，对注册的服务设置key TTL，定时保持服务的心跳以达到监控健康状态的效果。</strong></p>
<h3 id="路由策略"><a href="#路由策略" class="headerlink" title="路由策略"></a>路由策略</h3><p><img src="https://static001.geekbang.org/resource/image/b7/68/b78964a2db3adc8080364e9cfc79ca68.jpg?wh=3900*879" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                              <strong>调用流程</strong></p>
<p><img src="https://static001.geekbang.org/resource/image/23/f7/23f24c545d33ec4d6d72fc10e94a0ff7.jpg?wh=2513*1991" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                              <strong>IP路由调用拓扑</strong></p>
<h4 id="参数路由："><a href="#参数路由：" class="headerlink" title="参数路由："></a>参数路由：</h4><p><img src="https://static001.geekbang.org/resource/image/78/39/7868289c87ca9de144fe32fac98f8339.jpg?wh=2506*1964" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                 <strong>参数路由调用拓扑</strong></p>
<p>相比 IP 路由，参数路由支持的灰度粒度更小，他为服务提供方应用提供了另外一个服务治理的手段。灰度发布功能是 RPC 路由功能的一个典型应用场景，通过 RPC 路由策略的组合使用可以让服务提供方更加灵活地管理、调用自己的流量，进一步降低上线可能导致的风险。</p>
<h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p><strong>需求：</strong></p>
<p><img src="https://s2.loli.net/2022/08/28/vAXShkqrxu8e2pK.png" srcset="/img/loading.gif" lazyload alt="需求.png"></p>
<h4 id="什么是负载均衡？"><a href="#什么是负载均衡？" class="headerlink" title="什么是负载均衡？"></a>什么是负载均衡？</h4><p>当我们的一个服务节点无法支撑现有的访问量时，我们会部署多个节点，组成一个集群，然后通过负载均衡，将请求分发给这个集群下的每个服务节点，从而达到多个服务节点共同分担请求压力的目的。</p>
<p><img src="https://static001.geekbang.org/resource/image/f4/b8/f48704443b33df17fc490778c00c71b8.jpg?wh=3345*1443" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                    <strong>负载均衡示意图</strong></p>
<p>负载均衡主要分为软负载和硬负载，软负载就是在一台或多台服务器上安装负载均衡的软件，如 LVS、Nginx 等，硬负载就是通过硬件设备来实现的负载均衡，如 F5 服务器等。负载均衡的算法主要有随机法、轮询法、最小连接法等。</p>
<p>刚才介绍的负载均衡主要还是应用在 Web 服务上，Web 服务的域名绑定负载均衡的地址，通过负载均衡将用户的请求分发到一个个后端服务上。</p>
<h4 id="RPC-框架中的负载均衡"><a href="#RPC-框架中的负载均衡" class="headerlink" title="RPC 框架中的负载均衡"></a>RPC 框架中的负载均衡</h4><p><strong>RPC使用传统的负载均衡存在的问题？</strong></p>
<ol>
<li>搭建负载均衡设备或 TCP&#x2F;IP 四层代理，需要额外成本；</li>
<li>请求流量都经过负载均衡设备，多经过一次网络传输，会额外浪费一些性能；</li>
<li>负载均衡添加节点和摘除节点，一般都要手动添加，当大批量扩容和下线时，会有大量的人工操作，“服务发现”在操作上是个问题；</li>
<li>我们在服务治理的时候，针对不同接口服务、服务的不同分组，我们的负载均衡策略是需要可配的，如果大家都经过这一个负载均衡设备，就不容易根据不同的场景来配置不同的负载均衡策略了。</li>
</ol>
<p>RPC 的负载均衡完全由 RPC 框架自身实现，RPC 的服务调用者会与“注册中心”下发的所有服务节点建立长连接，在每次发起 RPC 调用时，服务调用者都会通过配置的负载均衡插件，自主选择一个服务节点，发起 RPC 调用请求。</p>
<p><img src="https://static001.geekbang.org/resource/image/5e/1c/5e294378a3d86e7d279507f62fe5ee1c.jpg?wh=4175*1969" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                      RPC框架负载均衡示意图</p>
<p>RPC 负载均衡策略一般包括随机权重、Hash、轮询。当然，这还是主要看 RPC 框架自身的实现。其中的随机权重策略应该是我们最常用的一种了，通过随机算法，我们基本可以保证每个节点接收到的请求流量是均匀的；同时我们还可以通过控制节点权重的方式，来进行流量控制。比如我们默认每个节点的权重都是 100，但当我们把其中的一个节点的权重设置成 50 时，它接收到的流量就是其他节点的 1&#x2F;2。</p>
<h4 id="如何设计自适应的负载均衡？"><a href="#如何设计自适应的负载均衡？" class="headerlink" title="如何设计自适应的负载均衡？"></a>如何设计自适应的负载均衡？</h4><p>RPC 的负载均衡完全由 RPC 框架自身实现，服务调用者发起请求时，会通过配置的负载均衡插件，自主地选择服务节点。那是不是只要调用者知道每个服务节点处理请求的能力，再根据服务处理节点处理请求的能力来判断要打给它多少流量就可以了？当一个服务节点负载过高或响应过慢时，就少给它发送请求，反之则多给它发送请求。这就有点像日常工作中的分配任务，要多考虑实际情况。当一位下属身体欠佳，就少给他些工作；若刚好另一位下属状态很好，手头工作又不是很多，就多分给他一点。</p>
<h5 id="服务调用者节点该如何判定一个服务节点的处理能力呢？"><a href="#服务调用者节点该如何判定一个服务节点的处理能力呢？" class="headerlink" title="服务调用者节点该如何判定一个服务节点的处理能力呢？"></a>服务调用者节点该如何判定一个服务节点的处理能力呢？</h5><p>采用一种打分的策略，服务调用者收集与之建立长连接的每个服务节点的指标数据，如服务节点的负载指标、CPU 核数、内存大小、请求处理的耗时指标（如请求平均耗时、TP99、TP999）、服务节点的状态指标（如正常、亚健康）。通过这些指标，计算出一个分数，比如总分 10 分，如果 CPU 负载达到 70%，就减它 3 分，当然了，减 3 分只是个类比，需要减多少分是需要一个计算策略的。</p>
<h5 id="该如果根据这些指标来打分呢？"><a href="#该如果根据这些指标来打分呢？" class="headerlink" title="该如果根据这些指标来打分呢？"></a>该如果根据这些指标来打分呢？</h5><p>这就有点像公司对员工进行年终考核。假设我是老板，我要考核专业能力、沟通能力和工作态度，这三项的占比分别是 30%、30%、40%，我给一个员工的评分是 10、8、8，那他的综合分数就是这样计算的：10<em>30%+8</em>30%+8*40%&#x3D;8.6 分。给服务节点打分也一样，我们可以为每个指标都设置一个指标权重占比，然后再根据这些指标数据，计算分数。</p>
<h5 id="服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？"><a href="#服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？" class="headerlink" title="服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？"></a>服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？</h5><p>我们可以配合随机权重的负载均衡策略去控制，通过最终的指标分数修改服务节点最终的权重。例如给一个服务节点综合打分是 8 分（满分 10 分），服务节点的权重是 100，那么计算后最终权重就是 80（100*80%）。服务调用者发送请求时，会通过随机权重的策略来选择服务节点，那么这个节点接收到的流量就是其他正常节点的 80%（这里假设其他节点默认权重都是 100，且指标正常，打分为 10 分的情况）。</p>
<p>整体的设计方案如下图所示：</p>
<p><img src="https://static001.geekbang.org/resource/image/00/af/00065674063f30c98caaa58bb4cd7baf.jpg?wh=4085*2365" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                      <strong>RPC自适应负载均衡示意图</strong></p>
<p><strong>关键步骤：</strong></p>
<ol>
<li>添加服务指标收集器，并将其作为插件，默认有运行时状态指标收集器、请求耗时指标收集器。</li>
<li>运行时状态指标收集器收集服务节点 CPU 核数、CPU 负载以及内存等指标，在服务调用者与服务提供者的心跳数据中获取。</li>
<li>请求耗时指标收集器收集请求耗时数据，如平均耗时、TP99、TP999 等。</li>
<li>可以配置开启哪些指标收集器，并设置这些参考指标的指标权重，再根据指标数据和指标权重来综合打分。</li>
<li>通过服务节点的综合打分与节点的权重，最终计算出节点的最终权重，之后服务调用者会根据随机权重的策略，来选择服务节点。</li>
</ol>
<p><strong>RPC 框架的负载均衡与 Web 服务的负载均衡的不同之处在于：</strong></p>
<p>RPC 框架并不是依赖一个负载均衡设备或者负载均衡服务器来实现负载均衡的，而是由 RPC 框架本身实现的，服务调用者可以自主选择服务节点，发起服务调用。这样的好处是，RPC 框架不再需要依赖专门的负载均衡设备，可以节约成本；还减少了与负载均衡设备间额外的网络传输，提升了传输效率；并且均衡策略可配，便于服务治理。</p>
<h3 id="异常重试与熔断限流"><a href="#异常重试与熔断限流" class="headerlink" title="异常重试与熔断限流"></a>异常重试与熔断限流</h3><h4 id="RPC重试机制"><a href="#RPC重试机制" class="headerlink" title="RPC重试机制"></a>RPC重试机制</h4><p><img src="https://static001.geekbang.org/resource/image/32/81/32441dc643e64a022acfcbe0b4c77e81.jpg?wh=5154*1923" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                       <strong>RPC异常重试流程</strong></p>
<p>调用端发起的请求失败时，RPC 框架自身可以进行重试，再重新发送请求，用户可以自行设置是否开启重试以及重试的次数。</p>
<p>调用端在发起 RPC 调用时，会经过负载均衡，选择一个节点，之后它会向这个节点发送请求信息。当消息发送失败或收到异常消息时，我们就可以捕获异常，根据异常触发重试，重新通过负载均衡选择一个节点发送请求消息，并且记录请求的重试次数，当重试次数达到用户配置的重试次数的时候，就返回给调用端动态代理一个失败异常，否则就一直重试下去。</p>
<p>RPC 框架的重试机制就是调用端发现请求失败时捕获异常，之后触发重试，那是不是所有的异常都要触发重试呢？当然不是了，因为这个异常可能是服务提供方抛回来的业务异常，它是应该正常返回给动态代理的，所以我们要在触发重试之前对捕获的异常进行判定，只有符合重试条件的异常才能触发重试，比如网络超时异常、网络连接异常等等。</p>
<p><strong>异常重试需要注意的问题：</strong></p>
<p>当网络突然抖动了一下导致请求超时了，但这个时候调用方的请求信息可能已经发送到服务提供方的节点上，也可能已经发送到服务提供方的服务节点上，那如果请求信息成功地发送到了服务节点上，那这个节点是不是就要执行业务逻辑了呢？是的。</p>
<p>如果该业务不是幂等，比如插入数据操作，那触发重试的话会不会引发问题呢？会的。</p>
<h4 id="如何在约定时间内安全可靠地重试？"><a href="#如何在约定时间内安全可靠地重试？" class="headerlink" title="如何在约定时间内安全可靠地重试？"></a>如何在约定时间内安全可靠地重试？</h4><p>RPC 框架是不会知道哪些业务异常能够去进行异常重试的，我们可以加个重试异常的白名单，用户可以将允许重试的异常加入到这个白名单中。当调用端发起调用，并且配置了异常重试策略，捕获到异常之后，我们就可以采用这样的异常处理策略。如果这个异常是 RPC 框架允许重试的异常，或者这个异常类型存在于可重试异常的白名单中，我们就允许对这个请求进行重试。</p>
<p><img src="https://static001.geekbang.org/resource/image/5e/81/5e5706e6fc02ef0caaee565ea358f281.jpg?wh=5129*2058" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                 <strong>可靠的异常重试机制</strong></p>
<h4 id="为什么需要自我保护"><a href="#为什么需要自我保护" class="headerlink" title="为什么需要自我保护"></a>为什么需要自我保护</h4><p>RPC 是解决分布式系统通信问题的一大利器，而分布式系统的一大特点就是高并发，所以说 RPC 也会面临高并发的场景。在这样的情况下，我们提供服务的每个服务节点就都可能由于访问量过大而引起一系列的问题，比如业务处理耗时过长、CPU 飘高、频繁 Full GC 以及服务进程直接宕机等等。但是在生产环境中，我们要保证服务的稳定性和高可用性，这时我们就需要业务进行自我保护，从而保证在高访问量、高并发的场景下，应用系统依然稳定，服务依然高可用。</p>
<h5 id="那么在使用-RPC-时，业务又如何实现自我保护呢？"><a href="#那么在使用-RPC-时，业务又如何实现自我保护呢？" class="headerlink" title="那么在使用 RPC 时，业务又如何实现自我保护呢？"></a>那么在使用 RPC 时，业务又如何实现自我保护呢？</h5><p>最常见的方式就是限流了，简单有效，但 RPC 框架的自我保护方式可不只有限流，并且 RPC 框架的限流方式可以是多种多样的。我们可以将 RPC 框架拆开来分析，RPC 调用包括服务端和调用端，调用端向服务端发起调用。下面分享一下服务端与调用端分别是如何进行自我保护的。</p>
<h4 id="服务端的自我保护"><a href="#服务端的自我保护" class="headerlink" title="服务端的自我保护"></a>服务端的自我保护</h4><p>举个例子，假如我们要发布一个 RPC 服务，作为服务端接收调用端发送过来的请求，这时服务端的某个节点负载压力过高了，我们该如何保护这个节点？</p>
<p><img src="https://static001.geekbang.org/resource/image/9b/17/9bae10ba8a5b96b03102fb9ef4f30e17.jpg?wh=2560*1315" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>那么就是限流吧？是的，<strong>在 RPC 调用中服务端的自我保护策略就是限流</strong>，那你有没有想过我们是如何实现限流的呢？是在服务端的业务逻辑中做限流吗？有没有更优雅的方式？</p>
<p>限流是一个比较通用的功能，我们可以在 RPC 框架中集成限流的功能，让使用方自己去配置限流阈值；我们还可以在服务端添加限流逻辑，当调用端发送请求过来时，服务端在执行业务逻辑之前先执行限流逻辑，如果发现访问量过大并且超出了限流的阈值，就让服务端直接抛回给调用端一个限流异常，否则就执行正常的业务逻辑。                                                </p>
<p><img src="https://static001.geekbang.org/resource/image/f8/ad/f8e8a4dd16f2fd2af366f810404057ad.jpg?wh=2563*1313" srcset="/img/loading.gif" lazyload alt="img">                 </p>
<h5 id="服务端的限流逻辑该如何实现呢？"><a href="#服务端的限流逻辑该如何实现呢？" class="headerlink" title="服务端的限流逻辑该如何实现呢？"></a>服务端的限流逻辑该如何实现呢？</h5><p>计数器，平滑限流的滑动窗口、漏斗算法以及令牌桶算法等等</p>
<h4 id="调用端的自我保护"><a href="#调用端的自我保护" class="headerlink" title="调用端的自我保护"></a>调用端的自我保护</h4><p>举个例子，假如发布一个服务 B，而服务 B 又依赖服务 C，当一个服务 A 来调用服务 B 时，服务 B 的业务逻辑调用服务 C，而这时服务 C 响应超时了，由于服务 B 依赖服务 C，C 超时直接导致 B 的业务逻辑一直等待，而这个时候服务 A 在频繁地调用服务 B，服务 B 就可能会因为堆积大量的请求而导致服务宕机。</p>
<p><img src="https://static001.geekbang.org/resource/image/dc/31/dc2a18f1e2c495380cc4053b92ed3131.jpg?wh=2171*1472" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>由此可见，服务 B 调用服务 C，服务 C 执行业务逻辑出现异常时，会影响到服务 B，甚至可能会引起服务 B 宕机。这还只是 A-&gt;B-&gt;C 的情况，试想一下 A-&gt;B-&gt;C-&gt;D-&gt;……呢？在整个调用链中，只要中间有一个服务出现问题，都可能会引起上游的所有服务出现一系列的问题，甚至会引起整个调用链的服务都宕机，这是非常恐怖的。</p>
<p>所以说，在一个服务作为调用端调用另外一个服务时，为了防止被调用的服务出现问题而影响到作为调用端的这个服务，这个服务也需要进行自我保护。<strong>而最有效的自我保护方式就是熔断。</strong></p>
<p><strong>熔断机制:</strong></p>
<p><img src="https://static001.geekbang.org/resource/image/90/64/903fa4374beb753c1db8f1f8b82ff464.jpg?wh=2642*1990" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><strong>熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换</strong>。</p>
<ol>
<li>在正常情况下，熔断器是关闭的；</li>
<li>当调用端调用下游服务出现异常时，熔断器会收集异常指标信息进行计算，当达到熔断条件时熔断器打开，这时调用端再发起请求是会直接被熔断器拦截，并快速地执行失败逻辑；</li>
<li>当熔断器打开一段时间后，会转为半打开状态，这时熔断器允许调用端发送一个请求给服务端，如果这次请求能够正常地得到服务端的响应，则将状态置为关闭状态，否则设置为打开。</li>
</ol>
<h5 id="在-RPC-框架中，该如何整合熔断器呢？"><a href="#在-RPC-框架中，该如何整合熔断器呢？" class="headerlink" title="在 RPC 框架中，该如何整合熔断器呢？"></a>在 RPC 框架中，该如何整合熔断器呢？</h5><p>熔断机制主要是保护调用端，调用端在发出请求的时候会先经过熔断器。我们可以回想下 RPC 的调用流程：</p>
<p><img src="https://static001.geekbang.org/resource/image/59/87/59b7479220a415ef034fb6edb589ec87.jpg?wh=3788*1350" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><strong>哪个步骤整合熔断器会比较合适呢？</strong></p>
<p>动态代理，因为在 RPC 调用的流程中，动态代理是 RPC 调用的第一个关口。在发出请求时先经过熔断器，如果状态是闭合则正常发出请求，如果状态是打开则执行熔断器的失败策略。</p>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><h5 id="RPC-框架是如何实现业务的自我保护？"><a href="#RPC-框架是如何实现业务的自我保护？" class="headerlink" title="RPC 框架是如何实现业务的自我保护？"></a>RPC 框架是如何实现业务的自我保护？</h5><p><strong>服务端主要是通过限流来进行自我保护</strong>，我们在实现限流时要考虑到应用和 IP 级别，方便我们在服务治理的时候，对部分访问量特别大的应用进行合理的限流；服务端的限流阈值配置都是作用于单机的，而在有些场景下，例如对整个服务设置限流阈值，服务进行扩容时，限流的配置并不方便，我们可以在注册中心或配置中心下发限流阈值配置的时候，将总服务节点数也下发给服务节点，让 RPC 框架自己去计算限流阈值；我们还可以让 RPC 框架的限流模块依赖一个专门的限流服务，对服务设置限流阈值进行精准地控制，但是这种方式依赖了限流服务，相比单机的限流方式，在性能和耗时上有劣势。</p>
<p><strong>调用端可以通过熔断机制进行自我保护</strong>，防止调用下游服务出现异常，或者耗时过长影响调用端的业务逻辑，RPC 框架可以在动态代理的逻辑中去整合熔断器，实现 RPC 框架的熔断功能。</p>
<h5 id="服务保护一般就是限流、熔断、降级。"><a href="#服务保护一般就是限流、熔断、降级。" class="headerlink" title="服务保护一般就是限流、熔断、降级。"></a>服务保护一般就是限流、熔断、降级。</h5><p> 限流的落地方式有：Guava RateLimiter、lua+Redis、Sentinel等； 熔断：Hystrix、Resilience4j； 降级：服务降级，就是对不怎么重要的服务进行低优先级的处理。说白了，就是尽可能的把系统资源让给优先级高的服务。资源有限，而请求是无限的。</p>
<h4 id="业务分组"><a href="#业务分组" class="headerlink" title="业务分组"></a>业务分组</h4><p>通过分组的方式人为地给不同的调用方划分出不同的小集群，从而实现调用方流量隔离的效果，保障我们的核心业务不受非核心业务的干扰。但我们在考虑问题的时候，不能顾此失彼，不能因为新加一个的功能而影响到原有系统的稳定性。</p>
<h4 id="实践案例："><a href="#实践案例：" class="headerlink" title="实践案例："></a>实践案例：</h4><p><img src="https://s2.loli.net/2022/08/28/KPjgxwin6sIVuby.png" srcset="/img/loading.gif" lazyload alt="实现.png"></p>
<h3 id="RPC服务重启的关闭与开启"><a href="#RPC服务重启的关闭与开启" class="headerlink" title="RPC服务重启的关闭与开启"></a>RPC服务重启的关闭与开启</h3><h4 id="在重启服务的过程中，RPC-怎么做到让调用方系统不出问题呢？"><a href="#在重启服务的过程中，RPC-怎么做到让调用方系统不出问题呢？" class="headerlink" title="在重启服务的过程中，RPC 怎么做到让调用方系统不出问题呢？"></a>在重启服务的过程中，RPC 怎么做到让调用方系统不出问题呢？</h4><p>简述下上线的大概流程：当服务提供方要上线的时候，一般是通过部署系统完成实例重启。在这个过程中，服务提供方的团队并不会事先告诉调用方他们需要操作哪些机器，从而让调用方去事先切走流量。而对调用方来说，它也无法预测到服务提供方要对哪些机器重启上线，因此负载均衡就有可能把要正在重启的机器选出来，这样就会导致把请求发送到正在重启中的机器里面，从而导致调用方不能拿到正确的响应结果。</p>
<p><img src="https://static001.geekbang.org/resource/image/c8/67/c899c36097fd5e3f70bf031f4b2c2167.jpg?wh=3596*1810" srcset="/img/loading.gif" lazyload alt="img"></p>
<p><strong>在服务重启的时候，对于调用方来说，这时候可能会存在以下几种情况：</strong></p>
<ul>
<li>调用方发请求前，目标服务已经下线。对于调用方来说，跟目标节点的连接会断开，这时候调用方可以立马感知到，并且在其健康列表里面会把这个节点挪掉，自然也就不会被负载均衡选中。</li>
<li>调用方发请求的时候，目标服务正在关闭，但调用方并不知道它正在关闭，而且两者之间的连接也没断开，所以这个节点还会存在健康列表里面，因此该节点就有一定概率会被负载均衡选中。</li>
</ul>
<h4 id="关闭流程"><a href="#关闭流程" class="headerlink" title="关闭流程"></a>关闭流程</h4><p><strong>通常的关闭流程：</strong></p>
<p><img src="https://static001.geekbang.org/resource/image/a1/50/a15be58b32195422bd5a18dba0e68050.jpg?wh=3195*1277" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>如上图所示，整个关闭过程中依赖了两次 RPC 调用，一次是服务提供方通知注册中心下线操作，一次是注册中心通知服务调用方下线节点操作。注册中心通知服务调用方都是异步的，我们在“服务发现”一讲中讲过在大规模集群里面，服务发现只保证最终一致性，并不保证实时性，所以注册中心在收到服务提供方下线的时候，并不能成功保证把这次要下线的节点推送到所有的调用方。</p>
<p>所以这么来看，通过服务发现并不能做到应用无损关闭。不能强依赖“服务发现”来通知调用方要下线的机器，那服务提供方自己来通知行不行？因为在 RPC 里面调用方跟服务提供方之间是长连接，我们可以在提供方应用内存里面维护一份调用方连接集合，当服务要关闭的时候，挨个去通知调用方去下线这台机器。这样整个调用链路就变短了，对于每个调用方来说就一次 RPC，可以确保调用的成功率很高。大部分场景下，这么做确实没有问题，我们之前也是这么实现的，但是我们发现线上还是会偶尔会出现，因为服务提供方上线而导致调用失败的问题。</p>
<h4 id="优雅关闭"><a href="#优雅关闭" class="headerlink" title="优雅关闭"></a>优雅关闭</h4><p>因为服务提供方已经开始进入关闭流程，那么很多对象就可能已经被销毁了，关闭后再收到的请求按照正常业务请求来处理，肯定是没法保证能处理的。所以我们可以在关闭的时候，设置一个请求“挡板”，挡板的作用就是告诉调用方，我已经开始进入关闭流程了，我不能再处理你这个请求了。</p>
<p><strong>举例：</strong>如果大家经常去银行办理业务，就会很熟悉这个流程。在交接班或者有其他要事情处理的时候，银行柜台工作人员会拿出一个纸板，放在窗口前，上面写到“该窗口已关闭”。在该窗口排队的人虽然有一万个不愿意，也只能换到其它窗口办理业务，因为柜台工作人员会把当前正在办理的业务处理完后正式关闭窗口。</p>
<p>基于这个思路，我们可以这么处理：当服务提供方正在关闭，如果这之后还收到了新的业务请求，服务提供方直接返回一个特定的异常给调用方（比如 ShutdownException）。这个异常就是告诉调用方“我已经收到这个请求了，但是我正在关闭，并没有处理这个请求”，然后调用方收到这个异常响应后，RPC 框架把这个节点从健康列表挪出，并把请求自动重试到其他节点，因为这个请求是没有被服务提供方处理过，所以可以安全地重试到其他节点，这样就可以实现对业务无损。</p>
<p>但如果只是靠等待被动调用，就会让这个关闭过程整体有点漫长。因为有的调用方那个时刻没有业务请求，就不能及时地通知调用方了，所以我们可以加上主动通知流程，这样既可以保证实时性，也可以避免通知失败的情况。</p>
<p><strong>怎么捕获到关闭事件呢？</strong></p>
<p>通过捕获操作系统的进程信号来获取，在 Java 语言里面，对应的是 Runtime.addShutdownHook 方法，可以注册关闭的钩子。在 RPC 启动的时候，我们提前注册关闭钩子，并在里面添加了两个处理程序，一个负责开启关闭标识，一个负责安全关闭服务对象，服务对象在关闭的时候会通知调用方下线节点。同时需要在我们调用链里面加上挡板处理器，当新的请求来的时候，会判断关闭标识，如果正在关闭，则抛出特定异常。</p>
<p><strong>关闭过程中已经在处理的请求会不会受到影响呢？</strong></p>
<p>如果进程结束过快会造成这些请求还没有来得及应答，同时调用方会也会抛出异常。为了尽可能地完成正在处理的请求，首先我们要把这些请求识别出来。</p>
<p>这就好比日常生活中，我们经常看见停车场指示牌上提示还有多少剩余车位，这个是如何做到的呢？如果仔细观察一下，你就会发现它是每进入一辆车，剩余车位就减一，每出来一辆车，剩余车位就加一。我们也可以利用这个原理在服务对象加上引用计数器，每开始处理请求之前加一，完成请求处理减一，通过该计数器我们就可以快速判断是否有正在处理的请求。</p>
<p>服务对象在关闭过程中，会拒绝新的请求，同时根据引用计数器等待正在处理的请求全部结束之后才会真正关闭。但考虑到有些业务请求可能处理时间长，或者存在被挂住的情况，为了避免一直等待造成应用无法正常退出，我们可以在整个 ShutdownHook 里面，加上超时时间控制，当超过了指定时间没有结束，则强制退出应用。超时时间我建议可以设定成 10s，基本可以确保请求都处理完了。整个流程如下图所示。</p>
<p><img src="https://static001.geekbang.org/resource/image/77/cc/7752081ec658f1d56ac4219f1c07fbcc.jpg?wh=3131*2891" srcset="/img/loading.gif" lazyload alt="img"></p>
<h4 id="关闭总结"><a href="#关闭总结" class="headerlink" title="关闭总结"></a>关闭总结</h4><p>在 RPC 里面，关闭虽然看似不属于 RPC 主流程，但如果我们不能处理得很好的话，可能就会导致调用方业务异常，从而需要我们加入很多额外的运维工作。一个好的关闭流程，可以确保使用我们框架的业务实现平滑的上下线，而不用担心重启导致的问题。</p>
<p>“优雅关闭”这个概念除了在 RPC 里面有，在很多框架里面也都挺常见的，比如像我们经常用的应用容器框架 Tomcat。Tomcat 关闭的时候也是先从外层到里层逐层进行关闭，先保证不接收新请求，然后再处理关闭前收到的请求。</p>
<h5 id="相关解释："><a href="#相关解释：" class="headerlink" title="相关解释："></a>相关解释：</h5><p><img src="https://s2.loli.net/2022/08/28/qUCtZw2Ps7EdYDu.png" srcset="/img/loading.gif" lazyload alt="image-20220723212313198.png"></p>
<h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><h5 id="启动预热"><a href="#启动预热" class="headerlink" title="启动预热"></a>启动预热</h5><p>让刚启动的服务提供方应用不承担全部的流量，而是让它被调用的次数随着时间的移动慢慢增加，最终让流量缓和地增加到跟已经运行一段时间后的水平一样。</p>
<p><strong>实现：</strong>我们可以先简单地回顾下调用方发起的 RPC 调用流程是怎样的，调用方应用通过服务发现能够获取到服务提供方的 IP 地址，然后每次发送请求前，都需要通过负载均衡算法从连接池中选择一个可用连接。那这样的话，我们是不是就可以让负载均衡在选择连接的时候，区分一下是否是刚启动不久的应用？对于刚启动的应用，我们可以让它被选择到的概率特别低，但这个概率会随着时间的推移慢慢变大，从而实现一个动态增加流量的过程。</p>
<p>当服务提供方运行时长小于预热时间时，对服务提供方进行降权，减少被负载均衡选择的概率，避免让应用在启动之初就处于高负载状态，从而实现服务提供方在启动后有一个预热的过程。</p>
<p><img src="https://static001.geekbang.org/resource/image/e7/d4/e796da8cf26f056479a59fd97b43d0d4.jpg?wh=2558*2523" srcset="/img/loading.gif" lazyload alt="img"></p>
<p>​                                                                                                                   <strong>预热过程图</strong></p>
<p>启动预热更多是从调用方的角度出发，去解决服务提供方应用冷启动的问题，让调用方的请求量通过一个时间窗口过渡，慢慢达到一个正常水平，从而实现平滑上线。但对于服务提供方本身来说，有没有相关方案可以实现这种效果呢？</p>
<h5 id="延迟暴露"><a href="#延迟暴露" class="headerlink" title="延迟暴露"></a>延迟暴露</h5><p>举例：spring应用启动的时候都是通过 main 入口，然后顺序加载各种相关依赖的类。以 Spring 应用启动为例，在加载的过程中，Spring 容器会顺序加载 Spring Bean，如果某个 Bean 是 RPC 服务的话，我们不光要把它注册到 Spring-BeanFactory 里面去，还要把这个 Bean 对应的接口注册到注册中心。注册中心在收到新上线的服务提供方地址的时候，会把这个地址推送到调用方应用内存中；当调用方收到这个服务提供方地址的时候，就会去建立连接发请求。</p>
<p>但这时候可能存在服务提供方并没有启动完成的情况？因为服务提供方应用可能还在加载其它的 Bean。对于调用方来说，只要获取到了服务提供方的 IP，就有可能发起 RPC 调用，但如果这时候服务提供方没有启动完成的话，就会导致调用失败，从而使业务受损。</p>
<p>解决方案：</p>
<ul>
<li><p>在应用启动加载、解析 Bean 的时候，如果遇到了 RPC 服务的 Bean，只先把这个 Bean 注册到 Spring-BeanFactory 里面去，而并不把这个 Bean 对应的接口注册到注册中心，只有等应用启动完成后，才把接口注册到注册中心用于服务发现，从而实现让服务调用方延迟获取到服务提供方地址。这样是可以保证应用在启动完后才开始接入流量的，但其实这样做，我们还是没有实现最开始的目标。因为这时候应用虽然启动完成了，但并没有执行相关的业务代码，所以 JVM 内存里面还是冷的。如果这时候大量请求过来，还是会导致整个应用在高负载模式下运行，从而导致不能及时地返回请求结果。而且在实际业务中，一个服务的内部业务逻辑一般会依赖其它资源的，比如缓存数据。如果我们能在服务正式提供服务前，先完成缓存的初始化操作，而不是等请求来了之后才去加载，我们就可以降低重启后第一次请求出错的概率。</p>
</li>
<li><p>利用服务提供方把接口注册到注册中心的那段时间。我们可以在服务提供方应用启动后，接口注册到注册中心前，预留一个 Hook 过程，让用户可以实现可扩展的 Hook 逻辑。用户可以在 Hook 里面模拟调用逻辑，从而使 JVM 指令能够预热起来，并且用户也可以在 Hook 里面事先预加载一些资源，只有等所有的资源都加载完成后，最后才把接口注册到注册中心。整个应用启动过程如下图所示：</p>
<p><img src="https://static001.geekbang.org/resource/image/3c/bd/3c84f9cf6745f2d50e34bd8431c84abd.jpg?wh=3374*893" srcset="/img/loading.gif" lazyload alt="img"></p>
</li>
</ul>
<p>​                                                                                                                <strong>启动顺序图</strong></p>
<h5 id="相关解释：-1"><a href="#相关解释：-1" class="headerlink" title="相关解释："></a>相关解释：</h5><p><img src="https://s2.loli.net/2022/08/28/HhWuQ9j2KxJ3Ayt.png" srcset="/img/loading.gif" lazyload alt="image-20220723225147106.png"></p>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><img src="https://s2.loli.net/2022/08/28/FZ1Tlig6GQbLCvE.png" srcset="/img/loading.gif" lazyload alt="image-20220724150651258.png"></p>
<p><img src="https://s2.loli.net/2022/08/28/tT46nkNsdzK9Vmw.png" srcset="/img/loading.gif" lazyload alt="image-20220724150622961.png"></p>
<h4 id="分布式场景中如何做到快速定位RPC相关问题？"><a href="#分布式场景中如何做到快速定位RPC相关问题？" class="headerlink" title="分布式场景中如何做到快速定位RPC相关问题？"></a>分布式场景中如何做到快速定位RPC相关问题？</h4><p>在分布式的生产环境中，比如下面这个场景：我们搭建了一个分布式的应用系统，在这个应用系统中，我启动了 4 个子服务，分别是服务 A、服务 B、服务 C 与服务 D，而这 4 个服务的依赖关系是 A-&gt;B-&gt;C-&gt;D，而这些服务又都部署在不同的机器上。在 RPC 调用中，如果服务端的业务逻辑出现了异常，就会把异常抛回给调用端，那么如果现在这个调用链中有一个服务出现了异常，我们该如何定位问题呢？</p>
<h5 id="方法-1：借助合理封装的异常信息"><a href="#方法-1：借助合理封装的异常信息" class="headerlink" title="方法 1：借助合理封装的异常信息"></a>方法 1：借助合理封装的异常信息</h5><p><img src="https://static001.geekbang.org/resource/image/b8/1b/b8fee37688d39ae7913429f6cbc06f1b.jpg?wh=4498*1228" srcset="/img/loading.gif" lazyload alt="img"></p>
<h5 id="方法-2：借助分布式链路跟踪"><a href="#方法-2：借助分布式链路跟踪" class="headerlink" title="方法 2：借助分布式链路跟踪"></a>方法 2：借助分布式链路跟踪</h5><p><img src="https://s2.loli.net/2022/08/28/ldO1BCDz3xqs7ay.png" srcset="/img/loading.gif" lazyload alt="image-20220724163935463.png"></p>
<h4 id="流量回放"><a href="#流量回放" class="headerlink" title="流量回放"></a>流量回放</h4><p><img src="https://s2.loli.net/2022/08/28/Cq24cT78wnWaYRz.png" srcset="/img/loading.gif" lazyload alt="image-20220724170611177.png"></p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/RPC/" class="category-chain-item">RPC</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%8E%9F%E5%88%9B/">#原创</a>
      
        <a href="/tags/RPC/">#RPC</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>RPC实战笔记</div>
      <div>https://blog.longpi1.com/2022/08/28/RPC实战笔记/</div>
    </div>
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/08/28/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/" title="分布式系统笔记">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">分布式系统笔记</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/08/27/Golang%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/" title="Golang内存分配和垃圾回收">
                        <span class="hidden-mobile">Golang内存分配和垃圾回收</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  <article id="comments" lazyload>
    
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.4.17/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"UvaCwj6C0pVj9XCWuMtLaBWJ-gzGzoHsz","appKey":"w2xUk9wycItSqrREmRMDYJHY","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"zh-CN","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


  </article>


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <div>lp的个人博客 | 记录成长的过程</div> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        总访问量 
        <span id="leancloud-site-pv"></span>
         次
      </span>
    

    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      headingSelector : CONFIG.toc.headingSelector || 'h1,h2,h3,h4,h5,h6',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      collapseDepth   : CONFIG.toc.collapseDepth || 0,
      scrollSmooth    : true,
      headingsOffset  : -boardTop
    });
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.10/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
