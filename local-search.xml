<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Golang内存分配与内存逃逸</title>
    <link href="/2022/09/20/Go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/"/>
    <url>/2022/09/20/Go%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E5%86%85%E5%AD%98%E9%80%83%E9%80%B8/</url>
    
    <content type="html"><![CDATA[<h1 id="Go内存分配与内存逃逸"><a href="#Go内存分配与内存逃逸" class="headerlink" title="Go内存分配与内存逃逸"></a>Go内存分配与内存逃逸</h1><h2 id="内存为什么需要管理"><a href="#内存为什么需要管理" class="headerlink" title="内存为什么需要管理"></a>内存为什么需要管理</h2><p>当存储的东西越来越多，也就发现物理内存的容量依然是不够用，那么对物理内存的利用率和合理的分配，管理就变得非常的重要。</p><p>（1）操作系统就会对内存进行非常详细的管理。</p><p>（2）基于操作系统的基础上，不同语言的内存管理机制也应允而生，有的一些语言并没有提供自动的内存管理模式，有的语言就已经提供了自身程序的内存管理模式，如表2所示。</p><h6 id="表2-自动与非自动内存管理的语言"><a href="#表2-自动与非自动内存管理的语言" class="headerlink" title="表2 自动与非自动内存管理的语言"></a>表2 自动与非自动内存管理的语言</h6><table><thead><tr><th><strong>内存自动管理的语言（部分）</strong></th><th><strong>内存非自动管理的语言（部分）</strong></th></tr></thead><tbody><tr><td>Golang</td><td>C</td></tr><tr><td>Java</td><td>C++</td></tr><tr><td>Python</td><td>Rust</td></tr></tbody></table><p>所以为了降低内存管理的难度，像C、C++这样的编程语言会完全将分配和回收内存的权限交给开发者，而Rust则是通过生命周期限定开发者对非法权限内存的访问来自动回收，因而并没有提供自动管理的一套机制。但是像Golang、Java、Python这类为了完全让开发则关注代码逻辑本身，语言层提供了一套管理模式。因为Golang编程语言给开发者提供了一套内存管理模式，所以开发者有必要了解一下Golang做了哪些助力的功能。</p><p>在理解Golang语言层内存管理之前，应先了解操作系统针对物理内存做了哪些管理的方式。当插上内存条之后，通过操作系统是如何将软件存放在这个绿色的物理内存条中去的。</p><h2 id="为什么需要关心内存分配问题"><a href="#为什么需要关心内存分配问题" class="headerlink" title="为什么需要关心内存分配问题"></a><strong>为什么需要关心内存分配问题</strong></h2><hr><p>每个工程师的时间都如此宝贵，在继续读这篇文章之前，需要你先回答几个问题，如果得到的答案是否定的，那可能本文章里写的内容对你并没有什么帮助。但是，如果你遇到了因内存分配而导致的性能问题，可能这篇文章能带你理解 Golang 的内存分配的冰山一角，带你入个门。</p><p>问题如下：</p><ul><li>你的程序是性能敏感型吗？</li><li>GC 带来的延迟影响到了你的程序性能吗？</li><li>你的程序有过多的堆内存分配吗？</li></ul><p>如果你命中上面问题的其中一个或两个，那这篇文章适合你继续读下去。或你根本不知道如何回答这些问题，可能去了解下 go 性能观测相关的知识（pprof 的使用等）对你更有帮助。</p><p><strong>下面正文开始。</strong></p><h2 id="Golang-简要内存划分"><a href="#Golang-简要内存划分" class="headerlink" title="Golang 简要内存划分"></a><strong>Golang 简要内存划分</strong></h2><hr><p><img src="https://ask.qcloudimg.com/http-save/5469577/b1e2510bc404791b9a0909da0a0f1a99.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>可以简单的认为 Golang 程序在启动时，会向操作系统申请一定区域的内存，分为栈（Stack）和堆（Heap）。栈内存会随着函数的调用分配和回收；堆内存由程序申请分配，由垃圾回收器（Garbage Collector）负责回收。性能上，栈内存的使用和回收更迅速一些；尽管Golang 的 GC 很高效，但也不可避免的会带来一些性能损耗。因此，Go 优先使用栈内存进行内存分配。在不得不将对象分配到堆上时，才将特定的对象放到堆中。</p><h2 id="内存分配过程分析"><a href="#内存分配过程分析" class="headerlink" title="内存分配过程分析"></a><strong>内存分配过程分析</strong></h2><hr><p>本部分，将以代码的形式，分别介绍栈内存分配、指针作为参数情况下的栈内存分配、指针作为返回值情况下的栈内存分配并逐步引出逃逸分析和几个内存逃逸的基本原则。</p><p>正文开始，Talk is cheap，show me the code。</p><h2 id="栈内存分配"><a href="#栈内存分配" class="headerlink" title="栈内存分配"></a><strong>栈内存分配</strong></h2><p>我将以一段简单的代码作为示例，分析这段代码的内存分配过程。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-number">4</span>  n2 := <span class="hljs-title function_">square</span>(n)  fmt.<span class="hljs-title class_">Println</span>(n2)&#125;<br>func <span class="hljs-title function_">square</span>(n int) int&#123;  <span class="hljs-keyword">return</span> n * n&#125;<br></code></pre></td></tr></table></figure><p>复制</p><p>代码的功能很简单，一个 main 函数作为程序入口，定义了一个变量n，定义了另一个函数 squire ，返回乘方操作后的 int 值。最后，将返回的值打印到控制台。程序输出为16。</p><p>下面开始逐行进行分析，解析调用时，go 运行时是如何对内存进行分配的。</p><p><img src="https://ask.qcloudimg.com/http-save/5469577/479e83aa67b17d920bd71f6625afe1c9.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>当代码运行到第6行，进入 main 函数时，会在栈上创建一个 Stack frame，存放本函数中的变量信息。包括函数名称，变量等。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/h4jok0khik.png?imageView2/2/w/1620" alt="img"></p><p>当代码运行到第7行时，go 会在栈中压入一个新的 Stack Frame，用于存放调用 square 函数的信息；包括函数名、变量 n 的值等。此时，计算4 * 4 的值，并返回。</p><p><img src="https://ask.qcloudimg.com/http-save/5469577/e595bc8e8421e68646c147ea1cb411ab.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>当 square 函数调用完成，返回16到 main 函数后，将16赋值给 n2变量。注意，原来的 stack frame 并不会被 go 清理掉，而是如栈左侧的箭头所示，被标记为不合法。上图夹在红色箭头和绿色箭头之间的横线可以理解为 go 汇编代码中的 SP 栈寄存器的值，当程序申请或释放栈内存时，只需要修改 SP 寄存器的值，这种栈内存分配方式省掉了清理栈内存空间的耗时【1】。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/m6ls2qtdbl.png?imageView2/2/w/1620" alt="img"></p><p>接下来，调用 fmt.Println 时，SP 寄存器的值会进一步增加，覆盖掉原来 square 函数的 stack frame，完成 print 后，程序正常退出。</p><h2 id="指针作为参数情况下的栈内存分配"><a href="#指针作为参数情况下的栈内存分配" class="headerlink" title="指针作为参数情况下的栈内存分配"></a><strong>指针作为参数情况下的栈内存分配</strong></h2><p>还是同样的过程，看如下这段代码。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-number">4</span>  <span class="hljs-title function_">increase</span>(&amp;n)  fmt.<span class="hljs-title class_">Println</span>(n)&#125;<br>func <span class="hljs-title function_">increase</span>(<span class="hljs-params">i *int</span>) &#123;  *i++&#125;<br></code></pre></td></tr></table></figure><p>main 作为程序入口，声明了一个变量 n，赋值为4。声明了一个函数  increase，使用一个 int 类型的指针 i 作为参数，increase 函数内，对指针 i 对应的值进行自增操作。最后 main 函数中打印了 n 的值。程序输出为5。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/7snaopjz26.png?imageView2/2/w/1620" alt="img"></p><p>当程序运行到 main 函数的第6行时，go 在栈上分配了一个 stack frame ，对变量 n 进行了赋值，n 在内存中对应的地址为0xc0008771，此时程序将继续向下执行，调用 increase 函数。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/nzbfzfdkup.png?imageView2/2/w/1620" alt="img"></p><p>这时，increase 函数对应的 stack fream 被创建，i 被赋值为变量 n对应的地址值0xc0008771，然后进行自增操作。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/u14njxdglz.png?imageView2/2/w/1620" alt="img"></p><p>当 increase 函数运行结束后，SP 寄存器会上移，将之前分配的 stack freme 标记为不合法。此时，程序运行正常，并没有因为 SP 寄存器的改动而影响程序的正确性，内存中的值也被正确的修改了。</p><h2 id="指针作为返回值情况下的栈内存分配"><a href="#指针作为返回值情况下的栈内存分配" class="headerlink" title="指针作为返回值情况下的栈内存分配"></a><strong>指针作为返回值情况下的栈内存分配</strong></h2><p>文章之前的部分分别介绍了普通变量作为参数和将指针作为参数情况下的栈内存使用，本部分来介绍将指针作为返回值，返回给调用方的情况下，内存是如何分配的，并引出内存逃逸相关内容。来看这段代码：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-title function_">initValue</span>()  fmt.<span class="hljs-title class_">Println</span>(*n/<span class="hljs-number">2</span>)&#125;<br>func <span class="hljs-title function_">initValue</span>() *int &#123;  i := <span class="hljs-number">4</span>  <span class="hljs-keyword">return</span> &amp;i&#125;<br></code></pre></td></tr></table></figure><p>main 函数中，调用了 initValue 函数，该函数返回一个 int 指针并赋值给 n，指针对应的值为4。随后，main 函数调用 fmt.Println 打印了指针 n &#x2F; 2对应的值。程序输出为2。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/945gf1ih2a.png?imageView2/2/w/1620" alt="img"></p><p>程序调用 initValue 后，将 i 的地址赋值给变量 n 。注意，如果这时，变量 i 的位置在栈上，则可能会随时被覆盖掉。</p><p><img src="https://ask.qcloudimg.com/developer-images/article/5469577/8ydk3bi2lv.png?imageView2/2/w/1620" alt="img"></p><p>在调用 fmt.Println 时，Stack Frame 会被重新创建，变量 i 被赋值为*n&#x2F;2也就是2，会覆盖掉原来 n 所指向的变量值。这会导致及其严重的问题。在面对 sharing up 场景时，go 通常会将变量分配到堆中，如下图所示：</p><p><img src="https://ask.qcloudimg.com/http-save/5469577/16ab1617ecd4832e038e07e9a612fd69.webp?imageView2/2/w/1620/format/jpg" alt="img"></p><p>通过上面的分析，可以看到在面对被调用的函数返回一个指针类型时将对象分配到栈上会带来严重的问题，因此 Go 将变量分配到了堆上。这种分配方式保证了程序的安全性，但也不可避免的增加了堆内存创建，并需要在将来的某个时候，需要 GC 将不再使用的内存清理掉。</p><h2 id="内存分配原则"><a href="#内存分配原则" class="headerlink" title="内存分配原则"></a><strong>内存分配原则</strong></h2><hr><p>经过上述分析，可以简单的归纳几条原则。</p><ul><li>Sharing down typically stays on the stack 在调用方创建的变量或对象，通过参数的形式传递给被调用函数，这时，在调用方创建的内存空间通常在栈上。这种在调用方创建内存，在被调用方使用该内存的“内存共享”方式，称之为 Sharing down。</li><li>Sharing up typically escapes to the heap 在被调用函数内创建的对象，以指针的形式返回给调用方的情况下，通常，创建的内存空间在堆上。这种在被调用方创建，在调用方使用的“内存共享”方式，称之为 Sharing up。</li><li>Only the compiler knows 之所以上面两条原则都加了通常，因为具体的分配方式，是由编译器确定的，一些编译器后端优化，可能会突破这两个原则，因此，具体的分配逻辑，只有编译器（或开发编译器的人）知道。</li></ul><h2 id="使用-go-build-命令确定内存逃逸情况"><a href="#使用-go-build-命令确定内存逃逸情况" class="headerlink" title="使用 go build 命令确定内存逃逸情况"></a><strong>使用 go build 命令确定内存逃逸情况</strong></h2><hr><p>值得注意的是，Go 在判断一个变量或对象是否需要逃逸到堆的操作，是在编译器完成的；也就是说，当代码写好后，经过编译器编译后，会在二进制中进行特定的标注，声明指定的变量要被分配到堆或栈。可以使用如下命令在编译期打印出内存分配逻辑，来具体获知特定变量或对象的内存分配位置。</p><p>查看 go help 可以看到 go build 其实是在调用 go tool compile。</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">go help build ... -gcflags <span class="hljs-string">&#x27;[pattern=]arg list&#x27;</span>        <span class="hljs-variable language_">arguments</span> to pass on each go tool compile invocation....<br></code></pre></td></tr></table></figure><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs javascript">go tool compile -h...-m    print optimization decisions...-l    disable inlining...<br></code></pre></td></tr></table></figure><p>其中，需要关心的参数有两个，</p><ul><li>-m 显示优化决策</li><li>-l 禁止使用内联【2】</li></ul><p>代码如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs javascript">package main<br>func <span class="hljs-title function_">main</span>(<span class="hljs-params"></span>) &#123;  n := <span class="hljs-title function_">initValue</span>()  <span class="hljs-title function_">println</span>(*n / <span class="hljs-number">2</span>)<br>  o := <span class="hljs-title function_">initObj</span>()  <span class="hljs-title function_">println</span>(o)<br>  f := <span class="hljs-title function_">initFn</span>()  <span class="hljs-title function_">println</span>(f)<br>  num := <span class="hljs-number">5</span>  result := <span class="hljs-title function_">add</span>(num)  <span class="hljs-title function_">println</span>(result)&#125;<br>func <span class="hljs-title function_">initValue</span>() *int &#123;  i := <span class="hljs-number">3</span>                <span class="hljs-comment">// ./main.go:19:2: moved to heap: i  return &amp;i&#125;</span><br>type <span class="hljs-title class_">Obj</span> struct &#123;  i int&#125;<br>func <span class="hljs-title function_">initObj</span>() *<span class="hljs-title class_">Obj</span> &#123;  <span class="hljs-keyword">return</span> &amp;<span class="hljs-title class_">Obj</span>&#123;<span class="hljs-attr">i</span>: <span class="hljs-number">3</span>&#125;      <span class="hljs-comment">// ./main.go:28:9: &amp;Obj literal escapes to heap&#125;</span><br>func <span class="hljs-title function_">initFn</span>() <span class="hljs-title function_">func</span>(<span class="hljs-params"></span>) &#123;  <span class="hljs-keyword">return</span> <span class="hljs-title function_">func</span>(<span class="hljs-params"></span>) &#123;       <span class="hljs-comment">// ./main.go:32:9: func literal escapes to heap    println(&quot;I am a function&quot;)  &#125;&#125;</span><br>func <span class="hljs-title function_">add</span>(i int) int &#123;  <span class="hljs-keyword">return</span> i + <span class="hljs-number">1</span>&#125;<br></code></pre></td></tr></table></figure><p>完整的构建命令和输出如下：</p><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs javascript">go build -gcflags=<span class="hljs-string">&quot;-m -l&quot;</span> <br># _/<span class="hljs-title class_">Users</span>/rocket/workspace/stack-or-heap./main.<span class="hljs-property">go</span>:<span class="hljs-number">19</span>:<span class="hljs-number">2</span>: moved to <span class="hljs-attr">heap</span>: i./main.<span class="hljs-property">go</span>:<span class="hljs-number">24</span>:<span class="hljs-number">9</span>: &amp;<span class="hljs-title class_">Obj</span> literal escapes to heap./main.<span class="hljs-property">go</span>:<span class="hljs-number">28</span>:<span class="hljs-number">9</span>: func literal escapes to heap<br></code></pre></td></tr></table></figure><p>可以看到，sharing up 的情况（initValue，initObj，initFn）内存空间被分配到了堆上。sharing down 的情况（add）内存空间在栈上。</p><p>这里给读者留个问题，大家可以研究下 moved to heap 和 escapes to heap 的区别。</p><h1 id="内存逃逸"><a href="#内存逃逸" class="headerlink" title="内存逃逸"></a>内存逃逸</h1><h2 id="怎么答"><a href="#怎么答" class="headerlink" title="怎么答"></a><strong>怎么答</strong></h2><p><code>golang程序变量</code>会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在<code>栈上</code>分配。否则就说它 <code>逃逸</code> 了，必须在<code>堆上分配</code>。</p><p>能引起变量逃逸到堆上的<strong>典型情况</strong>：</p><ul><li><strong>在方法内把局部变量指针返回</strong> 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。</li><li><strong>发送指针或带有指针的值到 channel 中。</strong> 在编译时，是没有办法知道哪个 <a href="https://www.zhihu.com/search?q=goroutine&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22article%22,%22sourceId%22:%22145468000%22%7D">goroutine</a> 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。</li><li><strong>在一个切片上存储指针或带指针的值。</strong> 一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。</li><li><strong>slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。</strong> slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。</li><li><strong>在 interface 类型上调用方法。</strong> 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配。</li></ul><h2 id="举例"><a href="#举例" class="headerlink" title="举例"></a><strong>举例</strong></h2><ul><li>通过一个例子加深理解，接下来尝试下怎么通过 <code>go build -gcflags=-m</code> 查看逃逸的情况。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-keyword">type</span> A <span class="hljs-keyword">struct</span> &#123;<br> s <span class="hljs-type">string</span><br>&#125;<br><span class="hljs-comment">// 这是上面提到的 &quot;在方法内把局部变量指针返回&quot; 的情况</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">foo</span><span class="hljs-params">(s <span class="hljs-type">string</span>)</span></span> *A &#123;<br> a := <span class="hljs-built_in">new</span>(A) <br> a.s = s<br> <span class="hljs-keyword">return</span> a <span class="hljs-comment">//返回局部变量a,在C语言中妥妥野指针，但在go则ok，但a会逃逸到堆</span><br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br> a := foo(<span class="hljs-string">&quot;hello&quot;</span>)<br> b := a.s + <span class="hljs-string">&quot; world&quot;</span><br> c := b + <span class="hljs-string">&quot;!&quot;</span><br> fmt.Println(c)<br>&#125;<br></code></pre></td></tr></table></figure><p>执行<code>go build -gcflags=-m main.go</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">go</span> build -gcflags=-m main.<span class="hljs-keyword">go</span><br># command-line-arguments<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">7</span>:<span class="hljs-number">6</span>: can inline foo<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">13</span>:<span class="hljs-number">10</span>: inlining call to foo<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: inlining call to fmt.Println<br>/<span class="hljs-keyword">var</span>/folders/<span class="hljs-number">45</span>/qx9lfw2s2zzgvhzg3mtzkwzc0000gn/T/<span class="hljs-keyword">go</span>-build409982591/b001/_gomod_.<span class="hljs-keyword">go</span>:<span class="hljs-number">6</span>:<span class="hljs-number">6</span>: can inline init<span class="hljs-number">.0</span><br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">7</span>:<span class="hljs-number">10</span>: leaking param: s<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">8</span>:<span class="hljs-number">10</span>: <span class="hljs-built_in">new</span>(A) escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: io.Writer(os.Stdout) escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: c escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">15</span>:<span class="hljs-number">9</span>: b + <span class="hljs-string">&quot;!&quot;</span> escapes to heap<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">13</span>:<span class="hljs-number">10</span>: main <span class="hljs-built_in">new</span>(A) does not escape<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">14</span>:<span class="hljs-number">11</span>: main a.s + <span class="hljs-string">&quot; world&quot;</span> does not escape<br>./main.<span class="hljs-keyword">go</span>:<span class="hljs-number">16</span>:<span class="hljs-number">13</span>: main []<span class="hljs-keyword">interface</span> &#123;&#125; literal does not escape<br>&lt;autogenerated&gt;:<span class="hljs-number">1</span>: os.(*File).<span class="hljs-built_in">close</span> .this does not escape<br></code></pre></td></tr></table></figure><ul><li><code>./main.go:8:10: new(A) escapes to heap</code> 说明 <code>new(A)</code> 逃逸了,符合上述提到的常见情况中的第一种。</li><li><code>./main.go:14:11: main a.s + &quot; world&quot; does not escape</code> 说明 <code>b</code> 变量没有逃逸，因为它只在方法内存在，会在方法结束时被回收。</li><li><code>./main.go:15:9: b + &quot;!&quot; escapes to heap</code> 说明 <code>c</code> 变量逃逸，通过<code>fmt.Println(a ...interface&#123;&#125;)</code>打印的变量，都会发生逃逸，感兴趣的朋友可以去查查为什么。</li><li>以上操作其实就叫<strong>逃逸分析</strong></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><hr><p>1.因为栈比堆更高效，不需要 GC，因此 Go 会尽可能的将内存分配到栈上。</p><p>2.当分配到栈上可能引起非法内存访问等问题后，会使用堆，主要场景有：</p><ol><li>当一个值可能在函数被调用后访问，这个值极有可能被分配到堆上。</li><li>当编译器检测到某个值过大，这个值会被分配到堆上。</li><li>当编译时，编译器不知道这个值的大小（slice、map…）这个值会被分配到堆上。</li></ol><p>3.Sharing down typically stays on the stack</p><p>4.Sharing up typically escapes to the heap</p><p>5.Don’t guess, Only the compiler knows</p><p>6.Golang中一个函数内局部变量，不管是不是动态new出来的，它会被分配在堆还是栈，是由编译器做逃逸分析之后做出的决定。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a><strong>参考文献</strong></h1><p>【1】Go语言设计与实现：<a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/#%E5%AF%84%E5%AD%98%E5%99%A8">https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/#%E5%AF%84%E5%AD%98%E5%99%A8</a></p><p>【2】Inlining optimisations in Go：<a href="https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go">https://dave.cheney.net/2020/04/25/inlining-optimisations-in-go</a></p><p>【3】Golang FAQ：<a href="https://golang.org/doc/faq#stack_or_heap">https://golang.org/doc/faq#stack_or_heap</a></p><p>【4】知乎：<a href="https://zhuanlan.zhihu.com/p/145468000">https://zhuanlan.zhihu.com/p/145468000</a></p>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang为什么不用Java的gc模式</title>
    <link href="/2022/09/12/Golang%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8Java%E7%9A%84gc%E6%A8%A1%E5%BC%8F/"/>
    <url>/2022/09/12/Golang%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E7%94%A8Java%E7%9A%84gc%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang为什么不用Java的gc模式"><a href="#Golang为什么不用Java的gc模式" class="headerlink" title="Golang为什么不用Java的gc模式"></a>Golang为什么不用Java的gc模式</h1><blockquote><p><strong>为什么Go、Julia 和 Rust 等现代语言不需要像 Java C# 那样复杂的垃圾收集器？</strong></p></blockquote><p>为了解释原因，我们需要了解垃圾收集器是如何工作的，以及不同的语言如何以不同的方式分配内存。我们首先了解为什么 Java 特别需要如此复杂的垃圾收集器。</p><p>以下面几个主题为出发点来做相关介绍：</p><ul><li>为什么 Java 如此依赖快速 GC。介绍 Java 语言本身中对 GC 造成很大压力的一些设计选择。</li><li>内存碎片以及它如何影响 GC 设计。为什么这对 Java 很重要，而对 Go 却没有那么重要。</li><li>值类型以及它们如何改变 GC 。</li><li>分代GC以及为什么 Go 不需要。</li><li>逃逸分析——Go 如何用来减少 GC 压力的技巧。</li><li>分代 垃圾收集器——在 Java 世界中很重要，但 Go 以某种方式避免了对它的需求。为什么？</li><li>Concurrent Garbage Collection — Go 如何通过使用多个线程运行并发垃圾收集器来解决许多 GC 挑战。为什么使用 Java 更难做到这一点。</li><li>对 Go GC 的常见批评以及为什么批评背后的许多假设通常是有缺陷或完全错误的。</li><li>为什么低延迟对 Java 也很重要</li></ul><h2 id="为什么-Java-比其他人更需要快速-GC"><a href="#为什么-Java-比其他人更需要快速-GC" class="headerlink" title="为什么 Java 比其他人更需要快速 GC"></a>为什么 Java 比其他人更需要快速 GC</h2><p><strong>背景：</strong>Java 设计工作开始时。垃圾收集器风靡一时。研究看起来很有希望，Java 的设计者将赌注押在高级垃圾收集器上，这些垃圾收集器能够从根本上解决管理内存方面的所有挑战。</p><p>出于这个原因，Java 中的所有对象都设计为在堆上分配，但整数和浮点值等原始类型除外。在谈到内存分配时，我们一般会区分所谓的堆和栈。堆栈使用起来非常快，但空间有限，只能用于在函数调用的生命周期之后不需要存在的对象。它仅适用于局部变量。堆可用于所有对象。Java 基本上忽略了堆栈并选择在堆上分配所有内容，除了整数和浮点数等原语。每当您<code>new Something()</code>使用 Java 编写代码时，都会消耗堆上的内存。</p><p>然而，这种类型的内存管理在内存使用方面实际上是相当昂贵的。你会认为创建一个只有 32 位整数的对象只需要 4 个字节的内存。</p><p>但是，为了让垃圾收集器工作，Java 会存储一个标头，其中包含以下信息：</p><ul><li>类型 — 标识对象的类别或类型。</li><li>Lock — 用于同步语句。</li><li>标记 - 在垃圾收集器的标记和扫描面期间使用。</li></ul><p>该数据通常为 16 个字节。因此，标题数据与实际数据的比率为 4:1。Java 对象的 C++ 源代码定义为：<a href="http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/oops/oop.hpp">OpenJDK Base Class</a>。</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript"><span class="hljs-keyword">class</span> <span class="hljs-symbol">oopDesc</span> &#123;<br>    volatile markOop  _mark;   <span class="hljs-comment">// for mark and sweep</span><br>    Klass*           _klass;   <span class="hljs-comment">// the type</span><br>&#125;<br></code></pre></td></tr></table></figure><h2 id="内存碎片"><a href="#内存碎片" class="headerlink" title="内存碎片"></a>内存碎片</h2><p>当 Java 分配一个对象数组时，它真正做的是创建一个引用数组，指向内存中某个其他位置的对象。这些对象最终可能分散在堆内存周围。这对性能不利，因为现代微处理器不读取单个数据字节。因为启动内存传输很慢，微处理器每次尝试访问一个特定的内存位置时总是读取一个大的连续内存块。</p><p><img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/20220912124051.png"></p><p>这块内存称为高速缓存行。CPU 有自己的高速内存，称为高速缓存。这比主存储器小得多。它用于存储最近访问的对象，因为这些对象很可能会再次被访问。如果主内存是碎片化的，这意味着高速缓存行将被碎片化，CPU 高速缓存将被大量无用数据填满。</p><p><strong>Java如何克服内存碎片</strong></p><p>为了解决这些主要缺点，Java 维护人员在高级垃圾收集器上投入了大量资金。这些做一些称为<em>压缩</em>的事情。压缩涉及在内存中移动对象并将它们收集到内存中的连续块中。这并不便宜。不仅将块从一个内存位置移动到另一个内存位置会消耗 CPU 周期，而且更新对这些对象的每个引用以指向新位置也会消耗 CPU 周期。</p><p>进行这些更新需要冻结所有线程。您不能在使用它们时更新参考。这通常会导致 Java 程序完全冻结数百毫秒，其中对象移动、引用更新和未使用的内存回收。</p><p><strong>增加复杂性</strong></p><p>为了减少这些长时间的停顿，Java 使用了所谓的<em>分代垃圾收集器</em>. 这些都是基于以下前提：</p><blockquote><p>程序中分配的大多数值很快就会被使用，因此 GC 可以花更多时间查看最近分配的对象。</p></blockquote><p>这就是为什么 Java 将它们分配的对象分成两组：</p><ul><li>旧对象——在 GC 的多次标记和清除操作中幸存下来的对象。每次标记和扫描都会更新生成计数器，以跟踪对象的年龄。</li><li>年轻对象——这些对象的生成计数器较低。这意味着它们最近才被分配。</li></ul><p>Java 更积极地调查最近分配的对象并检查它们是否应该被回收或移动。随着对象年龄的增长，它们会被移出年轻代区域。</p><p>所有这些自然会产生更多的复杂性。它需要更多的发展。</p><p><strong>现代语言如何避免与 Java 相同的陷阱</strong></p><p>现代语言不需要像 Java 和 C# 这样的复杂垃圾收集器。这是因为它们没有被设计成同样程度地依赖它们。</p><figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs smali">// Go: Make an an<span class="hljs-built_in"> array </span>of 15 000 Point objects in<br>type Point struct &#123;<br>    X, Y<span class="hljs-built_in"> int</span><br><span class="hljs-built_in"></span>&#125;<br>var points [15000]Point<br></code></pre></td></tr></table></figure><p>在上面的 Go 代码示例中，我们分配了 15000 个<code>Point</code>对象。这只是一个单一的分配，产生一个单一的指针。在 Java 中，这需要 15 000 个单独的分配，每个分配都产生一个必须管理的单独引用。每个<code>Point</code>对象都有我之前写过的 16 字节头开销。在 Go、Julia 或 Rust 中，你都不会得到这个开销。这些对象通常是无标题的。</p><p>在 Java 中，GC 获得它必须跟踪和管理的 15000 个单独的对象。Go 只有 1 个要跟踪的对象。</p><h2 id="值类型"><a href="#值类型" class="headerlink" title="值类型"></a>值类型</h2><p>下面的代码定义了一个矩形，其中一个<code>Min</code>和<code>Max</code>点定义了它的范围。</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">Rect</span> struct &#123;<br>   <span class="hljs-type">Min</span>, <span class="hljs-type">Max</span> <span class="hljs-type">Point</span><br>&#125;<br></code></pre></td></tr></table></figure><p>这成为一个连续的内存块。在 Java 中，这将变成一个<code>Rect</code>对象，其中引用了两个单独的对象，Min<code>和</code>Max<code>point 对象。因此在 Java 中，一个 的实例</code>Rect&#96;需要 3 次分配，但在 Go、Rust、C&#x2F;C++ 和 Julia 中只需要 1 次分配。</p><p><img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/image-20220912125744670.png" alt="image-20220912125744670"></p><p>左边是 Java 风格的内存碎片。在 Go、C&#x2F;C++、Julia 等中可能存在正确的连续内存块。</p><p>在将 Git 移植到 Java 时，缺少值类型会产生重大问题。没有值类型，很难获得良好的性能。正如 Shawn O. Pearce<a href="https://marc.info/?l=git&m=124111702609723">在 JGit 开发者邮件列表中所说</a>：</p><blockquote><p>JGit 苦于没有一种有效的方式来表示 SHA-1。C 可以说<code>unsigned char[20]</code>并将其内联到容器的内存分配中。<code>byte[20]</code>Java 中的A将花费<em>额外</em>的16 字节内存，并且访问速度较慢，因为字节本身与容器对象位于不同的内存区域。我们尝试通过从 a 转换为 5 个整数来解决它<code>byte[20]</code>，但这会花费我们的机器指令。</p></blockquote><p>我们在那里谈论什么？在 Go 中，我可以做与 C&#x2F;C++ 相同的事情并定义如下结构：</p><figure class="highlight elm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs elm"><span class="hljs-keyword">type</span> <span class="hljs-type">Sha1</span> struct &#123;<br>   data [20]byte<br>&#125;<br></code></pre></td></tr></table></figure><p>然后这些字节将成为一个内存块的一部分。Java 将创建一个指向内存中其他位置的指针。</p><p>Java 开发人员意识到他们搞砸了，并且您确实需要值类型才能获得良好的性能。您可以称该陈述为夸张，但随后您需要解释<a href="https://en.wikipedia.org/wiki/Project_Valhalla_(Java_language)">Project Valhalla</a>。这是 Oracle 为提供 Java 值类型而带头的一项努力，他们阐明这样做的原因正是我在这里所说的。</p><p><strong>值类型还不够</strong></p><p>那么<em>Project Valhalla</em>会解决Java 的问题吗？并不真地。它只会使 Java 与 C# 处于同等地位。C# 在 Java 之后几年问世，并从那时起意识到垃圾收集器并不是每个人都认为的那样神奇。因此，他们添加了值类型。</p><p>但是，在内存管理灵活性方面，这并没有使 C# 和 Java 与 Go 和 C&#x2F;C++ 等语言处于同等地位。Java 不支持真正的指针。在 Go 中，我可以这样写：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">// Go 指针用法var </span><br>ptr *Point = &amp;rect.Min <span class="hljs-comment">// 将指向 Min 的指针存储在 ptr </span><br>*ptr = Point(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>) <span class="hljs-comment">// 替换 rect.Min</span><br></code></pre></td></tr></table></figure><p>您可以在 Go 中获取对象的地址或对象的字段，就像在 C&#x2F;C++ 中一样，并将其存储在指针中。然后，您可以传递此指针并使用它来修改它指向的字段。这意味着您可以在 Go 中创建大值对象并将其作为指向函数的指针传递以优化性能。使用 C#，情况会好一些，因为它对指针的支持<em>有限。</em>前面的 Go 示例可以用 C# 编写为：</p><figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c#"><span class="hljs-comment">// C# 指针用法不安全的 void foo() &#123; </span><br>   Rect* ptr = &amp;rect.Min; <br>   *ptr = <span class="hljs-keyword">new</span> Point(<span class="hljs-number">2</span>, <span class="hljs-number">4</span>); <br>&#125;<br></code></pre></td></tr></table></figure><p>然而，C# 指针支持带有一些不适用于 Go 的警告：</p><ol><li>使用点的代码必须标记为<strong>unsafe</strong>。这会创建安全性较低且更容易崩溃的代码。</li><li>在堆栈上分配的纯值类型（所有结构字段必须是值类型）。</li><li>在已关闭垃圾收集的<strong>固定范围内，使用 fixed 关键字。</strong></li></ol><p>因此，在 C# 中使用值类型的正常且安全的方法是复制它们，因为这不需要定义不安全或固定的代码区域。但是对于较大的值类型，这可能会产生性能问题。Go 没有这些问题。您可以在 Go 中创建指向垃圾收集器管理的对象的指针。您不需要像在 C# 中那样在 Go 中使用指针来隔离代码。</p><h2 id="自定义辅助分配器"><a href="#自定义辅助分配器" class="headerlink" title="自定义辅助分配器"></a>自定义辅助分配器</h2><p>使用正确的指针，您可以做很多只有值类型时无法做到的事情。一个示例是创建辅助分配器。<a href="https://github.com/ordovician/arena">这</a>是使用 Go 泛型创建的 Arena 分配器的示例。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">type</span> Arena[T any] <span class="hljs-keyword">struct</span> &#123;<br>    blocks Stack[*T]<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(arena *Arena[T])</span></span> Alloc() *T &#123;<br>    <span class="hljs-keyword">if</span> arena.blocks.IsEmpty() &#123;<br>        <span class="hljs-keyword">var</span> blocks [<span class="hljs-number">32</span>]T     <span class="hljs-comment">// allocate 32 elements at a time</span><br>        <span class="hljs-keyword">for</span> i, _ := <span class="hljs-keyword">range</span> blocks &#123;<br>            arena.blocks.Push(&amp;blocks[i])<br>        &#125;<br>    &#125;<br>    b, _ := arena.blocks.Top()<br>    arena.blocks.Pop()<br>    <span class="hljs-keyword">return</span> b<br>&#125;<br></code></pre></td></tr></table></figure><p>为什么这些有用？如果您查看生成二叉树的算法的微基准测试，您通常会发现 Java 比 Go 具有很大优势。这是因为二叉树算法通常用于测试垃圾收集器分配对象的速度。Java 在这方面非常快，因为它使用了我们所说的凹凸指针。它只是增加一个指针，而 Go 将在内存中搜索合适的位置来分配对象。但是，使用 Arena 分配器，您也可以在 Go 中快速构建二叉树。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;golang.org/x/exp/constraints&quot;</span><br><span class="hljs-keyword">type</span> Tree[K constraints.Ordered, V any] <span class="hljs-keyword">struct</span> &#123;<br>    Root      *TreeNode[K, V]<br>    allocator Arena[TreeNode[K, V]]<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tree *Tree[K, V])</span></span> NewNode(key K, value V) *TreeNode[K, V] &#123;<br>    n := tree.allocator.Alloc()<br>    n.Key = key<br>    n.Value = value<br>    n.left = <span class="hljs-literal">nil</span><br>    n.right = <span class="hljs-literal">nil</span><br>    <span class="hljs-keyword">return</span> n<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(tree *Tree[K, V])</span></span> Insert(key K, value V) &#123;<br>    n := tree.NewNode(key, value)<br>    <span class="hljs-keyword">if</span> tree.Root == <span class="hljs-literal">nil</span> &#123;<br>        tree.Root = n<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        tree.Root.Insert(n)<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>这就是为什么拥有真正的指针有好处的原因。没有它，您无法在连续的内存块中创建指向元素的指针。在该<code>Alloc</code>方法中，我们创建了一个由 32 个元素组成的连续块。然后，我们将指向该块中每个元素的指针存储在一个堆栈上，该堆栈包含一个可用于分配的块列表。</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-selector-tag">var</span> blocks <span class="hljs-selector-attr">[32]</span>T <br><span class="hljs-keyword">for</span> <span class="hljs-selector-tag">i</span>, _ := range blocks &#123; <br>    arena<span class="hljs-selector-class">.blocks</span><span class="hljs-selector-class">.Push</span>(&amp;blocks<span class="hljs-selector-attr">[i]</span>) <br>&#125;<br></code></pre></td></tr></table></figure><p>这只是可能的，因为我可以选择任意元素<code>blocks[i]</code>并获取指向该元素的指针<code>&amp;blocks[i]</code>。Java 没有给你这种可能性。</p><p>Java GC 使用的Bump分配器与 Arena 分配器类似，您只需增加一个指针即可获取下一个值。除非您不必自己构建它。这可能看起来更聪明。但这会导致 Go 中避免的几个问题：</p><ol><li>迟早您需要进行<em>压缩</em>，这涉及移动数据和修复指针。Arena 分配器不必这样做。</li><li>在多线程程序中，凹凸分配器需要锁（除非您使用线程本地存储）。这会扼杀它们的性能优势，因为锁会降低性能，或者线程本地存储会导致碎片，需要稍后进行压缩。</li></ol><p>Go 的创建者之一 Ian Lance Taylor<a href="https://groups.google.com/g/golang-nuts/c/KJiyv2mV2pU">阐明了Bump分配器的问题</a>：</p><blockquote><p>一般来说，使用一组每线程缓存分配内存可能会更有效，此时您已经失去了凹凸分配器的优势。所以我要断言，总的来说，有很多警告，今天为多线程程序使用压缩内存分配器并没有真正的优势。</p></blockquote><h2 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h2><p>Java 垃圾收集器还有很多工作要做，因为它分配了更多的对象。为什么？我们刚刚介绍了这一点。如果没有值对象和真正的指针，在分配大型数组或复杂数据结构时总是会以大量对象告终。因此它需要一个分代GC。</p><p>分配更少对象的需求对 Go 有利。但是 Go 还使用了另一个技巧。Go 和 Java在编译函数时都会进行所谓的<em>转义分析。</em></p><p>转义分析涉及查看在函数内部创建的指针并确定该指针是否曾经转义函数范围。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">escapingPtr</span><span class="hljs-params">()</span></span> []<span class="hljs-type">int</span> &#123; <br>   values := []<span class="hljs-type">int</span>&#123;<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>&#125;<br>   <span class="hljs-keyword">return</span> values<br>&#125; <br><br>fun nonEscapingPtr() <span class="hljs-type">int</span> &#123; <br>    values = []<span class="hljs-type">int</span>&#123;<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>&#125; <br>    <span class="hljs-keyword">var</span> total <span class="hljs-type">int</span> = addUp(values)<br>    <span class="hljs-keyword">return</span> total<br>&#125;<br></code></pre></td></tr></table></figure><p>在第一个示例中，<code>values</code>指向一个切片，它本质上与指向数组的指针相同。它逃脱，因为它被退回。这意味着<code>values</code>必须在堆上分配。</p><p>然而，在第二个例子中，没有指针<code>values</code>离开<code>nonEscapingPtr</code>函数。因此<code>values</code>可以在堆栈上分配，这非常快速且便宜。转义分析本身只是分析指针是否转义。</p><p><strong>Java Escape 分析的局限性</strong></p><p>Java 也确实逃脱了分析，但对其使用有更多限制。来自涵盖 HotSpot VM 的<a href="https://docs.oracle.com/en/java/javase/16/vm/java-hotspot-virtual-machine-performance-enhancements.html#GUID-6BD8FCB5-995B-4AE9-BFAA-B2C7DE2BA5CD">Java SE 16 Oracle 文档：</a></p><blockquote><p>它不会***将***堆分配替换为未全局转义的对象的堆栈分配。</p></blockquote><p>然而，Java 使用了一种称为<em>标量替换的替代技巧，</em>它避免了将对象放在堆栈上的需要。本质上它会爆炸和对象并将其原始成员放在堆栈上。请记住，Java 已经可以将原始值（例如<code>int</code>和<code>float</code>）放在堆栈上。<a href="https://pkolaczk.github.io/">然而，正如Piotr Kołaczkowski</a>在 2021 年发现的那样，在实践中，即使在非常微不足道的情况下，标量替换也不起作用。</p><p>相反，主要优点是避免锁定。如果您知道指针没有在函数外部使用，您还可以确定它不需要锁。</p><p><strong>Go Escape分析的优势</strong></p><p>然而，Go 使用逃逸分析来确定可以在堆栈上分配哪些对象。这显着减少了可以从分代 GC 中受益的短期对象的数量。请记住，分代 GC 的全部意义在于利用最近分配的对象存活时间短的事实。然而，Go 中的大多数对象可能会长期存在，因为短期对象很可能会被逃逸分析捕获。</p><p>与 Java 不同，这也适用于复杂对象。Java 通常只能成功地对字节数组等简单对象进行转义分析。即使是内置的<code>ByteBuffer</code>也不能使用标量替换在堆栈上分配。</p><h2 id="分代-GC-与并发-GC-暂停"><a href="#分代-GC-与并发-GC-暂停" class="headerlink" title="分代 GC 与并发 GC 暂停"></a>分代 GC 与并发 GC 暂停</h2><p>你可以读到很多关于垃圾收集器的专家声称，由于内存碎片，Go 比 Java 更有可能耗尽内存。争论是这样的：因为 Go 没有分代垃圾收集器，内存会随着时间的推移变得碎片化。当内存碎片化时，您将达到将新对象装入内存变得困难的地步。</p><p>但是，由于两个原因，此问题大大减少：</p><ol><li>Go 分配的小对象没有 Java 那么多。它可以将大型对象数组分配为单个内存块。</li><li>现代内存分配器，如 Google 的 TCMalloc 或 Intel 的 Scalable Malloc 不会对内存进行分段。</li></ol><p>在设计 Java 时，内存碎片是内存分配器的一个大问题。人们不认为它可以解决。但早在 1998 年，Java 出现后不久，研究人员就开始解决这个问题。<a href="https://dl.acm.org/doi/10.1145/286860.286864">这是 Mark S. Johnstone 和 Paul R. Wilson 的论文</a>：</p><blockquote><p>这大大加强了我们之前的结果，即内存碎片问题通常被误解，并且好的分配器策略可以为大多数程序提供良好的内存使用。</p></blockquote><p>因此，为 Java 设计内存分配策略的许多假设根本不再适用</p><p>使用分代 GC 的 Java 策略旨在缩短垃圾收集周期。请记住，Java 必须停止一切来移动数据并修复指针。如果持续时间过长，这会降低性能和响应能力。使用分代 GC，每次缩短此时间时要检查的数据更少。</p><p>然而，Go 用多种替代策略解决了同样的问题：</p><ol><li>因为不需要移动内存，也不需要固定指针，所以在 GC 运行期间要做的工作更少。Go GC 只进行标记和扫描：它通过对象图查找应该释放的对象。</li><li>它同时运行。因此，一个单独的 GC 线程可以在不停止其他线程的情况下寻找要释放的对象。</li></ol><p>为什么 Go 可以同时运行它的 GC 而不是 Java？因为 Go 不会修复任何指针或移动内存中的任何对象。因此，不存在尝试访问指向刚刚移动但该指针尚未更新的对象的指针的风险。由于某些并发线程正在运行，不再有任何引用的对象不会突然获得引用。因此，并行移除死对象是没有危险的。</p><p>这是怎么回事？假设你有 4 个线程在 Go 程序中工作。其中一个线程偶尔会在任意时间段<code>T</code>秒内完成总共 4 秒的 GC 工作。</p><p>现在想象一个带有 GC 的 Java 程序执行 GC 工作仅 2 秒。哪个程序挤出最多的性能？谁在<code>T</code>几秒钟内完成最多？听起来像 Java 程序，对吧？错误的！</p><p>Java 程序中的 4 个工作线程将所有工作停止 2 秒。<code>T</code>这意味着 2×4 &#x3D; 8 秒的工作在间隔中丢失。因此，虽然 Go 停止的时间更长，但每次停止都会影响更少的工作，因为所有线程都没有停止。因此，缓慢的并发 GC 可能会胜过依赖于停止所有线程来完成其工作的更快的 GC。</p><p><strong>如果垃圾的创建速度比 Go 清理它的速度快怎么办？</strong></p><p>反对当前垃圾收集器的一个流行论点是，您可能会遇到一种情况，即活动工作线程产生垃圾的速度比垃圾收集器线程收集垃圾的速度要快。在 Java 世界中，这被称为“并发模式故障”。</p><p>声称在这种情况下，运行时别无选择，只能完全停止您的程序并等待 GC 周期完成。因此，当 Go 声称 GC 暂停非常低时，这种说法仅适用于 GC 有足够的 CPU 时间和余量超过主程序的情况。</p><p>但是 Go 有一个巧妙的技巧来解决<a href="https://blog.golang.org/ismmkeynote">Go GC 大师 Rick Hudson 所描述的</a>这个问题。Go 使用所谓的 Pacer。</p><blockquote><p>如果需要，Pacer 会在加快标记速度的同时减慢分配速度。在高层次上，Pacer 会停止执行大量分配的 Goroutine，并将其投入到标记工作中。工作量与 Goroutine 的分配成正比。这加快了垃圾收集器的速度，同时减慢了 mutator 的速度。</p></blockquote><p>Goroutines 有点像在线程池上多路复用的绿色线程。基本上，Go 接管了正在运行产生大量垃圾的工作负载的线程，并将它们用于帮助 GC 清理这些垃圾。它只会继续接管线程，直到 GC 运行得比产生垃圾的例程快。</p><p><strong>简而言之</strong></p><p>虽然高级垃圾收集器解决了 Java 中的实际问题，但 Go 和 Julia 等现代语言一开始就简单地避免了产生这些问题，因此不再需要劳斯莱斯垃圾收集器。当您拥有值类型、转义分析、指针、多核处理器和现代分配器时，Java 设计背后的许多假设都将不复存在。它们不再适用。</p><h2 id="假定的-GC-权衡不再适用"><a href="#假定的-GC-权衡不再适用" class="headerlink" title="假定的 GC 权衡不再适用"></a>假定的 GC 权衡不再适用</h2><p>Mike Hearn 在 Medium 上有一个非常受欢迎的故事，他批评了有关 Go GC 的说法：<a href="https://blog.plan99.net/modern-garbage-collection-911ef4f8bd8e">现代垃圾收集。</a>.</p><p>Hearn 的关键信息是在 GC 设计中总是存在权衡。他提出的观点是，因为 Go 的目标是低延迟收集，所以它们会受到许多其他指标的影响。这是一本有趣的读物，因为它涵盖了很多关于 GC 设计权衡的细节。</p><p>首先，我所说的低延迟是什么意思？与可能花费数百毫秒的各种 Java 收集器相比，Go GC 平均仅暂停大约 0.5 毫秒。</p><p>我从 Mike Hearn 的论点中看到的问题是，它们基于一个有缺陷的前提，即所有语言的内存访问模式都是相同的。正如我在本文中介绍的那样，这根本不是真的。Go 将产生更少的对象来由 GC 管理，并且它会使用逃逸分析及早清理大量对象。</p><p><strong>旧技术天生就不好？</strong></p><p>赫恩提出的论点表明，简单的收集在某种程度上天生就不好：</p><blockquote><p>Stop-the-world (STW) 标记&#x2F;扫描是本科计算机科学课程中最常教授的 GC 算法。在进行工作面试时，我有时会要求应聘者谈谈 GC，而且几乎总是，他们要么将 GC 视为一个黑匣子，对此一无所知，要么认为它现在仍在使用这种非常古老的技术。</p></blockquote><p>是的，它可能已经过时了，但是这种技术允许您同时运行 GC，这是“现代”技术所不允许的。在我们拥有多核的现代硬件世界中，这一点更为重要。</p><p><strong>Go 不是 C#</strong></p><p>另一种说法：</p><blockquote><p>由于 Go 是一种具有值类型的相对普通的命令式语言，它的内存访问模式可能与 C# 相当，其中分代假设肯定成立，因此 .NET 使用分代收集器。</p></blockquote><p>情况并非如此。AC# 开发人员会尽量减少对较大值对象的使用，因为与指针相关的代码无法安全使用。我们必须假设 C# 开发人员更喜欢复制值类型而不是使用指针，因为这可以在 CLR 中安全地完成。这自然会带来更高的开销。</p><p>据我所知，C# 也没有利用逃逸分析来减少堆上短期对象的产生。其次，<a href="https://alexyakunin.medium.com/go-vs-c-part-1-goroutines-vs-async-await-ac909c651c11">C# 并不擅长同时运行大量任务</a>。正如 Pacer 所提到的，Go 可以利用它们的协程来加速并发收集。</p><h2 id="为什么低延迟对-Java-也很重要"><a href="#为什么低延迟对-Java-也很重要" class="headerlink" title="为什么低延迟对 Java 也很重要"></a>为什么低延迟对 Java 也很重要</h2><p>我们生活在一个充满 docker 容器和微服务的世界中。这意味着许多较小的程序相互通信并为彼此工作。想象一下工作需要通过几个服务。每当一条链中的这些服务中的一项出现重大暂停时，就会产生涟漪效应。它会导致所有其他进程停止工作。如果管道中的下一个服务正在等待一个忙于进行垃圾收集的服务，它就无法工作。</p><p>因此，延迟&#x2F;吞吐量的权衡不再是 GC 设计中的权衡。当多个服务一起工作时，高延迟会导致吞吐量下降。Java 对高吞吐量和高延迟 GC 的偏好适用于单体应用程序世界。它不再适用于微服务世界。</p><p>这是 Mike Hearn 的论点的一个基本问题，即没有灵丹妙药，只有权衡取舍。它试图给人的印象是 Java 的权衡是同样有效的。但权衡必须适合我们生活的世界。</p><p>简而言之，我认为可以说围棋做出了许多明智的举动和战略选择。挥舞它，好像它只是任何人都可以做出的权衡一样，并没有削减它</p>]]></content>
    
    
    <categories>
      
      <category>golang vs java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes网络模型进阶</title>
    <link href="/2022/09/10/Kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%9B%E9%98%B6/"/>
    <url>/2022/09/10/Kubernetes%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%BF%9B%E9%98%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes-网络模型进阶"><a href="#Kubernetes-网络模型进阶" class="headerlink" title="Kubernetes 网络模型进阶"></a>Kubernetes 网络模型进阶</h1><h2 id="Underlay-Network-Model"><a href="#Underlay-Network-Model" class="headerlink" title="Underlay Network Model"></a>Underlay Network Model</h2><h3 id="什么是Underlay-Network"><a href="#什么是Underlay-Network" class="headerlink" title="什么是Underlay Network"></a>什么是Underlay Network</h3><p>底层网络 <em>Underlay Network</em> 顾名思义是指网络设备基础设施，如交换机，路由器, <em>DWDM</em> 使用网络介质将其链接成的物理网络拓扑，负责网络之间的数据包传输。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyxjoDlKBvyPVoThkJ42pKhe4t3iaE0U1VgCcn0jybn1TCx6yicMB1efjA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                  <strong>图：Underlay network topology</strong></p><p><em>Source：</em><a href="https://community.cisco.com/t5/data-center-switches/understanding-underlay-and-overlay-networks/td-p/4295870">https://community.cisco.com/t5/data-center-switches/understanding-underlay-and-overlay-networks/td-p/4295870</a></p><p><em>underlay network</em> 可以是二层，也可以是三层；二层 <em>underlay network</em> 的典型例子是以太网 <em>Ethernet</em>，三层是 <em>underlay network</em> 的典型例子是互联网 <em>Internet</em>。</p><p>而工作与二层的技术是 <em>vlan</em>，工作在三层的技术是由 <em>OSPF</em>, <em>BGP</em> 等协议组成</p><h3 id="kubernetes中的underlay-network"><a href="#kubernetes中的underlay-network" class="headerlink" title="kubernetes中的underlay network"></a>kubernetes中的underlay network</h3><p>在kubernetes中，<em>underlay network</em> 中比较典型的例子是通过将宿主机作为路由器设备，Pod 的网络则通过学习成路由条目从而实现跨节点通讯。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyqjHDK7dv8WtgBpibmbozUC7wo5zWdEDlIkoK03vxpv5QoR7ciaVNKzTw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                  <strong>图：underlay network topology in kubernetes</strong></p><p>这种模型下典型的有 <em>flannel</em> 的 <em>host-gw</em> 模式与 <em>calico</em> <em>BGP</em> 模式。</p><h4 id="flannel-host-gw-1"><a href="#flannel-host-gw-1" class="headerlink" title="flannel host-gw [1]"></a>flannel host-gw [1]</h4><p><em>flannel host-gw</em> 模式中每个Node需要在同一个二层网络中，并将Node作为一个路由器，跨节点通讯将通过路由表方式进行，这样方式下将网络模拟成一个<em>underlay network</em>。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyDLPDv7ZTCW14W1wtUs1SbR9yOcibm3ncwCd6dJV7C076XoSovLehaZA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                         <strong>图：layer2 ethernet topology</strong></p><p><em>Source：</em><a href="https://www.auvik.com/franklyit/blog/layer-3-switches-layer-2/">https://www.auvik.com/franklyit/blog/layer-3-switches-layer-2/</a></p><blockquote><p>Notes：因为是通过路由方式，集群的cidr至少要配置16，因为这样可以保证，跨节点的Node作为一层网络，同节点的Pod作为一个网络。如果不是这种用情况，路由表处于相同的网络中，会存在网络不可达</p></blockquote><h4 id="Calico-BGP-2"><a href="#Calico-BGP-2" class="headerlink" title="Calico BGP [2]"></a>Calico BGP [2]</h4><p>BGP（<em>Border Gateway Protocol</em>）是去中心化自治路由协议。它是通过维护IP路由表或’前缀’表来实现AS （<em>Autonomous System</em>）之间的可访问性，属于向量路由协议。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyGwaHm71fY1JAaOyWcdvfX0gjcO0e61aB56kskOgdjsLSmiayBoaLeQg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                  <strong>图：BGP network topology</strong></p><p><em>Source：</em><a href="https://infocenter.nokia.com/public/7705SAR214R1A/index.jsp?topic=/com.sar.routing_protocols%25">https://infocenter.nokia.com/public/7705SAR214R1A/index.jsp?topic=%2Fcom.sar.routing_protocols%</a></p><p>与 <em>flannel</em> 不同的是，<em>Calico</em> 提供了的 <em>BGP</em> 网络解决方案，在网络模型上，<em>Calico</em> 与 <em>Flannel host-gw</em> 是近似的，但在软件架构的实现上，<em>flannel</em> 使用 <em>flanneld</em> 进程来维护路由信息；而 <em>Calico</em> 是包含多个守护进程的，其中 <em>Brid</em> 进程是一个 <em>BGP</em> 的客户端 与路由反射器(<em>Router Reflector</em>)，<em>BGP</em> 客户端负责从 <em>Felix</em> 中获取路由并分发到其他 <em>BGP Peer</em>，而反射器在BGP中起了优化的作用。在同一个IBGP中，BGP客户端仅需要和一个 <em>RR</em> 相连，这样减少了<em>AS</em>内部维护的大量的BGP连接。通常情况下，<em>RR</em> 是真实的路由设备，而 <em>Bird</em> 作为 <em>BGP</em> 客户端工作。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyfEXWkGJTBS8TSt3pksPGe18LTicxXWDvCnTZXPibJrJ5Og5oE1wOHibrQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                       <strong>图：Calico Network Architecture</strong></p><p><em>Source：</em><a href="https://www.cisco.com/c/en/us/td/docs/dcn/whitepapers/cisco-nx-os-calico-network-design.html">https://www.cisco.com/c/en/us/td/docs/dcn/whitepapers/cisco-nx-os-calico-network-design.html</a></p><h4 id="IPVLAN-amp-MACVLAN-4"><a href="#IPVLAN-amp-MACVLAN-4" class="headerlink" title="IPVLAN &amp; MACVLAN [4]"></a>IPVLAN &amp; MACVLAN [4]</h4><p><em>IPVLAN</em> 和 <em>MACVLAN</em> 是一种网卡虚拟化技术，两者之间的区别为， <em>IPVLAN</em> 允许一个物理网卡拥有多个IP地址，并且所有的虚拟接口用同一个MAC地址；而 <em>MACVLAN</em> 则是相反的，其允许同一个网卡拥有多个MAC地址，而虚拟出的网卡可以没有IP地址。</p><p>因为是网卡虚拟化技术，而不是网络虚拟化技术，本质上来说属于 <em>Overlay network</em>，这种方式在虚拟化环境中与<em>Overlay network</em> 相比最大的特点就是可以将Pod的网络拉平到Node网络同级，从而提供更高的性能、低延迟的网络接口。本质上来说其网络模型属于下图中第二个。</p><ul><li>虚拟网桥：创建一个虚拟网卡对(veth pair)，一头栽容器内，一头栽宿主机的root namespaces内。这样一来容器内发出的数据包可以通过网桥直接进入宿主机网络栈，而发往容器的数据包也可以经过网桥进入容器。</li><li>多路复用：使用一个中间网络设备，暴露多个虚拟网卡接口，容器网卡都可以介入这个中间设备，并通过MAC&#x2F;IP地址来区分packet应该发往哪个容器设备。</li><li>硬件交换，为每个Pod分配一个虚拟网卡，这样一来，Pod与Pod之间的连接关系就会变得非常清晰，因为近乎物理机之间的通信基础。如今大多数网卡都支持SR-IOV功能，该功能将单一的物理网卡虚拟成多个VF接口，每个VF接口都有单独的虚拟PCIe通道，这些虚拟的PCIe通道共用物理网卡的PCIe通道。</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyXl7hJSbrKicdnPZLbNhads4BrWPwDS78RZJIAtodUb5v8m0mWtkmiaDQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                           <strong>图：Virtual networking modes: bridging, multiplexing and SR-IOV</strong></p><p><em>Source：</em><a href="https://thenewstack.io/hackers-guide-kubernetes-networking/">https://thenewstack.io/hackers-guide-kubernetes-networking/</a></p><p>在kubernetes中 <em>IPVLAN</em> 这种网络模型下典型的CNI有，multus 与 danm。</p><h5 id="multus"><a href="#multus" class="headerlink" title="multus"></a>multus</h5><p><em>multus</em> 是 intel 开源的CNI方案，是由传统的 <em>cni</em> 与 <em>multus</em> 组成，并且提供了 SR-IOV CNI 插件使 K8s pod 能够连接到 SR-IOV VF 。这是使用了 <em>IPVLAN&#x2F;MACVLAN</em> 的功能。</p><p>当创建新的Pod后，SR-IOV 插件开始工作。配置 VF 将被移动到新的 CNI 名称空间。该插件根据 CNI 配置文件中的 “name” 选项设置接口名称。最后将VF状态设置为UP。</p><p>下图是一个 Multus 和 SR-IOV CNI 插件的网络环境，具有三个接口的 pod。</p><ul><li><em>eth0</em> 是 <em>flannel</em> 网络插件，也是作为Pod的默认网络</li><li>VF 是主机的物理端口 <em>ens2f0</em> 的实例化。这是英特尔X710-DA4上的一个端口。在Pod端的 VF 接口名称为 <em>south0</em> 。</li><li>这个VF使用了 DPDK 驱动程序，此 VF 是从主机的物理端口 <em>ens2f1</em> 实例化出的。这个是英特尔® X710-DA4上另外一个端口。Pod 内的 VF 接口名称为 <em>north0</em>。该接口绑定到 DPDK 驱动程序 <em>vfio-pci</em> 。</li></ul><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxy1fqm6eakBu9XZT59bervsUvIFp2pF4fteTOULSaV24NIaSTFaTCuYA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                      <strong>图：Mutus networking Architecture overlay and SR-IOV</strong></p><p><em>Source：</em><a href="https://builders.intel.com/docs/networkbuilders/enabling_new_features_in_kubernetes_for_NFV.pdf">https://builders.intel.com/docs/networkbuilders/enabling_new_features_in_kubernetes_for_NFV.pdf</a></p><blockquote><p>Notes：terminology</p><ul><li>NIC：network interface card，网卡</li><li>SR-IOV：single root I&#x2F;O virtualization，硬件实现的功能，允许各虚拟机间共享PCIe设备。</li><li>VF：Virtual Function，基于PF，与PF或者其他VF共享一个物理资源。</li><li>PF：PCIe Physical Function，拥有完全控制PCIe资源的能力</li><li>DPDK：Data Plane Development Kit</li></ul></blockquote><p>于此同时，也可以将主机接口直接移动到Pod的网络名称空间，当然这个接口是必须存在，并且不能是与默认网络使用同一个接口。这种情况下，在普通网卡的环境中，就直接将Pod网络与Node网络处于同一个平面内了。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyBpQH5b5UoWxWhM0YKPIVBW25oZLowbR6BuCu8ZGf0zXeiatS7zxudTw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                         <strong>图：Mutus networking Architecture overlay and ipvlan</strong></p><p><em>Source：</em><a href="https://devopstales.github.io/kubernetes/multus/">https://devopstales.github.io/kubernetes/multus/</a></p><h5 id="danm"><a href="#danm" class="headerlink" title="danm"></a>danm</h5><p>DANM是诺基亚开源的CNI项目，目的是将电信级网络引入kubernetes中，与multus相同的是，也提供了SR-IOV&#x2F;DPDK 的硬件技术，并且支持IPVLAN.</p><h2 id="Overlay-Network-Model"><a href="#Overlay-Network-Model" class="headerlink" title="Overlay Network Model"></a>Overlay Network Model</h2><h3 id="什么是Overlay"><a href="#什么是Overlay" class="headerlink" title="什么是Overlay"></a>什么是Overlay</h3><p>叠加网络是使用网络虚拟化技术，在 <em>underlay</em> 网络上构建出的虚拟逻辑网络，而无需对物理网络架构进行更改。本质上来说，<em>overlay network</em> 使用的是一种或多种隧道协议 (<em>tunneling</em>)，通过将数据包封装，实现一个网络到另一个网络中的传输，具体来说隧道协议关注的是数据包（帧）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyyGkhSJE7WhbUna4s0mvzghkvGDCgPsPNtmibTUAtIWYfCRLdkGSasGQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>图：overlay network topology</p><p><em>Source：</em><a href="https://www.researchgate.net/figure/Example-Overlay-Network-built-on-top-of-an-Internet-style-Underlay_fig4_230774628">https://www.researchgate.net/figure/Example-Overlay-Network-built-on-top-of-an-Internet-style-Underlay_fig4_230774628</a></p><h3 id="常见的网络隧道技术"><a href="#常见的网络隧道技术" class="headerlink" title="常见的网络隧道技术"></a>常见的网络隧道技术</h3><ul><li>通用路由封装 ( <em>Generic Routing Encapsulation</em> ) 用于将来自 IPv4&#x2F;IPv6的数据包封装为另一个协议的数据包中，通常工作与L3网络层中。</li><li>VxLAN (<em>Virtual Extensible LAN</em>)，是一个简单的隧道协议，本质上是将L2的以太网帧封装为L4中UDP数据包的方法，使用 4789 作为默认端口。<em>VxLAN</em> 也是 <em>VLAN</em> 的扩展对于 4096（212 位 <em>VLAN ID</em>） 扩展为1600万（224 位 <em>VNID</em> ）个逻辑网络。</li></ul><p>这种工作在 <em>overlay</em> 模型下典型的有 <em>flannel</em> 与 <em>calico</em> 中的的 <em>VxLAN</em>, <em>IPIP</em> 模式。</p><h3 id="IPIP"><a href="#IPIP" class="headerlink" title="IPIP"></a>IPIP</h3><p><em>IP in IP</em> 也是一种隧道协议，与 <em>VxLAN</em> 类似的是，<em>IPIP</em> 的实现也是通过Linux内核功能进行的封装。<em>IPIP</em> 需要内核模块 <code>ipip.ko</code> 使用命令查看内核是否加载IPIP模块<code>lsmod | grep ipip</code> ；使用命令<code>modprobe ipip</code> 加载。</p><p><img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/640" alt="图片"></p><p>图：A simple IPIP network workflow</p><p><em>Source：</em><a href="https://ssup2.github.io/theory_analysis/IPIP_GRE_Tunneling/">https://ssup2.github.io/theory_analysis/IPIP_GRE_Tunneling/</a></p><p>Kubernetes中 <em>IPIP</em> 与 <em>VxLAN</em> 类似，也是通过网络隧道技术实现的。与 <em>VxLAN</em> 差别就是，<em>VxLAN</em> 本质上是一个 UDP包，而 <em>IPIP</em> 则是将包封装在本身的报文包上。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxybmxBiantAKWVD2nlCUNBHAIQkHSOJZcQeM4znchxeRqicRNvh3pcPIMw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                         <strong>图：IPIP in kubernetes</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyNfkHJrC9xJw6SzZRFND1XdRacXJ6A7utD0RYvRyj7qOwJPzM60YiaeA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                         <strong>图：IPIP packet with wireshark unpack</strong></p><blockquote><p>Notes：公有云可能不允许IPIP流量，例如Azure</p></blockquote><h3 id="VxLAN"><a href="#VxLAN" class="headerlink" title="VxLAN"></a>VxLAN</h3><p>kubernetes中不管是 <em>flannel</em> 还是 <em>calico</em> VxLAN的实现都是使用Linux内核功能进行的封装，Linux 对 vxlan 协议的支持时间并不久，2012 年 Stephen Hemminger 才把相关的工作合并到 kernel 中，并最终出现在 kernel 3.7.0 版本。为了稳定性和很多的功能，你可以会看到某些软件推荐在 3.9.0 或者 3.10.0 以后版本的 kernel 上使用 <em>VxLAN</em>。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyVuvdFPpJgI1QG5U2MHUib3DbBGia1HVB6sicRiadIptJxM0B7nUXaCSqYQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                             <strong>图：A simple VxLAN network topology</strong></p><p>在kubernetes中vxlan网络，例如 <em>flannel</em>，守护进程会根据kubernetes的Node而维护 <em>VxLAN</em>，名称为 <code>flannel.1</code> 这是 <em>VNID</em>，并维护这个网络的路由，当发生跨节点的流量时，本地会维护对端 <em>VxLAN</em> 设备的MAC地址，通过这个地址可以知道发送的目的端，这样就可以封包发送到对端，收到包的对端 VxLAN设备 <code>flannel.1</code> 解包后得到真实的目的地址。</p><p>查看 <em>Forwarding database</em> 列表</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-variable">$ </span>bridge fdb <span class="hljs-number">26</span><span class="hljs-symbol">:</span>5<span class="hljs-symbol">e:</span><span class="hljs-number">87</span><span class="hljs-symbol">:</span><span class="hljs-number">90</span><span class="hljs-symbol">:</span><span class="hljs-number">91</span><span class="hljs-symbol">:fc</span> dev flannel.<span class="hljs-number">1</span> dst <span class="hljs-number">10.0</span>.<span class="hljs-number">0.3</span> <span class="hljs-variable language_">self</span> permanent<br></code></pre></td></tr></table></figure><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyib50Tia4cxibibR5uhmL4eO4m158hQFxZsiaWaqYE9vH2Fflee6aEaEACJg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                      <strong>图：VxLAN in kubernetes</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxyCSReVTSz26R2z2ibGa2HvNuTjwKI8tQHHv14amJr1eoOTw05gpMc5mg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                       <strong>图：VxLAN packet with wireshark unpack</strong></p><blockquote><p>Notes：VxLAN使用的4789端口，wireshark应该是根据端口进行分析协议的，而flannel在linux中默认端口是8472，此时抓包仅能看到是一个UDP包。</p></blockquote><p>通过上述的架构可以看出，隧道实际上是一个抽象的概念，并不是建立的真实的两端的隧道，而是通过将数据包封装成另一个数据包，通过物理设备传输后，经由相同的设备（网络隧道）进行解包实现网络的叠加。</p><h3 id="weave-vxlan-3"><a href="#weave-vxlan-3" class="headerlink" title="weave vxlan [3]"></a>weave vxlan [3]</h3><p>weave也是使用了 <em>VxLAN</em> 技术完成的包的封装，这个技术在 <em>weave</em> 中称之为 *fastdp (fast data path)*，与 <em>calico</em> 和 <em>flannel</em> 中用到的技术不同的，这里使用的是 Linux 内核中的 <em>openvswitch datapath module</em>，并且weave对网络流量进行了加密。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/D727NicjCjMOfSoHgRPZfL1ZzWoqxIyxy1r4xqNRVbh6Ua8kaalhWPbicCYYI0CcbC3tLeuoMGHxLX6zLqmEOiawA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                           <strong>图：weave fastdp network topology</strong></p><p><em>Source：</em><a href="https://www.weave.works/docs/net/latest/concepts/fastdp-how-it-works/">https://www.weave.works/docs/net/latest/concepts/fastdp-how-it-works/</a></p><blockquote><p>Notes：fastdp工作在Linux 内核版本 3.12 及更高版本，如果低于此版本的例如CentOS7，weave将工作在用户空间，weave中称之为 <em>sleeve mode</em></p></blockquote><p>Reference</p><p>[1] flannel host-gw</p><p>[2] calico bgp networking</p><p>[3] calico bgp networking</p><p>[4] sriov network</p><p>[5] danm</p><p>作者：Cylon</p><p>出处：<a href="https://www.cnblogs.com/Cylon/p/16595820.html">https://www.cnblogs.com/Cylon/p/16595820.html</a></p>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang对比Java、python为什么要保留指针</title>
    <link href="/2022/09/05/Golang%E5%AF%B9%E6%AF%94Java%E3%80%81python%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BF%9D%E7%95%99%E6%8C%87%E9%92%88/"/>
    <url>/2022/09/05/Golang%E5%AF%B9%E6%AF%94Java%E3%80%81python%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E4%BF%9D%E7%95%99%E6%8C%87%E9%92%88/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang对比Java、python为什么要保留指针"><a href="#Golang对比Java、python为什么要保留指针" class="headerlink" title="Golang对比Java、python为什么要保留指针"></a>Golang对比Java、python为什么要保留指针</h1><h2 id="为什么要用指针？"><a href="#为什么要用指针？" class="headerlink" title="为什么要用指针？"></a>为什么要用指针？</h2><p>平时我们在Golang使用指针一般是为了以下的情况：</p><ul><li><strong>方法直接修改原来对象</strong></li><li><strong>保证参数传递的自由，可以在传递重量级对象时使用指针</strong></li></ul><p>但Go 保留指针不仅仅是为了解决传递参数的问题，还跟它的语言特性有密不可分的联系。</p><h2 id="值语义"><a href="#值语义" class="headerlink" title="值语义"></a>值语义</h2><p>Go 里面的变量是<strong>值语义</strong>，这个跟 C&#x2F;C++是一脉相承的。比如一个结构体变量赋值给另外一个变量就是一次内存拷贝，而不是只拷贝一个指针，因此需要指针来表达引用语义，关于拷贝的具体实现可以了解<a href="https://gfw.go101.org/article/value-part.html">直接值部与间接值部的实现</a>。</p><p>关于值语义(value semantics)：<strong>值语义</strong>指的是对象的拷贝与原对象无关，就像拷贝 int 一样。C++ 的内置类型(bool&#x2F;int&#x2F;double&#x2F;char)都是值语义，标准库里的 complex&lt;&gt; 、pair&lt;&gt;、vector&lt;&gt;、map&lt;&gt;、string 等等类型也都是值语意，拷贝之后就与原对象脱离关系。同样，Java 语言的 primitive types 也是值语义。</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p><strong>复杂的高级类型占用的内存往往相对较大，存储在 <a href="https://www.zhihu.com/search?q=heap&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:1665421830%7D">heap</a> 中，GC 回收频率相对较低，代价也较大，因此传引用&#x2F;指针可以避免进行成本较高的复制操作，并且节省内存，提高程序运行效率。</strong></p><p>为什么要保留值语义，而不是像 Java 或者 Python 一样让复合类型默认都是指针类型呢？因为值语义带来了如下好处：</p><ul><li><strong><a href="https://www.zhihu.com/search?q=%E7%BB%93%E6%9E%84%E4%BD%93&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2242103027%7D">结构体</a>可以直接用来比较相等，而非比较指针，Java 里面的 &#x3D;&#x3D; 操作符除了基本类型有用，其他类型几乎没用。</strong></li><li><strong>与 C 语言更好地交互。Go 可以通过 cgo 与 C 语言无缝交互。Go 里面的结构体基本上不用特殊处理就能传递给 C 的函数使用。主要得益于 Go 的结构体和 C 的一样都是值类型。</strong></li><li><strong>开发者能更好的掌控内存布局。一个结构体数组就是一段连续内存，而不是一个指针数组。</strong></li><li><strong>减轻 GC 压力。紧凑的内存布局减少了 GC 对象的个数，比如一个100w 长度的结构体数组就是一个 GC 对象，而不是100w 个。</strong></li><li><strong>减轻堆内存的分配压力。函数通过传值的方式传递参数后，原变量不会发生逃逸，可以被分配在栈上</strong></li></ul><p>Go 为了内存安全，虽然有指针，但不支持指针算数，但结合 unsafe.Pointer 也可以完成一些非常规情景下的精细内存操作。比如结合 <a href="https://www.zhihu.com/search?q=mmap&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra=%7B%22sourceType%22:%22answer%22,%22sourceId%22:2242103027%7D">mmap</a> 实现堆外内存管理，runtime 里面的内存管理就是这么来的，完全不用另外用 C 语言来实现。 这也是可以使用 Go 语言来写操作系统（<a href="https://link.zhihu.com/?target=https://github.com/icexin/eggos">eggos</a>）的原因。</p><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p><strong>Go 的指针一方面提供了引用语义，另一方面像 C 语言一样给了开发者灵活管理内存的能力。</strong></p><p>参考链接：樊冰心：<a href="https://www.zhihu.com/question/399589293/answer/2242103027">https://www.zhihu.com/question/399589293/answer/2242103027</a></p>]]></content>
    
    
    <categories>
      
      <category>golang vs java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
      <tag>java</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>编程范式之泛型编程</title>
    <link href="/2022/09/04/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E4%B9%8B%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/"/>
    <url>/2022/09/04/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F%E4%B9%8B%E6%B3%9B%E5%9E%8B%E7%BC%96%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="编程范式之泛型编程"><a href="#编程范式之泛型编程" class="headerlink" title="编程范式之泛型编程"></a>编程范式之泛型编程</h1><h3 id="C-语言的泛型"><a href="#C-语言的泛型" class="headerlink" title="C 语言的泛型"></a>C 语言的泛型</h3><h3 id="一个泛型的示例-swap-函数"><a href="#一个泛型的示例-swap-函数" class="headerlink" title="一个泛型的示例 - swap 函数"></a>一个泛型的示例 - swap 函数</h3><p>好了，我们再看下，C 语言是如何泛型的。C 语言的类型泛型基本上来说就是使用<code>void *</code>关键字或是使用宏定义。</p><p>下面是一个使用了<code>void*</code>泛型版本的 swap 函数。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs C"><span class="hljs-type">void</span> <span class="hljs-title function_">swap</span><span class="hljs-params">(<span class="hljs-type">void</span>* x, <span class="hljs-type">void</span>* y, <span class="hljs-type">size_t</span> size)</span><br>&#123;<br>     <span class="hljs-type">char</span> tmp[size];<br>     <span class="hljs-built_in">memcpy</span>(tmp, y, size);<br>     <span class="hljs-built_in">memcpy</span>(y, x, size);<br>     <span class="hljs-built_in">memcpy</span>(x, tmp, size);<br>&#125;<br></code></pre></td></tr></table></figure><p>上面这个函数几乎完全改变了 int 版的函数的实现方式，这个实现方式有三个重点：</p><ul><li><strong>函数接口中增加了一个<code>size</code>参数</strong>。为什么要这么干呢？因为，用了 <code>void*</code> 后，类型被“抽象”掉了，编译器不能通过类型得到类型的尺寸了，所以，需要我们手动地加上一个类型长度的标识。</li><li><strong>函数的实现中使用了<code>memcpy()</code>函数</strong>。为什么要这样干呢？还是因为类型被“抽象”掉了，所以不能用赋值表达式了，很有可能传进来的参数类型还是一个结构体，因此，为了要交换这些复杂类型的值，我们只能使用内存复制的方法了。</li><li><strong>函数的实现中使用了一个<code>temp[size]</code>数组</strong>。这就是交换数据时需要用的 buffer，用 buffer 来做临时的空间存储。</li></ul><p>于是，新增的<code>size</code>参数，使用的<code>memcpy</code>内存拷贝以及一个 buffer，这增加了编程的复杂度。这就是 C 语言的类型抽象所带来的复杂度的提升。</p><p>在提升复杂度的同时，我们发现还有问题，比如，我们想交换两个字符串数组，类型是：<code>char*</code>，那么，我的<code>swap()</code>函数的<code>x</code>和<code>y</code>参数是不是要用<code>void**</code>了？这样一来，接口就没法定义了。</p><p>除了使用 <code>void*</code> 来做泛型，在 C 语言中，还可以用宏定义来做泛型，如下所示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> swap(x, y, size) &#123;\</span><br><span class="hljs-meta">char temp[size]; \</span><br><span class="hljs-meta">memcpy(temp, &amp;y, size); \</span><br><span class="hljs-meta">memcpy(&amp;y,   &amp;x, size); \</span><br><span class="hljs-meta">memcpy(&amp;x, temp, size); \</span><br><span class="hljs-meta">&#125;</span><br></code></pre></td></tr></table></figure><p>但用宏带来的问题就是编译器做字符串替换，因为宏是做字符串替换，所以会导致代码膨胀，导致编译出的执行文件比较大。不过对于 swap 这个简单的函数来说，用<code>void*</code>和宏替换来说都可以达到泛型。</p><p>但是，如果我们不是 swap，而是 min() 或 max() 函数，那么宏替换的问题就会暴露得更多一些。比如，对于下面的这个宏：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> min(x, y)  （(x)&gt;(y) ? (y) : (x)）</span><br></code></pre></td></tr></table></figure><p>其中一个最大的问题，就是有可能会有<strong>重复执行</strong>的问题。</p><h3 id="C-泛型编程"><a href="#C-泛型编程" class="headerlink" title="C++ 泛型编程"></a>C++ 泛型编程</h3><p>C++ 泛型版的代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">typename</span> T, <span class="hljs-keyword">typename</span> Iter&gt;</span><br><span class="hljs-function">Iter <span class="hljs-title">search</span><span class="hljs-params">(Iter pStart, Iter pEnd, T target)</span> </span><br><span class="hljs-function"></span>&#123;<br><span class="hljs-keyword">for</span>(Iter p = pStart; p != pEnd; p++) &#123;<br><span class="hljs-keyword">if</span> ( *p == target ) <br><span class="hljs-keyword">return</span> p;<br>&#125;<br><span class="hljs-keyword">return</span> <span class="hljs-literal">NULL</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>在 C++ 的泛型版本中，我们可以看到：</p><ul><li>使用<code>typename T</code>抽象了数据结构中存储数据的类型。</li><li>使用<code>typename Iter</code>，这是不同的数据结构需要自己实现的“迭代器”，这样也就抽象掉了不同类型的数据结构。</li><li>然后，我们对数据容器的遍历使用了<code>Iter</code>中的<code>++</code>方法，这是数据容器需要重载的操作符，这样通过操作符重载也就泛型掉了遍历。</li><li>在函数的入参上使用了<code>pStart</code>和<code>pEnd</code>来表示遍历的起止。</li><li>使用<code>*Iter</code>来取得这个“指针”的内容。这也是通过重载 <code>*</code> 取值操作符来达到的泛型。</li></ul><h3 id="Go-泛型编程"><a href="#Go-泛型编程" class="headerlink" title="Go 泛型编程"></a>Go 泛型编程</h3><p>go1.18开始可以支持泛型</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-keyword">package</span> main<br><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">find</span>[<span class="hljs-title">T</span> <span class="hljs-title">comparable</span>] <span class="hljs-params">(arr []T, elem T)</span></span> <span class="hljs-type">int</span> &#123;<br>  <span class="hljs-keyword">for</span> i, v := <span class="hljs-keyword">range</span> arr &#123;<br>    <span class="hljs-keyword">if</span>  v == elem &#123;<br>      <span class="hljs-keyword">return</span> i<br>    &#125;<br>  &#125;<br>  <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>&#125;<br></code></pre></td></tr></table></figure><p>Go语言的泛型已基本可用了，只不过，还有三个问题：</p><ul><li>一个是 <code>fmt.Printf()</code>中的泛型类型是 <code>%v</code> 还不够好，不能像c++ <code>iostream</code>重载 <code>&gt;&gt;</code> 来获得程序自定义的输出。</li><li>另外一个是，go不支持操作符重载，所以，你也很难在泛型算法中使用“泛型操作符”如：<code>==</code> 等</li><li>最后一个是，上面的 <code>find()</code> 算法依赖于“数组”，对于hash-table、tree、graph、link等数据结构还要重写。也就是说，没有一个像C++ STL那样的一个泛型迭代器（这其中的一部分工作当然也需要通过重载操作符（如：<code>++</code> 来实现）</li></ul><h3 id="Java泛型编程"><a href="#Java泛型编程" class="headerlink" title="Java泛型编程"></a>Java泛型编程</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型</span><br><span class="hljs-comment">//在实例化泛型类时，必须指定T的具体类型</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">Generic</span>&lt;T&gt;&#123; <br>    <span class="hljs-comment">//key这个成员变量的类型为T,T的类型由外部指定  </span><br>    <span class="hljs-keyword">private</span> T key;<br> <br>    <span class="hljs-keyword">public</span> <span class="hljs-title function_">Generic</span><span class="hljs-params">(T key)</span> &#123; <span class="hljs-comment">//泛型构造方法形参key的类型也为T，T的类型由外部指定</span><br>        <span class="hljs-built_in">this</span>.key = key;<br>    &#125;<br> <br>    <span class="hljs-keyword">public</span> T <span class="hljs-title function_">getKey</span><span class="hljs-params">()</span>&#123; <span class="hljs-comment">//泛型方法getKey的返回值类型为T，T的类型由外部指定</span><br>        <span class="hljs-keyword">return</span> key;<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure><h3 id="类型系统"><a href="#类型系统" class="headerlink" title="类型系统"></a>类型系统</h3><p>在计算机科学中，类型系统用于定义如何将编程语言中的数值和表达式归类为许多不同的类型，以及如何操作这些类型，还有这些类型如何互相作用。类型可以确认一个值或者一组值具有特定的意义和目的。</p><p>一般来说，编程语言会有两种类型，一种是内建类型，如 int、float 和 char 等，一种是抽象类型，如 struct、class 和 function 等。抽象类型在程序运行中，可能不表示为值。类型系统在各种语言之间有非常大的不同，也许，最主要的差异存在于编译时期的语法，以及运行时期的操作实现方式。</p><p>编译器可能使用值的静态类型以最优化所需的存储区，并选取对数值运算时的最佳算法。例如，在许多 C 编译器中，“浮点数”数据类型是以 32 比特表示、与 IEEE 754 规格一致的单精度浮点数。因此，在数值运算上，C 应用了浮点数规范（浮点数加法、乘法等）。</p><p>类型的约束程度以及评估方法，影响了语言的类型。更进一步，编程语言可能就类型多态性部分，对每一个类型都对应了一个针对于这个类型的算法运算。类型理论研究类型系统，尽管实际的编程语言类型系统，起源于计算机架构的实际问题、编译器实现，以及语言设计。</p><p>程序语言的类型系统主要提供如下的功能。</p><ul><li><strong>程序语言的安全性</strong>。使用类型可以让编译器侦测一些代码的错误。例如：可以识别出一个错误无效的表达式。如：<code>“Hello, World” + 3</code>这样的不同数据类型间操作的问题。强类型语言提供更多的安全性，但是并不能保证绝对的安全。</li><li><strong>利于编译器的优化</strong>。 静态类型语言的类型声明，可以让编译器明确地知道程序员的意图。因此，编译器就可以利用这一信息做很多代码优化工作。例如：如果我们指定一个类型是 <code>int</code> ，那么编译就知道，这个类型会以 4 个字节的倍数进行对齐，编译器就可以非常有效地利用更有效率的机器指令。</li><li><strong>代码的可读性</strong>。有类型的编程语言，可以让代码更易读和更易维护。代码的语义也更清楚，代码模块的接口（如函数）也更丰富和清楚。</li><li><strong>抽象化</strong>。类型允许程序设计者对程序以较高层次的方式思考，而不是烦人的低层次实现。例如，我们使用整型或是浮点型来取代底层的字节实现，我们可以将字符串设计成一个值，而不是底层字节的数组。从高层上来说，类型可以用来定义不同模块间的交互协议，比如函数的入参类型和返回类型，从而可以让接口更有语义，而且不同的模块数据交换更为直观和易懂。</li></ul><p>但是，正如前面说的，<strong>类型带来的问题就是我们作用于不同类型的代码，虽然长得非常相似，但是由于类型的问题需要根据不同版本写出不同的算法，如果要做到泛型，就需要涉及比较底层的玩法</strong>。</p><h3 id="泛型的本质"><a href="#泛型的本质" class="headerlink" title="泛型的本质"></a>泛型的本质</h3><p>要了解泛型的本质，就需要了解类型的本质。</p><ul><li>类型是对内存的一种抽象。不同的类型，会有不同的内存布局和内存分配的策略。</li><li>不同的类型，有不同的操作。所以，对于特定的类型，也有特定的一组操作。</li></ul><p>所以，要做到泛型，我们需要做下面的事情。</p><ul><li>标准化掉类型的内存分配、释放和访问。</li><li>标准化掉类型的操作。比如：比较操作，I&#x2F;O 操作，复制操作……</li><li>标准化掉数据容器的操作。比如：查找算法、过滤算法、聚合算法……</li><li>标准化掉类型上特有的操作。需要有标准化的接口来回调不同类型的具体操作……</li></ul><p>所以，C++ 动用了非常繁多和复杂的技术来达到泛型编程的目标。</p><ul><li>通过类中的构造、析构、拷贝构造，重载赋值操作符，标准化（隐藏）了类型的内存分配、释放和复制的操作。</li><li>通过重载操作符，可以标准化类型的比较等操作。</li><li>通过 iostream，标准化了类型的输入输出控制。</li><li>通过模板技术（包括模板的特化），来为不同的类型生成类型专属的代码。</li><li>通过迭代器来标准化数据容器的遍历操作。</li><li>通过面向对象的接口依赖（虚函数技术），来标准化了特定类型在特定算法上的操作。</li><li>通过函数式（函数对象），来标准化对于不同类型的特定操作。</li></ul><p>我理解其本质就是 —— <strong>屏蔽掉数据和操作数据的细节，让算法更为通用，让编程者更多地关注算法的结构，而不是在算法中处理不同的数据类型。</strong></p>]]></content>
    
    
    <categories>
      
      <category>编程范式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>左耳听风</tag>
      
      <tag>编程范式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo常用操作以及注意事项</title>
    <link href="/2022/09/03/hexo%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <url>/2022/09/03/hexo%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h2 id="新建文章"><a href="#新建文章" class="headerlink" title="新建文章"></a>新建文章</h2><blockquote><p>命令：<code>hexo new [layout] title</code>或 <code>hexo n [layout] title</code></p></blockquote><p>创建文章前要先选定模板，在hexo中也叫做布局。hexo支持三种布局（layout）：post(默认)、draft、page。我们先介绍如何使用已有布局，后面还将会介绍如何自定义布局。</p><p>在博客目录下输入以下命令时，会默认使用post布局，然后自动在<code>source\_posts</code>目录生成一个text1.md文件：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo n text1<br></code></pre></td></tr></table></figure><p>当然你还可以指定布局：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo n [layout_name] draft1<br></code></pre></td></tr></table></figure><p>该命令创建了一个使用特定布局的名为draft1的文章。</p><p>打开之前创建的text1.md文件，我们可以看到文章开头包含以下内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">text1</span><br><span class="hljs-attr">author:</span> <span class="hljs-string">longpi1</span><br><span class="hljs-attr">tags:</span> <span class="hljs-string">hexo</span><br><span class="hljs-attr">categories:</span> <span class="hljs-string">blog</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><p>上面的内容在hexo被称作<strong>Front-matter，实际上就是该文章的一些变量，用于实现一些特定的功能</strong>。比如使<code>author: longpi1</code>，那么渲染后的文章中将显示文章作者为<code>longpi1</code>。</p><h2 id="本地调试"><a href="#本地调试" class="headerlink" title="本地调试"></a>本地调试</h2><p>启动hexo本地服务器<code>hexo server</code> 或 <code>hexo s</code></p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">$ hexo s INFO  Start processingINFO  Hexo is running <span class="hljs-keyword">at</span> <span class="hljs-keyword">http</span>://localhost:<span class="hljs-number">4000</span>/. Press Ctrl+C <span class="hljs-built_in">to</span> <span class="hljs-built_in">stop</span>.<br></code></pre></td></tr></table></figure><p>在浏览器输入 <a href="http://localhost:4000/">http://localhost:4000/</a> 进行预览，回到Git Bash输入<code>Ctrl+C</code>关闭本地服务器退出预览。</p><p>指定端口：<br><code>hexo s -p 8080</code></p><p>自定义 IP<br>服务器默认运行在 0.0.0.0，您可以覆盖默认的 IP 设置，如下：<br><code>hexo server -i 192.168.1.1</code></p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p><code>hexo d</code> 或 <code>hexo deploy</code><br><code>hexo d -g</code> 部署之前预先生成静态文件</p><h3 id="关于部署后原来的CNAME文件被覆盖的问题"><a href="#关于部署后原来的CNAME文件被覆盖的问题" class="headerlink" title="关于部署后原来的CNAME文件被覆盖的问题"></a>关于部署后原来的CNAME文件被覆盖的问题</h3><p>解决：CNAME,README,404.html都可以放在Hexo&#x2F;source文件夹下，<code>hexo g</code>生成博客时会被原封不动的拷贝到public文件夹中，部署后自然就到了项目的根目录。</p>]]></content>
    
    
    <categories>
      
      <category>hexo</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分布式系统笔记</title>
    <link href="/2022/08/28/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/08/28/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="传统单体架构和分布式服务化架构的区别"><a href="#传统单体架构和分布式服务化架构的区别" class="headerlink" title="传统单体架构和分布式服务化架构的区别"></a>传统单体架构和分布式服务化架构的区别</h2><p><img src="https://static001.geekbang.org/resource/image/8f/91/8fecccec610626a3e348318b1fd17791.png?wh=1084*724" alt="img"></p><p><strong>存在的问题：</strong></p><ul><li>架构设计变得复杂（尤其是其中的分布式事务）。</li><li>部署单个服务会比较快，但是如果一次部署需要多个服务，流程会变得复杂。</li><li>系统的吞吐量会变大，但是响应时间会变长。</li><li>运维复杂度会因为服务变多而变得很复杂。</li><li>架构复杂导致学习曲线变大。</li><li>测试和查错的复杂度增大。</li><li>技术多元化，这会带来维护和运维的复杂度。</li><li>管理分布式系统中的服务和调度变得困难和复杂。</li></ul><h2 id="分布式系统的目的以及相关技术"><a href="#分布式系统的目的以及相关技术" class="headerlink" title="分布式系统的目的以及相关技术"></a>分布式系统的目的以及相关技术</h2><p><strong>构建分布式系统的目的是增加系统容量，提高系统的可用性，转换成技术方面，也就是完成下面两件事。</strong></p><ul><li><strong>大流量处理。</strong>通过集群技术把大规模并发请求的负载分散到不同的机器上。</li><li><strong>关键业务保护。</strong>提高后台服务的可用性，把故障隔离起来阻止多米诺骨牌效应（雪崩效应）。如果流量过大，需要对业务降级，以保护关键业务流转。</li></ul><h3 id="提高架构的性能"><a href="#提高架构的性能" class="headerlink" title="提高架构的性能"></a>提高架构的性能</h3><p><img src="https://static001.geekbang.org/resource/image/a9/17/a9edeae125a80f381003d8d9d0056317.png?wh=863*321" alt="img"></p><ul><li><strong>缓存系统。</strong>加入缓存系统，可以有效地提高系统的访问能力。从前端的浏览器，到网络，再到后端的服务，底层的数据库、文件系统、硬盘和 CPU，全都有缓存，这是提高快速访问能力最有效的手段。对于分布式系统下的缓存系统，需要的是一个缓存集群。这其中需要一个 Proxy 来做缓存的分片和路由。</li><li><strong>负载均衡系统。</strong>负载均衡系统是水平扩展的关键技术，它可以使用多台机器来共同分担一部分流量请求。</li><li><strong>异步调用。</strong>异步系统主要通过消息队列来对请求做排队处理，这样可以把前端的请求的峰值给“削平”了，而后端通过自己能够处理的速度来处理请求。这样可以增加系统的吞吐量，但是实时性就差很多了。同时，还会引入消息丢失的问题，所以要对消息做持久化，这会造成“有状态”的结点，从而增加了服务调度的难度。</li><li><strong>数据分区和数据镜像。数据分区</strong>是把数据按一定的方式分成多个区（比如通过地理位置），不同的数据区来分担不同区的流量。这需要一个数据路由的中间件，会导致跨库的 Join 和跨库的事务非常复杂。而<strong>数据镜像</strong>是把一个数据库镜像成多份一样的数据，这样就不需要数据路由的中间件了。你可以在任意结点上进行读写，内部会自行同步数据。然而，数据镜像中最大的问题就是数据的一致性问题。</li></ul><h3 id="提高架构的稳定性"><a href="#提高架构的稳定性" class="headerlink" title="提高架构的稳定性"></a>提高架构的稳定性</h3><p><img src="https://static001.geekbang.org/resource/image/be/79/befd21e1b41a257c5028f8c1bc7fa279.png?wh=865*315" alt="img"></p><ul><li><strong>服务拆分。</strong>服务拆分主要有两个目的：一是为了隔离故障，二是为了重用服务模块。但服务拆分完之后，会引入服务调用间的依赖问题。</li><li><strong>服务冗余。</strong>服务冗余是为了去除单点故障，并可以支持服务的弹性伸缩，以及故障迁移。然而，对于一些有状态的服务来说，冗余这些有状态的服务带来了更高的复杂性。其中一个是弹性伸缩时，需要考虑数据的复制或是重新分片，迁移的时候还要迁移数据到其它机器上。</li><li><strong>限流降级。</strong>当系统实在扛不住压力时，只能通过限流或者功能降级的方式来停掉一部分服务，或是拒绝一部分用户，以确保整个架构不会挂掉。这些技术属于保护措施。</li><li><strong>高可用架构。</strong>通常来说高可用架构是从冗余架构的角度来保障可用性。比如，多租户隔离，灾备多活，或是数据可以在其中复制保持一致性的集群。总之，就是为了不出单点故障。</li><li><strong>高可用运维。</strong>高可用运维指的是 DevOps 中的 CI&#x2F;CD（持续集成 &#x2F; 持续部署）。一个良好的运维应该是一条很流畅的软件发布管线，其中做了足够的自动化测试，还可以做相应的灰度发布，以及对线上系统的自动化控制。这样，可以做到“计划内”或是“非计划内”的宕机事件的时长最短。</li></ul><h3 id="分布式系统的关键技术"><a href="#分布式系统的关键技术" class="headerlink" title="分布式系统的关键技术"></a>分布式系统的关键技术</h3><ul><li><strong>服务治理。</strong>服务拆分、服务调用、服务发现、服务依赖、服务的关键度定义……服务治理的最大意义是需要把服务间的依赖关系、服务调用链，以及关键的服务给梳理出来，并对这些服务进行性能和可用性方面的管理。</li><li><strong>架构软件管理。</strong>服务之间有依赖，而且有兼容性问题，所以，整体服务所形成的架构需要有架构版本管理、整体架构的生命周期管理，以及对服务的编排、聚合、事务处理等服务调度功能。</li><li><strong>DevOps。</strong>分布式系统可以更为快速地更新服务，但是对于服务的测试和部署都会是挑战。所以，还需要 DevOps 的全流程，其中包括环境构建、持续集成、持续部署等。</li><li><strong>自动化运维。</strong>有了 DevOps 后，我们就可以对服务进行自动伸缩、故障迁移、配置管理、状态管理等一系列的自动化运维技术了。</li><li><strong>资源调度管理。</strong>应用层的自动化运维需要基础层的调度支持，也就是云计算 IaaS 层的计算、存储、网络等资源调度、隔离和管理。</li><li><strong>整体架构监控。</strong>如果没有一个好的监控系统，那么自动化运维和资源调度管理只可能成为一个泡影，因为监控系统是你的眼睛。没有眼睛，没有数据，就无法进行高效运维。所以说，监控是非常重要的部分。这里的监控需要对三层系统（应用层、中间件层、基础层）进行监控。</li><li><strong>流量控制</strong>。最后是我们的流量控制，负载均衡、服务路由、熔断、降级、限流等和流量相关的调度都会在这里，包括灰度发布之类的功能也在这里。</li></ul><p><img src="https://static001.geekbang.org/resource/image/8e/db/8e92e2dff4f66147c014f930aa678fdb.jpg?wh=2556x1006" alt="img"></p><h3 id="全栈监控"><a href="#全栈监控" class="headerlink" title="全栈监控"></a>全栈监控</h3><p><strong>全栈监控，其实就是三层监控。</strong></p><ul><li><strong>基础层：</strong>监控主机和底层资源。比如：CPU、内存、网络吞吐、硬盘 I&#x2F;O、硬盘使用等。</li><li><strong>中间层：</strong>就是中间件层的监控。比如：Nginx、Redis、ActiveMQ、Kafka、MySQL、Tomcat 等。应用层：</li><li><strong>监控应用层的使用</strong>。比如：HTTP 访问的吞吐量、响应时间、返回码、调用链路分析、性能瓶颈，还包括用户端的监控。</li></ul><p><img src="https://static001.geekbang.org/resource/image/fe/4f/fe3aaf79df1565505cdac32494078a4f.jpg?wh=2145x1152" alt="img"></p><h4 id="什么才是好的监控系统"><a href="#什么才是好的监控系统" class="headerlink" title="什么才是好的监控系统"></a>什么才是好的监控系统</h4><p><strong>监控系统可能存在的问题：</strong></p><p>1.<strong>监控数据是隔离开来的。</strong>因为公司分工的问题，开发、应用运维、系统运维，各管各的，所以很多公司的监控系统之间都有一道墙，完全串不起来。</p><p><strong>2.监控的数据项太多。</strong>有些公司的运维团队把监控的数据项多作为一个亮点到处讲，比如监控指标达到 5 万多个。老实说，这太丢人了。因为信息太多等于没有信息，抓不住重点的监控才会做成这个样子，完全就是使蛮力的做法。</p><p><strong>好的监控系统有以下几个特征：</strong></p><ol><li><strong>关注于整体应用的 SLA（服务级别协议）。</strong>主要从为用户服务的 API 来监控整个系统。</li><li><strong>关联指标聚合。</strong>把有关联的系统及其指标聚合展示。主要是三层系统数据：基础层、平台中间件层和应用层。其中，最重要的是把服务和相关的中间件以及主机关联在一起，服务有可能运行在 Docker 中，也有可能运行在微服务平台上的多个 JVM 中，也有可能运行在 Tomcat 中。总之，无论运行在哪里，我们都需要把服务的具体实例和主机关联在一起，否则，对于一个分布式系统来说，定位问题犹如大海捞针。</li><li><strong>快速故障定位。</strong>对于现有的系统来说，故障总是会发生的，而且还会频繁发生。故障发生不可怕，可怕的是故障的恢复时间过长。所以，快速地定位故障就相当关键。快速定位问题需要对整个分布式系统做一个用户请求跟踪的 trace 监控，我们需要监控到所有的请求在分布式系统中的调用链，这个事最好是做成没有侵入性的。</li></ol><p><strong>以下两大主要功能实现</strong></p><h5 id="“体检”"><a href="#“体检”" class="headerlink" title="“体检”"></a>“体检”</h5><ul><li><strong>容量管理。</strong>提供一个全局的系统运行时数据的展示，可以让工程师团队知道是否需要增加机器或者其它资源。</li><li><strong>性能管理。</strong>可以通过查看大盘，找到系统瓶颈，并有针对性地优化系统和相应代码。</li></ul><h5 id="“急诊”"><a href="#“急诊”" class="headerlink" title="“急诊”"></a>“急诊”</h5><ul><li><strong>定位问题</strong>。可以快速地暴露并找到问题的发生点，帮助技术人员诊断问题。</li><li><strong>性能分析。</strong>当出现非预期的流量提升时，可以快速地找到系统的瓶颈，并帮助开发人员深入代码。</li></ul><p><strong>如何做出一个好的监控系统</strong></p><ul><li><strong>服务调用链跟踪。</strong>这个监控系统应该从对外的 API 开始，然后将后台的实际服务给关联起来，然后再进一步将这个服务的依赖服务关联起来，直到最后一个服务（如 MySQL 或 Redis），这样就可以把整个系统的服务全部都串连起来了。这个事情的最佳实践是 Google Dapper 系统，其对应于开源的实现是 Zipkin。对于 Java 类的服务，我们可以使用字节码技术进行字节码注入，做到代码无侵入式。</li><li><strong>服务调用时长分布。</strong>使用 Zipkin，可以看到一个服务调用链上的时间分布，这样有助于我们知道最耗时的服务是什么。下图是 Zipkin 的服务调用时间分布。</li><li><strong>服务的 TOP N 视图。</strong>所谓 TOP N 视图就是一个系统请求的排名情况。一般来说，这个排名会有三种排名的方法：a）按调用量排名，b) 按请求最耗时排名，c）按热点排名（一个时间段内的请求次数的响应时间和）。</li><li><strong>数据库操作关联。</strong>对于 Java 应用，我们可以很方便地通过 JavaAgent 字节码注入技术拿到 JDBC 执行数据库操作的执行时间。对此，我们可以和相关的请求对应起来。</li><li><strong>服务资源跟踪。</strong>我们的服务可能运行在物理机上，也可能运行在虚拟机里，还可能运行在一个 Docker 的容器里，Docker 容器又运行在物理机或是虚拟机上。我们需要把服务运行的机器节点上的数据（如 CPU、MEM、I&#x2F;O、DISK、NETWORK）关联起来。</li></ul><p><strong>了这些数据上的关联，我们就可以达到如下的目标。</strong></p><ol><li>当一台机器挂掉是因为 CPU 或 I&#x2F;O 过高的时候，我们马上可以知道其会影响到哪些对外服务的 API。</li><li>当一个服务响应过慢的时候，我们马上能关联出来是否在做 Java GC，或是其所在的计算结点上是否有资源不足的情况，或是依赖的服务是否出现了问题。</li><li>当发现一个 SQL 操作过慢的时候，我们能马上知道其会影响哪个对外服务的 API。</li><li>当发现一个消息队列拥塞的时候，我们能马上知道其会影响哪些对外服务的 API。</li></ol><p><strong>一旦了解了这些信息，我们就可以做出调度。比如：</strong></p><ol><li>一旦发现某个服务过慢是因为 CPU 使用过多，我们就可以做弹性伸缩。</li><li>一旦发现某个服务过慢是因为 MySQL 出现了一个慢查询，我们就无法在应用层上做弹性伸缩，只能做流量限制，或是降级操作了。</li></ol><p><strong>实现效果如下图：</strong></p><p><img src="https://static001.geekbang.org/resource/image/6b/33/6b17dd779cfecd62e02924dc8618e833.png?wh=865*381" alt="img"></p><h3 id="服务调度"><a href="#服务调度" class="headerlink" title="服务调度"></a>服务调度</h3><p><strong>微服务是服务依赖最优解的上限，而服务依赖的下限是千万不要有依赖环。</strong>如果系统架构中有服务依赖环，那么表明你的架构设计是错误的。循环依赖有很多的副作用，最大的问题是这是一种极强的耦合，会导致服务部署相当复杂和难解，而且会导致无穷尽的递归故障和一些你意想不到的问题。</p><h4 id="服务状态和生命周期的管理"><a href="#服务状态和生命周期的管理" class="headerlink" title="服务状态和生命周期的管理"></a>服务状态和生命周期的管理</h4><p>服务的生命周期通常会有以下几个状态：</p><ul><li>Provision，代表在供应一个新的服务；</li><li>Ready，表示启动成功了；</li><li>Run，表示通过了服务健康检查；</li><li>Update，表示在升级中；</li><li>Rollback，表示在回滚中；</li><li>Scale，表示正在伸缩中（可以有 Scale-in 和 Scale-out 两种）；</li><li>Destroy，表示在销毁中；</li><li>Failed，表示失败状态。</li></ul><p>这几个状态需要管理好，不然的话，你将不知道这些服务在什么样的状态下。不知道在什么样的状态下，你对整个分布式架构也就无法控制了。</p><h4 id="整个架构的版本管理"><a href="#整个架构的版本管理" class="headerlink" title="整个架构的版本管理"></a>整个架构的版本管理</h4><p>需要一个架构的 manifest，一个服务清单，这个服务清单定义了所有服务的版本运行环境，其中包括但不限于：</p><ul><li>服务的软件版本；</li><li>服务的运行环境——环境变量、CPU、内存、可以运行的节点、文件系统等；</li><li>服务运行的最大最小实例数。</li></ul><h4 id="资源-x2F-服务调度"><a href="#资源-x2F-服务调度" class="headerlink" title="资源 &#x2F; 服务调度"></a>资源 &#x2F; 服务调度</h4><p>服务和资源的调度有点像操作系统。操作系统一方面把用户进程在硬件资源上进行调度，另一方面提供进程间的通信方式，可以让不同的进程在一起协同工作。服务和资源调度的过程，与操作系统调度进程的方式很相似，主要有以下一些关键技术。</p><ul><li>服务状态的维持和拟合。</li><li>服务的弹性伸缩和故障迁移。</li><li>作业和应用调度。</li><li>作业工作流编排。</li><li>服务编排。</li></ul><h4 id="服务状态的维持"><a href="#服务状态的维持" class="headerlink" title="服务状态的维持"></a>服务状态的维持</h4><p>所谓服务状态不是服务中的数据状态，而是服务的运行状态，换句话说就是服务的 Status，而不是 State。也就是上述服务运行时生命周期中的状态——Provision，Ready，Run，Scale，Rollback，Update，Destroy，Failed……服务运行时的状态是非常关键的。</p><p>服务运行过程中，状态也是会有变化的，这样的变化有两种。</p><ul><li>一种是没有预期的变化。比如，服务运行因为故障导致一些服务挂掉，或是别的什么原因出现了服务不健康的状态。而一个好的集群管理控制器应该能够强行维护服务的状态。在健康的实例数变少时，控制器会把不健康的服务给摘除，而又启动几个新的，强行维护健康的服务实例数。</li><li>另外一种是预期的变化。比如，我们需要发布新版本，需要伸缩，需要回滚。这时，集群管理控制器就应该把集群从现有状态迁移到另一个新的状态。这个过程并不是一蹴而就的，集群控制器需要一步一步地向集群发送若干控制命令。这个过程叫“拟合”——从一个状态拟合到另一个状态，而且要穷尽所有的可能，玩命地不断地拟合，直到达到目的。</li></ul><h4 id="服务的弹性伸缩和故障迁移"><a href="#服务的弹性伸缩和故障迁移" class="headerlink" title="服务的弹性伸缩和故障迁移"></a>服务的弹性伸缩和故障迁移</h4><p>有了上述的服务状态拟合的基础工作之后，我们就能很容易地管理服务的生命周期了，甚至可以通过底层的支持进行便利的服务弹性伸缩和故障迁移。</p><p>对于弹性伸缩，在上面我已经给出了一个服务伸缩所需要的操作步骤。还是比较复杂的，其中涉及到了：</p><ul><li>底层资源的伸缩；</li><li>服务的自动化部署；</li><li>服务的健康检查；</li><li>服务发现的注册；</li><li>服务流量的调度。</li></ul><p>而对于故障迁移，也就是服务的某个实例出现问题时，我们需要自动地恢复它。对于服务来说，有两种模式，一种是宠物模式，一种是奶牛模式。</p><ul><li>所谓宠物模式，就是一定要救活，主要是对于 stateful 的服务。</li><li>而奶牛模式，就是不用救活了，重新生成一个实例。</li></ul><p>对于这两种模式，在运行中也是比较复杂的，其中涉及到了：</p><ul><li>服务的健康监控（这可能需要一个 APM 的监控）。</li><li>如果是宠物模式，需要：服务的重新启动和服务的监控报警（如果重试恢复不成功，需要人工介入）。</li><li>如果是奶牛模式，需要：服务的资源申请，服务的自动化部署，服务发现的注册，以及服务的流量调度。</li></ul><p>把传统的服务迁移到 Docker 和 Kubernetes 上来，再加上更上层的对服务生命周期的控制系统的调度，我们就可以做到一个完全自动化的运维架构了。</p><h4 id="服务工作流和编排"><a href="#服务工作流和编排" class="headerlink" title="服务工作流和编排"></a>服务工作流和编排</h4><p>正如上面和操作系统做的类比一样，一个好的操作系统需要能够通过一定的机制把一堆独立工作的进程给协同起来。在分布式的服务调度中，这个工作叫做 <strong>Orchestration</strong>，国内把这个词翻译成<strong>“编排”</strong>。</p><h3 id="流量与数据调度"><a href="#流量与数据调度" class="headerlink" title="流量与数据调度"></a>流量与数据调度</h3><p>关于流量调度，现在很多人都把这个事和服务治理混为一谈了。但是还是应该分开的。</p><ol><li>一方面，服务治理是内部系统的事，而流量调度可以是内部的，更是外部接入层的事。</li><li>另一方面，服务治理是数据中心的事，而流量调度要做得好，应该是数据中心之外的事，也就是我们常说的边缘计算，是应该在类似于 CDN 上完成的事。</li></ol><p>所以，流量调度和服务治理是在不同层面上的，不应该混在一起，所以在系统架构上应该把它们分开。</p><h4 id="流量调度的主要功能"><a href="#流量调度的主要功能" class="headerlink" title="流量调度的主要功能"></a>流量调度的主要功能</h4><p>对于一个流量调度系统来说，其应该具有的主要功能是：</p><ol><li>依据系统运行的情况，自动地进行流量调度，在无需人工干预的情况下，提升整个系统的稳定性；</li><li>让系统应对爆品等突发事件时，在弹性计算扩缩容的较长时间窗口内或底层资源消耗殆尽的情况下，保护系统平稳运行。</li></ol><p>这还是为了提高系统架构的稳定性和高可用性。</p><p>此外，这个流量调度系统还可以完成以下几方面的事情。</p><ul><li><strong>服务流控。</strong>服务发现、服务路由、服务降级、服务熔断、服务保护等。</li><li><strong>流量控制。</strong>负载均衡、流量分配、流量控制、异地灾备（多活）等。</li><li><strong>流量管理。</strong>协议转换、请求校验、数据缓存、数据计算等。</li></ul><p>所有的这些都应该是一个 API Gateway 应该做的事。</p><h4 id="流量调度的关键技术"><a href="#流量调度的关键技术" class="headerlink" title="流量调度的关键技术"></a>流量调度的关键技术</h4><p>一个好的 API Gateway 需要具备以下的关键技术。</p><ul><li><strong>高性能。</strong>API Gateway 必须使用高性能的技术，所以，也就需要使用高性能的语言。</li><li><strong>扛流量。</strong>要能扛流量，就需要使用集群技术。集群技术的关键点是在集群内的各个结点中共享数据。这就需要使用像 Paxos、Raft、Gossip 这样的通讯协议。因为 Gateway 需要部署在广域网上，所以还需要集群的分组技术。</li><li><strong>业务逻辑。</strong>API Gateway 需要有简单的业务逻辑，所以，最好是像 AWS 的 Lambda 服务一样，可以让人注入不同语言的简单业务逻辑。</li><li><strong>服务化。</strong>一个好的 API Gateway 需要能够通过 Admin API 来不停机地管理配置变更，而不是通过一个.conf 文件来人肉地修改配置。</li></ul><h4 id="状态数据调度"><a href="#状态数据调度" class="headerlink" title="状态数据调度"></a>状态数据调度</h4><p>对于服务调度来说，最难办的就是有状态的服务了。这里的状态是 State，也就是说，有些服务会保存一些数据，而这些数据是不能丢失的，所以，这些数据是需要随服务一起调度的。</p><p>一般来说，我们会通过“转移问题”的方法来让服务变成“无状态的服务”。也就是说，会把这些有状态的东西存储到第三方服务上，比如 Redis、MySQL、ZooKeeper，或是 NFS、Ceph 的文件系统中。</p><p>这些“转移问题”的方式把问题转移到了第三方服务上，于是自己的 Java 或 PHP 服务中没有状态，但是 Redis 和 MySQL 上则有了状态。所以，我们可以看到，现在的分布式系统架构中出问题的基本都是这些存储状态的服务。</p><p>因为数据存储结点在 Scale 上比较困难，所以成了一个单点的瓶颈。</p><h4 id="分布式事务一致性的问题"><a href="#分布式事务一致性的问题" class="headerlink" title="分布式事务一致性的问题"></a>分布式事务一致性的问题</h4><p>要解决数据结点的 Scale 问题，也就是让数据服务可以像无状态的服务一样在不同的机器上进行调度，这就会涉及数据的 replication 问题。而数据 replication 则会带来数据一致性的问题，进而对性能带来严重的影响。</p><p>要解决数据不丢失的问题，只能通过数据冗余的方法，就算是数据分区，每个区也需要进行数据冗余处理。这就是数据副本。当出现某个节点的数据丢失时，可以从副本读到。数据副本是分布式系统解决数据丢失异常的唯一手段。简单来说：</p><ul><li>要想让数据有高可用性，就得写多份数据。</li><li>写多份会引起数据一致性的问题。</li><li>数据一致性的问题又会引发性能问题</li></ul><p>在解决数据副本间的一致性问题时，可以使用以下这些技术方案。</p><ul><li>Master-Slave 方案。</li><li>Master-Master 方案。</li><li>两阶段和三阶段提交方案。</li><li>Paxos 方案。</li></ul><p><strong>关于分布式的事务处理：</strong><a href="https://coolshell.cn/articles/10910.html">https://coolshell.cn/articles/10910.html</a></p><h4 id="状态数据调总结"><a href="#状态数据调总结" class="headerlink" title="状态数据调总结"></a>状态数据调总结</h4><ul><li>对于应用层上的分布式事务一致性，只有两阶段提交这样的方式。</li><li>而底层存储可以解决这个问题的方式是通过一些像 Paxos、Raft 或是 NWR 这样的算法和模型来解决。</li><li>状态数据调度应该是由分布式存储系统来解决的，这样会更为完美。但是因为数据存储的 Scheme 太多，所以，导致我们有各式各样的分布式存储系统，有文件对象的，有关系型数据库的，有 NoSQL 的，有时序数据的，有搜索数据的，有队列的……</li></ul><p>数据调度应该是在 IaaS 层的数据存储解决的问题，而不是在 PaaS 层或者 SaaS 层来解决的。</p><p>在 IaaS 层上解决这个问题，一般来说有三种方案，</p><p>一种是使用比较廉价的开源产品，如：NFS、Ceph、TiDB、CockroachDB、ElasticSearch、InfluxDB、MySQL Cluster 和 Redis Cluster 之类的；另一种是用云计算厂商的方案。当然，如果不差钱的话，可以使用更为昂贵的商业网络存储方案。</p><h3 id="Pass平台的本质"><a href="#Pass平台的本质" class="headerlink" title="Pass平台的本质"></a>Pass平台的本质</h3><p><img src="https://s2.loli.net/2022/08/28/ABQ1nR9wt5opvFY.png" alt="Pass平台.png"></p><p>下面这三件事是 PaaS 跟传统中间件最大的差别。</p><ul><li><strong>服务化是 PaaS 的本质</strong>。软件模块重用，服务治理，对外提供能力是 PaaS 的本质。</li><li><strong>分布式是 PaaS 的根本特性</strong>。多租户隔离、高可用、服务编排是 PaaS 的基本特性。</li><li><strong>自动化是 PaaS 的灵魂</strong>。自动化部署安装运维，自动化伸缩调度是 PaaS 的关键。</li></ul><h2 id="PaaS-平台的总体架构"><a href="#PaaS-平台的总体架构" class="headerlink" title="PaaS 平台的总体架构"></a>PaaS 平台的总体架构</h2><p><img src="https://s2.loli.net/2022/08/28/rTUA9lfnSFjOtqC.png" alt="架构图.png"></p><p>在 Docker+Kubernetes 层之上，我们看到了两个相关的 PaaS 层。一个是 PaaS 调度层，很多人将其称为 iPaaS；另一个是 PaaS 能力层，通常被称为 aPaaS。没有 PaaS 调度层，PaaS 能力层很难被管理和运维，而没有 PaaS 能力层，PaaS 就失去了提供实际能力的业务价值。而本文更多的是在讲 PaaS 调度层上的东西。</p><p>一个完整的 PaaS 平台会包括以下几部分。</p><ul><li>PaaS 调度层 – 主要是 PaaS 的自动化和分布式对于高可用高性能的管理。</li><li>PaaS 能力服务层 – 主要是 PaaS 真正提供给用户的服务和能力。</li><li>PaaS 的流量调度 – 主要是与流量调度相关的东西，包括对高并发的管理。</li><li>PaaS 的运营管理 – 软件资源库、软件接入、认证和开放平台门户。</li><li>PaaS 的运维管理 – 主要是 DevOps 相关的东西。</li></ul><h2 id="PaaS-平台的生产和运维"><a href="#PaaS-平台的生产和运维" class="headerlink" title="PaaS 平台的生产和运维"></a>PaaS 平台的生产和运维</h2><p><img src="https://s2.loli.net/2022/08/28/m2DzoMRpQkUT5Ii.png" alt="image-20220814122700725.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>传统的单体架构系统容量显然是有上限的。同时，为了应对有计划和无计划的下线时间，系统的可用性也是有其极限的。分布式系统为以上两个问题提供了解决方案，并且还附带有其他优势。但是，要同时解决这两个问题决非易事。为了构建分布式系统，我们面临的主要问题如下。</p><ul><li>分布式系统的硬件故障发生率更高，故障发生是常态，需要尽可能地将运维流程自动化。</li><li>需要良好地设计服务，避免某服务的单点故障对依赖它的其他服务造成大面积影响。</li><li>为了容量的可伸缩性，服务的拆分、自治和无状态变得更加重要，可能需要对老的软件逻辑做大的修改。</li><li>老的服务可能是异构的，此时需要让它们使用标准的协议，以便可以被调度、编排，且互相之间可以通信。</li><li>服务软件故障的处理也变得复杂，需要优化的流程，以加快故障的恢复。</li><li>为了管理各个服务的容量，让分布式系统发挥出最佳性能，需要有流量调度技术。</li><li>分布式存储会让事务处理变得复杂；在事务遇到故障无法被自动恢复的情况下，手动恢复流程也会变得复杂。</li><li>测试和查错的复杂度增大。</li><li>系统的吞吐量会变大，但响应时间会变长。</li></ul><p>为了解决这些问题，我们深入了解了以下这些解决方案。</p><ul><li>需要有完善的监控系统，以便对服务运行状态有全面的了解。</li><li>设计服务时要分析其依赖链；当非关键服务故障时，其他服务要自动降级功能，避免调用该服务。</li><li>重构老的软件，使其能被服务化；可以参考 SOA 和微服务的设计方式，目标是微服务化；使用 Docker 和 Kubernetes 来调度服务。</li><li>为老的服务编写接口逻辑来使用标准协议，或在必要时重构老的服务以使得它们有这些功能。</li><li>自动构建服务的依赖地图，并引入好的处理流程，让团队能以最快速度定位和恢复故障。</li><li>使用一个 API Gateway，它具备服务流向控制、流量控制和管理的功能。</li><li>事务处理建议在存储层实现；根据业务需求，或者降级使用更简单、吞吐量更大的最终一致性方案，或者通过二阶段提交、Paxos、Raft、NWR 等方案之一，使用吞吐量小的强一致性方案。</li><li>通过更真实地模拟生产环境，乃至在生产环境中做灰度发布，从而增加测试强度；同时做充分的单元测试和集成测试以发现和消除缺陷；最后，在服务故障发生时，相关的多个团队同时上线自查服务状态，以最快地定位故障原因。</li><li>通过异步调用来减少对短响应时间的依赖；对关键服务提供专属硬件资源，并优化软件逻辑以缩短响应时间。</li></ul><h3 id="基础理论"><a href="#基础理论" class="headerlink" title="基础理论"></a>基础理论</h3><h2 id="CAP-定理"><a href="#CAP-定理" class="headerlink" title="CAP 定理"></a><a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP 定理</a></h2><p>CAP 定理是分布式系统设计中最基础，也是最为关键的理论。它指出，分布式数据存储不可能同时满足以下三个条件。</p><ul><li><strong>一致性（Consistency）</strong>：每次读取要么获得最近写入的数据，要么获得一个错误。</li><li><strong>可用性（Availability）</strong>：每次请求都能获得一个（非错误）响应，但不保证返回的是最新写入的数据。</li><li><strong>分区容忍（Partition tolerance）</strong>：尽管任意数量的消息被节点间的网络丢失（或延迟），系统仍继续运行。</li></ul><p>也就是说，CAP 定理表明，在存在网络分区的情况下，一致性和可用性必须二选一。而在没有发生网络故障时，即分布式系统正常运行时，一致性和可用性是可以同时被满足的。这里需要注意的是，CAP 定理中的一致性与 ACID 数据库事务中的一致性截然不同。</p><p>掌握 CAP 定理，尤其是能够正确理解 C、A、P 的含义，对于系统架构来说非常重要。因为对于分布式系统来说，网络故障在所难免，如何在出现网络故障的时候，维持系统按照正常的行为逻辑运行就显得尤为重要。你可以结合实际的业务场景和具体需求，来进行权衡。</p><p>例如，对于大多数互联网应用来说（如门户网站），因为机器数量庞大，部署节点分散，网络故障是常态，可用性是必须要保证的，所以只有舍弃一致性来保证服务的 AP。而对于银行等，需要确保一致性的场景，通常会权衡 CA 和 CP 模型，CA 模型网络故障时完全不可用，CP 模型具备部分可用性。</p><p><img src="https://s2.loli.net/2022/08/28/VhY8TjpDHOAs6JX.png" alt="image-20220814124520469.png"></p><ul><li>CA (consistency + availability)，这样的系统关注一致性和可用性，它需要非常严格的全体一致的协议，比如“两阶段提交”（2PC）。CA 系统不能容忍网络错误或节点错误，一旦出现这样的问题，整个系统就会拒绝写请求，因为它并不知道对面的那个结点是否挂掉了，还是只是网络问题。唯一安全的做法就是把自己变成只读的。</li><li>CP (consistency + partition tolerance)，这样的系统关注一致性和分区容忍性。它关注的是系统里大多数人的一致性协议，比如：Paxos 算法（Quorum 类的算法）。这样的系统只需要保证大多数结点数据一致，而少数的结点会在没有同步到最新版本的数据时变成不可用的状态。这样能够提供一部分的可用性。</li><li>AP (availability + partition tolerance)，这样的系统关心可用性和分区容忍性。因此，这样的系统不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。Dynamo 就是这样的系统。</li></ul><h4 id="Paxos-算法"><a href="#Paxos-算法" class="headerlink" title="Paxos 算法"></a>Paxos 算法</h4><p>Paxos 算法，是莱斯利·兰伯特（Lesile Lamport）于 1990 年提出来的一种基于消息传递且具有高度容错特性的一致性算法。但是这个算法太过于晦涩，所以，一直以来都属于理论上的论文性质的东西。</p><h4 id="Raft-算法"><a href="#Raft-算法" class="headerlink" title="Raft 算法"></a>Raft 算法</h4><p>因为 Paxos 算法太过于晦涩，而且在实际的实现上有太多的坑，并不太容易写对。所以，有人搞出了另外一个一致性的算法，叫 Raft。其原始论文是<a href="https://raft.github.io/raft.pdf"> In search of an Understandable Consensus Algorithm (Extended Version) </a>寻找一种易于理解的 Raft 算法。这篇论文的译文在 InfoQ 上《<a href="http://www.infoq.com/cn/articles/raft-paper">Raft 一致性算法论文译文</a>》</p><p>Raft 算法和 Paxos 的性能和功能是一样的，但是它和 Paxos 算法的结构不一样，这使 Raft 算法更容易理解并且更容易实现。那么 Raft 是怎样做到的呢？</p><p>Raft 把这个一致性的算法分解成了几个部分，一个是领导选举（Leader Selection），一个是日志复制（Log Replication），一个是安全性（Safety），还有一个是成员变化（Membership Changes）。对于一般人来说，Raft 协议比 Paxos 的学习曲线更低，也更平滑。</p><p>Raft 协议中有一个状态机，每个结点会有三个状态，分别是 Leader、Candidate 和 Follower。Follower 只响应其他服务器的请求，如果没有收到任何信息，它就会成为一个 Candidate，并开始进行选举。收到大多数人同意选票的人会成为新的 Leader。</p><p><img src="https://s2.loli.net/2022/08/28/AZdFOXp17fvj2J9.png" alt="image-20220814125128384.png"></p><p>一旦选举出了一个 Leader，它就开始负责服务客户端的请求。每个客户端的请求都包含一个要被复制状态机执行的指令。Leader 首先要把这个指令追加到 log 中形成一个新的 entry，然后通过 AppendEntries RPC 并行地把该 entry 发给其他服务器（server）。如果其他服务器没发现问题，复制成功后会给 Leader 一个表示成功的 ACK。</p><p>Leader 收到大多数 ACK 后应用该日志，返回客户端执行结果。如果 Follower 崩溃 （crash）或者丢包，Leader 会不断重试 AppendEntries RPC。</p><p><img src="https://s2.loli.net/2022/08/28/9EcGBU8KDSrdah5.png" alt="image-20220814125218440.png"></p><p>几个不错的 Raft 算法的动画演示。</p><ul><li><a href="http://thesecretlivesofdata.com/raft/">Raft – The Secret Lives of Data</a></li><li><a href="https://raft.github.io/">Raft Consensus Algorithm</a></li><li><a href="http://kanaka.github.io/raft.js/">Raft Distributed Consensus Algorithm Visualization</a></li></ul><h4 id="逻辑钟和向量钟"><a href="#逻辑钟和向量钟" class="headerlink" title="逻辑钟和向量钟"></a>逻辑钟和向量钟</h4><p>后面，业内又搞出来一些工程上的东西，比如 Amazon 的 DynamoDB，其论文<a href="http://bnrg.eecs.berkeley.edu/~randy/Courses/CS294.F07/Dynamo.pdf">Dynamo: Amazon’s Highly Available Key Value Store</a> 的影响力也很大。这篇论文中讲述了 Amazon 的 DynamoDB 是如何满足系统的高可用、高扩展和高可靠要求的，其中还展示了系统架构是如何做到数据分布以及数据一致性的。</p><p>GFS 采用的是查表式的数据分布，而 DynamoDB 采用的是计算式的，也是一个改进版的通过虚拟结点减少增加结点带来数据迁移的一致性哈希。另外，这篇论文中还讲述了一个 NRW 模式用于让用户可以灵活地在 CAP 系统中选取其中两项，这使用到了 Vector Clock——向量时钟来检测相应的数据冲突。最后还介绍了使用 Handoff 的机制对可用性的提升。</p><p>这篇文章中有几个关键的概念，一个是 Vector Clock，另一个是 Gossip 协议。</p><p>提到向量时钟就需要提一下逻辑时钟。所谓逻辑时间，也就是在分布系统中为了解决消息有序的问题，由于在不同的机器上有不同的本地时间，这些本地时间的同步很难搞，会导致消息乱序。</p><p>于是 Paxos 算法的发明人兰伯特（Lamport）搞了个向量时钟，每个系统维护一个本地的计数器，这就是所谓的逻辑时钟。每执行一个事件（例如向网络发送消息，或是交付到应用层）都对这个计数器做加 1 操作。当跨系统的时候，在消息体上附着本地计算器，当接收端收到消息时，更新自己的计数器（取对端传来的计数器和自己当成计数器的最大值），也就是调整自己的时钟。</p><p>逻辑时钟可以保证，如果事件 A 先于事件 B，那么事件 A 的时钟一定小于事件 B 的时钟，但是返过来则无法保证，因为返过来没有因果关系。所以，向量时钟解释了因果关系。向量时钟维护了数据更新的一组版本号（版本号其实就是使用逻辑时钟）。</p><p>假如一个数据需要存在三个结点上 A、B、C。那么向量维度就是 3，在初始化的时候，所有结点对于这个数据的向量版本是 [A:0, B:0, C:0]。当有数据更新时，比如从 A 结点更新，那么，数据的向量版本变成 [A:1, B:0, C:0]，然后向其他结点复制这个版本，其在语义上表示为我当前的数据是由 A 结果更新的，而在逻辑上则可以让分布式系统中的数据更新的顺序找到相关的因果关系。</p><p>这其中的逻辑关系，你可以看一下<a href="http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures.html"> 马萨诸塞大学课程 Distributed Operating System </a>中第 10 节<a href="http://lass.cs.umass.edu/~shenoy/courses/spring05/lectures/Lec10.pdf"> Clock Synchronization </a>这篇讲议。关于 Vector Clock，你可以看一下<a href="http://basho.com/posts/technical/why-vector-clocks-are-easy/"> Why Vector Clocks are Easy</a>和<a href="http://basho.com/posts/technical/why-vector-clocks-are-hard/">Why Vector Clocks are Hard</a> 这两篇文章。</p><h4 id="Gossip-协议"><a href="#Gossip-协议" class="headerlink" title="Gossip 协议"></a>Gossip 协议</h4><p>另外，DynamoDB 中使用到了 Gossip 协议来做数据同步，这个协议的原始论文是 <a href="https://www.cs.cornell.edu/home/rvr/papers/flowgossip.pdf">Efficient Reconciliation and Flow Control for Anti-Entropy Protocols</a>。Gossip 算法也是 Cassandra 使用的数据复制协议。这个协议就像八卦和谣言传播一样，可以 “一传十、十传百”传播开来。但是这个协议看似简单，细节上却非常麻烦。</p><p>根据这篇论文，节点之间存在三种通信方式。</p><ul><li>push 方式。A 节点将数据 (key,value,version) 及对应的版本号推送给 B 节点，B 节点更新 A 中比自己新的数据。</li><li>pull 方式。A 仅将数据 key,version 推送给 B，B 将本地比 A 新的数据 (key,value,version) 推送给 A，A 更新本地。</li><li>push&#x2F;pull 方式。与 pull 类似，只是多了一步，A 再将本地比 B 新的数据推送给 B，B 更新本地。</li></ul><p>如果把两个节点数据同步一次定义为一个周期，那么在一个周期内，push 需通信 1 次，pull 需 2 次，push&#x2F;pull 则需 3 次。从效果上来讲，push&#x2F;pull 最好，理论上一个周期内可以使两个节点完全一致。直观感觉上，也是 push&#x2F;pull 的收敛速度最快。</p><p>另外，每个节点上的又需要一个协调机制，也就是如何交换数据能达到最快的一致性——消除节点的不一致性。上面所讲的 push、pull 等是通信方式，协调是在通信方式下的数据交换机制。</p><p>关于 Gossip 的一些图示化的东西，可以看一下动画<a href="https://rrmoelker.github.io/gossip-visualization/">gossip visualization</a>。</p><h4 id="分布式数据库方面"><a href="#分布式数据库方面" class="headerlink" title="分布式数据库方面"></a>分布式数据库方面</h4><p>数据库方面的一些论文。</p><p>一篇是 AWS Aurora 的论文 <a href="http://www.allthingsdistributed.com/files/p1041-verbitski.pdf">Amazon Aurora: Design Considerations for High Throughput Cloud –Native Relation Databases</a>。</p><p>Aurora 是 AWS 将 MySQL 的计算和存储分离后，计算节点 scale up，存储节点 scale out。并把其 redo log 独立设计成一个存储服务，把分布式的数据方面的东西全部甩给了底层存储系统。从而提高了整体的吞吐量和水平的扩展能力。</p><p>Aurora 要写 6 份拷贝，但是其只需要把一个 Quorum 中的日志写成功就可以了。如下所示。可以看到，将存储服务做成一个跨数据中心的服务，提高数据库容灾，降低性能影响。</p><p><img src="https://s2.loli.net/2022/08/28/G2eINobOhBxMFXu.png" alt="image-20220814125522918.png"></p><p>对于存储服务的设计，核心的原理就是 latency 一定要低，毕竟写 6 个 copy 是一件开销很大的事。所以，基本上来说，Aurora 用的是异步模型，然后拼命地做并行处理，其中用到的也是 Gossip 协议。如下所示。</p><p><img src="https://s2.loli.net/2022/08/28/8jlGWnqfyZHVTFx.png" alt="image-20220814125553446.png"></p><p>在上面这个图中，我们可以看到，完成前两步，就可以 ACK 回调用方。也就是说，只要数据在本地落地了，就可以返回成功了。然后，对于六个副本，这个 log 会同时发送到 6 个存储结点，只需要有大于 4 个成功 ACK，就算写成功了。第 4 步我们可以看到用的是 Gossip 协议。然后，第 5 步产生 cache 页，便于查询。第 6 步在 S3 做 Snapshot，类似于 Checkpoint。</p><h3 id="经典资料"><a href="#经典资料" class="headerlink" title="经典资料"></a>经典资料</h3><ul><li>Distributed systems theory for the distributed systems engineer</li><li>FLP Impossibility Result</li><li>An introduction to distributed systems</li><li>Distributed Systems for fun and profit</li><li>Distributed Systems: Principles and Paradigms</li><li>Scalable Web Architecture and Distributed Systems</li><li>Principles of Distributed Systems</li><li>Making reliable distributed systems in the presence of software errors</li><li>Designing Data Intensive Applications</li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>分布式</tag>
      
      <tag>左耳听风</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RPC实战笔记</title>
    <link href="/2022/08/28/RPC%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/"/>
    <url>/2022/08/28/RPC%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="RPC总结"><a href="#RPC总结" class="headerlink" title="RPC总结"></a>RPC总结</h1><h2 id="RPC-的作用"><a href="#RPC-的作用" class="headerlink" title="RPC 的作用"></a>RPC 的作用</h2><ol><li><p>屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；</p></li><li><p>隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。</p></li></ol><h2 id="一个完整的-RPC-会涉及到哪些步骤？"><a href="#一个完整的-RPC-会涉及到哪些步骤？" class="headerlink" title="一个完整的 RPC 会涉及到哪些步骤？"></a>一个完整的 RPC 会涉及到哪些步骤？</h2><p><img src="https://static001.geekbang.org/resource/image/ac/fa/acf53138659f4982bbef02acdd30f1fa.jpg?wh=3846*1377" alt="img"></p><h2 id="RPC架构"><a href="#RPC架构" class="headerlink" title="RPC架构"></a>RPC架构</h2><p><img src="https://static001.geekbang.org/resource/image/30/fb/30f52b433aa5f103114a8420c6f829fb.jpg?wh=2951*2181" alt="img"></p><p>​                                                                                                                      <strong>核心功能体系</strong> </p><p><img src="https://static001.geekbang.org/resource/image/a3/a6/a3688580dccd3053fac8c0178cef4ba6.jpg?wh=3084*2183" alt="img"></p><p>​                                                                                                                  <strong>插件化体系架构</strong> </p><p><strong>插件化体系</strong>整个架构就变成了一个微内核架构，我们将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离并提供接口的默认实现。这样的架构相比之前的架构，有很多优势。首先它的可扩展性很好，实现了开闭原则，用户可以非常方便地通过插件扩展实现自己的功能，而且不需要修改核心功能的本身；其次就是保持了核心包的精简，依赖外部包少，这样可以有效减少开发人员引入 RPC 导致的包版本冲突问题。</p><h2 id="RPC应用场景"><a href="#RPC应用场景" class="headerlink" title="RPC应用场景"></a>RPC应用场景</h2><p><img src="https://static001.geekbang.org/resource/image/50/be/506e902e06e91663334672c29bfbc2be.jpg?wh=3205*1778" alt="img"></p><h2 id="RPC注意点"><a href="#RPC注意点" class="headerlink" title="RPC注意点"></a>RPC注意点</h2><p><img src="https://s2.loli.net/2022/08/28/c19JKY4lWEjf3y7.png" alt="image-20220716134042279.png"></p><h2 id="RPC协议与HTTP的设计区别"><a href="#RPC协议与HTTP的设计区别" class="headerlink" title="RPC协议与HTTP的设计区别"></a>RPC协议与HTTP的设计区别</h2><p>相对于 HTTP 的用处，RPC 更多的是负责应用间的通信，所以性能要求相对更高。但 HTTP 协议的数据包大小相对请求数据本身要大很多，又需要加入很多无用的内容，比如换行符号、回车符等；还有一个更重要的原因是，HTTP 协议属于无状态协议，客户端无法对请求和响应进行关联，每次请求都需要重新建立连接，响应完成后再关闭连接。因此，对于要求高性能的 RPC 来说，HTTP 协议基本很难满足需求，所以 RPC 会选择设计更紧凑的私有协议。</p><h2 id="对象如何在网络中传输"><a href="#对象如何在网络中传输" class="headerlink" title="对象如何在网络中传输"></a>对象如何在网络中传输</h2><h3 id="序列化与反序列化"><a href="#序列化与反序列化" class="headerlink" title="序列化与反序列化"></a>序列化与反序列化</h3><p>网络传输的数据必须是二进制数据，但调用方请求的出入参数都是对象。对象是不能直接在网络中传输的，所以我们需要提前把它转成可传输的二进制，并且要求转换算法是可逆的，这个过程叫做“序列化”。这时，服务提供方就可以正确地从二进制数据中分割出不同的请求，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象，这个过程称之为“反序列化”。</p><p><img src="https://static001.geekbang.org/resource/image/d2/04/d215d279ef8bfbe84286e81174b4e704.jpg" alt="img"></p><h3 id="RPC通信流程"><a href="#RPC通信流程" class="headerlink" title="RPC通信流程"></a>RPC通信流程</h3><p><img src="https://static001.geekbang.org/resource/image/82/59/826a6da653c4093f3dc3f0a833915259.jpg" alt="img"></p><h3 id="常见的序列化方式"><a href="#常见的序列化方式" class="headerlink" title="常见的序列化方式"></a>常见的序列化方式</h3><p><strong>JDK 原生序列化</strong></p><p>JDK序列化过程就是在读取对象数据的时候，不断加入一些特殊分隔符，这些特殊分隔符用于在反序列化过程中截断用。</p><p><img src="https://static001.geekbang.org/resource/image/7e/9f/7e2616937e3bc5323faf3ba4c09d739f.jpg" alt="img"></p><ul><li>头部数据用来声明序列化协议、序列化版本，用于高低版本向后兼容</li><li>对象数据主要包括类名、签名、属性名、属性类型及属性值，当然还有开头结尾等数据，除了属性值属于真正的对象值，其他都是为了反序列化用的元数据</li><li>存在对象引用、继承的情况下，就是递归遍历“写对象”逻辑</li></ul><p><strong>JSON序列化</strong></p><p><strong>缺点：</strong></p><p>JSON 进行序列化的额外空间开销比较大，对于大数据量服务这意味着需要巨大的内存和磁盘开销；JSON 没有类型，但像 Java 这种强类型语言，需要通过反射统一解决，所以性能不会太好。</p><p>JSON 没有类型，但像 Java 这种强类型语言，需要通过反射统一解决，所以性能不会太好。</p><p>所以如果 RPC 框架选用 JSON 序列化，服务提供者与服务调用者之间传输的数据量要相对较小，否则将严重影响性能。</p><p><strong>Hessian序列化</strong></p><p>Hessian 是动态类型、二进制、紧凑的，并且可跨语言移植的一种序列化框架。Hessian 协议要比 JDK、JSON 更加紧凑，性能上要比 JDK、JSON 序列化高效很多，而且生成的字节数也更小。</p><p><strong>Protobuf序列化</strong></p><p>Protobuf 是 Google 公司内部的混合语言数据标准，是一种轻便、高效的结构化数据存储格式，可以用于结构化数据序列化，支持 Java、Python、C++、Go 等语言。Protobuf 使用的时候需要定义 IDL（Interface description language），然后使用不同语言的 IDL 编译器，生成序列化工具类；</p><p><strong>优点：</strong></p><ul><li>序列化后体积相比 JSON、Hessian 小很多；</li><li>IDL 能清晰地描述语义，所以足以帮助并保证应用程序之间的类型不会丢失，无需类似 XML 解析器；</li><li>序列化反序列化速度很快，不需要通过反射获取类型；</li><li>消息格式升级和兼容性不错，可以做到向后兼容。</li></ul><p><strong>缺点：</strong>对于具有反射和动态能力的语言来说，用起来很费劲</p><h4 id="如何选择哪种框架"><a href="#如何选择哪种框架" class="headerlink" title="如何选择哪种框架"></a>如何选择哪种框架</h4><p><img src="https://static001.geekbang.org/resource/image/b4/a5/b42e44968c3fdcdfe2acf96377f5b2a5.jpg" alt="img"></p><h2 id="RPC-框架在使用时要注意哪些问题？"><a href="#RPC-框架在使用时要注意哪些问题？" class="headerlink" title="RPC 框架在使用时要注意哪些问题？"></a>RPC 框架在使用时要注意哪些问题？</h2><p><strong>对象构造得过于复杂：</strong>属性很多，并且存在多层的嵌套，比如 A 对象关联 B 对象，B 对象又聚合 C 对象，C 对象又关联聚合很多其他对象，对象依赖关系过于复杂。序列化框架在序列化与反序列化对象时，对象越复杂就越浪费性能，消耗 CPU，这会严重影响 RPC 框架整体的性能；另外，对象越复杂，在序列化与反序列化的过程中，出现问题的概率就越高。</p><p><strong>对象过于庞大：</strong>我经常遇到业务过来咨询，为啥他们的 RPC 请求经常超时，排查后发现他们的入参对象非常得大，比如为一个大 List 或者大 Map，序列化之后字节长度达到了上兆字节。这种情况同样会严重地浪费了性能、CPU，并且序列化一个如此大的对象是很耗费时间的，这肯定会直接影响到请求的耗时。</p><p><strong>使用序列化框架不支持的类作为入参类：</strong>比如 Hessian 框架，不支持 LinkedHashMap、LinkedHashSet 等，而且大多数情况下最好不要使用第三方集合类，如 Guava 中的集合类，很多开源的序列化框架都是优先支持编程语言原生的对象。因此如果入参是集合类，应尽量选用原生的、最为常用的集合类，如 HashMap、ArrayList。</p><p><strong>对象有复杂的继承关系：</strong>大多数序列化框架在序列化对象时都会将对象的属性一一进行序列化，当有继承关系时，会不停地寻找父类，遍历属性。就像问题 1 一样，对象关系越复杂，就越浪费性能，同时又很容易出现序列化上的问题。</p><p><img src="C:\Users\longp\AppData\Roaming\Typora\typora-user-images\image-20220717151659788.png" alt="image-20220717151659788"></p><h2 id="RPC主要实现功能"><a href="#RPC主要实现功能" class="headerlink" title="RPC主要实现功能"></a>RPC主要实现功能</h2><h3 id="服务发现"><a href="#服务发现" class="headerlink" title="服务发现"></a>服务发现</h3><p><strong>一致性（Consistency）、可用性（Availability）、分区容错性（Partition tolerance）要AP还是CP</strong></p><p><img src="https://static001.geekbang.org/resource/image/51/5d/514dc04df2b8b2f3130b7d44776a825d.jpg?wh=2746*1445" alt="img"></p><p>​                                                                                                                                          <strong>服务发现原理</strong></p><p><strong>服务注册：</strong>在服务提供方启动的时候，将对外暴露的接口注册到注册中心之中，注册中心将这个服务节点的 IP 和接口保存下来。</p><p><strong>服务订阅：</strong>在服务调用方启动的时候，去注册中心查找并订阅服务提供方的 IP，然后缓存到本地，并用于后续的远程调用。</p><h4 id="为什么不使用-DNS？"><a href="#为什么不使用-DNS？" class="headerlink" title="为什么不使用 DNS？"></a>为什么不使用 DNS？</h4><p><img src="https://static001.geekbang.org/resource/image/3b/18/3b6a23f392b9b8d6fcf31803a5b4ef18.jpg?wh=5273*1884" alt="img"></p><p>​                                                                                                             <strong>DNS查询流程</strong></p><p><strong>使用DNS存在的问题：</strong></p><ul><li>如果这个 IP 端口下线了，服务调用者不能及时摘除服务节点；</li><li>如果在之前已经上线了一部分服务节点，这时我突然对这个服务进行扩容，那么新上线的服务节点不能及时接收到流量；</li></ul><h4 id="基于-ZooKeeper-的服务发现"><a href="#基于-ZooKeeper-的服务发现" class="headerlink" title="基于 ZooKeeper 的服务发现"></a>基于 ZooKeeper 的服务发现</h4><p><img src="https://static001.geekbang.org/resource/image/50/75/503fabeeae226a722f83e9fb6c0d4075.jpg?wh=4214*1803" alt="img"></p><p><img src="https://s2.loli.net/2022/08/28/9rWbXJjnkFMGdgL.png" alt="实践.png"></p><h4 id="基于消息总线的最终一致性的注册中心"><a href="#基于消息总线的最终一致性的注册中心" class="headerlink" title="基于消息总线的最终一致性的注册中心"></a>基于消息总线的最终一致性的注册中心</h4><p>ZooKeeper 的一大特点就是强一致性，ZooKeeper 集群的每个节点的数据每次发生更新操作，都会通知其它 ZooKeeper 节点同时执行更新。它要求保证每个节点的数据能够实时的完全一致，这也就直接导致了 ZooKeeper 集群性能上的下降。这就好比几个人在玩传递东西的游戏，必须这一轮每个人都拿到东西之后，所有的人才能开始下一轮，而不是说我只要获得到东西之后，就可以直接进行下一轮了。</p><p>而 RPC 框架的服务发现，在服务节点刚上线时，服务调用方是可以容忍在一段时间之后（比如几秒钟之后）发现这个新上线的节点的。毕竟服务节点刚上线之后的几秒内，甚至更长的一段时间内没有接收到请求流量，对整个服务集群是没有什么影响的，<strong>所以我们可以牺牲掉 CP（强制一致性），而选择 AP（最终一致），来换取整个注册中心集群的性能和稳定性。</strong></p><p>是否有一种简单、高效，并且最终一致的更新机制，能代替 ZooKeeper 那种数据强一致的数据更新机制呢？</p><p>因为要求最终一致性，我们可以考虑采用消息总线机制。注册数据可以全量缓存在每个注册中心内存中，通过消息总线来同步数据。当有一个注册中心节点接收到服务节点注册时，会产生一个消息推送给消息总线，再通过消息总线通知给其它注册中心节点更新数据并进行服务下发，从而达到注册中心间数据最终一致性，具体流程如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/73/ff/73b59c7949ebed2903ede474856062ff.jpg?wh=4256*2276" alt="img"></p><ul><li>当有服务上线，注册中心节点收到注册请求，服务列表数据发生变化，会生成一个消息，推送给消息总线，每个消息都有整体递增的版本。</li><li>消息总线会主动推送消息到各个注册中心，同时注册中心也会定时拉取消息。对于获取到消息的在消息回放模块里面回放，只接受大于本地版本号的消息，小于本地版本号的消息直接丢弃，从而实现最终一致性。</li><li>消费者订阅可以从注册中心内存拿到指定接口的全部服务实例，并缓存到消费者的内存里面。</li><li>采用推拉模式，消费者可以及时地拿到服务实例增量变化情况，并和内存中的缓存数据进行合并。</li></ul><p>为了性能，采用两级缓存，注册中心和消费者的内存缓存，通过异步推拉模式来确保最终一致性。</p><p><img src="https://s2.loli.net/2022/08/28/OfNVTmrCbYEkohq.png" alt="image-20220720220716266.png"><br><img src="https://s2.loli.net/2022/08/28/g4dzHEyWfrpRhDK.png" alt="image-20220720220817173.png"></p><h3 id="健康检测"><a href="#健康检测" class="headerlink" title="健康检测"></a>健康检测</h3><p><strong>Script Check、HTTP Check、TCP Check、TTL Check等</strong></p><h4 id="consul做法"><a href="#consul做法" class="headerlink" title="consul做法"></a>consul做法</h4><p><strong>TTL&#x2F;TCP？</strong></p><h4 id="etcd做法？"><a href="#etcd做法？" class="headerlink" title="etcd做法？"></a>etcd做法？</h4><p><strong>基于lease租约机制，对注册的服务设置key TTL，定时保持服务的心跳以达到监控健康状态的效果。</strong></p><h3 id="路由策略"><a href="#路由策略" class="headerlink" title="路由策略"></a>路由策略</h3><p><img src="https://static001.geekbang.org/resource/image/b7/68/b78964a2db3adc8080364e9cfc79ca68.jpg?wh=3900*879" alt="img"></p><p>​                                                                                                                              <strong>调用流程</strong></p><p><img src="https://static001.geekbang.org/resource/image/23/f7/23f24c545d33ec4d6d72fc10e94a0ff7.jpg?wh=2513*1991" alt="img"></p><p>​                                                                                                                              <strong>IP路由调用拓扑</strong></p><h4 id="参数路由："><a href="#参数路由：" class="headerlink" title="参数路由："></a>参数路由：</h4><p><img src="https://static001.geekbang.org/resource/image/78/39/7868289c87ca9de144fe32fac98f8339.jpg?wh=2506*1964" alt="img"></p><p>​                                                                                                                 <strong>参数路由调用拓扑</strong></p><p>相比 IP 路由，参数路由支持的灰度粒度更小，他为服务提供方应用提供了另外一个服务治理的手段。灰度发布功能是 RPC 路由功能的一个典型应用场景，通过 RPC 路由策略的组合使用可以让服务提供方更加灵活地管理、调用自己的流量，进一步降低上线可能导致的风险。</p><h3 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h3><p><strong>需求：</strong></p><p><img src="https://s2.loli.net/2022/08/28/vAXShkqrxu8e2pK.png" alt="需求.png"></p><h4 id="什么是负载均衡？"><a href="#什么是负载均衡？" class="headerlink" title="什么是负载均衡？"></a>什么是负载均衡？</h4><p>当我们的一个服务节点无法支撑现有的访问量时，我们会部署多个节点，组成一个集群，然后通过负载均衡，将请求分发给这个集群下的每个服务节点，从而达到多个服务节点共同分担请求压力的目的。</p><p><img src="https://static001.geekbang.org/resource/image/f4/b8/f48704443b33df17fc490778c00c71b8.jpg?wh=3345*1443" alt="img"></p><p>​                                                                                                                    <strong>负载均衡示意图</strong></p><p>负载均衡主要分为软负载和硬负载，软负载就是在一台或多台服务器上安装负载均衡的软件，如 LVS、Nginx 等，硬负载就是通过硬件设备来实现的负载均衡，如 F5 服务器等。负载均衡的算法主要有随机法、轮询法、最小连接法等。</p><p>刚才介绍的负载均衡主要还是应用在 Web 服务上，Web 服务的域名绑定负载均衡的地址，通过负载均衡将用户的请求分发到一个个后端服务上。</p><h4 id="RPC-框架中的负载均衡"><a href="#RPC-框架中的负载均衡" class="headerlink" title="RPC 框架中的负载均衡"></a>RPC 框架中的负载均衡</h4><p><strong>RPC使用传统的负载均衡存在的问题？</strong></p><ol><li>搭建负载均衡设备或 TCP&#x2F;IP 四层代理，需要额外成本；</li><li>请求流量都经过负载均衡设备，多经过一次网络传输，会额外浪费一些性能；</li><li>负载均衡添加节点和摘除节点，一般都要手动添加，当大批量扩容和下线时，会有大量的人工操作，“服务发现”在操作上是个问题；</li><li>我们在服务治理的时候，针对不同接口服务、服务的不同分组，我们的负载均衡策略是需要可配的，如果大家都经过这一个负载均衡设备，就不容易根据不同的场景来配置不同的负载均衡策略了。</li></ol><p>RPC 的负载均衡完全由 RPC 框架自身实现，RPC 的服务调用者会与“注册中心”下发的所有服务节点建立长连接，在每次发起 RPC 调用时，服务调用者都会通过配置的负载均衡插件，自主选择一个服务节点，发起 RPC 调用请求。</p><p><img src="https://static001.geekbang.org/resource/image/5e/1c/5e294378a3d86e7d279507f62fe5ee1c.jpg?wh=4175*1969" alt="img"></p><p>​                                                                                                                      RPC框架负载均衡示意图</p><p>RPC 负载均衡策略一般包括随机权重、Hash、轮询。当然，这还是主要看 RPC 框架自身的实现。其中的随机权重策略应该是我们最常用的一种了，通过随机算法，我们基本可以保证每个节点接收到的请求流量是均匀的；同时我们还可以通过控制节点权重的方式，来进行流量控制。比如我们默认每个节点的权重都是 100，但当我们把其中的一个节点的权重设置成 50 时，它接收到的流量就是其他节点的 1&#x2F;2。</p><h4 id="如何设计自适应的负载均衡？"><a href="#如何设计自适应的负载均衡？" class="headerlink" title="如何设计自适应的负载均衡？"></a>如何设计自适应的负载均衡？</h4><p>RPC 的负载均衡完全由 RPC 框架自身实现，服务调用者发起请求时，会通过配置的负载均衡插件，自主地选择服务节点。那是不是只要调用者知道每个服务节点处理请求的能力，再根据服务处理节点处理请求的能力来判断要打给它多少流量就可以了？当一个服务节点负载过高或响应过慢时，就少给它发送请求，反之则多给它发送请求。这就有点像日常工作中的分配任务，要多考虑实际情况。当一位下属身体欠佳，就少给他些工作；若刚好另一位下属状态很好，手头工作又不是很多，就多分给他一点。</p><h5 id="服务调用者节点该如何判定一个服务节点的处理能力呢？"><a href="#服务调用者节点该如何判定一个服务节点的处理能力呢？" class="headerlink" title="服务调用者节点该如何判定一个服务节点的处理能力呢？"></a>服务调用者节点该如何判定一个服务节点的处理能力呢？</h5><p>采用一种打分的策略，服务调用者收集与之建立长连接的每个服务节点的指标数据，如服务节点的负载指标、CPU 核数、内存大小、请求处理的耗时指标（如请求平均耗时、TP99、TP999）、服务节点的状态指标（如正常、亚健康）。通过这些指标，计算出一个分数，比如总分 10 分，如果 CPU 负载达到 70%，就减它 3 分，当然了，减 3 分只是个类比，需要减多少分是需要一个计算策略的。</p><h5 id="该如果根据这些指标来打分呢？"><a href="#该如果根据这些指标来打分呢？" class="headerlink" title="该如果根据这些指标来打分呢？"></a>该如果根据这些指标来打分呢？</h5><p>这就有点像公司对员工进行年终考核。假设我是老板，我要考核专业能力、沟通能力和工作态度，这三项的占比分别是 30%、30%、40%，我给一个员工的评分是 10、8、8，那他的综合分数就是这样计算的：10<em>30%+8</em>30%+8*40%&#x3D;8.6 分。给服务节点打分也一样，我们可以为每个指标都设置一个指标权重占比，然后再根据这些指标数据，计算分数。</p><h5 id="服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？"><a href="#服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？" class="headerlink" title="服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？"></a>服务调用者给每个服务节点都打完分之后，会发送请求，那这时候我们又该如何根据分数去控制给每个服务节点发送多少流量呢？</h5><p>我们可以配合随机权重的负载均衡策略去控制，通过最终的指标分数修改服务节点最终的权重。例如给一个服务节点综合打分是 8 分（满分 10 分），服务节点的权重是 100，那么计算后最终权重就是 80（100*80%）。服务调用者发送请求时，会通过随机权重的策略来选择服务节点，那么这个节点接收到的流量就是其他正常节点的 80%（这里假设其他节点默认权重都是 100，且指标正常，打分为 10 分的情况）。</p><p>整体的设计方案如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/00/af/00065674063f30c98caaa58bb4cd7baf.jpg?wh=4085*2365" alt="img"></p><p>​                                                                                                                      <strong>RPC自适应负载均衡示意图</strong></p><p><strong>关键步骤：</strong></p><ol><li>添加服务指标收集器，并将其作为插件，默认有运行时状态指标收集器、请求耗时指标收集器。</li><li>运行时状态指标收集器收集服务节点 CPU 核数、CPU 负载以及内存等指标，在服务调用者与服务提供者的心跳数据中获取。</li><li>请求耗时指标收集器收集请求耗时数据，如平均耗时、TP99、TP999 等。</li><li>可以配置开启哪些指标收集器，并设置这些参考指标的指标权重，再根据指标数据和指标权重来综合打分。</li><li>通过服务节点的综合打分与节点的权重，最终计算出节点的最终权重，之后服务调用者会根据随机权重的策略，来选择服务节点。</li></ol><p><strong>RPC 框架的负载均衡与 Web 服务的负载均衡的不同之处在于：</strong></p><p>RPC 框架并不是依赖一个负载均衡设备或者负载均衡服务器来实现负载均衡的，而是由 RPC 框架本身实现的，服务调用者可以自主选择服务节点，发起服务调用。这样的好处是，RPC 框架不再需要依赖专门的负载均衡设备，可以节约成本；还减少了与负载均衡设备间额外的网络传输，提升了传输效率；并且均衡策略可配，便于服务治理。</p><h3 id="异常重试与熔断限流"><a href="#异常重试与熔断限流" class="headerlink" title="异常重试与熔断限流"></a>异常重试与熔断限流</h3><h4 id="RPC重试机制"><a href="#RPC重试机制" class="headerlink" title="RPC重试机制"></a>RPC重试机制</h4><p><img src="https://static001.geekbang.org/resource/image/32/81/32441dc643e64a022acfcbe0b4c77e81.jpg?wh=5154*1923" alt="img"></p><p>​                                                                                                                       <strong>RPC异常重试流程</strong></p><p>调用端发起的请求失败时，RPC 框架自身可以进行重试，再重新发送请求，用户可以自行设置是否开启重试以及重试的次数。</p><p>调用端在发起 RPC 调用时，会经过负载均衡，选择一个节点，之后它会向这个节点发送请求信息。当消息发送失败或收到异常消息时，我们就可以捕获异常，根据异常触发重试，重新通过负载均衡选择一个节点发送请求消息，并且记录请求的重试次数，当重试次数达到用户配置的重试次数的时候，就返回给调用端动态代理一个失败异常，否则就一直重试下去。</p><p>RPC 框架的重试机制就是调用端发现请求失败时捕获异常，之后触发重试，那是不是所有的异常都要触发重试呢？当然不是了，因为这个异常可能是服务提供方抛回来的业务异常，它是应该正常返回给动态代理的，所以我们要在触发重试之前对捕获的异常进行判定，只有符合重试条件的异常才能触发重试，比如网络超时异常、网络连接异常等等。</p><p><strong>异常重试需要注意的问题：</strong></p><p>当网络突然抖动了一下导致请求超时了，但这个时候调用方的请求信息可能已经发送到服务提供方的节点上，也可能已经发送到服务提供方的服务节点上，那如果请求信息成功地发送到了服务节点上，那这个节点是不是就要执行业务逻辑了呢？是的。</p><p>如果该业务不是幂等，比如插入数据操作，那触发重试的话会不会引发问题呢？会的。</p><h4 id="如何在约定时间内安全可靠地重试？"><a href="#如何在约定时间内安全可靠地重试？" class="headerlink" title="如何在约定时间内安全可靠地重试？"></a>如何在约定时间内安全可靠地重试？</h4><p>RPC 框架是不会知道哪些业务异常能够去进行异常重试的，我们可以加个重试异常的白名单，用户可以将允许重试的异常加入到这个白名单中。当调用端发起调用，并且配置了异常重试策略，捕获到异常之后，我们就可以采用这样的异常处理策略。如果这个异常是 RPC 框架允许重试的异常，或者这个异常类型存在于可重试异常的白名单中，我们就允许对这个请求进行重试。</p><p><img src="https://static001.geekbang.org/resource/image/5e/81/5e5706e6fc02ef0caaee565ea358f281.jpg?wh=5129*2058" alt="img"></p><p>​                                                                                                                 <strong>可靠的异常重试机制</strong></p><h4 id="为什么需要自我保护"><a href="#为什么需要自我保护" class="headerlink" title="为什么需要自我保护"></a>为什么需要自我保护</h4><p>RPC 是解决分布式系统通信问题的一大利器，而分布式系统的一大特点就是高并发，所以说 RPC 也会面临高并发的场景。在这样的情况下，我们提供服务的每个服务节点就都可能由于访问量过大而引起一系列的问题，比如业务处理耗时过长、CPU 飘高、频繁 Full GC 以及服务进程直接宕机等等。但是在生产环境中，我们要保证服务的稳定性和高可用性，这时我们就需要业务进行自我保护，从而保证在高访问量、高并发的场景下，应用系统依然稳定，服务依然高可用。</p><h5 id="那么在使用-RPC-时，业务又如何实现自我保护呢？"><a href="#那么在使用-RPC-时，业务又如何实现自我保护呢？" class="headerlink" title="那么在使用 RPC 时，业务又如何实现自我保护呢？"></a>那么在使用 RPC 时，业务又如何实现自我保护呢？</h5><p>最常见的方式就是限流了，简单有效，但 RPC 框架的自我保护方式可不只有限流，并且 RPC 框架的限流方式可以是多种多样的。我们可以将 RPC 框架拆开来分析，RPC 调用包括服务端和调用端，调用端向服务端发起调用。下面分享一下服务端与调用端分别是如何进行自我保护的。</p><h4 id="服务端的自我保护"><a href="#服务端的自我保护" class="headerlink" title="服务端的自我保护"></a>服务端的自我保护</h4><p>举个例子，假如我们要发布一个 RPC 服务，作为服务端接收调用端发送过来的请求，这时服务端的某个节点负载压力过高了，我们该如何保护这个节点？</p><p><img src="https://static001.geekbang.org/resource/image/9b/17/9bae10ba8a5b96b03102fb9ef4f30e17.jpg?wh=2560*1315" alt="img"></p><p>那么就是限流吧？是的，<strong>在 RPC 调用中服务端的自我保护策略就是限流</strong>，那你有没有想过我们是如何实现限流的呢？是在服务端的业务逻辑中做限流吗？有没有更优雅的方式？</p><p>限流是一个比较通用的功能，我们可以在 RPC 框架中集成限流的功能，让使用方自己去配置限流阈值；我们还可以在服务端添加限流逻辑，当调用端发送请求过来时，服务端在执行业务逻辑之前先执行限流逻辑，如果发现访问量过大并且超出了限流的阈值，就让服务端直接抛回给调用端一个限流异常，否则就执行正常的业务逻辑。                                                </p><p><img src="https://static001.geekbang.org/resource/image/f8/ad/f8e8a4dd16f2fd2af366f810404057ad.jpg?wh=2563*1313" alt="img">                 </p><h5 id="服务端的限流逻辑该如何实现呢？"><a href="#服务端的限流逻辑该如何实现呢？" class="headerlink" title="服务端的限流逻辑该如何实现呢？"></a>服务端的限流逻辑该如何实现呢？</h5><p>计数器，平滑限流的滑动窗口、漏斗算法以及令牌桶算法等等</p><h4 id="调用端的自我保护"><a href="#调用端的自我保护" class="headerlink" title="调用端的自我保护"></a>调用端的自我保护</h4><p>举个例子，假如发布一个服务 B，而服务 B 又依赖服务 C，当一个服务 A 来调用服务 B 时，服务 B 的业务逻辑调用服务 C，而这时服务 C 响应超时了，由于服务 B 依赖服务 C，C 超时直接导致 B 的业务逻辑一直等待，而这个时候服务 A 在频繁地调用服务 B，服务 B 就可能会因为堆积大量的请求而导致服务宕机。</p><p><img src="https://static001.geekbang.org/resource/image/dc/31/dc2a18f1e2c495380cc4053b92ed3131.jpg?wh=2171*1472" alt="img"></p><p>由此可见，服务 B 调用服务 C，服务 C 执行业务逻辑出现异常时，会影响到服务 B，甚至可能会引起服务 B 宕机。这还只是 A-&gt;B-&gt;C 的情况，试想一下 A-&gt;B-&gt;C-&gt;D-&gt;……呢？在整个调用链中，只要中间有一个服务出现问题，都可能会引起上游的所有服务出现一系列的问题，甚至会引起整个调用链的服务都宕机，这是非常恐怖的。</p><p>所以说，在一个服务作为调用端调用另外一个服务时，为了防止被调用的服务出现问题而影响到作为调用端的这个服务，这个服务也需要进行自我保护。<strong>而最有效的自我保护方式就是熔断。</strong></p><p><strong>熔断机制:</strong></p><p><img src="https://static001.geekbang.org/resource/image/90/64/903fa4374beb753c1db8f1f8b82ff464.jpg?wh=2642*1990" alt="img"></p><p><strong>熔断器的工作机制主要是关闭、打开和半打开这三个状态之间的切换</strong>。</p><ol><li>在正常情况下，熔断器是关闭的；</li><li>当调用端调用下游服务出现异常时，熔断器会收集异常指标信息进行计算，当达到熔断条件时熔断器打开，这时调用端再发起请求是会直接被熔断器拦截，并快速地执行失败逻辑；</li><li>当熔断器打开一段时间后，会转为半打开状态，这时熔断器允许调用端发送一个请求给服务端，如果这次请求能够正常地得到服务端的响应，则将状态置为关闭状态，否则设置为打开。</li></ol><h5 id="在-RPC-框架中，该如何整合熔断器呢？"><a href="#在-RPC-框架中，该如何整合熔断器呢？" class="headerlink" title="在 RPC 框架中，该如何整合熔断器呢？"></a>在 RPC 框架中，该如何整合熔断器呢？</h5><p>熔断机制主要是保护调用端，调用端在发出请求的时候会先经过熔断器。我们可以回想下 RPC 的调用流程：</p><p><img src="https://static001.geekbang.org/resource/image/59/87/59b7479220a415ef034fb6edb589ec87.jpg?wh=3788*1350" alt="img"></p><p><strong>哪个步骤整合熔断器会比较合适呢？</strong></p><p>动态代理，因为在 RPC 调用的流程中，动态代理是 RPC 调用的第一个关口。在发出请求时先经过熔断器，如果状态是闭合则正常发出请求，如果状态是打开则执行熔断器的失败策略。</p><h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><h5 id="RPC-框架是如何实现业务的自我保护？"><a href="#RPC-框架是如何实现业务的自我保护？" class="headerlink" title="RPC 框架是如何实现业务的自我保护？"></a>RPC 框架是如何实现业务的自我保护？</h5><p><strong>服务端主要是通过限流来进行自我保护</strong>，我们在实现限流时要考虑到应用和 IP 级别，方便我们在服务治理的时候，对部分访问量特别大的应用进行合理的限流；服务端的限流阈值配置都是作用于单机的，而在有些场景下，例如对整个服务设置限流阈值，服务进行扩容时，限流的配置并不方便，我们可以在注册中心或配置中心下发限流阈值配置的时候，将总服务节点数也下发给服务节点，让 RPC 框架自己去计算限流阈值；我们还可以让 RPC 框架的限流模块依赖一个专门的限流服务，对服务设置限流阈值进行精准地控制，但是这种方式依赖了限流服务，相比单机的限流方式，在性能和耗时上有劣势。</p><p><strong>调用端可以通过熔断机制进行自我保护</strong>，防止调用下游服务出现异常，或者耗时过长影响调用端的业务逻辑，RPC 框架可以在动态代理的逻辑中去整合熔断器，实现 RPC 框架的熔断功能。</p><h5 id="服务保护一般就是限流、熔断、降级。"><a href="#服务保护一般就是限流、熔断、降级。" class="headerlink" title="服务保护一般就是限流、熔断、降级。"></a>服务保护一般就是限流、熔断、降级。</h5><p> 限流的落地方式有：Guava RateLimiter、lua+Redis、Sentinel等； 熔断：Hystrix、Resilience4j； 降级：服务降级，就是对不怎么重要的服务进行低优先级的处理。说白了，就是尽可能的把系统资源让给优先级高的服务。资源有限，而请求是无限的。</p><h4 id="业务分组"><a href="#业务分组" class="headerlink" title="业务分组"></a>业务分组</h4><p>通过分组的方式人为地给不同的调用方划分出不同的小集群，从而实现调用方流量隔离的效果，保障我们的核心业务不受非核心业务的干扰。但我们在考虑问题的时候，不能顾此失彼，不能因为新加一个的功能而影响到原有系统的稳定性。</p><h4 id="实践案例："><a href="#实践案例：" class="headerlink" title="实践案例："></a>实践案例：</h4><p><img src="https://s2.loli.net/2022/08/28/KPjgxwin6sIVuby.png" alt="实现.png"></p><h3 id="RPC服务重启的关闭与开启"><a href="#RPC服务重启的关闭与开启" class="headerlink" title="RPC服务重启的关闭与开启"></a>RPC服务重启的关闭与开启</h3><h4 id="在重启服务的过程中，RPC-怎么做到让调用方系统不出问题呢？"><a href="#在重启服务的过程中，RPC-怎么做到让调用方系统不出问题呢？" class="headerlink" title="在重启服务的过程中，RPC 怎么做到让调用方系统不出问题呢？"></a>在重启服务的过程中，RPC 怎么做到让调用方系统不出问题呢？</h4><p>简述下上线的大概流程：当服务提供方要上线的时候，一般是通过部署系统完成实例重启。在这个过程中，服务提供方的团队并不会事先告诉调用方他们需要操作哪些机器，从而让调用方去事先切走流量。而对调用方来说，它也无法预测到服务提供方要对哪些机器重启上线，因此负载均衡就有可能把要正在重启的机器选出来，这样就会导致把请求发送到正在重启中的机器里面，从而导致调用方不能拿到正确的响应结果。</p><p><img src="https://static001.geekbang.org/resource/image/c8/67/c899c36097fd5e3f70bf031f4b2c2167.jpg?wh=3596*1810" alt="img"></p><p><strong>在服务重启的时候，对于调用方来说，这时候可能会存在以下几种情况：</strong></p><ul><li>调用方发请求前，目标服务已经下线。对于调用方来说，跟目标节点的连接会断开，这时候调用方可以立马感知到，并且在其健康列表里面会把这个节点挪掉，自然也就不会被负载均衡选中。</li><li>调用方发请求的时候，目标服务正在关闭，但调用方并不知道它正在关闭，而且两者之间的连接也没断开，所以这个节点还会存在健康列表里面，因此该节点就有一定概率会被负载均衡选中。</li></ul><h4 id="关闭流程"><a href="#关闭流程" class="headerlink" title="关闭流程"></a>关闭流程</h4><p><strong>通常的关闭流程：</strong></p><p><img src="https://static001.geekbang.org/resource/image/a1/50/a15be58b32195422bd5a18dba0e68050.jpg?wh=3195*1277" alt="img"></p><p>如上图所示，整个关闭过程中依赖了两次 RPC 调用，一次是服务提供方通知注册中心下线操作，一次是注册中心通知服务调用方下线节点操作。注册中心通知服务调用方都是异步的，我们在“服务发现”一讲中讲过在大规模集群里面，服务发现只保证最终一致性，并不保证实时性，所以注册中心在收到服务提供方下线的时候，并不能成功保证把这次要下线的节点推送到所有的调用方。</p><p>所以这么来看，通过服务发现并不能做到应用无损关闭。不能强依赖“服务发现”来通知调用方要下线的机器，那服务提供方自己来通知行不行？因为在 RPC 里面调用方跟服务提供方之间是长连接，我们可以在提供方应用内存里面维护一份调用方连接集合，当服务要关闭的时候，挨个去通知调用方去下线这台机器。这样整个调用链路就变短了，对于每个调用方来说就一次 RPC，可以确保调用的成功率很高。大部分场景下，这么做确实没有问题，我们之前也是这么实现的，但是我们发现线上还是会偶尔会出现，因为服务提供方上线而导致调用失败的问题。</p><h4 id="优雅关闭"><a href="#优雅关闭" class="headerlink" title="优雅关闭"></a>优雅关闭</h4><p>因为服务提供方已经开始进入关闭流程，那么很多对象就可能已经被销毁了，关闭后再收到的请求按照正常业务请求来处理，肯定是没法保证能处理的。所以我们可以在关闭的时候，设置一个请求“挡板”，挡板的作用就是告诉调用方，我已经开始进入关闭流程了，我不能再处理你这个请求了。</p><p><strong>举例：</strong>如果大家经常去银行办理业务，就会很熟悉这个流程。在交接班或者有其他要事情处理的时候，银行柜台工作人员会拿出一个纸板，放在窗口前，上面写到“该窗口已关闭”。在该窗口排队的人虽然有一万个不愿意，也只能换到其它窗口办理业务，因为柜台工作人员会把当前正在办理的业务处理完后正式关闭窗口。</p><p>基于这个思路，我们可以这么处理：当服务提供方正在关闭，如果这之后还收到了新的业务请求，服务提供方直接返回一个特定的异常给调用方（比如 ShutdownException）。这个异常就是告诉调用方“我已经收到这个请求了，但是我正在关闭，并没有处理这个请求”，然后调用方收到这个异常响应后，RPC 框架把这个节点从健康列表挪出，并把请求自动重试到其他节点，因为这个请求是没有被服务提供方处理过，所以可以安全地重试到其他节点，这样就可以实现对业务无损。</p><p>但如果只是靠等待被动调用，就会让这个关闭过程整体有点漫长。因为有的调用方那个时刻没有业务请求，就不能及时地通知调用方了，所以我们可以加上主动通知流程，这样既可以保证实时性，也可以避免通知失败的情况。</p><p><strong>怎么捕获到关闭事件呢？</strong></p><p>通过捕获操作系统的进程信号来获取，在 Java 语言里面，对应的是 Runtime.addShutdownHook 方法，可以注册关闭的钩子。在 RPC 启动的时候，我们提前注册关闭钩子，并在里面添加了两个处理程序，一个负责开启关闭标识，一个负责安全关闭服务对象，服务对象在关闭的时候会通知调用方下线节点。同时需要在我们调用链里面加上挡板处理器，当新的请求来的时候，会判断关闭标识，如果正在关闭，则抛出特定异常。</p><p><strong>关闭过程中已经在处理的请求会不会受到影响呢？</strong></p><p>如果进程结束过快会造成这些请求还没有来得及应答，同时调用方会也会抛出异常。为了尽可能地完成正在处理的请求，首先我们要把这些请求识别出来。</p><p>这就好比日常生活中，我们经常看见停车场指示牌上提示还有多少剩余车位，这个是如何做到的呢？如果仔细观察一下，你就会发现它是每进入一辆车，剩余车位就减一，每出来一辆车，剩余车位就加一。我们也可以利用这个原理在服务对象加上引用计数器，每开始处理请求之前加一，完成请求处理减一，通过该计数器我们就可以快速判断是否有正在处理的请求。</p><p>服务对象在关闭过程中，会拒绝新的请求，同时根据引用计数器等待正在处理的请求全部结束之后才会真正关闭。但考虑到有些业务请求可能处理时间长，或者存在被挂住的情况，为了避免一直等待造成应用无法正常退出，我们可以在整个 ShutdownHook 里面，加上超时时间控制，当超过了指定时间没有结束，则强制退出应用。超时时间我建议可以设定成 10s，基本可以确保请求都处理完了。整个流程如下图所示。</p><p><img src="https://static001.geekbang.org/resource/image/77/cc/7752081ec658f1d56ac4219f1c07fbcc.jpg?wh=3131*2891" alt="img"></p><h4 id="关闭总结"><a href="#关闭总结" class="headerlink" title="关闭总结"></a>关闭总结</h4><p>在 RPC 里面，关闭虽然看似不属于 RPC 主流程，但如果我们不能处理得很好的话，可能就会导致调用方业务异常，从而需要我们加入很多额外的运维工作。一个好的关闭流程，可以确保使用我们框架的业务实现平滑的上下线，而不用担心重启导致的问题。</p><p>“优雅关闭”这个概念除了在 RPC 里面有，在很多框架里面也都挺常见的，比如像我们经常用的应用容器框架 Tomcat。Tomcat 关闭的时候也是先从外层到里层逐层进行关闭，先保证不接收新请求，然后再处理关闭前收到的请求。</p><h5 id="相关解释："><a href="#相关解释：" class="headerlink" title="相关解释："></a>相关解释：</h5><p><img src="https://s2.loli.net/2022/08/28/qUCtZw2Ps7EdYDu.png" alt="image-20220723212313198.png"></p><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><h5 id="启动预热"><a href="#启动预热" class="headerlink" title="启动预热"></a>启动预热</h5><p>让刚启动的服务提供方应用不承担全部的流量，而是让它被调用的次数随着时间的移动慢慢增加，最终让流量缓和地增加到跟已经运行一段时间后的水平一样。</p><p><strong>实现：</strong>我们可以先简单地回顾下调用方发起的 RPC 调用流程是怎样的，调用方应用通过服务发现能够获取到服务提供方的 IP 地址，然后每次发送请求前，都需要通过负载均衡算法从连接池中选择一个可用连接。那这样的话，我们是不是就可以让负载均衡在选择连接的时候，区分一下是否是刚启动不久的应用？对于刚启动的应用，我们可以让它被选择到的概率特别低，但这个概率会随着时间的推移慢慢变大，从而实现一个动态增加流量的过程。</p><p>当服务提供方运行时长小于预热时间时，对服务提供方进行降权，减少被负载均衡选择的概率，避免让应用在启动之初就处于高负载状态，从而实现服务提供方在启动后有一个预热的过程。</p><p><img src="https://static001.geekbang.org/resource/image/e7/d4/e796da8cf26f056479a59fd97b43d0d4.jpg?wh=2558*2523" alt="img"></p><p>​                                                                                                                   <strong>预热过程图</strong></p><p>启动预热更多是从调用方的角度出发，去解决服务提供方应用冷启动的问题，让调用方的请求量通过一个时间窗口过渡，慢慢达到一个正常水平，从而实现平滑上线。但对于服务提供方本身来说，有没有相关方案可以实现这种效果呢？</p><h5 id="延迟暴露"><a href="#延迟暴露" class="headerlink" title="延迟暴露"></a>延迟暴露</h5><p>举例：spring应用启动的时候都是通过 main 入口，然后顺序加载各种相关依赖的类。以 Spring 应用启动为例，在加载的过程中，Spring 容器会顺序加载 Spring Bean，如果某个 Bean 是 RPC 服务的话，我们不光要把它注册到 Spring-BeanFactory 里面去，还要把这个 Bean 对应的接口注册到注册中心。注册中心在收到新上线的服务提供方地址的时候，会把这个地址推送到调用方应用内存中；当调用方收到这个服务提供方地址的时候，就会去建立连接发请求。</p><p>但这时候可能存在服务提供方并没有启动完成的情况？因为服务提供方应用可能还在加载其它的 Bean。对于调用方来说，只要获取到了服务提供方的 IP，就有可能发起 RPC 调用，但如果这时候服务提供方没有启动完成的话，就会导致调用失败，从而使业务受损。</p><p>解决方案：</p><ul><li><p>在应用启动加载、解析 Bean 的时候，如果遇到了 RPC 服务的 Bean，只先把这个 Bean 注册到 Spring-BeanFactory 里面去，而并不把这个 Bean 对应的接口注册到注册中心，只有等应用启动完成后，才把接口注册到注册中心用于服务发现，从而实现让服务调用方延迟获取到服务提供方地址。这样是可以保证应用在启动完后才开始接入流量的，但其实这样做，我们还是没有实现最开始的目标。因为这时候应用虽然启动完成了，但并没有执行相关的业务代码，所以 JVM 内存里面还是冷的。如果这时候大量请求过来，还是会导致整个应用在高负载模式下运行，从而导致不能及时地返回请求结果。而且在实际业务中，一个服务的内部业务逻辑一般会依赖其它资源的，比如缓存数据。如果我们能在服务正式提供服务前，先完成缓存的初始化操作，而不是等请求来了之后才去加载，我们就可以降低重启后第一次请求出错的概率。</p></li><li><p>利用服务提供方把接口注册到注册中心的那段时间。我们可以在服务提供方应用启动后，接口注册到注册中心前，预留一个 Hook 过程，让用户可以实现可扩展的 Hook 逻辑。用户可以在 Hook 里面模拟调用逻辑，从而使 JVM 指令能够预热起来，并且用户也可以在 Hook 里面事先预加载一些资源，只有等所有的资源都加载完成后，最后才把接口注册到注册中心。整个应用启动过程如下图所示：</p><p><img src="https://static001.geekbang.org/resource/image/3c/bd/3c84f9cf6745f2d50e34bd8431c84abd.jpg?wh=3374*893" alt="img"></p></li></ul><p>​                                                                                                                <strong>启动顺序图</strong></p><h5 id="相关解释：-1"><a href="#相关解释：-1" class="headerlink" title="相关解释："></a>相关解释：</h5><p><img src="https://s2.loli.net/2022/08/28/HhWuQ9j2KxJ3Ayt.png" alt="image-20220723225147106.png"></p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p><img src="https://s2.loli.net/2022/08/28/FZ1Tlig6GQbLCvE.png" alt="image-20220724150651258.png"></p><p><img src="https://s2.loli.net/2022/08/28/tT46nkNsdzK9Vmw.png" alt="image-20220724150622961.png"></p><h4 id="分布式场景中如何做到快速定位RPC相关问题？"><a href="#分布式场景中如何做到快速定位RPC相关问题？" class="headerlink" title="分布式场景中如何做到快速定位RPC相关问题？"></a>分布式场景中如何做到快速定位RPC相关问题？</h4><p>在分布式的生产环境中，比如下面这个场景：我们搭建了一个分布式的应用系统，在这个应用系统中，我启动了 4 个子服务，分别是服务 A、服务 B、服务 C 与服务 D，而这 4 个服务的依赖关系是 A-&gt;B-&gt;C-&gt;D，而这些服务又都部署在不同的机器上。在 RPC 调用中，如果服务端的业务逻辑出现了异常，就会把异常抛回给调用端，那么如果现在这个调用链中有一个服务出现了异常，我们该如何定位问题呢？</p><h5 id="方法-1：借助合理封装的异常信息"><a href="#方法-1：借助合理封装的异常信息" class="headerlink" title="方法 1：借助合理封装的异常信息"></a>方法 1：借助合理封装的异常信息</h5><p><img src="https://static001.geekbang.org/resource/image/b8/1b/b8fee37688d39ae7913429f6cbc06f1b.jpg?wh=4498*1228" alt="img"></p><h5 id="方法-2：借助分布式链路跟踪"><a href="#方法-2：借助分布式链路跟踪" class="headerlink" title="方法 2：借助分布式链路跟踪"></a>方法 2：借助分布式链路跟踪</h5><p><img src="https://s2.loli.net/2022/08/28/ldO1BCDz3xqs7ay.png" alt="image-20220724163935463.png"></p><h4 id="流量回放"><a href="#流量回放" class="headerlink" title="流量回放"></a>流量回放</h4><p><img src="https://s2.loli.net/2022/08/28/Cq24cT78wnWaYRz.png" alt="image-20220724170611177.png"></p>]]></content>
    
    
    <categories>
      
      <category>RPC</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>RPC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Golang内存分配和垃圾回收</title>
    <link href="/2022/08/27/Golang%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/"/>
    <url>/2022/08/27/Golang%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%92%8C%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="Golang内存管理和垃圾回收"><a href="#Golang内存管理和垃圾回收" class="headerlink" title="Golang内存管理和垃圾回收"></a>Golang内存管理和垃圾回收</h1><p>现代高级编程语言管理内存的方式分自动和手动两种。手动管理内存的典型代表是C和C++，编写代码过程中需要主动申请或者释放内存；而PHP、Java 和Go等语言使用自动的内存管理系统，由内存分配器和垃圾收集器来代为分配和回收内存，其中垃圾收集器就是我们常说的GC。今天腾讯后台开发工程师汪汇向大家分享 Golang 垃圾回收算法。（当然，Rust 是另一种）</p><p>从Go v1.12版本开始，Go使用了<strong>非分代的、并发的、基于三色标记清除的垃圾回收器</strong>。相关标记清除算法可以参考C&#x2F;C++，而Go是一种静态类型的编译型语言。因此，Go不需要VM，Go应用程序二进制文件中嵌入了一个小型运行时(Go runtime)，可以处理诸如垃圾收集(GC)、调度和并发之类的语言功能。首先让我们看一下Go内部的内存管理是什么样子的。</p><h2 id="一、-Golang内存管理"><a href="#一、-Golang内存管理" class="headerlink" title="一、 Golang内存管理"></a><strong>一、 Golang内存管理</strong></h2><p>这里先简单介绍一下 Golang 运行调度。在 Golang 里面有三个基本的概念：G, M, P。</p><ul><li>G: Goroutine 执行的上下文环境。</li><li>M: 操作系统线程。</li><li>P: Processer。进程调度的关键，调度器，也可以认为约等于CPU。</li></ul><p>一个 Goroutine 的运行需要G+P+M三部分结合起来。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpQu2e0dr5z6Za2b2aIw9peb8icIQyc29bC7VNuYfPh81ibaUdoSJg6ibicw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p> 图源：《Golang—内存管理(内存分配)》</p><p>(<a href="http://t.zoukankan.com/zpcoding-p-13259943.html">http://t.zoukankan.com/zpcoding-p-13259943.html</a>)</p><h3 id="（一）TCMalloc"><a href="#（一）TCMalloc" class="headerlink" title="（一）TCMalloc"></a><strong>（一）TCMalloc</strong></h3><p>Go将内存划分和分组为页（Page），这和Java的内存结构完全不同，没有分代内存，这样的原因是Go的内存分配器采用了TCMalloc的<strong>设计思想</strong>：</p><h4 id="1-Page"><a href="#1-Page" class="headerlink" title="1.Page"></a><strong>1.Page</strong></h4><p>与TCMalloc中的Page相同，x64下1个Page的大小是8KB。上图的最下方，1个浅蓝色的长方形代表1个Page。</p><h4 id="2-Span"><a href="#2-Span" class="headerlink" title="2.Span"></a><strong>2.Span</strong></h4><p>与TCMalloc中的Span相同，Span是内存管理的基本单位，代码中为mspan，一组连续的Page组成1个Span，所以上图一组连续的浅蓝色长方形代表的是一组Page组成的1个Span，另外，1个淡紫色长方形为1个Span。</p><h4 id="3-mcache"><a href="#3-mcache" class="headerlink" title="3.mcache"></a><strong>3.mcache</strong></h4><p>mcache是提供给P（逻辑处理器）的高速缓存，用于存储小对象（对象大小&lt;&#x3D; 32Kb）。尽管这类似于线程堆栈，但它是堆的一部分，用于动态数据。所有类大小的mcache包含scan和noscan类型mspan。Goroutine可以从mcache没有任何锁的情况下获取内存，因为一次P只能有一个锁G。因此，这更有效。mcache从mcentral需要时请求新的span。</p><h4 id="4-mcentral"><a href="#4-mcentral" class="headerlink" title="4.mcentral"></a><strong>4.mcentral</strong></h4><p>mcentral与TCMalloc中的CentralCache类似，是所有线程共享的缓存，需要加锁访问，它按Span class对Span分类，串联成链表，当mcache的某个级别Span的内存被分配光时，它会向mcentral申请1个当前级别的Span。每个mcentral包含两个mspanList：</p><ul><li>empty：双向span链表，包括没有空闲对象的span或缓存mcache中的span。当此处的span被释放时，它将被移至non-empty span链表。</li><li>non-empty：有空闲对象的span双向链表。当从mcentral请求新的span，mcentral将从该链表中获取span并将其移入empty span链表。</li></ul><h4 id="5-mheap"><a href="#5-mheap" class="headerlink" title="5.mheap"></a><strong>5.mheap</strong></h4><p>mheap与TCMalloc中的PageHeap类似，它是堆内存的抽象，也是垃圾回收的重点区域，把从OS申请出的内存页组织成Span，并保存起来。当mcentral的Span不够用时会向mheap申请，mheap的Span不够用时会向OS申请，向OS的内存申请是按页来的，然后把申请来的内存页生成Span组织起来，同样也是需要加锁访问的。</p><h4 id="6-栈"><a href="#6-栈" class="headerlink" title="6.栈"></a><strong>6.栈</strong></h4><p>这是栈存储区，每个Goroutine（G）有一个栈。在这里存储了静态数据，包括函数栈帧，静态结构，原生类型值和指向动态结构的指针。这与分配给每个P的mcache不是一回事。</p><h3 id="7-TCMalloc为什么快："><a href="#7-TCMalloc为什么快：" class="headerlink" title="7.TCMalloc为什么快："></a>7.TCMalloc为什么快：</h3><p>1.使用了thread cache（线程cache），小块的内存分配都可以从cache中分配，这样再多线程分配内存的情况下，可以减少锁竞争。</p><p>2.tcmalloc会为每个线程分配本地缓存，小对象请求可以直接从本地缓存获取，如果没有空闲内存，则从central heap中一次性获取一连串小对象。大对象是直接使用页级分配器（page-level allocator）从Central page Heap中进行分配，即一个大对象总是按页对齐的。tcmalloc对于小内存，按8的整数次倍分配，对于大内存，按4K的整数次倍分配。</p><p>3.当某个线程缓存中所有对象的总大小超过2MB的时候，会进行垃圾收集。垃圾收集阈值会自动根据线程数量的增加而减少，这样就不会因为程序有大量线程而过度浪费内存。</p><p>4.tcmalloc为每个线程分配一个thread-local cache，小对象的分配直接从thread-local cache中分配。根据需要将对象从CentralHeap中移动到thread-local cache，同时定期的用垃圾回收器把内存从thread-local cache回收到Central free list中。</p><h3 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h3><p>ThreadCache（用于小对象分配）：线程本地缓存，每个线程独立维护一个该对象，多线程在并发申请内存时不会产生锁竞争。</p><p>CentralCache（Central free list，用于小对象分配）：全局cache，所有线程共享。当thread cache空闲链表为空时，会批量从CentralCache中申请内存；当thread cache总内存超过阈值，会进行内存垃圾回收，将空闲内存返还给CentralCache。</p><p>Page Heap（小&#x2F;大对象）：全局页堆，所有线程共享。对于小对象，当centralcache为空时，会从page heap中申请一个span；当一个span完全空闲时，会将该span返还给page heap。对于大对象，直接从page heap中分配，用完直接返还给page heap。系统内存：当page cache内存用光后，会通过sbrk、mmap等系统调用向OS申请内存。</p><h3 id="（二）内存分配"><a href="#（二）内存分配" class="headerlink" title="（二）内存分配"></a><strong>（二）内存分配</strong></h3><p>Go 中的内存分类并不像TCMalloc那样分成小、中、大对象，但是它的小对象里又细分了一个Tiny对象，Tiny对象指大小在1Byte到16Byte之间并且不包含指针的对象。小对象和大对象只用大小划定，无其他区分。</p><p><strong>核心思想</strong>：把内存分为多级管理，降低锁的粒度(只是去mcentral和mheap会申请锁), 以及多种对象大小类型，减少分配产生的内存碎片。</p><ul><li>*<em>*微小对象(Tiny)（size&lt;16B*</em>*<em>）*</em>*</li></ul><p>使用mcache的微小分配器分配小于16个字节的对象，并且在单个16字节块上可完成多个微小分配。</p><ul><li><em><strong>*小对象（尺寸16B〜32KB）*</strong></em></li></ul><p>大小在16个字节和32k字节之间的对象被分配在G运行所在的P的mcache的对应的mspan size class上。</p><ul><li><em><strong>*大对象（大小&gt;32KB）*</strong></em></li></ul><p>大于32 KB的对象直接分配在mheap的相应大小类上(size class)。</p><ul><li>如果mheap为空或没有足够大的页面满足分配请求，则它将从操作系统中分配一组新的页（至少1MB）。</li><li>如果对应的大小规格在mcache中没有可用的块，则向mcentral申请。</li><li>如果mcentral中没有可用的块，则向mheap申请，并根据BestFit 算法找到最合适的mspan。如果申请到的mspan超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的mspan放回mheap的空闲列表。</li><li>如果mheap中没有可用span，则向操作系统申请一系列新的页（最小 1MB）。Go 会在操作系统分配超大的页（称作arena）。分配一大批页会减少和操作系统通信的成本。</li></ul><h3 id="（三）内存回收"><a href="#（三）内存回收" class="headerlink" title="（三）内存回收"></a><strong>（三）内存回收</strong></h3><p>go内存会分成堆区（Heap）和栈区（Stack）两个部分，程序在运行期间可以主动从堆区申请内存空间，这些内存由内存分配器分配并由垃圾收集器负责回收。栈区的内存由编译器自动进行分配和释放，栈区中存储着函数的参数以及局部变量，它们会随着函数的创建而创建，函数的返回而销毁。如果只申请和分配内存，内存终将枯竭。Go使用垃圾回收收集不再使用的span，把span释放交给mheap，mheap对span进行span的合并，把合并后的span加入scav树中，等待再分配内存时，由mheap进行内存再分配。<strong>因此，Go堆是Go垃圾收集器管理的主要区域</strong>。</p><h2 id="二、常见的GC算法"><a href="#二、常见的GC算法" class="headerlink" title="二、常见的GC算法"></a>二、常见的GC算法</h2><h3 id="引用计数法"><a href="#引用计数法" class="headerlink" title="引用计数法"></a>引用计数法</h3><p>根据对象自身的引用计数来回收，当引用计数归零时进行回收，但是计数频繁更新会带来更多开销，且无法解决循环引用的问题。</p><ul><li>优点：简单直接，回收速度快</li><li>缺点：需要额外的空间存放计数，无法处理循环引用的情况；</li></ul><h3 id="可达性分析"><a href="#可达性分析" class="headerlink" title="可达性分析"></a>可达性分析</h3><p>对象引用链：通过一系列的称为”GCRoots”的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain) ，如果一个对象到GCRoots没有任何引用链相连，或者用图论的话来说，就是，从GCRoots到这个对象不可达时，则证明此对象是不可用的。</p><p>根对象在垃圾回收的术语中又叫做根集合，它是垃圾回收器在标记过程时最先检查的对象，包括：</p><p>1.全局变量：程序在编译期就能确定的那些存在于程序整个生命周期的变量。</p><p>2.执行栈：每个 goroutine 都包含自己的执行栈，这些执行栈上包含栈上的变量及指向分配的堆内存区块的指针。</p><p>3.寄存器：寄存器的值可能表示一个指针，参与计算的这些指针可能指向某些赋值器分配的堆内存区块。<br><img src="https://img-blog.csdnimg.cn/20200801163955410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMDA5MjYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h3 id="标记清除法"><a href="#标记清除法" class="headerlink" title="标记清除法"></a>标记清除法</h3><p>标记出所有不需要回收的对象，在标记完成后统一回收掉所有未被标记的对象。<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/mark_clean.png" alt="mark_clean"></p><ul><li>优点：简单直接，速度快，适合可回收对象不多的场景</li><li>缺点：会造成不连续的内存空间（内存碎片），导致有大的对象创建的时候，明明内存中总内存是够的，但是空间不是连续的造成对象无法分配；</li></ul><h3 id="复制法"><a href="#复制法" class="headerlink" title="复制法"></a>复制法</h3><p>复制法将内存分为大小相同的两块，每次使用其中的一块，当这一块的内存使用完后，将还存活的对象复制到另一块去，然后再把使用的空间一次清理掉<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/copy_method.png" alt="copy_method"></p><ul><li>优点：解决了内存碎片的问题，每次清除针对的都是整块内存，但是因为移动对象需要耗费时间，效率低于标记清除法；</li><li>缺点：有部分内存总是利用不到，资源浪费，移动存活对象比较耗时，并且如果存活对象较多的时候，需要担保机制确保复制区有足够的空间可完成复制；</li></ul><h3 id="标记整理"><a href="#标记整理" class="headerlink" title="标记整理"></a>标记整理</h3><p>标记过程同标记清除法，结束后将存活对象压缩至一端，然后清除边界外的内容<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/mark_tidy.png" alt="mark_tidy"></p><ul><li>优点：解决了内存碎片的问题，也不像标记复制法那样需要担保机制，存活对象较多的场景也使适用；</li><li>缺点：性能低，因为在移动对象的时候不仅需要移动对象还要维护对象的引用地址，可能需要对内存经过几次扫描才能完成；</li></ul><h3 id="分代式"><a href="#分代式" class="headerlink" title="分代式"></a>分代式</h3><p>将对象根据存活时间的长短进行分类，存活时间小于某个值的为年轻代，存活时间大于某个值的为老年代，永远不会参与回收的对象为永久代。并根据分代假设（如果一个对象存活时间不长则倾向于被回收，如果一个对象已经存活很长时间则倾向于存活更长时间）对对象进行回收。</p><h3 id="Golang的垃圾回收（GC）算法"><a href="#Golang的垃圾回收（GC）算法" class="headerlink" title="Golang的垃圾回收（GC）算法"></a>Golang的垃圾回收（GC）算法</h3><p>Golang的垃圾回收（GC）算法使用的是无分代（对象没有代际之分）、不整理（回收过程中不对对象进行移动与整理）、并发（与用户代码并发执行）的三色标记清扫算法。原因在于：</p><ul><li>对象整理的优势是解决内存碎片问题以及“允许”使用顺序内存分配器。但 Go 运行时的分配算法基于<code>tcmalloc</code>，基本上没有碎片问题。 并且顺序内存分配器在多线程的场景下并不适用。Go 使用的是基于<code>tcmalloc</code>的现代内存分配算法，对对象进行整理不会带来实质性的性能提升。</li><li>分代<code>GC</code>依赖分代假设，即<code>GC</code>将主要的回收目标放在新创建的对象上（存活时间短，更倾向于被回收），而非频繁检查所有对象。</li><li>Go 的编译器会通过逃逸分析将大部分新生对象存储在栈上（栈直接被回收），只有那些需要长期存在的对象才会被分配到需要进行垃圾回收的堆中。也就是说，分代<code>GC</code>回收的那些存活时间短的对象在 Go 中是直接被分配到栈上，当<code>goroutine</code>死亡后栈也会被直接回收，不需要<code>GC</code>的参与，进而分代假设并没有带来直接优势。</li><li>Go 的垃圾回收器与用户代码并发执行，使得 STW 的时间与对象的代际、对象的 size 没有关系。Go 团队更关注于如何更好地让 GC 与用户代码并发执行（使用适当的 CPU 来执行垃圾回收），而非减少停顿时间这一单一目标上。</li></ul><h2 id="三、Go的垃圾回收"><a href="#三、Go的垃圾回收" class="headerlink" title="三、Go的垃圾回收"></a>三、Go的垃圾回收</h2><p>垃圾回收(Garbage Collection，简称GC)是编程语言中提供的自动的内存管理机制，自动释放不需要的内存对象，让出存储器资源。GC过程中无需程序员手动执行。GC机制在现代很多编程语言都支持，GC能力的性能与优劣也是不同语言之间对比度指标之一。</p><p>Golang在GC的演进过程中也经历了很多次变革，Go V1.3之前的标记-清除(mark and sweep)算法，Go V1.3之前的标记-清扫(mark and sweep)的缺点</p><ul><li>Go V1.5的三色并发标记法</li><li>Go V1.5的三色标记为什么需要STW</li><li>Go V1.5的三色标记为什么需要屏障机制(“强-弱” 三色不变式、插入屏障、删除屏障 )</li><li>Go V1.8混合写屏障机制</li><li>Go V1.8混合写屏障机制的全场景分析</li></ul><h3 id="（一）、Go-V1-3之前的标记-清除-mark-and-sweep-算法"><a href="#（一）、Go-V1-3之前的标记-清除-mark-and-sweep-算法" class="headerlink" title="（一）、Go V1.3之前的标记-清除(mark and sweep)算法"></a>（一）、Go V1.3之前的标记-清除(mark and sweep)算法</h3><p>在Golang1.3之前的时候主要用的普通的标记-清除算法，此算法主要有两个主要的步骤：</p><ul><li>标记(Mark phase)</li><li>清除(Sweep phase)</li></ul><h4 id="1-标记清除算法的具体步骤"><a href="#1-标记清除算法的具体步骤" class="headerlink" title="1 标记清除算法的具体步骤"></a>1 标记清除算法的具体步骤</h4><p><strong>第一步</strong>，暂停程序业务逻辑, 分类出可达和不可达的对象，然后做上标记。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787873045-d038fe47-4898-4b07-9e16-007bebb6fb9c.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_43,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>图中表示是程序与对象的可达关系，目前程序的可达对象有对象1-2-3，对象4-7等五个对象。</p><p><strong>第二步</strong>, 开始标记，程序找出它所有可达的对象，并做上标记。如下图所示：<br><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787891194-883ec541-5f13-4934-9274-080e5f44cf5e.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_44,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>所以对象1-2-3、对象4-7等五个对象被做上标记。</p><p><strong>第三步</strong>,  标记完了之后，然后开始清除未标记的对象. 结果如下。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787913616-ecf21ee2-c247-4401-9d3e-5e2fa278726f.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_38,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>操作非常简单，但是有一点需要额外注意：mark and sweep算法在执行的时候，需要程序暂停！即 <code>STW(stop the world)</code>，STW的过程中，CPU不执行用户代码，全部用于垃圾回收，这个过程的影响很大，所以STW也是一些回收机制最大的难题和希望优化的点。所以在执行第三步的这段时间，程序会暂定停止任何工作，卡在那等待回收执行完毕。</p><p><strong>第四步</strong>, 停止暂停，让程序继续跑。然后循环重复这个过程，直到process程序生命周期结束。</p><p>以上便是标记-清除（mark and sweep）回收的算法。</p><h4 id="2-标记-清除-mark-and-sweep-的缺点"><a href="#2-标记-清除-mark-and-sweep-的缺点" class="headerlink" title="2 标记-清除(mark and sweep)的缺点"></a>2 标记-清除(mark and sweep)的缺点</h4><p>标记清除算法明了，过程鲜明干脆，但是也有非常严重的问题。</p><ul><li>STW，stop the world；让程序暂停，程序出现卡顿 **(重要问题)**；</li><li>标记需要扫描整个heap；</li><li>清除数据会产生heap碎片。</li></ul><p>Go V1.3版本之前就是以上来实施的,  在执行GC的基本流程就是首先启动STW暂停，然后执行标记，再执行数据回收，最后停止STW，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650787936233-9002040d-220b-4af6-8e51-75d7887569b4.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_69,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>从上图来看，全部的GC时间都是包裹在STW范围之内的，这样貌似程序暂停的时间过长，影响程序的运行性能。所以Go V1.3 做了简单的优化,将STW的步骤提前, 减少STW暂停的时间范围.如下所示</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1650788071197-26a29703-0fb5-43f4-afc5-87a35fc78a4b.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_69,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br>上图主要是将STW的步骤提前了一步，因为在Sweep清除的时候，可以不需要STW停止，因为这些对象已经是不可达对象了，不会出现回收写冲突等问题。</p><p>但是无论怎么优化，Go V1.3都面临这个一个重要问题，就是<strong>mark-and-sweep 算法会暂停整个程序</strong> 。</p><p>Go是如何面对并这个问题的呢？接下来G V1.5版本 就用<strong>三色并发标记法</strong>来优化这个问题.</p><h3 id="（二）、Go-V1-5的三色并发标记法"><a href="#（二）、Go-V1-5的三色并发标记法" class="headerlink" title="（二）、Go V1.5的三色并发标记法"></a>（二）、Go V1.5的三色并发标记法</h3><p>为了解决标记清除算法带来的STW问题，Go和Java都会实现三色可达性分析标记算法的变种以缩短STW的时间。三色可达性分析标记算法按“是否被访问过”将程序中的对象分成白色、黑色和灰色：</p><ul><li><strong>白色对象 — 对象尚未被垃圾收集器访问过，在可达性分析刚开始的阶段，所有的对象都是白色的，若在分析结束阶段，仍然是白色的对象，即代表不可达。</strong></li><li><strong>黑色对象 — 表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经被扫描过，黑色的对象代表已经被扫描过而且是安全存活的，如果有其他对象只想黑色对象无需再扫描一遍，黑色对象不可能直接（不经过灰色对象）指向某个白色对象。</strong></li><li><strong>灰色对象 — 表示对象已经被垃圾收集器访问过，但是这个对象上至少存在一个引用还没有被扫描过，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象。</strong></li></ul><p>三色可达性分析算法大致的流程是（初始状态所有对象都是白色）：</p><p><strong>1.从GC Roots开始枚举，它们所有的直接引用变为灰色（移入灰色集合），GC Roots变为黑色。</strong></p><p><strong>2.从灰色集合中取出一个灰色对象进行分析：</strong></p><ul><li><strong>将这个对象所有的直接引用变为灰色，放入灰色集合中；</strong></li><li><strong>将这个对象变为黑色。</strong></li></ul><p><strong>3.重复步骤2，一直重复直到灰色集合为空。</strong></p><p><strong>4.分析完成，仍然是白色的对象就是GC Roots不可达的对象，可以作为垃圾被清理。</strong></p><p>Golang中的垃圾回收主要应用三色标记法，GC过程和其他用户goroutine可并发运行，但需要一定时间的<strong>STW(stop the world)<strong>，所谓</strong>三色标记法</strong>实际上就是通过三个阶段的标记来确定清楚的对象都有哪些？我们来看一下具体的过程。</p><p><strong>第一步</strong> , 每次新创建的对象，默认的颜色都是标记为“白色”，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/png/26269664/1651035738281-051f7a89-e07f-418c-ad0e-7cb94ef1a3b8.png?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_61,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>上图所示，我们的程序可抵达的内存对象关系如左图所示，右边的标记表，是用来记录目前每个对象的标记颜色分类。这里面需要注意的是，所谓“程序”，则是一些对象的根节点集合。所以我们如果将“程序”展开，会得到类似如下的表现形式，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035821416-b0ad644e-ef8e-440a-bbf4-b9e24a7e0257.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><strong>第二步</strong>, 每次GC回收开始, 会从根节点开始遍历所有对象，把遍历到的对象从白色集合放入“灰色”集合如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035842467-7341846f-6dee-4f8b-ad37-dc9723aa6407.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br>这里 要注意的是，本次遍历是一次遍历，非递归形式，是从程序抽次可抵达的对象遍历一层，如上图所示，当前可抵达的对象是对象1和对象4，那么自然本轮遍历结束，对象1和对象4就会被标记为灰色，灰色标记表就会多出这两个对象。</p><p><strong>第三步</strong>, 遍历灰色集合，将灰色对象引用的对象从白色集合放入灰色集合，之后将此灰色对象放入黑色集合，如图所示。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035859950-96053775-24f7-4bdc-a1fb-295747055b3e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br>这一次遍历是只扫描灰色对象，将灰色对象的第一层遍历可抵达的对象由白色变为灰色，如：对象2、对象7. 而之前的灰色对象1和对象4则会被标记为黑色，同时由灰色标记表移动到黑色标记表中。</p><p><strong>第四步</strong>, 重复<strong>第三步</strong>, 直到灰色中无任何对象，如图所示。<br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035907012-927d6cbc-686b-4f81-a1de-097ac7598a8e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><br><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035916208-9c293dc0-8988-4180-a9b7-412e2599af0e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>当我们全部的可达对象都遍历完后，灰色标记表将不再存在灰色对象，目前全部内存的数据只有两种颜色，黑色和白色。那么黑色对象就是我们程序逻辑可达（需要的）对象，这些数据是目前支撑程序正常业务运行的，是合法的有用数据，不可删除，白色的对象是全部不可达对象，目前程序逻辑并不依赖他们，那么白色对象就是内存中目前的垃圾数据，需要被清除。</p><p><strong>第五步</strong>: 回收所有的白色标记表的对象. 也就是回收垃圾，如图所示。</p><p>以上我们将全部的白色对象进行删除回收，<img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651035960263-e50436a6-4a3c-48f9-82cb-bb5729d71116.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img">剩下的就是全部依赖的黑色对象。</p><p>三色标记清除算法本身是不可以并发或者增量执行的，<strong>它需要STW</strong>，<strong>而如果并发执行，用户程序可能在标记执行的过程中修改对象的指针。</strong></p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpDGBI8liaibcvyXxOjP7kowzG1TnVmgAJefhegPo2IJiabXQ6IxnRdVqPQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><h3 id="没有STW的异常情况一般会有2种："><a href="#没有STW的异常情况一般会有2种：" class="headerlink" title="没有STW的异常情况一般会有2种："></a><strong>没有STW的异常情况一般会有2种：</strong></h3><p>1.一种是把原本应该垃圾回收的死亡对象错误的标记为存活。虽然这不好，但是不会导致严重后果，只不过产生了一点逃过本次回收的浮动垃圾而已，下次清理就可以，比如上图所示的三色标记过程中，用户程序取消了从B对象到E对象的引用，但是因为B到E已经被标记完成不会继续执行步骤2，所以E对象最终会被错误的标记成黑色，不会被回收，这个D就是<strong>浮动垃圾</strong>，会在下次垃圾收集中清理。</p><p>2.一种是把原本存活的对象错误的标记为已死亡，导致“对象消失”，这在内存管理中是非常严重的错误。比如上图所示的三色标记过程中，用户程序建立了从B对象到H对象的引用(例如<strong>B.next &#x3D;H</strong>)，接着执行<strong>D.next&#x3D;nil</strong>，但是因为B到H中不存在灰色对象，因此在这之间不会继续执行三色并发标记中的步骤2，D到H之间的链接被断开，所以H对象最终会被标记成白色，会被垃圾收集器错误地回收。我们将这种错误称为<strong>悬挂指针</strong>，即指针没有指向特定类型的合法对象，影响了内存的安全性。</p><h3 id="没有STW的三色标记法情况下-—-悬挂指针的具体介绍"><a href="#没有STW的三色标记法情况下-—-悬挂指针的具体介绍" class="headerlink" title="没有STW的三色标记法情况下  — 悬挂指针的具体介绍"></a>没有STW的三色标记法情况下  — 悬挂指针的具体介绍</h3><p>先抛砖引玉，我们加入如果没有STW，那么也就不会再存在性能上的问题，那么接下来我们假设如果三色标记法不加入STW会发生什么事情？<br>我们还是基于上述的三色并发标记法来说, 他是一定要依赖STW的. 因为如果不暂停程序, 程序的逻辑改变对象引用关系, 这种动作如果在标记阶段做了修改，会影响标记结果的正确性，我们来看看一个场景，如果三色标记法, 标记过程不使用STW将会发生什么事情?</p><p>1.我们把初始状态设置为已经经历了第一轮扫描，目前黑色的有对象1和对象4， 灰色的有对象2和对象7，其他的为白色对象，且对象2是通过指针p指向对象3的，如图所示。<br><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_1.png" alt="no_STW_1"></p><p>2.现在如何三色标记过程不启动STW，那么在GC扫描过程中，任意的对象均可能发生读写操作，如图所示，在还没有扫描到对象2的时候，已经标记为黑色的对象4，此时创建指针q，并且指向白色的对象3。</p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_2.png" alt="no_STW_2"></p><ol start="3"><li>与此同时灰色的对象2将指针p移除，那么白色的对象3实则就是被挂在了已经扫描完成的黑色的对象4下，如图所示。</li></ol><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_3.png" alt="no_STW_3"></p><p>4.然后我们正常指向三色标记的算法逻辑，将所有灰色的对象标记为黑色，那么对象2和对象7就被标记成了黑色，如图所示。<img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_4.png" alt="no_STW_4"></p><p>5.那么就执行了三色标记的最后一步，将所有白色对象当做垃圾进行回收，如图所示。</p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/no_STW_5.png" alt="no_STW_5"><br>但是最后我们才发现，本来是对象4合法引用的对象3，却被GC给“误杀”回收掉了。</p><p><strong>可以看出，有两种情况，在三色标记法中，是不希望被发生的。</strong></p><ul><li>条件1: 一个白色对象被黑色对象引用**(白色被挂在黑色下)**</li><li>条件2: 灰色对象与它之间的可达关系的白色对象遭到破坏**(灰色同时丢了该白色)**<br>如果当以上两个条件同时满足时，就会出现对象丢失现象!</li></ul><p>并且，如图所示的场景中，如果示例中的白色对象3还有很多下游对象的话, 也会一并都清理掉。</p><p>为了防止这种现象的发生，最简单的方式就是STW，直接禁止掉其他用户程序对对象引用关系的干扰，但是<strong>STW的过程有明显的资源浪费，对所有的用户程序都有很大影响</strong>。那么是否可以在保证对象不丢失的情况下合理的尽可能的提高GC效率，减少STW时间呢？答案是可以的，我们只要使用一种机制，尝试去破坏上面的两个必要条件就可以了。</p><h2 id="四、屏障技术"><a href="#四、屏障技术" class="headerlink" title="四、屏障技术"></a><strong>四、屏障技术</strong></h2><p>为了解决上述的“对象消失”的现象，Wilson于1994年在理论上证明了，当且仅当以下两个条件同时满足时，会产生“对象消失”的问题，即原本应该是黑色的对象被误标为白色：</p><ul><li>赋值器插入了一条或多条从黑色对象到白色对象的新引用；</li><li>赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。</li></ul><p>因此为了我们要解决并发扫描时的对象消失问题，保证垃圾收集算法的正确性，只需破坏这两个条件的任意一个即可，<strong>屏障技术</strong>就是在并发或者增量标记过程中保证<strong>三色不变性</strong>的重要技术。</p><p>内存屏障技术是一种屏障指令，它可以让CPU或者编译器在执行内存相关操作时遵循特定的约束，目前多数的现代处理器都会乱序执行指令以最大化性能，但是该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存屏障后执行的操作。垃圾收集中的屏障技术更像是一个<strong>钩子方法</strong>，它是在用户程序读取对象、创建新对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以将它们分成<strong>读屏障（Read barrier）</strong>和写屏障（Write barrier）两种，<strong>因为读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以编程语言往往都会采用写屏障保证三色不变性。</strong></p><p><strong>重点</strong>：</p><ol><li><strong>写屏障的代码在编译期间生成好，之后不会再变化；</strong></li><li>堆上对象赋值才会生成写屏障；</li><li>哪些对象分配在栈上，哪些分配在堆上？也是编译期间由编译器决定，这个过程叫做“逃逸分析”；</li></ol><h4 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h4><p>下面的例子使用的是 go1.13.3。</p><h5 id="示例分析代码"><a href="#示例分析代码" class="headerlink" title="示例分析代码"></a>示例分析代码</h5><p>写屏障是编译器生成的，先形象看下代码样子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs go"> <span class="hljs-number">1</span> <span class="hljs-keyword">package</span> main<br> <span class="hljs-number">2</span> <br> <span class="hljs-number">3</span> <span class="hljs-keyword">type</span> BaseStruct <span class="hljs-keyword">struct</span> &#123;<br> <span class="hljs-number">4</span>     name <span class="hljs-type">string</span><br> <span class="hljs-number">5</span>     age  <span class="hljs-type">int</span><br> <span class="hljs-number">6</span> &#125;<br> <span class="hljs-number">7</span> <br> <span class="hljs-number">8</span> <span class="hljs-keyword">type</span> Tstruct <span class="hljs-keyword">struct</span> &#123;<br> <span class="hljs-number">9</span>     base   *BaseStruct<br><span class="hljs-number">10</span>     field0 <span class="hljs-type">int</span><br><span class="hljs-number">11</span> &#125;<br><span class="hljs-number">12</span> <br><span class="hljs-number">13</span> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">funcAlloc0</span> <span class="hljs-params">(a *Tstruct)</span></span> &#123;<br><span class="hljs-number">14</span>     a.base = <span class="hljs-built_in">new</span>(BaseStruct)    <span class="hljs-comment">// new 一个BaseStruct结构体，赋值给 a.base 字段</span><br><span class="hljs-number">15</span> &#125;<br><span class="hljs-number">16</span> <br><span class="hljs-number">17</span> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">funcAlloc1</span> <span class="hljs-params">(b *Tstruct)</span></span> &#123;<br><span class="hljs-number">18</span>     <span class="hljs-keyword">var</span> b0 Tstruct<br><span class="hljs-number">19</span>     b0.base = <span class="hljs-built_in">new</span>(BaseStruct)  <span class="hljs-comment">// new 一个BaseStruct结构体，赋值给 b0.base 字段</span><br><span class="hljs-number">20</span> &#125;<br><span class="hljs-number">21</span> <br><span class="hljs-number">22</span> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br><span class="hljs-number">23</span>     a := <span class="hljs-built_in">new</span>(Tstruct)    <span class="hljs-comment">// new 一个Tstruct 结构体</span><br><span class="hljs-number">24</span>     b := <span class="hljs-built_in">new</span>(Tstruct)   <span class="hljs-comment">// new 一个Tstruct 结构体</span><br><span class="hljs-number">25</span>     <br><span class="hljs-number">26</span>     <span class="hljs-keyword">go</span> funcAlloc0(a)<br><span class="hljs-number">27</span>     <span class="hljs-keyword">go</span> funcAlloc1(b)<br><span class="hljs-number">28</span> &#125;<br></code></pre></td></tr></table></figure><p>这里例子，可以用来观察两个东西：</p><ol><li>逃逸分析</li><li>编译器插入内存屏障的时机</li></ol><h5 id="逃逸分析"><a href="#逃逸分析" class="headerlink" title="逃逸分析"></a>逃逸分析</h5><p>只有堆上对象的写才会可能有写屏障，因为如果对栈上的写做拦截，那么流程代码会非常复杂，并且性能下降会非常大，得不偿失。根据局部性的原理来说，其实我们程序跑起来，大部分的其实都是操作在栈上，函数参数啊、函数调用导致的压栈出栈啊、局部变量啊，协程栈，这些如果也弄起写屏障，那么可想而知了，根本就不现实，复杂度和性能就是越不过去的坎。</p><p>继续看逃逸什么意思？就是内存分配到堆上。golang 可以在编译的时候使用 <code>-m</code> 参数支持把这个可视化出来：</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vim">$ <span class="hljs-keyword">go</span> build -gcflags <span class="hljs-string">&quot;-N -l -m&quot;</span> ./test_writebarrier0.<span class="hljs-keyword">go</span> <br># <span class="hljs-keyword">command</span>-<span class="hljs-built_in">line</span>-arguments<br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">13</span>:<span class="hljs-number">18</span>: funcAlloc0 <span class="hljs-keyword">a</span> does not <span class="hljs-built_in">escape</span><br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">14</span>:<span class="hljs-number">17</span>: <span class="hljs-keyword">new</span>(BaseStruct) escapes <span class="hljs-keyword">to</span> heap<br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">17</span>:<span class="hljs-number">18</span>: funcAlloc1 <span class="hljs-keyword">b</span> does not <span class="hljs-built_in">escape</span><br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">19</span>:<span class="hljs-number">18</span>: funcAlloc1 <span class="hljs-keyword">new</span>(BaseStruct) does not <span class="hljs-built_in">escape</span><br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">23</span>:<span class="hljs-number">13</span>: <span class="hljs-keyword">new</span>(Tstruct) escapes <span class="hljs-keyword">to</span> heap<br>./test_writebarrier0.<span class="hljs-keyword">go</span>:<span class="hljs-number">24</span>:<span class="hljs-number">13</span>: <span class="hljs-keyword">new</span>(Tstruct) escapes <span class="hljs-keyword">to</span> heap<br></code></pre></td></tr></table></figure><p><strong>先说逃逸分析两点原则</strong>：</p><ol><li>在保证程序正确性的前提下，尽可能的把对象分配到栈上，这样性能最好；<ol><li>栈上的对象生命周期就跟随 goroutine ，协程终结了，它就没了</li></ol></li><li>明确一定要分配到堆上对象，或者不确定是否要分配在堆上的对象，那么就全都分配到堆上；<ol><li>这种对象的生命周期始于业务程序的创建，终于垃圾回收器的回收</li></ol></li></ol><p>我们看到源代码，有四次 new 对象的操作，经过编译器的“逃逸分析”之后，实际分配到堆上的是三次：</p><ol><li><p>14 行 —— 触发逃逸（分配到堆上）</p><ol><li>这个必须得分配到堆上，因为除了这个 goroutine 还要存活呢</li></ol></li><li><p>19 行 —— 无 （分配到栈上）</p><ol><li>这个虽然也是 new，单就分配到栈上就行，因为 b0 这个对象就是一个纯粹的栈对象</li></ol></li><li><p>23 行 —— 触发逃逸 （分配到堆上）</p><ol><li>这个需要分配到堆上，因为分配出来的对象需要传递到其他协程使用</li></ol></li><li><p>24 行 —— 触发逃逸 （分配到堆上）</p><p>  1.这次必须注意下，其实站在我们上帝视角，这次的分配其实也可以分配到栈上。这种情况编译器就简单处理了，直接给分配到堆上。这种就属于编译器它摸不准的，那么分配到堆上就对了，反正也就性能有点影响，功能不会有问题，不然的话你真分配到栈上了，一旦栈被回收就出问题了</p></li></ol><h5 id="写屏障真实的样子"><a href="#写屏障真实的样子" class="headerlink" title="写屏障真实的样子"></a>写屏障真实的样子</h5><p>再看下编译器汇编的代码：</p><p>![汇编后]<img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/20220919223939.png"></p><p>从这个地方我们需要知道一个事情，go 的关键字语法呀，其实在编译的时候，都会对应到一个特定的函数，比如 new 这个关键字就对应了 <code>newobject</code> 函数，go 这个关键字对应的是 <code>newproc</code> 函数。贴一张比较完整的图：</p><p><img src="https://cdn.jsdelivr.net/gh/longpi1/blog-img/20220919224028.png"></p><p>从这个汇编代码我们也确认了，23，24行的对象分配确实是在堆上。我们再看下函数 <code>funcAlloc0</code> 和 <code>funcAlloc1</code> 这两个。</p><p><strong><code>main.funcAlloc0</code></strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">13 </span>func funcAlloc0 (a *Tstruct) &#123;<br><span class="hljs-symbol">14 </span>    a.<span class="hljs-keyword">base</span> = <span class="hljs-keyword">new</span>(BaseStruct)    // <span class="hljs-keyword">new</span> 一个BaseStruct结构体，赋值给 a.<span class="hljs-keyword">base</span> 字段<br><span class="hljs-symbol">15 </span>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/liqingqiya/liqingqiya.github.io/images/posts/2020-07-11-gc2/23DEE999-886F-4298-BCAE-EDB4F7A0B454.png"></p><p>简单的注释解析：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs x86asm">(gdb) disassemble <br>Dump of assembler code for function main<span class="hljs-number">.</span>funcAlloc0:<br>   <span class="hljs-number">0x0000000000456b10</span> &lt;+<span class="hljs-number">0</span>&gt;:     <span class="hljs-keyword">mov</span>    %fs:<span class="hljs-number">0xfffffffffffffff8</span>,%rcx<br>   <span class="hljs-number">0x0000000000456b19</span> &lt;+<span class="hljs-number">9</span>&gt;:     <span class="hljs-keyword">cmp</span>    <span class="hljs-number">0x10</span>(%rcx),%rsp<br>   <span class="hljs-number">0x0000000000456b1d</span> &lt;+<span class="hljs-number">13</span>&gt;:    <span class="hljs-keyword">jbe</span>    <span class="hljs-number">0x456b6f</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">95</span>&gt;<br>   <span class="hljs-number">0x0000000000456b1f</span> &lt;+<span class="hljs-number">15</span>&gt;:    <span class="hljs-keyword">sub</span>    <span class="hljs-number">$0</span>x20,%rsp<br>   <span class="hljs-number">0x0000000000456b23</span> &lt;+<span class="hljs-number">19</span>&gt;:    <span class="hljs-keyword">mov</span>    %rbp,<span class="hljs-number">0x18</span>(%rsp)<br>   <span class="hljs-number">0x0000000000456b28</span> &lt;+<span class="hljs-number">24</span>&gt;:    <span class="hljs-keyword">lea</span>    <span class="hljs-number">0x18</span>(%rsp),%rbp<br>   <span class="hljs-number">0x0000000000456b2d</span> &lt;+<span class="hljs-number">29</span>&gt;:    <span class="hljs-keyword">lea</span>    <span class="hljs-number">0x1430c</span>(%rip),%rax        # <span class="hljs-number">0x46ae40</span><br>   <span class="hljs-number">0x0000000000456b34</span> &lt;+<span class="hljs-number">36</span>&gt;:    <span class="hljs-keyword">mov</span>    %rax,(%rsp)<br>   <span class="hljs-number">0x0000000000456b38</span> &lt;+<span class="hljs-number">40</span>&gt;:    callq  <span class="hljs-number">0x40b060</span> &lt;runtime<span class="hljs-number">.</span>newobject&gt;<br>   # newobject的返回值在 <span class="hljs-number">0x8</span>(%rsp) 里，golang 的参数和返回值都是通过栈传递的。这个跟 c 程序不同，c 程序是溢出才会用到栈，这里先把返回值放到寄存器 <span class="hljs-built_in">rax</span><br>   <span class="hljs-number">0x0000000000456b3d</span> &lt;+<span class="hljs-number">45</span>&gt;:    <span class="hljs-keyword">mov</span>    <span class="hljs-number">0x8</span>(%rsp),%rax           <br>   <span class="hljs-number">0x0000000000456b42</span> &lt;+<span class="hljs-number">50</span>&gt;:    <span class="hljs-keyword">mov</span>    %rax,<span class="hljs-number">0x10</span>(%rsp)<br>   # <span class="hljs-number">0x28</span>(%rsp) 就是 a 的地址：<span class="hljs-number">0xc0000840b0</span><br>=&gt; <span class="hljs-number">0x0000000000456b47</span> &lt;+<span class="hljs-number">55</span>&gt;:    <span class="hljs-keyword">mov</span>    <span class="hljs-number">0x28</span>(%rsp),%rdi         <br>   <span class="hljs-number">0x0000000000456b4c</span> &lt;+<span class="hljs-number">60</span>&gt;:    <span class="hljs-keyword">test</span>   %al,(%rdi)<br>   # 这里判断是否开启了屏障（垃圾回收的扫描并发过程，才会把这个标记打开，没有打开的情况，对于堆上的赋值只是多走一次判断开销）<br>   <span class="hljs-number">0x0000000000456b4e</span> &lt;+<span class="hljs-number">62</span>&gt;:    cmpl   <span class="hljs-number">$0</span>x0,<span class="hljs-number">0x960fb</span>(%rip)        # <span class="hljs-number">0x4ecc50</span> &lt;runtime<span class="hljs-number">.</span>writeBarrier&gt;<br>   <span class="hljs-number">0x0000000000456b55</span> &lt;+<span class="hljs-number">69</span>&gt;:    <span class="hljs-keyword">je</span>     <span class="hljs-number">0x456b59</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">73</span>&gt;<br>   <span class="hljs-number">0x0000000000456b57</span> &lt;+<span class="hljs-number">71</span>&gt;:    <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b68</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">88</span>&gt;<br>   # 赋值 a<span class="hljs-number">.</span>base = xxxx<br>   <span class="hljs-number">0x0000000000456b59</span> &lt;+<span class="hljs-number">73</span>&gt;:    <span class="hljs-keyword">mov</span>    %rax,(%rdi)<br>   <span class="hljs-number">0x0000000000456b5c</span> &lt;+<span class="hljs-number">76</span>&gt;:    <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b5e</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">78</span>&gt;<br>   <span class="hljs-number">0x0000000000456b5e</span> &lt;+<span class="hljs-number">78</span>&gt;:    <span class="hljs-keyword">mov</span>    <span class="hljs-number">0x18</span>(%rsp),%rbp<br>   <span class="hljs-number">0x0000000000456b63</span> &lt;+<span class="hljs-number">83</span>&gt;:    <span class="hljs-keyword">add</span>    <span class="hljs-number">$0</span>x20,%rsp<br>   <span class="hljs-number">0x0000000000456b67</span> &lt;+<span class="hljs-number">87</span>&gt;:    retq   <br>   # 如果是开启了屏障，那么完成 a<span class="hljs-number">.</span>base = xxx 的赋值就是在 gcWriteBarrier 函数里面了<br>   <span class="hljs-number">0x0000000000456b68</span> &lt;+<span class="hljs-number">88</span>&gt;:    callq  <span class="hljs-number">0x44d170</span> &lt;runtime<span class="hljs-number">.</span>gcWriteBarrier&gt;<br>   <span class="hljs-number">0x0000000000456b6d</span> &lt;+<span class="hljs-number">93</span>&gt;:    <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b5e</span> &lt;main<span class="hljs-number">.</span>funcAlloc0+<span class="hljs-number">78</span>&gt;<br>   <span class="hljs-number">0x0000000000456b6f</span> &lt;+<span class="hljs-number">95</span>&gt;:    callq  <span class="hljs-number">0x44b370</span> &lt;runtime<span class="hljs-number">.</span>morestack_noctxt&gt;<br>   <span class="hljs-number">0x0000000000456b74</span> &lt;+<span class="hljs-number">100</span>&gt;:   <span class="hljs-keyword">jmp</span>    <span class="hljs-number">0x456b10</span> &lt;main<span class="hljs-number">.</span>funcAlloc0&gt;<br>End of assembler dump.<br></code></pre></td></tr></table></figure><p><strong>所以，从上面简单的汇编代码，我们印证得出几个小知识点</strong>：</p><ol><li>golang 传参和返回参数都是通过栈来传递的（可以思考下优略点，有点是逻辑简单了，也能很好的支持多返回值的实现，缺点是比寄存器的方式略慢，但是这种损耗在程序的运行下可以忽略）；</li><li>写屏障是一段编译器插入的特殊代码，在编译期间插入，代码函数名字叫做 <code>gcWriteBarrier</code> ；</li><li>屏障代码并不是直接运行，也是要条件判断的，并不是只要是堆上内存赋值就会运行gcWriteBarrier 代码，而是要有一个条件判断。这里提前透露下，这个条件判断是垃圾回收器扫描开始前，stw 程序给设置上去的；<ol><li>所以平时对于堆上内存的赋值，多了一次写操作；</li></ol></li></ol><p>伪代码如下：</p><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-keyword">if</span> runtime.writeBarrier.enabled &#123;<br>    runtime.gc<span class="hljs-constructor">WriteBarrier(<span class="hljs-params">ptr</span>, <span class="hljs-params">val</span>)</span><br>&#125; <span class="hljs-keyword">else</span> &#123;<br>    *ptr = <span class="hljs-keyword">val</span><br>&#125;<br></code></pre></td></tr></table></figure><p><code>runtime·gcWriteBarrier</code> 函数干啥的，这个函数是用纯汇编写的，举一个特定cpu集合的例子，在 asm_amd64.s 里的实现。这个函数只干两件事：</p><ol><li>执行写请求</li><li>处理 GC 相关的逻辑</li></ol><p>下面简单理解下 <code>runtime·gcWriteBarrier</code> 这个函数：</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs x86asm">TEXT runtime·gcWriteBarrier(SB),<span class="hljs-built_in">NOSPLIT</span>,<span class="hljs-number">$120</span><br><br>        get_tls(<span class="hljs-built_in">R13</span>)<br>        <span class="hljs-keyword">MOVQ</span>    g(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    g_m(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    m_p(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    (p_wbBuf+wbBuf_next)(<span class="hljs-built_in">R13</span>), <span class="hljs-built_in">R14</span><br><br>        LEAQ    <span class="hljs-number">16</span>(<span class="hljs-built_in">R14</span>), <span class="hljs-built_in">R14</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">R14</span>, (p_wbBuf+wbBuf_next)(<span class="hljs-built_in">R13</span>)<br>    // 检查 buffer 队列是否满？<br>        CMPQ    <span class="hljs-built_in">R14</span>, (p_wbBuf+wbBuf_end)(<span class="hljs-built_in">R13</span>)<br><br>    // 赋值的前后两个值都会被入队<br><br>        // 把 value 存到指定 buffer 位置<br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">AX</span>, -<span class="hljs-number">16</span>(<span class="hljs-built_in">R14</span>)   // Record value<br><br>    // 把 *slot 存到指定 buffer 位置<br>        <span class="hljs-keyword">MOVQ</span>    (<span class="hljs-built_in">DI</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">R13</span>, -<span class="hljs-number">8</span>(<span class="hljs-built_in">R14</span>)<br><br>    // 如果 wbBuffer 队列满了，那么就下刷处理，比如置灰，置黑等操作<br>        JEQ     flush<br><span class="hljs-symbol">ret:</span><br>    // 赋值：*slot = val <br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-number">104</span>(<span class="hljs-built_in">SP</span>), <span class="hljs-built_in">R14</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-number">112</span>(<span class="hljs-built_in">SP</span>), <span class="hljs-built_in">R13</span><br>        <span class="hljs-keyword">MOVQ</span>    <span class="hljs-built_in">AX</span>, (<span class="hljs-built_in">DI</span>)<br>        <span class="hljs-keyword">RET</span><br><span class="hljs-symbol"></span><br><span class="hljs-symbol">flush:</span><br>    。。。<br><br>        //  队列满了，统一处理，这个其实是一个批量优化手段<br>        <span class="hljs-keyword">CALL</span>    runtime·wbBufFlush(SB)<br><br>    。。。<br><br>        <span class="hljs-keyword">JMP</span>     <span class="hljs-keyword">ret</span><br></code></pre></td></tr></table></figure><p><strong>思考下：不是说把 <code>\*slot = value</code> 直接置灰色，置黑色，就完了嘛，这里搞得这么复杂？</strong></p><p>最开始还真不是这样的，这个也是一个优化的过程，这里是利用批量的一个思想做的一个优化。我们再理解下最本质的东西，触发了写屏障之后，我们的核心目的是为了能够把赋值的前后两个值记录下来，以便 GC 垃圾回收器能得到通知，从而避免错误的回收。记录下来是最本质的，但是并不是要立马处理，所以这里做的优化就是，攒满一个 buffer ，然后批量处理，这样效率会非常高的。</p><p>wbBuf 结构如下： |————————————-| | 8 | 8 | 8 * 512 | 4 | |————————————-|</p><p>每个 P 都有这么个 wbBuf 队列。</p><p>我们看到 <code>CALL runtime·wbBufFlush(SB)</code> ，这个函数 wbBufFlush 是 golang 实现的，本质上是调用 <code>wbBufFlush1</code> 。这个函数才是 hook 写操作想要做的事情，精简了下代码如下：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs stylus">func <span class="hljs-built_in">wbBufFlush1</span>(_p_ *p) &#123;<br>        start := <span class="hljs-built_in">uintptr</span>(unsafe<span class="hljs-selector-class">.Pointer</span>(&amp;_p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.buf</span><span class="hljs-selector-attr">[0]</span>))<br>        n := (_p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.next</span> - start) / unsafe<span class="hljs-selector-class">.Sizeof</span>(_p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.buf</span><span class="hljs-selector-attr">[0]</span>)<br>        ptrs := _p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.buf</span><span class="hljs-selector-attr">[:n]</span><br><br>        _p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.next</span> = <span class="hljs-number">0</span><br><br>        gcw := &amp;_p_<span class="hljs-selector-class">.gcw</span><br>        pos := <span class="hljs-number">0</span><br>    <span class="hljs-comment">// 循环批量处理队列里的值，这个就是之前在 gcWriteBarrier 赋值的</span><br>        <span class="hljs-keyword">for</span> _, ptr := range ptrs &#123;<br>                <span class="hljs-keyword">if</span> ptr &lt; minLegalPointer &#123;<br>                        continue<br>                &#125;<br>                obj, <span class="hljs-selector-tag">span</span>, objIndex := <span class="hljs-built_in">findObject</span>(ptr, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">if</span> obj == <span class="hljs-number">0</span> &#123;<br>                        continue<br>                &#125;<br><br>                mbits := <span class="hljs-selector-tag">span</span><span class="hljs-selector-class">.markBitsForIndex</span>(objIndex)<br>                <span class="hljs-keyword">if</span> mbits<span class="hljs-selector-class">.isMarked</span>() &#123;<br>                        continue<br>                &#125;<br>                mbits<span class="hljs-selector-class">.setMarked</span>()<br>                <span class="hljs-keyword">if</span> <span class="hljs-selector-tag">span</span><span class="hljs-selector-class">.spanclass</span><span class="hljs-selector-class">.noscan</span>() &#123;<br>                        gcw<span class="hljs-selector-class">.bytesMarked</span> += <span class="hljs-built_in">uint64</span>(<span class="hljs-selector-tag">span</span>.elemsize)<br>                        continue<br>                &#125;<br>                ptrs<span class="hljs-selector-attr">[pos]</span> = obj<br>                pos++<br>        &#125;<br><br>        <span class="hljs-comment">// 置灰色（投入灰色的队列），这就是我们的目的，对象在这里面我们就不怕了，我们要扫描的就是这个队列；</span><br>        gcw<span class="hljs-selector-class">.putBatch</span>(ptrs<span class="hljs-selector-attr">[:pos]</span>)<br><br>        _p_<span class="hljs-selector-class">.wbBuf</span><span class="hljs-selector-class">.reset</span>()<br>&#125;<br></code></pre></td></tr></table></figure><p>所以我们总结下，写屏障到底做了什么：</p><ol><li>hook 写操作</li><li>hook 住了写操作之后，把赋值语句的前后两个值都记录下来，投入 buffer 队列</li><li>buffer 攒满之后，批量刷到扫描队列（置灰）（这是 GO 1.10 左右引入的优化）</li></ol><p><strong><code>main.funcAlloc1</code></strong></p><figure class="highlight basic"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs basic"><span class="hljs-symbol">17 </span>func funcAlloc1 (b *Tstruct) &#123;<br><span class="hljs-symbol">18 </span>    var b0 Tstruct<br><span class="hljs-symbol">19 </span>    b0.<span class="hljs-keyword">base</span> = <span class="hljs-keyword">new</span>(BaseStruct)  // <span class="hljs-keyword">new</span> 一个BaseStruct结构体，赋值给 b0.<span class="hljs-keyword">base</span> 字段<br><span class="hljs-symbol">20 </span>&#125;<br></code></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/liqingqiya/liqingqiya.github.io/images/posts/2020-07-11-gc2/FB0B964D-0A0F-4650-8700-45C4278E704E.png"></p><p>最后，再回顾看下 <code>main.funcAlloc1</code> 函数，这个函数是只有栈操作，非常简单。</p><h4 id="“强-弱”-三色不变式"><a href="#“强-弱”-三色不变式" class="headerlink" title="“强-弱” 三色不变式"></a>“强-弱” 三色不变式</h4><p>我们让GC回收器，满足下面两种情况之一时，即可保对象不丢失。  这两种方式就是<strong>“强三色不变式”和“ 弱三色不变式”</strong>。</p><ul><li>强三色不变式</li></ul><p>不存在黑色对象引用到白色对象的指针。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036383192-cb6b9fe9-4946-47da-bb9a-643f0c38a654.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>弱三色不变色实际上是强制性的不允许黑色对象引用白色对象，这样就不会出现有白色对象被误删的情况。</p><ul><li>弱三色不变式</li></ul><p>所有被黑色对象引用的白色对象都处于灰色保护状态（允许黑色对象指向白色对象，但必须保证一个前提，这个白色对象必须处于灰色对象的保护下）。</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036404003-e0ea569e-7a8a-4d9f-a08f-4bb9ed5c64ed.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>弱三色不变式强调，黑色对象可以引用白色对象，但是这个白色对象必须存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象。 这样实则是黑色对象引用白色对象，白色对象处于一个危险被删除的状态，但是上游灰色对象的引用，可以保护该白色对象，使其安全。</p><p>为了遵循上述的两个方式，GC算法演进到两种屏障方式，他们<strong>“插入写屏障”, “删除写屏障”</strong>。</p><p><strong>插入写屏障：</strong></p><p><code>具体操作</code>: 在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)</p><p><code>满足</code>: <strong>强三色不变式</strong>. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)</p><p><strong>删除写屏障：</strong></p><p><code>具体操作</code>: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。</p><p><code>满足</code>: <strong>弱三色不变式</strong>. (保护灰色对象到白色对象的路径不会断)</p><h3 id="（一）插入写屏障"><a href="#（一）插入写屏障" class="headerlink" title="（一）插入写屏障"></a><strong>（一）插入写屏障</strong></h3><p>Dijkstra在1978年提出了插入写屏障，也被叫做增量更新，通过如下所示的写屏障，破坏上述第一个条件（赋值器插入了一条或多条从黑色对象到白色对象的新引用）：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-keyword">func</span> DijkstraWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) <br>     shade(ptr)  <span class="hljs-regexp">//</span>先将新下游对象 ptr 标记为灰色<br>     *slot = ptr<br>&#125;<br><br><span class="hljs-regexp">//</span>说明：<br>添加下游对象(当前下游对象slot, 新下游对象ptr) &#123; <br> <span class="hljs-regexp">//</span>step <span class="hljs-number">1</span><br> 标记灰色(新下游对象ptr) <br> <br> <span class="hljs-regexp">//</span>step <span class="hljs-number">2</span><br> 当前下游对象slot = 新下游对象ptr <br>&#125;<br><br><span class="hljs-regexp">//</span>场景：<br>A.添加下游对象(nil, B) <span class="hljs-regexp">//</span>A 之前没有下游， 新添加一个下游对象B， B被标记为灰色<br>A.添加下游对象(C, B) <span class="hljs-regexp">//</span>A 将下游对象C 更换为B， B被标记为灰色<br></code></pre></td></tr></table></figure><p>上述伪代码非常好理解，当黑色对象（slot）插入新的指向白色对象（ptr）的引用关系时，就尝试使用shade函数将这个新插入的引用（ptr）标记为灰色。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpj99S1E3KkyG9kbgAWz9mcJeJthjrVDZZ47DHBs3IgiaicSxjVvhlKUsw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>假设我们上图的例子并发可达性分析中使用插入写屏障：</p><p>1.GC 将根对象Root2指向的B对象标记成黑色并将B对象指向的对象D标记成灰色；</p><p>2.用户程序修改指针，<strong>B.next&#x3D;H</strong>这时触发写屏障将H对象标记成灰色；</p><p>3.用户程序修改指针<strong>D.next&#x3D;null</strong>；</p><p>4.GC依次遍历程序中的H和D将它们分别标记成黑色。</p><h3 id="关于栈没有写屏障的原因"><a href="#关于栈没有写屏障的原因" class="headerlink" title="关于栈没有写屏障的原因"></a>关于栈没有写屏障的原因</h3><p> 黑色对象的内存槽有两种位置, <code>栈</code>和<code>堆</code>. 栈空间的特点是<strong>容量小</strong>,但是<strong>要求响应速度快,因为函数调用弹出频繁使用</strong>, 所以“插入屏障”机制,在<strong>栈空间的对象操作中不使用</strong>. 而仅仅使用在堆空间对象的操作中.</p><p><strong>由于栈上的对象在垃圾回收中被认为是根对象，并没有写屏障，那么导致黑色的栈可能指向白色的堆对象。为了保障内存安全，Dijkstra必须为栈上的对象增加写屏障或者在标记阶段完成重新对栈上的对象进行扫描，这两种方法各有各的缺点，前者会大幅度增加写入指针的额外开销，后者重新扫描栈对象时需要暂停程序，垃圾收集算法的设计者需要在这两者之前做出权衡。</strong></p><p>​接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036442131-91f36e55-5c94-4931-a140-58ff5627c681.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036449149-2fb53d7c-d351-4305-84a8-7a1b51806ce4.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036456806-6b1aeb27-831d-43d9-a79e-4dad49fea07d.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036465710-e260440e-b53d-4f76-a826-842e28666efe.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036474130-755abe1f-d070-47e6-93cf-7aa129489206.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036481384-c4e44929-09e4-4a05-81bb-b5e9ed195982.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>​但是如果栈不添加,当全部三色标记扫描之后,栈上有可能依然存在白色对象被引用的情况(如上图的对象9).  所以要对栈重新进行三色标记扫描, 但这次为了对象不丢失, 要对本次标记扫描启动STW暂停. 直到栈空间的三色标记结束.</p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036522462-5e0c1ea9-e136-45c8-9648-bf691b270431.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036531031-d37d4239-9b13-4d0e-a9cc-d7bc230d56a8.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036538543-d84895c0-451d-4c49-9c67-f77dcf5a3ae9.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><p>​最后将栈和堆空间 扫描剩余的全部 白色节点清除.  这次STW大约的时间在10~100ms间.</p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036559017-4564c417-9059-415c-aa81-d9504ac4e00b.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h3 id="（二）删除写屏障"><a href="#（二）删除写屏障" class="headerlink" title="（二）删除写屏障"></a><strong>（二）删除写屏障</strong></h3><p>Yuasa在1990年的论文Real-time garbage collection on general-purpose machines 中提出了删除写屏障，因为一旦该写屏障开始工作，它会保证开启写屏障时堆上所有对象的可达。起始时STW扫描所有的goroutine栈，保证所有堆上在用的对象都处于灰色保护下，所以也被称作<strong>快照垃圾收集或者原始快照</strong>（Snapshot GC），这是破坏了“对象消失”的第二个条件（赋值器删除了全部从灰色对象到该白色对象的直接或间接引用）</p><p>原始快照(Snapshot At The Beginning，SATB)。当某个时刻 的 GC Roots 确定后，当时的对象图就已经确定了。当赋值器（业务线程）从灰色或者白色对象中删除白色指针时候，写屏障会捕捉这一行为，将这一行为通知给回收器。这样，基于起始快照的解决方案保守地将其目标对象当作存活的对象，这样就绝对不会有被误回收的对象，但是有扫描工作量浮动放大的风险。术语叫做追踪波面的回退。这个操作在「修改操作前」进行，JVM中 的 G1 垃圾回收器用的也是这个思路。</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-regexp">//</span> 黑色赋值器 Yuasa 屏障<br><span class="hljs-keyword">func</span> YuasaWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) &#123;<br>    shade(*slot) 先将*slot标记为灰色<br>    *slot = ptr<br>&#125;<br><br><span class="hljs-regexp">//</span>说明：<br>添加下游对象(当前下游对象slot， 新下游对象ptr) &#123;<br>  <span class="hljs-regexp">//</span>step <span class="hljs-number">1</span><br>  <span class="hljs-keyword">if</span> (当前下游对象slot是灰色 || 当前下游对象slot是白色) &#123;<br>          标记灰色(当前下游对象slot)     <span class="hljs-regexp">//</span>slot为被删除对象， 标记为灰色<br>  &#125;  <br>  <span class="hljs-regexp">//</span>step <span class="hljs-number">2</span><br>  当前下游对象slot = 新下游对象ptr<br>&#125;<br><br><span class="hljs-regexp">//</span>场景<br>A.添加下游对象(B, nil)   <span class="hljs-regexp">//</span>A对象，删除B对象的引用。B被A删除，被标记为灰(如果B之前为白)<br>A.添加下游对象(B, C)     <span class="hljs-regexp">//</span>A对象，更换下游B变成C。B被A删除，被标记为灰(如果B之前为白)<br></code></pre></td></tr></table></figure><p>上述代码会在老对象的引用被删除时，将白色的老对象涂成灰色，这样删除写屏障就可以保证弱三色不变性，老对象引用的下游对象一定可以被灰色对象引用。</p><p>但是这样也会导致一个问题，由于会将<strong>有存活可能的对象都标记成灰色</strong>，因此最后可能会导致应该回收的对象未被回收，这个对象只有在下一个循环才会被回收，比如下图的D对象。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/VY8SELNGe94Cjxng5VbT4M7FkUgyAfhpTuHVXfE7fSIbu8yNpJt877FyhAQuBB96eYr2wH7QcxKBIVxNrssIyQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p><strong>由于原始快照的原因，起始也是执行STW，删除写屏障不适用于栈特别大的场景，栈越大，STW扫描时间越长。</strong></p><p>接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_1.png" alt="delete_barrier_1"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_2.png" alt="delete_barrier_2"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_3.png" alt="delete_barrier_3"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_4.png" alt="delete_barrier_4"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_5.png" alt="delete_barrier_5"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_6.png" alt="delete_barrier_6"></p><p><img src="https://liangyaopei.github.io/2021/01/02/golang-gc-intro/delete_barrier_7.png" alt="delete_barrier_7"></p><p>这种方式的回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。</p><p><img src="C:\Users\longp\AppData\Roaming\Typora\typora-user-images\image-20220821132611515.png" alt="image-20220821132611515"></p><p><strong>插入写屏障和删除写屏障的短板：</strong></p><ul><li>插入写屏障：结束时需要STW来重新扫描栈，标记栈上引用的白色对象的存活； </li><li>删除写屏障：回收精度低，GC开始时STW扫描堆栈来记录初始快照，这个过程会保护开始时刻的所有存活对象。</li></ul><h3 id="（三）混合写屏障"><a href="#（三）混合写屏障" class="headerlink" title="（三）混合写屏障"></a><strong>（三）混合写屏障</strong></h3><p>在 Go 语言 v1.7版本之前，运行时会使用Dijkstra插入写屏障保证强三色不变性，但是运行时并没有在所有的垃圾收集根对象上开启插入写屏障。因为应用程序可能包含成百上千的Goroutine，而垃圾收集的根对象一般包括全局变量和栈对象，如果运行时需要在几百个Goroutine的栈上都开启写屏障，会带来巨大的额外开销，所以 Go 团队在v1.8结合上述2种写屏障构成了混合写屏障，实现上选择了在标记阶段完成时暂停程序、将所有栈对象标记为灰色并重新扫描。</p><p>Go 语言在v1.8组合Dijkstra插入写屏障和Yuasa删除写屏障构成了如下所示的混合写屏障，该写屏障会将被覆盖的对象标记成灰色并在当前栈没有扫描时将新对象也标记成灰色：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">writePointer</span><span class="hljs-params">(slot, ptr)</span></span>:<br>    <span class="hljs-built_in">shade</span>(*slot)<br>    <span class="hljs-keyword">if</span> current stack is grey:<br>        <span class="hljs-built_in">shade</span>(ptr)<br>    *slot = ptr<br></code></pre></td></tr></table></figure><p>为了移除栈的重扫描过程，除了引入混合写屏障之外，在垃圾收集的标记阶段，我们还需要将创建的所有新对象都标记成黑色，防止新分配的栈内存和堆内存中的对象被错误地回收，因为栈内存在标记阶段最终都会变为黑色，所以不再需要重新扫描栈空间。总结来说主要有这几点：</p><ul><li><p>GC开始将栈上的对象全部扫描并标记为黑色；</p></li><li><p>GC期间，任何在栈上创建的新对象，均为黑色；</p></li><li><p>被删除的堆对象标记为灰色；</p></li><li><p>被添加的堆对象标记为灰色。</p></li></ul><p>Go V1.8版本引入了混合写屏障机制（hybrid write barrier），避免了对栈re-scan的过程，极大的减少了STW的时间。结合了两者的优点。</p><p>最本质的区别就是：<strong>内存屏障其实就是编译器帮你生成的一段 hook 代码</strong>，这三个屏障的本质区别就是 hook 的时机不同而已。</p><hr><h4 id="1-混合写屏障规则"><a href="#1-混合写屏障规则" class="headerlink" title="(1) 混合写屏障规则"></a>(1) 混合写屏障规则</h4><p><code>具体操作</code>:</p><p>1、GC开始将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，</p><p>2、GC期间，任何在栈上创建的新对象，均为黑色。</p><p>3、被删除的对象标记为灰色。</p><p>4、被添加的对象标记为灰色。</p><p><code>满足</code>: 变形的<strong>弱三色不变式</strong>.</p><p>伪代码：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs go">添加下游对象(当前下游对象slot, 新下游对象ptr) &#123;<br>  <span class="hljs-comment">//1 </span><br>标记灰色(当前下游对象slot)    <span class="hljs-comment">//只要当前下游对象被移走，就标记灰色</span><br>  <br>  <span class="hljs-comment">//2 </span><br>  标记灰色(新下游对象ptr)<br>  <br>  <span class="hljs-comment">//3</span><br>  当前下游对象slot = 新下游对象ptr<br>&#125;<br></code></pre></td></tr></table></figure><p>这里我们注意， 屏障技术是不在栈上应用的，因为要保证栈的运行效率。</p><h4 id="2-混合写屏障的具体场景分析"><a href="#2-混合写屏障的具体场景分析" class="headerlink" title="(2) 混合写屏障的具体场景分析"></a>(2) 混合写屏障的具体场景分析</h4><p>接下来，我们用几张图，来模拟整个一个详细的过程， 希望您能够更可观的看清晰整体流程。</p><p>注意混合写屏障是Gc的一种屏障机制，所以只是当程序执行GC的时候，才会触发这种机制。</p><h5 id="GC开始：扫描栈区，将可达对象全部标记为黑"><a href="#GC开始：扫描栈区，将可达对象全部标记为黑" class="headerlink" title="GC开始：扫描栈区，将可达对象全部标记为黑"></a>GC开始：扫描栈区，将可达对象全部标记为黑</h5><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036708530-f7c50de5-6a63-45dc-baef-f53b1b42eb62.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036716310-65729a9c-d8df-40ce-9c2b-d35228278791.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><hr><h5 id="场景一：-对象被一个堆对象删除引用，成为栈对象的下游"><a href="#场景一：-对象被一个堆对象删除引用，成为栈对象的下游" class="headerlink" title="场景一： 对象被一个堆对象删除引用，成为栈对象的下游"></a>场景一： 对象被一个堆对象删除引用，成为栈对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//前提：堆对象4-&gt;对象7 = 对象7；  //对象7 被 对象4引用</span><br>栈对象<span class="hljs-number">1</span>-&gt;对象<span class="hljs-number">7</span> = 堆对象<span class="hljs-number">7</span>；  <span class="hljs-comment">//将堆对象7 挂在 栈对象1 下游</span><br>堆对象<span class="hljs-number">4</span>-&gt;对象<span class="hljs-number">7</span> = null；    <span class="hljs-comment">//对象4 删除引用 对象7</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036737874-a2f71441-c4f9-4f74-8c8a-c5a53bd35d4c.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036745104-24b7bf17-27b9-4531-97b7-48c5b7e64fac.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h5 id="场景二：-对象被一个栈对象删除引用，成为另一个栈对象的下游"><a href="#场景二：-对象被一个栈对象删除引用，成为另一个栈对象的下游" class="headerlink" title="场景二： 对象被一个栈对象删除引用，成为另一个栈对象的下游"></a>场景二： 对象被一个栈对象删除引用，成为另一个栈对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-built_in">new</span> 栈对象<span class="hljs-number">9</span>；<br>对象<span class="hljs-number">8</span>-&gt;对象<span class="hljs-number">3</span> = 对象<span class="hljs-number">3</span>；      <span class="hljs-comment">//将栈对象3 挂在 栈对象9 下游</span><br>对象<span class="hljs-number">2</span>-&gt;对象<span class="hljs-number">3</span> = null；      <span class="hljs-comment">//对象2 删除引用 对象3</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036778055-bda31c21-45dc-4602-9241-11a33b6393a6.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036785024-0edb665e-7b4b-46e3-b8cf-1d4ff02e73cd.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036791814-78eed337-a9ac-42d9-bcd8-99a21c01111c.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h5 id="场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游"><a href="#场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游" class="headerlink" title="场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游"></a>场景三：对象被一个堆对象删除引用，成为另一个堆对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">堆对象<span class="hljs-number">10</span>-&gt;对象<span class="hljs-number">7</span> = 堆对象<span class="hljs-number">7</span>；       <span class="hljs-comment">//将堆对象7 挂在 堆对象10 下游</span><br>堆对象<span class="hljs-number">4</span>-&gt;对象<span class="hljs-number">7</span> = null；         <span class="hljs-comment">//对象4 删除引用 对象7</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036826144-893174fb-0111-4838-9f7d-38fe2f89648a.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036833484-a18064d9-1329-42d7-8687-8a029542e85e.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036840569-f50df9db-5219-48fe-83ff-c3545ed4dec4.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><h5 id="场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游"><a href="#场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游" class="headerlink" title="场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游"></a>场景四：对象从一个栈对象删除引用，成为另一个堆对象的下游</h5><p>伪代码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs go">堆对象<span class="hljs-number">10</span>-&gt;对象<span class="hljs-number">7</span> = 堆对象<span class="hljs-number">7</span>；       <span class="hljs-comment">//将堆对象7 挂在 堆对象10 下游</span><br>堆对象<span class="hljs-number">4</span>-&gt;对象<span class="hljs-number">7</span> = null；         <span class="hljs-comment">//对象4 删除引用 对象7</span><br></code></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036859560-21a75ea4-ee66-46ae-81bc-ce4e697c3814.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036864959-929ec428-e8d8-48a9-aaeb-e2589723ec62.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/26269664/1651036876957-976a0ac6-6c82-4eca-88f3-10180782281c.jpeg?x-oss-process=image/watermark,type_d3F5LW1pY3JvaGVp,size_55,text_5YiY5Li55YawQWNlbGQ=,color_FFFFFF,shadow_50,t_80,g_se,x_10,y_10" alt="img"></p><p>​Golang中的混合写屏障满足<code>弱三色不变式</code>，结合了删除写屏障和插入写屏障的优点，只需要在开始时并发扫描各个goroutine的栈，使其变黑并一直保持，这个过程不需要STW，而标记结束后，因为栈在扫描后始终是黑色的，也无需再进行re-scan操作了，减少了STW的时间。</p><h2 id="五、GC演进过程"><a href="#五、GC演进过程" class="headerlink" title="五、GC演进过程"></a><strong>五、GC演进过程</strong></h2><p>v1.0 — 完全串行的标记和清除过程，需要暂停整个程序；</p><p>v1.1 — 在多核主机并行执行垃圾收集的标记和清除阶段；</p><p>v1.3 — 运行时<strong>基于只有指针类型的值包含指针</strong>的假设增加了对栈内存的精确扫描支持，实现了真正精确的垃圾收集；将unsafe.Pointer类型转换成整数类型的值认定为不合法的，可能会造成悬挂指针等严重问题；</p><p>v1.5 — 实现了基于<strong>三色标记清扫的并发</strong>垃圾收集器（插入写屏障）：</p><ul><li>大幅度降低垃圾收集的延迟从几百 ms 降低至 10ms 以下；</li><li>计算垃圾收集启动的合适时间并通过并发加速垃圾收集的过程；</li></ul><p>v1.6 — 实现了去中心化的垃圾收集协调器：</p><ul><li>基于显式的状态机使得任意Goroutine都能触发垃圾收集的状态迁移；</li><li>使用密集的位图替代空闲链表表示的堆内存，降低清除阶段的CPU占用;</li></ul><p>v1.7 — 通过<strong>并行栈收缩</strong>将垃圾收集的时间缩短至2ms以内；</p><p>v1.8 — 使用<strong>混合写屏障</strong>将垃圾收集的时间缩短至0.5ms以内；</p><p>v1.9 — 彻底移除暂停程序的重新扫描栈的过程；</p><p>v1.10 — 更新了垃圾收集调频器（Pacer）的实现，分离软硬堆大小的目标；</p><p>v1.12 — 使用<strong>新的标记终止算法</strong>简化垃圾收集器的几个阶段；</p><p>v1.13 — 通过新的 Scavenger 解决瞬时内存占用过高的应用程序向操作系统归还内存的问题；</p><p>v1.14 — 使用全新的页分配器<strong>优化内存分配的速度</strong>；</p><p>v1.15 — 改进编译器和运行时内部的CL 226367，它使编译器可以将更多的x86寄存器用于垃圾收集器的写屏障调用；</p><p>v1.16 — Go runtime默认使用MADV_DONTNEED更积极的将不用的内存释放给OS。</p><h2 id="六、GC过程"><a href="#六、GC过程" class="headerlink" title="六、GC过程"></a><strong>六、GC过程</strong></h2><p>Golang GC 相关的代码在<strong>runtime&#x2F;mgc.go</strong>文件下，可以看见GC总共分为4个阶段(翻译自Golang v1.16版本源码)：</p><p><strong>1.sweep termination（清理终止）</strong></p><ul><li><p>暂停程序，触发STW。所有的P（处理器）都会进入safe-point（安全点）；</p></li><li><p>清理未被清理的 span 。如果当前垃圾收集是强制触发的，需要处理还未被清理的内存管理单元；</p></li></ul><p><strong>2.the mark phase（标记阶段）</strong></p><ul><li>将<strong>GC状态gcphase从_GCoff改成_GCmark</strong>、开启写屏障、启用协助线程（mutator assists）、将根对象入队；</li><li>恢复程序执行，标记进程（mark workers）和协助程序会开始并发标记内存中的对象，写屏障会覆盖的重写指针和新指针（标记成灰色），而所有新创建的对象都会被直接标记成黑色；</li><li>GC执行根节点的标记，这包括扫描所有的栈、全局对象以及不在堆中的运行时数据结构。扫描goroutine栈会导致goroutine停止，并对栈上找到的所有指针加置灰，然后继续执行goroutine；</li><li>GC遍历灰色对象队列，会将灰色对象变成黑色，并将该指针指向的对象置灰；</li><li>由于GC工作分布在本地缓存中，GC会使用分布式终止算法（distributed termination algorithm）来检测何时不再有根标记作业或灰色对象，如果没有了GC会转为mark termination（标记终止）。</li></ul><p><strong>3. mark termination（标记终止）</strong></p><ul><li>STW；</li><li>将GC状态gcphase切换至_GCmarktermination，关闭gc工作线程和协助程序；</li><li>执行housekeeping，例如刷新mcaches。</li></ul><p><strong>4. the sweep phase（清理阶段）</strong></p><ul><li>将GC状态gcphase切换至_GCoff来准备清理阶段，初始化清理阶段并关闭写屏障；</li><li>恢复用户程序，从现在开始，所有新创建的对象会标记成白色；如果有必要，在使用前分配清理spans；</li><li>后台并发清理所有的内存管理类单元。</li></ul><p><strong>GC过程代码示例</strong></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">gcfinished</span><span class="hljs-params">()</span></span> *<span class="hljs-type">int</span> &#123;<br>  p := <span class="hljs-number">1</span><br>  runtime.SetFinalizer(&amp;p, <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(_ *<span class="hljs-type">int</span>)</span></span> &#123;<br>    <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;gc finished&quot;</span>)<br>  &#125;)<br>  <span class="hljs-keyword">return</span> &amp;p<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">allocate</span><span class="hljs-params">()</span></span> &#123;<br>  _ = <span class="hljs-built_in">make</span>([]<span class="hljs-type">byte</span>, <span class="hljs-type">int</span>((<span class="hljs-number">1</span>&lt;&lt;<span class="hljs-number">20</span>)*<span class="hljs-number">0.25</span>))<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<br>  f, _ := os.Create(<span class="hljs-string">&quot;trace.out&quot;</span>)<br>  <span class="hljs-keyword">defer</span> f.Close()<br>  trace.Start(f)<br>  <span class="hljs-keyword">defer</span> trace.Stop()<br>  gcfinished()<br>  <span class="hljs-comment">// 当完成 GC 时停止分配</span><br>  <span class="hljs-keyword">for</span> n := <span class="hljs-number">1</span>; n &lt; <span class="hljs-number">50</span>; n++ &#123;<br>    <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;#allocate: &quot;</span>, n)<br>    allocate()<br>  &#125;<br>  <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;terminate&quot;</span>)<br>&#125;<br></code></pre></td></tr></table></figure><p>运行程序</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">hewittwang@HEWITTWANG-MB0 rtx % <span class="hljs-attr">GODEBUG=</span><span class="hljs-attr">gctrace=</span><span class="hljs-number">1</span> go run new1.go  <br>gc <span class="hljs-number">1</span> @<span class="hljs-number">0.015s</span> <span class="hljs-number">0</span>%: <span class="hljs-number">0.015</span>+<span class="hljs-number">0.36</span>+<span class="hljs-number">0.043</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">clock</span>, <span class="hljs-number">0.18</span>+<span class="hljs-number">0.55</span>/<span class="hljs-number">0.64</span>/<span class="hljs-number">0.13</span>+<span class="hljs-number">0.52</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">cpu</span>, <span class="hljs-number">4</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">0</span> MB, <span class="hljs-number">5</span> MB goal, <span class="hljs-number">12</span> P<br>gc <span class="hljs-number">2</span> @<span class="hljs-number">0.024s</span> <span class="hljs-number">1</span>%: <span class="hljs-number">0.045</span>+<span class="hljs-number">0.19</span>+<span class="hljs-number">0.018</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">clock</span>, <span class="hljs-number">0.54</span>+<span class="hljs-number">0.37</span>/<span class="hljs-number">0.31</span>/<span class="hljs-number">0.041</span>+<span class="hljs-number">0.22</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">cpu</span>, <span class="hljs-number">4</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">0</span> MB, <span class="hljs-number">5</span> MB goal, <span class="hljs-number">12</span> P<br>....<br></code></pre></td></tr></table></figure><p>栈分析</p><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">gc <span class="hljs-number">2</span>      : 第一个GC周期<br>@<span class="hljs-number">0.024s</span>   : 从程序开始运行到第一次GC时间为<span class="hljs-number">0.024</span> 秒<br><span class="hljs-number">1</span>%        : 此次GC过程中CPU 占用率<br><br>wall clock<br><span class="hljs-number">0.045</span>+<span class="hljs-number">0.19</span>+<span class="hljs-number">0.018</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">clock</span><br><span class="hljs-number">0.045</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: STW</span>，Marking <span class="hljs-literal">Start</span>, 开启写屏障<br><span class="hljs-number">0.19</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: Marking</span>阶段<br><span class="hljs-number">0.018</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: STW</span>，Marking终止，关闭写屏障<br><br>CPU time<br><span class="hljs-number">0.54</span>+<span class="hljs-number">0.37</span>/<span class="hljs-number">0.31</span>/<span class="hljs-number">0.041</span>+<span class="hljs-number">0.22</span> <span class="hljs-keyword">ms</span> <span class="hljs-title">cpu</span><br><span class="hljs-number">0.54</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: STW</span>，Marking <span class="hljs-literal">Start</span><br><span class="hljs-number">0.37</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: 辅助标记时间</span><br><span class="hljs-title">0</span>.<span class="hljs-number">31</span> <span class="hljs-keyword">ms</span>  <span class="hljs-title">: 并发标记时间</span><br><span class="hljs-title">0</span>.<span class="hljs-number">041</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: GC</span> 空闲时间<br><span class="hljs-number">0.22</span> <span class="hljs-keyword">ms</span>   <span class="hljs-title">: Mark</span> 终止时间<br><br><span class="hljs-number">4</span>-&gt;<span class="hljs-number">4</span>-&gt;<span class="hljs-number">0</span> MB， <span class="hljs-number">5</span> MB goal<br><span class="hljs-number">4</span> MB      ：标记开始时，堆大小实际值<br><span class="hljs-number">4</span> MB      ：标记结束时，堆大小实际值<br><span class="hljs-number">0</span> MB      ：标记结束时，标记为存活对象大小<br><span class="hljs-number">5</span> MB      ：标记结束时，堆大小预测值<br><br><span class="hljs-number">12</span> P      ：本次GC过程中使用的goroutine 数量<br></code></pre></td></tr></table></figure><h2 id="七、GC触发条件"><a href="#七、GC触发条件" class="headerlink" title="七、GC触发条件"></a><strong>七、GC触发条件</strong></h2><p>运行时会通过runtime.gcTrigger.test方法决定是否需要触发垃圾收集，当满足触发垃圾收集的基本条件（即满足_GCoff阶段的退出条件）时——允许垃圾收集、程序没有崩溃并且没有处于垃圾收集循环，该方法会根据三种不同方式触发进行不同的检查：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-comment">//mgc.go 文件 runtime.gcTrigger.test</span><br> <span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(t gcTrigger)</span></span> test() <span class="hljs-type">bool</span> &#123;<br>    <span class="hljs-comment">//测试是否满足触发垃圾手机的基本条件</span><br>    <span class="hljs-keyword">if</span> !memstats.enablegc || panicking != <span class="hljs-number">0</span> || gcphase != _GCoff &#123;<br>       <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>    &#125;<br>    <span class="hljs-keyword">switch</span> t.kind &#123;<br>      <span class="hljs-keyword">case</span> gcTriggerHeap:    <span class="hljs-comment">//堆内存的分配达到达控制器计算的触发堆大小</span><br>         <span class="hljs-comment">// Non-atomic access to gcController.heapLive for performance. If</span><br>         <span class="hljs-comment">// we are going to trigger on this, this thread just</span><br>         <span class="hljs-comment">// atomically wrote gcController.heapLive anyway and we&#x27;ll see our</span><br>         <span class="hljs-comment">// own write.</span><br>         <span class="hljs-keyword">return</span> gcController.heapLive &gt;= gcController.trigger<br>      <span class="hljs-keyword">case</span> gcTriggerTime:      <span class="hljs-comment">//如果一定时间内没有触发，就会触发新的循环，该出发条件由 `runtime.forcegcperiod`变量控制，默认为 2 分钟；</span><br>         <span class="hljs-keyword">if</span> gcController.gcPercent &lt; <span class="hljs-number">0</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span><br>        &#125;<br>         lastgc := <span class="hljs-type">int64</span>(atomic.Load64(&amp;memstats.last_gc_nanotime))<br>         <span class="hljs-keyword">return</span> lastgc != <span class="hljs-number">0</span> &amp;&amp; t.now-lastgc &gt; forcegcperiod<br>      <span class="hljs-keyword">case</span> gcTriggerCycle:      <span class="hljs-comment">//如果当前没有开启垃圾收集，则触发新的循环；</span><br>         <span class="hljs-comment">// t.n &gt; work.cycles, but accounting for wraparound.</span><br>         <span class="hljs-keyword">return</span> <span class="hljs-type">int32</span>(t.n-work.cycles) &gt; <span class="hljs-number">0</span><br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span><br> &#125;<br></code></pre></td></tr></table></figure><p>用于开启垃圾回收的方法为runtime.gcStart，因此所有调用该函数的地方都是触发GC的代码：</p><ul><li>runtime.mallocgc申请内存时根据堆大小触发GC</li><li>runtime.GC用户程序手动触发GC</li><li>runtime.forcegchelper后台运行定时检查触发GC</li></ul><p><strong>（一）申请内存触发runtime.mallocgc</strong></p><p>Go运行时会将堆上的对象按大小分成微对象、小对象和大对象三类，这三类对象的创建都可能会触发新的GC。</p><p>1.当前线程的内存管理单元中不存在空闲空间时，创建微对象(noscan &amp;&amp;size&lt;maxTinySize)和小对象需要调用 runtime.mcache.nextFree从中心缓存或者页堆中获取新的管理单元，这时如果span满了就会导致返回的shouldhelpgc&#x3D;true，就可能触发垃圾收集；</p><p>2.当用户程序申请分配32KB以上的大对象时，一定会构建 runtime.gcTrigger结构体尝试触发垃圾收集。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">mallocgc</span><span class="hljs-params">(size <span class="hljs-type">uintptr</span>, typ *_type, needzero <span class="hljs-type">bool</span>)</span></span> unsafe.Pointer &#123;<br>    省略代码 ...<br>    shouldhelpgc := <span class="hljs-literal">false</span>  <br>  dataSize := size<br>  c := getMCache()       <span class="hljs-comment">//尝试获取mCache。如果没启动或者没有P,返回nil；</span><br> <br>    省略代码 ...<br>    <span class="hljs-keyword">if</span> size &lt;= maxSmallSize &#123;  <br>       <span class="hljs-keyword">if</span> noscan &amp;&amp; size &lt; maxTinySize &#123; <span class="hljs-comment">// 微对象分配</span><br>  省略代码 ...<br>          v := nextFreeFast(span)<br>          <span class="hljs-keyword">if</span> v == <span class="hljs-number">0</span> &#123;<br>             v, span, shouldhelpgc = c.nextFree(tinySpanClass)<br>          &#125;<br>      省略代码 ...<br>      &#125; <span class="hljs-keyword">else</span> &#123;      <span class="hljs-comment">//小对象分配</span><br>         省略代码 ...<br>          <span class="hljs-keyword">if</span> v == <span class="hljs-number">0</span> &#123;<br>             v, span, shouldhelpgc = c.nextFree(spc)<br>          &#125;<br>        省略代码 ...<br>      &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>       shouldhelpgc = <span class="hljs-literal">true</span><br>       省略代码 ...<br>    &#125;<br>  省略代码 ...<br>    <span class="hljs-keyword">if</span> shouldhelpgc &#123;      <span class="hljs-comment">//是否应该触发gc</span><br>      <span class="hljs-keyword">if</span> t := (gcTrigger&#123;kind: gcTriggerHeap&#125;); t.test() &#123;   <span class="hljs-comment">//如果满足gc触发条件就调用gcStart()</span><br>          gcStart(t)<br>      &#125;<br>    &#125;<br>  省略代码 ...<br>    <span class="hljs-keyword">return</span> x<br> &#125;<br></code></pre></td></tr></table></figure><p>这个时候调用t.test()执行的是gcTriggerHeap情况，只需要判断gcController.heapLive &gt;&#x3D; gcController.trigger的真假就可以了。 heapLive表示垃圾收集中存活对象字节数，trigger表示触发标记的堆内存大小的；当内存中存活的对象字节数大于触发垃圾收集的堆大小时，新一轮的垃圾收集就会开始。</p><p>1.heapLive — 为了减少锁竞争，运行时只会在中心缓存分配或者释放内存管理单元以及在堆上分配大对象时才会更新；</p><p>2.trigger — 在标记终止阶段调用runtime.gcSetTriggerRatio更新触发下一次垃圾收集的堆大小，它能够决定触发垃圾收集的时间以及用户程序和后台处理的标记任务的多少，利用反馈控制的算法根据堆的增长情况和垃圾收集CPU利用率确定触发垃圾收集的时机。</p><p><strong>（二）手动触发runtime.GC</strong></p><p>用户程序会通过runtime.GC函数在程序运行期间主动通知运行时执行，该方法在调用时会阻塞调用方直到当前垃圾收集循环完成，在垃圾收集期间也可能会通过STW暂停整个程序：</p><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs awk"><span class="hljs-keyword">func</span> GC() &#123;<br>    <span class="hljs-regexp">//</span>在正式开始垃圾收集前，运行时需要通过runtime.gcWaitOnMark等待上一个循环的标记终止、标记和清除终止阶段完成；<br>    n := atomic.Load(&amp;work.cycles)<br>    gcWaitOnMark(n)<br> <br>  <span class="hljs-regexp">//</span>调用 `runtime.gcStart` 触发新一轮的垃圾收集<br>    gcStart(gcTrigger&#123;kind: gcTriggerCycle, n: n + <span class="hljs-number">1</span>&#125;)<br> <br>    <span class="hljs-regexp">//</span>`runtime.gcWaitOnMark` 等待该轮垃圾收集的标记终止阶段正常结束；<br>    gcWaitOnMark(n + <span class="hljs-number">1</span>)<br> <br>    <span class="hljs-regexp">//</span> 持续调用 `runtime.sweepone` 清理全部待处理的内存管理单元并等待所有的清理工作完成<br>    <span class="hljs-keyword">for</span> atomic.Load(&amp;work.cycles) == n+<span class="hljs-number">1</span> &amp;&amp; sweepone() != ^uintptr(<span class="hljs-number">0</span>) &#123;<br>        sweep.nbgsweep++<br>        Gosched()  <span class="hljs-regexp">//</span>等待期间会调用 `runtime.Gosched` 让出处理器<br>    &#125;<br> <br>    <span class="hljs-regexp">//</span><br>    <span class="hljs-keyword">for</span> atomic.Load(&amp;work.cycles) == n+<span class="hljs-number">1</span> &amp;&amp; !isSweepDone() &#123;<br>        Gosched()<br>    &#125;<br> <br>    <span class="hljs-regexp">//</span> 完成本轮垃圾收集的清理工作后，通过 `runtime.mProf_PostSweep` 将该阶段的堆内存状态快照发布出来，我们可以获取这时的内存状态<br>    mp := acquirem()<br>    cycle := atomic.Load(&amp;work.cycles)<br>    <span class="hljs-keyword">if</span> cycle == n+<span class="hljs-number">1</span> || (gcphase == _GCmark &amp;&amp; cycle == n+<span class="hljs-number">2</span>) &#123;   <span class="hljs-regexp">//</span>仅限于没有启动其他标记终止过程<br>        mProf_PostSweep()<br>    &#125;<br>    releasem(mp)<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>（三）后台运行定时检查触发runtime.forcegchelper</strong></p><p>运行时会在应用程序启动时在后台开启一个用于强制触发垃圾收集的Goroutine，该Goroutine调用runtime.gcStart尝试启动新一轮的垃圾收集：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs stylus"><span class="hljs-comment">// start forcegc helper goroutine</span><br>func <span class="hljs-built_in">init</span>() &#123;<br>   go <span class="hljs-built_in">forcegchelper</span>()<br>&#125;<br> <br>func <span class="hljs-built_in">forcegchelper</span>() &#123;<br>   forcegc<span class="hljs-selector-class">.g</span> = <span class="hljs-built_in">getg</span>()<br>   <span class="hljs-built_in">lockInit</span>(&amp;forcegc<span class="hljs-selector-class">.lock</span>, lockRankForcegc)<br>   <span class="hljs-keyword">for</span> &#123;<br>      <span class="hljs-built_in">lock</span>(&amp;forcegc.lock)<br>      <span class="hljs-keyword">if</span> forcegc<span class="hljs-selector-class">.idle</span> != <span class="hljs-number">0</span> &#123;<br>         <span class="hljs-built_in">throw</span>(<span class="hljs-string">&quot;forcegc: phase error&quot;</span>)<br>      &#125;<br>      atomic<span class="hljs-selector-class">.Store</span>(&amp;forcegc<span class="hljs-selector-class">.idle</span>, <span class="hljs-number">1</span>)<br>      <br>     <span class="hljs-comment">//该 Goroutine 会在循环中调用runtime.goparkunlock主动陷入休眠等待其他 Goroutine 的唤醒</span><br>      <span class="hljs-built_in">goparkunlock</span>(&amp;forcegc<span class="hljs-selector-class">.lock</span>, waitReasonForceGCIdle, traceEvGoBlock, <span class="hljs-number">1</span>)<br>       <br>      <span class="hljs-keyword">if</span> debug<span class="hljs-selector-class">.gctrace</span> &gt; <span class="hljs-number">0</span> &#123;<br>         <span class="hljs-built_in">println</span>(<span class="hljs-string">&quot;GC forced&quot;</span>)<br>      &#125;<br>      <span class="hljs-comment">// Time-triggered, fully concurrent.</span><br>      <span class="hljs-built_in">gcStart</span>(gcTrigger&#123;kind: gcTriggerTime, n<br>      ow: <span class="hljs-built_in">nanotime</span>()&#125;)<br>   &#125;<br>&#125;<br></code></pre></td></tr></table></figure><h2 id="八、问题思考"><a href="#八、问题思考" class="headerlink" title="八、问题思考"></a>八、问题思考</h2><p>1.为什么删除写屏障的时候要原始快照？</p><p>2.删除写屏障出现已扫描黑色对象新增白色对象的怎么处理？</p><p>3.关于内存管理，gc整体流程，go如何将代码转化为二进制？</p><p><strong>参考文献</strong></p><p>  1.《Go语言设计与实现》</p><p>(<a href="https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/">https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-garbage-collector/</a>)</p><p>  2.《一个专家眼中的Go与Java垃圾回收算法大对比》</p><p>(<a href="https://blog.csdn.net/u011277123/article/details/53991572">https://blog.csdn.net/u011277123/article/details/53991572</a>)</p><p>  3.《Go语言问题集》</p><p>(<a href="https://www.bookstack.cn/read/qcrao-Go-Questions/spilt.19.GC-GC.md">https://www.bookstack.cn/read/qcrao-Go-Questions/spilt.19.GC-GC.md</a>)</p><p>   4.《CMS垃圾收集器》</p><p>(<a href="https://juejin.cn/post/6844903782107578382">https://juejin.cn/post/6844903782107578382</a>)</p><p>  5.《Golang v 1.16版本源码》</p><p>(<a href="https://github.com/golang/go">https://github.com/golang/go</a>)</p><p>  6.《Golang—内存管理(内存分配)》</p><p>(<a href="http://t.zoukankan.com/zpcoding-p-13259943.html">http://t.zoukankan.com/zpcoding-p-13259943.html</a>)</p><p>  7.《深入理解Java虚拟机：JVM高级特性与最佳实践（第3版）》—机械工业出版社</p><p>  8.《腾讯妹子图解Golang内存分配和垃圾回收》](<a href="https://mp.weixin.qq.com/s/iAy9ReQhnmCYUFvwYroGPA">https://mp.weixin.qq.com/s/iAy9ReQhnmCYUFvwYroGPA</a>)</p><p>  9.<a href="https://www.yuque.com/aceld/golang/zhzanb">《Golang修养之路》</a></p><ol start="10"><li><p><a href="https://golang.design/under-the-hood/zh-cn/part2runtime/ch08gc/barrier/">https://golang.design/under-the-hood/zh-cn/part2runtime/ch08gc/barrier/</a></p></li><li><p><a href="https://liqingqiya.github.io/golang/gc/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/2020/06/02/gc2.html">https://liqingqiya.github.io/golang/gc/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/2020/06/02/gc2.html</a></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>golang</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>golang</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Kubernetes 网络基础</title>
    <link href="/2022/08/27/Kubernetes-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"/>
    <url>/2022/08/27/Kubernetes-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="Kubernetes-网络模型基础"><a href="#Kubernetes-网络模型基础" class="headerlink" title="Kubernetes 网络模型基础"></a>Kubernetes 网络模型基础</h1><p>github对应地址：<a href="https://github.com/longpi1/Reading-notes/blob/main/kuberneters/%E7%BD%91%E7%BB%9C/Kubernetes%20%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md">https://github.com/longpi1/Reading-notes/blob/main/kuberneters/%E7%BD%91%E7%BB%9C/Kubernetes%20%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80.md</a></p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Kubernetes 是为运行分布式集群而建立的，分布式系统的本质使得网络成为 Kubernetes 的核心和必要组成部分，了解 Kubernetes 网络模型可以使你能够正确运行、监控和排查应用程序故障。</p><p><img src="https://s2.loli.net/2022/08/27/OlUZo4yNiTAPgmC.png" alt="网络模型.png"></p><p>网络是非常复杂的，拥有许多概念，对于不熟悉这个领域的用户来说，这可能会有一定的难度，这里面有很多概念需要理解，并且还需要把这些概念整合起来形成一个连贯的整体，比如网络命名空间、虚拟接口、IP 转发、NAT 等概念。</p><p>Kubernetes 中对任何网络实现都规定了以下的一些要求：</p><ul><li>所有 Pod 都可以在不使用 NAT 的情况下与所有其他 Pod 进行通信</li><li>所有节点都可以在没有 NAT 的情况下与所有 Pod 进行通信</li><li>Pod 自己的 IP 与其他 Pod 看到的 IP 是相同的</li></ul><p>鉴于这些限制，我们需要解决几个不同的网络问题：</p><ol><li>容器到容器的网络</li><li>Pod 到 Pod 的网络</li><li>Pod 到 Service 的网络</li><li>互联网到 Service 的网络</li></ol><p>接下来我们将来讨论这些问题及其解决方案。</p><h2 id="容器到容器网络"><a href="#容器到容器网络" class="headerlink" title="容器到容器网络"></a>容器到容器网络</h2><p>通常情况下我们将虚拟机中的网络通信视为直接与以太网设备进行交互，如图1所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgCV9T9zxQ7pfMHEiauW3V6z9TiaUIrm4TfdVibb5hNJMJO7OticAOK1v6Ng/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                <strong>图1.网络设备的理想视图</strong></p><p>实际的情况肯定比这要复杂，在 Linux 中，每个正在运行的进程都在一个网络命名空间内进行通信，该命名空间提供了一个具有自己的路由、防火墙规则和网络设备的逻辑网络栈，从本质上讲，网络命名空间为命名空间内的所有进程提供了一个全新的网络堆栈。</p><p>Linux 用户可以使用 <code>ip</code> 命令创建网络命名空间。例如，以下命令将创建一个名为 ns1 的网络命名空间。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">$<span class="hljs-built_in"> ip </span>netns <span class="hljs-built_in">add</span> ns1 <br></code></pre></td></tr></table></figure><p>命名空间创建后，会在 <code>/var/run/netns</code> 下面为其创建一个挂载点，即使没有附加任何进程，命名空间也是可以保留的。</p><p>你可以通过列出 <code>/var/run/netns</code> 下的所有挂载点或使用 <code>ip</code> 命令来列出可用的命名空间。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash"><span class="hljs-built_in">ls</span> /var/run/netns</span><br>ns1<br><span class="hljs-meta prompt_">$ </span><span class="language-bash">ip netns</span><br>ns1<br></code></pre></td></tr></table></figure><p>默认情况下，Linux 将为每个进程分配到 root network namespace，以提供访问外部的能力，如图2所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgoTjJmceqShbEoZ6ibwMOA1VZOV2yYQmN6z9BovoSiafExusQt9dpyu0A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                <strong>图2.root network namespace</strong></p><p>对于 Docker 而言，一个 Pod 会被构建成一组共享网络命名空间的 Docker 容器，Pod 中的容器都有相同的 IP 地址和端口空间，它们都是通过分配给 Pod 的网络命名空间来分配的，并且可以通过 localhost 访问彼此，因为它们位于同一个命名空间中。这是使用 Docker 作为 Pod 容器来实现的，它持有网络命名空间，而应用容器则通过 Docker 的 <code>-net=container:sandbox-container</code> 功能加入到该命名空间中，图3显示了每个 Pod 如何由共享网络命名空间内的多个 Docker 容器（<code>ctr*</code>）组成的。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgx14N89bgPKjXwqTDV2ia9FbbLyLP2fGEvBrMUT5U4ibvq87nySmZ1xTQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                               <strong>图3.每个 Pod 的网络命名空间</strong></p><p>此外 Pod 中的容器还可以访问共享卷，这些卷被定义为 Pod 的一部分，并且可以挂载到每个容器的文件系统中。</p><h2 id="Pod-到-Pod-网络"><a href="#Pod-到-Pod-网络" class="headerlink" title="Pod 到 Pod 网络"></a>Pod 到 Pod 网络</h2><p>在 Kubernetes 中，每个 Pod 都有一个真实的 IP 地址，每个 Pod 都使用该 IP 地址与其他 Pod 进行通信。接下来我们将来了解 Kubernetes 如何使用真实的 IP 来实现 Pod 与 Pod 之间的通信的。我们先来讨论同一节点上的 Pod 通信的方式。</p><p>从 Pod 的角度来看，它存在于自己的网络命名空间中，需要与同一节点上的其他网络命名空间进行通信。值得庆幸的时候，命名空间可以使用 Linux 虚拟以太网设备或由两个虚拟接口组成的 <code>veth</code> 对进行连接，这些虚拟接口可以分布在多个命名空间上。要连接 Pod 命名空间，我们可以将 veth 对的的一侧分配给 root network namespace，将另一侧分配给 Pod 的网络命名空间。每个 veth 对就像一根网线，连接两侧并允许流量在它们之间流动。这种设置可以复制到节点上的任意数量的 Pod。图4显示了连接虚拟机上每个 Pod 的 root network namespace 的 veth 对。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgiav7goAhdM2Fg40BpBNia6OmnP1yZJ0O2aD9ajK98r46EfkGxIfMYJzQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                  <strong>图4.Pod 的 veth 对</strong></p><p>现在 Pod 都有自己的网络命名空间，这样它们就有自己的网络设备和 IP 地址，并且它们连接到节点的 root 命名空间，现在我们希望 Pod 能够通过 root 命名空间进行通信，那么我们将要使用一个网络 <em>bridge（网桥）</em>来实现。</p><p>Linux bridge 是用纯软件实现的虚拟交换机，有着和物理交换机相同的功能，例如二层交换，MAC 地址学习等。因此我们可以把 veth pair 等设备绑定到网桥上，就像是把设备连接到物理交换机上一样。bridge 的工作方式是通过检查通过它的数据包目的地，并决定是否将数据包传递给连接到网桥的其他网段，从而在源和目的地之间维护一个转发表。bridge 通过查看网络中每个以太网设备的唯一 MAC 地址来决定是桥接数据还是丢弃数据。</p><p>Bridges 实现了 ARP 协议来发现与指定 IP 地址关联的链路层 MAC 地址。当 bridge 接收到数据帧的时候，bridge 将该帧广播给所有连接的设备（原始发送者除外），响应该帧的设备被存储在一个查找表中，未来具有相同 IP 地址的通信使用查找表来发现正确的 MAC 地址来转发数据包。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgaC5x2L2NGESEDibAC2J9Y4cSics1zvr3vlQEubR88po8icKdIZnzVDGag/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                          <strong>图5.使用桥接连接命名空间</strong></p><h3 id="同节点-Pod-通信"><a href="#同节点-Pod-通信" class="headerlink" title="同节点 Pod 通信"></a>同节点 Pod 通信</h3><p>网络命名空间将每个 Pod 隔离到自己的网络堆栈中，虚拟以太网设备将每个命名空间连接到根命名空间，以及一个将命名空间连接在一起的网桥，这样我们就准备好在同一节点上的 Pod 之间发送流量了，如下图6所示。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgbMZZruJE0xAuacLiaia0y3HtN4ic5QJWsCEEpHgfoWsQMboak31eaeXOg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                   <strong>图6.同节点上的Pod间的数据包移动</strong></p><p>这上图中，pod1 向自己的网络设备 <code>eth0</code> 发送了一个数据包，对于 pod1 来说，<code>eth0</code> 通过虚拟网络设备连接到 root netns 的 <code>veth0(1)</code>，网桥 <code>cbr0</code> 被配置为与 <code>veth0</code> 一端相连，一旦数据包到达网桥，网桥就会使用 ARP 协议将数据包发送到 <code>veth1(3)</code>。当数据包到达虚拟设备 <code>veth1</code> 时，它被直接转发到 pod2 的命名空间内的 <code>eth0(4)</code> 设备。这整个过程中，每个 Pod 仅与 <code>localhost</code> 上的 <code>eth0</code> 进行通信，流量就会被路由到正确的 Pod。</p><p>Kubernetes 的网络模型决定了 Pod 必须可以通过其 IP 地址跨节点访问，也就是说，一个 Pod 的 IP 地址始终对网络中的其他 Pod 是可见的，每个 Pod 看待自己的 IP 地址的方式与其他 Pod 看待它的方式是相同的。接下来我们来看看不同节点上的 Pod 之间的流量路由问题。</p><h3 id="跨节点-Pod-通信"><a href="#跨节点-Pod-通信" class="headerlink" title="跨节点 Pod 通信"></a>跨节点 Pod 通信</h3><p>在研究了如何在同一节点上的 Pod 之间路由数据包之后，接下来我们来看下不同节点上的 Pod 之间的通信。Kubernetes 网络模型要求 Pod 的 IP 是可以通过网络访问的，但它并没有规定必须如何来实现。</p><p>通常集群中的每个节点都分配有一个 <code>CIDR</code>，用来指定该节点上运行的 Pod 可用的 IP 地址。一旦以 <code>CIDR</code> 为目的地的流量到达节点，节点就会将流量转发到正确的 Pod。图7展示了两个节点之间的网络通信，假设网络可以将 <code>CIDR</code> 中的流量转发到正确的节点。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgvHLovL3sZSEtEia3tKWIDCS43V6PLN4kxIjdLnMugfW32fl4ZfHmwSg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                   <strong>图7.不同节点上的Pod间通信</strong></p><p>上图一样和图6相同的地方开始请求，但是这次目标 Pod（绿色标注）与源 Pod（蓝色标注）位于不同的节点上。数据包首先通过 pod1 的网络设备发送，该设备与 root netns（1）中的虚拟网络设备配对，最终数据包到达 root netns 的网桥（2）上。</p><p>这个时候网桥上的 ARP 会失败，因为与网桥相连的没有正确的数据包 MAC 地址。一旦失败，网桥会将数据包发送到默认路由上 - root netns 的 <code>eth0</code> 设备，此时就会路由离开节点，进入网络（3）。我们现在假设网络可以根据分配给节点的 <code>CIDR</code> 将数据包路由到正确的节点（4）。数据包进入目标节点的 root netns（VM2 上的 eth0），这那里它通过网桥路由到正确的虚拟设备（5）。最后，路由通过位于 pod4 的命名空间（6）中的虚拟设备 <code>eth0</code> 来完成。一般来说，每个节点都知道如何将数据包传递给其内部运行的 Pod，一旦数据包到达目标节点，数据包的流动方式与同一节点上的 Pod 间通信方式一样。</p><p>我们这里没有介绍如何配置网络来将 Pod IPs 的流量路由到负责这些 IP 的正确节点，这和特定的网络有关系，比如 AWS 就维护了一个 Kubernetes 容器网络插件，该插件允许在 AWS 的 VPC 环境中使用 [容器网络接口（<code>CNI</code>）插件]（<a href="https://github.com/aws/amazon-vpc-cni-k8s%EF%BC%89%E6%9D%A5%E8%BF%9B%E8%A1%8C%E8%8A%82%E7%82%B9%E5%88%B0%E8%8A%82%E7%82%B9%E7%9A%84%E7%BD%91%E7%BB%9C%E9%80%9A%E4%BF%A1%E3%80%82">https://github.com/aws/amazon-vpc-cni-k8s）来进行节点到节点的网络通信。</a></p><p>在 EC2 中，每个实例都绑定到一个弹性网络接口 (ENI)，并且所有 ENI 都连接在一个 VPC 内 —— ENI 无需额外操作即可相互访问。默认情况下，每个 EC2 实例部署一个 ENI，但你可以创建多个 ENI 并将它们部署到 EC2 实例上。Kubernetes 的 AWS CNI 插件会为节点上的每个 Pod 创建一个新的 ENI，因为 VPC 中的 ENI 已经连接到了现有 AWS 基础设施中，这使得每个 Pod 的 IP 地址可以在 VPC 内自然寻址。当 CNI 插件被部署到集群时，每个节点（EC2 实例）都会创建多个弹性网络接口，并为这些实例分配 IP 地址，从而为每个节点形成了一个 <code>CIDR</code> 块。当部署 Pod 时，有一个小的二进制文件会作为 DaemonSet 部署到 Kubernetes 集群中，从节点本地的 <code>kubelet</code> 进程接收任何添加 Pod 到网络的请求，这个二进制文件会从节点的可用 ENI 池中挑选一个可用的 IP 地址，并通过在 Linux 内核中连接虚拟网络设备和网桥将其分配给 Pod，和在同一节点内容的 Pod 通信一样，有了这个，Pod 的流量就可以跨集群内的节点进行通信了。</p><h2 id="Pod-到-Service"><a href="#Pod-到-Service" class="headerlink" title="Pod 到 Service"></a>Pod 到 Service</h2><p>上面我们已经介绍了如何在 Pod 和它们相关的 IP 地址之间的通信。但是 Pod 的 IP 地址并不是固定不变的，会随着应用的扩缩容、应用崩溃或节点重启而出现或消失，这些都可能导致 Pod IP 地址发生变化，Kubernetes 中可以通过 <em>Service</em> 对象来解决这个问题。</p><p>Kubernetes Service 管理一组 Pod，允许你跟踪一组随时间动态变化的 Pod IP 地址，Service 作为对 Pod 的抽象，为一组 Pod 分配一个虚拟的 VIP 地址，任何发往 Service VIP 的流量都会被路由到与其关联的一组 Pod。这就允许与 Service 相关的 Pod 集可以随时变更 - 客户端只需要知道 Service VIP 即可。</p><p>创建 Service 时候，会创建一个新的虚拟 IP（也称为 clusterIP），这集群中的任何地方，发往虚拟 IP 的流量都将负载均衡到与 Service 关联的一组 Pod。实际上，Kubernetes 会自动创建并维护一个分布式集群内的负载均衡器，将流量分配到 Service 相关联的健康 Pod 上。接下来让我们仔细看看它是如何工作的。</p><h3 id="netfilter-与-iptables"><a href="#netfilter-与-iptables" class="headerlink" title="netfilter 与 iptables"></a>netfilter 与 iptables</h3><p>为了在集群中执行负载均衡，Kubernetes 会依赖于 Linux 内置的网络框架 - <code>netfilter</code>。Netfilter 是 Linux 提供的一个框架，它允许以自定义处理程序的形式实现各种与网络相关的操作，Netfilter 为数据包过滤、网络地址转换和端口转换提供了各种功能和操作，它们提供了引导数据包通过网络所需的功能，以及提供禁止数据包到达计算机网络中敏感位置的能力。</p><p><code>iptables</code> 是一个用户空间程序，它提供了一个基于 table 的系统，用于定义使用 netfilter 框架操作和转换数据包的规则。在 Kubernetes 中，iptables 规则由 kube-proxy 控制器配置，该控制器会 watch kube-apiserver 的变更，当对 Service 或 Pod 的变化更新了 Service 的虚拟 IP 地址或 Pod 的 IP 地址时，iptables 规则会被自动更新，以便正确地将指向 Service 的流量路由到支持 Pod。iptables 规则会监听发往 Service VIP 的流量，并且在匹配时，从可用 Pod 集中选择一个随机 Pod IP 地址，并且 iptables 规则将数据包的目标 IP 地址从 Service 的 VIP 更改为所选的 Pod IP。当 Pod 启动或关闭时，iptables 规则集也会更新以反映集群的变化状态。换句话说，iptables 已经在节点上做了负载均衡，以将指向 Service VIP 的流量路由到实际的 Pod 的 IP 上。</p><p>在返回路径上，IP 地址来自目标 Pod，在这种情况下，iptables 再次重写 IP 头以将 Pod IP 替换为 Service 的 IP，以便 Pod 认为它一直只与 Service 的 IP 通信。</p><h3 id="IPVS"><a href="#IPVS" class="headerlink" title="IPVS"></a>IPVS</h3><p>Kubernetes 新版本已经提供了另外一个用于集群负载均衡的选项：IPVS， IPVS 也是构建在 netfilter 之上的，并作为 Linux 内核的一部分实现了传输层的负载均衡。IPVS 被合并到了 LVS（Linux 虚拟服务器）中，它在主机上运行并充当真实服务器集群前面的负载均衡器，IPVS 可以将基于 TCP 和 UDP 的服务请求定向到真实服务器，并使真实服务器的服务作为虚拟服务出现在一个 IP 地址上。这使得 IPVS 非常适合 Kubernetes 服务。</p><p>这部署 kube-proxy 时，可以指定使用 iptables 或 IPVS 来实现集群内的负载均衡。IPVS 专为负载均衡而设计，并使用更高效的数据结构（哈希表），与 iptables  相比允许更大的规模。在使用 IPVS 模式的 Service 时，会发生三件事：在 Node 节点上创建一个虚拟 IPVS 接口，将 Service 的 VIP 地址绑定到虚拟 IPVS 接口，并为每个 Service VIP 地址创建 IPVS 服务器。</p><h3 id="Pod-到-Service-通信"><a href="#Pod-到-Service-通信" class="headerlink" title="Pod 到 Service 通信"></a>Pod 到 Service 通信</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgO80nIibbUc6npiblqjuW8RAqlU6MhtBDUSRCwf4D1K81Wc9jdzwhnr8w/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                     <strong>图8. Pod 与 Service 之间通信</strong></p><p>当这 Pod 和 Service 之间路由一个数据包时，流量和以前开始的方式一样，数据包首先通过连接到 Pod 的网络命名空间（1）的 <code>eth0</code> 离开 Pod，。然后它通过虚拟网络设备到达网桥（2）。网桥上运行的 ARP 是不知道 Service 地址的，所以它通过默认路由 <code>eth0</code>（3）将数据包传输出去。到这里会有一些不同的地方了，在 <code>eth0</code> 接收之前，该数据包会被 iptables 过滤，在收到数据包后，iptables 使用 kube-proxy 在节点上安装的规则来响应 Service 或 Pod 事件，将数据包的目的地从 Service VIP 改写为特定的 Pod IP（4）。该数据包现在就要到达 pod4 了，而不是 Service 的 VIP，iptables 利用内核的 <code>conntrack</code> 工具来记录选择的 Pod，以便将来的流量会被路由到相同的 Pod。从本质上讲，iptables 直接从节点上完成了集群内的负载均衡，然后流量流向 Pod，剩下的就和前面的 Pod 到 Pod 通信一样的了（5）。</p><h3 id="Service-到-Pod-通信"><a href="#Service-到-Pod-通信" class="headerlink" title="Service 到 Pod 通信"></a>Service 到 Pod 通信</h3><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgtV3KndqR2yoKUjoRlicMAwVOAnRzQn1lzibNE7ndyQpNHQ3UoeF0toiag/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                              <strong>图9.在 Service 和 Pod 之间通信</strong></p><p>相应的回包的时候，收到该数据包的 Pod 将响应，将源 IP 标记为自己的 IP，将目标 IP 标记为最初发送数据包的 Pod(1)。进入节点后，数据包流经 iptables，它使用 <code>conntrack</code> 记住它之前所做的选择，并将数据包的源重写为 Service 的 VIP 而不是现在 Pod 的 IP(2)。从这里开始，数据包通过网桥流向与 Pod 的命名空间配对的虚拟网络设备 (3)，然后流向我们之前看到的 Pod 的虚拟网络设备 (4)。</p><h2 id="外网到-Service-通信"><a href="#外网到-Service-通信" class="headerlink" title="外网到 Service 通信"></a>外网到 Service 通信</h2><p>到这里我们已经了解了 Kubernetes 集群内的流量是如何路由的，但是更多的时候我们需要将服务暴露到外部去。这个时候会涉及到两个主要的问题：</p><ul><li>将流量从 Kubernetes 服务路由到互联网上去</li><li>将流量从互联网传到你的 Kubernetes 服务</li></ul><p>接下来我们就来讨论这些问题。</p><h3 id="出流量"><a href="#出流量" class="headerlink" title="出流量"></a>出流量</h3><p>从节点到公共 Internet 的路由流量也是和特定的网络有关系的，这取决于你的网络如何配置来发布流量的。这里我们以 AWS VPC 为例来进行说明。</p><p>在 AWS 中，Kubernetes 集群在 VPC 中运行，每个节点都分配有一个私有 IP 地址，该地址可从 Kubernetes 集群内访问。要从集群外部访问服务，你可以在 VPC 上附加一个外网网关。外网网关有两个用途：在你的 VPC 路由表中为可路由到外网的流量提供目标，以及为已分配公共 IP 地址的实例执行网络地址转换 (NAT)。NAT 转换负责将集群节点的内部 IP 地址更改为公网中可用的外部 IP 地址。</p><p>有了外网网关，VM 就可以自由地将流量路由到外网。不过有一个小问题，Pod 有自己的 IP 地址，与运行 Pod 的节点 IP 地址不同，并且外网网关的 NAT 转换仅适用于 VM IP 地址，因为它不知道哪些 Pod 在哪些 VM 上运行 —— 网关不支持容器。让我们看看 Kubernetes 是如何使用 iptables 来解决这个问题的。</p><p>在下图中，数据包源自 Pod 的命名空间 (1)，并经过连接到根命名空间 (2) 的 veth 对。一旦进入根命名空间，数据包就会从网桥移动到默认设备，因为数据包上的 IP 与连接到网桥的任何网段都不匹配。在到达根命名空间的网络设备 (3) 之前，iptables 会破坏数据包 (3)。在这种情况下，数据包的源 IP 地址是 Pod，如果我们将源保留为 Pod，外网网关将拒绝它，因为网关 NAT 只了解连接到 VM 的 IP 地址。解决方案是<strong>让 iptables 执行源 NAT</strong> —— 更改数据包源，使数据包看起来来自 VM 而不是 Pod。有了正确的源 IP，数据包现在可以离开 VM (4) 并到达外网网关 (5) 了。外网网关将执行另一个 NAT，将源 IP 从 VM 内部 IP 重写为公网IP。最后，数据包将到达互联网上 (6)。在返回的路上，数据包遵循相同的路径，并且任何源 IP 的修改都会被取消，这样系统的每一层都会接收到它理解的 IP 地址：节点或 VM 级别的 VM 内部，以及 Pod 内的 Pod IP命名空间。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgGaUDVlu2VesbE999GjqtA1WthWLBRF47ZDQ6XttQMqkjq9fc1YE3kg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                       <strong>图10.从Pod到互联网通信</strong></p><h3 id="入流量"><a href="#入流量" class="headerlink" title="入流量"></a>入流量</h3><p>让流量进入你的集群是一个非常难以解决的问题。同样这也和特定的网络环境有关系，但是一般来说入流量可以分为两种解决方案：</p><ul><li>Service LoadBalancer</li><li>Ingress 控制器</li></ul><p><strong>LoadBalancer</strong></p><p>当你创建一个 Kubernetes Service时，你可以选择指定一个 LoadBalancer 来使用它。LoadBalancer 有为你提供服务的云供应商负责创建负载均衡器，创建服务后，它将暴露负载均衡器的 IP 地址。终端用户可以直接通过该 IP 地址与你的服务进行通信。</p><p><strong>LoadBalancer 到 Service</strong></p><p>在部署了 Service 后，你使用的云提供商将会为你创建一个新的 LoadBalancer（1）。因为 LoadBalancer 不支持容器，所以一旦流量到达 LoadBalancer，它就会分布在集群的各个节点上（2）。每个节点上的 iptables 规则会将来自 LoadBalancer 的传入流量路由到正确的 Pod 上（3）。从 Pod 到客户端的响应将返回 Pod 的 IP，但客户端需要有 LoadBalancer 的 IP 地址。正如我们之前看到的，iptables 和 conntrack 被用来在返回路径上正确重写 IP 地址。</p><p>下图展示的就是托管 Pod 的三个节点前面的负载均衡器。传入流量（1）指向 Service 的 LoadBalancer，一旦 LoadBalancer 接收到数据包（2），它就会随机选择一个节点。我们这里的示例中，我们选择了没有运行 Pod 的节点 VM2（3）。在这里，运行在节点上的 iptables 规则将使用 kube-proxy 安装到集群中的内部负载均衡规则，将数据包转发到正确的 Pod。iptables 执行正确的 NAT 并将数据包转发到正确的 Pod（4）。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgjicHYRZia3uYzyTenTbsnsCcUaKZYt1PeIj69MYh8uNic3oziaicIZeFKmQ/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                      <strong>图11.外网访问 Service</strong></p><p><strong>Ingress 控制器</strong></p><p>在七层网络上 Ingress 在 HTTP&#x2F;HTTPS 协议范围内运行，并建立在 Service 之上。启用 Ingress 的第一步是使用 Kubernetes 中的 NodePort 类型的 Service，如果你将 Service 设置成 NodePort 类型，Kubernetes master 将从你指定的范围内分配一个端口，并且每个节点都会将该端口代理到你的 Service，也就是说，任何指向节点端口的流量都将使用 iptables 规则转发到 Service。</p><p>将节点的端口暴露在外网，可以使用一个 Ingress 对象，Ingress 是一个更高级别的 HTTP 负载均衡器，它将 HTTP 请求映射到 Kubernetes Service。根据控制器的实现方式，Ingress 的使用方式会有所不同。HTTP 负载均衡器，和四层网络负载均衡器一样，只了解节点 IP（而不是 Pod IP），因此流量路由同样利用由 kube-proxy 安装在每个节点上的 iptables 规则提供的内部负载均衡。</p><p>在 AWS 环境中，ALB Ingress 控制器使用 AWS 的七层应用程序负载均衡器提供 Kubernetes 入口。下图详细介绍了此控制器创建的 AWS 组件，它还演示了 Ingress 流量从 ALB 到 Kubernetes 集群的路由。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgdr38KkXPhd9AKtGnrYhn2SxGDKy0fbjFWIrfrgzXaXCzjicEIjrWzRg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片"></p><p>​                                                                                                                   <strong>图12.Ingress 控制器</strong></p><p>创建后，(1) Ingress Controller 会 watch 来自 Kubernetes APIServer 的 Ingress 事件。当它找到满足其要求的 Ingress 资源时，它会开始创建 AWS 资源。AWS 将 Application Load Balancer (ALB) (2) 用于 Ingress 资源。负载均衡器与用于将请求路由到一个或多个注册节点的 TargetGroup一起工作。(3) 在 AWS 中为 Ingress 资源描述的每个唯一 Kubernetes Service 创建 TargetGroup。(4) Listener 是一个 ALB 进程，它使用你配置的协议和端口检查连接请求。Listener 由 Ingress 控制器为你的 Ingress 资源中描述的每个端口创建。最后，为 Ingress 资源中指定的每个路径创建 TargetGroup 规则。这可以保证到特定路径的流量被路由到正确的 Kubernetes 服务上 (5)。</p><p><strong>Ingress 到 Service</strong></p><p>流经 Ingress 的数据包的生命周期与 LoadBalancer 的生命周期非常相似。主要区别在于 Ingress 知道 URL 的路径（可以根据路径将流量路由到 Service）Ingress 和节点之间的初始连接是通过节点上为每个服务暴露的端口。</p><p>部署 Service 后，你使用的云提供商将为你创建一个新的 Ingress 负载均衡器 (1)。因为负载均衡器不支持容器，一旦流量到达负载均衡器，它就会通过为你的服务端口分布在组成集群 (2) 的整个节点中。每个节点上的 iptables 规则会将来自负载均衡器的传入流量路由到正确的 Pod (3)。Pod 到客户端的响应将返回 Pod 的 IP，但客户端需要有负载均衡器的 IP 地址。正如我们之前看到的，iptables 和 conntrack 用于在返回路径上正确重写 IP。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_gif/z9BgVMEm7YtugibqBH8vj7OvmDx0O2fwgB6f7ZsmsiamnMF10mxPp1NvlmMw5sHGfqAQ0MKnkYTxlMKpjkI6Gctg/640?wx_fmt=gif&wxfrom=5&wx_lazy=1" alt="图片"></p><p>​                                                                                                                                               <strong>图13.从 Ingress 到 Service</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文介绍了 Kubernetes 网络模型以及如何实现常见网络任务。网络知识点既广泛又很深，所以我们这里不可能涵盖所有的内容，但是你可以以本文为起点，然后去深入了解你感兴趣的主题。</p><blockquote><p>原文链接：<a href="https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model">https://sookocheff.com/post/kubernetes/understanding-kubernetes-networking-model</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>Kubernetes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Kubernetes</tag>
      
      <tag>转载</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深信服内推</title>
    <link href="/2022/08/27/%E6%B7%B1%E4%BF%A1%E6%9C%8D%E5%86%85%E6%8E%A8/"/>
    <url>/2022/08/27/%E6%B7%B1%E4%BF%A1%E6%9C%8D%E5%86%85%E6%8E%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果-简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。"><a href="#帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果-简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。" class="headerlink" title="帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果 - 简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。"></a>帮忙社招、校招、实习内推，可帮忙查询最新进展、面试结果 - 简历优先处理、可以帮忙看简历以及回答力所能及的问题，欢迎大家来投，想要帮忙看简历或者问问题可以私聊加微信或者发送邮箱，由于内推岗位选择数量有限制，存在部分岗位没有显示，可以私聊我直接投递或者上官网公众号投递。</h3><h3 id="招聘网址-https-app-mokahr-com-recommendation-apply-sangfor-5369-recommendCode-NTAEMbl-jobs-isCampusJob-1-amp-commitment-E5-85-A8-E8-81-8C"><a href="#招聘网址-https-app-mokahr-com-recommendation-apply-sangfor-5369-recommendCode-NTAEMbl-jobs-isCampusJob-1-amp-commitment-E5-85-A8-E8-81-8C" class="headerlink" title="招聘网址:   https://app.mokahr.com/recommendation-apply/sangfor/5369?recommendCode=NTAEMbl#/jobs?isCampusJob=1&amp;commitment=%E5%85%A8%E8%81%8C"></a>招聘网址:   <a href="https://app.mokahr.com/recommendation-apply/sangfor/5369?recommendCode=NTAEMbl#/jobs?isCampusJob=1&amp;commitment=%E5%85%A8%E8%81%8C">https://app.mokahr.com/recommendation-apply/sangfor/5369?recommendCode=NTAEMbl#/jobs?isCampusJob=1&amp;commitment=%E5%85%A8%E8%81%8C</a></h3><h3 id="内推码：NTAEMbl-投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！"><a href="#内推码：NTAEMbl-投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！" class="headerlink" title="内推码：NTAEMbl   投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！"></a>内推码：NTAEMbl   投递时直接官网投递时填内推码即可，后续进展等问题可直接私信我！</h3><p><img src="https://s2.loli.net/2022/08/27/aR4mNMEGDWwsHfT.jpg" alt="a3a7bad9b480bd23d69abd81723f366.jpg"></p>]]></content>
    
    
    
    <tags>
      
      <tag>原创</tag>
      
      <tag>内推</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
